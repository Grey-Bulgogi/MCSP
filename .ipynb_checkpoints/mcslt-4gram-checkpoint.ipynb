{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import utility.Data_loader as D\n",
    "from utility.Model import Mcslt\n",
    "from utility.Custom import CustomDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 10736/10736 [00:02<00:00, 4835.43it/s]\n",
      "  0%|                                                                                    | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "1th- epoch: 0, train_loss = 152.95249550044537, train_acc = 0.7392873777363763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DTools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:99: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.8310055865921788:\n",
      "1th- epoch: 1, train_loss = 53.89130235463381, train_acc = 0.8913600372612949\n",
      "test Acc 0.8966480446927374:\n",
      "1th- epoch: 2, train_loss = 37.86744794994593, train_acc = 0.9233814625058221\n",
      "test Acc 0.9199255121042831:\n",
      "1th- epoch: 3, train_loss = 29.80711743235588, train_acc = 0.9371215649743828\n",
      "test Acc 0.9278398510242085:\n",
      "1th- epoch: 4, train_loss = 24.71362467110157, train_acc = 0.9493479273404751\n",
      "test Acc 0.9334264432029795:\n",
      "1th- epoch: 5, train_loss = 21.14100305363536, train_acc = 0.9569166278528178\n",
      "test Acc 0.9394785847299814:\n",
      "1th- epoch: 6, train_loss = 18.458827279508114, train_acc = 0.9630880298090359\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 7, train_loss = 16.37180996313691, train_acc = 0.9689101071262226\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 8, train_loss = 14.702631890773773, train_acc = 0.971821145784816\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 9, train_loss = 13.332399712875485, train_acc = 0.9741499767116907\n",
      "test Acc 0.9539106145251397:\n",
      "1th- epoch: 10, train_loss = 12.182999374344945, train_acc = 0.975780158360503\n",
      "test Acc 0.9543761638733705:\n",
      "1th- epoch: 11, train_loss = 11.201682919636369, train_acc = 0.9777596646483465\n",
      "test Acc 0.9557728119180633:\n",
      "1th- epoch: 12, train_loss = 10.358906438574195, train_acc = 0.9791569632044713\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 13, train_loss = 9.628010658547282, train_acc = 0.9813693525850024\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 14, train_loss = 8.984502291306853, train_acc = 0.9827666511411272\n",
      "test Acc 0.9604283054003724:\n",
      "1th- epoch: 15, train_loss = 8.410722957924008, train_acc = 0.9845132743362832\n",
      "test Acc 0.9618249534450651:\n",
      "1th- epoch: 16, train_loss = 7.907898606732488, train_acc = 0.985444806707033\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 17, train_loss = 7.4531715996563435, train_acc = 0.9864927806241267\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 18, train_loss = 7.045103847980499, train_acc = 0.9875407545412203\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 19, train_loss = 6.67870313860476, train_acc = 0.9878900791802515\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 20, train_loss = 6.347363840788603, train_acc = 0.9885887284583139\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 21, train_loss = 6.044615579769015, train_acc = 0.9890544946436889\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 22, train_loss = 5.769442206248641, train_acc = 0.9895202608290639\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 23, train_loss = 5.514131290838122, train_acc = 0.9896367023754076\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 24, train_loss = 5.28100405074656, train_acc = 0.9901024685607824\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 25, train_loss = 5.068895108997822, train_acc = 0.990801117838845\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 26, train_loss = 4.873630980029702, train_acc = 0.9910340009315324\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 27, train_loss = 4.692760572768748, train_acc = 0.9916162086632511\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 28, train_loss = 4.525629203766584, train_acc = 0.9923148579413135\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 29, train_loss = 4.372819087468088, train_acc = 0.9925477410340009\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 30, train_loss = 4.230646929703653, train_acc = 0.9930135072193759\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 31, train_loss = 4.100506934337318, train_acc = 0.9932463903120633\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 32, train_loss = 3.9759356640279293, train_acc = 0.9934792734047508\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 33, train_loss = 3.863325100392103, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 34, train_loss = 3.7575594624504447, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 35, train_loss = 3.6593574034050107, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 36, train_loss = 3.564310568384826, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 37, train_loss = 3.475091333501041, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 38, train_loss = 3.39363406971097, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 39, train_loss = 3.3136444306001067, train_acc = 0.9951094550535631\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 40, train_loss = 3.2405112450942397, train_acc = 0.9951094550535631\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 41, train_loss = 3.170648409985006, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 42, train_loss = 3.1055568801239133, train_acc = 0.9953423381462506\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 43, train_loss = 3.0417545363307, train_acc = 0.9954587796925943\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 44, train_loss = 2.9836070565506816, train_acc = 0.9956916627852818\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 45, train_loss = 2.9261993849650025, train_acc = 0.9956916627852818\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 46, train_loss = 2.87440653052181, train_acc = 0.9958081043316255\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 47, train_loss = 2.8215774185955524, train_acc = 0.9959245458779693\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 48, train_loss = 2.773360524326563, train_acc = 0.9961574289706567\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 49, train_loss = 2.7260628594085574, train_acc = 0.9962738705170004\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 50, train_loss = 2.6812671879306436, train_acc = 0.9962738705170004\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 51, train_loss = 2.638404899276793, train_acc = 0.9962738705170004\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 52, train_loss = 2.5969697758555412, train_acc = 0.9962738705170004\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 53, train_loss = 2.556624624878168, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 54, train_loss = 2.520059421658516, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 55, train_loss = 2.482325606048107, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 56, train_loss = 2.4480866342782974, train_acc = 0.9967396367023754\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 57, train_loss = 2.414825599640608, train_acc = 0.9967396367023754\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 58, train_loss = 2.3834378868341446, train_acc = 0.9967396367023754\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 59, train_loss = 2.3512084647081792, train_acc = 0.9967396367023754\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 60, train_loss = 2.321662411093712, train_acc = 0.9967396367023754\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 61, train_loss = 2.2933427267707884, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 62, train_loss = 2.2663738378323615, train_acc = 0.9967396367023754\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 63, train_loss = 2.239591009914875, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 64, train_loss = 2.2133890949189663, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "1th- epoch: 65, train_loss = 2.1892828582786024, train_acc = 0.9968560782487191\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 66, train_loss = 2.165435090661049, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 67, train_loss = 2.141988317016512, train_acc = 0.9968560782487191\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 68, train_loss = 2.1209115460515022, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 69, train_loss = 2.0995629518292844, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 70, train_loss = 2.0796636058948934, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 71, train_loss = 2.0593721023760736, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 72, train_loss = 2.0395521447062492, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 73, train_loss = 2.021629592869431, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 74, train_loss = 2.003541303332895, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 75, train_loss = 1.9862035675905645, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 76, train_loss = 1.9687327183783054, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 77, train_loss = 1.9523826763033867, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 78, train_loss = 1.9364619478583336, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 79, train_loss = 1.9215023280121386, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 80, train_loss = 1.905952375382185, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 81, train_loss = 1.8909890041686594, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 82, train_loss = 1.8770955777727067, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 83, train_loss = 1.8631242611445487, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 84, train_loss = 1.849305335432291, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 85, train_loss = 1.836859484668821, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 86, train_loss = 1.8237735007423908, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 87, train_loss = 1.8111066531855613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 88, train_loss = 1.7994658201932907, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 89, train_loss = 1.787383823422715, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 90, train_loss = 1.7753617886919528, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 91, train_loss = 1.7645016461610794, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 92, train_loss = 1.7534808330237865, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 93, train_loss = 1.7429112866520882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 94, train_loss = 1.732281205477193, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 95, train_loss = 1.7210258580744267, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 96, train_loss = 1.711800817400217, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 97, train_loss = 1.7017216496169567, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 98, train_loss = 1.6920043118298054, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 99, train_loss = 1.6831172208767384, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 100, train_loss = 1.673188328742981, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 101, train_loss = 1.6637309391517192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 102, train_loss = 1.6563915822189301, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 103, train_loss = 1.6461367297451943, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 104, train_loss = 1.6378811534959823, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 105, train_loss = 1.6298590190708637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 106, train_loss = 1.621626055566594, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 107, train_loss = 1.613478273153305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 108, train_loss = 1.6053790810983628, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 109, train_loss = 1.597761207493022, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 110, train_loss = 1.5901116468012333, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 111, train_loss = 1.5820303845684975, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 112, train_loss = 1.575550839304924, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 113, train_loss = 1.567776508629322, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 114, train_loss = 1.5608737990260124, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 115, train_loss = 1.5538763615768403, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 116, train_loss = 1.547359749674797, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 117, train_loss = 1.5407658007461578, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 118, train_loss = 1.5338984429836273, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 119, train_loss = 1.5279640145599842, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 120, train_loss = 1.521990843117237, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 121, train_loss = 1.5159408871550113, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 122, train_loss = 1.5093258905690163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 123, train_loss = 1.5037412245292217, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 124, train_loss = 1.4977716554421932, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 125, train_loss = 1.492152736755088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 126, train_loss = 1.485979673685506, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 127, train_loss = 1.4808815866708755, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 128, train_loss = 1.4755199924111366, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 129, train_loss = 1.469763807952404, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 130, train_loss = 1.4645566877443343, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 131, train_loss = 1.4601190860848874, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 132, train_loss = 1.4542416010517627, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 133, train_loss = 1.449343818007037, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 134, train_loss = 1.4438442413229495, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 135, train_loss = 1.4397329862695187, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 136, train_loss = 1.435042378725484, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 137, train_loss = 1.4296609114389867, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 138, train_loss = 1.4250754427630454, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 139, train_loss = 1.4206629295367748, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 140, train_loss = 1.415687620639801, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 141, train_loss = 1.4116224485915154, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 142, train_loss = 1.4066015431890264, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 143, train_loss = 1.4027165919542313, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 144, train_loss = 1.398429624736309, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 145, train_loss = 1.3945504178991541, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 146, train_loss = 1.3896966303000227, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 147, train_loss = 1.3856978453695774, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 148, train_loss = 1.381543700932525, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 149, train_loss = 1.3773145837476477, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 150, train_loss = 1.3732647933065891, train_acc = 0.9974382859804378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 151, train_loss = 1.368846389115788, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 152, train_loss = 1.365379884839058, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 153, train_loss = 1.3611929366597906, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 154, train_loss = 1.3573722405126318, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 155, train_loss = 1.35332613310311, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 156, train_loss = 1.349892637343146, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 157, train_loss = 1.346063214004971, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 158, train_loss = 1.3424196913838387, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 159, train_loss = 1.3385665664682165, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 160, train_loss = 1.3354503015289083, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 161, train_loss = 1.332018043845892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 162, train_loss = 1.3287105871131644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 163, train_loss = 1.3245963752269745, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 164, train_loss = 1.321692162542604, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 165, train_loss = 1.318551334203221, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 166, train_loss = 1.3151742530753836, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 167, train_loss = 1.3118780242512003, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 168, train_loss = 1.3084364732494578, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 169, train_loss = 1.3050507195293903, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 170, train_loss = 1.3020298579940572, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 171, train_loss = 1.2993638142943382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 172, train_loss = 1.2960412005195394, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 173, train_loss = 1.2929839715361595, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 174, train_loss = 1.289931240142323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 175, train_loss = 1.2869773966958746, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 176, train_loss = 1.2840028181672096, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 177, train_loss = 1.2809776017675176, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 178, train_loss = 1.278613805770874, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 179, train_loss = 1.2751306829741225, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 180, train_loss = 1.2726074369857088, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 181, train_loss = 1.2696256103226915, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 182, train_loss = 1.2672150991857052, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 183, train_loss = 1.2643937977263704, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 184, train_loss = 1.261480806977488, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 185, train_loss = 1.258545475662686, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 186, train_loss = 1.2564462944865227, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 187, train_loss = 1.2533482114085928, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 188, train_loss = 1.250772231607698, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 189, train_loss = 1.2482647895812988, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 190, train_loss = 1.245485289604403, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 191, train_loss = 1.2425114003708586, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 192, train_loss = 1.2401487914612517, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 193, train_loss = 1.2377079700818285, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 194, train_loss = 1.2350896274438128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 195, train_loss = 1.2329255379736423, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 196, train_loss = 1.2299353269627318, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 197, train_loss = 1.2278256105491892, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 198, train_loss = 1.2252706587314606, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 199, train_loss = 1.22285296022892, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 200, train_loss = 1.2207314806291834, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 201, train_loss = 1.2186840362846851, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 202, train_loss = 1.2158397088060156, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 203, train_loss = 1.213755908072926, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 204, train_loss = 1.2115201900014654, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 205, train_loss = 1.2091538993408903, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 206, train_loss = 1.2069647734751925, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 207, train_loss = 1.2054095044732094, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 208, train_loss = 1.2028408447513357, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 209, train_loss = 1.2001517489552498, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 210, train_loss = 1.1983043266227469, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 211, train_loss = 1.195874915807508, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 212, train_loss = 1.1942873956868425, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 213, train_loss = 1.191875676275231, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 214, train_loss = 1.1895455904304981, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 215, train_loss = 1.1878400134155527, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 216, train_loss = 1.1857218071818352, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 217, train_loss = 1.183833684772253, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 218, train_loss = 1.1818816115846857, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 219, train_loss = 1.1801787950098515, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 220, train_loss = 1.1776914658257738, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 221, train_loss = 1.175928475917317, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 222, train_loss = 1.174094526679255, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 223, train_loss = 1.1721253829309717, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 224, train_loss = 1.1700494649121538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 225, train_loss = 1.1687606995692477, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 226, train_loss = 1.1663763634860516, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 227, train_loss = 1.1647443833062425, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 228, train_loss = 1.1630444912007079, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 229, train_loss = 1.1606435714056715, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 230, train_loss = 1.159456081688404, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 231, train_loss = 1.1577402167022228, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 232, train_loss = 1.1561583305010572, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 233, train_loss = 1.154222670942545, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 234, train_loss = 1.1521601751446724, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 235, train_loss = 1.1505776966223493, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 236, train_loss = 1.1491152085363865, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 237, train_loss = 1.1473066123435274, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 238, train_loss = 1.145974057377316, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 239, train_loss = 1.1439596129348502, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 240, train_loss = 1.1419519148766994, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 241, train_loss = 1.1405201752786525, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 242, train_loss = 1.138970509171486, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 243, train_loss = 1.1374139984254725, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 244, train_loss = 1.1362953446805477, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 245, train_loss = 1.1340969974990003, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 246, train_loss = 1.1325645484030247, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 247, train_loss = 1.1311421965365298, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 248, train_loss = 1.1299016525154002, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 249, train_loss = 1.1280071723158471, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 250, train_loss = 1.1263218795065768, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 251, train_loss = 1.1249690068070777, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 252, train_loss = 1.1235947224195115, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 253, train_loss = 1.1223758806590922, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 254, train_loss = 1.1208596329088323, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 255, train_loss = 1.1187440405483358, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 256, train_loss = 1.1176991698448546, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 257, train_loss = 1.1162694282829762, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 258, train_loss = 1.1148221790790558, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 259, train_loss = 1.113768597424496, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 260, train_loss = 1.1120210501248948, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 261, train_loss = 1.1105580441653728, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 262, train_loss = 1.1092634337837808, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 263, train_loss = 1.1075942553579807, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 264, train_loss = 1.1064381375908852, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 265, train_loss = 1.1049713480169885, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 266, train_loss = 1.1036026043002494, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 267, train_loss = 1.102216585248243, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 268, train_loss = 1.101636177569162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 269, train_loss = 1.0998427768354304, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 270, train_loss = 1.0981874838471413, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 271, train_loss = 1.0972490571439266, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 272, train_loss = 1.0956282603438012, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 273, train_loss = 1.0942110021715052, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 274, train_loss = 1.0933479219675064, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 275, train_loss = 1.091920645267237, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 276, train_loss = 1.0908373954589479, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 277, train_loss = 1.0894488294725306, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 278, train_loss = 1.0883862686459906, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 279, train_loss = 1.0871839697356336, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 280, train_loss = 1.0858786925673485, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 281, train_loss = 1.0846588350832462, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 282, train_loss = 1.0834488905966282, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 283, train_loss = 1.082418707490433, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 284, train_loss = 1.081188503652811, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 285, train_loss = 1.0797027262742631, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 286, train_loss = 1.0788191978936084, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 287, train_loss = 1.077518243342638, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 288, train_loss = 1.0766549371182919, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 289, train_loss = 1.075339323549997, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 290, train_loss = 1.0741579246823676, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 291, train_loss = 1.0732001401484013, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 292, train_loss = 1.0716334779863246, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 293, train_loss = 1.0707680831546895, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 294, train_loss = 1.0695589085225947, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 295, train_loss = 1.0685490506584756, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 296, train_loss = 1.067142839252483, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 297, train_loss = 1.0662255088682286, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 298, train_loss = 1.0650606155395508, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 299, train_loss = 1.064030094712507, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 300, train_loss = 1.062970593571663, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 301, train_loss = 1.0616804647142999, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 302, train_loss = 1.0608106379513629, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 303, train_loss = 1.0597335982020013, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 304, train_loss = 1.0586116425693035, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 305, train_loss = 1.0580903043155558, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 306, train_loss = 1.0569809141452424, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 307, train_loss = 1.0556661213631742, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 308, train_loss = 1.0546564770047553, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 309, train_loss = 1.0537043015356176, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 310, train_loss = 1.0524125111405738, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 311, train_loss = 1.051484504074324, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 312, train_loss = 1.0507650822401047, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 313, train_loss = 1.049853228032589, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 314, train_loss = 1.0484521041507833, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 315, train_loss = 1.0478912902181037, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 316, train_loss = 1.0467076202039607, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 317, train_loss = 1.046063291549217, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 318, train_loss = 1.0451093738083728, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 319, train_loss = 1.0438010655343533, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 320, train_loss = 1.0424873232841492, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 321, train_loss = 1.0421460208599456, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 322, train_loss = 1.0412312981789, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 323, train_loss = 1.0402036681771278, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 324, train_loss = 1.039374286949169, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 325, train_loss = 1.038079598278273, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 326, train_loss = 1.037394033104647, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 327, train_loss = 1.0369195180828683, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 328, train_loss = 1.0356566433911212, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 329, train_loss = 1.0347457329626195, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 330, train_loss = 1.0345305241644382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 331, train_loss = 1.0327039982075803, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 332, train_loss = 1.0322468715603463, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 333, train_loss = 1.0312045700848103, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 334, train_loss = 1.0302019069786184, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 335, train_loss = 1.0293872480397113, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 336, train_loss = 1.0286045596003532, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 337, train_loss = 1.0277069633011706, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 338, train_loss = 1.0263958002324216, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 339, train_loss = 1.0261602327227592, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 340, train_loss = 1.024631020904053, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 341, train_loss = 1.024095578759443, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 342, train_loss = 1.0228549453313462, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 343, train_loss = 1.0220545306801796, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 344, train_loss = 1.0212648548185825, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 345, train_loss = 1.0196537573938258, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 346, train_loss = 1.0195052810013294, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 347, train_loss = 1.018808922439348, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 348, train_loss = 1.0177682017092593, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 349, train_loss = 1.0173474748735316, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 350, train_loss = 1.016283791512251, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 351, train_loss = 1.0153412111103535, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 352, train_loss = 1.014642244845163, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 353, train_loss = 1.0139297569985501, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 354, train_loss = 1.013379639654886, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 355, train_loss = 1.0120367693598382, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 356, train_loss = 1.0118708771769889, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 357, train_loss = 1.0109707564115524, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 358, train_loss = 1.0098166267271154, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 359, train_loss = 1.0092189361457713, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 360, train_loss = 1.0084893479943275, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 361, train_loss = 1.0076217887108214, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 362, train_loss = 1.0072925761342049, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 363, train_loss = 1.0064925104379654, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 364, train_loss = 1.0054755210876465, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 365, train_loss = 1.0043099522590637, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 366, train_loss = 1.003703614056576, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 367, train_loss = 1.0032087204162963, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 368, train_loss = 1.002667857974302, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 369, train_loss = 1.0018237295444123, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 370, train_loss = 1.0008747801184654, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 371, train_loss = 1.0002459163661115, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 372, train_loss = 0.9995051249861717, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 373, train_loss = 0.998916617303621, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 374, train_loss = 0.9985506907105446, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 375, train_loss = 0.9973867945373058, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 376, train_loss = 0.9965968765318394, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 377, train_loss = 0.9962105937302113, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 378, train_loss = 0.9952304835314862, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 379, train_loss = 0.994796956598293, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 380, train_loss = 0.9937803584034555, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 381, train_loss = 0.9934280390734784, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 382, train_loss = 0.9923954345285892, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 383, train_loss = 0.9920059057767503, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 384, train_loss = 0.9910208123619668, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 385, train_loss = 0.9907804454560392, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 386, train_loss = 0.9897741650347598, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 387, train_loss = 0.9895907330210321, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 388, train_loss = 0.988485271751415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 389, train_loss = 0.9881433571572416, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 390, train_loss = 0.9872621608083136, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 391, train_loss = 0.9863242271239869, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 392, train_loss = 0.9860847641830333, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 393, train_loss = 0.9853404425084591, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 394, train_loss = 0.9844324104487896, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 395, train_loss = 0.9841570767457597, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 396, train_loss = 0.9831505119800568, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 397, train_loss = 0.9827146555180661, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 398, train_loss = 0.9820101360674016, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 399, train_loss = 0.9816504840855487, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 400, train_loss = 0.9808878488838673, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 401, train_loss = 0.980293242901098, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 402, train_loss = 0.9793516099452972, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 403, train_loss = 0.9790310561656952, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 404, train_loss = 0.9783348217606544, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 405, train_loss = 0.9776939886505716, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 406, train_loss = 0.9768600066308863, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 407, train_loss = 0.976518711715471, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 408, train_loss = 0.9758984695072286, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 409, train_loss = 0.9751314210589044, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 410, train_loss = 0.974644171714317, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 411, train_loss = 0.974060510576237, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 412, train_loss = 0.9734512691793498, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 413, train_loss = 0.9730519379372708, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 414, train_loss = 0.9725499488413334, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 415, train_loss = 0.9713972074387129, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 416, train_loss = 0.9710374673304614, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 417, train_loss = 0.970466418802971, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 418, train_loss = 0.9698600383999292, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 419, train_loss = 0.9691723572614137, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 420, train_loss = 0.9687984138727188, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 421, train_loss = 0.9681343138217926, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 422, train_loss = 0.9672580510377884, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 423, train_loss = 0.9667154202761594, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 424, train_loss = 0.9661393761634827, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 425, train_loss = 0.9660085439682007, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 426, train_loss = 0.965241593628889, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 427, train_loss = 0.9646474930050317, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 428, train_loss = 0.9639193378388882, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 429, train_loss = 0.9635597007873002, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 430, train_loss = 0.9629461442527827, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 431, train_loss = 0.9622919422981795, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 432, train_loss = 0.9618974762561265, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 433, train_loss = 0.961031187325716, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 434, train_loss = 0.9605681536195334, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 435, train_loss = 0.959974579513073, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 436, train_loss = 0.9595586819050368, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 437, train_loss = 0.9588493419287261, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 438, train_loss = 0.9584130073490087, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 439, train_loss = 0.9577068226935808, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 440, train_loss = 0.9578553736209869, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 441, train_loss = 0.9569051377475262, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 442, train_loss = 0.9562863024475519, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 443, train_loss = 0.9557990431785583, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 444, train_loss = 0.9553855968115386, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 445, train_loss = 0.9547240932879504, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 446, train_loss = 0.9542191649379674, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 447, train_loss = 0.9537316113710403, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 448, train_loss = 0.9532016081211623, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 449, train_loss = 0.95269675552845, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 450, train_loss = 0.9522973621787969, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 451, train_loss = 0.9515115581452847, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 452, train_loss = 0.9511744988558348, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 453, train_loss = 0.9504037822189275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 454, train_loss = 0.9501762303116266, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 455, train_loss = 0.9495669106545392, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 456, train_loss = 0.9492444122734014, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 457, train_loss = 0.9489123920502607, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 458, train_loss = 0.9482602377829608, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 459, train_loss = 0.9478197159769479, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 460, train_loss = 0.9472863587143365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 461, train_loss = 0.9469743656518403, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 462, train_loss = 0.9461795339884702, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 463, train_loss = 0.9457675963640213, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 464, train_loss = 0.9452505061926786, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 465, train_loss = 0.9447837248444557, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 466, train_loss = 0.9444014976324979, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 467, train_loss = 0.9438703792693559, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 468, train_loss = 0.9433328745362815, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 469, train_loss = 0.9429801391961519, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 470, train_loss = 0.9425879952905234, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 471, train_loss = 0.9422770328819752, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 472, train_loss = 0.9417976178228855, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 473, train_loss = 0.9412260899844114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 474, train_loss = 0.940274794906145, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 475, train_loss = 0.940227991581196, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 476, train_loss = 0.9398255757987499, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 477, train_loss = 0.9391875875589903, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 478, train_loss = 0.9387662224471569, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 479, train_loss = 0.9382136737403926, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 480, train_loss = 0.9382308026251849, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 481, train_loss = 0.9374814704060555, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 482, train_loss = 0.9368931713106576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 483, train_loss = 0.9366155055759009, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 484, train_loss = 0.9361147073504981, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 485, train_loss = 0.9355300428869668, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 486, train_loss = 0.9356948447821196, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 487, train_loss = 0.9349302922782954, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 488, train_loss = 0.9347143160703126, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 489, train_loss = 0.9337795054016169, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 490, train_loss = 0.9332524848578032, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 491, train_loss = 0.9331828517315444, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 492, train_loss = 0.9327528066933155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 493, train_loss = 0.9323139116168022, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 494, train_loss = 0.9316638186573982, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 495, train_loss = 0.931125362723833, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 496, train_loss = 0.930744187295204, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 497, train_loss = 0.9298503398895264, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 498, train_loss = 0.9296862967312336, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 499, train_loss = 0.92946451032185, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                      | 1/30 [09:25<4:33:28, 565.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "2th- epoch: 0, train_loss = 154.08877535909414, train_acc = 0.7343968327899395\n",
      "test Acc 0.8389199255121043:\n",
      "2th- epoch: 1, train_loss = 54.000666469335556, train_acc = 0.884257102934327\n",
      "test Acc 0.8919925512104283:\n",
      "2th- epoch: 2, train_loss = 38.284685630351305, train_acc = 0.9189566837447601\n",
      "test Acc 0.9157355679702048:\n",
      "2th- epoch: 3, train_loss = 30.541963724419475, train_acc = 0.9354913833255706\n",
      "test Acc 0.9287709497206704:\n",
      "2th- epoch: 4, train_loss = 25.61072311922908, train_acc = 0.9437587331159758\n",
      "test Acc 0.9371508379888268:\n",
      "2th- epoch: 5, train_loss = 22.09210024960339, train_acc = 0.9523754075454122\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 6, train_loss = 19.49425300769508, train_acc = 0.9597112249650676\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 7, train_loss = 17.494698269292712, train_acc = 0.9643688868188169\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 8, train_loss = 15.884919472038746, train_acc = 0.9679785747554728\n",
      "test Acc 0.9534450651769087:\n",
      "2th- epoch: 9, train_loss = 14.560280676931143, train_acc = 0.9712389380530974\n",
      "test Acc 0.9553072625698324:\n",
      "2th- epoch: 10, train_loss = 13.434358663856983, train_acc = 0.9733348858872846\n",
      "test Acc 0.9567039106145251:\n",
      "2th- epoch: 11, train_loss = 12.470107289031148, train_acc = 0.976245924545878\n",
      "test Acc 0.9567039106145251:\n",
      "2th- epoch: 12, train_loss = 11.62745794840157, train_acc = 0.9781089892873778\n",
      "test Acc 0.957169459962756:\n",
      "2th- epoch: 13, train_loss = 10.891858991235495, train_acc = 0.9799720540288775\n",
      "test Acc 0.957635009310987:\n",
      "2th- epoch: 14, train_loss = 10.234943883493543, train_acc = 0.9814857941313461\n",
      "test Acc 0.9581005586592178:\n",
      "2th- epoch: 15, train_loss = 9.647672154009342, train_acc = 0.9824173265020959\n",
      "test Acc 0.9581005586592178:\n",
      "2th- epoch: 16, train_loss = 9.124157223850489, train_acc = 0.9838146250582208\n",
      "test Acc 0.9604283054003724:\n",
      "2th- epoch: 17, train_loss = 8.65279152803123, train_acc = 0.9848625989753144\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 18, train_loss = 8.222533855587244, train_acc = 0.985910572892408\n",
      "test Acc 0.9613594040968343:\n",
      "2th- epoch: 19, train_loss = 7.834754029288888, train_acc = 0.986376339077783\n",
      "test Acc 0.9613594040968343:\n",
      "2th- epoch: 20, train_loss = 7.481940969824791, train_acc = 0.9870749883558454\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 21, train_loss = 7.1576802264899015, train_acc = 0.9877736376339078\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 22, train_loss = 6.860830852761865, train_acc = 0.9883558453656265\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 23, train_loss = 6.585060361772776, train_acc = 0.9885887284583139\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 24, train_loss = 6.328203837387264, train_acc = 0.9888216115510013\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 25, train_loss = 6.0907535115256906, train_acc = 0.9897531439217513\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 26, train_loss = 5.868636918254197, train_acc = 0.9904517931998137\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 27, train_loss = 5.661407423205674, train_acc = 0.9906846762925011\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 28, train_loss = 5.469127067364752, train_acc = 0.9909175593851887\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 29, train_loss = 5.289596260525286, train_acc = 0.9910340009315324\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 30, train_loss = 5.121979305520654, train_acc = 0.9913833255705635\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 31, train_loss = 4.9649868961423635, train_acc = 0.9917326502095948\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 32, train_loss = 4.816424286924303, train_acc = 0.9921984163949698\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 33, train_loss = 4.6769201857969165, train_acc = 0.9921984163949698\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 34, train_loss = 4.545580157078803, train_acc = 0.9924312994876572\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 35, train_loss = 4.423070803284645, train_acc = 0.9927806241266884\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 36, train_loss = 4.305373953655362, train_acc = 0.9928970656730322\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 37, train_loss = 4.195290530100465, train_acc = 0.9928970656730322\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 38, train_loss = 4.089703225530684, train_acc = 0.9933628318584071\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 39, train_loss = 3.9928597696125507, train_acc = 0.9934792734047508\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 40, train_loss = 3.898769238963723, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 41, train_loss = 3.8118656426668167, train_acc = 0.9940614811364695\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 42, train_loss = 3.7246999740600586, train_acc = 0.9940614811364695\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 43, train_loss = 3.6453005922958255, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 44, train_loss = 3.5708791026845574, train_acc = 0.9940614811364695\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 45, train_loss = 3.496503201313317, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 46, train_loss = 3.427202694118023, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 47, train_loss = 3.3599740881472826, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 48, train_loss = 3.2956131785176694, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 49, train_loss = 3.2357391021214426, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 50, train_loss = 3.1775516546331346, train_acc = 0.9952258965999069\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 51, train_loss = 3.120488622225821, train_acc = 0.9952258965999069\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 52, train_loss = 3.067048102617264, train_acc = 0.9952258965999069\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 53, train_loss = 3.0163455032743514, train_acc = 0.9952258965999069\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 54, train_loss = 2.966916303150356, train_acc = 0.9953423381462506\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 55, train_loss = 2.919595700222999, train_acc = 0.9953423381462506\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 56, train_loss = 2.8747266051359475, train_acc = 0.9954587796925943\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 57, train_loss = 2.8312040749005973, train_acc = 0.995575221238938\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 58, train_loss = 2.7887359033338726, train_acc = 0.9956916627852818\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 59, train_loss = 2.74814465129748, train_acc = 0.9958081043316255\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 60, train_loss = 2.7103391704149544, train_acc = 0.9958081043316255\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 61, train_loss = 2.672939245123416, train_acc = 0.9958081043316255\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 62, train_loss = 2.6363779683597386, train_acc = 0.996040987424313\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 63, train_loss = 2.6023486722260714, train_acc = 0.996040987424313\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 64, train_loss = 2.5685809985734522, train_acc = 0.996040987424313\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 65, train_loss = 2.536042164079845, train_acc = 0.996040987424313\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 66, train_loss = 2.5046636438928545, train_acc = 0.9961574289706567\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 67, train_loss = 2.4736130838282406, train_acc = 0.9962738705170004\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 68, train_loss = 2.4449695595540106, train_acc = 0.9962738705170004\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 69, train_loss = 2.4161716094240546, train_acc = 0.9963903120633442\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 70, train_loss = 2.388625120278448, train_acc = 0.9963903120633442\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 71, train_loss = 2.3618944538757205, train_acc = 0.9963903120633442\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 72, train_loss = 2.336321623530239, train_acc = 0.9963903120633442\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 73, train_loss = 2.310994925443083, train_acc = 0.9963903120633442\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 74, train_loss = 2.287037470843643, train_acc = 0.9963903120633442\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 75, train_loss = 2.2637040172703564, train_acc = 0.9963903120633442\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 76, train_loss = 2.2399593177251518, train_acc = 0.9966231951560317\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 77, train_loss = 2.2180031784810126, train_acc = 0.9966231951560317\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 78, train_loss = 2.196364908479154, train_acc = 0.9966231951560317\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 79, train_loss = 2.17434876319021, train_acc = 0.9966231951560317\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 80, train_loss = 2.154805969912559, train_acc = 0.9966231951560317\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 81, train_loss = 2.1341369226574898, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 82, train_loss = 2.1156456540338695, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 83, train_loss = 2.0963752162642777, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 84, train_loss = 2.0784191749989986, train_acc = 0.9967396367023754\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 85, train_loss = 2.0598079268820584, train_acc = 0.9967396367023754\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 86, train_loss = 2.04299351060763, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 87, train_loss = 2.0254636434838176, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 88, train_loss = 2.0098999340552837, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 89, train_loss = 1.9932324523106217, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 90, train_loss = 1.978163163876161, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 91, train_loss = 1.963183682411909, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 92, train_loss = 1.9486199442762882, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 93, train_loss = 1.9340790705755353, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 94, train_loss = 1.9207709725014865, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 95, train_loss = 1.9066898634191602, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 96, train_loss = 1.8941720013972372, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 97, train_loss = 1.8818899218458682, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 98, train_loss = 1.8684744087513536, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 99, train_loss = 1.8570236628875136, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 100, train_loss = 1.8450019310694188, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 101, train_loss = 1.8337068343535066, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 102, train_loss = 1.822007179260254, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 103, train_loss = 1.8108031956944615, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 104, train_loss = 1.8001204123720527, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 105, train_loss = 1.7896089202258736, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 106, train_loss = 1.7794473245739937, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 107, train_loss = 1.7692358819767833, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 108, train_loss = 1.7589384869206697, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 109, train_loss = 1.749638699227944, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 110, train_loss = 1.7408998613245785, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 111, train_loss = 1.7311417318414897, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 112, train_loss = 1.7220837178174406, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 113, train_loss = 1.7130993276368827, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 114, train_loss = 1.704977537272498, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 115, train_loss = 1.6965225874446332, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 116, train_loss = 1.6878930612001568, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 117, train_loss = 1.6801035907119513, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 118, train_loss = 1.671877944841981, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 119, train_loss = 1.6635978219565004, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 120, train_loss = 1.6560978046618402, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 121, train_loss = 1.6488132325466722, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 122, train_loss = 1.640695146517828, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 123, train_loss = 1.633763013407588, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 124, train_loss = 1.6268574146088213, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 125, train_loss = 1.61980220512487, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 126, train_loss = 1.6125290708150715, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 127, train_loss = 1.6060291489120573, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 128, train_loss = 1.598964208504185, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 129, train_loss = 1.5923429736867547, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 130, train_loss = 1.5854020693805069, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 131, train_loss = 1.5793925046455115, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 132, train_loss = 1.5720358083490282, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 133, train_loss = 1.5658541310112923, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "2th- epoch: 134, train_loss = 1.5597971088718623, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "2th- epoch: 135, train_loss = 1.5539438866544515, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "2th- epoch: 136, train_loss = 1.5484123032074422, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "2th- epoch: 137, train_loss = 1.5422110895160586, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 138, train_loss = 1.536741665797308, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 139, train_loss = 1.5313938674516976, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 140, train_loss = 1.5258226797450334, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 141, train_loss = 1.5206051552668214, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 142, train_loss = 1.5154090716969222, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 143, train_loss = 1.5101008706260473, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 144, train_loss = 1.5049460644368082, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 145, train_loss = 1.4999839467927814, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 146, train_loss = 1.494803840527311, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 147, train_loss = 1.4901005912106484, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 148, train_loss = 1.4859596739988774, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 149, train_loss = 1.4809331789147109, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 150, train_loss = 1.4764103456400335, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 151, train_loss = 1.4718612676952034, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 152, train_loss = 1.4670769344083965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 153, train_loss = 1.4622629745863378, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 154, train_loss = 1.458091346314177, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 155, train_loss = 1.452907921280712, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 156, train_loss = 1.4491214086301625, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 157, train_loss = 1.445069860201329, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 158, train_loss = 1.4408000144176185, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 159, train_loss = 1.4362962660379708, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 160, train_loss = 1.4327222717693076, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 161, train_loss = 1.428374348091893, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 162, train_loss = 1.424354030750692, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 163, train_loss = 1.420548299443908, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 164, train_loss = 1.416738489526324, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 165, train_loss = 1.4133245986886322, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 166, train_loss = 1.4089585901238024, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 167, train_loss = 1.4054796680575237, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 168, train_loss = 1.4018063667463139, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 169, train_loss = 1.398552899598144, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 170, train_loss = 1.3945753639563918, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 171, train_loss = 1.391083703842014, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 172, train_loss = 1.3878066018223763, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 173, train_loss = 1.3844357831403613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 174, train_loss = 1.3811062899185345, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 175, train_loss = 1.377591808908619, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 176, train_loss = 1.37404624838382, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 177, train_loss = 1.3709982513682917, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 178, train_loss = 1.367413821280934, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 179, train_loss = 1.364502434269525, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 180, train_loss = 1.3611628491198644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 181, train_loss = 1.3577989606419578, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 182, train_loss = 1.3550035447115079, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 183, train_loss = 1.3521813891129568, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 184, train_loss = 1.3489860022673383, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 185, train_loss = 1.3453527508536354, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 186, train_loss = 1.3429071996361017, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 187, train_loss = 1.3398256320506334, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 188, train_loss = 1.3370018067071214, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 189, train_loss = 1.3341454962501302, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 190, train_loss = 1.3312993720173836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 191, train_loss = 1.328253060928546, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 192, train_loss = 1.3254502011695877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 193, train_loss = 1.32218522450421, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 194, train_loss = 1.319798881188035, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 195, train_loss = 1.3173547514015809, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 196, train_loss = 1.3144114032620564, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 197, train_loss = 1.311585359624587, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 198, train_loss = 1.309908470720984, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 199, train_loss = 1.3066168132936582, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 200, train_loss = 1.3037495097378269, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 201, train_loss = 1.3015577368205413, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 202, train_loss = 1.2987952089169994, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 203, train_loss = 1.2964507946744561, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 204, train_loss = 1.2937018930679187, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 205, train_loss = 1.2915713196853176, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 206, train_loss = 1.288560887449421, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 207, train_loss = 1.2864983789622784, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 208, train_loss = 1.284673667163588, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 209, train_loss = 1.2818384546553716, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 210, train_loss = 1.2795516258338466, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 211, train_loss = 1.2766343211987987, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 212, train_loss = 1.2744091510539874, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 213, train_loss = 1.2721229888265952, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 214, train_loss = 1.2699964962666854, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 215, train_loss = 1.2675640626112, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 216, train_loss = 1.265191780985333, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 217, train_loss = 1.2632167661795393, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 218, train_loss = 1.261151660233736, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 219, train_loss = 1.2590891051804647, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 220, train_loss = 1.2564213502919301, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 221, train_loss = 1.2550453500589356, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 222, train_loss = 1.2521193949505687, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 223, train_loss = 1.2505700150504708, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 224, train_loss = 1.2479929089313373, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 225, train_loss = 1.2461524497484788, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 226, train_loss = 1.2445949617540464, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 227, train_loss = 1.2428773896535859, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 228, train_loss = 1.2401832692557946, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 229, train_loss = 1.2381923465291038, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 230, train_loss = 1.2364068158203736, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 231, train_loss = 1.2339401114732027, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 232, train_loss = 1.2321216448908672, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 233, train_loss = 1.2298416327685118, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 234, train_loss = 1.2284655725816265, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 235, train_loss = 1.2267058439319953, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 236, train_loss = 1.2240920389303938, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 237, train_loss = 1.2221467004856095, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 238, train_loss = 1.2204701254377142, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 239, train_loss = 1.2184661763021722, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 240, train_loss = 1.2167886063689366, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 241, train_loss = 1.2146667971974239, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 242, train_loss = 1.2130074681481346, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 243, train_loss = 1.2114732371410355, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 244, train_loss = 1.2093399477889761, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 245, train_loss = 1.207185654551722, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 246, train_loss = 1.2059939997270703, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 247, train_loss = 1.2037917621200904, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 248, train_loss = 1.2022810889175162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 249, train_loss = 1.2007289357716218, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 250, train_loss = 1.1987465349957347, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 251, train_loss = 1.1978062773123384, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 252, train_loss = 1.1950558125972748, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 253, train_loss = 1.1940771387889981, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 254, train_loss = 1.191991300904192, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 255, train_loss = 1.1906788054620847, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 256, train_loss = 1.1893144237110391, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 257, train_loss = 1.1876576425274834, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 258, train_loss = 1.1857415629783645, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 259, train_loss = 1.1845117388293147, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 260, train_loss = 1.1827797340229154, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 261, train_loss = 1.1813839845126495, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 262, train_loss = 1.1800953695783392, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 263, train_loss = 1.1783539522439241, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 264, train_loss = 1.176452566869557, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 265, train_loss = 1.1752649390837178, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 266, train_loss = 1.1739521020790562, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 267, train_loss = 1.172185022966005, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 268, train_loss = 1.170768739655614, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 269, train_loss = 1.1690686283400282, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 270, train_loss = 1.1675293712178245, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 271, train_loss = 1.166171245276928, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 272, train_loss = 1.1644431973109022, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 273, train_loss = 1.1632915921509266, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 274, train_loss = 1.1617684637894854, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 275, train_loss = 1.160154684097506, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 276, train_loss = 1.1591782849282026, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 277, train_loss = 1.157429276034236, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 278, train_loss = 1.1561265183845535, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 279, train_loss = 1.1547329233726487, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 280, train_loss = 1.1536215003579855, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 281, train_loss = 1.1522130189696327, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 282, train_loss = 1.1506418468197808, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 283, train_loss = 1.1492096720030531, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 284, train_loss = 1.1482643423369154, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 285, train_loss = 1.1469372119754553, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 286, train_loss = 1.14496809738921, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 287, train_loss = 1.1439226679503918, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 288, train_loss = 1.142699648917187, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 289, train_loss = 1.141198456287384, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 290, train_loss = 1.1400027101044543, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 291, train_loss = 1.138469462573994, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 292, train_loss = 1.1372591629624367, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 293, train_loss = 1.1358504897798412, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 294, train_loss = 1.134811504452955, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 295, train_loss = 1.1332801307435147, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 296, train_loss = 1.1323615008150227, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 297, train_loss = 1.1308012561057694, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 298, train_loss = 1.1298066930030473, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 299, train_loss = 1.1283519423450343, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 300, train_loss = 1.127551740675699, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 301, train_loss = 1.1262489004875533, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 302, train_loss = 1.1249637734144926, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 303, train_loss = 1.1234685089439154, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 304, train_loss = 1.1223915691371076, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 305, train_loss = 1.1211476524476893, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 306, train_loss = 1.1202459378982894, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 307, train_loss = 1.118882401555311, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 308, train_loss = 1.1178627579356544, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 309, train_loss = 1.1161538045853376, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 310, train_loss = 1.1153714464162476, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 311, train_loss = 1.1139816511422396, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 312, train_loss = 1.113186538219452, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 313, train_loss = 1.1119317673146725, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 314, train_loss = 1.110877012833953, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 315, train_loss = 1.1096094027161598, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 316, train_loss = 1.108950110792648, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 317, train_loss = 1.1076828024233691, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 318, train_loss = 1.106891677423846, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 319, train_loss = 1.1053616106510162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 320, train_loss = 1.1041996572166681, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 321, train_loss = 1.103165887936484, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 322, train_loss = 1.1023284054244868, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 323, train_loss = 1.1012703459709883, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 324, train_loss = 1.1004241176997311, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 325, train_loss = 1.0993050529505126, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 326, train_loss = 1.0981617501820438, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 327, train_loss = 1.0971760911052115, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 328, train_loss = 1.095807823643554, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 329, train_loss = 1.0951933314208873, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 330, train_loss = 1.0938538331538439, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 331, train_loss = 1.0925327160512097, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 332, train_loss = 1.0911844316869974, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 333, train_loss = 1.090570802509319, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 334, train_loss = 1.0887321817572229, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 335, train_loss = 1.0882436353713274, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 336, train_loss = 1.0871741126175039, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 337, train_loss = 1.0856516460771672, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 338, train_loss = 1.0849159478093497, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 339, train_loss = 1.0841624556924216, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 340, train_loss = 1.082689344882965, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 341, train_loss = 1.0819472440634854, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 342, train_loss = 1.0807658403064124, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 343, train_loss = 1.0803967987303622, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 344, train_loss = 1.0790408694301732, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 345, train_loss = 1.0780334919691086, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 346, train_loss = 1.0767181136761792, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 347, train_loss = 1.0760153072769754, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 348, train_loss = 1.0748052124981768, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 349, train_loss = 1.0738198484177701, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 350, train_loss = 1.072988557338249, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 351, train_loss = 1.072392970963847, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 352, train_loss = 1.071103308990132, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 353, train_loss = 1.070513813465368, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 354, train_loss = 1.06925404939102, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 355, train_loss = 1.0685794676537625, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 356, train_loss = 1.06749395217048, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 357, train_loss = 1.0666082979296334, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 358, train_loss = 1.0655357452924363, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 359, train_loss = 1.0645619065617211, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 360, train_loss = 1.0642635896801949, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 361, train_loss = 1.0632240933482535, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 362, train_loss = 1.0622699012164958, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 363, train_loss = 1.061579467728734, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 364, train_loss = 1.060566708445549, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 365, train_loss = 1.0599899254739285, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 366, train_loss = 1.0587201143498532, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 367, train_loss = 1.0578217201982625, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 368, train_loss = 1.0571921424125321, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 369, train_loss = 1.0564096576417796, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 370, train_loss = 1.0554224898223765, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 371, train_loss = 1.054755809425842, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 372, train_loss = 1.0539091173559427, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 373, train_loss = 1.0530752136255614, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 374, train_loss = 1.0524102144991048, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 375, train_loss = 1.0514198026503436, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 376, train_loss = 1.0506509356200695, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 377, train_loss = 1.0497687856550328, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 378, train_loss = 1.0491051369463094, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 379, train_loss = 1.0483050681650639, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 380, train_loss = 1.0477203062619083, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 381, train_loss = 1.0467718939180486, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 382, train_loss = 1.045878753066063, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 383, train_loss = 1.0453928572242148, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 384, train_loss = 1.044746936589945, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 385, train_loss = 1.0434303873335011, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 386, train_loss = 1.042988296598196, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 387, train_loss = 1.042097343772184, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 388, train_loss = 1.041625623300206, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 389, train_loss = 1.0406207243795507, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 390, train_loss = 1.0399029317195527, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 391, train_loss = 1.039562212943565, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 392, train_loss = 1.0386570512200706, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 393, train_loss = 1.0374716607038863, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 394, train_loss = 1.0371817567502148, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 395, train_loss = 1.0364397795055993, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 396, train_loss = 1.035410410433542, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 397, train_loss = 1.034810256853234, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 398, train_loss = 1.0341274731908925, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 399, train_loss = 1.033187311142683, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 400, train_loss = 1.0325108648394234, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 401, train_loss = 1.0321727221016772, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 402, train_loss = 1.0312552638351917, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 403, train_loss = 1.0304616360808723, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 404, train_loss = 1.0301348554785363, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 405, train_loss = 1.029209463566076, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 406, train_loss = 1.0285415059770457, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 407, train_loss = 1.0276751804049127, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 408, train_loss = 1.026859228790272, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 409, train_loss = 1.0263802520930767, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 410, train_loss = 1.025818311900366, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 411, train_loss = 1.0248384550213814, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 412, train_loss = 1.0243134678457864, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 413, train_loss = 1.023535446554888, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 414, train_loss = 1.0226697039906867, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 415, train_loss = 1.0218276921659708, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 416, train_loss = 1.0219403728842735, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 417, train_loss = 1.0209405347704887, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 418, train_loss = 1.0205785452271812, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 419, train_loss = 1.0193297968362458, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 420, train_loss = 1.018876027315855, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 421, train_loss = 1.0186340759391896, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 422, train_loss = 1.017774858220946, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 423, train_loss = 1.016861713200342, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 424, train_loss = 1.0162827223539352, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 425, train_loss = 1.0150438130949624, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 426, train_loss = 1.0148748879437335, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 427, train_loss = 1.0142488231067546, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 428, train_loss = 1.013745003088843, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 429, train_loss = 1.0128573321853764, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 430, train_loss = 1.012533572211396, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 431, train_loss = 1.011119733855594, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 432, train_loss = 1.0116338941152208, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 433, train_loss = 1.0106147875194438, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 434, train_loss = 1.0096974298357964, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 435, train_loss = 1.0090985906426795, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 436, train_loss = 1.0080018446897157, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 437, train_loss = 1.0080291603808291, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 438, train_loss = 1.0075833195005544, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 439, train_loss = 1.006743370264303, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 440, train_loss = 1.0063296246225946, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 441, train_loss = 1.0052038573776372, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 442, train_loss = 1.0047246795147657, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 443, train_loss = 1.0043065026402473, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 444, train_loss = 1.0035093910992146, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 445, train_loss = 1.002491298422683, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 446, train_loss = 1.00245468999492, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 447, train_loss = 1.0018565698410384, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 448, train_loss = 1.0010332849924453, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 449, train_loss = 1.0008353597368114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 450, train_loss = 1.0000697312061675, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 451, train_loss = 0.9994704549317248, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 452, train_loss = 0.9993129707872868, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 453, train_loss = 0.9983291539247148, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 454, train_loss = 0.9977144710719585, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 455, train_loss = 0.9971852879971266, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 456, train_loss = 0.9967184215784073, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 457, train_loss = 0.9959986433386803, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 458, train_loss = 0.9957261836971156, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 459, train_loss = 0.9949144944548607, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 460, train_loss = 0.9943278568680398, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 461, train_loss = 0.9942603136296384, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 462, train_loss = 0.9934971078182571, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 463, train_loss = 0.9926494155079126, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 464, train_loss = 0.9922515644575469, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 465, train_loss = 0.9922096549416892, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 466, train_loss = 0.9908486020867713, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 467, train_loss = 0.9907162289018743, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 468, train_loss = 0.9897672559018247, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 469, train_loss = 0.9896402191370726, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 470, train_loss = 0.9888441258226521, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 471, train_loss = 0.9885432819719426, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 472, train_loss = 0.9877807591110468, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 473, train_loss = 0.9872913875733502, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 474, train_loss = 0.9868160554324277, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 475, train_loss = 0.9865248892456293, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 476, train_loss = 0.985689839348197, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 477, train_loss = 0.9853517680312507, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 478, train_loss = 0.9847207317943685, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 479, train_loss = 0.9839003992383368, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 480, train_loss = 0.9833574083750136, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 481, train_loss = 0.9828177758608945, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 482, train_loss = 0.9824449892039411, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 483, train_loss = 0.9821555254166014, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 484, train_loss = 0.9812828861176968, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 485, train_loss = 0.9809025774593465, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 486, train_loss = 0.9803711995482445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 487, train_loss = 0.9799788829986937, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 488, train_loss = 0.9796155244112015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 489, train_loss = 0.9787181963329203, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 490, train_loss = 0.9783280926640145, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 491, train_loss = 0.977927450730931, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 492, train_loss = 0.9773726661805995, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 493, train_loss = 0.9767432802473195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 494, train_loss = 0.9766254157875665, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 495, train_loss = 0.9761241066153161, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 496, train_loss = 0.9753216467797756, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 497, train_loss = 0.9749824081663974, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 498, train_loss = 0.9746057695592754, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 499, train_loss = 0.9738851959700696, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████▊                                                                    | 2/30 [19:26<4:28:56, 576.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "3th- epoch: 0, train_loss = 123.17900551855564, train_acc = 0.765836050302748\n",
      "test Acc 0.8654562383612663:\n",
      "3th- epoch: 1, train_loss = 48.73801824450493, train_acc = 0.895668374476013\n",
      "test Acc 0.9143389199255121:\n",
      "3th- epoch: 2, train_loss = 35.17724047601223, train_acc = 0.9253609687936656\n",
      "test Acc 0.9245810055865922:\n",
      "3th- epoch: 3, train_loss = 28.33591763302684, train_acc = 0.9415463437354448\n",
      "test Acc 0.9334264432029795:\n",
      "3th- epoch: 4, train_loss = 23.950195588171482, train_acc = 0.9507452258965999\n",
      "test Acc 0.9413407821229051:\n",
      "3th- epoch: 5, train_loss = 20.844478575512767, train_acc = 0.9587796925943176\n",
      "test Acc 0.9445996275605214:\n",
      "3th- epoch: 6, train_loss = 18.48219825513661, train_acc = 0.9633209129017233\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 7, train_loss = 16.60634214989841, train_acc = 0.9672799254774104\n",
      "test Acc 0.952048417132216:\n",
      "3th- epoch: 8, train_loss = 15.075611611828208, train_acc = 0.9708896134140661\n",
      "test Acc 0.9543761638733705:\n",
      "3th- epoch: 9, train_loss = 13.790681954473257, train_acc = 0.9734513274336283\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 10, train_loss = 12.700601579621434, train_acc = 0.9748486259897532\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 11, train_loss = 11.758721970021725, train_acc = 0.9774103400093154\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 12, train_loss = 10.938521258533001, train_acc = 0.9792734047508151\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 13, train_loss = 10.224113618023694, train_acc = 0.9803213786679087\n",
      "test Acc 0.9622905027932961:\n",
      "3th- epoch: 14, train_loss = 9.597219976596534, train_acc = 0.9813693525850024\n",
      "test Acc 0.9622905027932961:\n",
      "3th- epoch: 15, train_loss = 9.036378673277795, train_acc = 0.9820680018630648\n",
      "test Acc 0.962756052141527:\n",
      "3th- epoch: 16, train_loss = 8.537104990333319, train_acc = 0.984163949697252\n",
      "test Acc 0.9646182495344506:\n",
      "3th- epoch: 17, train_loss = 8.085681860335171, train_acc = 0.9850954820680019\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 18, train_loss = 7.681358494795859, train_acc = 0.9860270144387517\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 19, train_loss = 7.316317283548415, train_acc = 0.9868421052631579\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 20, train_loss = 6.9858660362660885, train_acc = 0.9874243129948765\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 21, train_loss = 6.681586221791804, train_acc = 0.9876571960875641\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 22, train_loss = 6.404455121606588, train_acc = 0.9889380530973452\n",
      "test Acc 0.9697392923649907:\n",
      "3th- epoch: 23, train_loss = 6.150136318989098, train_acc = 0.9895202608290639\n",
      "test Acc 0.9702048417132216:\n",
      "3th- epoch: 24, train_loss = 5.918342899531126, train_acc = 0.9896367023754076\n",
      "test Acc 0.9702048417132216:\n",
      "3th- epoch: 25, train_loss = 5.703386728651822, train_acc = 0.9902189101071263\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 26, train_loss = 5.504372381605208, train_acc = 0.990801117838845\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 27, train_loss = 5.318349029868841, train_acc = 0.9911504424778761\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 28, train_loss = 5.1473275469616055, train_acc = 0.9913833255705635\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 29, train_loss = 4.988979484885931, train_acc = 0.9914997671169073\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 30, train_loss = 4.838620472699404, train_acc = 0.9918490917559385\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 31, train_loss = 4.698875014670193, train_acc = 0.9918490917559385\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 32, train_loss = 4.568671282380819, train_acc = 0.9921984163949698\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 33, train_loss = 4.446950986050069, train_acc = 0.9924312994876572\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 34, train_loss = 4.330178301781416, train_acc = 0.9930135072193759\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 35, train_loss = 4.2237246902659535, train_acc = 0.9933628318584071\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 36, train_loss = 4.11893770005554, train_acc = 0.9933628318584071\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 37, train_loss = 4.021775358356535, train_acc = 0.9935957149510946\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 38, train_loss = 3.929813086055219, train_acc = 0.9940614811364695\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 39, train_loss = 3.8440230898559093, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 40, train_loss = 3.7593715069815516, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 41, train_loss = 3.6810448998585343, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 42, train_loss = 3.6067883232608438, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 43, train_loss = 3.5349510377272964, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 44, train_loss = 3.4675549352541566, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 45, train_loss = 3.4014363884925842, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 46, train_loss = 3.339315967168659, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 47, train_loss = 3.2787841334939003, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 48, train_loss = 3.2213972322642803, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 49, train_loss = 3.166755800601095, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 50, train_loss = 3.1138972542248666, train_acc = 0.9954587796925943\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 51, train_loss = 3.0627652085386217, train_acc = 0.9954587796925943\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 52, train_loss = 3.0156818218529224, train_acc = 0.995575221238938\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 53, train_loss = 2.9666711897589266, train_acc = 0.9958081043316255\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 54, train_loss = 2.923031285405159, train_acc = 0.9958081043316255\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 55, train_loss = 2.879731208086014, train_acc = 0.9958081043316255\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 56, train_loss = 2.8355648666620255, train_acc = 0.9958081043316255\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 57, train_loss = 2.796157542616129, train_acc = 0.9958081043316255\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 58, train_loss = 2.7580765783786774, train_acc = 0.9959245458779693\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 59, train_loss = 2.7196269310079515, train_acc = 0.9959245458779693\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 60, train_loss = 2.6829541898332536, train_acc = 0.9959245458779693\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 61, train_loss = 2.6474464959464967, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 62, train_loss = 2.6132872588932514, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 63, train_loss = 2.5791648835875094, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 64, train_loss = 2.5483342707157135, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 65, train_loss = 2.5160151249729097, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 66, train_loss = 2.4859211556613445, train_acc = 0.9962738705170004\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 67, train_loss = 2.4567142501473427, train_acc = 0.9962738705170004\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 68, train_loss = 2.427423471119255, train_acc = 0.9962738705170004\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 69, train_loss = 2.399382249917835, train_acc = 0.9962738705170004\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 70, train_loss = 2.372266460210085, train_acc = 0.9963903120633442\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 71, train_loss = 2.347159994300455, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 72, train_loss = 2.320889758411795, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 73, train_loss = 2.2962440489791334, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 74, train_loss = 2.272628092672676, train_acc = 0.996506753609688\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 75, train_loss = 2.2479282268323004, train_acc = 0.996506753609688\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 76, train_loss = 2.225821560714394, train_acc = 0.996506753609688\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 77, train_loss = 2.2046560696326196, train_acc = 0.996506753609688\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 78, train_loss = 2.1824940256774426, train_acc = 0.996506753609688\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 79, train_loss = 2.161523826420307, train_acc = 0.996506753609688\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 80, train_loss = 2.1412349939346313, train_acc = 0.9966231951560317\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 81, train_loss = 2.121972683817148, train_acc = 0.9966231951560317\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 82, train_loss = 2.102315270807594, train_acc = 0.9966231951560317\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 83, train_loss = 2.083916103001684, train_acc = 0.996506753609688\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 84, train_loss = 2.0671437182463706, train_acc = 0.996506753609688\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 85, train_loss = 2.0489237806759775, train_acc = 0.9966231951560317\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 86, train_loss = 2.0320924394764006, train_acc = 0.9966231951560317\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 87, train_loss = 2.0158126414753497, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 88, train_loss = 1.9992298721335828, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 89, train_loss = 1.9848033138550818, train_acc = 0.9968560782487191\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 90, train_loss = 1.9692660965956748, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 91, train_loss = 1.9544685422442853, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 92, train_loss = 1.9397724396549165, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 93, train_loss = 1.9258518554270267, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 94, train_loss = 1.9123983681201935, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 95, train_loss = 1.8990403688512743, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 96, train_loss = 1.8865995593369007, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 97, train_loss = 1.873508685734123, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 98, train_loss = 1.8618073523975909, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 99, train_loss = 1.8491940833628178, train_acc = 0.9968560782487191\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 100, train_loss = 1.8380005869548768, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 101, train_loss = 1.8261356763541698, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 102, train_loss = 1.815406161127612, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 103, train_loss = 1.8048169389367104, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 104, train_loss = 1.7935397129040211, train_acc = 0.9969725197950629\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 105, train_loss = 1.7838581514079124, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 106, train_loss = 1.7731167699676007, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 107, train_loss = 1.763637263327837, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 108, train_loss = 1.7533557664137334, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 109, train_loss = 1.7445418983697891, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 110, train_loss = 1.7345955446362495, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 111, train_loss = 1.7258132684510201, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 112, train_loss = 1.7170083820819855, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 113, train_loss = 1.708257481455803, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 114, train_loss = 1.699596919119358, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 115, train_loss = 1.6913975987117738, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 116, train_loss = 1.682543732225895, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 117, train_loss = 1.675353470025584, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 118, train_loss = 1.6673050646204501, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 119, train_loss = 1.6596206326503307, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 120, train_loss = 1.6521251685917377, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 121, train_loss = 1.6444560028612614, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 122, train_loss = 1.6372725230176002, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 123, train_loss = 1.6299194369930774, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 124, train_loss = 1.6227142016869038, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 125, train_loss = 1.6159248277544975, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 126, train_loss = 1.6094093818683177, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 127, train_loss = 1.602312282891944, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 128, train_loss = 1.5963751301169395, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 129, train_loss = 1.5891787696164101, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 130, train_loss = 1.5827769227325916, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 131, train_loss = 1.5763928692322224, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 132, train_loss = 1.5703150432091206, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 133, train_loss = 1.5644441049080342, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 134, train_loss = 1.558424421818927, train_acc = 0.9972054028877504\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 135, train_loss = 1.5521550688426942, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 136, train_loss = 1.547022444428876, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 137, train_loss = 1.5407388422172517, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 138, train_loss = 1.535773438634351, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 139, train_loss = 1.529375196667388, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 140, train_loss = 1.5242887772619724, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 141, train_loss = 1.518340525450185, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 142, train_loss = 1.5135352599900216, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 143, train_loss = 1.5082535210531205, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 144, train_loss = 1.5023251075763255, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 145, train_loss = 1.49758201953955, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 146, train_loss = 1.492598271695897, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 147, train_loss = 1.4876832652371377, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 148, train_loss = 1.4830412678420544, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 149, train_loss = 1.4778119511902332, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 150, train_loss = 1.4728173215407878, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 151, train_loss = 1.4692124377470464, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 152, train_loss = 1.463656086474657, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 153, train_loss = 1.4598353567998856, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 154, train_loss = 1.45487134414725, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 155, train_loss = 1.4507416635751724, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 156, train_loss = 1.4461368981283158, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 157, train_loss = 1.4418698213994503, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 158, train_loss = 1.4372999246697873, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 159, train_loss = 1.4335645698010921, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 160, train_loss = 1.4289696055930108, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 161, train_loss = 1.4250844022026286, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 162, train_loss = 1.4208391606807709, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 163, train_loss = 1.416802899329923, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 164, train_loss = 1.4131284343311563, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 165, train_loss = 1.4089503064751625, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 166, train_loss = 1.405182165442966, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 167, train_loss = 1.4009167278418317, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 168, train_loss = 1.39792536071036, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 169, train_loss = 1.3936867974698544, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 170, train_loss = 1.3904480958590284, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 171, train_loss = 1.3865362256765366, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 172, train_loss = 1.3825616812100634, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 173, train_loss = 1.3797292982926592, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 174, train_loss = 1.3756213746964931, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 175, train_loss = 1.3725435821106657, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 176, train_loss = 1.3692256212234497, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 177, train_loss = 1.3653553016483784, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 178, train_loss = 1.3626397302141413, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 179, train_loss = 1.359091330319643, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 180, train_loss = 1.3556861033430323, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 181, train_loss = 1.352095982641913, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 182, train_loss = 1.3495009504258633, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 183, train_loss = 1.3460381092736498, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 184, train_loss = 1.342941320152022, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 185, train_loss = 1.3389523066580296, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 186, train_loss = 1.337115260423161, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 187, train_loss = 1.3335678788134828, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 188, train_loss = 1.3302232412388548, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 189, train_loss = 1.328039489686489, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 190, train_loss = 1.324844287126325, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 191, train_loss = 1.3215650655329227, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 192, train_loss = 1.3186812736093998, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 193, train_loss = 1.316168992430903, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 194, train_loss = 1.3131609968841076, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 195, train_loss = 1.310080897063017, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 196, train_loss = 1.3073722483823076, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 197, train_loss = 1.3048464059829712, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 198, train_loss = 1.3017412535846233, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 199, train_loss = 1.2992690926184878, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 200, train_loss = 1.29677040502429, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 201, train_loss = 1.2943981438875198, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 202, train_loss = 1.2914733303477988, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 203, train_loss = 1.2887660562992096, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 204, train_loss = 1.2865004813065752, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 205, train_loss = 1.2839669646928087, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 206, train_loss = 1.281376026570797, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 207, train_loss = 1.2792527414858341, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 208, train_loss = 1.2763653012225404, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 209, train_loss = 1.27428772917483, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 210, train_loss = 1.2713865973055363, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 211, train_loss = 1.2696879828581586, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 212, train_loss = 1.26684680825565, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 213, train_loss = 1.2644644131651148, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 214, train_loss = 1.262622875510715, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 215, train_loss = 1.2599884681403637, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 216, train_loss = 1.2578535601496696, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 217, train_loss = 1.2555022811284289, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 218, train_loss = 1.2532718479633331, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 219, train_loss = 1.2514190239598975, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 220, train_loss = 1.2488203967222944, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 221, train_loss = 1.2464606849243864, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 222, train_loss = 1.2443653965601698, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 223, train_loss = 1.2422449378063902, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 224, train_loss = 1.2400120608508587, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 225, train_loss = 1.2376823028316721, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 226, train_loss = 1.2360731536755338, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 227, train_loss = 1.2334995405981317, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 228, train_loss = 1.231752077699639, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 229, train_loss = 1.229520513326861, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 230, train_loss = 1.2272752908756956, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 231, train_loss = 1.2252804612508044, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 232, train_loss = 1.2236251706490293, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 233, train_loss = 1.2209851033985615, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 234, train_loss = 1.219863789738156, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 235, train_loss = 1.2174073407659307, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 236, train_loss = 1.2153972797095776, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 237, train_loss = 1.2136989360442385, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 238, train_loss = 1.2113785656401888, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 239, train_loss = 1.2096598955104128, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 240, train_loss = 1.2072138860821724, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 241, train_loss = 1.2055414480855688, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 242, train_loss = 1.2037062086164951, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 243, train_loss = 1.201961513608694, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 244, train_loss = 1.1999259950825945, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 245, train_loss = 1.198232372640632, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 246, train_loss = 1.1967986834933981, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 247, train_loss = 1.1946352310478687, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 248, train_loss = 1.1927610449492931, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 249, train_loss = 1.1916974248597398, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 250, train_loss = 1.1894085878739133, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 251, train_loss = 1.1876815035939217, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 252, train_loss = 1.1861556557705626, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 253, train_loss = 1.184390245587565, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 254, train_loss = 1.1823302680859342, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 255, train_loss = 1.1813881322741508, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 256, train_loss = 1.1796231692424044, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 257, train_loss = 1.1776649616658688, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 258, train_loss = 1.1758373342454433, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 259, train_loss = 1.1744303305749781, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 260, train_loss = 1.1731005273759365, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 261, train_loss = 1.171063790738117, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 262, train_loss = 1.1698157700593583, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 263, train_loss = 1.1679729682509787, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 264, train_loss = 1.1669000834226608, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 265, train_loss = 1.1650016966159455, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 266, train_loss = 1.1635563398594968, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 267, train_loss = 1.1620300076901913, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 268, train_loss = 1.1606630670721643, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 269, train_loss = 1.158888642967213, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 270, train_loss = 1.157521112530958, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 271, train_loss = 1.1559539598529227, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 272, train_loss = 1.1550631138379686, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 273, train_loss = 1.1532258999650367, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 274, train_loss = 1.1519010824267752, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 275, train_loss = 1.1502488466794603, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 276, train_loss = 1.149089212238323, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 277, train_loss = 1.1473286536638625, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 278, train_loss = 1.1466672991518863, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 279, train_loss = 1.1448317455942743, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 280, train_loss = 1.1432288413052447, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 281, train_loss = 1.1425387226045132, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 282, train_loss = 1.1405975259840488, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 283, train_loss = 1.1397423520684242, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 284, train_loss = 1.1378731516306289, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 285, train_loss = 1.136605642735958, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 286, train_loss = 1.1352232955396175, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 287, train_loss = 1.13414577889489, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 288, train_loss = 1.132679098576773, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 289, train_loss = 1.131370548158884, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 290, train_loss = 1.1299996103043668, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 291, train_loss = 1.128370023041498, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 292, train_loss = 1.1275738689000718, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 293, train_loss = 1.126074944913853, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 294, train_loss = 1.124865047633648, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 295, train_loss = 1.1233927831053734, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 296, train_loss = 1.1221769116818905, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 297, train_loss = 1.1212139179115184, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 298, train_loss = 1.1198465749621391, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 299, train_loss = 1.1182581645553, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 300, train_loss = 1.117754717648495, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 301, train_loss = 1.116240366070997, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 302, train_loss = 1.115282962739002, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 303, train_loss = 1.1135982908308506, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 304, train_loss = 1.1124266274273396, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 305, train_loss = 1.11134484159993, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 306, train_loss = 1.109673272818327, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 307, train_loss = 1.1088783877785318, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 308, train_loss = 1.107641742855776, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 309, train_loss = 1.1063212106819265, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 310, train_loss = 1.1053934109513648, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 311, train_loss = 1.1039742541615851, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 312, train_loss = 1.1030692222411744, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 313, train_loss = 1.1018313194508664, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 314, train_loss = 1.1008924854104407, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 315, train_loss = 1.0994480177760124, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 316, train_loss = 1.0984951071441174, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 317, train_loss = 1.09735832241131, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 318, train_loss = 1.0958998203277588, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 319, train_loss = 1.0952084598247893, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 320, train_loss = 1.0936741257901303, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 321, train_loss = 1.0930935318465345, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 322, train_loss = 1.0915313164587133, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 323, train_loss = 1.0905651437933557, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 324, train_loss = 1.0895723824505694, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 325, train_loss = 1.0884961374104023, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 326, train_loss = 1.0877836768631823, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 327, train_loss = 1.086192728311289, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 328, train_loss = 1.085343775630463, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 329, train_loss = 1.0844426986877806, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 330, train_loss = 1.0838910527527332, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 331, train_loss = 1.0823328184778802, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 332, train_loss = 1.0814411503379233, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 333, train_loss = 1.08054879802512, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 334, train_loss = 1.0792910394375212, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 335, train_loss = 1.078360581130255, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 336, train_loss = 1.07751314091729, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 337, train_loss = 1.0765638500452042, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 338, train_loss = 1.0755366918747313, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 339, train_loss = 1.074469177692663, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 340, train_loss = 1.0736045837402344, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 341, train_loss = 1.0730174842174165, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 342, train_loss = 1.0716997695271857, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 343, train_loss = 1.0705436418647878, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 344, train_loss = 1.0699919611215591, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 345, train_loss = 1.0687296688556671, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 346, train_loss = 1.0679027090664022, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 347, train_loss = 1.0669468268752098, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 348, train_loss = 1.066132886975538, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 349, train_loss = 1.0654623831505887, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 350, train_loss = 1.0642213399405591, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 351, train_loss = 1.0636285084183328, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 352, train_loss = 1.0627273954451084, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 353, train_loss = 1.0616170589928515, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 354, train_loss = 1.0609800194506533, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 355, train_loss = 1.0598576379125006, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 356, train_loss = 1.0588323771953583, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 357, train_loss = 1.0584631375968456, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 358, train_loss = 1.0573830206994899, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 359, train_loss = 1.0566269370610826, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 360, train_loss = 1.0558839005534537, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 361, train_loss = 1.0552347314660437, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 362, train_loss = 1.054169274866581, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 363, train_loss = 1.0529449954628944, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 364, train_loss = 1.0521503947675228, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 365, train_loss = 1.0512227515573613, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 366, train_loss = 1.0512841567397118, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 367, train_loss = 1.0499096537823789, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 368, train_loss = 1.0489458094234578, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 369, train_loss = 1.0479632951319218, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 370, train_loss = 1.0476256646215916, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 371, train_loss = 1.046376449347008, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 372, train_loss = 1.0457895721192472, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 373, train_loss = 1.045259380072821, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 374, train_loss = 1.0440117232501507, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 375, train_loss = 1.0434361584484577, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 376, train_loss = 1.042938121885527, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 377, train_loss = 1.0418459537322633, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 378, train_loss = 1.041073713451624, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 379, train_loss = 1.0401659260387532, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 380, train_loss = 1.039013008296024, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 381, train_loss = 1.039078636735212, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 382, train_loss = 1.0379835876519792, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 383, train_loss = 1.0371635469491594, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 384, train_loss = 1.0365765057504177, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 385, train_loss = 1.0357752169365995, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 386, train_loss = 1.035084122151602, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 387, train_loss = 1.0340463382308371, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 388, train_loss = 1.0336678462917916, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 389, train_loss = 1.032441842078697, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 390, train_loss = 1.0322991758584976, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 391, train_loss = 1.0313750741188414, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 392, train_loss = 1.0307140785153024, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 393, train_loss = 1.0297583391075023, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 394, train_loss = 1.0292392547125928, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 395, train_loss = 1.0285928646917455, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 396, train_loss = 1.0278128099744208, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 397, train_loss = 1.027291928709019, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 398, train_loss = 1.026159277826082, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 399, train_loss = 1.0256539583206177, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 400, train_loss = 1.0247805553372018, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 401, train_loss = 1.0243112966418266, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 402, train_loss = 1.0234352499246597, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 403, train_loss = 1.0227447536890395, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 404, train_loss = 1.0222293883562088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 405, train_loss = 1.0214986304636113, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 406, train_loss = 1.0208841860294342, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 407, train_loss = 1.0200270998175256, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 408, train_loss = 1.0195727062528022, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 409, train_loss = 1.018664029717911, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 410, train_loss = 1.018115557730198, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 411, train_loss = 1.0171710650320165, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 412, train_loss = 1.0169711261987686, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 413, train_loss = 1.0159778160159476, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 414, train_loss = 1.0156567717785947, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 415, train_loss = 1.0144853268866427, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 416, train_loss = 1.0143874448840506, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 417, train_loss = 1.0133131605689414, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 418, train_loss = 1.0132170195574872, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 419, train_loss = 1.0121168357436545, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 420, train_loss = 1.0114365530316718, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 421, train_loss = 1.0111126762931235, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 422, train_loss = 1.0101775799994357, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 423, train_loss = 1.0096806238288991, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 424, train_loss = 1.0089396238327026, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 425, train_loss = 1.0084768645465374, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 426, train_loss = 1.0076446483726613, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 427, train_loss = 1.0072073464398272, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 428, train_loss = 1.0061671150033362, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 429, train_loss = 1.006023645401001, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 430, train_loss = 1.0052054089610465, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 431, train_loss = 1.0043418171699159, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 432, train_loss = 1.0037622638046741, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 433, train_loss = 1.0031583445961587, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 434, train_loss = 1.002589947253, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 435, train_loss = 1.0019173423352186, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 436, train_loss = 1.0009982287883759, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 437, train_loss = 1.0006617307662964, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 438, train_loss = 0.9998947741987649, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 439, train_loss = 0.9992965708079282, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 440, train_loss = 0.9989706712367479, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 441, train_loss = 0.9983633595111314, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 442, train_loss = 0.9974348271789495, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 443, train_loss = 0.997384749352932, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 444, train_loss = 0.9964788692595903, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 445, train_loss = 0.9957679609360639, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 446, train_loss = 0.995318283647066, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 447, train_loss = 0.9947852355835494, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 448, train_loss = 0.994014206022257, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 449, train_loss = 0.9937700206937734, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 450, train_loss = 0.9927196465432644, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 451, train_loss = 0.9925276873109397, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 452, train_loss = 0.9918291407229844, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 453, train_loss = 0.9913220877351705, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 454, train_loss = 0.9904582922754344, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 455, train_loss = 0.9902904368937016, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 456, train_loss = 0.9897631853818893, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 457, train_loss = 0.9889104155299719, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 458, train_loss = 0.9885268310608808, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 459, train_loss = 0.9875696574745234, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 460, train_loss = 0.9874161928892136, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 461, train_loss = 0.9866638481616974, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 462, train_loss = 0.9864107097091619, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 463, train_loss = 0.9855214332637843, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 464, train_loss = 0.9848738821747247, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 465, train_loss = 0.9843283792433795, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 466, train_loss = 0.9838478403689805, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 467, train_loss = 0.9838373313250486, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 468, train_loss = 0.9827606926264707, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 469, train_loss = 0.9822858373227064, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 470, train_loss = 0.9814098365604877, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 471, train_loss = 0.9811170150933322, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 472, train_loss = 0.9806707898678724, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 473, train_loss = 0.979909927904373, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 474, train_loss = 0.9794828867015895, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 475, train_loss = 0.9789423110487405, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 476, train_loss = 0.9783093792793807, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 477, train_loss = 0.9771963991224766, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 478, train_loss = 0.977574640273815, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 479, train_loss = 0.9766879417002201, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 480, train_loss = 0.975913150847191, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 481, train_loss = 0.975628312677145, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 482, train_loss = 0.9750452227890491, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 483, train_loss = 0.9743273593485355, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 484, train_loss = 0.973793264478445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 485, train_loss = 0.9731722697615623, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 486, train_loss = 0.9727336540818214, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 487, train_loss = 0.9723760907945689, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 488, train_loss = 0.9720342718064785, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 489, train_loss = 0.971172209829092, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 490, train_loss = 0.9708874300122261, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 491, train_loss = 0.9702653773128986, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 492, train_loss = 0.9699490753409918, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 493, train_loss = 0.969030499458313, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 494, train_loss = 0.9687714812753256, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 495, train_loss = 0.9687554687261581, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 496, train_loss = 0.967631538718706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 497, train_loss = 0.9673705361783504, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 498, train_loss = 0.9667671943607274, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 499, train_loss = 0.9667176579532679, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▎                                                                 | 3/30 [29:24<4:22:18, 582.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "4th- epoch: 0, train_loss = 147.49719558656216, train_acc = 0.7502328830926874\n",
      "test Acc 0.8547486033519553:\n",
      "4th- epoch: 1, train_loss = 55.71110089123249, train_acc = 0.8878667908709827\n",
      "test Acc 0.8947858472998138:\n",
      "4th- epoch: 2, train_loss = 40.02158988267183, train_acc = 0.9175593851886353\n",
      "test Acc 0.9129422718808193:\n",
      "4th- epoch: 3, train_loss = 31.796170972287655, train_acc = 0.9337447601304145\n",
      "test Acc 0.9213221601489758:\n",
      "4th- epoch: 4, train_loss = 26.57037415355444, train_acc = 0.945388914764788\n",
      "test Acc 0.9278398510242085:\n",
      "4th- epoch: 5, train_loss = 22.898487240076065, train_acc = 0.9526082906380997\n",
      "test Acc 0.9348230912476723:\n",
      "4th- epoch: 6, train_loss = 20.154392927885056, train_acc = 0.9585468095016302\n",
      "test Acc 0.9390130353817505:\n",
      "4th- epoch: 7, train_loss = 17.990746503695846, train_acc = 0.9636702375407545\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 8, train_loss = 16.242438225075603, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "4th- epoch: 9, train_loss = 14.79536416940391, train_acc = 0.9704238472286912\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 10, train_loss = 13.572915114462376, train_acc = 0.9731020027945971\n",
      "test Acc 0.9529795158286778:\n",
      "4th- epoch: 11, train_loss = 12.526941407471895, train_acc = 0.9760130414531905\n",
      "test Acc 0.9548417132216015:\n",
      "4th- epoch: 12, train_loss = 11.614555083215237, train_acc = 0.9778761061946902\n",
      "test Acc 0.9557728119180633:\n",
      "4th- epoch: 13, train_loss = 10.824876694008708, train_acc = 0.9789240801117839\n",
      "test Acc 0.957169459962756:\n",
      "4th- epoch: 14, train_loss = 10.127196015790105, train_acc = 0.9814857941313461\n",
      "test Acc 0.957169459962756:\n",
      "4th- epoch: 15, train_loss = 9.51329776737839, train_acc = 0.9824173265020959\n",
      "test Acc 0.9590316573556797:\n",
      "4th- epoch: 16, train_loss = 8.967185098677874, train_acc = 0.9829995342338146\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 17, train_loss = 8.479305393993855, train_acc = 0.984163949697252\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 18, train_loss = 8.04342920333147, train_acc = 0.9855612482533768\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 19, train_loss = 7.653523645363748, train_acc = 0.9868421052631579\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 20, train_loss = 7.301514538004994, train_acc = 0.9874243129948765\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 21, train_loss = 6.980158208869398, train_acc = 0.9883558453656265\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 22, train_loss = 6.6869339952245355, train_acc = 0.9888216115510013\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 23, train_loss = 6.420660015195608, train_acc = 0.9896367023754076\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 24, train_loss = 6.174920562654734, train_acc = 0.9899860270144387\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 25, train_loss = 5.94735761359334, train_acc = 0.9904517931998137\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 26, train_loss = 5.734946571290493, train_acc = 0.990801117838845\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 27, train_loss = 5.5442456332966685, train_acc = 0.9913833255705635\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 28, train_loss = 5.362894364632666, train_acc = 0.9917326502095948\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 29, train_loss = 5.193247606046498, train_acc = 0.9918490917559385\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 30, train_loss = 5.034303174354136, train_acc = 0.992081974848626\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 31, train_loss = 4.884962092153728, train_acc = 0.9926641825803446\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 32, train_loss = 4.745101071894169, train_acc = 0.9930135072193759\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 33, train_loss = 4.612335631623864, train_acc = 0.9933628318584071\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 34, train_loss = 4.491172663867474, train_acc = 0.9935957149510946\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 35, train_loss = 4.37323923734948, train_acc = 0.9935957149510946\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 36, train_loss = 4.262596118729562, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 37, train_loss = 4.158128809183836, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 38, train_loss = 4.060214806348085, train_acc = 0.9946436888681882\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 39, train_loss = 3.965020848903805, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 40, train_loss = 3.8774515367113054, train_acc = 0.9951094550535631\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 41, train_loss = 3.792041275650263, train_acc = 0.9951094550535631\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 42, train_loss = 3.712480069603771, train_acc = 0.9951094550535631\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 43, train_loss = 3.6360476366244256, train_acc = 0.9954587796925943\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 44, train_loss = 3.562372714281082, train_acc = 0.9953423381462506\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 45, train_loss = 3.491142824292183, train_acc = 0.995575221238938\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 46, train_loss = 3.425814548972994, train_acc = 0.995575221238938\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 47, train_loss = 3.3599614300765097, train_acc = 0.995575221238938\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 48, train_loss = 3.2987286560237408, train_acc = 0.995575221238938\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 49, train_loss = 3.240704087074846, train_acc = 0.9956916627852818\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 50, train_loss = 3.183576201554388, train_acc = 0.9956916627852818\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 51, train_loss = 3.1308698379434645, train_acc = 0.996040987424313\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 52, train_loss = 3.078491074498743, train_acc = 0.9961574289706567\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 53, train_loss = 3.028678732458502, train_acc = 0.9963903120633442\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 54, train_loss = 2.9807977825403214, train_acc = 0.9962738705170004\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 55, train_loss = 2.9356583482585847, train_acc = 0.9962738705170004\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 56, train_loss = 2.8910809345543385, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 57, train_loss = 2.847862297203392, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 58, train_loss = 2.8068561465479434, train_acc = 0.9963903120633442\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 59, train_loss = 2.7672324664890766, train_acc = 0.9963903120633442\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 60, train_loss = 2.7291147797368467, train_acc = 0.9963903120633442\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 61, train_loss = 2.6918157800100744, train_acc = 0.9963903120633442\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 62, train_loss = 2.6558866302948445, train_acc = 0.9963903120633442\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 63, train_loss = 2.6222842920105904, train_acc = 0.9963903120633442\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 64, train_loss = 2.587991200387478, train_acc = 0.996506753609688\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 65, train_loss = 2.5560144397895783, train_acc = 0.996506753609688\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 66, train_loss = 2.5237636354286224, train_acc = 0.996506753609688\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 67, train_loss = 2.494005585787818, train_acc = 0.9966231951560317\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 68, train_loss = 2.463892050087452, train_acc = 0.9966231951560317\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 69, train_loss = 2.4353091109078377, train_acc = 0.9966231951560317\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 70, train_loss = 2.408435359597206, train_acc = 0.9967396367023754\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 71, train_loss = 2.381716825067997, train_acc = 0.9968560782487191\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 72, train_loss = 2.3546503621619195, train_acc = 0.9968560782487191\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 73, train_loss = 2.329141916008666, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 74, train_loss = 2.305178592680022, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 75, train_loss = 2.2810999292414635, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 76, train_loss = 2.259186316281557, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 77, train_loss = 2.235670043854043, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 78, train_loss = 2.215843563200906, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 79, train_loss = 2.1935832637827843, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 80, train_loss = 2.1737753227353096, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 81, train_loss = 2.1535904344636947, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 82, train_loss = 2.1337002243380994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 83, train_loss = 2.1155181366484612, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 84, train_loss = 2.0963523413520306, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 85, train_loss = 2.0798461735248566, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 86, train_loss = 2.061652310192585, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 87, train_loss = 2.045480467379093, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 88, train_loss = 2.0286033637821674, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 89, train_loss = 2.0132830888032913, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 90, train_loss = 1.997934527695179, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 91, train_loss = 1.9823542200028896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 92, train_loss = 1.9683188099879771, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 93, train_loss = 1.9537255552131683, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 94, train_loss = 1.9393903985619545, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 95, train_loss = 1.9261844207067043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 96, train_loss = 1.913348724367097, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 97, train_loss = 1.899661100236699, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 98, train_loss = 1.8871561910491437, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 99, train_loss = 1.8753615705063567, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 100, train_loss = 1.8632847927510738, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 101, train_loss = 1.851230668486096, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 102, train_loss = 1.8393544629216194, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 103, train_loss = 1.8291350057115778, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 104, train_loss = 1.8169563425472006, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 105, train_loss = 1.806978446780704, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 106, train_loss = 1.7960757898399606, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 107, train_loss = 1.786163100390695, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 108, train_loss = 1.7767274478683248, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 109, train_loss = 1.7671201577177271, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 110, train_loss = 1.7573237965116277, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 111, train_loss = 1.7473832331597805, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 112, train_loss = 1.7395707927644253, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 113, train_loss = 1.7304327798774466, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 114, train_loss = 1.7217787988483906, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 115, train_loss = 1.7125402515521273, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 116, train_loss = 1.7042575428495184, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 117, train_loss = 1.6973129523685202, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 118, train_loss = 1.6881685182452202, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 119, train_loss = 1.681099358946085, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 120, train_loss = 1.6725500648608431, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 121, train_loss = 1.664770788163878, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 122, train_loss = 1.6578941196203232, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 123, train_loss = 1.6507030526408926, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 124, train_loss = 1.643437821418047, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 125, train_loss = 1.6362807167461142, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 126, train_loss = 1.6292701537022367, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 127, train_loss = 1.6225140938768163, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 128, train_loss = 1.6160132735967636, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 129, train_loss = 1.6096066907048225, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 130, train_loss = 1.6034077890217304, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 131, train_loss = 1.5961721576750278, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 132, train_loss = 1.5900614000856876, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 133, train_loss = 1.5844570124754682, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 134, train_loss = 1.5783949246397242, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 135, train_loss = 1.5725742155918851, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 136, train_loss = 1.5662779906997457, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 137, train_loss = 1.561074792058207, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 138, train_loss = 1.5546601451933384, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 139, train_loss = 1.548970845877193, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 140, train_loss = 1.5437496801605448, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 141, train_loss = 1.5383507423102856, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 142, train_loss = 1.5330554569372907, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 143, train_loss = 1.5274826114764437, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 144, train_loss = 1.5223035389790311, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 145, train_loss = 1.5175620056688786, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 146, train_loss = 1.5120556764304638, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 147, train_loss = 1.5069506367435679, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 148, train_loss = 1.5021513676038012, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 149, train_loss = 1.4972094086697325, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 150, train_loss = 1.4921583185205236, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 151, train_loss = 1.487641990184784, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 152, train_loss = 1.4830655058613047, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 153, train_loss = 1.4782175148138776, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 154, train_loss = 1.4739153943955898, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 155, train_loss = 1.4699126580962911, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 156, train_loss = 1.4645102036301978, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 157, train_loss = 1.4608409516513348, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 158, train_loss = 1.4556537829339504, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 159, train_loss = 1.452439073473215, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 160, train_loss = 1.447833204001654, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 161, train_loss = 1.4440495756571181, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 162, train_loss = 1.4394062757492065, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 163, train_loss = 1.4355108861927874, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 164, train_loss = 1.4319350284640677, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 165, train_loss = 1.4274950263206847, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 166, train_loss = 1.4237075820565224, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 167, train_loss = 1.4197518776054494, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 168, train_loss = 1.4170770645141602, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 169, train_loss = 1.4120727355475537, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 170, train_loss = 1.40938175591873, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 171, train_loss = 1.4050355491344817, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 172, train_loss = 1.4016625955700874, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 173, train_loss = 1.397687202959787, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 174, train_loss = 1.3943091717665084, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 175, train_loss = 1.3913287346367724, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 176, train_loss = 1.3874943566625006, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 177, train_loss = 1.38430180773139, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 178, train_loss = 1.3809486230020411, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 179, train_loss = 1.377481943636667, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 180, train_loss = 1.3738367979531176, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 181, train_loss = 1.3716102677281015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 182, train_loss = 1.3670508190989494, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 183, train_loss = 1.3650698053534143, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 184, train_loss = 1.3613862109486945, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 185, train_loss = 1.358354613184929, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 186, train_loss = 1.3554480138118379, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 187, train_loss = 1.3519406728446484, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 188, train_loss = 1.3491972808842547, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 189, train_loss = 1.3461000472307205, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 190, train_loss = 1.3431722025270574, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 191, train_loss = 1.3404886548523791, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 192, train_loss = 1.337623671919573, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 193, train_loss = 1.334457166492939, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 194, train_loss = 1.3320641281898133, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 195, train_loss = 1.3288448217208497, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 196, train_loss = 1.326436469971668, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 197, train_loss = 1.3233269763295539, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 198, train_loss = 1.3207700488273986, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 199, train_loss = 1.317954522848595, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 200, train_loss = 1.3149655374581926, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 201, train_loss = 1.312926200509537, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 202, train_loss = 1.3098829127848148, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 203, train_loss = 1.307974934577942, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 204, train_loss = 1.3042731980676763, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 205, train_loss = 1.3024647620623, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 206, train_loss = 1.2999766183202155, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 207, train_loss = 1.2969707759912126, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 208, train_loss = 1.2944292140309699, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 209, train_loss = 1.2922752897138707, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 210, train_loss = 1.2891766031389125, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 211, train_loss = 1.2871540052001365, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 212, train_loss = 1.2847890282864682, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 213, train_loss = 1.2825609669089317, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 214, train_loss = 1.2802368961274624, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 215, train_loss = 1.2770381048321724, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 216, train_loss = 1.275809120386839, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 217, train_loss = 1.2725531446631067, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 218, train_loss = 1.2709896813030355, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 219, train_loss = 1.2682974562048912, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 220, train_loss = 1.2664241033489816, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 221, train_loss = 1.264232815534342, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 222, train_loss = 1.2613171562552452, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 223, train_loss = 1.2595861529116519, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 224, train_loss = 1.2575954335625283, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 225, train_loss = 1.2557170428335667, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 226, train_loss = 1.2525682672858238, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 227, train_loss = 1.2513587586581707, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 228, train_loss = 1.248832845420111, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 229, train_loss = 1.2471979968249798, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 230, train_loss = 1.244984081655275, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 231, train_loss = 1.242929161817301, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 232, train_loss = 1.240624015510548, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 233, train_loss = 1.2390301053528674, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 234, train_loss = 1.236675713211298, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 235, train_loss = 1.2344776044483297, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 236, train_loss = 1.2327379758353345, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 237, train_loss = 1.2305897250771523, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 238, train_loss = 1.2280815243721008, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 239, train_loss = 1.226483064412605, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 240, train_loss = 1.2242307650740258, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 241, train_loss = 1.2229077841038816, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 242, train_loss = 1.2204356069560163, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 243, train_loss = 1.2187703289091587, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 244, train_loss = 1.2168248755042441, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 245, train_loss = 1.2152369444374926, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 246, train_loss = 1.2130453288555145, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 247, train_loss = 1.2112540031666867, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 248, train_loss = 1.2093527342076413, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 249, train_loss = 1.2078812879917677, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 250, train_loss = 1.2058221163752023, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 251, train_loss = 1.204401253402466, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 252, train_loss = 1.2026431312260684, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 253, train_loss = 1.2005778476595879, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 254, train_loss = 1.1992194416525308, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 255, train_loss = 1.197740434348816, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 256, train_loss = 1.1952646324934904, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 257, train_loss = 1.1939523704349995, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 258, train_loss = 1.1925489207205828, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 259, train_loss = 1.1910149951872882, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 260, train_loss = 1.1885790204105433, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 261, train_loss = 1.1882064628007356, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 262, train_loss = 1.1859031890926417, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 263, train_loss = 1.1842005414364394, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 264, train_loss = 1.1827547488210257, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 265, train_loss = 1.1811605940165464, train_acc = 0.9980204937121565\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 266, train_loss = 1.1795031291840132, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 267, train_loss = 1.178023667394882, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 268, train_loss = 1.1763605251908302, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 269, train_loss = 1.1752412753703538, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 270, train_loss = 1.1736099123954773, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 271, train_loss = 1.1719982301292475, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 272, train_loss = 1.1708857603371143, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 273, train_loss = 1.168565926462179, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 274, train_loss = 1.1674687725899275, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 275, train_loss = 1.1659516232612077, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 276, train_loss = 1.1642380791308824, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 277, train_loss = 1.1628350913524628, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 278, train_loss = 1.1619746250507887, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 279, train_loss = 1.159774570405716, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 280, train_loss = 1.1586818123760168, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 281, train_loss = 1.1571430563926697, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 282, train_loss = 1.156349703669548, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 283, train_loss = 1.153931725770235, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 284, train_loss = 1.1529052245023195, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 285, train_loss = 1.1517026883957442, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 286, train_loss = 1.149891876935726, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 287, train_loss = 1.149043863028055, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 288, train_loss = 1.1473239312472288, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 289, train_loss = 1.1461571330728475, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 290, train_loss = 1.145146088063484, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 291, train_loss = 1.1432499016227666, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 292, train_loss = 1.1418531152012292, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 293, train_loss = 1.14104493954801, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 294, train_loss = 1.1396040754916612, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 295, train_loss = 1.1382737433013972, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 296, train_loss = 1.1369840527477209, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 297, train_loss = 1.1359189748764038, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 298, train_loss = 1.134335229784483, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 299, train_loss = 1.1334302152099553, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 300, train_loss = 1.1321919833717402, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 301, train_loss = 1.130595007300144, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 302, train_loss = 1.1299029129149858, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 303, train_loss = 1.128212379902834, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 304, train_loss = 1.1273093186318874, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 305, train_loss = 1.1256456238625105, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 306, train_loss = 1.1248874465527479, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 307, train_loss = 1.1234727340342943, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 308, train_loss = 1.1224396812322084, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 309, train_loss = 1.1210450778307859, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 310, train_loss = 1.119844483822817, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 311, train_loss = 1.118493522197241, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 312, train_loss = 1.11767091229558, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 313, train_loss = 1.1164664079842623, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 314, train_loss = 1.1157029407622758, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 315, train_loss = 1.113685306161642, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 316, train_loss = 1.112772992491955, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 317, train_loss = 1.1116116729972418, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 318, train_loss = 1.1105994755926076, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 319, train_loss = 1.1096917353570461, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 320, train_loss = 1.108439485222334, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 321, train_loss = 1.107555945724016, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 322, train_loss = 1.1064551932213362, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 323, train_loss = 1.1053594810364302, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 324, train_loss = 1.104093737900257, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 325, train_loss = 1.1035791970789433, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 326, train_loss = 1.102105040103197, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 327, train_loss = 1.1011735424399376, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 328, train_loss = 1.0995246308448259, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 329, train_loss = 1.0991513381304685, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 330, train_loss = 1.0979901788232382, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 331, train_loss = 1.0972196869552135, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 332, train_loss = 1.0956710254249629, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 333, train_loss = 1.09448173144483, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 334, train_loss = 1.0941315827367362, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 335, train_loss = 1.092359217494959, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 336, train_loss = 1.092162591725355, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 337, train_loss = 1.0909945195016917, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 338, train_loss = 1.089713916182518, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 339, train_loss = 1.0890800754132215, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 340, train_loss = 1.0881613194942474, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 341, train_loss = 1.0865935906767845, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 342, train_loss = 1.086226655781502, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 343, train_loss = 1.085061650723219, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 344, train_loss = 1.0838656363484915, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 345, train_loss = 1.0829450637102127, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 346, train_loss = 1.0826650373637676, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 347, train_loss = 1.0805951058864594, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 348, train_loss = 1.0803676880896091, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 349, train_loss = 1.0792292542755604, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 350, train_loss = 1.0783409550786018, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 351, train_loss = 1.0775098092854023, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 352, train_loss = 1.076318138599163, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 353, train_loss = 1.075203325599432, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 354, train_loss = 1.074676093965536, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 355, train_loss = 1.0735540936293546, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 356, train_loss = 1.0722572045924608, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 357, train_loss = 1.0718170503678266, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 358, train_loss = 1.070620946586132, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 359, train_loss = 1.0703606431779917, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 360, train_loss = 1.0692010683414992, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 361, train_loss = 1.0682767666876316, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 362, train_loss = 1.0671706783177797, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 363, train_loss = 1.0670115922985133, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 364, train_loss = 1.0650851974787656, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 365, train_loss = 1.065013200044632, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 366, train_loss = 1.0637527728977147, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 367, train_loss = 1.063676899910206, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 368, train_loss = 1.0621539826097433, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 369, train_loss = 1.0619885908963624, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 370, train_loss = 1.0602984738943633, train_acc = 0.9981369352585002\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 371, train_loss = 1.0601769424974918, train_acc = 0.9981369352585002\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 372, train_loss = 1.0588712344469968, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 373, train_loss = 1.0582996557059232, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 374, train_loss = 1.057280544191599, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 375, train_loss = 1.0562233602104243, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 376, train_loss = 1.0560176807048265, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 377, train_loss = 1.054474369942909, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 378, train_loss = 1.0543794818222523, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 379, train_loss = 1.052995285630459, train_acc = 0.9981369352585002\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 380, train_loss = 1.0519663356244564, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 381, train_loss = 1.0519352754054125, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 382, train_loss = 1.0506145929393824, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 383, train_loss = 1.0499824260768946, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 384, train_loss = 1.0489399371144827, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 385, train_loss = 1.0488031804561615, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 386, train_loss = 1.047582097351551, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 387, train_loss = 1.0470639107224997, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 388, train_loss = 1.0462525809707586, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 389, train_loss = 1.045717004686594, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 390, train_loss = 1.0442837998270988, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 391, train_loss = 1.0440595286490861, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 392, train_loss = 1.0432127751410007, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 393, train_loss = 1.041882017016178, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 394, train_loss = 1.041626459598774, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 395, train_loss = 1.0409775711596012, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 396, train_loss = 1.0403552204370499, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 397, train_loss = 1.0394004161062185, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 398, train_loss = 1.0386398608388845, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 399, train_loss = 1.0380585938692093, train_acc = 0.9981369352585002\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 400, train_loss = 1.037553258240223, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 401, train_loss = 1.0363790951669216, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 402, train_loss = 1.035917054861784, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 403, train_loss = 1.034680395066971, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 404, train_loss = 1.0347360422310885, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 405, train_loss = 1.0332730114459991, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 406, train_loss = 1.0328047735092696, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 407, train_loss = 1.0321029238402843, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 408, train_loss = 1.0315496275725309, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 409, train_loss = 1.0306895238754805, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 410, train_loss = 1.0301005244255066, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 411, train_loss = 1.0295257022080477, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 412, train_loss = 1.0286462008953094, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 413, train_loss = 1.0278881316335173, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 414, train_loss = 1.0276688349840697, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 415, train_loss = 1.0265359592885943, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 416, train_loss = 1.0258733866066905, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 417, train_loss = 1.0250717786402674, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 418, train_loss = 1.0244708905665902, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 419, train_loss = 1.0237753416149644, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 420, train_loss = 1.0230485523788957, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 421, train_loss = 1.022277003779891, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 422, train_loss = 1.0217912308871746, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 423, train_loss = 1.021028661474702, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 424, train_loss = 1.0204913392663002, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 425, train_loss = 1.0199973061680794, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 426, train_loss = 1.0186532201914815, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 427, train_loss = 1.0185453643352957, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 428, train_loss = 1.0178117180912523, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 429, train_loss = 1.017345156520605, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 430, train_loss = 1.0164229162037373, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 431, train_loss = 1.0155550303607015, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 432, train_loss = 1.0156086881906958, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 433, train_loss = 1.0147941708564758, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 434, train_loss = 1.0139455584139796, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 435, train_loss = 1.0137228618114023, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 436, train_loss = 1.0126952206046553, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 437, train_loss = 1.0120177753269672, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 438, train_loss = 1.0116394100041362, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 439, train_loss = 1.0107305546553107, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 440, train_loss = 1.010076095655677, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 441, train_loss = 1.010240598276141, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 442, train_loss = 1.0088588446378708, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 443, train_loss = 1.008510182306054, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 444, train_loss = 1.007768447205308, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 445, train_loss = 1.007431839898345, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 446, train_loss = 1.0061978946177987, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 447, train_loss = 1.0064678614289733, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 448, train_loss = 1.005401940390584, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 449, train_loss = 1.0052430381329032, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 450, train_loss = 1.0044450287969084, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 451, train_loss = 1.003870299711707, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 452, train_loss = 1.0038677801640006, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 453, train_loss = 1.0027519750146894, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 454, train_loss = 1.002146011844161, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 455, train_loss = 1.0013493585138349, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 456, train_loss = 1.000920449689147, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 457, train_loss = 1.0004256616084604, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 458, train_loss = 1.0002234280109406, train_acc = 0.9981369352585002\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 459, train_loss = 0.9994270205497742, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 460, train_loss = 0.998787405595067, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 461, train_loss = 0.9978650485427352, train_acc = 0.9981369352585002\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 462, train_loss = 0.9978013833315345, train_acc = 0.9981369352585002\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 463, train_loss = 0.9964176577777835, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 464, train_loss = 0.996776123836753, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 465, train_loss = 0.9957677672355203, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 466, train_loss = 0.9953034247009782, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 467, train_loss = 0.9947512596845627, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 468, train_loss = 0.9941642346529989, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 469, train_loss = 0.99334251631808, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 470, train_loss = 0.9931124945433112, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 471, train_loss = 0.9924886276276084, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 472, train_loss = 0.9919515487999888, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 473, train_loss = 0.991094193115714, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 474, train_loss = 0.9904728891997365, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 475, train_loss = 0.9903475008904934, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 476, train_loss = 0.9896700829267502, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 477, train_loss = 0.9889923557639122, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 478, train_loss = 0.9887740202248096, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 479, train_loss = 0.9876856642513303, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 480, train_loss = 0.9875567431299714, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 481, train_loss = 0.9868998527526855, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 482, train_loss = 0.9864121961145429, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 483, train_loss = 0.9857858841569396, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 484, train_loss = 0.9853121365158586, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 485, train_loss = 0.9851082836539717, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 486, train_loss = 0.984333448112011, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 487, train_loss = 0.9840119108557701, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 488, train_loss = 0.9832702775747748, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 489, train_loss = 0.9828407888562651, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 490, train_loss = 0.9819399168045493, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 491, train_loss = 0.9818979365081759, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 492, train_loss = 0.9814093038439751, train_acc = 0.9982533768048439\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 493, train_loss = 0.9807565100491047, train_acc = 0.9982533768048439\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 494, train_loss = 0.9801051057875156, train_acc = 0.9982533768048439\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 495, train_loss = 0.9795947037637234, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 496, train_loss = 0.9796028075070353, train_acc = 0.9982533768048439\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 497, train_loss = 0.9783560087234946, train_acc = 0.9981369352585002\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 498, train_loss = 0.9783255569636822, train_acc = 0.9982533768048439\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 499, train_loss = 0.9779483092279406, train_acc = 0.9982533768048439\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████▋                                                               | 4/30 [39:24<4:14:44, 587.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "5th- epoch: 0, train_loss = 138.70187711715698, train_acc = 0.7395202608290639\n",
      "test Acc 0.8505586592178771:\n",
      "5th- epoch: 1, train_loss = 51.63381112366915, train_acc = 0.8914764788076386\n",
      "test Acc 0.9031657355679702:\n",
      "5th- epoch: 2, train_loss = 36.8081136867404, train_acc = 0.9232650209594784\n",
      "test Acc 0.9245810055865922:\n",
      "5th- epoch: 3, train_loss = 29.473633747547865, train_acc = 0.9386353050768514\n",
      "test Acc 0.9338919925512105:\n",
      "5th- epoch: 4, train_loss = 24.857946317642927, train_acc = 0.9479506287843502\n",
      "test Acc 0.9385474860335196:\n",
      "5th- epoch: 5, train_loss = 21.57964688912034, train_acc = 0.9563344201210993\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 6, train_loss = 19.089361602440476, train_acc = 0.9620400558919422\n",
      "test Acc 0.946927374301676:\n",
      "5th- epoch: 7, train_loss = 17.10355679690838, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 8, train_loss = 15.487917250022292, train_acc = 0.9686772240335352\n",
      "test Acc 0.952513966480447:\n",
      "5th- epoch: 9, train_loss = 14.142235597595572, train_acc = 0.972286911970191\n",
      "test Acc 0.9557728119180633:\n",
      "5th- epoch: 10, train_loss = 13.00706154294312, train_acc = 0.9749650675360969\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 11, train_loss = 12.02368048299104, train_acc = 0.9763623660922217\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 12, train_loss = 11.169479636475444, train_acc = 0.9782254308337215\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 13, train_loss = 10.411428179591894, train_acc = 0.9795062878435026\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 14, train_loss = 9.739168625324965, train_acc = 0.9803213786679087\n",
      "test Acc 0.962756052141527:\n",
      "5th- epoch: 15, train_loss = 9.136040955781937, train_acc = 0.9811364694923148\n",
      "test Acc 0.9622905027932961:\n",
      "5th- epoch: 16, train_loss = 8.600980251096189, train_acc = 0.9827666511411272\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 17, train_loss = 8.124479224905372, train_acc = 0.9839310666045645\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 18, train_loss = 7.695756996050477, train_acc = 0.9845132743362832\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 19, train_loss = 7.305881069973111, train_acc = 0.9856776897997206\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 20, train_loss = 6.947317723184824, train_acc = 0.9867256637168141\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 21, train_loss = 6.6244396436959505, train_acc = 0.9877736376339078\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 22, train_loss = 6.328157438896596, train_acc = 0.9885887284583139\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 23, train_loss = 6.058639163151383, train_acc = 0.9889380530973452\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 24, train_loss = 5.814226767979562, train_acc = 0.9896367023754076\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 25, train_loss = 5.5857493337243795, train_acc = 0.989869585468095\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 26, train_loss = 5.375589167699218, train_acc = 0.9902189101071263\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 27, train_loss = 5.1832644091919065, train_acc = 0.9910340009315324\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 28, train_loss = 5.003753119148314, train_acc = 0.9916162086632511\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 29, train_loss = 4.8393140230327845, train_acc = 0.9917326502095948\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 30, train_loss = 4.682480747811496, train_acc = 0.9919655333022822\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 31, train_loss = 4.540406306274235, train_acc = 0.9924312994876572\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 32, train_loss = 4.40414793882519, train_acc = 0.9930135072193759\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 33, train_loss = 4.2786338878795505, train_acc = 0.9932463903120633\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 34, train_loss = 4.160560870543122, train_acc = 0.9934792734047508\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 35, train_loss = 4.048980605788529, train_acc = 0.993828598043782\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 36, train_loss = 3.9459202270954847, train_acc = 0.9939450395901258\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 37, train_loss = 3.8464037105441093, train_acc = 0.9939450395901258\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 38, train_loss = 3.754396360833198, train_acc = 0.9941779226828132\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 39, train_loss = 3.6671692691743374, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 40, train_loss = 3.5828789160586894, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 41, train_loss = 3.504693131893873, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 42, train_loss = 3.4299938967451453, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "5th- epoch: 43, train_loss = 3.3588800309225917, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "5th- epoch: 44, train_loss = 3.2911285273730755, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "5th- epoch: 45, train_loss = 3.2274881759658456, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "5th- epoch: 46, train_loss = 3.164947558194399, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 47, train_loss = 3.1060201274231076, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 48, train_loss = 3.047805802896619, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 49, train_loss = 2.993609237484634, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 50, train_loss = 2.9429907919839025, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 51, train_loss = 2.8924858793616295, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 52, train_loss = 2.846769695635885, train_acc = 0.9952258965999069\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 53, train_loss = 2.80176609614864, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 54, train_loss = 2.758449427317828, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 55, train_loss = 2.7176870852708817, train_acc = 0.9956916627852818\n",
      "test Acc 0.9753258845437617:\n",
      "5th- epoch: 56, train_loss = 2.6772754690609872, train_acc = 0.9958081043316255\n",
      "test Acc 0.9753258845437617:\n",
      "5th- epoch: 57, train_loss = 2.6395706068724394, train_acc = 0.9958081043316255\n",
      "test Acc 0.9753258845437617:\n",
      "5th- epoch: 58, train_loss = 2.602996023837477, train_acc = 0.9958081043316255\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 59, train_loss = 2.567395424004644, train_acc = 0.9958081043316255\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 60, train_loss = 2.533806782681495, train_acc = 0.9959245458779693\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 61, train_loss = 2.5012388243339956, train_acc = 0.9959245458779693\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 62, train_loss = 2.4707569065503776, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 63, train_loss = 2.439930362161249, train_acc = 0.996040987424313\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 64, train_loss = 2.411023219116032, train_acc = 0.9961574289706567\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 65, train_loss = 2.383228986058384, train_acc = 0.9961574289706567\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 66, train_loss = 2.3553833118639886, train_acc = 0.9961574289706567\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 67, train_loss = 2.328886470757425, train_acc = 0.9963903120633442\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 68, train_loss = 2.303944854531437, train_acc = 0.9963903120633442\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 69, train_loss = 2.2788050905801356, train_acc = 0.9963903120633442\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 70, train_loss = 2.255071067251265, train_acc = 0.9963903120633442\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 71, train_loss = 2.2314697937108576, train_acc = 0.996506753609688\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 72, train_loss = 2.209757379256189, train_acc = 0.996506753609688\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 73, train_loss = 2.187981206923723, train_acc = 0.9966231951560317\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 74, train_loss = 2.167149691376835, train_acc = 0.9966231951560317\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 75, train_loss = 2.146226924378425, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 76, train_loss = 2.1265353527851403, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 77, train_loss = 2.1074243262410164, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 78, train_loss = 2.0886460193432868, train_acc = 0.9967396367023754\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 79, train_loss = 2.07041296409443, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 80, train_loss = 2.052857088856399, train_acc = 0.9967396367023754\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 81, train_loss = 2.0357581549324095, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 82, train_loss = 2.018794304691255, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 83, train_loss = 2.002424621488899, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 84, train_loss = 1.987089999485761, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 85, train_loss = 1.9715667688287795, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 86, train_loss = 1.9565585739910603, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 87, train_loss = 1.9424988054670393, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 88, train_loss = 1.9279471808113158, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 89, train_loss = 1.9138741195201874, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 90, train_loss = 1.9008854534476995, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 91, train_loss = 1.8876003785990179, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 92, train_loss = 1.875201943796128, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 93, train_loss = 1.8621355178765953, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 94, train_loss = 1.8499002768658102, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 95, train_loss = 1.838398972293362, train_acc = 0.9969725197950629\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 96, train_loss = 1.8267857611645013, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 97, train_loss = 1.8155991041567177, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 98, train_loss = 1.8040946621913463, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 99, train_loss = 1.7933711875230074, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 100, train_loss = 1.7824924271553755, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 101, train_loss = 1.7723377030342817, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 102, train_loss = 1.7621921098325402, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 103, train_loss = 1.7522667639423162, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 104, train_loss = 1.741940462961793, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 105, train_loss = 1.7330978251993656, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 106, train_loss = 1.7235484784469008, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 107, train_loss = 1.714152597123757, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 108, train_loss = 1.70527985971421, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 109, train_loss = 1.696901701623574, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 110, train_loss = 1.6877718502655625, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 111, train_loss = 1.6797722454648465, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 112, train_loss = 1.6710614208132029, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 113, train_loss = 1.662791542476043, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 114, train_loss = 1.6550363237038255, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 115, train_loss = 1.6471917962189764, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 116, train_loss = 1.639531065709889, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 117, train_loss = 1.6316801449283957, train_acc = 0.9970889613414066\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 118, train_loss = 1.6242554348427802, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 119, train_loss = 1.616852467181161, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 120, train_loss = 1.60917360894382, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 121, train_loss = 1.602559502935037, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 122, train_loss = 1.5952164663467556, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 123, train_loss = 1.5880809084046632, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 124, train_loss = 1.58176252967678, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 125, train_loss = 1.5743514078203589, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 126, train_loss = 1.5684325869660825, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 127, train_loss = 1.5616254124324769, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 128, train_loss = 1.5548514209222049, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 129, train_loss = 1.5493172642309219, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 130, train_loss = 1.5426757109817117, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 131, train_loss = 1.537167432717979, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 132, train_loss = 1.5304810777306557, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 133, train_loss = 1.5251581072807312, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 134, train_loss = 1.518723253160715, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 135, train_loss = 1.5132552364375442, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 136, train_loss = 1.5081008558627218, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 137, train_loss = 1.5018604972865433, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 138, train_loss = 1.496631400892511, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 139, train_loss = 1.4912406562361866, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 140, train_loss = 1.4857023155782372, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 141, train_loss = 1.4809661144390702, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 142, train_loss = 1.475567857036367, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 143, train_loss = 1.4699017831590027, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 144, train_loss = 1.4658071377780288, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 145, train_loss = 1.4601054566446692, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 146, train_loss = 1.4554658287670463, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 147, train_loss = 1.4506375116761774, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 148, train_loss = 1.445879136910662, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 149, train_loss = 1.4413319460581988, train_acc = 0.9970889613414066\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 150, train_loss = 1.4368453368078917, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 151, train_loss = 1.4321783112827688, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 152, train_loss = 1.4276916680391878, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 153, train_loss = 1.4233582869637758, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 154, train_loss = 1.4189039536286145, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 155, train_loss = 1.4144825593102723, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 156, train_loss = 1.4104890741873533, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 157, train_loss = 1.4061429768335074, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 158, train_loss = 1.4019905154127628, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 159, train_loss = 1.3978830308187753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 160, train_loss = 1.3941858399193734, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 161, train_loss = 1.3894057521829382, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 162, train_loss = 1.3861184673151001, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 163, train_loss = 1.382115475833416, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 164, train_loss = 1.3783775555202737, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 165, train_loss = 1.374284721328877, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 166, train_loss = 1.3704975923756137, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 167, train_loss = 1.3671482218196616, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 168, train_loss = 1.363356021582149, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 169, train_loss = 1.3595637442776933, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 170, train_loss = 1.3562125010648742, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 171, train_loss = 1.3524321099976078, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 172, train_loss = 1.3486505231121555, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 173, train_loss = 1.3454735781997442, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 174, train_loss = 1.3421629518270493, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 175, train_loss = 1.3390870752045885, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 176, train_loss = 1.3352444717893377, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 177, train_loss = 1.3319108436116949, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 178, train_loss = 1.3290038699051365, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 179, train_loss = 1.3253885625163093, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 180, train_loss = 1.3227055966854095, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 181, train_loss = 1.3192573258420452, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 182, train_loss = 1.316478188498877, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 183, train_loss = 1.3126089194556698, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 184, train_loss = 1.3100551087409258, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 185, train_loss = 1.3076140409102663, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 186, train_loss = 1.3040426230290905, train_acc = 0.9972054028877504\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 187, train_loss = 1.3013879464706406, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 188, train_loss = 1.2984486985951662, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 189, train_loss = 1.2951696813106537, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 190, train_loss = 1.2925024256110191, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 191, train_loss = 1.289612328633666, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 192, train_loss = 1.286788028315641, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 193, train_loss = 1.2840724736452103, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 194, train_loss = 1.2812232685973868, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 195, train_loss = 1.2784153303364292, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 196, train_loss = 1.2758957339683548, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 197, train_loss = 1.2735776044428349, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 198, train_loss = 1.2705320635577664, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 199, train_loss = 1.2677704077214003, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 200, train_loss = 1.2659264113754034, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 201, train_loss = 1.2626351112267002, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 202, train_loss = 1.2605270718922839, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 203, train_loss = 1.2577073132852092, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 204, train_loss = 1.255580946803093, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 205, train_loss = 1.2527998058358207, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 206, train_loss = 1.250676367431879, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 207, train_loss = 1.2481902657309547, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 208, train_loss = 1.245846270932816, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 209, train_loss = 1.2430863553890958, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 210, train_loss = 1.2410789678106084, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 211, train_loss = 1.2379993764916435, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 212, train_loss = 1.2361970903584734, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 213, train_loss = 1.2343636993318796, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 214, train_loss = 1.231997674331069, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 215, train_loss = 1.2289142509689555, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 216, train_loss = 1.2270976174622774, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 217, train_loss = 1.2245976086705923, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 218, train_loss = 1.2229677749564871, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 219, train_loss = 1.2206184584647417, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 220, train_loss = 1.2185349253704771, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 221, train_loss = 1.2158616352826357, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 222, train_loss = 1.2139420881867409, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 223, train_loss = 1.211458694189787, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 224, train_loss = 1.210021490813233, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 225, train_loss = 1.2078511914005503, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 226, train_loss = 1.2052113035460934, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 227, train_loss = 1.2035755949327722, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 228, train_loss = 1.2008954851189628, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 229, train_loss = 1.1994484458118677, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 230, train_loss = 1.1969590336084366, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 231, train_loss = 1.1952916501322761, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 232, train_loss = 1.193238254636526, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 233, train_loss = 1.1909774461528286, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 234, train_loss = 1.189387485384941, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 235, train_loss = 1.1875357571989298, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 236, train_loss = 1.1851778887212276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 237, train_loss = 1.1836729204514995, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 238, train_loss = 1.1815289097139612, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 239, train_loss = 1.1802994267782196, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 240, train_loss = 1.1768897883594036, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 241, train_loss = 1.1766808902611956, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 242, train_loss = 1.1744705121964216, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 243, train_loss = 1.172473106533289, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 244, train_loss = 1.170409681275487, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 245, train_loss = 1.1687085101148114, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 246, train_loss = 1.167397828772664, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 247, train_loss = 1.1652985122054815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 248, train_loss = 1.1639725925633684, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 249, train_loss = 1.1614622889319435, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 250, train_loss = 1.1605388224124908, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 251, train_loss = 1.1591029645642266, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 252, train_loss = 1.1569625480333343, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 253, train_loss = 1.1552834877511486, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 254, train_loss = 1.1540781073272228, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 255, train_loss = 1.1526819387217984, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 256, train_loss = 1.1504936007549986, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 257, train_loss = 1.1489893110701814, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 258, train_loss = 1.1473946390906349, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 259, train_loss = 1.1458089835941792, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 260, train_loss = 1.1454871421447024, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 261, train_loss = 1.1428930647671223, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 262, train_loss = 1.1414845356484875, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 263, train_loss = 1.1397826435277238, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 264, train_loss = 1.1384961468866095, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 265, train_loss = 1.136792934150435, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 266, train_loss = 1.1352662401041016, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 267, train_loss = 1.1342462487518787, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 268, train_loss = 1.1328752301633358, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 269, train_loss = 1.1304545173188671, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 270, train_loss = 1.1294966420391575, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 271, train_loss = 1.128778276965022, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 272, train_loss = 1.1267549054464325, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 273, train_loss = 1.1255374290049076, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 274, train_loss = 1.1241936640581116, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 275, train_loss = 1.1220962218940258, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 276, train_loss = 1.1212699667667039, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 277, train_loss = 1.1203007375006564, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 278, train_loss = 1.118337410793174, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 279, train_loss = 1.1168414403800853, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 280, train_loss = 1.1158294274355285, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 281, train_loss = 1.114600722969044, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 282, train_loss = 1.1128748636692762, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 283, train_loss = 1.1111948695033789, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 284, train_loss = 1.1099119205027819, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 285, train_loss = 1.1091501681949012, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 286, train_loss = 1.1076408047229052, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 287, train_loss = 1.1061536104534753, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 288, train_loss = 1.1046546244178899, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 289, train_loss = 1.1038304188405164, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 290, train_loss = 1.1023434959352016, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 291, train_loss = 1.100850950286258, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 292, train_loss = 1.0999977073515765, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 293, train_loss = 1.0987416307325475, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 294, train_loss = 1.09777570766164, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 295, train_loss = 1.096132454171311, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 296, train_loss = 1.0949525758624077, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 297, train_loss = 1.0939288244699128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 298, train_loss = 1.0926783972536214, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 299, train_loss = 1.0915734029258601, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 300, train_loss = 1.0904840373550542, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 301, train_loss = 1.0897144197369926, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 302, train_loss = 1.0881486025755294, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 303, train_loss = 1.0866456596995704, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 304, train_loss = 1.085754148021806, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 305, train_loss = 1.0854856086079963, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 306, train_loss = 1.0839044824242592, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 307, train_loss = 1.0822745468467474, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 308, train_loss = 1.0813338520820253, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 309, train_loss = 1.0806711949408054, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 310, train_loss = 1.0793377459049225, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 311, train_loss = 1.0782260901178233, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 312, train_loss = 1.0766074365819804, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 313, train_loss = 1.075835692405235, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 314, train_loss = 1.0754070983384736, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 315, train_loss = 1.0736705486779101, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 316, train_loss = 1.0726864741300233, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 317, train_loss = 1.071689025789965, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 318, train_loss = 1.0706360551412217, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 319, train_loss = 1.0694493620540015, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 320, train_loss = 1.0686330602620728, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 321, train_loss = 1.067144448577892, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 322, train_loss = 1.067030272737611, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 323, train_loss = 1.065127735317219, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 324, train_loss = 1.0636369325220585, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 325, train_loss = 1.0640812168712728, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 326, train_loss = 1.0628760966355912, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 327, train_loss = 1.0610194653272629, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 328, train_loss = 1.0602879021316767, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 329, train_loss = 1.0593327209353447, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 330, train_loss = 1.0584982559084892, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 331, train_loss = 1.0576188291306607, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 332, train_loss = 1.0563780392403714, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 333, train_loss = 1.0554714724421501, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 334, train_loss = 1.054212749004364, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 335, train_loss = 1.0532851126044989, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 336, train_loss = 1.0526543377782218, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 337, train_loss = 1.0516661200672388, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 338, train_loss = 1.0502707554842345, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 339, train_loss = 1.050101960718166, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 340, train_loss = 1.0492969881743193, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 341, train_loss = 1.0477950132335536, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 342, train_loss = 1.0466744980658405, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 343, train_loss = 1.0466174173052423, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 344, train_loss = 1.0452752690762281, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 345, train_loss = 1.0437912971829064, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 346, train_loss = 1.043628663464915, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 347, train_loss = 1.0424567584996112, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 348, train_loss = 1.0414120070636272, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 349, train_loss = 1.0408961065113544, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 350, train_loss = 1.0398648672853597, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 351, train_loss = 1.038941951468587, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 352, train_loss = 1.0382290097768418, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 353, train_loss = 1.0371178475324996, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 354, train_loss = 1.0363582521677017, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 355, train_loss = 1.035163948952686, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 356, train_loss = 1.0343481823801994, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 357, train_loss = 1.0332784559577703, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 358, train_loss = 1.0324622572516091, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 359, train_loss = 1.0318337896023877, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 360, train_loss = 1.0307858877931722, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 361, train_loss = 1.0301288533955812, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 362, train_loss = 1.0296454690396786, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 363, train_loss = 1.028368143364787, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 364, train_loss = 1.027648173912894, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 365, train_loss = 1.026594564318657, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 366, train_loss = 1.026339138566982, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 367, train_loss = 1.0253158963168971, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 368, train_loss = 1.0246344543993473, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 369, train_loss = 1.0233041017199866, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 370, train_loss = 1.0226289499551058, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 371, train_loss = 1.0225191519712098, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 372, train_loss = 1.0216357136960141, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 373, train_loss = 1.0203345865011215, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 374, train_loss = 1.019726723432541, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 375, train_loss = 1.0192243748460896, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 376, train_loss = 1.0184709181194194, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 377, train_loss = 1.0174116672133096, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 378, train_loss = 1.0172374515677802, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 379, train_loss = 1.0157389237429015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 380, train_loss = 1.0148874347214587, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 381, train_loss = 1.0141838931594975, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 382, train_loss = 1.0134548638015985, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 383, train_loss = 1.0124569839681499, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 384, train_loss = 1.0124508868902922, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 385, train_loss = 1.011370686814189, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 386, train_loss = 1.0109551374916919, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 387, train_loss = 1.0100356098264456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 388, train_loss = 1.0091312446747907, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 389, train_loss = 1.008619808300864, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 390, train_loss = 1.0074552900041454, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 391, train_loss = 1.0069779070909135, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 392, train_loss = 1.0063205274636857, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 393, train_loss = 1.0059248662437312, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 394, train_loss = 1.0049261984531768, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 395, train_loss = 1.004194778681267, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 396, train_loss = 1.0031417086720467, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 397, train_loss = 1.0031873751431704, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 398, train_loss = 1.0019484236836433, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 399, train_loss = 1.0013006522203796, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 400, train_loss = 1.0006306159193628, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 401, train_loss = 0.9999257251620293, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 402, train_loss = 0.9991896661813371, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 403, train_loss = 0.998517906293273, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 404, train_loss = 0.9976452228729613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 405, train_loss = 0.9970056868041866, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 406, train_loss = 0.9964299972052686, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 407, train_loss = 0.9952800671453588, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 408, train_loss = 0.9948174667661078, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 409, train_loss = 0.9938689905102365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 410, train_loss = 0.993691582872998, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 411, train_loss = 0.9927542271907441, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 412, train_loss = 0.9922564228181727, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 413, train_loss = 0.9910768941044807, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 414, train_loss = 0.990370225161314, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 415, train_loss = 0.990349346131552, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 416, train_loss = 0.9897162349079736, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 417, train_loss = 0.9887011187965982, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 418, train_loss = 0.9884196842904203, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 419, train_loss = 0.9872207175940275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 420, train_loss = 0.9873207975178957, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 421, train_loss = 0.9858825716073625, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 422, train_loss = 0.9862793696229346, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 423, train_loss = 0.9856285055284388, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 424, train_loss = 0.9843348935246468, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 425, train_loss = 0.9842162120039575, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 426, train_loss = 0.9833557966048829, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 427, train_loss = 0.9823619115049951, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 428, train_loss = 0.9818040281534195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 429, train_loss = 0.9815896625514142, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 430, train_loss = 0.980870246887207, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 431, train_loss = 0.9805162523989566, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 432, train_loss = 0.9798775662784465, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 433, train_loss = 0.9791615183348767, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 434, train_loss = 0.9786215902422555, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 435, train_loss = 0.9783556014299393, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 436, train_loss = 0.9772747897659428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 437, train_loss = 0.9765688317711465, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 438, train_loss = 0.9763619887526147, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 439, train_loss = 0.9757065649027936, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 440, train_loss = 0.9745888343895786, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 441, train_loss = 0.9744565213914029, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 442, train_loss = 0.9735425282269716, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 443, train_loss = 0.9735722430050373, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 444, train_loss = 0.9728127159178257, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 445, train_loss = 0.9723043330013752, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 446, train_loss = 0.9713116809725761, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 447, train_loss = 0.9715440105646849, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 448, train_loss = 0.9704683988238685, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 449, train_loss = 0.9698152666096576, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 450, train_loss = 0.9689186910691205, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 451, train_loss = 0.9685013654234353, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 452, train_loss = 0.9680655660631601, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 453, train_loss = 0.9678066074848175, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 454, train_loss = 0.9668154331448022, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 455, train_loss = 0.9665622686443385, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 456, train_loss = 0.9662100200948771, train_acc = 0.9977876106194691\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 457, train_loss = 0.9651482949557249, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 458, train_loss = 0.9651091738196556, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 459, train_loss = 0.9640367502870504, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 460, train_loss = 0.9634455026534852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 461, train_loss = 0.9638227758405264, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 462, train_loss = 0.9627760586736258, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 463, train_loss = 0.9622863233089447, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 464, train_loss = 0.9615460795757826, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 465, train_loss = 0.9614605146052781, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 466, train_loss = 0.9607999163272325, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 467, train_loss = 0.9606100792589132, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 468, train_loss = 0.9596116319298744, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 469, train_loss = 0.9589551178214606, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 470, train_loss = 0.9591890921292361, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 471, train_loss = 0.9580064552428667, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 472, train_loss = 0.9577047030034009, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 473, train_loss = 0.9571284974517766, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 474, train_loss = 0.9564339593052864, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 475, train_loss = 0.9561602858302649, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 476, train_loss = 0.955487592756981, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 477, train_loss = 0.9551096521317959, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 478, train_loss = 0.9545178133994341, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 479, train_loss = 0.9541520321217831, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 480, train_loss = 0.9537731719610747, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 481, train_loss = 0.9530833574535791, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 482, train_loss = 0.9526010627450887, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 483, train_loss = 0.9523074266908225, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 484, train_loss = 0.9512729942798615, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 485, train_loss = 0.9510321778652724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 486, train_loss = 0.9503428662719671, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 487, train_loss = 0.9506222059426364, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 488, train_loss = 0.9495901154878084, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 489, train_loss = 0.9492761380970478, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 490, train_loss = 0.9488303748366889, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 491, train_loss = 0.9477093517780304, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 492, train_loss = 0.9475640846940223, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 493, train_loss = 0.9471203268913087, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 494, train_loss = 0.9468901331129018, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 495, train_loss = 0.946008396014804, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 496, train_loss = 0.9461580372008029, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 497, train_loss = 0.9458282788691577, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 498, train_loss = 0.9448721359076444, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 499, train_loss = 0.9443826849164907, train_acc = 0.9979040521658128\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████▏                                                            | 5/30 [49:26<4:06:42, 592.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "6th- epoch: 0, train_loss = 145.12541434168816, train_acc = 0.7401024685607824\n",
      "test Acc 0.8445065176908753:\n",
      "6th- epoch: 1, train_loss = 53.523081820458174, train_acc = 0.8876339077782953\n",
      "test Acc 0.8929236499068901:\n",
      "6th- epoch: 2, train_loss = 37.701557744294405, train_acc = 0.9193060083837913\n",
      "test Acc 0.9110800744878957:\n",
      "6th- epoch: 3, train_loss = 29.71613502688706, train_acc = 0.9350256171401956\n",
      "test Acc 0.9236499068901304:\n",
      "6th- epoch: 4, train_loss = 24.695085471495986, train_acc = 0.9487657196087564\n",
      "test Acc 0.9324953445065177:\n",
      "6th- epoch: 5, train_loss = 21.212551033124328, train_acc = 0.956450861667443\n",
      "test Acc 0.9413407821229051:\n",
      "6th- epoch: 6, train_loss = 18.612396704033017, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 7, train_loss = 16.559086906723678, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 8, train_loss = 14.886173020116985, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "6th- epoch: 9, train_loss = 13.496039154939353, train_acc = 0.9726362366092222\n",
      "test Acc 0.952048417132216:\n",
      "6th- epoch: 10, train_loss = 12.331263232044876, train_acc = 0.9754308337214718\n",
      "test Acc 0.9529795158286778:\n",
      "6th- epoch: 11, train_loss = 11.335866977460682, train_acc = 0.9777596646483465\n",
      "test Acc 0.9548417132216015:\n",
      "6th- epoch: 12, train_loss = 10.478891941718757, train_acc = 0.9796227293898463\n",
      "test Acc 0.9548417132216015:\n",
      "6th- epoch: 13, train_loss = 9.732514495961368, train_acc = 0.9810200279459711\n",
      "test Acc 0.9562383612662942:\n",
      "6th- epoch: 14, train_loss = 9.079033543355763, train_acc = 0.9827666511411272\n",
      "test Acc 0.957635009310987:\n",
      "6th- epoch: 15, train_loss = 8.501566554419696, train_acc = 0.9843968327899395\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 16, train_loss = 7.992987590841949, train_acc = 0.9855612482533768\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 17, train_loss = 7.534341249614954, train_acc = 0.9861434559850955\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 18, train_loss = 7.1281318897381425, train_acc = 0.9877736376339078\n",
      "test Acc 0.9604283054003724:\n",
      "6th- epoch: 19, train_loss = 6.762341524474323, train_acc = 0.9888216115510013\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 20, train_loss = 6.4329494358971715, train_acc = 0.9896367023754076\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 21, train_loss = 6.13570789899677, train_acc = 0.9904517931998137\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 22, train_loss = 5.865276414901018, train_acc = 0.9912668840242198\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 23, train_loss = 5.617304213345051, train_acc = 0.9917326502095948\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 24, train_loss = 5.389464654028416, train_acc = 0.992081974848626\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 25, train_loss = 5.1832223711535335, train_acc = 0.9921984163949698\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 26, train_loss = 4.99140411010012, train_acc = 0.9924312994876572\n",
      "test Acc 0.9622905027932961:\n",
      "6th- epoch: 27, train_loss = 4.814091370906681, train_acc = 0.9925477410340009\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 28, train_loss = 4.652082070708275, train_acc = 0.9932463903120633\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 29, train_loss = 4.4998054900206625, train_acc = 0.9937121564974383\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 30, train_loss = 4.359470352530479, train_acc = 0.9937121564974383\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 31, train_loss = 4.227364038582891, train_acc = 0.9939450395901258\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 32, train_loss = 4.108206380158663, train_acc = 0.9940614811364695\n",
      "test Acc 0.9646182495344506:\n",
      "6th- epoch: 33, train_loss = 3.9923886731266975, train_acc = 0.9944108057755007\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 34, train_loss = 3.8849330111406744, train_acc = 0.9946436888681882\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 35, train_loss = 3.782692162785679, train_acc = 0.9947601304145319\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 36, train_loss = 3.687589561101049, train_acc = 0.9947601304145319\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 37, train_loss = 3.599434097763151, train_acc = 0.9949930135072194\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 38, train_loss = 3.514048393815756, train_acc = 0.9954587796925943\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 39, train_loss = 3.435148081276566, train_acc = 0.9956916627852818\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 40, train_loss = 3.357842091470957, train_acc = 0.9956916627852818\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 41, train_loss = 3.286473773419857, train_acc = 0.9958081043316255\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 42, train_loss = 3.2169980905018747, train_acc = 0.9959245458779693\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 43, train_loss = 3.152946535497904, train_acc = 0.9959245458779693\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 44, train_loss = 3.089398821350187, train_acc = 0.9959245458779693\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 45, train_loss = 3.0310113839805126, train_acc = 0.996040987424313\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 46, train_loss = 2.9743488244712353, train_acc = 0.996040987424313\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 47, train_loss = 2.9200647831894457, train_acc = 0.9961574289706567\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 48, train_loss = 2.8680272200144827, train_acc = 0.9961574289706567\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 49, train_loss = 2.81800185283646, train_acc = 0.9961574289706567\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 50, train_loss = 2.771028173621744, train_acc = 0.9961574289706567\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 51, train_loss = 2.7259127921424806, train_acc = 0.9961574289706567\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 52, train_loss = 2.682366445660591, train_acc = 0.9961574289706567\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 53, train_loss = 2.641140893101692, train_acc = 0.9961574289706567\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 54, train_loss = 2.601074181497097, train_acc = 0.996506753609688\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 55, train_loss = 2.5632351264357567, train_acc = 0.996506753609688\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 56, train_loss = 2.5263158581219614, train_acc = 0.9966231951560317\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 57, train_loss = 2.491027054609731, train_acc = 0.9968560782487191\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 58, train_loss = 2.457094579935074, train_acc = 0.9968560782487191\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 59, train_loss = 2.425071441801265, train_acc = 0.9968560782487191\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 60, train_loss = 2.3933645747601986, train_acc = 0.9968560782487191\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 61, train_loss = 2.3629519902169704, train_acc = 0.9968560782487191\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 62, train_loss = 2.334508226485923, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 63, train_loss = 2.306449222145602, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 64, train_loss = 2.279655159683898, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 65, train_loss = 2.2535881213843822, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 66, train_loss = 2.228617787361145, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 67, train_loss = 2.2038238756358624, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 68, train_loss = 2.180724136531353, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 69, train_loss = 2.157998848706484, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 70, train_loss = 2.1352435934823006, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 71, train_loss = 2.113655296387151, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 72, train_loss = 2.0924646023195237, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 73, train_loss = 2.0726491648238152, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 74, train_loss = 2.052880556555465, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 75, train_loss = 2.0346223637461662, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 76, train_loss = 2.0155125681776553, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 77, train_loss = 1.9982866358477622, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 78, train_loss = 1.9801944345235825, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 79, train_loss = 1.9647992711979896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 80, train_loss = 1.9479586842935532, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 81, train_loss = 1.932354760589078, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 82, train_loss = 1.9167625878471881, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 83, train_loss = 1.9016570101957768, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 84, train_loss = 1.8875180843751878, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 85, train_loss = 1.873187568038702, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 86, train_loss = 1.8595380906481296, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 87, train_loss = 1.8462262190878391, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 88, train_loss = 1.8332069988828152, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 89, train_loss = 1.8211087472736835, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 90, train_loss = 1.8083356209099293, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 91, train_loss = 1.7964421212673187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 92, train_loss = 1.7846386779565364, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 93, train_loss = 1.773620367050171, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 94, train_loss = 1.7624452064046636, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 95, train_loss = 1.751142892986536, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 96, train_loss = 1.740781250060536, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 97, train_loss = 1.730669284821488, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 98, train_loss = 1.7207565034041181, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 99, train_loss = 1.7108855558326468, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 100, train_loss = 1.7009489635238424, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 101, train_loss = 1.6919553987681866, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 102, train_loss = 1.6824530474841595, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 103, train_loss = 1.6733534584054723, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 104, train_loss = 1.6644376131007448, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 105, train_loss = 1.6560227511217818, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 106, train_loss = 1.6476486237952486, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 107, train_loss = 1.6390617924043909, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 108, train_loss = 1.6306456550955772, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 109, train_loss = 1.6227324394276366, train_acc = 0.9979040521658128\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 110, train_loss = 1.614350369782187, train_acc = 0.9979040521658128\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 111, train_loss = 1.6057186549296603, train_acc = 0.9979040521658128\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 112, train_loss = 1.598135408014059, train_acc = 0.9979040521658128\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 113, train_loss = 1.589963729144074, train_acc = 0.9979040521658128\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 114, train_loss = 1.5825455287704244, train_acc = 0.9980204937121565\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 115, train_loss = 1.5747955652186647, train_acc = 0.9980204937121565\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 116, train_loss = 1.5678823528578505, train_acc = 0.9980204937121565\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 117, train_loss = 1.5613809576025233, train_acc = 0.9981369352585002\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 118, train_loss = 1.5541542110731825, train_acc = 0.9981369352585002\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 119, train_loss = 1.5477474170038477, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 120, train_loss = 1.541178371757269, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 121, train_loss = 1.5351361781358719, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 122, train_loss = 1.5283818878233433, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 123, train_loss = 1.5226424658903852, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 124, train_loss = 1.5166109340498224, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 125, train_loss = 1.5104814283549786, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 126, train_loss = 1.5050823340425268, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 127, train_loss = 1.498611138551496, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 128, train_loss = 1.4934404628584161, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 129, train_loss = 1.488060623407364, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 130, train_loss = 1.4822614354779944, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 131, train_loss = 1.477125951438211, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 132, train_loss = 1.4722059717169032, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 133, train_loss = 1.4669412672519684, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 134, train_loss = 1.4617124361684546, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 135, train_loss = 1.4568058401346207, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 136, train_loss = 1.4518345954129472, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 137, train_loss = 1.4468432366847992, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 138, train_loss = 1.4419294757535681, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 139, train_loss = 1.4371227932861075, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 140, train_loss = 1.4322476871311665, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 141, train_loss = 1.428019892424345, train_acc = 0.9981369352585002\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 142, train_loss = 1.4234714905032888, train_acc = 0.9981369352585002\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 143, train_loss = 1.4192443614592776, train_acc = 0.9981369352585002\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 144, train_loss = 1.4144603287568316, train_acc = 0.9981369352585002\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 145, train_loss = 1.4107266081264243, train_acc = 0.9981369352585002\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 146, train_loss = 1.4056921364972368, train_acc = 0.9981369352585002\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 147, train_loss = 1.4017912931740284, train_acc = 0.9981369352585002\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 148, train_loss = 1.3975938471267, train_acc = 0.9981369352585002\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 149, train_loss = 1.3931218571960926, train_acc = 0.9981369352585002\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 150, train_loss = 1.389257891685702, train_acc = 0.9981369352585002\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 151, train_loss = 1.3851356406812556, train_acc = 0.9981369352585002\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 152, train_loss = 1.3813892069156282, train_acc = 0.9981369352585002\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 153, train_loss = 1.3773728187079541, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 154, train_loss = 1.3734300844371319, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 155, train_loss = 1.3697755237226374, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 156, train_loss = 1.3659558805520646, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 157, train_loss = 1.3624544044141658, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 158, train_loss = 1.358784178912174, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 159, train_loss = 1.354971494525671, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 160, train_loss = 1.351529868959915, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 161, train_loss = 1.3482006192207336, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 162, train_loss = 1.3445065220003016, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 163, train_loss = 1.3416688268189318, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 164, train_loss = 1.338141467422247, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 165, train_loss = 1.3349717085366137, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 166, train_loss = 1.3316665453021415, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 167, train_loss = 1.328235914290417, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 168, train_loss = 1.325751256197691, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 169, train_loss = 1.322659098834265, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 170, train_loss = 1.3185513677890413, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 171, train_loss = 1.3161981515586376, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 172, train_loss = 1.3130891348118894, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 173, train_loss = 1.3100399250979535, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 174, train_loss = 1.307503778487444, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 175, train_loss = 1.3044042835826986, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 176, train_loss = 1.3016013440792449, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 177, train_loss = 1.2984004467725754, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 178, train_loss = 1.2955862047965638, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 179, train_loss = 1.2929543952341191, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 180, train_loss = 1.2898008835618384, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 181, train_loss = 1.2876879920368083, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 182, train_loss = 1.2850572019815445, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 183, train_loss = 1.282178606837988, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 184, train_loss = 1.2792645593290217, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 185, train_loss = 1.2769135075504892, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 186, train_loss = 1.2741558030247688, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 187, train_loss = 1.271915778517723, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 188, train_loss = 1.2691509847645648, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 189, train_loss = 1.2667372251744382, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 190, train_loss = 1.2649124513263814, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 191, train_loss = 1.2617753085796721, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 192, train_loss = 1.25939666852355, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 193, train_loss = 1.2571385924820788, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 194, train_loss = 1.2549549601972103, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 195, train_loss = 1.2524097301065922, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 196, train_loss = 1.2500733571941964, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 197, train_loss = 1.2483314163982868, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 198, train_loss = 1.2459602442686446, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 199, train_loss = 1.2439058435265906, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 200, train_loss = 1.2415000833570957, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 201, train_loss = 1.2390897174482234, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 202, train_loss = 1.2368609954719432, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 203, train_loss = 1.2344317808747292, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 204, train_loss = 1.2326092955772765, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 205, train_loss = 1.2306741935317405, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 206, train_loss = 1.2281830795109272, train_acc = 0.9981369352585002\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 207, train_loss = 1.2265262380242348, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 208, train_loss = 1.2243007309734821, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 209, train_loss = 1.2221700635855086, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 210, train_loss = 1.2197164222598076, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 211, train_loss = 1.2186298805172555, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 212, train_loss = 1.2162852573092096, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 213, train_loss = 1.2142208603327163, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 214, train_loss = 1.2120942014153115, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 215, train_loss = 1.210354634851683, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 216, train_loss = 1.2081744869356044, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 217, train_loss = 1.206978986680042, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 218, train_loss = 1.2045668003265746, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 219, train_loss = 1.2025996620650403, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 220, train_loss = 1.2005899784271605, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 221, train_loss = 1.1990201945300214, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 222, train_loss = 1.1966935048694722, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 223, train_loss = 1.1953392935101874, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 224, train_loss = 1.1932916293735616, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 225, train_loss = 1.191653134941589, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 226, train_loss = 1.1899532973766327, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 227, train_loss = 1.1881643260712735, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 228, train_loss = 1.1864104618434794, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 229, train_loss = 1.1846702732145786, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 230, train_loss = 1.1828751402790658, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 231, train_loss = 1.1811641988460906, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 232, train_loss = 1.1794971277122386, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 233, train_loss = 1.1777697739307769, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 234, train_loss = 1.1765620410442352, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 235, train_loss = 1.1748432430322282, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 236, train_loss = 1.1727436557412148, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 237, train_loss = 1.1714762337505817, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 238, train_loss = 1.1696905779535882, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 239, train_loss = 1.1680676068062894, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 240, train_loss = 1.1665998411481269, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 241, train_loss = 1.1649590134620667, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 242, train_loss = 1.1634763640468009, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 243, train_loss = 1.162214420735836, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 244, train_loss = 1.1600577210483607, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 245, train_loss = 1.158662104367977, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 246, train_loss = 1.1572979440388735, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 247, train_loss = 1.1556908687052783, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 248, train_loss = 1.1545256165263709, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 249, train_loss = 1.1529006138443947, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 250, train_loss = 1.1516302513482515, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 251, train_loss = 1.1499187499284744, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 252, train_loss = 1.1486387414333876, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 253, train_loss = 1.1465124959649984, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 254, train_loss = 1.145916839450365, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 255, train_loss = 1.1442408040165901, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 256, train_loss = 1.1429536516370717, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 257, train_loss = 1.1418073698878288, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 258, train_loss = 1.1400419883430004, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 259, train_loss = 1.1385739011166152, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 260, train_loss = 1.137404135108227, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 261, train_loss = 1.1363678698835429, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 262, train_loss = 1.1350693752465304, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 263, train_loss = 1.1334526451828424, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 264, train_loss = 1.132113728672266, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 265, train_loss = 1.1307070069015026, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 266, train_loss = 1.1299236739578191, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 267, train_loss = 1.128184894711012, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 268, train_loss = 1.1272867346706335, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 269, train_loss = 1.1253291132452432, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 270, train_loss = 1.1245719715952873, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 271, train_loss = 1.1232624339463655, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 272, train_loss = 1.1216922576131765, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 273, train_loss = 1.1209083596768323, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 274, train_loss = 1.1195708265004214, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 275, train_loss = 1.1179485768079758, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 276, train_loss = 1.1170297997596208, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 277, train_loss = 1.1159633683564607, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 278, train_loss = 1.1147049864230212, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 279, train_loss = 1.1135557716188487, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 280, train_loss = 1.1122606545686722, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 281, train_loss = 1.111023978650337, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 282, train_loss = 1.1099329205753747, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 283, train_loss = 1.1087752866151277, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 284, train_loss = 1.1076476275920868, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 285, train_loss = 1.1064593034388963, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 286, train_loss = 1.1052676526305731, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 287, train_loss = 1.1042908728122711, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 288, train_loss = 1.1028842305240687, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 289, train_loss = 1.1019062139093876, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 290, train_loss = 1.101051931589609, train_acc = 0.9981369352585002\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 291, train_loss = 1.09959919625544, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 292, train_loss = 1.098329166561598, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 293, train_loss = 1.0975048790278379, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 294, train_loss = 1.096760551125044, train_acc = 0.9981369352585002\n",
      "test Acc 0.9762569832402235:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 295, train_loss = 1.0953670268354472, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 296, train_loss = 1.0943967774510384, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 297, train_loss = 1.0933005089464132, train_acc = 0.9981369352585002\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 298, train_loss = 1.0922819500265177, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 299, train_loss = 1.0911235846579075, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 300, train_loss = 1.0903192485275213, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 301, train_loss = 1.0891324716212694, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 302, train_loss = 1.088162654399639, train_acc = 0.9981369352585002\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 303, train_loss = 1.087102960795164, train_acc = 0.9981369352585002\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 304, train_loss = 1.0860695528390352, train_acc = 0.9981369352585002\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 305, train_loss = 1.0853380473854486, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 306, train_loss = 1.0840520473720971, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 307, train_loss = 1.0830522825417574, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 308, train_loss = 1.0818775544466916, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 309, train_loss = 1.0811377950012684, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 310, train_loss = 1.0798481330275536, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 311, train_loss = 1.0791632992622908, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 312, train_loss = 1.0779453764262144, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 313, train_loss = 1.0772980712354183, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 314, train_loss = 1.075828599423403, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 315, train_loss = 1.0754170678555965, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 316, train_loss = 1.0740819560887758, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 317, train_loss = 1.0733210394682828, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 318, train_loss = 1.0722699649631977, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 319, train_loss = 1.0712755607964937, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 320, train_loss = 1.0702589713037014, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 321, train_loss = 1.0695747931895312, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 322, train_loss = 1.0683155829610769, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 323, train_loss = 1.068060110002989, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 324, train_loss = 1.0666728168725967, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 325, train_loss = 1.06573124229908, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 326, train_loss = 1.0650148602726404, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 327, train_loss = 1.063821405172348, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 328, train_loss = 1.0630134120583534, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 329, train_loss = 1.0621955481765326, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 330, train_loss = 1.0614574924111366, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 331, train_loss = 1.0605267075297888, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 332, train_loss = 1.0598116939363535, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 333, train_loss = 1.05889493227005, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 334, train_loss = 1.0579259681107942, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 335, train_loss = 1.0569479068217333, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 336, train_loss = 1.056365691125393, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 337, train_loss = 1.0553043869731482, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 338, train_loss = 1.0542948469519615, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 339, train_loss = 1.0532740863563959, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 340, train_loss = 1.0530398736300413, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 341, train_loss = 1.0516714838740882, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 342, train_loss = 1.0508214980363846, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 343, train_loss = 1.0501821699144784, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 344, train_loss = 1.049509468168253, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 345, train_loss = 1.0483973970112856, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 346, train_loss = 1.0475857183337212, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 347, train_loss = 1.0467404102382716, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 348, train_loss = 1.0459584991040174, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 349, train_loss = 1.0451594976184424, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 350, train_loss = 1.044618334621191, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 351, train_loss = 1.0436031383869704, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 352, train_loss = 1.0428118618729059, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 353, train_loss = 1.0421399685146753, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 354, train_loss = 1.0413264570233878, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 355, train_loss = 1.0403012248279992, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 356, train_loss = 1.0397472331824247, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 357, train_loss = 1.0391802377998829, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 358, train_loss = 1.0383050069212914, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 359, train_loss = 1.0375288985669613, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 360, train_loss = 1.0363746633229312, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 361, train_loss = 1.0357480707170907, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 362, train_loss = 1.0349826999008656, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 363, train_loss = 1.0343909449875355, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 364, train_loss = 1.0336346961557865, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 365, train_loss = 1.0327679639158305, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 366, train_loss = 1.0322273286583368, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 367, train_loss = 1.0310832237300929, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 368, train_loss = 1.0304983059468213, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 369, train_loss = 1.0299819509091321, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 370, train_loss = 1.0291431161167566, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 371, train_loss = 1.0283003710210323, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 372, train_loss = 1.0278969047067221, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 373, train_loss = 1.0267076355812605, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 374, train_loss = 1.0263585547509138, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 375, train_loss = 1.0255144350230694, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 376, train_loss = 1.0249612517654896, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 377, train_loss = 1.0242631720902864, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 378, train_loss = 1.0234619739057962, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 379, train_loss = 1.022703596710926, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 380, train_loss = 1.0221203789114952, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 381, train_loss = 1.0213576344249304, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 382, train_loss = 1.0203717040421907, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 383, train_loss = 1.0199646341206972, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 384, train_loss = 1.0193918161094189, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 385, train_loss = 1.0186766758561134, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 386, train_loss = 1.0178903055784758, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 387, train_loss = 1.0173150040209293, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 388, train_loss = 1.0163545024988707, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 389, train_loss = 1.0159226953983307, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 390, train_loss = 1.015314593911171, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 391, train_loss = 1.0145889868435916, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 392, train_loss = 1.013849426060915, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 393, train_loss = 1.0131270115671214, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 394, train_loss = 1.012978419661522, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 395, train_loss = 1.0119306618871633, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 396, train_loss = 1.0111072522995528, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 397, train_loss = 1.010828291386133, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 398, train_loss = 1.0101773676869925, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 399, train_loss = 1.0093040565552656, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 400, train_loss = 1.0085680907068308, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 401, train_loss = 1.0078758175077382, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 402, train_loss = 1.0073741252126638, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 403, train_loss = 1.0069599064590875, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 404, train_loss = 1.0061765983700752, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 405, train_loss = 1.0055083148181438, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 406, train_loss = 1.004702347010607, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 407, train_loss = 1.0045445449650288, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 408, train_loss = 1.0037508594541578, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 409, train_loss = 1.0032030865550041, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 410, train_loss = 1.0023398026823997, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 411, train_loss = 1.0019931010901928, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 412, train_loss = 1.001485792294261, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 413, train_loss = 1.0007862187922, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 414, train_loss = 0.9998721145093441, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 415, train_loss = 0.9994286460132571, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 416, train_loss = 0.9987381920218468, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 417, train_loss = 0.9982126603572397, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 418, train_loss = 0.9976633501501055, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 419, train_loss = 0.9969463671295671, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 420, train_loss = 0.996462291732314, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 421, train_loss = 0.9955439008772373, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 422, train_loss = 0.9954634979367256, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 423, train_loss = 0.9949019861669512, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 424, train_loss = 0.9943085089325905, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 425, train_loss = 0.9934193616063567, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 426, train_loss = 0.9928565534501104, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 427, train_loss = 0.9925731172115775, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 428, train_loss = 0.9917662814259529, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 429, train_loss = 0.9914656020700932, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 430, train_loss = 0.9905160553753376, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 431, train_loss = 0.9900606734008761, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 432, train_loss = 0.9894937326462241, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 433, train_loss = 0.9890069216489792, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 434, train_loss = 0.9884047197847394, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 435, train_loss = 0.9875104439706774, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 436, train_loss = 0.987318828701973, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 437, train_loss = 0.9870013395993738, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 438, train_loss = 0.9860433799476596, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 439, train_loss = 0.9859473245887784, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 440, train_loss = 0.9852167020289926, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 441, train_loss = 0.9847859243600396, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 442, train_loss = 0.9835717491805553, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 443, train_loss = 0.9835333861410618, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 444, train_loss = 0.983184405908105, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 445, train_loss = 0.9826679254620103, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 446, train_loss = 0.981956506773713, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 447, train_loss = 0.9815739206969738, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 448, train_loss = 0.9806800559163094, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 449, train_loss = 0.9803753085434437, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 450, train_loss = 0.9795751633791951, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 451, train_loss = 0.9794602480978938, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 452, train_loss = 0.9785601620824309, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 453, train_loss = 0.9777655924408464, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 454, train_loss = 0.9781461283564568, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 455, train_loss = 0.9769475944340229, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 456, train_loss = 0.9767306769936113, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 457, train_loss = 0.9762947373092175, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 458, train_loss = 0.9757502861320972, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 459, train_loss = 0.9750849877746077, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 460, train_loss = 0.974791004016879, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 461, train_loss = 0.973761823028326, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 462, train_loss = 0.9736636616289616, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 463, train_loss = 0.9730023791344138, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 464, train_loss = 0.9728299155831337, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 465, train_loss = 0.9721105011849431, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 466, train_loss = 0.97145760555577, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 467, train_loss = 0.9712383809237508, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 468, train_loss = 0.9707932484598132, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 469, train_loss = 0.9699561446905136, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 470, train_loss = 0.9698882885277271, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 471, train_loss = 0.9693775847554207, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 472, train_loss = 0.9681934329419164, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 473, train_loss = 0.9681959338486195, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 474, train_loss = 0.9676299343555002, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 475, train_loss = 0.9670136136264773, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 476, train_loss = 0.9667881801724434, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 477, train_loss = 0.9661102605314227, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 478, train_loss = 0.9657821146101924, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 479, train_loss = 0.9656161442399025, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 480, train_loss = 0.9642485976219177, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 481, train_loss = 0.9646701849997044, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 482, train_loss = 0.9636849338858156, train_acc = 0.9981369352585002\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 483, train_loss = 0.9635944428591756, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 484, train_loss = 0.9629764010460349, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 485, train_loss = 0.9626751691102982, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 486, train_loss = 0.9618053523154231, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 487, train_loss = 0.9617577667086152, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 488, train_loss = 0.960964730635169, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 489, train_loss = 0.9606129229068756, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 490, train_loss = 0.9599692337214947, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 491, train_loss = 0.9598797845392255, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 492, train_loss = 0.9588559257535962, train_acc = 0.9981369352585002\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 493, train_loss = 0.9588297680020332, train_acc = 0.9981369352585002\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 494, train_loss = 0.9585175079555484, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 495, train_loss = 0.9573896303772926, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 496, train_loss = 0.9574079985468416, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 497, train_loss = 0.9566787270159693, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 498, train_loss = 0.9565595661551924, train_acc = 0.9981369352585002\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 499, train_loss = 0.9560080033988925, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████▌                                                          | 6/30 [59:28<3:58:05, 595.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "7th- epoch: 0, train_loss = 130.6896826326847, train_acc = 0.7472054028877504\n",
      "test Acc 0.8691806331471136:\n",
      "7th- epoch: 1, train_loss = 53.300356052815914, train_acc = 0.8874010246856078\n",
      "test Acc 0.909217877094972:\n",
      "7th- epoch: 2, train_loss = 37.77710651233792, train_acc = 0.9208197484862599\n",
      "test Acc 0.930633147113594:\n",
      "7th- epoch: 3, train_loss = 29.93952849879861, train_acc = 0.9385188635305077\n",
      "test Acc 0.9376163873370578:\n",
      "7th- epoch: 4, train_loss = 25.08260739967227, train_acc = 0.9492314857941313\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 5, train_loss = 21.709920037537813, train_acc = 0.9581974848625989\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 6, train_loss = 19.20861315354705, train_acc = 0.9628551467163484\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 7, train_loss = 17.262689059600234, train_acc = 0.9664648346530041\n",
      "test Acc 0.9534450651769087:\n",
      "7th- epoch: 8, train_loss = 15.697431357577443, train_acc = 0.9699580810433163\n",
      "test Acc 0.9562383612662942:\n",
      "7th- epoch: 9, train_loss = 14.395340399816632, train_acc = 0.9725197950628784\n",
      "test Acc 0.9567039106145251:\n",
      "7th- epoch: 10, train_loss = 13.286740254610777, train_acc = 0.9748486259897532\n",
      "test Acc 0.9590316573556797:\n",
      "7th- epoch: 11, train_loss = 12.32712215743959, train_acc = 0.9767116907312529\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 12, train_loss = 11.485544070601463, train_acc = 0.9775267815556591\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 13, train_loss = 10.751161754131317, train_acc = 0.9790405216581276\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 14, train_loss = 10.092093657702208, train_acc = 0.9805542617605962\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 15, train_loss = 9.504778218455613, train_acc = 0.9814857941313461\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 16, train_loss = 8.969589686021209, train_acc = 0.9825337680484397\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 17, train_loss = 8.48776673618704, train_acc = 0.983698183511877\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 18, train_loss = 8.049060647375882, train_acc = 0.9848625989753144\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 19, train_loss = 7.650780761614442, train_acc = 0.9861434559850955\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 20, train_loss = 7.284065016545355, train_acc = 0.9868421052631579\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 21, train_loss = 6.9515108885243535, train_acc = 0.9876571960875641\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 22, train_loss = 6.642792782746255, train_acc = 0.9883558453656265\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 23, train_loss = 6.362097281031311, train_acc = 0.9891709361900326\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 24, train_loss = 6.103417127393186, train_acc = 0.989869585468095\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 25, train_loss = 5.867359549738467, train_acc = 0.9902189101071263\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 26, train_loss = 5.649371707811952, train_acc = 0.990801117838845\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 27, train_loss = 5.4458454782143235, train_acc = 0.9910340009315324\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 28, train_loss = 5.259816936217248, train_acc = 0.9911504424778761\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 29, train_loss = 5.085999391973019, train_acc = 0.9914997671169073\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 30, train_loss = 4.925333634018898, train_acc = 0.9918490917559385\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 31, train_loss = 4.77425932418555, train_acc = 0.9918490917559385\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 32, train_loss = 4.634885963052511, train_acc = 0.992081974848626\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 33, train_loss = 4.503021669574082, train_acc = 0.9923148579413135\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 34, train_loss = 4.380886222235858, train_acc = 0.9923148579413135\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 35, train_loss = 4.264912202954292, train_acc = 0.9927806241266884\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 36, train_loss = 4.156903248280287, train_acc = 0.9932463903120633\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 37, train_loss = 4.053400167264044, train_acc = 0.9933628318584071\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 38, train_loss = 3.9563756622374058, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 39, train_loss = 3.864515050314367, train_acc = 0.9940614811364695\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 40, train_loss = 3.7768917456269264, train_acc = 0.9941779226828132\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 41, train_loss = 3.6945047066546977, train_acc = 0.9941779226828132\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 42, train_loss = 3.6156956679187715, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 43, train_loss = 3.5417643054388463, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 44, train_loss = 3.470339494291693, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 45, train_loss = 3.4023771011270583, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 46, train_loss = 3.3373567587696016, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 47, train_loss = 3.2745396099053323, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 48, train_loss = 3.214570401702076, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 49, train_loss = 3.1579026081599295, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 50, train_loss = 3.102279060985893, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 51, train_loss = 3.0489176511764526, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 52, train_loss = 3.0003992430865765, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 53, train_loss = 2.951591521501541, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 54, train_loss = 2.906695444136858, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 55, train_loss = 2.8634162223897874, train_acc = 0.9954587796925943\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 56, train_loss = 2.8197425976395607, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 57, train_loss = 2.781790193170309, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 58, train_loss = 2.7405517757870257, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 59, train_loss = 2.7049250206910074, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 60, train_loss = 2.6678237444721162, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 61, train_loss = 2.6323688738048077, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 62, train_loss = 2.5992176732979715, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 63, train_loss = 2.566982144024223, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 64, train_loss = 2.5353136458434165, train_acc = 0.9956916627852818\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 65, train_loss = 2.5051911459304392, train_acc = 0.995575221238938\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 66, train_loss = 2.4752430231310427, train_acc = 0.995575221238938\n",
      "test Acc 0.9776536312849162:\n",
      "7th- epoch: 67, train_loss = 2.4468897208571434, train_acc = 0.9956916627852818\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 68, train_loss = 2.4194591441191733, train_acc = 0.9958081043316255\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 69, train_loss = 2.3929644734598696, train_acc = 0.9958081043316255\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 70, train_loss = 2.367434927728027, train_acc = 0.9958081043316255\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 71, train_loss = 2.3417973197065294, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 72, train_loss = 2.317180161830038, train_acc = 0.9959245458779693\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 73, train_loss = 2.2940047420561314, train_acc = 0.9961574289706567\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 74, train_loss = 2.271606133785099, train_acc = 0.9961574289706567\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 75, train_loss = 2.249053616076708, train_acc = 0.9962738705170004\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 76, train_loss = 2.2267410359345376, train_acc = 0.9963903120633442\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 77, train_loss = 2.2071846066974103, train_acc = 0.996506753609688\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 78, train_loss = 2.1870452612638474, train_acc = 0.996506753609688\n",
      "test Acc 0.9776536312849162:\n",
      "7th- epoch: 79, train_loss = 2.167038582265377, train_acc = 0.996506753609688\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 80, train_loss = 2.14768477762118, train_acc = 0.996506753609688\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 81, train_loss = 2.1299891234375536, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 82, train_loss = 2.1119068660773337, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 83, train_loss = 2.0944238465745, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 84, train_loss = 2.077380819944665, train_acc = 0.9966231951560317\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 85, train_loss = 2.060573247494176, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 86, train_loss = 2.044649763731286, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 87, train_loss = 2.0293265704531223, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 88, train_loss = 2.013834848999977, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 89, train_loss = 1.998592858435586, train_acc = 0.9967396367023754\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 90, train_loss = 1.9834746320266277, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 91, train_loss = 1.9698077279608697, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 92, train_loss = 1.9558277316391468, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 93, train_loss = 1.9415166638791561, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 94, train_loss = 1.92837014910765, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 95, train_loss = 1.9159915212076157, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 96, train_loss = 1.9030062668025494, train_acc = 0.9968560782487191\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 97, train_loss = 1.8911275565624237, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 98, train_loss = 1.8798242148477584, train_acc = 0.9968560782487191\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 99, train_loss = 1.8678604438900948, train_acc = 0.9969725197950629\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 100, train_loss = 1.8558688771445304, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 101, train_loss = 1.845928906230256, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 102, train_loss = 1.8343481682240963, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 103, train_loss = 1.8244070510845631, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 104, train_loss = 1.8137810577172786, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 105, train_loss = 1.8031752903480083, train_acc = 0.9972054028877504\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 106, train_loss = 1.7933775559067726, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 107, train_loss = 1.7843379590194672, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 108, train_loss = 1.7743035953026265, train_acc = 0.9970889613414066\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 109, train_loss = 1.7654961433727294, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 110, train_loss = 1.756072636693716, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 111, train_loss = 1.7467776152770966, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 112, train_loss = 1.7384321528952569, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 113, train_loss = 1.729913716437295, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 114, train_loss = 1.7211187880020589, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 115, train_loss = 1.7132493890821934, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 116, train_loss = 1.7055400747340173, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 117, train_loss = 1.696828618645668, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 118, train_loss = 1.6893695543985814, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 119, train_loss = 1.681499969214201, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 120, train_loss = 1.6739893816411495, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 121, train_loss = 1.6671906523406506, train_acc = 0.9970889613414066\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 122, train_loss = 1.659399438649416, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 123, train_loss = 1.6524947385769337, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 124, train_loss = 1.6453075397294015, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 125, train_loss = 1.6384878668468446, train_acc = 0.9970889613414066\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 126, train_loss = 1.6315732647199184, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 127, train_loss = 1.6251180842518806, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 128, train_loss = 1.6183532390277833, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 129, train_loss = 1.6118425093591213, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 130, train_loss = 1.6063361603301018, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 131, train_loss = 1.5992476393003017, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 132, train_loss = 1.5937017661053687, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 133, train_loss = 1.587076800642535, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 134, train_loss = 1.5819112434983253, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 135, train_loss = 1.5755050543230027, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 136, train_loss = 1.5700031879823655, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 137, train_loss = 1.5646199274342507, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 138, train_loss = 1.5591325784334913, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 139, train_loss = 1.5529751653084531, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 140, train_loss = 1.5476080439984798, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 141, train_loss = 1.5423877959838137, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 142, train_loss = 1.5365986116230488, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 143, train_loss = 1.5315395084908232, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 144, train_loss = 1.5257546355715021, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 145, train_loss = 1.520790739567019, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 146, train_loss = 1.5154321814188734, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 147, train_loss = 1.510573111474514, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 148, train_loss = 1.5055828405311331, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 149, train_loss = 1.5008986989269033, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 150, train_loss = 1.4962416788330302, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 151, train_loss = 1.4912759339204058, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 152, train_loss = 1.4869877422461286, train_acc = 0.9972054028877504\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 153, train_loss = 1.482096552848816, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 154, train_loss = 1.477939359843731, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 155, train_loss = 1.4732552418718114, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 156, train_loss = 1.469434286118485, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 157, train_loss = 1.46480017027352, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 158, train_loss = 1.4608377715339884, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 159, train_loss = 1.4561683610081673, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 160, train_loss = 1.4529541209340096, train_acc = 0.9972054028877504\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 161, train_loss = 1.4480506019899622, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 162, train_loss = 1.4442626411328092, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 163, train_loss = 1.4400134856114164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 164, train_loss = 1.4366851337254047, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 165, train_loss = 1.4317004220793024, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 166, train_loss = 1.4286182522773743, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 167, train_loss = 1.4244477363536134, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 168, train_loss = 1.4208187237381935, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 169, train_loss = 1.4166870439657941, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 170, train_loss = 1.4137222915887833, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 171, train_loss = 1.4096279056975618, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 172, train_loss = 1.4060913746943697, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 173, train_loss = 1.4022770561277866, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 174, train_loss = 1.3992703631520271, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 175, train_loss = 1.3951167613267899, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 176, train_loss = 1.3921807445585728, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 177, train_loss = 1.3886379724135622, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 178, train_loss = 1.3853321796050295, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 179, train_loss = 1.3820885308086872, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 180, train_loss = 1.3785681599983945, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 181, train_loss = 1.3756556200096384, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 182, train_loss = 1.3718863079557195, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 183, train_loss = 1.36968683952, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 184, train_loss = 1.3658637218177319, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 185, train_loss = 1.3626047422876582, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 186, train_loss = 1.3598911439767107, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 187, train_loss = 1.3569391878554597, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 188, train_loss = 1.353767933906056, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 189, train_loss = 1.3512825208017603, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 190, train_loss = 1.347823116928339, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 191, train_loss = 1.3451829614350572, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 192, train_loss = 1.342088001430966, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 193, train_loss = 1.3395691191544756, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 194, train_loss = 1.3367637371411547, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 195, train_loss = 1.3335637984564528, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 196, train_loss = 1.3306552147259936, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 197, train_loss = 1.3290330866584554, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 198, train_loss = 1.3255043340614066, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 199, train_loss = 1.322908135713078, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 200, train_loss = 1.3205504963407293, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 201, train_loss = 1.3179342932999134, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 202, train_loss = 1.3151213402161375, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 203, train_loss = 1.313063483685255, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 204, train_loss = 1.3100517255952582, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 205, train_loss = 1.307578063220717, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 206, train_loss = 1.3053209310164675, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 207, train_loss = 1.3029961002757773, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 208, train_loss = 1.3002677833428606, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 209, train_loss = 1.2976199513068423, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 210, train_loss = 1.2956158133456483, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 211, train_loss = 1.2929656952619553, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 212, train_loss = 1.2907413356006145, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 213, train_loss = 1.2888007698347792, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 214, train_loss = 1.285938460379839, train_acc = 0.9973218444340941\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 215, train_loss = 1.2838278412818909, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 216, train_loss = 1.2815417560050264, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 217, train_loss = 1.279218920855783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 218, train_loss = 1.277511882246472, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 219, train_loss = 1.2746355620911345, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 220, train_loss = 1.2724448317894712, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 221, train_loss = 1.2703176451614127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 222, train_loss = 1.2678257301449776, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 223, train_loss = 1.2659246722469106, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 224, train_loss = 1.263829750358127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 225, train_loss = 1.2616521766176447, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 226, train_loss = 1.2595245502889156, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 227, train_loss = 1.2573709624120966, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 228, train_loss = 1.2558137340238318, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 229, train_loss = 1.253300216048956, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 230, train_loss = 1.251449752599001, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 231, train_loss = 1.2492698890855536, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 232, train_loss = 1.2475759945809841, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 233, train_loss = 1.2453417964279652, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 234, train_loss = 1.243055765866302, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 235, train_loss = 1.2419134763185866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 236, train_loss = 1.2395223143394105, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 237, train_loss = 1.2375454592402093, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 238, train_loss = 1.2355517074465752, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 239, train_loss = 1.233638297766447, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 240, train_loss = 1.2321275025606155, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 241, train_loss = 1.2299002322251908, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 242, train_loss = 1.228390449017752, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 243, train_loss = 1.226462913036812, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 244, train_loss = 1.2246879476006143, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 245, train_loss = 1.223373968154192, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 246, train_loss = 1.22090507671237, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 247, train_loss = 1.21948516741395, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 248, train_loss = 1.2173347920179367, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 249, train_loss = 1.216351430863142, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 250, train_loss = 1.2138391571934335, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 251, train_loss = 1.2123948385124095, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 252, train_loss = 1.210779091983568, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 253, train_loss = 1.2093495701556094, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 254, train_loss = 1.207131128758192, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 255, train_loss = 1.2060633723740466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 256, train_loss = 1.2040453689987771, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 257, train_loss = 1.2026796527206898, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 258, train_loss = 1.20061593252467, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 259, train_loss = 1.1989220778341405, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 260, train_loss = 1.1976257872884162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 261, train_loss = 1.1959273790125735, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 262, train_loss = 1.194692759483587, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 263, train_loss = 1.1930730938911438, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 264, train_loss = 1.1911627451772802, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 265, train_loss = 1.1892172333900817, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 266, train_loss = 1.1883337150211446, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 267, train_loss = 1.1862342630629428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 268, train_loss = 1.1848068994586356, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 269, train_loss = 1.1830477465991862, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 270, train_loss = 1.1819713550503366, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 271, train_loss = 1.1800757547025569, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 272, train_loss = 1.178081898659002, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 273, train_loss = 1.1771201640367508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 274, train_loss = 1.1762860615854152, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 275, train_loss = 1.1741114768083207, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 276, train_loss = 1.1725717683439143, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 277, train_loss = 1.1712145048077218, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 278, train_loss = 1.1697119909222238, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 279, train_loss = 1.168838731944561, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 280, train_loss = 1.167091652750969, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 281, train_loss = 1.1656185872852802, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 282, train_loss = 1.164223201572895, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 283, train_loss = 1.162959783046972, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 284, train_loss = 1.1615905898506753, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 285, train_loss = 1.160511436581146, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 286, train_loss = 1.1586462284321897, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 287, train_loss = 1.157372670888435, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 288, train_loss = 1.1558937231893651, train_acc = 0.9979040521658128\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 289, train_loss = 1.1548961214721203, train_acc = 0.9979040521658128\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 290, train_loss = 1.153972948610317, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 291, train_loss = 1.1521103419363499, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 292, train_loss = 1.150501060008537, train_acc = 0.9979040521658128\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 293, train_loss = 1.149504665285349, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 294, train_loss = 1.1485697142779827, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 295, train_loss = 1.1468178555369377, train_acc = 0.9979040521658128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 296, train_loss = 1.1454719143803231, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 297, train_loss = 1.1442581477458589, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 298, train_loss = 1.1428947212989442, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 299, train_loss = 1.141693014651537, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 300, train_loss = 1.1395873266155832, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 301, train_loss = 1.1386179749970324, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 302, train_loss = 1.137072067707777, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 303, train_loss = 1.1361490090494044, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 304, train_loss = 1.1344769683782943, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 305, train_loss = 1.1331403205986135, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 306, train_loss = 1.1319885377888568, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 307, train_loss = 1.130745779722929, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 308, train_loss = 1.1294487503473647, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 309, train_loss = 1.1281317819957621, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 310, train_loss = 1.1270353819127195, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 311, train_loss = 1.1261557464604266, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 312, train_loss = 1.1246948192710988, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 313, train_loss = 1.123170102655422, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 314, train_loss = 1.1221076573128812, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 315, train_loss = 1.1210803811554797, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 316, train_loss = 1.1198937433655374, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 317, train_loss = 1.1192539185285568, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 318, train_loss = 1.117891900241375, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 319, train_loss = 1.1163571812212467, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 320, train_loss = 1.1153220124542713, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 321, train_loss = 1.114506748795975, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 322, train_loss = 1.113066750287544, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 323, train_loss = 1.1123640934820287, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 324, train_loss = 1.111114040017128, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 325, train_loss = 1.109676708758343, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 326, train_loss = 1.108799657493364, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 327, train_loss = 1.1077073626220226, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 328, train_loss = 1.1069095867569558, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 329, train_loss = 1.1057433697278611, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 330, train_loss = 1.1047128066420555, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 331, train_loss = 1.1035567944054492, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 332, train_loss = 1.1029995270073414, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 333, train_loss = 1.1015945498947985, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 334, train_loss = 1.100503322959412, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 335, train_loss = 1.0994466568226926, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 336, train_loss = 1.0985198740963824, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 337, train_loss = 1.09779242426157, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 338, train_loss = 1.0965054966509342, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 339, train_loss = 1.0956426833872683, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 340, train_loss = 1.0946410484611988, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 341, train_loss = 1.0940235282178037, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 342, train_loss = 1.092549453198444, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 343, train_loss = 1.0919198927585967, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 344, train_loss = 1.0908986628055573, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 345, train_loss = 1.089770719408989, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 346, train_loss = 1.0887733064591885, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 347, train_loss = 1.0877804408664815, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 348, train_loss = 1.0870098558370955, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 349, train_loss = 1.0862737347488292, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 350, train_loss = 1.085093171626795, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 351, train_loss = 1.08441947522806, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 352, train_loss = 1.083215308666695, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 353, train_loss = 1.0827510431408882, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 354, train_loss = 1.0813525232370012, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 355, train_loss = 1.0805552217061631, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 356, train_loss = 1.079789325594902, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 357, train_loss = 1.0786319536273368, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 358, train_loss = 1.0779106194968335, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 359, train_loss = 1.0769539822940715, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 360, train_loss = 1.0760384078021161, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 361, train_loss = 1.0752038185601123, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 362, train_loss = 1.0742752713267691, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 363, train_loss = 1.0732485030894168, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 364, train_loss = 1.0729108527302742, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 365, train_loss = 1.0717592984437943, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 366, train_loss = 1.0709237356786616, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 367, train_loss = 1.070012814074289, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 368, train_loss = 1.0690580196678638, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 369, train_loss = 1.0680693226750009, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 370, train_loss = 1.067549854516983, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 371, train_loss = 1.066757120192051, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 372, train_loss = 1.0656383273308165, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 373, train_loss = 1.0649430665071122, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 374, train_loss = 1.0641514261369593, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 375, train_loss = 1.0631052615935914, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 376, train_loss = 1.0624887545709498, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 377, train_loss = 1.0615598310832866, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 378, train_loss = 1.0610822376911528, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 379, train_loss = 1.0595559130306356, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 380, train_loss = 1.059266670315992, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 381, train_loss = 1.0585561084444635, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 382, train_loss = 1.0577008153195493, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 383, train_loss = 1.0568197195534594, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 384, train_loss = 1.0559723314945586, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 385, train_loss = 1.0551335488562472, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 386, train_loss = 1.0547271445393562, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 387, train_loss = 1.053476912289625, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 388, train_loss = 1.0527797738614026, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 389, train_loss = 1.0521614452300128, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 390, train_loss = 1.051468184828991, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 391, train_loss = 1.0505281624791678, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 392, train_loss = 1.0500159598886967, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 393, train_loss = 1.0489843698742334, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 394, train_loss = 1.0484596652386244, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 395, train_loss = 1.0476647056639194, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 396, train_loss = 1.046768403291935, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 397, train_loss = 1.0458080346288625, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 398, train_loss = 1.0454344165918883, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 399, train_loss = 1.0447786425647791, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 400, train_loss = 1.0439063074591104, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 401, train_loss = 1.0432290372846182, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 402, train_loss = 1.0422366323473398, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 403, train_loss = 1.0418051543238107, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 404, train_loss = 1.0409420231881086, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 405, train_loss = 1.039979179709917, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 406, train_loss = 1.0394663164915983, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 407, train_loss = 1.0386477460560855, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 408, train_loss = 1.0378702034649905, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 409, train_loss = 1.0373755010368768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 410, train_loss = 1.0363808522524778, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 411, train_loss = 1.0357698537409306, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 412, train_loss = 1.034731446445221, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 413, train_loss = 1.0342357767221984, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 414, train_loss = 1.0335421226918697, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 415, train_loss = 1.0330452682974283, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 416, train_loss = 1.0321836794319097, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 417, train_loss = 1.0312887293694075, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 418, train_loss = 1.030831536889309, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 419, train_loss = 1.0301565540430602, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 420, train_loss = 1.029254854976898, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 421, train_loss = 1.0286588321032468, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 422, train_loss = 1.0279790175554808, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 423, train_loss = 1.0272940509021282, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 424, train_loss = 1.0264919884502888, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 425, train_loss = 1.0262575869855937, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "7th- epoch: 426, train_loss = 1.0251755180361215, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 427, train_loss = 1.0249557743372861, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 428, train_loss = 1.0238049017789308, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 429, train_loss = 1.0232134138641413, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 430, train_loss = 1.0226545607147273, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 431, train_loss = 1.0217966487107333, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 432, train_loss = 1.0214208786783274, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 433, train_loss = 1.0203565992414951, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 434, train_loss = 1.020086376607651, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 435, train_loss = 1.0192518569529057, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 436, train_loss = 1.018525242805481, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 437, train_loss = 1.0181771330535412, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 438, train_loss = 1.0172591308655683, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 439, train_loss = 1.0169908913376275, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 440, train_loss = 1.0155370322463568, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 441, train_loss = 1.0154204505088273, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 442, train_loss = 1.0147235728800297, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 443, train_loss = 1.0139885718526784, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 444, train_loss = 1.013663181423908, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 445, train_loss = 1.01259826371097, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 446, train_loss = 1.0122396163642406, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 447, train_loss = 1.011437720299, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 448, train_loss = 1.0107593213615473, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 449, train_loss = 1.0104109980165958, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 450, train_loss = 1.0095544196665287, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 451, train_loss = 1.0090011445281561, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 452, train_loss = 1.0082944383320864, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 453, train_loss = 1.007753349840641, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 454, train_loss = 1.0070776380598545, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 455, train_loss = 1.006586636096472, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 456, train_loss = 1.006049898773199, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 457, train_loss = 1.0048718017933425, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 458, train_loss = 1.0046697916986886, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 459, train_loss = 1.0041121827962343, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 460, train_loss = 1.0029910293815192, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 461, train_loss = 1.0026100538671017, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 462, train_loss = 1.0019659561512526, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 463, train_loss = 1.001209275185829, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 464, train_loss = 1.000629240035778, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 465, train_loss = 1.0001848352549132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 466, train_loss = 0.999139921128517, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 467, train_loss = 0.9988144809904043, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 468, train_loss = 0.9982529232802335, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 469, train_loss = 0.9974778182804585, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 470, train_loss = 0.9970356250705663, train_acc = 0.9979040521658128\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 471, train_loss = 0.9963018906710204, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 472, train_loss = 0.9960166054370347, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 473, train_loss = 0.9955753944814205, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 474, train_loss = 0.9949040524661541, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 475, train_loss = 0.99440011754632, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 476, train_loss = 0.9934460818767548, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 477, train_loss = 0.99321630349732, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 478, train_loss = 0.9925399211642798, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 479, train_loss = 0.9921112172305584, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 480, train_loss = 0.9915589615702629, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 481, train_loss = 0.9911181467177812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 482, train_loss = 0.9903279803693295, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 483, train_loss = 0.9897131199541036, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 484, train_loss = 0.9891870108840521, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 485, train_loss = 0.98865101361298, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 486, train_loss = 0.9881630875170231, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 487, train_loss = 0.9876485404965933, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 488, train_loss = 0.9869332313537598, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 489, train_loss = 0.9866917058825493, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 490, train_loss = 0.986206474393839, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 491, train_loss = 0.9853271072206553, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 492, train_loss = 0.9849818609654903, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 493, train_loss = 0.9843540489673615, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 494, train_loss = 0.9839713374676649, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 495, train_loss = 0.9834087751805782, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 496, train_loss = 0.9829850693640765, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 497, train_loss = 0.9824853775498923, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 498, train_loss = 0.9818394780158997, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 499, train_loss = 0.9812327958643436, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|████████████████▌                                                      | 7/30 [1:09:31<3:49:00, 597.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "8th- epoch: 0, train_loss = 139.13524037599564, train_acc = 0.7424312994876572\n",
      "test Acc 0.8645251396648045:\n",
      "8th- epoch: 1, train_loss = 53.41073361411691, train_acc = 0.8872845831392641\n",
      "test Acc 0.9068901303538175:\n",
      "8th- epoch: 2, train_loss = 38.439810164272785, train_acc = 0.9184909175593852\n",
      "test Acc 0.9283054003724395:\n",
      "8th- epoch: 3, train_loss = 30.718181427568197, train_acc = 0.9373544480670704\n",
      "test Acc 0.9380819366852886:\n",
      "8th- epoch: 4, train_loss = 25.766608955338597, train_acc = 0.9471355379599441\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 5, train_loss = 22.255240177735686, train_acc = 0.9547042384722869\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 6, train_loss = 19.629870420321822, train_acc = 0.9609920819748486\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 7, train_loss = 17.58880179747939, train_acc = 0.9657661853749417\n",
      "test Acc 0.952048417132216:\n",
      "8th- epoch: 8, train_loss = 15.923979457467794, train_acc = 0.9689101071262226\n",
      "test Acc 0.9534450651769087:\n",
      "8th- epoch: 9, train_loss = 14.530041759833694, train_acc = 0.9724033535165347\n",
      "test Acc 0.9557728119180633:\n",
      "8th- epoch: 10, train_loss = 13.358713642694056, train_acc = 0.9739170936190032\n",
      "test Acc 0.9585661080074488:\n",
      "8th- epoch: 11, train_loss = 12.351987050846219, train_acc = 0.9769445738239404\n",
      "test Acc 0.9594972067039106:\n",
      "8th- epoch: 12, train_loss = 11.473882971331477, train_acc = 0.9785747554727526\n",
      "test Acc 0.9594972067039106:\n",
      "8th- epoch: 13, train_loss = 10.700660740025342, train_acc = 0.9790405216581276\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 14, train_loss = 10.022133030928671, train_acc = 0.9803213786679087\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 15, train_loss = 9.416797146201134, train_acc = 0.9817186772240335\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 16, train_loss = 8.87871330510825, train_acc = 0.9832324173265021\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 17, train_loss = 8.388566720299423, train_acc = 0.984163949697252\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 18, train_loss = 7.947739257477224, train_acc = 0.9855612482533768\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 19, train_loss = 7.549127848818898, train_acc = 0.9869585468095017\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 20, train_loss = 7.185037768445909, train_acc = 0.9874243129948765\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 21, train_loss = 6.8559365617111325, train_acc = 0.9877736376339078\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 22, train_loss = 6.556996581144631, train_acc = 0.9883558453656265\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 23, train_loss = 6.277761808596551, train_acc = 0.9892873777363763\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 24, train_loss = 6.021431111730635, train_acc = 0.9902189101071263\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 25, train_loss = 5.786252056248486, train_acc = 0.9909175593851887\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 26, train_loss = 5.569321969524026, train_acc = 0.9910340009315324\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 27, train_loss = 5.369521690532565, train_acc = 0.9913833255705635\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 28, train_loss = 5.181925314478576, train_acc = 0.9918490917559385\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 29, train_loss = 5.007881147786975, train_acc = 0.992081974848626\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 30, train_loss = 4.846175482496619, train_acc = 0.9923148579413135\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 31, train_loss = 4.696806143037975, train_acc = 0.9931299487657196\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 32, train_loss = 4.554424463771284, train_acc = 0.9933628318584071\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 33, train_loss = 4.420683887787163, train_acc = 0.9937121564974383\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 34, train_loss = 4.295697113499045, train_acc = 0.9937121564974383\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 35, train_loss = 4.177646404132247, train_acc = 0.993828598043782\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 36, train_loss = 4.067434137687087, train_acc = 0.9939450395901258\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 37, train_loss = 3.9621112532913685, train_acc = 0.9940614811364695\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 38, train_loss = 3.863155665807426, train_acc = 0.9940614811364695\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 39, train_loss = 3.7704352801665664, train_acc = 0.9940614811364695\n",
      "test Acc 0.9725325884543762:\n",
      "8th- epoch: 40, train_loss = 3.682529794983566, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 41, train_loss = 3.5998526513576508, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 42, train_loss = 3.5205578673630953, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 43, train_loss = 3.4453732119873166, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 44, train_loss = 3.3750358764082193, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 45, train_loss = 3.307584350928664, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 46, train_loss = 3.243040501140058, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 47, train_loss = 3.181542741600424, train_acc = 0.9951094550535631\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 48, train_loss = 3.1240940620191395, train_acc = 0.9953423381462506\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 49, train_loss = 3.068988535553217, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 50, train_loss = 3.017238305415958, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 51, train_loss = 2.9658633656799793, train_acc = 0.995575221238938\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 52, train_loss = 2.916778065264225, train_acc = 0.9956916627852818\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 53, train_loss = 2.8712469711899757, train_acc = 0.9958081043316255\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 54, train_loss = 2.8278264878317714, train_acc = 0.9959245458779693\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 55, train_loss = 2.783204262610525, train_acc = 0.996040987424313\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 56, train_loss = 2.7418596637435257, train_acc = 0.996040987424313\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 57, train_loss = 2.70251408778131, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 58, train_loss = 2.663835985586047, train_acc = 0.9963903120633442\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 59, train_loss = 2.6272389967925847, train_acc = 0.9963903120633442\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 60, train_loss = 2.5916126794181764, train_acc = 0.996506753609688\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 61, train_loss = 2.5572866462171078, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 62, train_loss = 2.5251647420227528, train_acc = 0.996506753609688\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 63, train_loss = 2.4929605568759143, train_acc = 0.9966231951560317\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 64, train_loss = 2.462522942107171, train_acc = 0.9966231951560317\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 65, train_loss = 2.432856396306306, train_acc = 0.996506753609688\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 66, train_loss = 2.4037111150100827, train_acc = 0.996506753609688\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 67, train_loss = 2.3773149009793997, train_acc = 0.9967396367023754\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 68, train_loss = 2.349722067825496, train_acc = 0.9967396367023754\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 69, train_loss = 2.3249508584849536, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 70, train_loss = 2.2997422772459686, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 71, train_loss = 2.274987020995468, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 72, train_loss = 2.251556722447276, train_acc = 0.9970889613414066\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 73, train_loss = 2.2286739610135555, train_acc = 0.9970889613414066\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 74, train_loss = 2.2068033725954592, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 75, train_loss = 2.185698250774294, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 76, train_loss = 2.164791638031602, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 77, train_loss = 2.1442488157190382, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 78, train_loss = 2.124816113617271, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 79, train_loss = 2.1050181798636913, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 80, train_loss = 2.0871745264157653, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 81, train_loss = 2.06826064363122, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 82, train_loss = 2.050578547641635, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 83, train_loss = 2.033990197815001, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 84, train_loss = 2.0166463451460004, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 85, train_loss = 2.0009319875389338, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 86, train_loss = 1.9848783176857978, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 87, train_loss = 1.9698971675243229, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 88, train_loss = 1.9546623204369098, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 89, train_loss = 1.9398696010466665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 90, train_loss = 1.9258835066575557, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 91, train_loss = 1.9115696356166154, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 92, train_loss = 1.898410772671923, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 93, train_loss = 1.8851077139843255, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 94, train_loss = 1.871997675159946, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 95, train_loss = 1.8591743290890008, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 96, train_loss = 1.8465853778179735, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 97, train_loss = 1.8342325172852725, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 98, train_loss = 1.822700516320765, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 99, train_loss = 1.810531682567671, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 100, train_loss = 1.7995725960936397, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 101, train_loss = 1.7888521749991924, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 102, train_loss = 1.777804872719571, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 103, train_loss = 1.7675162591040134, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 104, train_loss = 1.757383604766801, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 105, train_loss = 1.746943430043757, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 106, train_loss = 1.7373400337528437, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 107, train_loss = 1.7279496977571398, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 108, train_loss = 1.7183055707719177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 109, train_loss = 1.7091367952525616, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 110, train_loss = 1.7000705795362592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 111, train_loss = 1.6912561042699963, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 112, train_loss = 1.6826929526869208, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 113, train_loss = 1.6741243759170175, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 114, train_loss = 1.6654957139398903, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 115, train_loss = 1.6575273259077221, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 116, train_loss = 1.6494885720312595, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 117, train_loss = 1.6418873593211174, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 118, train_loss = 1.6336279136594385, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 119, train_loss = 1.6265578411985189, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 120, train_loss = 1.6184712890535593, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 121, train_loss = 1.6120302046183497, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 122, train_loss = 1.6040978636592627, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 123, train_loss = 1.5969926819670945, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 124, train_loss = 1.5904962678905576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 125, train_loss = 1.583597393706441, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 126, train_loss = 1.5770993996411562, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 127, train_loss = 1.5700934182386845, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 128, train_loss = 1.5642046246211976, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 129, train_loss = 1.5575233835261315, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 130, train_loss = 1.5511761717498302, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 131, train_loss = 1.5450537248980254, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 132, train_loss = 1.538969400105998, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 133, train_loss = 1.5326688482891768, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 134, train_loss = 1.5269988793879747, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 135, train_loss = 1.5215353444218636, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 136, train_loss = 1.515414432855323, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 137, train_loss = 1.5099380481988192, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 138, train_loss = 1.5041648868937045, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 139, train_loss = 1.4990815352648497, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 140, train_loss = 1.4934869550634176, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 141, train_loss = 1.4878562142839655, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 142, train_loss = 1.4831272382289171, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 143, train_loss = 1.4779546819627285, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 144, train_loss = 1.4726593177765608, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 145, train_loss = 1.4675729479640722, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 146, train_loss = 1.462238123640418, train_acc = 0.9977876106194691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 147, train_loss = 1.457721425802447, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 148, train_loss = 1.4525516275316477, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 149, train_loss = 1.447779467329383, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 150, train_loss = 1.4433828108012676, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 151, train_loss = 1.438342514098622, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 152, train_loss = 1.4338463047752157, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 153, train_loss = 1.4294695189455524, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 154, train_loss = 1.4254361341008916, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 155, train_loss = 1.420253217802383, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 156, train_loss = 1.41670523583889, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 157, train_loss = 1.4122635088860989, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 158, train_loss = 1.4077132567763329, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 159, train_loss = 1.4035283891716972, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 160, train_loss = 1.3999413481215015, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 161, train_loss = 1.3949197760084644, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 162, train_loss = 1.3918156642466784, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 163, train_loss = 1.3877615369856358, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 164, train_loss = 1.3833529961993918, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 165, train_loss = 1.3797358250012621, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 166, train_loss = 1.3761446917196736, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 167, train_loss = 1.3719423779984936, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 168, train_loss = 1.368834545253776, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 169, train_loss = 1.3642241595080122, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 170, train_loss = 1.3618147410452366, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 171, train_loss = 1.3580047147115692, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 172, train_loss = 1.3546790512045845, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 173, train_loss = 1.3507627540966496, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 174, train_loss = 1.3475413508713245, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 175, train_loss = 1.3434194525470957, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 176, train_loss = 1.3407201636582613, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 177, train_loss = 1.3371402025222778, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 178, train_loss = 1.3338016836205497, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 179, train_loss = 1.3303874917328358, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 180, train_loss = 1.327828465611674, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 181, train_loss = 1.3239900475600734, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 182, train_loss = 1.3209312172839418, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 183, train_loss = 1.3175860978662968, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 184, train_loss = 1.3148181097349152, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 185, train_loss = 1.3114979615202174, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 186, train_loss = 1.3081626327475533, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 187, train_loss = 1.3056271044770256, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 188, train_loss = 1.3025038900086656, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 189, train_loss = 1.2994597107172012, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 190, train_loss = 1.2964766807854176, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 191, train_loss = 1.2942233668873087, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 192, train_loss = 1.2910743864485994, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 193, train_loss = 1.2884383822092786, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 194, train_loss = 1.2856928067049012, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 195, train_loss = 1.2827086374163628, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 196, train_loss = 1.2800240529468283, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 197, train_loss = 1.2779712975025177, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 198, train_loss = 1.274660755530931, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 199, train_loss = 1.2724223118275404, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 200, train_loss = 1.2698895372450352, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 201, train_loss = 1.2672160683432594, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 202, train_loss = 1.264189843670465, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 203, train_loss = 1.262298863963224, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 204, train_loss = 1.2593910129508004, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 205, train_loss = 1.257237253128551, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 206, train_loss = 1.2550490573048592, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 207, train_loss = 1.2524853106588125, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 208, train_loss = 1.2500907027861103, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 209, train_loss = 1.2481068074703217, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 210, train_loss = 1.2451011849334463, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 211, train_loss = 1.2432179605821148, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 212, train_loss = 1.240990562364459, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 213, train_loss = 1.2387859908631071, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 214, train_loss = 1.2363273780792952, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 215, train_loss = 1.2338868007063866, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 216, train_loss = 1.2319394802907482, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 217, train_loss = 1.2300002463161945, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 218, train_loss = 1.2271769730141386, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 219, train_loss = 1.2251276423921809, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 220, train_loss = 1.2232266446808353, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 221, train_loss = 1.2209960669279099, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 222, train_loss = 1.2186059994855896, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 223, train_loss = 1.217039750306867, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 224, train_loss = 1.214501035748981, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 225, train_loss = 1.2123341454425827, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 226, train_loss = 1.210676054120995, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 227, train_loss = 1.2086563259363174, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 228, train_loss = 1.2064212337136269, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 229, train_loss = 1.2042070335010067, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 230, train_loss = 1.2023979717632756, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 231, train_loss = 1.2006036695092916, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 232, train_loss = 1.198940236121416, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 233, train_loss = 1.1965668480843306, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 234, train_loss = 1.1953789237886667, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 235, train_loss = 1.1931459171464667, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 236, train_loss = 1.1911181578179821, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 237, train_loss = 1.1890625916421413, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 238, train_loss = 1.1874154483666644, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 239, train_loss = 1.1854752786457539, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 240, train_loss = 1.1839037457248196, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 241, train_loss = 1.1817677225917578, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 242, train_loss = 1.1803864669054747, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 243, train_loss = 1.1784402740304358, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 244, train_loss = 1.176186690106988, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 245, train_loss = 1.1749945282936096, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 246, train_loss = 1.173467354848981, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 247, train_loss = 1.1718182868207805, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 248, train_loss = 1.1696791437570937, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 249, train_loss = 1.168513550714124, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 250, train_loss = 1.166491786018014, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 251, train_loss = 1.1653344525839202, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 252, train_loss = 1.1630715541541576, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 253, train_loss = 1.1619498419458978, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 254, train_loss = 1.1600110375438817, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 255, train_loss = 1.1585580334067345, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 256, train_loss = 1.157081741199363, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 257, train_loss = 1.1556217459146865, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 258, train_loss = 1.1539251916110516, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 259, train_loss = 1.1526580192148685, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 260, train_loss = 1.1506619422580115, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 261, train_loss = 1.1496448926627636, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 262, train_loss = 1.1476010761107318, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 263, train_loss = 1.1461875848472118, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 264, train_loss = 1.1443547655944712, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 265, train_loss = 1.1435476045007817, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 266, train_loss = 1.1414132937788963, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 267, train_loss = 1.1405679558520205, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 268, train_loss = 1.1389333394472487, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 269, train_loss = 1.1375806338037364, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 270, train_loss = 1.1357542648911476, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 271, train_loss = 1.1348944138735533, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 272, train_loss = 1.1328738114680164, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 273, train_loss = 1.131781232834328, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 274, train_loss = 1.130299559503328, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 275, train_loss = 1.1290359764243476, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 276, train_loss = 1.1272211938048713, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 277, train_loss = 1.1264014175976627, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 278, train_loss = 1.1246348936110735, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 279, train_loss = 1.1238350930507295, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 280, train_loss = 1.1216286569833755, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 281, train_loss = 1.1209083323483355, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 282, train_loss = 1.1192768787150271, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 283, train_loss = 1.1174893981660716, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 284, train_loss = 1.1164942998439074, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 285, train_loss = 1.1148702862556092, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 286, train_loss = 1.1138655853574164, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 287, train_loss = 1.1126107306336053, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 288, train_loss = 1.1112382542341948, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 289, train_loss = 1.1100966998492368, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 290, train_loss = 1.1085360273718834, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 291, train_loss = 1.1076715476810932, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 292, train_loss = 1.1064700682763942, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 293, train_loss = 1.1048913256381638, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 294, train_loss = 1.1040005975519307, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 295, train_loss = 1.1024218599195592, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 296, train_loss = 1.1012403449858539, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 297, train_loss = 1.1001245751976967, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 298, train_loss = 1.0991483951802365, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 299, train_loss = 1.097308750555385, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 300, train_loss = 1.0967159159481525, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 301, train_loss = 1.0955212122644298, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 302, train_loss = 1.0947031316463836, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 303, train_loss = 1.0934013270889409, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 304, train_loss = 1.0921919091488235, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 305, train_loss = 1.0905736361746676, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 306, train_loss = 1.08968168561114, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 307, train_loss = 1.0889543655212037, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 308, train_loss = 1.0874795361305587, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 309, train_loss = 1.0859080981463194, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 310, train_loss = 1.0851224474608898, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 311, train_loss = 1.0836325368727557, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 312, train_loss = 1.0830261272494681, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 313, train_loss = 1.0816326687927358, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 314, train_loss = 1.0804529841989279, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 315, train_loss = 1.0801124647259712, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 316, train_loss = 1.0792821564828046, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 317, train_loss = 1.0780641988967545, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 318, train_loss = 1.0768810734152794, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 319, train_loss = 1.0752086881548166, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 320, train_loss = 1.074434248090256, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 321, train_loss = 1.0732390719349496, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 322, train_loss = 1.072952875867486, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 323, train_loss = 1.0714856932754628, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 324, train_loss = 1.0704860885743983, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 325, train_loss = 1.0693833486293443, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 326, train_loss = 1.067824104160536, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 327, train_loss = 1.067499001219403, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 328, train_loss = 1.0662481884355657, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 329, train_loss = 1.0656322824652307, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 330, train_loss = 1.064451762184035, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 331, train_loss = 1.0633516311645508, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 332, train_loss = 1.062517759099137, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 333, train_loss = 1.0615203070337884, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 334, train_loss = 1.0603205555235036, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 335, train_loss = 1.0601032730191946, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 336, train_loss = 1.0587711769039743, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 337, train_loss = 1.0585158460889943, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 338, train_loss = 1.0568923627142794, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 339, train_loss = 1.0556624624878168, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 340, train_loss = 1.055377825454343, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 341, train_loss = 1.0542031303048134, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 342, train_loss = 1.0535073224455118, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 343, train_loss = 1.0518781791324727, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 344, train_loss = 1.051118868694175, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 345, train_loss = 1.0504861666704528, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 346, train_loss = 1.0493022439186461, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 347, train_loss = 1.0486072444473393, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 348, train_loss = 1.0473331660032272, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 349, train_loss = 1.046805348887574, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 350, train_loss = 1.045506217807997, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 351, train_loss = 1.045187170326244, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 352, train_loss = 1.0445603312109597, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 353, train_loss = 1.0433365355129354, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 354, train_loss = 1.0424780963803641, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 355, train_loss = 1.0412032597814687, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 356, train_loss = 1.0403141242568381, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 357, train_loss = 1.0391549486666918, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 358, train_loss = 1.0384015403687954, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 359, train_loss = 1.0377088406239636, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 360, train_loss = 1.0369622576981783, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 361, train_loss = 1.0355033998494036, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 362, train_loss = 1.0347784776240587, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 363, train_loss = 1.0343850192730315, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 364, train_loss = 1.0324510280042887, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 365, train_loss = 1.0318670881097205, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 366, train_loss = 1.0313990358263254, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 367, train_loss = 1.0304474259610288, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 368, train_loss = 1.029572480067145, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 369, train_loss = 1.0286370441317558, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 370, train_loss = 1.0281816497445107, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 371, train_loss = 1.026576039090287, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 372, train_loss = 1.0258832213585265, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 373, train_loss = 1.0248294764314778, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 374, train_loss = 1.0241404846310616, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 375, train_loss = 1.0238498828257434, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 376, train_loss = 1.0223192945122719, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 377, train_loss = 1.0212417182628997, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 378, train_loss = 1.0206180841778405, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 379, train_loss = 1.0206053964793682, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 380, train_loss = 1.0190756190568209, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 381, train_loss = 1.0181015829439275, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 382, train_loss = 1.0174192494596355, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 383, train_loss = 1.017073052644264, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 384, train_loss = 1.0153366749291308, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 385, train_loss = 1.0151979817892425, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 386, train_loss = 1.0141116219456308, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 387, train_loss = 1.0132649522274733, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 388, train_loss = 1.012335701554548, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 389, train_loss = 1.011897896125447, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 390, train_loss = 1.011048138141632, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 391, train_loss = 1.0096337043796666, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 392, train_loss = 1.0092470149393193, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 393, train_loss = 1.0080637789214961, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 394, train_loss = 1.0076120744342916, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 395, train_loss = 1.0073676127940416, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 396, train_loss = 1.0059060559724458, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 397, train_loss = 1.0056075602769852, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 398, train_loss = 1.004790021746885, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 399, train_loss = 1.0044085271656513, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 400, train_loss = 1.003376841545105, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 401, train_loss = 1.0026100923423655, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 402, train_loss = 1.0015548865194432, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 403, train_loss = 1.001328116923105, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 404, train_loss = 1.0003677892382257, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 405, train_loss = 0.9999162629246712, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 406, train_loss = 0.9988761928980239, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 407, train_loss = 0.99850669875741, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 408, train_loss = 0.9979500534827821, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 409, train_loss = 0.997114886820782, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 410, train_loss = 0.9962038286030293, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 411, train_loss = 0.9959077860112302, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 412, train_loss = 0.9949984339182265, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 413, train_loss = 0.9951876501436345, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 414, train_loss = 0.9934700566227548, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 415, train_loss = 0.9929378740489483, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 416, train_loss = 0.9925446410779841, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 417, train_loss = 0.9916899986565113, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 418, train_loss = 0.9913074498181231, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 419, train_loss = 0.9904218912124634, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 420, train_loss = 0.9896742875571363, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 421, train_loss = 0.9892508648335934, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 422, train_loss = 0.9885111686890014, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 423, train_loss = 0.9880138151347637, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 424, train_loss = 0.9869640034739859, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 425, train_loss = 0.9865664889512118, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 426, train_loss = 0.9860694023373071, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 427, train_loss = 0.9851899445056915, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 428, train_loss = 0.9846934812667314, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 429, train_loss = 0.9835547283291817, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 430, train_loss = 0.9831910828652326, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 431, train_loss = 0.9827543509600218, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 432, train_loss = 0.9822287050483283, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 433, train_loss = 0.98116185516119, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 434, train_loss = 0.9799676090478897, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 435, train_loss = 0.9793590195477009, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 436, train_loss = 0.9790953944029752, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 437, train_loss = 0.9778023771941662, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 438, train_loss = 0.9773953581752721, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 439, train_loss = 0.9768222620186862, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 440, train_loss = 0.9761827327311039, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 441, train_loss = 0.975578503072029, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 442, train_loss = 0.9749732924101409, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 443, train_loss = 0.9743924947979394, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 444, train_loss = 0.9742061147990171, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 445, train_loss = 0.9729321027698461, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 446, train_loss = 0.97237273430801, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 447, train_loss = 0.9723350082931574, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 448, train_loss = 0.9714453481137753, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 449, train_loss = 0.9708541346190032, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 450, train_loss = 0.9705657052400056, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 451, train_loss = 0.9696929256024305, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 452, train_loss = 0.9693793927726801, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 453, train_loss = 0.9683564715087414, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 454, train_loss = 0.9681377162632998, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 455, train_loss = 0.9674423982796725, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 456, train_loss = 0.9669598750770092, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 457, train_loss = 0.9668710740807, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 458, train_loss = 0.9660271952452604, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 459, train_loss = 0.9656840600073338, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 460, train_loss = 0.9647485911846161, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 461, train_loss = 0.9641217862663325, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 462, train_loss = 0.963781868427759, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 463, train_loss = 0.963617922127014, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 464, train_loss = 0.9631939257087652, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 465, train_loss = 0.9621089845895767, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 466, train_loss = 0.961531293898588, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 467, train_loss = 0.9615868305263575, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 468, train_loss = 0.9606831818819046, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 469, train_loss = 0.9602534981968347, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 470, train_loss = 0.9597057178616524, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 471, train_loss = 0.9596584364771843, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 472, train_loss = 0.9588405924441759, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 473, train_loss = 0.9580850998463575, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 474, train_loss = 0.9577096961438656, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 475, train_loss = 0.9571312616171781, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 476, train_loss = 0.9567245679500047, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 477, train_loss = 0.9563545013370458, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 478, train_loss = 0.9557499550282955, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 479, train_loss = 0.9547597902419511, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 480, train_loss = 0.954733112215763, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 481, train_loss = 0.9539783671498299, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 482, train_loss = 0.9537000929412898, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 483, train_loss = 0.9534962351026479, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 484, train_loss = 0.9525126156804617, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 485, train_loss = 0.9525693332252558, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 486, train_loss = 0.9518166979250964, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 487, train_loss = 0.9515785252151545, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 488, train_loss = 0.9508599067630712, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 489, train_loss = 0.9505733413097914, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 490, train_loss = 0.9501030022802297, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 491, train_loss = 0.9494601537880953, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 492, train_loss = 0.949350506067276, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 493, train_loss = 0.9481824201939162, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 494, train_loss = 0.948386454343563, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 495, train_loss = 0.9477833422424737, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 496, train_loss = 0.9467361445131246, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 497, train_loss = 0.9474511047301348, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 498, train_loss = 0.9460461959242821, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 499, train_loss = 0.9457618122396525, train_acc = 0.9980204937121565\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████▉                                                    | 8/30 [1:19:33<3:39:36, 598.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "9th- epoch: 0, train_loss = 132.65721866488457, train_acc = 0.7550069864927806\n",
      "test Acc 0.8417132216014898:\n",
      "9th- epoch: 1, train_loss = 52.31398078799248, train_acc = 0.8953190498369819\n",
      "test Acc 0.9031657355679702:\n",
      "9th- epoch: 2, train_loss = 37.59956260770559, train_acc = 0.926059618071728\n",
      "test Acc 0.9259776536312849:\n",
      "9th- epoch: 3, train_loss = 29.97028935328126, train_acc = 0.9411970190964136\n",
      "test Acc 0.9357541899441341:\n",
      "9th- epoch: 4, train_loss = 25.07636795192957, train_acc = 0.9509781089892874\n",
      "test Acc 0.9422718808193669:\n",
      "9th- epoch: 5, train_loss = 21.62777128443122, train_acc = 0.9568001863064741\n",
      "test Acc 0.9450651769087524:\n",
      "9th- epoch: 6, train_loss = 19.038024201989174, train_acc = 0.9612249650675361\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 7, train_loss = 17.00944727472961, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 8, train_loss = 15.35940426774323, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 9, train_loss = 13.980265131220222, train_acc = 0.972286911970191\n",
      "test Acc 0.9515828677839852:\n",
      "9th- epoch: 10, train_loss = 12.813375379890203, train_acc = 0.9742664182580345\n",
      "test Acc 0.9539106145251397:\n",
      "9th- epoch: 11, train_loss = 11.810331609100103, train_acc = 0.976245924545878\n",
      "test Acc 0.9553072625698324:\n",
      "9th- epoch: 12, train_loss = 10.930536845698953, train_acc = 0.9788076385654402\n",
      "test Acc 0.9567039106145251:\n",
      "9th- epoch: 13, train_loss = 10.164038319140673, train_acc = 0.9795062878435026\n",
      "test Acc 0.9581005586592178:\n",
      "9th- epoch: 14, train_loss = 9.48983428440988, train_acc = 0.981951560316721\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 15, train_loss = 8.888861017301679, train_acc = 0.9833488588728458\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 16, train_loss = 8.356726070865989, train_acc = 0.984163949697252\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 17, train_loss = 7.887292129918933, train_acc = 0.9849790405216581\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 18, train_loss = 7.454156616702676, train_acc = 0.9856776897997206\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 19, train_loss = 7.068996429443359, train_acc = 0.9864927806241267\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 20, train_loss = 6.719198785722256, train_acc = 0.9870749883558454\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 21, train_loss = 6.402698269113898, train_acc = 0.9882394038192828\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 22, train_loss = 6.113598631694913, train_acc = 0.9887051700046576\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 23, train_loss = 5.850725465454161, train_acc = 0.9899860270144387\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 24, train_loss = 5.609602655284107, train_acc = 0.9904517931998137\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 25, train_loss = 5.386227823793888, train_acc = 0.9912668840242198\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 26, train_loss = 5.181933235377073, train_acc = 0.9917326502095948\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 27, train_loss = 4.995376356877387, train_acc = 0.9923148579413135\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 28, train_loss = 4.823738317005336, train_acc = 0.9927806241266884\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 29, train_loss = 4.664238058961928, train_acc = 0.9932463903120633\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 30, train_loss = 4.517936552874744, train_acc = 0.9935957149510946\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 31, train_loss = 4.381117426790297, train_acc = 0.9941779226828132\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 32, train_loss = 4.253920629620552, train_acc = 0.9941779226828132\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 33, train_loss = 4.135102038271725, train_acc = 0.994294364229157\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 34, train_loss = 4.023588279262185, train_acc = 0.9945272473218444\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 35, train_loss = 3.9187240740284324, train_acc = 0.9945272473218444\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 36, train_loss = 3.8204745585098863, train_acc = 0.9946436888681882\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 37, train_loss = 3.7269889479503036, train_acc = 0.9946436888681882\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 38, train_loss = 3.639194798655808, train_acc = 0.9948765719608756\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 39, train_loss = 3.5571035584434867, train_acc = 0.9949930135072194\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 40, train_loss = 3.4796522725373507, train_acc = 0.9951094550535631\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 41, train_loss = 3.405543467029929, train_acc = 0.9952258965999069\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 42, train_loss = 3.3359461976215243, train_acc = 0.9953423381462506\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 43, train_loss = 3.2690192377194762, train_acc = 0.9953423381462506\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 44, train_loss = 3.205614565871656, train_acc = 0.9953423381462506\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 45, train_loss = 3.1446562064811587, train_acc = 0.995575221238938\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 46, train_loss = 3.0870540970936418, train_acc = 0.9958081043316255\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 47, train_loss = 3.032520898617804, train_acc = 0.9959245458779693\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 48, train_loss = 2.9795877221040428, train_acc = 0.9959245458779693\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 49, train_loss = 2.9294420615769923, train_acc = 0.996040987424313\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 50, train_loss = 2.8814291688613594, train_acc = 0.9961574289706567\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 51, train_loss = 2.83559745317325, train_acc = 0.9962738705170004\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 52, train_loss = 2.7915899455547333, train_acc = 0.9962738705170004\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 53, train_loss = 2.7486119060777128, train_acc = 0.9962738705170004\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 54, train_loss = 2.708767451811582, train_acc = 0.9962738705170004\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 55, train_loss = 2.6692677685059607, train_acc = 0.9962738705170004\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 56, train_loss = 2.630835496354848, train_acc = 0.9962738705170004\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 57, train_loss = 2.5954886619001627, train_acc = 0.9962738705170004\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 58, train_loss = 2.559644683729857, train_acc = 0.9962738705170004\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 59, train_loss = 2.525569681543857, train_acc = 0.9963903120633442\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 60, train_loss = 2.4940270096994936, train_acc = 0.9963903120633442\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 61, train_loss = 2.4621093086898327, train_acc = 0.9963903120633442\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 62, train_loss = 2.4311191798187792, train_acc = 0.9963903120633442\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 63, train_loss = 2.4026579782366753, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 64, train_loss = 2.373442950192839, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 65, train_loss = 2.3461922495625913, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 66, train_loss = 2.3201977373100817, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 67, train_loss = 2.2933324188925326, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 68, train_loss = 2.268562588840723, train_acc = 0.9966231951560317\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 69, train_loss = 2.2445202521048486, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 70, train_loss = 2.219865805003792, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 71, train_loss = 2.1973017901182175, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 72, train_loss = 2.1743775620125234, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 73, train_loss = 2.152692671865225, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 74, train_loss = 2.1317393318749964, train_acc = 0.996506753609688\n",
      "test Acc 0.9702048417132216:\n",
      "9th- epoch: 75, train_loss = 2.1105837747454643, train_acc = 0.996506753609688\n",
      "test Acc 0.9702048417132216:\n",
      "9th- epoch: 76, train_loss = 2.0913981893099844, train_acc = 0.996506753609688\n",
      "test Acc 0.9702048417132216:\n",
      "9th- epoch: 77, train_loss = 2.07144628232345, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 78, train_loss = 2.053633739706129, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 79, train_loss = 2.0357725084759295, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 80, train_loss = 2.017509024590254, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 81, train_loss = 2.000207158504054, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 82, train_loss = 1.983725483296439, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 83, train_loss = 1.9670318576972932, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 84, train_loss = 1.9517865267116576, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 85, train_loss = 1.9360342014115304, train_acc = 0.9966231951560317\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 86, train_loss = 1.9211964048445225, train_acc = 0.9966231951560317\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 87, train_loss = 1.906806617975235, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 88, train_loss = 1.8926388348918408, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 89, train_loss = 1.8790761406999081, train_acc = 0.9968560782487191\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 90, train_loss = 1.8656319740694016, train_acc = 0.9968560782487191\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 91, train_loss = 1.8520119253080338, train_acc = 0.9968560782487191\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 92, train_loss = 1.8395573571324348, train_acc = 0.9968560782487191\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 93, train_loss = 1.8267698597628623, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 94, train_loss = 1.8146494887769222, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 95, train_loss = 1.8026009164750576, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 96, train_loss = 1.7908333018422127, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 97, train_loss = 1.7796621199231595, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 98, train_loss = 1.7682903509121388, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 99, train_loss = 1.7576650939881802, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 100, train_loss = 1.746963697252795, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 101, train_loss = 1.7364594240207225, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 102, train_loss = 1.726176542462781, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 103, train_loss = 1.7169618580956012, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 104, train_loss = 1.7071943294722587, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 105, train_loss = 1.6972184777259827, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 106, train_loss = 1.6881389457266778, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 107, train_loss = 1.679206697968766, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 108, train_loss = 1.6696468878071755, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 109, train_loss = 1.6610129040200263, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 110, train_loss = 1.6524568710010499, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 111, train_loss = 1.6440800938289613, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 112, train_loss = 1.6355046581011266, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 113, train_loss = 1.6278334595263004, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 114, train_loss = 1.6188523087184876, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 115, train_loss = 1.6113694161176682, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 116, train_loss = 1.603320925263688, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 117, train_loss = 1.5961703658103943, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 118, train_loss = 1.5892386238556355, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 119, train_loss = 1.5816355869174004, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 120, train_loss = 1.5748571828007698, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "9th- epoch: 121, train_loss = 1.5676917743403465, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 122, train_loss = 1.5608984977006912, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 123, train_loss = 1.554240343393758, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 124, train_loss = 1.547477399231866, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 125, train_loss = 1.5410933680832386, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 126, train_loss = 1.534556521801278, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 127, train_loss = 1.5293916028458625, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 128, train_loss = 1.5224195359041914, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 129, train_loss = 1.5168935420224443, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 130, train_loss = 1.5110413605580106, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 131, train_loss = 1.5045645063510165, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 132, train_loss = 1.4995051374426112, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 133, train_loss = 1.4936332093784586, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 134, train_loss = 1.4883924722671509, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 135, train_loss = 1.4827941370895132, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 136, train_loss = 1.4778652129461989, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 137, train_loss = 1.4726364550879225, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 138, train_loss = 1.4676061818609014, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 139, train_loss = 1.4621566124260426, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 140, train_loss = 1.4573623599717394, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 141, train_loss = 1.4521847689757124, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 142, train_loss = 1.4472822174429893, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 143, train_loss = 1.4425876140594482, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 144, train_loss = 1.437999932677485, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 145, train_loss = 1.4331920010736212, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 146, train_loss = 1.4282805360853672, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 147, train_loss = 1.424071278423071, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 148, train_loss = 1.4196828504791483, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 149, train_loss = 1.4149613231420517, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 150, train_loss = 1.4107260294258595, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 151, train_loss = 1.4064013982424513, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 152, train_loss = 1.4019899740815163, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 153, train_loss = 1.3981061415979639, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 154, train_loss = 1.3934234715998173, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 155, train_loss = 1.389848466962576, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 156, train_loss = 1.3854812396457419, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 157, train_loss = 1.3816840760409832, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 158, train_loss = 1.3779872382292524, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 159, train_loss = 1.3740061161806807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 160, train_loss = 1.370612540631555, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 161, train_loss = 1.3661957085132599, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 162, train_loss = 1.3625071892747656, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 163, train_loss = 1.359508141875267, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 164, train_loss = 1.3557173497974873, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 165, train_loss = 1.351602554321289, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 166, train_loss = 1.3488183356821537, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 167, train_loss = 1.3449686964740977, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 168, train_loss = 1.3414884594967589, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 169, train_loss = 1.3384106842568144, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 170, train_loss = 1.334808455198072, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 171, train_loss = 1.3317834684858099, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 172, train_loss = 1.3281237172195688, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 173, train_loss = 1.3252355618169531, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 174, train_loss = 1.321421705186367, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 175, train_loss = 1.318452867330052, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 176, train_loss = 1.3153311783680692, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 177, train_loss = 1.3121271977433935, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 178, train_loss = 1.3091252198209986, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 179, train_loss = 1.3059523180127144, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 180, train_loss = 1.3030927454819903, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 181, train_loss = 1.29979133233428, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 182, train_loss = 1.2968084489693865, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 183, train_loss = 1.29385434219148, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 184, train_loss = 1.2904283193638548, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 185, train_loss = 1.287832137197256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 186, train_loss = 1.2850017560413107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 187, train_loss = 1.2817462533712387, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 188, train_loss = 1.2787207216024399, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 189, train_loss = 1.2759559812257066, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 190, train_loss = 1.272632853477262, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 191, train_loss = 1.2700338723370805, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 192, train_loss = 1.2665379606187344, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 193, train_loss = 1.2638744985451922, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 194, train_loss = 1.2609562563011423, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 195, train_loss = 1.2581610605120659, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 196, train_loss = 1.255624271929264, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 197, train_loss = 1.2533031813800335, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 198, train_loss = 1.2504505490651354, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 199, train_loss = 1.2480456667253748, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 200, train_loss = 1.2455089738359675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 201, train_loss = 1.2428524693241343, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 202, train_loss = 1.2403561534592882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 203, train_loss = 1.238382608979009, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 204, train_loss = 1.235608690767549, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 205, train_loss = 1.2334826228907332, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 206, train_loss = 1.231079744757153, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 207, train_loss = 1.228536962182261, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 208, train_loss = 1.22675095370505, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 209, train_loss = 1.2241315630963072, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 210, train_loss = 1.2216584061970934, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 211, train_loss = 1.2200953090796247, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 212, train_loss = 1.2176097942283377, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 213, train_loss = 1.2153439609101042, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 214, train_loss = 1.2131857523927465, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 215, train_loss = 1.2105643066461198, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 216, train_loss = 1.2085835064644925, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 217, train_loss = 1.2066414219443686, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 218, train_loss = 1.2044831861858256, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 219, train_loss = 1.2023211133782752, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 220, train_loss = 1.200534424453508, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 221, train_loss = 1.1984441975946538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 222, train_loss = 1.1961774204974063, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 223, train_loss = 1.1946308389306068, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 224, train_loss = 1.1923405987326987, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 225, train_loss = 1.190146331966389, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 226, train_loss = 1.188728169829119, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 227, train_loss = 1.1864479283685796, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 228, train_loss = 1.1845576104824431, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 229, train_loss = 1.1829216207261197, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 230, train_loss = 1.1808297249372117, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 231, train_loss = 1.17877884831978, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 232, train_loss = 1.1770834165508859, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 233, train_loss = 1.1749539313022979, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 234, train_loss = 1.1728710805182345, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 235, train_loss = 1.1712458941037767, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 236, train_loss = 1.1698159873485565, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 237, train_loss = 1.1677023495431058, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 238, train_loss = 1.1657978370785713, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 239, train_loss = 1.164170467585791, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 240, train_loss = 1.162475420802366, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 241, train_loss = 1.1607819385826588, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 242, train_loss = 1.1591210800106637, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 243, train_loss = 1.1575493228738196, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 244, train_loss = 1.1555223886971362, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 245, train_loss = 1.1539080987568013, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 246, train_loss = 1.1524466474656947, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 247, train_loss = 1.1503831024165265, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 248, train_loss = 1.1493219422991388, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 249, train_loss = 1.147458589344751, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 250, train_loss = 1.145788460969925, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 251, train_loss = 1.1441808107192628, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 252, train_loss = 1.1426918134093285, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 253, train_loss = 1.1411540296976455, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 254, train_loss = 1.1394949977402575, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 255, train_loss = 1.137955108017195, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 256, train_loss = 1.1363120165769942, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 257, train_loss = 1.1347126637701876, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 258, train_loss = 1.1335010354523547, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 259, train_loss = 1.1321424742345698, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 260, train_loss = 1.1305609146947972, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 261, train_loss = 1.1289133082027547, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 262, train_loss = 1.127438607334625, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 263, train_loss = 1.1259840168058872, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 264, train_loss = 1.124558549374342, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 265, train_loss = 1.1231009649927728, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 266, train_loss = 1.1215379958157428, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 267, train_loss = 1.120214985043276, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 268, train_loss = 1.119130605191458, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 269, train_loss = 1.1170471906661987, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 270, train_loss = 1.115977257490158, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 271, train_loss = 1.1145270119304769, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 272, train_loss = 1.113269365101587, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 273, train_loss = 1.1118458956480026, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 274, train_loss = 1.1106617164914496, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 275, train_loss = 1.1087379977107048, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 276, train_loss = 1.1078257101471536, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 277, train_loss = 1.1061605587601662, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 278, train_loss = 1.105139248073101, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 279, train_loss = 1.103666937618982, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 280, train_loss = 1.10235544788884, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 281, train_loss = 1.1008578154142015, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 282, train_loss = 1.0998002961277962, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 283, train_loss = 1.0983088065986522, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 284, train_loss = 1.097195761918556, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 285, train_loss = 1.0957584604620934, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 286, train_loss = 1.0945488040451892, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 287, train_loss = 1.0931585704092868, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 288, train_loss = 1.092107339471113, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 289, train_loss = 1.0909539200365543, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 290, train_loss = 1.0895978932385333, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 291, train_loss = 1.0884181062574498, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 292, train_loss = 1.08731384947896, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 293, train_loss = 1.085877675563097, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 294, train_loss = 1.0847639341955073, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 295, train_loss = 1.0836030232603662, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 296, train_loss = 1.082230652391445, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 297, train_loss = 1.081392265856266, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 298, train_loss = 1.0799535363912582, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 299, train_loss = 1.0790334616904147, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 300, train_loss = 1.0778583970968612, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 301, train_loss = 1.0765917114913464, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 302, train_loss = 1.0756999514997005, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 303, train_loss = 1.074462780088652, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 304, train_loss = 1.0734060530667193, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 305, train_loss = 1.0717552602291107, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 306, train_loss = 1.0713335585896857, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 307, train_loss = 1.0700107949669473, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 308, train_loss = 1.0688518472015858, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 309, train_loss = 1.0676770855789073, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 310, train_loss = 1.0665930435061455, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 311, train_loss = 1.0655242092907429, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 312, train_loss = 1.0640829292242415, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 313, train_loss = 1.0629693269729614, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 314, train_loss = 1.0620464881067164, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 315, train_loss = 1.060499391227495, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 316, train_loss = 1.0596997886896133, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 317, train_loss = 1.0584288512472995, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 318, train_loss = 1.056925309181679, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 319, train_loss = 1.0556256200070493, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 320, train_loss = 1.0546587866847403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 321, train_loss = 1.0538414965267293, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 322, train_loss = 1.0529900354449637, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 323, train_loss = 1.0514777787029743, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 324, train_loss = 1.0505798533558846, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 325, train_loss = 1.0492067610030062, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 326, train_loss = 1.0479339100420475, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 327, train_loss = 1.0472956870798953, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 328, train_loss = 1.0462606574292295, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 329, train_loss = 1.045231154828798, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 330, train_loss = 1.04395716014551, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 331, train_loss = 1.043189276009798, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 332, train_loss = 1.042309922457207, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 333, train_loss = 1.0413816955988295, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 334, train_loss = 1.040491908788681, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 335, train_loss = 1.039481914282078, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 336, train_loss = 1.038802513241535, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 337, train_loss = 1.0375229405763093, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 338, train_loss = 1.0366729758679867, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 339, train_loss = 1.035760054975981, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 340, train_loss = 1.0351736644806806, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 341, train_loss = 1.0341827658412512, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 342, train_loss = 1.0331288104353007, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 343, train_loss = 1.03226875141263, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 344, train_loss = 1.0316633842885494, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 345, train_loss = 1.030371218919754, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 346, train_loss = 1.0295899684133474, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 347, train_loss = 1.0289320461452007, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 348, train_loss = 1.0280864387750626, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 349, train_loss = 1.0273088800313417, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 350, train_loss = 1.0259910374879837, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 351, train_loss = 1.0254290377197322, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 352, train_loss = 1.024503921478754, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 353, train_loss = 1.02364943921566, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 354, train_loss = 1.0228161737322807, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 355, train_loss = 1.021888426184887, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 356, train_loss = 1.0209967568516731, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 357, train_loss = 1.0202091298997402, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 358, train_loss = 1.019864952802891, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 359, train_loss = 1.0186559433641378, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 360, train_loss = 1.0180036053061485, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 361, train_loss = 1.0170104528369848, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 362, train_loss = 1.0162189615366515, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 363, train_loss = 1.0153485114278737, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 364, train_loss = 1.0146718434989452, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 365, train_loss = 1.0141467352805194, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 366, train_loss = 1.0130536518990993, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 367, train_loss = 1.012422331928974, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 368, train_loss = 1.011936478316784, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 369, train_loss = 1.0108227965829428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 370, train_loss = 1.0104092272522394, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 371, train_loss = 1.0094022204575595, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 372, train_loss = 1.0084266103804111, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 373, train_loss = 1.007890054344898, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 374, train_loss = 1.0071522829530295, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 375, train_loss = 1.0060503569839057, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 376, train_loss = 1.005869410932064, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 377, train_loss = 1.0046786504390184, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 378, train_loss = 1.0037927950324956, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 379, train_loss = 1.0033248998224735, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 380, train_loss = 1.0029341615736485, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 381, train_loss = 1.0023535750806332, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 382, train_loss = 1.0013685561716557, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 383, train_loss = 1.0007211180927698, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 384, train_loss = 0.9996528563497122, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 385, train_loss = 0.9989049012365285, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 386, train_loss = 0.9984935745596886, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 387, train_loss = 0.9977478446962778, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 388, train_loss = 0.9970439535973128, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 389, train_loss = 0.9959790036082268, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 390, train_loss = 0.9953896353545133, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 391, train_loss = 0.9949882949294988, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 392, train_loss = 0.9940929735603277, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 393, train_loss = 0.9936160022916738, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 394, train_loss = 0.9925572288630065, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 395, train_loss = 0.9919958387908991, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 396, train_loss = 0.9913956349191722, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 397, train_loss = 0.9908758526144084, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 398, train_loss = 0.990403456002241, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 399, train_loss = 0.9894983718695585, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 400, train_loss = 0.9892968038620893, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 401, train_loss = 0.9882157655956689, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 402, train_loss = 0.9877877247927245, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 403, train_loss = 0.9865881738660391, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 404, train_loss = 0.9861834049224854, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 405, train_loss = 0.9855695366859436, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 406, train_loss = 0.9848580360412598, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 407, train_loss = 0.9841741795244161, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 408, train_loss = 0.9837382858095225, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 409, train_loss = 0.9826828936638776, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 410, train_loss = 0.9822334932687227, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 411, train_loss = 0.9814552776515484, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 412, train_loss = 0.9809642036852892, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 413, train_loss = 0.9802930106816348, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 414, train_loss = 0.9798898684384767, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 415, train_loss = 0.9785401076078415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 416, train_loss = 0.9787614569067955, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 417, train_loss = 0.9779888590273913, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 418, train_loss = 0.9771860564651433, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 419, train_loss = 0.9764706914720591, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 420, train_loss = 0.9760823833348695, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 421, train_loss = 0.975208872318035, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 422, train_loss = 0.9750294859113637, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 423, train_loss = 0.9743033895792905, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 424, train_loss = 0.9733207747340202, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 425, train_loss = 0.9731123757956084, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 426, train_loss = 0.9721788838505745, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 427, train_loss = 0.9723751408455428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 428, train_loss = 0.9714418463408947, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 429, train_loss = 0.9708114328386728, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 430, train_loss = 0.9699209729733411, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 431, train_loss = 0.9699499905109406, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 432, train_loss = 0.9686368865368422, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 433, train_loss = 0.9688238476810511, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 434, train_loss = 0.967504726111656, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 435, train_loss = 0.9675257591006812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 436, train_loss = 0.9665800693037454, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 437, train_loss = 0.9662884138524532, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 438, train_loss = 0.9654586066899356, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 439, train_loss = 0.9650955436227378, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 440, train_loss = 0.9645596320333425, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 441, train_loss = 0.9645688645541668, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 442, train_loss = 0.9636056683957577, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 443, train_loss = 0.9629326438007411, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 444, train_loss = 0.962063405662775, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 445, train_loss = 0.9617877168057021, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 446, train_loss = 0.9616364079120103, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 447, train_loss = 0.9606853561999742, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 448, train_loss = 0.9602133147418499, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 449, train_loss = 0.959479139506584, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 450, train_loss = 0.9597858985362109, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 451, train_loss = 0.9588262513279915, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 452, train_loss = 0.9584518087503966, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 453, train_loss = 0.9575100764632225, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 454, train_loss = 0.9567405010166112, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 455, train_loss = 0.9572607390582561, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 456, train_loss = 0.9561351972224656, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 457, train_loss = 0.9557727264764253, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 458, train_loss = 0.9552876452507917, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 459, train_loss = 0.9548171622154769, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 460, train_loss = 0.9540473222732544, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 461, train_loss = 0.9535156289639417, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 462, train_loss = 0.9531185353698675, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 463, train_loss = 0.952633182198042, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 464, train_loss = 0.9523506201803684, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 465, train_loss = 0.9518236940202769, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 466, train_loss = 0.9514271529915277, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 467, train_loss = 0.9507469621894415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 468, train_loss = 0.950340136885643, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 469, train_loss = 0.9498030220565852, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 470, train_loss = 0.9496101836266462, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 471, train_loss = 0.948544097453123, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 472, train_loss = 0.9482936548592988, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 473, train_loss = 0.9479854057135526, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 474, train_loss = 0.9474594121275004, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 475, train_loss = 0.9466552088561002, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 476, train_loss = 0.946313913911581, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 477, train_loss = 0.9461068498494569, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 478, train_loss = 0.9458102025091648, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 479, train_loss = 0.9446468092501163, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 480, train_loss = 0.944535074144369, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 481, train_loss = 0.9438236579298973, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 482, train_loss = 0.9436296174826566, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 483, train_loss = 0.9426663642225321, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 484, train_loss = 0.9424105944635812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 485, train_loss = 0.9419607023301069, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 486, train_loss = 0.9416003090736922, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 487, train_loss = 0.9408647082746029, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 488, train_loss = 0.9407372412679251, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 489, train_loss = 0.9403298882243689, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 490, train_loss = 0.9398013241589069, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 491, train_loss = 0.9392396236362401, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 492, train_loss = 0.9389078952372074, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 493, train_loss = 0.9383650831878185, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 494, train_loss = 0.9378173773584422, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 495, train_loss = 0.9371839314699173, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 496, train_loss = 0.9372414300742093, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 497, train_loss = 0.9364407087268773, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 498, train_loss = 0.9362868343887385, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 499, train_loss = 0.9353850235638674, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████████████▎                                                 | 9/30 [1:29:35<3:29:54, 599.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "10th- epoch: 0, train_loss = 144.76702085137367, train_acc = 0.7488355845365626\n",
      "test Acc 0.8472998137802608:\n",
      "10th- epoch: 1, train_loss = 55.605603531003, train_acc = 0.8887983232417327\n",
      "test Acc 0.8878026070763501:\n",
      "10th- epoch: 2, train_loss = 39.45965737849474, train_acc = 0.9207033069399162\n",
      "test Acc 0.909683426443203:\n",
      "10th- epoch: 3, train_loss = 31.150475934147835, train_acc = 0.9367722403353517\n",
      "test Acc 0.9250465549348231:\n",
      "10th- epoch: 4, train_loss = 25.972970850765705, train_acc = 0.9460875640428504\n",
      "test Acc 0.9343575418994413:\n",
      "10th- epoch: 5, train_loss = 22.383294969797134, train_acc = 0.9557522123893806\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 6, train_loss = 19.71737538650632, train_acc = 0.961690731252911\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 7, train_loss = 17.630961552262306, train_acc = 0.9651839776432231\n",
      "test Acc 0.9492551210428305:\n",
      "10th- epoch: 8, train_loss = 15.952043902128935, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "10th- epoch: 9, train_loss = 14.562713455408812, train_acc = 0.9721704704238472\n",
      "test Acc 0.9511173184357542:\n",
      "10th- epoch: 10, train_loss = 13.389493901282549, train_acc = 0.975314392175128\n",
      "test Acc 0.9534450651769087:\n",
      "10th- epoch: 11, train_loss = 12.381784662604332, train_acc = 0.9778761061946902\n",
      "test Acc 0.9553072625698324:\n",
      "10th- epoch: 12, train_loss = 11.502974312752485, train_acc = 0.9795062878435026\n",
      "test Acc 0.9567039106145251:\n",
      "10th- epoch: 13, train_loss = 10.728666266426444, train_acc = 0.9813693525850024\n",
      "test Acc 0.957635009310987:\n",
      "10th- epoch: 14, train_loss = 10.044018095359206, train_acc = 0.9826502095947834\n",
      "test Acc 0.9585661080074488:\n",
      "10th- epoch: 15, train_loss = 9.43405975215137, train_acc = 0.9833488588728458\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 16, train_loss = 8.891280518844724, train_acc = 0.9842803912435957\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 17, train_loss = 8.402367066591978, train_acc = 0.9857941313460643\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 18, train_loss = 7.960645625367761, train_acc = 0.9866092221704704\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 19, train_loss = 7.560534754768014, train_acc = 0.9873078714485328\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 20, train_loss = 7.197670208290219, train_acc = 0.9876571960875641\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 21, train_loss = 6.869216980412602, train_acc = 0.9882394038192828\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 22, train_loss = 6.566758219152689, train_acc = 0.9887051700046576\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 23, train_loss = 6.289407404139638, train_acc = 0.9896367023754076\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 24, train_loss = 6.034743539988995, train_acc = 0.989869585468095\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 25, train_loss = 5.794572465121746, train_acc = 0.9904517931998137\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 26, train_loss = 5.572293029166758, train_acc = 0.9910340009315324\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 27, train_loss = 5.368422648869455, train_acc = 0.9913833255705635\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 28, train_loss = 5.178132287226617, train_acc = 0.992081974848626\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 29, train_loss = 5.003243054263294, train_acc = 0.9925477410340009\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 30, train_loss = 4.8379680616781116, train_acc = 0.9927806241266884\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 31, train_loss = 4.682136437855661, train_acc = 0.9932463903120633\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 32, train_loss = 4.540668428875506, train_acc = 0.9932463903120633\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 33, train_loss = 4.404172425158322, train_acc = 0.9939450395901258\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 34, train_loss = 4.277619822882116, train_acc = 0.9940614811364695\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 35, train_loss = 4.15835481043905, train_acc = 0.9945272473218444\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 36, train_loss = 4.043977388180792, train_acc = 0.9945272473218444\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 37, train_loss = 3.937130104750395, train_acc = 0.9946436888681882\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 38, train_loss = 3.8356050327420235, train_acc = 0.9946436888681882\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 39, train_loss = 3.739257159642875, train_acc = 0.9946436888681882\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 40, train_loss = 3.6475151432678103, train_acc = 0.9947601304145319\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 41, train_loss = 3.5617244383320212, train_acc = 0.9949930135072194\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 42, train_loss = 3.478001897223294, train_acc = 0.9949930135072194\n",
      "test Acc 0.9664804469273743:\n",
      "10th- epoch: 43, train_loss = 3.3990255212411284, train_acc = 0.9949930135072194\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 44, train_loss = 3.323917326517403, train_acc = 0.9949930135072194\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 45, train_loss = 3.2519043125212193, train_acc = 0.9949930135072194\n",
      "test Acc 0.9664804469273743:\n",
      "10th- epoch: 46, train_loss = 3.183086061384529, train_acc = 0.9949930135072194\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 47, train_loss = 3.118337217718363, train_acc = 0.9951094550535631\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 48, train_loss = 3.0557584427297115, train_acc = 0.9951094550535631\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 49, train_loss = 2.9971569404006004, train_acc = 0.9951094550535631\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 50, train_loss = 2.9417825913988054, train_acc = 0.9952258965999069\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 51, train_loss = 2.8882965608499944, train_acc = 0.9952258965999069\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 52, train_loss = 2.8369741127826273, train_acc = 0.9953423381462506\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 53, train_loss = 2.7882690192200243, train_acc = 0.9953423381462506\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 54, train_loss = 2.741295470390469, train_acc = 0.9954587796925943\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 55, train_loss = 2.6979938969016075, train_acc = 0.995575221238938\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 56, train_loss = 2.6559103652834892, train_acc = 0.9956916627852818\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 57, train_loss = 2.6154810138978064, train_acc = 0.9956916627852818\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 58, train_loss = 2.577012103050947, train_acc = 0.9956916627852818\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 59, train_loss = 2.5399207160808146, train_acc = 0.996040987424313\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 60, train_loss = 2.5041579850949347, train_acc = 0.996040987424313\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 61, train_loss = 2.4705160818994045, train_acc = 0.9961574289706567\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 62, train_loss = 2.4380532279610634, train_acc = 0.9961574289706567\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 63, train_loss = 2.406743539031595, train_acc = 0.9962738705170004\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 64, train_loss = 2.3755328371189535, train_acc = 0.9962738705170004\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 65, train_loss = 2.3471693373285234, train_acc = 0.9962738705170004\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 66, train_loss = 2.318746490869671, train_acc = 0.9962738705170004\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 67, train_loss = 2.2915214709937572, train_acc = 0.9962738705170004\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 68, train_loss = 2.2656798847019672, train_acc = 0.9963903120633442\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 69, train_loss = 2.2410414018668234, train_acc = 0.9963903120633442\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 70, train_loss = 2.2165126889012754, train_acc = 0.9963903120633442\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 71, train_loss = 2.1931657269597054, train_acc = 0.9963903120633442\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 72, train_loss = 2.170142747461796, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 73, train_loss = 2.148594373371452, train_acc = 0.996506753609688\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 74, train_loss = 2.1269443915225565, train_acc = 0.996506753609688\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 75, train_loss = 2.106982314493507, train_acc = 0.996506753609688\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 76, train_loss = 2.086193809751421, train_acc = 0.996506753609688\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 77, train_loss = 2.066900270525366, train_acc = 0.996506753609688\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 78, train_loss = 2.0479133552871644, train_acc = 0.996506753609688\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 79, train_loss = 2.030029822140932, train_acc = 0.9967396367023754\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 80, train_loss = 2.0118150289636105, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 81, train_loss = 1.9950405496638268, train_acc = 0.9967396367023754\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 82, train_loss = 1.9790600549895316, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 83, train_loss = 1.9618621717672795, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 84, train_loss = 1.9462290580850095, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 85, train_loss = 1.9309979006648064, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 86, train_loss = 1.9155412700492889, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 87, train_loss = 1.9010699193459004, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 88, train_loss = 1.8868728626985103, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 89, train_loss = 1.872621702728793, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 90, train_loss = 1.8593880098778754, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 91, train_loss = 1.8463201485574245, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 92, train_loss = 1.8345241285860538, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 93, train_loss = 1.821894809603691, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 94, train_loss = 1.809480344178155, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 95, train_loss = 1.7984941948670894, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 96, train_loss = 1.7868813339155167, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 97, train_loss = 1.7762711755931377, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 98, train_loss = 1.7651857670862228, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 99, train_loss = 1.7546933591365814, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 100, train_loss = 1.7440910376608372, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 101, train_loss = 1.7345349986571819, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 102, train_loss = 1.7244890395086259, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 103, train_loss = 1.714980473043397, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 104, train_loss = 1.7055582378525287, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 105, train_loss = 1.6964030016679317, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 106, train_loss = 1.6875199440401047, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 107, train_loss = 1.6784198954701424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 108, train_loss = 1.6699499960523099, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 109, train_loss = 1.6616773542482406, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 110, train_loss = 1.6536553737241775, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 111, train_loss = 1.6454004619736224, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 112, train_loss = 1.6378304213285446, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 113, train_loss = 1.629844990791753, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 114, train_loss = 1.6224482122343034, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 115, train_loss = 1.6149699289817363, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 116, train_loss = 1.6076029427349567, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 117, train_loss = 1.6009820986073464, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 118, train_loss = 1.5936975926160812, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 119, train_loss = 1.5872774086892605, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 120, train_loss = 1.580797714414075, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 121, train_loss = 1.573840296594426, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 122, train_loss = 1.56737548741512, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 123, train_loss = 1.560953865526244, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 124, train_loss = 1.554782272549346, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 125, train_loss = 1.5486475203651935, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 126, train_loss = 1.5426158346235752, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 127, train_loss = 1.5363848928827792, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 128, train_loss = 1.5308751736301929, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 129, train_loss = 1.524913001805544, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 130, train_loss = 1.5192954812664539, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 131, train_loss = 1.5137912258505821, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 132, train_loss = 1.5081025722902268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 133, train_loss = 1.502614197670482, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 134, train_loss = 1.4975875417003408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 135, train_loss = 1.4918209202587605, train_acc = 0.9973218444340941\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 136, train_loss = 1.486914606182836, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 137, train_loss = 1.4818595573306084, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 138, train_loss = 1.4768527746200562, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 139, train_loss = 1.4716861931374297, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 140, train_loss = 1.4666357450187206, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 141, train_loss = 1.4620862863957882, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 142, train_loss = 1.4574324302375317, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 143, train_loss = 1.452838016091846, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 144, train_loss = 1.4480273524532095, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 145, train_loss = 1.443713710992597, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 146, train_loss = 1.4390854351222515, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 147, train_loss = 1.4348467104136944, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 148, train_loss = 1.4303906025597826, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 149, train_loss = 1.426138355047442, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 150, train_loss = 1.4222035048296675, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 151, train_loss = 1.4179262655088678, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 152, train_loss = 1.4137486839899793, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 153, train_loss = 1.4100199131062254, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 154, train_loss = 1.4058332095155492, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 155, train_loss = 1.4017802067101002, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 156, train_loss = 1.3980821954319254, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 157, train_loss = 1.3941856423625723, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 158, train_loss = 1.3903680170187727, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 159, train_loss = 1.3866175723960623, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 160, train_loss = 1.383011519908905, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 161, train_loss = 1.3794007463147864, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 162, train_loss = 1.375771228224039, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 163, train_loss = 1.3718880526721478, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 164, train_loss = 1.3686300106346607, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 165, train_loss = 1.3650901006767526, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 166, train_loss = 1.3618966018548235, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 167, train_loss = 1.3583228066563606, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 168, train_loss = 1.3551815077662468, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 169, train_loss = 1.3517294885823503, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 170, train_loss = 1.3482718417653814, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 171, train_loss = 1.3449346907436848, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 172, train_loss = 1.3421143343439326, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 173, train_loss = 1.3386778173735365, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 174, train_loss = 1.335688297986053, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 175, train_loss = 1.3324739733943716, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 176, train_loss = 1.329782895743847, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 177, train_loss = 1.3264186196029186, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 178, train_loss = 1.323651303886436, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 179, train_loss = 1.3206687718629837, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 180, train_loss = 1.3177160086343065, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 181, train_loss = 1.3148697527358308, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 182, train_loss = 1.3122432479867712, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 183, train_loss = 1.3093969089677557, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 184, train_loss = 1.306223971187137, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 185, train_loss = 1.303613219410181, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 186, train_loss = 1.3006624380359426, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 187, train_loss = 1.2983095273375511, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 188, train_loss = 1.2954471918055788, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 189, train_loss = 1.2928431890904903, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 190, train_loss = 1.2900830482831225, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 191, train_loss = 1.2876456441590562, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 192, train_loss = 1.2852707915008068, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 193, train_loss = 1.282586745917797, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 194, train_loss = 1.279833436012268, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 195, train_loss = 1.2778391875326633, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 196, train_loss = 1.2752317463746294, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 197, train_loss = 1.2728686643531546, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 198, train_loss = 1.270092036575079, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 199, train_loss = 1.2680692920694128, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 200, train_loss = 1.2655199505388737, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 201, train_loss = 1.2631594961276278, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 202, train_loss = 1.2609255561837927, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 203, train_loss = 1.2586149933049455, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 204, train_loss = 1.2562281092396006, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 205, train_loss = 1.2540761455893517, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 206, train_loss = 1.2517801076173782, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 207, train_loss = 1.249376611202024, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 208, train_loss = 1.2473110258579254, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 209, train_loss = 1.2451839037239552, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 210, train_loss = 1.2430032951524481, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 211, train_loss = 1.24095221364405, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 212, train_loss = 1.238692550570704, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 213, train_loss = 1.2365491762757301, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 214, train_loss = 1.2344346158206463, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 215, train_loss = 1.2325038401177153, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 216, train_loss = 1.230248792679049, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 217, train_loss = 1.2281652465462685, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 218, train_loss = 1.2264829674968496, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 219, train_loss = 1.2240299818804488, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 220, train_loss = 1.222316181869246, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 221, train_loss = 1.2200263775885105, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 222, train_loss = 1.21807385107968, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 223, train_loss = 1.216503705829382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 224, train_loss = 1.214394481270574, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 225, train_loss = 1.2124339379370213, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 226, train_loss = 1.2105139853665605, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 227, train_loss = 1.208852997631766, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 228, train_loss = 1.2066484777024016, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 229, train_loss = 1.2048923186957836, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 230, train_loss = 1.2031034280662425, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 231, train_loss = 1.2013204817776568, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 232, train_loss = 1.199315072328318, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 233, train_loss = 1.1975150667130947, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 234, train_loss = 1.1958089731633663, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 235, train_loss = 1.1939198139007203, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 236, train_loss = 1.1918628526036628, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 237, train_loss = 1.1903003938496113, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 238, train_loss = 1.1885129014845006, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 239, train_loss = 1.1868532113730907, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 240, train_loss = 1.1853102147579193, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 241, train_loss = 1.1833764600451104, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 242, train_loss = 1.1818586997687817, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 243, train_loss = 1.180085985630285, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 244, train_loss = 1.1785484601859935, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 245, train_loss = 1.1766922262613662, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 246, train_loss = 1.1749004386365414, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 247, train_loss = 1.1735838701133616, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 248, train_loss = 1.1720615004305728, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 249, train_loss = 1.170273022085894, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 250, train_loss = 1.1688124487991445, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 251, train_loss = 1.1671169002656825, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 252, train_loss = 1.1654047991032712, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 253, train_loss = 1.1635757175390609, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 254, train_loss = 1.1619523229892366, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 255, train_loss = 1.160650027275551, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 256, train_loss = 1.158978495746851, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 257, train_loss = 1.1574581898748875, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 258, train_loss = 1.156108919531107, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 259, train_loss = 1.1543447102303617, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 260, train_loss = 1.1529357408289798, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 261, train_loss = 1.1513143318588845, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 262, train_loss = 1.1502665144507773, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 263, train_loss = 1.1489646447007544, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 264, train_loss = 1.1473666715319268, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 265, train_loss = 1.1457171377842315, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 266, train_loss = 1.144660870253574, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 267, train_loss = 1.1430562597815879, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 268, train_loss = 1.141727960377466, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 269, train_loss = 1.1403299644589424, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 270, train_loss = 1.1391532681882381, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 271, train_loss = 1.1374880994553678, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 272, train_loss = 1.136576745659113, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 273, train_loss = 1.1348027847707272, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 274, train_loss = 1.133788478851784, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 275, train_loss = 1.1323001608252525, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 276, train_loss = 1.1310741926427, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 277, train_loss = 1.129641289531719, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 278, train_loss = 1.1286493602092378, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 279, train_loss = 1.1273135666851886, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 280, train_loss = 1.1263020895421505, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 281, train_loss = 1.1247339956462383, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 282, train_loss = 1.1235869551892392, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 283, train_loss = 1.1223903087084182, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 284, train_loss = 1.1210739091038704, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 285, train_loss = 1.1201376940007322, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 286, train_loss = 1.1187374467845075, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 287, train_loss = 1.117488730698824, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 288, train_loss = 1.1160007119178772, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 289, train_loss = 1.1146647644345649, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 290, train_loss = 1.1135163095896132, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 291, train_loss = 1.1120619587600231, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 292, train_loss = 1.110643457621336, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 293, train_loss = 1.1091866567730904, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 294, train_loss = 1.10754680755781, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 295, train_loss = 1.1065675057470798, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 296, train_loss = 1.1048610706930049, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 297, train_loss = 1.1041828629677184, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 298, train_loss = 1.102978394657839, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 299, train_loss = 1.1017867836053483, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 300, train_loss = 1.1008804142475128, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 301, train_loss = 1.0995674940641038, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 302, train_loss = 1.0984164873952977, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 303, train_loss = 1.097356193989981, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 304, train_loss = 1.0962721804971807, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 305, train_loss = 1.095224243879784, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 306, train_loss = 1.0941807590425014, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 307, train_loss = 1.0929681546986103, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 308, train_loss = 1.0919837926630862, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 309, train_loss = 1.090916511893738, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 310, train_loss = 1.0897782991523854, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 311, train_loss = 1.0890753716230392, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 312, train_loss = 1.0881825014948845, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 313, train_loss = 1.0867999643087387, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 314, train_loss = 1.0859043871168979, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 315, train_loss = 1.0849559133057483, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 316, train_loss = 1.083706010133028, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 317, train_loss = 1.0829470083117485, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 318, train_loss = 1.082150914997328, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 319, train_loss = 1.0809070554678328, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 320, train_loss = 1.0801162931020372, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 321, train_loss = 1.0789656614069827, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 322, train_loss = 1.078093824267853, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 323, train_loss = 1.077296468138229, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 324, train_loss = 1.0762292928993702, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 325, train_loss = 1.075384795665741, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 326, train_loss = 1.0742007866501808, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 327, train_loss = 1.0733895562589169, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 328, train_loss = 1.0725848712027073, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 329, train_loss = 1.0714722673292272, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 330, train_loss = 1.0709021426737309, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 331, train_loss = 1.0697271786630154, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 332, train_loss = 1.069168969988823, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 333, train_loss = 1.068079899996519, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 334, train_loss = 1.0668849435751326, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 335, train_loss = 1.0663393859867938, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 336, train_loss = 1.0652357314829715, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 337, train_loss = 1.0642698307638057, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 338, train_loss = 1.0634531304240227, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 339, train_loss = 1.0627370774745941, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 340, train_loss = 1.0619475580751896, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 341, train_loss = 1.0607204672996886, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 342, train_loss = 1.0601764544844627, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 343, train_loss = 1.0593256975407712, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 344, train_loss = 1.0584947789902799, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 345, train_loss = 1.0573799175326712, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 346, train_loss = 1.0570011014933698, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 347, train_loss = 1.0559738762676716, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 348, train_loss = 1.0551858742837794, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 349, train_loss = 1.054002312303055, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 350, train_loss = 1.0533069930970669, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 351, train_loss = 1.0526510812342167, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 352, train_loss = 1.0519990573520772, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 353, train_loss = 1.0510539909009822, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 354, train_loss = 1.0499436110258102, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 355, train_loss = 1.0491990260779858, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 356, train_loss = 1.0489418183569796, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 357, train_loss = 1.0477172595565207, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 358, train_loss = 1.0468945006723516, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 359, train_loss = 1.0459702697698958, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 360, train_loss = 1.045320514589548, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 361, train_loss = 1.044517207890749, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 362, train_loss = 1.0438073227996938, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 363, train_loss = 1.0430652126669884, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 364, train_loss = 1.0424123667180538, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 365, train_loss = 1.0414755679666996, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 366, train_loss = 1.040668811649084, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 367, train_loss = 1.0400590958888642, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 368, train_loss = 1.0393470923299901, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 369, train_loss = 1.0385139646823518, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 370, train_loss = 1.037691703706514, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 371, train_loss = 1.0368871639366262, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 372, train_loss = 1.0362463245983236, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 373, train_loss = 1.0354738284950145, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 374, train_loss = 1.0347024761140347, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 375, train_loss = 1.0339004658162594, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 376, train_loss = 1.0331576180760749, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 377, train_loss = 1.032561258703936, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 378, train_loss = 1.0319175571203232, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 379, train_loss = 1.0310963988304138, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 380, train_loss = 1.030377818911802, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 381, train_loss = 1.0296757891774178, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 382, train_loss = 1.028930090367794, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 383, train_loss = 1.028504554182291, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 384, train_loss = 1.0274878405034542, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 385, train_loss = 1.0269063487648964, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 386, train_loss = 1.0259840761427768, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 387, train_loss = 1.0254507971112616, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 388, train_loss = 1.0249162577092648, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 389, train_loss = 1.0240279945428483, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 390, train_loss = 1.023335736244917, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 391, train_loss = 1.022952278435696, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 392, train_loss = 1.0220651105046272, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 393, train_loss = 1.0215340480208397, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 394, train_loss = 1.0205380928819068, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 395, train_loss = 1.020092397928238, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 396, train_loss = 1.0193012319505215, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 397, train_loss = 1.0188591964542866, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 398, train_loss = 1.018032251537079, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 399, train_loss = 1.0173572078347206, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 400, train_loss = 1.0169834668340627, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 401, train_loss = 1.0159291277232114, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 402, train_loss = 1.0155362834630068, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 403, train_loss = 1.014958637446398, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 404, train_loss = 1.0139229968190193, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 405, train_loss = 1.0134905092418194, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 406, train_loss = 1.01305722197867, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 407, train_loss = 1.0121241932210978, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 408, train_loss = 1.011449677258497, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 409, train_loss = 1.0108608665468637, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 410, train_loss = 1.0103244582714979, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 411, train_loss = 1.0096030297281686, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 412, train_loss = 1.0087018994090613, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 413, train_loss = 1.0084089214506093, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 414, train_loss = 1.0080013237893581, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 415, train_loss = 1.0073682194051798, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 416, train_loss = 1.0066237313149031, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 417, train_loss = 1.0058256486954633, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 418, train_loss = 1.0055141958000604, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 419, train_loss = 1.0043958649039268, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 420, train_loss = 1.0043663966062013, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 421, train_loss = 1.0034640853700694, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 422, train_loss = 1.0025679543614388, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 423, train_loss = 1.002371375769144, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 424, train_loss = 1.0018699405191, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 425, train_loss = 1.0007405020296574, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 426, train_loss = 1.0006660831568297, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 427, train_loss = 0.9997542525234167, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 428, train_loss = 0.9991035299899522, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 429, train_loss = 0.9989674476382788, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 430, train_loss = 0.9979620948433876, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 431, train_loss = 0.9975905741157476, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 432, train_loss = 0.9969664663076401, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 433, train_loss = 0.9966594552097376, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 434, train_loss = 0.9962959438562393, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 435, train_loss = 0.9950530069472734, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 436, train_loss = 0.9948456063866615, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 437, train_loss = 0.9943390550615732, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 438, train_loss = 0.993500859796768, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 439, train_loss = 0.9930213466286659, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 440, train_loss = 0.99276409423328, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 441, train_loss = 0.9920995458960533, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 442, train_loss = 0.9914227873086929, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 443, train_loss = 0.9906331822276115, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 444, train_loss = 0.9902342719433364, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 445, train_loss = 0.9895072045328561, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 446, train_loss = 0.9892958005366381, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 447, train_loss = 0.9886054011585657, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 448, train_loss = 0.9880277551710606, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 449, train_loss = 0.9877637326717377, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 450, train_loss = 0.9875293374061584, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 451, train_loss = 0.9861626153287943, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 452, train_loss = 0.9860018379986286, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 453, train_loss = 0.9851296730339527, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 454, train_loss = 0.9852059123513754, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 455, train_loss = 0.9842995591461658, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 456, train_loss = 0.9838711755874101, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 457, train_loss = 0.9834079866704997, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 458, train_loss = 0.9829395549895708, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 459, train_loss = 0.9825893541274127, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 460, train_loss = 0.9816408219339792, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 461, train_loss = 0.9815222347679082, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 462, train_loss = 0.980625102907652, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 463, train_loss = 0.9802659700217191, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 464, train_loss = 0.9801609528658446, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 465, train_loss = 0.9790578410029411, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 466, train_loss = 0.9789680925605353, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 467, train_loss = 0.9782546311616898, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 468, train_loss = 0.9778875919582788, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 469, train_loss = 0.9773827964963857, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 470, train_loss = 0.9771121392550413, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 471, train_loss = 0.9760311978461687, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 472, train_loss = 0.9758945306239184, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 473, train_loss = 0.9751608346996363, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 474, train_loss = 0.9743785808386747, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 475, train_loss = 0.9746922900376376, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 476, train_loss = 0.9735604822635651, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 477, train_loss = 0.9732243070902769, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 478, train_loss = 0.9728719691338483, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 479, train_loss = 0.9724283342657145, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 480, train_loss = 0.9715834905800875, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 481, train_loss = 0.9715820687415544, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 482, train_loss = 0.9708711033163127, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 483, train_loss = 0.9702226991357747, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 484, train_loss = 0.9700631586310919, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 485, train_loss = 0.9694303944706917, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 486, train_loss = 0.969053216278553, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 487, train_loss = 0.9688000380992889, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 488, train_loss = 0.9678220599889755, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 489, train_loss = 0.9672752022743225, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 490, train_loss = 0.9671241504547652, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 491, train_loss = 0.9668214147386607, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 492, train_loss = 0.9666084870696068, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 493, train_loss = 0.9654527145030443, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 494, train_loss = 0.9654190490546171, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 495, train_loss = 0.9648575844767038, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 496, train_loss = 0.9642142491939012, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 497, train_loss = 0.9639204057457391, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 498, train_loss = 0.9635790871980134, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 499, train_loss = 0.9626361007394735, train_acc = 0.9977876106194691\n",
      "test Acc 0.972998137802607:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████▎                                              | 10/30 [1:39:37<3:20:10, 600.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "11th- epoch: 0, train_loss = 126.04840872436762, train_acc = 0.7611783884489987\n",
      "test Acc 0.8621973929236499:\n",
      "11th- epoch: 1, train_loss = 52.50549767538905, train_acc = 0.891243595714951\n",
      "test Acc 0.9050279329608939:\n",
      "11th- epoch: 2, train_loss = 37.70993671193719, train_acc = 0.9241965533302282\n",
      "test Acc 0.9217877094972067:\n",
      "11th- epoch: 3, train_loss = 30.092312321066856, train_acc = 0.9373544480670704\n",
      "test Acc 0.9273743016759777:\n",
      "11th- epoch: 4, train_loss = 25.137697216123343, train_acc = 0.9477177456916628\n",
      "test Acc 0.9343575418994413:\n",
      "11th- epoch: 5, train_loss = 21.60839789547026, train_acc = 0.9549371215649743\n",
      "test Acc 0.9376163873370578:\n",
      "11th- epoch: 6, train_loss = 18.954469503834844, train_acc = 0.9601769911504425\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 7, train_loss = 16.90198810584843, train_acc = 0.9651839776432231\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 8, train_loss = 15.256926208734512, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "11th- epoch: 9, train_loss = 13.898889085277915, train_acc = 0.9725197950628784\n",
      "test Acc 0.9515828677839852:\n",
      "11th- epoch: 10, train_loss = 12.770036859437823, train_acc = 0.9749650675360969\n",
      "test Acc 0.9539106145251397:\n",
      "11th- epoch: 11, train_loss = 11.80110253766179, train_acc = 0.9774103400093154\n",
      "test Acc 0.9557728119180633:\n",
      "11th- epoch: 12, train_loss = 10.962266622111201, train_acc = 0.9799720540288775\n",
      "test Acc 0.9557728119180633:\n",
      "11th- epoch: 13, train_loss = 10.229363599792123, train_acc = 0.9812529110386586\n",
      "test Acc 0.9581005586592178:\n",
      "11th- epoch: 14, train_loss = 9.585896937176585, train_acc = 0.9824173265020959\n",
      "test Acc 0.9581005586592178:\n",
      "11th- epoch: 15, train_loss = 9.007906017825007, train_acc = 0.984163949697252\n",
      "test Acc 0.9590316573556797:\n",
      "11th- epoch: 16, train_loss = 8.496734853833914, train_acc = 0.9852119236143456\n",
      "test Acc 0.9590316573556797:\n",
      "11th- epoch: 17, train_loss = 8.03709170781076, train_acc = 0.9861434559850955\n",
      "test Acc 0.9608938547486033:\n",
      "11th- epoch: 18, train_loss = 7.62535341270268, train_acc = 0.9870749883558454\n",
      "test Acc 0.9608938547486033:\n",
      "11th- epoch: 19, train_loss = 7.255354581400752, train_acc = 0.9882394038192828\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 20, train_loss = 6.920989817008376, train_acc = 0.9891709361900326\n",
      "test Acc 0.9608938547486033:\n",
      "11th- epoch: 21, train_loss = 6.616770513355732, train_acc = 0.9901024685607824\n",
      "test Acc 0.9608938547486033:\n",
      "11th- epoch: 22, train_loss = 6.3409685008227825, train_acc = 0.9904517931998137\n",
      "test Acc 0.9604283054003724:\n",
      "11th- epoch: 23, train_loss = 6.087418464943767, train_acc = 0.9910340009315324\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 24, train_loss = 5.854639574885368, train_acc = 0.9910340009315324\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 25, train_loss = 5.6377065777778625, train_acc = 0.9912668840242198\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 26, train_loss = 5.436316791921854, train_acc = 0.9916162086632511\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 27, train_loss = 5.246902398765087, train_acc = 0.9919655333022822\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 28, train_loss = 5.0694796070456505, train_acc = 0.9923148579413135\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 29, train_loss = 4.907298341393471, train_acc = 0.9927806241266884\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 30, train_loss = 4.758865125477314, train_acc = 0.9928970656730322\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 31, train_loss = 4.614082301035523, train_acc = 0.9931299487657196\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 32, train_loss = 4.483911233022809, train_acc = 0.9934792734047508\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 33, train_loss = 4.357253318652511, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 34, train_loss = 4.240795247256756, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 35, train_loss = 4.127352509647608, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 36, train_loss = 4.024561883881688, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 37, train_loss = 3.9246034305542707, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 38, train_loss = 3.8312155148014426, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 39, train_loss = 3.7412076899781823, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 40, train_loss = 3.6566809099167585, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 41, train_loss = 3.576130809262395, train_acc = 0.9947601304145319\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 42, train_loss = 3.498279138468206, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 43, train_loss = 3.426373280584812, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 44, train_loss = 3.3567882403731346, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 45, train_loss = 3.288614113815129, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 46, train_loss = 3.226811691187322, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 47, train_loss = 3.165129903703928, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "11th- epoch: 48, train_loss = 3.1057748151943088, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 49, train_loss = 3.049825460650027, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 50, train_loss = 2.9965815590694547, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 51, train_loss = 2.946154692210257, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 52, train_loss = 2.8978894725441933, train_acc = 0.995575221238938\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 53, train_loss = 2.850019194185734, train_acc = 0.995575221238938\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 54, train_loss = 2.8068903936073184, train_acc = 0.9956916627852818\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 55, train_loss = 2.7628882555291057, train_acc = 0.9958081043316255\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 56, train_loss = 2.722230192273855, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 57, train_loss = 2.6821446707472205, train_acc = 0.9959245458779693\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 58, train_loss = 2.6438451521098614, train_acc = 0.9959245458779693\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 59, train_loss = 2.6068692998960614, train_acc = 0.9959245458779693\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 60, train_loss = 2.5713171055540442, train_acc = 0.9959245458779693\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 61, train_loss = 2.5373081071302295, train_acc = 0.9959245458779693\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 62, train_loss = 2.504232242703438, train_acc = 0.9959245458779693\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 63, train_loss = 2.471791715826839, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 64, train_loss = 2.4413127875886858, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 65, train_loss = 2.4111894429661334, train_acc = 0.9962738705170004\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 66, train_loss = 2.3834493295289576, train_acc = 0.9963903120633442\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 67, train_loss = 2.354788926895708, train_acc = 0.9963903120633442\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 68, train_loss = 2.327565116342157, train_acc = 0.9963903120633442\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 69, train_loss = 2.3020468689501286, train_acc = 0.9963903120633442\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 70, train_loss = 2.276219639927149, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 71, train_loss = 2.2509952732361853, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 72, train_loss = 2.2287355922162533, train_acc = 0.9966231951560317\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 73, train_loss = 2.2046929225325584, train_acc = 0.9966231951560317\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 74, train_loss = 2.1815515905618668, train_acc = 0.9966231951560317\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 75, train_loss = 2.1605771989561617, train_acc = 0.9966231951560317\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 76, train_loss = 2.139298672322184, train_acc = 0.9966231951560317\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 77, train_loss = 2.1184831708669662, train_acc = 0.9969725197950629\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 78, train_loss = 2.099112255964428, train_acc = 0.9969725197950629\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 79, train_loss = 2.079435110092163, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 80, train_loss = 2.0602464713156223, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 81, train_loss = 2.0428092717193067, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 82, train_loss = 2.024207518901676, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 83, train_loss = 2.00737581634894, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 84, train_loss = 1.9906515963375568, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 85, train_loss = 1.9742561117745936, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 86, train_loss = 1.9586361558176577, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 87, train_loss = 1.9432287812232971, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 88, train_loss = 1.9279739619232714, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 89, train_loss = 1.9139285162091255, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 90, train_loss = 1.9000193453393877, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 91, train_loss = 1.885365005582571, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 92, train_loss = 1.8726394474506378, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 93, train_loss = 1.8594175851903856, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 94, train_loss = 1.8471137075684965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 95, train_loss = 1.8342727173585445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 96, train_loss = 1.8227558720391244, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 97, train_loss = 1.8110044859349728, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 98, train_loss = 1.8000099062919617, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 99, train_loss = 1.788005817681551, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 100, train_loss = 1.7771103356499225, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 101, train_loss = 1.7669559952337295, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 102, train_loss = 1.756338259903714, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 103, train_loss = 1.7460965774953365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 104, train_loss = 1.7362464603502303, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 105, train_loss = 1.7265960935037583, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 106, train_loss = 1.7170806105714291, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 107, train_loss = 1.7075883969664574, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 108, train_loss = 1.6976691621821374, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 109, train_loss = 1.6892355654854327, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 110, train_loss = 1.680166244506836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 111, train_loss = 1.671310445992276, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 112, train_loss = 1.6637055787723511, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 113, train_loss = 1.655094848247245, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 114, train_loss = 1.6476324833929539, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 115, train_loss = 1.6389351275283843, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 116, train_loss = 1.631258602021262, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 117, train_loss = 1.6242486350238323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 118, train_loss = 1.616054743528366, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 119, train_loss = 1.6093800589442253, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 120, train_loss = 1.601752683520317, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 121, train_loss = 1.594944865675643, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 122, train_loss = 1.5879560608882457, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 123, train_loss = 1.5811072897631675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 124, train_loss = 1.5745917956810445, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 125, train_loss = 1.5677351120393723, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 126, train_loss = 1.5616365782916546, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 127, train_loss = 1.5553435522597283, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 128, train_loss = 1.5488398622255772, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 129, train_loss = 1.5427111361641437, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 130, train_loss = 1.5370059076230973, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 131, train_loss = 1.5309501539450139, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 132, train_loss = 1.5250980146229267, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 133, train_loss = 1.5189614680130035, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 134, train_loss = 1.5140648384112865, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 135, train_loss = 1.5079175904393196, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 136, train_loss = 1.502214252948761, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 137, train_loss = 1.4969193898141384, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 138, train_loss = 1.4911127958912402, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 139, train_loss = 1.4864475193899125, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 140, train_loss = 1.4810796317178756, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 141, train_loss = 1.4761742923874408, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 142, train_loss = 1.470697705866769, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 143, train_loss = 1.4657515448052436, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 144, train_loss = 1.4609125144779682, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 145, train_loss = 1.45642449951265, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 146, train_loss = 1.4516100771725178, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 147, train_loss = 1.446702758432366, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 148, train_loss = 1.4418469741940498, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 149, train_loss = 1.4383937617531046, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 150, train_loss = 1.4325105609605089, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 151, train_loss = 1.4291678642621264, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 152, train_loss = 1.4243440827121958, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 153, train_loss = 1.4202794581651688, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 154, train_loss = 1.416403436451219, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 155, train_loss = 1.4116050464799628, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 156, train_loss = 1.4072917476296425, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 157, train_loss = 1.4031244019279256, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 158, train_loss = 1.3990661191055551, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 159, train_loss = 1.3948551391949877, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 160, train_loss = 1.3913513807347044, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 161, train_loss = 1.3872967002680525, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 162, train_loss = 1.3830398867139593, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 163, train_loss = 1.3793127039680257, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 164, train_loss = 1.3757069060811773, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 165, train_loss = 1.3720658185193315, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 166, train_loss = 1.3680901862680912, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 167, train_loss = 1.3644006053218618, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 168, train_loss = 1.3607318624854088, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 169, train_loss = 1.3573345044860616, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 170, train_loss = 1.3534017466008663, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 171, train_loss = 1.3501245900988579, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 172, train_loss = 1.3467496745288372, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 173, train_loss = 1.3430745912482962, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 174, train_loss = 1.3396543338894844, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 175, train_loss = 1.3366109194466844, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 176, train_loss = 1.333076020120643, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 177, train_loss = 1.3299003454158083, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 178, train_loss = 1.3268425427377224, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 179, train_loss = 1.3231083042919636, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 180, train_loss = 1.3200215672841296, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 181, train_loss = 1.317052630125545, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 182, train_loss = 1.3139378888299689, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 183, train_loss = 1.3106199553003535, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 184, train_loss = 1.307586265145801, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 185, train_loss = 1.304182787775062, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 186, train_loss = 1.3017591746756807, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 187, train_loss = 1.2986475167563185, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 188, train_loss = 1.2955833052983508, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 189, train_loss = 1.2927255866816267, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 190, train_loss = 1.2896129550645128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 191, train_loss = 1.2869857227196917, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 192, train_loss = 1.2839800069341436, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 193, train_loss = 1.2810617400100455, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 194, train_loss = 1.2782908864319324, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 195, train_loss = 1.2758446695515886, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 196, train_loss = 1.272809642017819, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 197, train_loss = 1.2703790614614263, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 198, train_loss = 1.268190806149505, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 199, train_loss = 1.2650141393532977, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 200, train_loss = 1.2629325414309278, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 201, train_loss = 1.2601057266583666, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 202, train_loss = 1.2576072290539742, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 203, train_loss = 1.2551403989782557, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 204, train_loss = 1.2528171315789223, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 205, train_loss = 1.249831891269423, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 206, train_loss = 1.247721410007216, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 207, train_loss = 1.2456064621219411, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 208, train_loss = 1.2427584814140573, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 209, train_loss = 1.2406855648150668, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 210, train_loss = 1.2378589982399717, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 211, train_loss = 1.236329149454832, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 212, train_loss = 1.2333765365183353, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 213, train_loss = 1.23175446188543, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 214, train_loss = 1.2287988439202309, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 215, train_loss = 1.227331254631281, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 216, train_loss = 1.2246183032402769, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 217, train_loss = 1.222579836845398, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 218, train_loss = 1.2202944718301296, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 219, train_loss = 1.2177145468303934, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 220, train_loss = 1.2164321752497926, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 221, train_loss = 1.2136005709180608, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 222, train_loss = 1.212230427772738, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 223, train_loss = 1.2090330732171424, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 224, train_loss = 1.2080413128132932, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 225, train_loss = 1.2050644221599214, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 226, train_loss = 1.2038769039209, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 227, train_loss = 1.2009712333674543, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 228, train_loss = 1.1991976673598401, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 229, train_loss = 1.1968863283400424, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 230, train_loss = 1.194741199433338, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 231, train_loss = 1.1924420706927776, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 232, train_loss = 1.1904813324217685, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 233, train_loss = 1.1884611857240088, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 234, train_loss = 1.1862936057150364, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 235, train_loss = 1.1846040723030455, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 236, train_loss = 1.182027683884371, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 237, train_loss = 1.1808306935126893, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 238, train_loss = 1.1787839097087272, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 239, train_loss = 1.1767813575570472, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 240, train_loss = 1.1752497044508345, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 241, train_loss = 1.1729990802705288, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 242, train_loss = 1.171839947521221, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 243, train_loss = 1.1697424339945428, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 244, train_loss = 1.1681939363479614, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 245, train_loss = 1.16611647605896, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 246, train_loss = 1.1645038847927935, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 247, train_loss = 1.1632378933136351, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 248, train_loss = 1.1609290763735771, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 249, train_loss = 1.1598350728745572, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 250, train_loss = 1.1578434656257741, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 251, train_loss = 1.1564319804310799, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 252, train_loss = 1.1543827478890307, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 253, train_loss = 1.1533736760611646, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 254, train_loss = 1.1514218847150914, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 255, train_loss = 1.150097029923927, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 256, train_loss = 1.1486842259764671, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 257, train_loss = 1.1466422975063324, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 258, train_loss = 1.1450762140448205, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 259, train_loss = 1.1439087117905729, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 260, train_loss = 1.1422706941957586, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 261, train_loss = 1.140631340444088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 262, train_loss = 1.1392315638368018, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 263, train_loss = 1.1379422371392138, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 264, train_loss = 1.1362691720132716, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 265, train_loss = 1.1349088450078852, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 266, train_loss = 1.1331721618771553, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 267, train_loss = 1.131848895282019, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 268, train_loss = 1.1303342965547927, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 269, train_loss = 1.1290902110631578, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 270, train_loss = 1.1272833347320557, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 271, train_loss = 1.125690769404173, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 272, train_loss = 1.1247546970844269, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 273, train_loss = 1.1229229420423508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 274, train_loss = 1.1218986548483372, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 275, train_loss = 1.1207002575392835, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 276, train_loss = 1.1190719964797609, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 277, train_loss = 1.117235291749239, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 278, train_loss = 1.1159364667837508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 279, train_loss = 1.1151337039773352, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 280, train_loss = 1.113032966852188, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 281, train_loss = 1.1123123628203757, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 282, train_loss = 1.1104967780411243, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 283, train_loss = 1.10928314429475, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 284, train_loss = 1.1077202136511914, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 285, train_loss = 1.1064624835853465, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 286, train_loss = 1.1052503536338918, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 287, train_loss = 1.1036934864823706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 288, train_loss = 1.1026648941333406, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 289, train_loss = 1.1008804365992546, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 290, train_loss = 1.0999980506603606, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 291, train_loss = 1.0990686801378615, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 292, train_loss = 1.097238791466225, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 293, train_loss = 1.0968148683314212, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 294, train_loss = 1.0946879659895785, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 295, train_loss = 1.0937812837655656, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 296, train_loss = 1.0922860304708593, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 297, train_loss = 1.0914266954059713, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 298, train_loss = 1.089524497569073, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 299, train_loss = 1.088732064992655, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 300, train_loss = 1.08755162358284, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 301, train_loss = 1.0861142563517205, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 302, train_loss = 1.0855049689416774, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 303, train_loss = 1.0842954206163995, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 304, train_loss = 1.082746285945177, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 305, train_loss = 1.0819947781856172, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 306, train_loss = 1.0805963737075217, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 307, train_loss = 1.0790320374071598, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 308, train_loss = 1.0776450261473656, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 309, train_loss = 1.0772717234794982, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 310, train_loss = 1.0759423797135241, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 311, train_loss = 1.0749279881711118, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 312, train_loss = 1.0735184227232821, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 313, train_loss = 1.072634766518604, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 314, train_loss = 1.071390236436855, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 315, train_loss = 1.0708022763137706, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 316, train_loss = 1.0689169193501584, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 317, train_loss = 1.068257812410593, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 318, train_loss = 1.066998792171944, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 319, train_loss = 1.066186085343361, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 320, train_loss = 1.0648745633661747, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 321, train_loss = 1.063979797065258, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 322, train_loss = 1.0625870947842486, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 323, train_loss = 1.0618534808163531, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 324, train_loss = 1.060757327824831, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 325, train_loss = 1.0598441499168985, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 326, train_loss = 1.0586032519931905, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 327, train_loss = 1.0578225068747997, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 328, train_loss = 1.0561448000371456, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 329, train_loss = 1.0559953811462037, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 330, train_loss = 1.0545006158645265, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 331, train_loss = 1.0540826320648193, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 332, train_loss = 1.0527900829911232, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 333, train_loss = 1.0519748466904275, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 334, train_loss = 1.0509443904156797, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 335, train_loss = 1.0502511325175874, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 336, train_loss = 1.0491073367302306, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 337, train_loss = 1.0481959730386734, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 338, train_loss = 1.0469884959165938, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 339, train_loss = 1.0466846364433877, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 340, train_loss = 1.0449516040389426, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 341, train_loss = 1.044758215546608, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 342, train_loss = 1.0433071851730347, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 343, train_loss = 1.0427104507689364, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 344, train_loss = 1.0421215035021305, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 345, train_loss = 1.0406332736311015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 346, train_loss = 1.0404958190920297, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 347, train_loss = 1.038780901581049, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 348, train_loss = 1.038042575120926, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 349, train_loss = 1.0373607414367143, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 350, train_loss = 1.0362282122077886, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 351, train_loss = 1.0359486726520117, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 352, train_loss = 1.0349417974648532, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 353, train_loss = 1.0337279227969702, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 354, train_loss = 1.0327357649803162, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 355, train_loss = 1.0317702442407608, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 356, train_loss = 1.0314537646772806, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 357, train_loss = 1.0301521880028304, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 358, train_loss = 1.0298682724533137, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 359, train_loss = 1.0286444388329983, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 360, train_loss = 1.0280504735710565, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 361, train_loss = 1.027185512095457, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 362, train_loss = 1.026436729967827, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 363, train_loss = 1.0255143803951796, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 364, train_loss = 1.0249237778189126, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 365, train_loss = 1.023569638520712, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 366, train_loss = 1.0233740620315075, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 367, train_loss = 1.0224166437983513, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 368, train_loss = 1.0217417428793851, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 369, train_loss = 1.0205338411033154, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 370, train_loss = 1.0201451828179415, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 371, train_loss = 1.0195407358405646, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 372, train_loss = 1.0183021823468152, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 373, train_loss = 1.017611282557482, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 374, train_loss = 1.0168026549217757, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 375, train_loss = 1.0161228726210538, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 376, train_loss = 1.0156161524355412, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 377, train_loss = 1.014669502765173, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 378, train_loss = 1.0142910915019456, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 379, train_loss = 1.0134741887450218, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 380, train_loss = 1.012709654867649, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 381, train_loss = 1.011687452584738, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 382, train_loss = 1.0109771862626076, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 383, train_loss = 1.0105473423900548, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 384, train_loss = 1.0094866417348385, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 385, train_loss = 1.0095051465032157, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 386, train_loss = 1.008205304533476, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 387, train_loss = 1.0075448540446814, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 388, train_loss = 1.0071824764308985, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 389, train_loss = 1.0062299842538778, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 390, train_loss = 1.0054287426173687, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 391, train_loss = 1.0046143544313964, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 392, train_loss = 1.0039789366128389, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 393, train_loss = 1.0037083812057972, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 394, train_loss = 1.002772287785774, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 395, train_loss = 1.0020909793674946, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 396, train_loss = 1.0016454806027468, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 397, train_loss = 1.000573047756916, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 398, train_loss = 1.0003800416889135, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 399, train_loss = 0.9993801563978195, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 400, train_loss = 0.9990207875671331, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 401, train_loss = 0.9979400572774466, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 402, train_loss = 0.9976149201393127, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 403, train_loss = 0.9970381905732211, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 404, train_loss = 0.9958159749803599, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 405, train_loss = 0.9959400767984334, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 406, train_loss = 0.994934576243395, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 407, train_loss = 0.9938658016326372, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 408, train_loss = 0.9941120594739914, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 409, train_loss = 0.9929893165826797, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 410, train_loss = 0.9924766806361731, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 411, train_loss = 0.9919734833238181, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 412, train_loss = 0.9913225397467613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 413, train_loss = 0.9902426066400949, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 414, train_loss = 0.9902022518217564, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 415, train_loss = 0.9895032619533595, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 416, train_loss = 0.9887987176480237, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 417, train_loss = 0.9880960620939732, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 418, train_loss = 0.9876622023584787, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 419, train_loss = 0.9870534030196723, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 420, train_loss = 0.9865171921846922, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 421, train_loss = 0.9858873374760151, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 422, train_loss = 0.9853366985917091, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 423, train_loss = 0.9845622405409813, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 424, train_loss = 0.9843350251612719, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 425, train_loss = 0.9833617359399796, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 426, train_loss = 0.9827153570950031, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 427, train_loss = 0.9824330384435598, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 428, train_loss = 0.9813517034053802, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 429, train_loss = 0.9813127989473287, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 430, train_loss = 0.9806000540556852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 431, train_loss = 0.9802702628076077, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 432, train_loss = 0.9791679283080157, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 433, train_loss = 0.979215644299984, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 434, train_loss = 0.9780512824654579, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 435, train_loss = 0.9778954386711121, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 436, train_loss = 0.9766076058149338, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 437, train_loss = 0.9770231172442436, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 438, train_loss = 0.9756039617059287, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 439, train_loss = 0.9760632316174451, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 440, train_loss = 0.9747918744978961, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 441, train_loss = 0.9743265906872693, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 442, train_loss = 0.9742079699935857, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 443, train_loss = 0.9732802497746889, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 444, train_loss = 0.9728618413209915, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 445, train_loss = 0.9725408045051154, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 446, train_loss = 0.9714135726389941, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 447, train_loss = 0.9713083915412426, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 448, train_loss = 0.9705820977687836, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 449, train_loss = 0.9702125912008341, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 450, train_loss = 0.9694550943968352, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 451, train_loss = 0.9687545038759708, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 452, train_loss = 0.9687965499761049, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 453, train_loss = 0.9679824126360472, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 454, train_loss = 0.9677775191667024, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 455, train_loss = 0.967033326625824, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 456, train_loss = 0.9662924980220851, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 457, train_loss = 0.9659040806291159, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 458, train_loss = 0.9655572921037674, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 459, train_loss = 0.9650585651397705, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 460, train_loss = 0.9649849658308085, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 461, train_loss = 0.9636188348231371, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 462, train_loss = 0.9637269303202629, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 463, train_loss = 0.9632671152648982, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 464, train_loss = 0.962325065076584, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 465, train_loss = 0.9622331534919795, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 466, train_loss = 0.9615917851624545, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 467, train_loss = 0.9611445888876915, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 468, train_loss = 0.9605103035864886, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 469, train_loss = 0.95999700948596, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 470, train_loss = 0.9596158290805761, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 471, train_loss = 0.9591634646058083, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 472, train_loss = 0.9585538295505103, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 473, train_loss = 0.9582471574249212, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 474, train_loss = 0.9573278898897115, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 475, train_loss = 0.9573046056029852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 476, train_loss = 0.9565932080149651, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 477, train_loss = 0.9562282264232635, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 478, train_loss = 0.9557223878800869, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 479, train_loss = 0.9550027934310492, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 480, train_loss = 0.9542870012519415, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 481, train_loss = 0.9544929675757885, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 482, train_loss = 0.9533860745432321, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 483, train_loss = 0.9535080008208752, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 484, train_loss = 0.9525910640659276, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 485, train_loss = 0.9521394906041678, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 486, train_loss = 0.9524205190537032, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 487, train_loss = 0.9514088965952396, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 488, train_loss = 0.9508414218726102, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 489, train_loss = 0.9509053578076418, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 490, train_loss = 0.9498800002038479, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 491, train_loss = 0.9499392534198705, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 492, train_loss = 0.9489964917302132, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 493, train_loss = 0.9486077018082142, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 494, train_loss = 0.9483516377804335, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 495, train_loss = 0.9476010464131832, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 496, train_loss = 0.9474369771778584, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 497, train_loss = 0.9471346562204417, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 498, train_loss = 0.9464724933204707, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 499, train_loss = 0.9462349874374922, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████▋                                            | 11/30 [1:49:38<3:10:09, 600.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "12th- epoch: 0, train_loss = 142.62350638210773, train_acc = 0.7424312994876572\n",
      "test Acc 0.866852886405959:\n",
      "12th- epoch: 1, train_loss = 54.574624706059694, train_acc = 0.8875174662319516\n",
      "test Acc 0.9124767225325885:\n",
      "12th- epoch: 2, train_loss = 39.04006975889206, train_acc = 0.9210526315789473\n",
      "test Acc 0.9278398510242085:\n",
      "12th- epoch: 3, train_loss = 30.96744266524911, train_acc = 0.9374708896134141\n",
      "test Acc 0.9343575418994413:\n",
      "12th- epoch: 4, train_loss = 25.77957373484969, train_acc = 0.9476013041453191\n",
      "test Acc 0.9432029795158287:\n",
      "12th- epoch: 5, train_loss = 22.120889184996486, train_acc = 0.9550535631113182\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 6, train_loss = 19.391035808250308, train_acc = 0.9609920819748486\n",
      "test Acc 0.9515828677839852:\n",
      "12th- epoch: 7, train_loss = 17.286307403817773, train_acc = 0.9664648346530041\n",
      "test Acc 0.9539106145251397:\n",
      "12th- epoch: 8, train_loss = 15.612665392458439, train_acc = 0.9708896134140661\n",
      "test Acc 0.9557728119180633:\n",
      "12th- epoch: 9, train_loss = 14.238870549947023, train_acc = 0.9734513274336283\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 10, train_loss = 13.078515827655792, train_acc = 0.9754308337214718\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 11, train_loss = 12.079270988702774, train_acc = 0.9767116907312529\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 12, train_loss = 11.215673753991723, train_acc = 0.9784583139264089\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 13, train_loss = 10.455680292099714, train_acc = 0.9799720540288775\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 14, train_loss = 9.786634245887399, train_acc = 0.9812529110386586\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 15, train_loss = 9.196633393876255, train_acc = 0.9828830926874709\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 16, train_loss = 8.670032289810479, train_acc = 0.9840475081509082\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 17, train_loss = 8.199123167432845, train_acc = 0.9848625989753144\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 18, train_loss = 7.778894736431539, train_acc = 0.9857941313460643\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 19, train_loss = 7.395765440538526, train_acc = 0.9870749883558454\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 20, train_loss = 7.052657422609627, train_acc = 0.9878900791802515\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 21, train_loss = 6.74021624866873, train_acc = 0.9883558453656265\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 22, train_loss = 6.453097818419337, train_acc = 0.9889380530973452\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 23, train_loss = 6.192067929543555, train_acc = 0.9890544946436889\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 24, train_loss = 5.947620078921318, train_acc = 0.9896367023754076\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 25, train_loss = 5.722934305667877, train_acc = 0.989869585468095\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 26, train_loss = 5.51301499363035, train_acc = 0.99033535165347\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 27, train_loss = 5.316003253683448, train_acc = 0.9906846762925011\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 28, train_loss = 5.131967085413635, train_acc = 0.9909175593851887\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 29, train_loss = 4.9615502413362265, train_acc = 0.9911504424778761\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 30, train_loss = 4.7996834688819945, train_acc = 0.9914997671169073\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 31, train_loss = 4.6513539482839406, train_acc = 0.9914997671169073\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 32, train_loss = 4.508701084181666, train_acc = 0.9916162086632511\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 33, train_loss = 4.373620932921767, train_acc = 0.9917326502095948\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 34, train_loss = 4.248925046995282, train_acc = 0.9921984163949698\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 35, train_loss = 4.129160807933658, train_acc = 0.9923148579413135\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 36, train_loss = 4.0176018457859755, train_acc = 0.9924312994876572\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 37, train_loss = 3.908631202299148, train_acc = 0.9928970656730322\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 38, train_loss = 3.807021750602871, train_acc = 0.9931299487657196\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 39, train_loss = 3.7123483158648014, train_acc = 0.9931299487657196\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 40, train_loss = 3.62092851055786, train_acc = 0.9933628318584071\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 41, train_loss = 3.5336294383741915, train_acc = 0.9935957149510946\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 42, train_loss = 3.452152469661087, train_acc = 0.993828598043782\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 43, train_loss = 3.3740502879954875, train_acc = 0.9940614811364695\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 44, train_loss = 3.3004959486424923, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 45, train_loss = 3.2289165537804365, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 46, train_loss = 3.1628042315132916, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 47, train_loss = 3.098120876122266, train_acc = 0.9951094550535631\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 48, train_loss = 3.036827125120908, train_acc = 0.9954587796925943\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 49, train_loss = 2.9794500884599984, train_acc = 0.9954587796925943\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 50, train_loss = 2.9236158318817616, train_acc = 0.9956916627852818\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 51, train_loss = 2.871678079944104, train_acc = 0.9956916627852818\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 52, train_loss = 2.821603366639465, train_acc = 0.996040987424313\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 53, train_loss = 2.7735039382241666, train_acc = 0.9961574289706567\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 54, train_loss = 2.727372291032225, train_acc = 0.9962738705170004\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 55, train_loss = 2.6836508605629206, train_acc = 0.9962738705170004\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 56, train_loss = 2.6418244324158877, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 57, train_loss = 2.600682309595868, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 58, train_loss = 2.5626149494200945, train_acc = 0.996506753609688\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 59, train_loss = 2.524904813617468, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 60, train_loss = 2.488859244855121, train_acc = 0.9967396367023754\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 61, train_loss = 2.4546406846493483, train_acc = 0.9967396367023754\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 62, train_loss = 2.422065069898963, train_acc = 0.9968560782487191\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 63, train_loss = 2.3896687377709895, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 64, train_loss = 2.3594522438943386, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 65, train_loss = 2.3302117369603366, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 66, train_loss = 2.301682559773326, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 67, train_loss = 2.274525310145691, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 68, train_loss = 2.2482720986008644, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 69, train_loss = 2.222640472697094, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 70, train_loss = 2.198253981070593, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 71, train_loss = 2.1755130037199706, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 72, train_loss = 2.15189680387266, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 73, train_loss = 2.130288078216836, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 74, train_loss = 2.109309356659651, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 75, train_loss = 2.0887423243839294, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 76, train_loss = 2.0688880023080856, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 77, train_loss = 2.0495131679344922, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 78, train_loss = 2.031753887189552, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 79, train_loss = 2.0135935072321445, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 80, train_loss = 1.996087670326233, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 81, train_loss = 1.9790879364591092, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 82, train_loss = 1.9630792171228677, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 83, train_loss = 1.9474769204389304, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 84, train_loss = 1.9318174459040165, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 85, train_loss = 1.9163561488967389, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 86, train_loss = 1.9022864934522659, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 87, train_loss = 1.8878563151229173, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 88, train_loss = 1.8744966685771942, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 89, train_loss = 1.860013070749119, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 90, train_loss = 1.848081999225542, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 91, train_loss = 1.8350165386218578, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 92, train_loss = 1.8221146818250418, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 93, train_loss = 1.8098335161339492, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 94, train_loss = 1.7980086138704792, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 95, train_loss = 1.7868362683802843, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 96, train_loss = 1.7756716856965795, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 97, train_loss = 1.7640480287373066, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 98, train_loss = 1.7537119394401088, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 99, train_loss = 1.7429042495787144, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 100, train_loss = 1.7324363198131323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 101, train_loss = 1.7228048493852839, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 102, train_loss = 1.7130936359753832, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 103, train_loss = 1.703329155803658, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 104, train_loss = 1.6943436419824138, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 105, train_loss = 1.684851169004105, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 106, train_loss = 1.675760971964337, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 107, train_loss = 1.667414378374815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 108, train_loss = 1.6587757201632485, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 109, train_loss = 1.6499559605726972, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 110, train_loss = 1.6417702349135652, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 111, train_loss = 1.633880447014235, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 112, train_loss = 1.6258330965647474, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 113, train_loss = 1.6183056695153937, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 114, train_loss = 1.611070141196251, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 115, train_loss = 1.603461322025396, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 116, train_loss = 1.595839973539114, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 117, train_loss = 1.58889776840806, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 118, train_loss = 1.5820157323032618, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 119, train_loss = 1.5747750228038058, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 120, train_loss = 1.568263128399849, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 121, train_loss = 1.5612597452709451, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 122, train_loss = 1.5549896657466888, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 123, train_loss = 1.5481777066597715, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 124, train_loss = 1.5418828738620505, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 125, train_loss = 1.535394586622715, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 126, train_loss = 1.5294038355350494, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 127, train_loss = 1.5234541930258274, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 128, train_loss = 1.517387950210832, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 129, train_loss = 1.511385466903448, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 130, train_loss = 1.505827885121107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 131, train_loss = 1.5002574088284746, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 132, train_loss = 1.4944723844528198, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 133, train_loss = 1.4891406496753916, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 134, train_loss = 1.4836134128272533, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 135, train_loss = 1.4782687661936507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 136, train_loss = 1.4731941781938076, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 137, train_loss = 1.4678443595767021, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 138, train_loss = 1.4626777122030035, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 139, train_loss = 1.4580240970244631, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 140, train_loss = 1.4531966844806448, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 141, train_loss = 1.4481903873383999, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 142, train_loss = 1.4436310939490795, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 143, train_loss = 1.4385257611284032, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 144, train_loss = 1.4343662349274382, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 145, train_loss = 1.4298054116079584, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 146, train_loss = 1.4250788515200838, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 147, train_loss = 1.4208575723459944, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 148, train_loss = 1.4161471935221925, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 149, train_loss = 1.4121306216111407, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 150, train_loss = 1.4079345539212227, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 151, train_loss = 1.40396998077631, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 152, train_loss = 1.3996988447615877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 153, train_loss = 1.395395594299771, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 154, train_loss = 1.3919224938144907, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 155, train_loss = 1.387803370715119, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 156, train_loss = 1.3837679115822539, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 157, train_loss = 1.3801767614786513, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 158, train_loss = 1.3762124006752856, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 159, train_loss = 1.372421873093117, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 160, train_loss = 1.3688650044496171, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 161, train_loss = 1.364741239696741, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 162, train_loss = 1.3611182421445847, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 163, train_loss = 1.3578970122034661, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 164, train_loss = 1.3540839130873792, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 165, train_loss = 1.3508400929276831, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 166, train_loss = 1.3472829163074493, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 167, train_loss = 1.343915847421158, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 168, train_loss = 1.340360902249813, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 169, train_loss = 1.3373240604996681, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 170, train_loss = 1.3342554494738579, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 171, train_loss = 1.3303735691006295, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 172, train_loss = 1.327439296990633, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 173, train_loss = 1.3243921150569804, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 174, train_loss = 1.3212291424279101, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 175, train_loss = 1.317999732971657, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 176, train_loss = 1.3154230999643914, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 177, train_loss = 1.311834083229769, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 178, train_loss = 1.3094443008303642, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 179, train_loss = 1.3062624149024487, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 180, train_loss = 1.303292240947485, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 181, train_loss = 1.300299521535635, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 182, train_loss = 1.2973198096151464, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 183, train_loss = 1.2947115401620977, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 184, train_loss = 1.2921357341110706, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 185, train_loss = 1.2894748647813685, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 186, train_loss = 1.2865214670891874, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 187, train_loss = 1.283223919570446, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 188, train_loss = 1.2810115590691566, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 189, train_loss = 1.2781728568370454, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 190, train_loss = 1.2753922256524675, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 191, train_loss = 1.2724867624347098, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 192, train_loss = 1.2702120877802372, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 193, train_loss = 1.2678734076325782, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 194, train_loss = 1.265240644395817, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 195, train_loss = 1.2627356611192226, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 196, train_loss = 1.2600260910694487, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 197, train_loss = 1.2573726859991439, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 198, train_loss = 1.2551960684359074, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 199, train_loss = 1.252827387303114, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 200, train_loss = 1.2504842740599997, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 201, train_loss = 1.2478440999984741, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 202, train_loss = 1.2456884955172427, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 203, train_loss = 1.2434694084222429, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 204, train_loss = 1.2413610319490544, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 205, train_loss = 1.2386274325544946, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 206, train_loss = 1.2362096036667936, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 207, train_loss = 1.2346831572358496, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 208, train_loss = 1.2320519859786145, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 209, train_loss = 1.229935863346327, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 210, train_loss = 1.2279899095301516, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 211, train_loss = 1.2252843503956683, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 212, train_loss = 1.2230160969193093, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 213, train_loss = 1.221074050932657, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 214, train_loss = 1.2189294596319087, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 215, train_loss = 1.2165317361359484, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 216, train_loss = 1.2149980328977108, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 217, train_loss = 1.2128889821469784, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 218, train_loss = 1.210914385796059, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 219, train_loss = 1.2086620752816088, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 220, train_loss = 1.2066019897465594, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 221, train_loss = 1.2046330993180163, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 222, train_loss = 1.2030939410324208, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 223, train_loss = 1.2006496315007098, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 224, train_loss = 1.1991920582950115, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 225, train_loss = 1.197016550868284, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 226, train_loss = 1.1951771527528763, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 227, train_loss = 1.1935231263632886, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 228, train_loss = 1.1913063141400926, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 229, train_loss = 1.18972346681403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 230, train_loss = 1.1876891876454465, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 231, train_loss = 1.1863295895163901, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 232, train_loss = 1.1844820280675776, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 233, train_loss = 1.1826213796739466, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 234, train_loss = 1.1809568529133685, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 235, train_loss = 1.1790424424107186, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 236, train_loss = 1.177821833640337, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 237, train_loss = 1.1760872788727283, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 238, train_loss = 1.1743052887613885, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 239, train_loss = 1.1728670696611516, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 240, train_loss = 1.1708737636799924, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 241, train_loss = 1.1692876753513701, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 242, train_loss = 1.1679695745115168, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 243, train_loss = 1.1660685129463673, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 244, train_loss = 1.1646217033267021, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 245, train_loss = 1.1629923011059873, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 246, train_loss = 1.160858595103491, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 247, train_loss = 1.1594597858493216, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 248, train_loss = 1.1582715002004988, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 249, train_loss = 1.156588216603268, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 250, train_loss = 1.1551536371116526, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 251, train_loss = 1.1531330980360508, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 252, train_loss = 1.1520482202176936, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 253, train_loss = 1.1505527645349503, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 254, train_loss = 1.1491851508617401, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 255, train_loss = 1.14774551987648, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 256, train_loss = 1.146355492353905, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 257, train_loss = 1.1446639858186245, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 258, train_loss = 1.1434330977499485, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 259, train_loss = 1.142198132991325, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 260, train_loss = 1.1407056550378911, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 261, train_loss = 1.1391790459456388, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 262, train_loss = 1.1376327561738435, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 263, train_loss = 1.13644153252244, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 264, train_loss = 1.1352023010549601, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 265, train_loss = 1.133236575871706, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 266, train_loss = 1.1323854649963323, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 267, train_loss = 1.1305458098649979, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 268, train_loss = 1.1299722492694855, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 269, train_loss = 1.1281940328481141, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 270, train_loss = 1.127257796615595, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 271, train_loss = 1.1259519060549792, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 272, train_loss = 1.1245798418822233, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 273, train_loss = 1.1230162481369916, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 274, train_loss = 1.121841593325371, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 275, train_loss = 1.1206337014737073, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 276, train_loss = 1.1188948787748814, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 277, train_loss = 1.1179716947081033, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 278, train_loss = 1.1166417872009333, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 279, train_loss = 1.1153299858269747, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 280, train_loss = 1.1136077282426413, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 281, train_loss = 1.1127130103704985, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 282, train_loss = 1.1112435671093408, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 283, train_loss = 1.11009082198143, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 284, train_loss = 1.1089851297438145, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 285, train_loss = 1.1078968482615892, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 286, train_loss = 1.1063514202833176, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 287, train_loss = 1.1055918832716998, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 288, train_loss = 1.1042213017644826, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 289, train_loss = 1.1033134435710963, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 290, train_loss = 1.1017375824449118, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 291, train_loss = 1.1007069957850035, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 292, train_loss = 1.0995155908167362, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 293, train_loss = 1.0985834772291128, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 294, train_loss = 1.0967870814201888, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 295, train_loss = 1.0962023536267225, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 296, train_loss = 1.0954775214195251, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 297, train_loss = 1.093880428612465, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 298, train_loss = 1.0925065515039023, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 299, train_loss = 1.0918510742485523, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 300, train_loss = 1.0906362272799015, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 301, train_loss = 1.0892353778181132, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 302, train_loss = 1.0885944863257464, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 303, train_loss = 1.0875706945953425, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 304, train_loss = 1.0863358999195043, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 305, train_loss = 1.0854804913105909, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 306, train_loss = 1.0845694156887475, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 307, train_loss = 1.0831521252694074, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 308, train_loss = 1.0819188194873277, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 309, train_loss = 1.0813659814593848, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 310, train_loss = 1.080198474228382, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 311, train_loss = 1.0789791184070054, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 312, train_loss = 1.078112876653904, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 313, train_loss = 1.0768408539297525, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 314, train_loss = 1.0759496241807938, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 315, train_loss = 1.0752841445209924, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 316, train_loss = 1.0738126511278097, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 317, train_loss = 1.0732527027430478, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 318, train_loss = 1.0716832553443965, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 319, train_loss = 1.071298435330391, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 320, train_loss = 1.070296511054039, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 321, train_loss = 1.0693880952894688, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 322, train_loss = 1.0685072913765907, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 323, train_loss = 1.0672881069185678, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 324, train_loss = 1.0663244438765105, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 325, train_loss = 1.0660681327281054, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 326, train_loss = 1.0644080514612142, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 327, train_loss = 1.0633150525391102, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 328, train_loss = 1.0623369713721331, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 329, train_loss = 1.0612053871154785, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 330, train_loss = 1.0607137767074164, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 331, train_loss = 1.0592079026100691, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 332, train_loss = 1.0586372142133769, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 333, train_loss = 1.0575308576226234, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 334, train_loss = 1.0570322511193808, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 335, train_loss = 1.056058565765852, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 336, train_loss = 1.055255795508856, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 337, train_loss = 1.0539886554179247, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 338, train_loss = 1.0534616187214851, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 339, train_loss = 1.0525297982094344, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 340, train_loss = 1.0515446079371031, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 341, train_loss = 1.0506586606206838, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 342, train_loss = 1.0497343564929906, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 343, train_loss = 1.0488468669354916, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 344, train_loss = 1.0482693314552307, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 345, train_loss = 1.0474508268234786, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 346, train_loss = 1.0462325488624629, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 347, train_loss = 1.0457173325121403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 348, train_loss = 1.0443846186099108, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 349, train_loss = 1.0441740602254868, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 350, train_loss = 1.0430869534611702, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 351, train_loss = 1.0421274093387183, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 352, train_loss = 1.041425491363043, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 353, train_loss = 1.040213676780695, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 354, train_loss = 1.0389352428319398, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 355, train_loss = 1.0385897656378802, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 356, train_loss = 1.0373853432538453, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 357, train_loss = 1.0366533497872297, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 358, train_loss = 1.0353606380522251, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 359, train_loss = 1.034679842501646, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 360, train_loss = 1.0332661904394627, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 361, train_loss = 1.0331140843627509, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 362, train_loss = 1.03215017542243, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 363, train_loss = 1.031300351023674, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 364, train_loss = 1.030368181556696, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 365, train_loss = 1.0298000164330006, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 366, train_loss = 1.0287291618587915, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 367, train_loss = 1.0282155014574528, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 368, train_loss = 1.0271447462437209, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 369, train_loss = 1.0271729131636675, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 370, train_loss = 1.0258419265446719, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 371, train_loss = 1.0252518616616726, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 372, train_loss = 1.024255309253931, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 373, train_loss = 1.023881133645773, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 374, train_loss = 1.022755408048397, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 375, train_loss = 1.021704157203203, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 376, train_loss = 1.0214736722409725, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 377, train_loss = 1.0207274829444941, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 378, train_loss = 1.0196012742817402, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 379, train_loss = 1.0192244412901346, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 380, train_loss = 1.0181278971431311, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 381, train_loss = 1.0179604912700597, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 382, train_loss = 1.01668119430542, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 383, train_loss = 1.0159693534078542, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 384, train_loss = 1.0151278674602509, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 385, train_loss = 1.0144319211540278, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 386, train_loss = 1.0136553297343198, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 387, train_loss = 1.0129494009015616, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 388, train_loss = 1.0120808271167334, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 389, train_loss = 1.011493694037199, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 390, train_loss = 1.0106911584734917, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 391, train_loss = 1.0100788250565529, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 392, train_loss = 1.0093153901398182, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 393, train_loss = 1.0091803645191249, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 394, train_loss = 1.0079500774445478, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 395, train_loss = 1.006783881544834, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 396, train_loss = 1.0061772763729095, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 397, train_loss = 1.0056324936449528, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 398, train_loss = 1.0049779886903707, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 399, train_loss = 1.0043298391101416, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 400, train_loss = 1.0035541392862797, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 401, train_loss = 1.0034373849630356, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 402, train_loss = 1.0026127683522645, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 403, train_loss = 1.0018190294504166, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 404, train_loss = 1.00121589252376, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 405, train_loss = 1.000752537191147, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 406, train_loss = 0.9998334484698717, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 407, train_loss = 0.9992893114686012, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 408, train_loss = 0.9987042583525181, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 409, train_loss = 0.9983351392147597, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 410, train_loss = 0.9974255623819772, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 411, train_loss = 0.9968807548284531, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 412, train_loss = 0.9959026326832827, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 413, train_loss = 0.9957163371145725, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 414, train_loss = 0.9951089322566986, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 415, train_loss = 0.9945232669415418, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 416, train_loss = 0.993870093167061, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 417, train_loss = 0.9929504667816218, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 418, train_loss = 0.9927488056418952, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 419, train_loss = 0.9919513911008835, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 420, train_loss = 0.991673161595827, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 421, train_loss = 0.9910173726675566, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 422, train_loss = 0.9902020829322282, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 423, train_loss = 0.9896138980984688, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 424, train_loss = 0.9894258665444795, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 425, train_loss = 0.9882125867006835, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 426, train_loss = 0.9881439829769079, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 427, train_loss = 0.9874247598054353, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 428, train_loss = 0.9867919261159841, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 429, train_loss = 0.9861024096608162, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 430, train_loss = 0.9856736697256565, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 431, train_loss = 0.9851063738169614, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 432, train_loss = 0.9845598327519838, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 433, train_loss = 0.9840031104686204, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 434, train_loss = 0.9836559481918812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 435, train_loss = 0.9826393996772822, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 436, train_loss = 0.9826248263416346, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 437, train_loss = 0.9812863146362361, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 438, train_loss = 0.9814391905965749, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 439, train_loss = 0.9806532984075602, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 440, train_loss = 0.9800699812622042, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 441, train_loss = 0.9793836871831445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 442, train_loss = 0.9790785287768813, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 443, train_loss = 0.978467100605485, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 444, train_loss = 0.9779487860650988, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 445, train_loss = 0.9770718378276797, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 446, train_loss = 0.9766528519539861, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 447, train_loss = 0.9759190914483042, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 448, train_loss = 0.9752671867609024, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 449, train_loss = 0.9743426032364368, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 450, train_loss = 0.9740679785609245, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 451, train_loss = 0.973450089499238, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 452, train_loss = 0.9732231758534908, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 453, train_loss = 0.9721126879303483, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 454, train_loss = 0.971891712397337, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 455, train_loss = 0.9711688421666622, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 456, train_loss = 0.9704780988395214, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 457, train_loss = 0.9702663819043664, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 458, train_loss = 0.9695155372173758, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 459, train_loss = 0.9689107872545719, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 460, train_loss = 0.9684139726014109, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 461, train_loss = 0.967638452842948, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 462, train_loss = 0.9675311061291723, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 463, train_loss = 0.966740916177514, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 464, train_loss = 0.9660720403044252, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 465, train_loss = 0.9656834987254115, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 466, train_loss = 0.9649911746382713, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 467, train_loss = 0.9644338128418894, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 468, train_loss = 0.9639105995447608, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 469, train_loss = 0.9638384443969699, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 470, train_loss = 0.9626557069568662, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 471, train_loss = 0.9623495452105999, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 472, train_loss = 0.9617905132472515, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 473, train_loss = 0.9615409423859091, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 474, train_loss = 0.9608153154404135, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 475, train_loss = 0.9606331648974447, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 476, train_loss = 0.9596741696150275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 477, train_loss = 0.9595250102429418, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 478, train_loss = 0.9585975967347622, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 479, train_loss = 0.9587575222103624, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 480, train_loss = 0.9578705740423175, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 481, train_loss = 0.9576281843037577, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 482, train_loss = 0.9566033904702635, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 483, train_loss = 0.9565552845597267, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 484, train_loss = 0.9559430927038193, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 485, train_loss = 0.9555809621961089, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 486, train_loss = 0.9546205215156078, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 487, train_loss = 0.9547096242458792, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 488, train_loss = 0.9542411280126544, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 489, train_loss = 0.9535512564034434, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 490, train_loss = 0.9526944843382807, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 491, train_loss = 0.9526319541037083, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 492, train_loss = 0.9520053640007973, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 493, train_loss = 0.9516930195241002, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 494, train_loss = 0.9508517657668563, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 495, train_loss = 0.9507719116954831, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 496, train_loss = 0.950540192425251, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 497, train_loss = 0.9497100810258416, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 498, train_loss = 0.948911285653594, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "12th- epoch: 499, train_loss = 0.9488751354365377, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████                                          | 12/30 [1:59:37<3:00:02, 600.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "13th- epoch: 0, train_loss = 130.44992643594742, train_acc = 0.7555891942244993\n",
      "test Acc 0.8561452513966481:\n",
      "13th- epoch: 1, train_loss = 49.66384865343571, train_acc = 0.8986958546809501\n",
      "test Acc 0.9082867783985102:\n",
      "13th- epoch: 2, train_loss = 35.365323424339294, train_acc = 0.9273404750815091\n",
      "test Acc 0.9269087523277467:\n",
      "13th- epoch: 3, train_loss = 28.274416513741016, train_acc = 0.9425943176525384\n",
      "test Acc 0.9343575418994413:\n",
      "13th- epoch: 4, train_loss = 23.80209792405367, train_acc = 0.9533069399161621\n",
      "test Acc 0.9399441340782123:\n",
      "13th- epoch: 5, train_loss = 20.643781404942274, train_acc = 0.9574988355845365\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 6, train_loss = 18.228120677173138, train_acc = 0.9632044713553796\n",
      "test Acc 0.9487895716945997:\n",
      "13th- epoch: 7, train_loss = 16.310922414064407, train_acc = 0.9670470423847228\n",
      "test Acc 0.952048417132216:\n",
      "13th- epoch: 8, train_loss = 14.74487904459238, train_acc = 0.97007452258966\n",
      "test Acc 0.9543761638733705:\n",
      "13th- epoch: 9, train_loss = 13.447336632758379, train_acc = 0.9724033535165347\n",
      "test Acc 0.9557728119180633:\n",
      "13th- epoch: 10, train_loss = 12.3561616782099, train_acc = 0.9749650675360969\n",
      "test Acc 0.9567039106145251:\n",
      "13th- epoch: 11, train_loss = 11.415691517293453, train_acc = 0.9776432231020028\n",
      "test Acc 0.9585661080074488:\n",
      "13th- epoch: 12, train_loss = 10.60710715688765, train_acc = 0.9796227293898463\n",
      "test Acc 0.9581005586592178:\n",
      "13th- epoch: 13, train_loss = 9.90024234354496, train_acc = 0.9814857941313461\n",
      "test Acc 0.9604283054003724:\n",
      "13th- epoch: 14, train_loss = 9.281639138236642, train_acc = 0.9831159757801584\n",
      "test Acc 0.9613594040968343:\n",
      "13th- epoch: 15, train_loss = 8.735932579264045, train_acc = 0.9847461574289706\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 16, train_loss = 8.252500865608454, train_acc = 0.9855612482533768\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 17, train_loss = 7.818767907097936, train_acc = 0.9866092221704704\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 18, train_loss = 7.434602143242955, train_acc = 0.9876571960875641\n",
      "test Acc 0.9641527001862198:\n",
      "13th- epoch: 19, train_loss = 7.079234566539526, train_acc = 0.9885887284583139\n",
      "test Acc 0.9641527001862198:\n",
      "13th- epoch: 20, train_loss = 6.762081820517778, train_acc = 0.98940381928272\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 21, train_loss = 6.472214316949248, train_acc = 0.9902189101071263\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 22, train_loss = 6.21409403719008, train_acc = 0.9905682347461574\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 23, train_loss = 5.976338118314743, train_acc = 0.9910340009315324\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 24, train_loss = 5.754069019109011, train_acc = 0.9912668840242198\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 25, train_loss = 5.555944583378732, train_acc = 0.9914997671169073\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 26, train_loss = 5.366794411092997, train_acc = 0.9918490917559385\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 27, train_loss = 5.194958971813321, train_acc = 0.9919655333022822\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 28, train_loss = 5.032907473854721, train_acc = 0.9923148579413135\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 29, train_loss = 4.881330049596727, train_acc = 0.9923148579413135\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 30, train_loss = 4.739619391970336, train_acc = 0.9925477410340009\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 31, train_loss = 4.607079527340829, train_acc = 0.9926641825803446\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 32, train_loss = 4.481763648800552, train_acc = 0.9931299487657196\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 33, train_loss = 4.365020698867738, train_acc = 0.9933628318584071\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 34, train_loss = 4.251538759097457, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 35, train_loss = 4.14767387509346, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 36, train_loss = 4.04957018699497, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 37, train_loss = 3.954682624898851, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 38, train_loss = 3.862641320563853, train_acc = 0.994294364229157\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 39, train_loss = 3.7780518978834152, train_acc = 0.994294364229157\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 40, train_loss = 3.6954499362036586, train_acc = 0.994294364229157\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 41, train_loss = 3.618542470037937, train_acc = 0.994294364229157\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 42, train_loss = 3.5447074957191944, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 43, train_loss = 3.474173146300018, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 44, train_loss = 3.404716015793383, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 45, train_loss = 3.3415576443076134, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 46, train_loss = 3.2791832983493805, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 47, train_loss = 3.219495890662074, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 48, train_loss = 3.163265105802566, train_acc = 0.9947601304145319\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 49, train_loss = 3.110395449679345, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 50, train_loss = 3.0559427407570183, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 51, train_loss = 3.005771796684712, train_acc = 0.9951094550535631\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 52, train_loss = 2.9586493489332497, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 53, train_loss = 2.9121069298125803, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 54, train_loss = 2.8677363456226885, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 55, train_loss = 2.8250921219587326, train_acc = 0.9953423381462506\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 56, train_loss = 2.7847276483662426, train_acc = 0.995575221238938\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 57, train_loss = 2.7450346294790506, train_acc = 0.995575221238938\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 58, train_loss = 2.706650050356984, train_acc = 0.995575221238938\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 59, train_loss = 2.6716894530691206, train_acc = 0.9956916627852818\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 60, train_loss = 2.635045599658042, train_acc = 0.9958081043316255\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 61, train_loss = 2.6009573373012245, train_acc = 0.9958081043316255\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 62, train_loss = 2.570309075061232, train_acc = 0.9958081043316255\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 63, train_loss = 2.537562754470855, train_acc = 0.9959245458779693\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 64, train_loss = 2.5074240011163056, train_acc = 0.996040987424313\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 65, train_loss = 2.4765943796373904, train_acc = 0.996040987424313\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 66, train_loss = 2.4486558181233704, train_acc = 0.9962738705170004\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 67, train_loss = 2.4213726706802845, train_acc = 0.9963903120633442\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 68, train_loss = 2.3939539417624474, train_acc = 0.9963903120633442\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 69, train_loss = 2.367927712853998, train_acc = 0.9963903120633442\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 70, train_loss = 2.34177364455536, train_acc = 0.9963903120633442\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 71, train_loss = 2.316900612320751, train_acc = 0.9963903120633442\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 72, train_loss = 2.2936059278436005, train_acc = 0.996506753609688\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 73, train_loss = 2.2703671641647816, train_acc = 0.996506753609688\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 74, train_loss = 2.2462410810403526, train_acc = 0.996506753609688\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 75, train_loss = 2.2246022671461105, train_acc = 0.9966231951560317\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 76, train_loss = 2.203753480222076, train_acc = 0.9966231951560317\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 77, train_loss = 2.1814050804823637, train_acc = 0.9966231951560317\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 78, train_loss = 2.162118969950825, train_acc = 0.9966231951560317\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 79, train_loss = 2.1417815890163183, train_acc = 0.9966231951560317\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 80, train_loss = 2.1230482044629753, train_acc = 0.9966231951560317\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 81, train_loss = 2.102916883304715, train_acc = 0.9966231951560317\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 82, train_loss = 2.0852237907238305, train_acc = 0.9966231951560317\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 83, train_loss = 2.0668899291194975, train_acc = 0.9966231951560317\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 84, train_loss = 2.0494314529933035, train_acc = 0.9966231951560317\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 85, train_loss = 2.032959504518658, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 86, train_loss = 2.015483121853322, train_acc = 0.9968560782487191\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 87, train_loss = 2.001166070345789, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 88, train_loss = 1.9838996909093112, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 89, train_loss = 1.9695993687491864, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 90, train_loss = 1.9538958154153079, train_acc = 0.9969725197950629\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 91, train_loss = 1.9396317477803677, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 92, train_loss = 1.9261987637728453, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 93, train_loss = 1.911126074148342, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 94, train_loss = 1.8988179054576904, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 95, train_loss = 1.8849230997730047, train_acc = 0.9969725197950629\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 96, train_loss = 1.8727283130865544, train_acc = 0.9969725197950629\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 97, train_loss = 1.8597326900344342, train_acc = 0.9969725197950629\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 98, train_loss = 1.847698436351493, train_acc = 0.9969725197950629\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 99, train_loss = 1.835897884098813, train_acc = 0.9969725197950629\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 100, train_loss = 1.8232407458126545, train_acc = 0.9970889613414066\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 101, train_loss = 1.8133781787473708, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 102, train_loss = 1.8008986439090222, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 103, train_loss = 1.7910335909109563, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 104, train_loss = 1.779202914563939, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 105, train_loss = 1.769423894584179, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 106, train_loss = 1.7599660244304687, train_acc = 0.9970889613414066\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 107, train_loss = 1.7491909626405686, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 108, train_loss = 1.7405220158398151, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 109, train_loss = 1.7299034979660064, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 110, train_loss = 1.720940784784034, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 111, train_loss = 1.7129087473731488, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 112, train_loss = 1.7029801048338413, train_acc = 0.9972054028877504\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 113, train_loss = 1.6957721163053066, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 114, train_loss = 1.686282352777198, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 115, train_loss = 1.677703971741721, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 116, train_loss = 1.6701942172367126, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 117, train_loss = 1.6626208510715514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 118, train_loss = 1.6545433339197189, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 119, train_loss = 1.6464994114357978, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 120, train_loss = 1.6392677624244243, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 121, train_loss = 1.6327743455767632, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 122, train_loss = 1.624852602602914, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 123, train_loss = 1.6175433050375432, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 124, train_loss = 1.6118291690945625, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 125, train_loss = 1.6037840098142624, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 126, train_loss = 1.5974337931256741, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 127, train_loss = 1.590436675818637, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 128, train_loss = 1.5841278422158211, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 129, train_loss = 1.5786391831934452, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 130, train_loss = 1.5713986307382584, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 131, train_loss = 1.565766641171649, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 132, train_loss = 1.559465604601428, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 133, train_loss = 1.5538912017364055, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 134, train_loss = 1.5475537690799683, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 135, train_loss = 1.54163059592247, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 136, train_loss = 1.5368840012233704, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 137, train_loss = 1.5309469860512763, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 138, train_loss = 1.5253954803338274, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 139, train_loss = 1.5198190672090277, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 140, train_loss = 1.514989777118899, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 141, train_loss = 1.5095646952977404, train_acc = 0.9972054028877504\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 142, train_loss = 1.5043993219733238, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 143, train_loss = 1.4990083239972591, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 144, train_loss = 1.4940596967935562, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 145, train_loss = 1.4895572116365656, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 146, train_loss = 1.4847296638181433, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 147, train_loss = 1.479332355200313, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 148, train_loss = 1.47494590037968, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 149, train_loss = 1.4701636160025373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 150, train_loss = 1.4653213880956173, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 151, train_loss = 1.4615546464920044, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 152, train_loss = 1.4563944712281227, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 153, train_loss = 1.4521812945604324, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 154, train_loss = 1.4478467851877213, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 155, train_loss = 1.4435674846172333, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 156, train_loss = 1.4392249746015295, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 157, train_loss = 1.4350517801940441, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 158, train_loss = 1.430904045701027, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 159, train_loss = 1.4268722409615293, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 160, train_loss = 1.4232170805335045, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 161, train_loss = 1.4184045232832432, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 162, train_loss = 1.415178923518397, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 163, train_loss = 1.410607552737929, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 164, train_loss = 1.4074621113250032, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 165, train_loss = 1.4032694585621357, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 166, train_loss = 1.399861428886652, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 167, train_loss = 1.3959814297268167, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 168, train_loss = 1.3925479067256674, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 169, train_loss = 1.3887406761059538, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 170, train_loss = 1.3849252810468897, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 171, train_loss = 1.381729039014317, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 172, train_loss = 1.3785188546171412, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 173, train_loss = 1.3743812553584576, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 174, train_loss = 1.3719577714800835, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 175, train_loss = 1.3675823112716898, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 176, train_loss = 1.3648497065296397, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 177, train_loss = 1.3612268380820751, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 178, train_loss = 1.3578957641730085, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 179, train_loss = 1.3552295491099358, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 180, train_loss = 1.3512589149177074, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 181, train_loss = 1.3488634327659383, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 182, train_loss = 1.3456672566244379, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 183, train_loss = 1.3426510021090508, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 184, train_loss = 1.3395838116994128, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 185, train_loss = 1.336711946874857, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 186, train_loss = 1.33351429796312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 187, train_loss = 1.3306656120112166, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 188, train_loss = 1.327864953665994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 189, train_loss = 1.3250692238798365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 190, train_loss = 1.3220616976032034, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 191, train_loss = 1.3194216700503603, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 192, train_loss = 1.316545084118843, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 193, train_loss = 1.3135544980177656, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 194, train_loss = 1.311052949517034, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 195, train_loss = 1.3083713799715042, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 196, train_loss = 1.3052281700074673, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 197, train_loss = 1.3028731966624036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 198, train_loss = 1.2995668264338747, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 199, train_loss = 1.2971441732952371, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 200, train_loss = 1.2947232289006934, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 201, train_loss = 1.292200569063425, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 202, train_loss = 1.2892832644283772, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 203, train_loss = 1.2869491875171661, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 204, train_loss = 1.2840944355120882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 205, train_loss = 1.2822463624179363, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 206, train_loss = 1.2792773904511705, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 207, train_loss = 1.2775614833226427, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 208, train_loss = 1.2747838832437992, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 209, train_loss = 1.2719265148043633, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 210, train_loss = 1.2695140851428732, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 211, train_loss = 1.2670198678970337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 212, train_loss = 1.2648595968494192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 213, train_loss = 1.2625032229116186, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 214, train_loss = 1.260625640512444, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 215, train_loss = 1.2582262480864301, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 216, train_loss = 1.2559692388167605, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 217, train_loss = 1.2536349134752527, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 218, train_loss = 1.2515546394279227, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 219, train_loss = 1.2494618991622701, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 220, train_loss = 1.2470819875597954, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 221, train_loss = 1.2448813183000311, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 222, train_loss = 1.2434887451818213, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 223, train_loss = 1.2406991682946682, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 224, train_loss = 1.2385706044733524, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 225, train_loss = 1.2368002633447759, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 226, train_loss = 1.2348956528003328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 227, train_loss = 1.2323294852976687, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 228, train_loss = 1.2302615977823734, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 229, train_loss = 1.2283457331359386, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 230, train_loss = 1.225831214338541, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 231, train_loss = 1.2242205615038984, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 232, train_loss = 1.2225224512512796, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 233, train_loss = 1.220730271190405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 234, train_loss = 1.2190165122156031, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 235, train_loss = 1.2167971568997018, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 236, train_loss = 1.2149583411519416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 237, train_loss = 1.213064341514837, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 238, train_loss = 1.2112487268750556, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 239, train_loss = 1.209657672792673, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 240, train_loss = 1.2081766079063527, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 241, train_loss = 1.205898775428068, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 242, train_loss = 1.2045017505879514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 243, train_loss = 1.2027644577319734, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 244, train_loss = 1.200927097350359, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 245, train_loss = 1.1991385494475253, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 246, train_loss = 1.1971931221778505, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 247, train_loss = 1.195764033764135, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 248, train_loss = 1.1942278283531778, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 249, train_loss = 1.1924087057705037, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 250, train_loss = 1.1909133046865463, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 251, train_loss = 1.1889664282207377, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 252, train_loss = 1.1874644719064236, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 253, train_loss = 1.185727994889021, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 254, train_loss = 1.1846446568961255, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 255, train_loss = 1.1821969685261138, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 256, train_loss = 1.1810198612511158, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 257, train_loss = 1.1793319669668563, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 258, train_loss = 1.1779287867248058, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 259, train_loss = 1.1762120686471462, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 260, train_loss = 1.17490502941655, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 261, train_loss = 1.173018169880379, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 262, train_loss = 1.171870597929228, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 263, train_loss = 1.1701554469764233, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 264, train_loss = 1.1685176727478392, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 265, train_loss = 1.1673872781102546, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 266, train_loss = 1.1655241337721236, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 267, train_loss = 1.1642771698534489, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 268, train_loss = 1.1625030959839933, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 269, train_loss = 1.16159999120282, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 270, train_loss = 1.159672090143431, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 271, train_loss = 1.1585557374055497, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 272, train_loss = 1.156779492914211, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 273, train_loss = 1.155235342681408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 274, train_loss = 1.1541304874117486, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 275, train_loss = 1.152755840390455, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 276, train_loss = 1.1516266291146167, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 277, train_loss = 1.1497367061674595, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 278, train_loss = 1.148567711294163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 279, train_loss = 1.1475689348881133, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 280, train_loss = 1.14572525274707, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 281, train_loss = 1.1449946102802642, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 282, train_loss = 1.142947266518604, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 283, train_loss = 1.1419539141352288, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 284, train_loss = 1.1404902189970016, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 285, train_loss = 1.1392208896577358, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 286, train_loss = 1.138306104869116, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 287, train_loss = 1.1366244952077977, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 288, train_loss = 1.1350839398801327, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 289, train_loss = 1.1340323786134832, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 290, train_loss = 1.132642426819075, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 291, train_loss = 1.1317686811089516, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 292, train_loss = 1.1304191661183722, train_acc = 0.9974382859804378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 293, train_loss = 1.1291997954249382, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 294, train_loss = 1.1277924900059588, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 295, train_loss = 1.1262277203495614, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 296, train_loss = 1.1253553107380867, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 297, train_loss = 1.1238552468712442, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 298, train_loss = 1.1230694763362408, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 299, train_loss = 1.1218513486091979, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 300, train_loss = 1.120525514066685, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 301, train_loss = 1.119424528151285, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 302, train_loss = 1.118296115368139, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 303, train_loss = 1.1171567874844186, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 304, train_loss = 1.1154860245878808, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 305, train_loss = 1.1145572476089, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 306, train_loss = 1.11342305195285, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 307, train_loss = 1.1123686445062049, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 308, train_loss = 1.1112531311810017, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 309, train_loss = 1.1102469712495804, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 310, train_loss = 1.1093040332198143, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 311, train_loss = 1.1075122095644474, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 312, train_loss = 1.1065882581169717, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 313, train_loss = 1.105394997925032, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 314, train_loss = 1.1045813200180419, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 315, train_loss = 1.1036027371883392, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 316, train_loss = 1.102699153125286, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 317, train_loss = 1.1012097385828383, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 318, train_loss = 1.0999164928798564, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 319, train_loss = 1.0989766158163548, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 320, train_loss = 1.0978539809584618, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 321, train_loss = 1.096519611775875, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 322, train_loss = 1.0958956207032315, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 323, train_loss = 1.0945458958740346, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 324, train_loss = 1.093849066644907, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 325, train_loss = 1.0923551234300248, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 326, train_loss = 1.0916686318814754, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 327, train_loss = 1.0905535494093783, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 328, train_loss = 1.089390744746197, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 329, train_loss = 1.0891818826203234, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 330, train_loss = 1.0873053148388863, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 331, train_loss = 1.086793101101648, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 332, train_loss = 1.0854929399793036, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 333, train_loss = 1.0849340930581093, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 334, train_loss = 1.084090419113636, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 335, train_loss = 1.0825132529134862, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 336, train_loss = 1.0817997679114342, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 337, train_loss = 1.0804844833910465, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 338, train_loss = 1.0800545401871204, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 339, train_loss = 1.078909816860687, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 340, train_loss = 1.077949742495548, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 341, train_loss = 1.077192059427034, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 342, train_loss = 1.0766050716047175, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 343, train_loss = 1.0749900005757809, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 344, train_loss = 1.0743477282230742, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 345, train_loss = 1.0737493162159808, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 346, train_loss = 1.0726444137399085, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 347, train_loss = 1.0718053628806956, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 348, train_loss = 1.0705713492934592, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 349, train_loss = 1.0695213700528257, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 350, train_loss = 1.0687472808058374, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 351, train_loss = 1.068313707888592, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 352, train_loss = 1.0671555126900785, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 353, train_loss = 1.0660551438922994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 354, train_loss = 1.065353800833691, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 355, train_loss = 1.0643907872145064, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 356, train_loss = 1.063302956521511, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 357, train_loss = 1.0634322638507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 358, train_loss = 1.0618048173491843, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 359, train_loss = 1.0611886878614314, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 360, train_loss = 1.0599183191661723, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 361, train_loss = 1.0599020458757877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 362, train_loss = 1.058901708573103, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 363, train_loss = 1.0574471888248809, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 364, train_loss = 1.0569157761638053, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 365, train_loss = 1.0561281542177312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 366, train_loss = 1.0553266095812432, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 367, train_loss = 1.0542430107598193, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 368, train_loss = 1.0539579329197295, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 369, train_loss = 1.0528241048450582, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 370, train_loss = 1.0519816391170025, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 371, train_loss = 1.051428252219921, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 372, train_loss = 1.0504219780268613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 373, train_loss = 1.0498031737806741, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 374, train_loss = 1.048831465333933, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 375, train_loss = 1.0483338547346648, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 376, train_loss = 1.0472355112433434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 377, train_loss = 1.0463095270097256, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 378, train_loss = 1.045582726597786, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 379, train_loss = 1.0448137124476489, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 380, train_loss = 1.0441043587925378, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 381, train_loss = 1.0428879670798779, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 382, train_loss = 1.0427129194140434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 383, train_loss = 1.0415134417416994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 384, train_loss = 1.0408288625476416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 385, train_loss = 1.0397183671593666, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 386, train_loss = 1.0394401823577937, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 387, train_loss = 1.0384290690126363, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 388, train_loss = 1.0374296431837138, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 389, train_loss = 1.0373893255891744, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 390, train_loss = 1.0360089080932084, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 391, train_loss = 1.0359203070402145, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 392, train_loss = 1.0347978795471136, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 393, train_loss = 1.0339736640453339, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 394, train_loss = 1.0332309889199678, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 395, train_loss = 1.0324160555901472, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 396, train_loss = 1.031563709169859, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 397, train_loss = 1.0308659859001637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 398, train_loss = 1.0303189046680927, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 399, train_loss = 1.0293629579246044, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 400, train_loss = 1.0291674199106637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 401, train_loss = 1.0279571115970612, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 402, train_loss = 1.0272179270687047, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 403, train_loss = 1.0269241680798586, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 404, train_loss = 1.0254925737681333, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 405, train_loss = 1.0251218800840434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 406, train_loss = 1.0243090415897314, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 407, train_loss = 1.0238346345722675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 408, train_loss = 1.022976459324127, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 409, train_loss = 1.0226879244146403, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 410, train_loss = 1.021599085390335, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 411, train_loss = 1.0210979183611926, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 412, train_loss = 1.0208335643110331, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 413, train_loss = 1.01974113410688, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 414, train_loss = 1.0189979871211108, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 415, train_loss = 1.0184097339806613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 416, train_loss = 1.0174842067062855, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 417, train_loss = 1.0170087528822478, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 418, train_loss = 1.0169097681937274, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 419, train_loss = 1.015849843621254, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 420, train_loss = 1.0150094802083913, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 421, train_loss = 1.0145023850200232, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 422, train_loss = 1.0140473755600397, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 423, train_loss = 1.013301756232977, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 424, train_loss = 1.0127675036492292, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 425, train_loss = 1.0119402930140495, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 426, train_loss = 1.0110477854905184, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 427, train_loss = 1.0105016405286733, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 428, train_loss = 1.0102512265148107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 429, train_loss = 1.0092014173569623, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 430, train_loss = 1.0085364170372486, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 431, train_loss = 1.0085446822049562, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 432, train_loss = 1.007472287863493, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 433, train_loss = 1.0063876248896122, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 434, train_loss = 1.0067359271051828, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 435, train_loss = 1.0054668821394444, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 436, train_loss = 1.0049890913069248, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 437, train_loss = 1.0044289864599705, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 438, train_loss = 1.0037377513945103, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 439, train_loss = 1.0032521349785384, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 440, train_loss = 1.0026897639036179, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 441, train_loss = 1.001886816084152, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 442, train_loss = 1.001552085072035, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 443, train_loss = 1.000484367221361, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 444, train_loss = 1.0003945814969484, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 445, train_loss = 0.9997962974011898, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 446, train_loss = 0.9994441643357277, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 447, train_loss = 0.9984567066130694, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 448, train_loss = 0.9979333107767161, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 449, train_loss = 0.9973688920435961, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 450, train_loss = 0.9966971538960934, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 451, train_loss = 0.9963698461651802, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 452, train_loss = 0.995847330748802, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 453, train_loss = 0.994777229934698, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 454, train_loss = 0.994232060998911, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 455, train_loss = 0.9942406738700811, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 456, train_loss = 0.9933336451649666, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 457, train_loss = 0.9924594437179621, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 458, train_loss = 0.9922742533090059, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 459, train_loss = 0.9918196760118008, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 460, train_loss = 0.9913732732238714, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 461, train_loss = 0.9907218180596828, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 462, train_loss = 0.9897187401948031, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 463, train_loss = 0.990025137871271, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 464, train_loss = 0.9883125027117785, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 465, train_loss = 0.9882725005445536, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 466, train_loss = 0.9879439311625902, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 467, train_loss = 0.9874826768937055, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 468, train_loss = 0.9869937226176262, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 469, train_loss = 0.9860122439858969, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 470, train_loss = 0.9855909608304501, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 471, train_loss = 0.9855068611504976, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 472, train_loss = 0.9846934837696608, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 473, train_loss = 0.9841119696793612, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 474, train_loss = 0.9834445081651211, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 475, train_loss = 0.983188626676565, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 476, train_loss = 0.9825308000145014, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 477, train_loss = 0.9825100762245711, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 478, train_loss = 0.9814161198737565, train_acc = 0.9976711690731253\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 479, train_loss = 0.9808519631624222, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 480, train_loss = 0.9807042603788432, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 481, train_loss = 0.9801610062422697, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 482, train_loss = 0.9794412491319235, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 483, train_loss = 0.979264747351408, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 484, train_loss = 0.9784378694894258, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 485, train_loss = 0.9780812772514764, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 486, train_loss = 0.9777861523034517, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 487, train_loss = 0.9770884998142719, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 488, train_loss = 0.9764174272713717, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 489, train_loss = 0.9760603569447994, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 490, train_loss = 0.9758392249641474, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 491, train_loss = 0.9748044013977051, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 492, train_loss = 0.974659508705372, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 493, train_loss = 0.9740127014520112, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 494, train_loss = 0.9735178438422736, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 495, train_loss = 0.9730262855591718, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 496, train_loss = 0.9726650243101176, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 497, train_loss = 0.9722513730230276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 498, train_loss = 0.9720521619019564, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 499, train_loss = 0.9710197262465954, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████▎                                       | 13/30 [2:09:37<2:50:01, 600.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "14th- epoch: 0, train_loss = 135.53779469430447, train_acc = 0.7558220773171868\n",
      "test Acc 0.8608007448789572:\n",
      "14th- epoch: 1, train_loss = 53.070725195109844, train_acc = 0.8846064275733582\n",
      "test Acc 0.8980446927374302:\n",
      "14th- epoch: 2, train_loss = 38.02295248955488, train_acc = 0.9193060083837913\n",
      "test Acc 0.9162011173184358:\n",
      "14th- epoch: 3, train_loss = 30.308994226157665, train_acc = 0.9363064741499767\n",
      "test Acc 0.9273743016759777:\n",
      "14th- epoch: 4, train_loss = 25.425975371152163, train_acc = 0.9485328365160689\n",
      "test Acc 0.9348230912476723:\n",
      "14th- epoch: 5, train_loss = 21.98725873604417, train_acc = 0.955519329296693\n",
      "test Acc 0.9390130353817505:\n",
      "14th- epoch: 6, train_loss = 19.405969068408012, train_acc = 0.961690731252911\n",
      "test Acc 0.9432029795158287:\n",
      "14th- epoch: 7, train_loss = 17.39787577278912, train_acc = 0.966581276199348\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 8, train_loss = 15.770472122356296, train_acc = 0.9706567303213787\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 9, train_loss = 14.416893007233739, train_acc = 0.9732184443409408\n",
      "test Acc 0.952048417132216:\n",
      "14th- epoch: 10, train_loss = 13.277433862909675, train_acc = 0.9751979506287843\n",
      "test Acc 0.952513966480447:\n",
      "14th- epoch: 11, train_loss = 12.289087478071451, train_acc = 0.9777596646483465\n",
      "test Acc 0.9543761638733705:\n",
      "14th- epoch: 12, train_loss = 11.430225852876902, train_acc = 0.9790405216581276\n",
      "test Acc 0.9543761638733705:\n",
      "14th- epoch: 13, train_loss = 10.67439241334796, train_acc = 0.980204937121565\n",
      "test Acc 0.9562383612662942:\n",
      "14th- epoch: 14, train_loss = 10.001959538087249, train_acc = 0.9812529110386586\n",
      "test Acc 0.9567039106145251:\n",
      "14th- epoch: 15, train_loss = 9.409133084118366, train_acc = 0.9828830926874709\n",
      "test Acc 0.9567039106145251:\n",
      "14th- epoch: 16, train_loss = 8.880056522786617, train_acc = 0.9839310666045645\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 17, train_loss = 8.4042286016047, train_acc = 0.9849790405216581\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 18, train_loss = 7.975321770645678, train_acc = 0.9860270144387517\n",
      "test Acc 0.9590316573556797:\n",
      "14th- epoch: 19, train_loss = 7.587974883615971, train_acc = 0.9862598975314392\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 20, train_loss = 7.235991705209017, train_acc = 0.9870749883558454\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 21, train_loss = 6.918410089798272, train_acc = 0.9880065207265952\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 22, train_loss = 6.621602515690029, train_acc = 0.9887051700046576\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 23, train_loss = 6.351197459734976, train_acc = 0.9890544946436889\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 24, train_loss = 6.103286539204419, train_acc = 0.9906846762925011\n",
      "test Acc 0.9636871508379888:\n",
      "14th- epoch: 25, train_loss = 5.874028996564448, train_acc = 0.9911504424778761\n",
      "test Acc 0.9636871508379888:\n",
      "14th- epoch: 26, train_loss = 5.661740404553711, train_acc = 0.9919655333022822\n",
      "test Acc 0.9636871508379888:\n",
      "14th- epoch: 27, train_loss = 5.465408391319215, train_acc = 0.9919655333022822\n",
      "test Acc 0.9636871508379888:\n",
      "14th- epoch: 28, train_loss = 5.285043548792601, train_acc = 0.9921984163949698\n",
      "test Acc 0.9641527001862198:\n",
      "14th- epoch: 29, train_loss = 5.114593575708568, train_acc = 0.9923148579413135\n",
      "test Acc 0.9641527001862198:\n",
      "14th- epoch: 30, train_loss = 4.954882479272783, train_acc = 0.9925477410340009\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 31, train_loss = 4.807754680514336, train_acc = 0.9927806241266884\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 32, train_loss = 4.6665350422263145, train_acc = 0.9927806241266884\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 33, train_loss = 4.534050046466291, train_acc = 0.9931299487657196\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 34, train_loss = 4.410202733241022, train_acc = 0.9932463903120633\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 35, train_loss = 4.292287590913475, train_acc = 0.9934792734047508\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 36, train_loss = 4.181468952447176, train_acc = 0.9937121564974383\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 37, train_loss = 4.074579678475857, train_acc = 0.993828598043782\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 38, train_loss = 3.975834201090038, train_acc = 0.9939450395901258\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 39, train_loss = 3.8778877751901746, train_acc = 0.9940614811364695\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 40, train_loss = 3.7883386500179768, train_acc = 0.9940614811364695\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 41, train_loss = 3.7034261310473084, train_acc = 0.9940614811364695\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 42, train_loss = 3.6203895853832364, train_acc = 0.9944108057755007\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 43, train_loss = 3.543443091213703, train_acc = 0.9944108057755007\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 44, train_loss = 3.467229424510151, train_acc = 0.9945272473218444\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 45, train_loss = 3.3968790411017835, train_acc = 0.9945272473218444\n",
      "test Acc 0.9664804469273743:\n",
      "14th- epoch: 46, train_loss = 3.329388940241188, train_acc = 0.9946436888681882\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 47, train_loss = 3.2638152888976038, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 48, train_loss = 3.2031909972429276, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 49, train_loss = 3.1436251029372215, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 50, train_loss = 3.0875408872962, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 51, train_loss = 3.0339396484196186, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 52, train_loss = 2.981398683041334, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 53, train_loss = 2.9317716993391514, train_acc = 0.9951094550535631\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 54, train_loss = 2.884476193692535, train_acc = 0.9951094550535631\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 55, train_loss = 2.8380120494402945, train_acc = 0.9951094550535631\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 56, train_loss = 2.793605992104858, train_acc = 0.9951094550535631\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 57, train_loss = 2.751507394015789, train_acc = 0.9952258965999069\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 58, train_loss = 2.712075375020504, train_acc = 0.9953423381462506\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 59, train_loss = 2.6707610809244215, train_acc = 0.9953423381462506\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 60, train_loss = 2.6345888203941286, train_acc = 0.9953423381462506\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 61, train_loss = 2.598670832812786, train_acc = 0.9954587796925943\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 62, train_loss = 2.5629480741918087, train_acc = 0.995575221238938\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 63, train_loss = 2.530440437141806, train_acc = 0.9958081043316255\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 64, train_loss = 2.4970644265413284, train_acc = 0.9959245458779693\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 65, train_loss = 2.4660477438010275, train_acc = 0.996040987424313\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 66, train_loss = 2.435953304171562, train_acc = 0.9961574289706567\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 67, train_loss = 2.4077481874264777, train_acc = 0.9962738705170004\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 68, train_loss = 2.378903441131115, train_acc = 0.9962738705170004\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 69, train_loss = 2.351798314601183, train_acc = 0.9962738705170004\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 70, train_loss = 2.3255075910128653, train_acc = 0.9963903120633442\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 71, train_loss = 2.3007671921513975, train_acc = 0.9963903120633442\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 72, train_loss = 2.2761345282197, train_acc = 0.9963903120633442\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 73, train_loss = 2.251238889992237, train_acc = 0.9963903120633442\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 74, train_loss = 2.228614283259958, train_acc = 0.9963903120633442\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 75, train_loss = 2.2062919684685767, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 76, train_loss = 2.1837728917598724, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 77, train_loss = 2.163522355258465, train_acc = 0.9966231951560317\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 78, train_loss = 2.1420452422462404, train_acc = 0.9966231951560317\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 79, train_loss = 2.122841640142724, train_acc = 0.9966231951560317\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 80, train_loss = 2.1024618335068226, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 81, train_loss = 2.084057552041486, train_acc = 0.9967396367023754\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 82, train_loss = 2.065367291448638, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 83, train_loss = 2.0480328139383346, train_acc = 0.9967396367023754\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 84, train_loss = 2.030522747663781, train_acc = 0.9968560782487191\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 85, train_loss = 2.0125307627022266, train_acc = 0.9968560782487191\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 86, train_loss = 1.9977584059815854, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 87, train_loss = 1.9808895450551063, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 88, train_loss = 1.965404223650694, train_acc = 0.9968560782487191\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 89, train_loss = 1.950241184560582, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 90, train_loss = 1.9351542654912919, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 91, train_loss = 1.9216220017988235, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 92, train_loss = 1.907924785045907, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 93, train_loss = 1.8932436916511506, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 94, train_loss = 1.8805910993833095, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 95, train_loss = 1.8676356908399612, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 96, train_loss = 1.8546984891872853, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 97, train_loss = 1.8429301555734128, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 98, train_loss = 1.8301037463825196, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 99, train_loss = 1.8184719644486904, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 100, train_loss = 1.8064445455092937, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 101, train_loss = 1.7954470701515675, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 102, train_loss = 1.7851450543385, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 103, train_loss = 1.7734208356123418, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 104, train_loss = 1.7642017726320773, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 105, train_loss = 1.7536517854314297, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 106, train_loss = 1.7441168564837426, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 107, train_loss = 1.7338807098567486, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 108, train_loss = 1.7247112430632114, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 109, train_loss = 1.7149558041710407, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 110, train_loss = 1.7071640864014626, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 111, train_loss = 1.69710507360287, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 112, train_loss = 1.6885606087744236, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 113, train_loss = 1.6796039703767747, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 114, train_loss = 1.6715915489476174, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 115, train_loss = 1.6623281475622207, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 116, train_loss = 1.654936034232378, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 117, train_loss = 1.6466978800017387, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 118, train_loss = 1.638883450301364, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 119, train_loss = 1.6310635183472186, train_acc = 0.9969725197950629\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 120, train_loss = 1.6232373577076942, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 121, train_loss = 1.6166204884648323, train_acc = 0.9969725197950629\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 122, train_loss = 1.6083526922157034, train_acc = 0.9969725197950629\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 123, train_loss = 1.6012725532054901, train_acc = 0.9969725197950629\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 124, train_loss = 1.594120103865862, train_acc = 0.9969725197950629\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 125, train_loss = 1.5869268166134134, train_acc = 0.9969725197950629\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 126, train_loss = 1.5802221124758944, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 127, train_loss = 1.5733396472642198, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 128, train_loss = 1.5671793756773695, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 129, train_loss = 1.560201837331988, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 130, train_loss = 1.5540085484972224, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 131, train_loss = 1.5480063495924696, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 132, train_loss = 1.5413727350533009, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 133, train_loss = 1.5356569787254557, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 134, train_loss = 1.5293535391101614, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 135, train_loss = 1.5240200447151437, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 136, train_loss = 1.5183081676950678, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 137, train_loss = 1.5121432691812515, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 138, train_loss = 1.507333784014918, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 139, train_loss = 1.5021973612019792, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 140, train_loss = 1.4962733698775992, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 141, train_loss = 1.4910389831056818, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 142, train_loss = 1.4861294379225, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 143, train_loss = 1.4811227731406689, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 144, train_loss = 1.4755352139472961, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 145, train_loss = 1.4710750604281202, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 146, train_loss = 1.4662146344780922, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 147, train_loss = 1.4614148611435667, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 148, train_loss = 1.4566672568907961, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 149, train_loss = 1.451966897933744, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 150, train_loss = 1.4475983729353175, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 151, train_loss = 1.442785949795507, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 152, train_loss = 1.4382406758377329, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 153, train_loss = 1.4339882420608774, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 154, train_loss = 1.4294928138842806, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 155, train_loss = 1.4255767613649368, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 156, train_loss = 1.4211734309792519, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 157, train_loss = 1.416269359528087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 158, train_loss = 1.4120986722409725, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 159, train_loss = 1.407774077146314, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 160, train_loss = 1.4030664140591398, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 161, train_loss = 1.399331816821359, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 162, train_loss = 1.3951802315423265, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 163, train_loss = 1.3910690061748028, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 164, train_loss = 1.387170778005384, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 165, train_loss = 1.3835576536366716, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 166, train_loss = 1.3788024907698855, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 167, train_loss = 1.3748501824447885, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 168, train_loss = 1.3706425105920061, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 169, train_loss = 1.366908529191278, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 170, train_loss = 1.3634167475393042, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 171, train_loss = 1.3593153059482574, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 172, train_loss = 1.3560665845870972, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 173, train_loss = 1.3519198410212994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 174, train_loss = 1.3490389734506607, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 175, train_loss = 1.3456612067529932, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 176, train_loss = 1.3419886752963066, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 177, train_loss = 1.338496976881288, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 178, train_loss = 1.3358135558664799, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 179, train_loss = 1.3320142291486263, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 180, train_loss = 1.3289194578537717, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 181, train_loss = 1.325426947325468, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 182, train_loss = 1.3231121761491522, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 183, train_loss = 1.319773810566403, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 184, train_loss = 1.3160457672784105, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 185, train_loss = 1.312717111199163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 186, train_loss = 1.309894765377976, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 187, train_loss = 1.3069095438113436, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 188, train_loss = 1.3037895696470514, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 189, train_loss = 1.301003256230615, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 190, train_loss = 1.2983691407134756, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 191, train_loss = 1.2953548096120358, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 192, train_loss = 1.292648664326407, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 193, train_loss = 1.2896896625170484, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 194, train_loss = 1.2869629487395287, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 195, train_loss = 1.2846248932182789, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 196, train_loss = 1.2817337028682232, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 197, train_loss = 1.2788877611747012, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 198, train_loss = 1.2758680383558385, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 199, train_loss = 1.273756980895996, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 200, train_loss = 1.2710586190223694, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 201, train_loss = 1.268789380788803, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 202, train_loss = 1.265681644261349, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 203, train_loss = 1.2636570259928703, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 204, train_loss = 1.2610332928597927, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 205, train_loss = 1.2586666469578631, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 206, train_loss = 1.255857702344656, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 207, train_loss = 1.2539486959576607, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 208, train_loss = 1.2514733858406544, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 209, train_loss = 1.2488904297351837, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 210, train_loss = 1.2465682898764499, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 211, train_loss = 1.2431893547181971, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 212, train_loss = 1.2412846957449801, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 213, train_loss = 1.2387566466932185, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 214, train_loss = 1.2368842959403992, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 215, train_loss = 1.2344790634815581, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 216, train_loss = 1.2325058194692247, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 217, train_loss = 1.2296094708144665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 218, train_loss = 1.227721557021141, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 219, train_loss = 1.2258786012534983, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 220, train_loss = 1.2237747982144356, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 221, train_loss = 1.2214921240811236, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 222, train_loss = 1.2197777653927915, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 223, train_loss = 1.2172939839656465, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 224, train_loss = 1.2156602144241333, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 225, train_loss = 1.2133700773119926, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 226, train_loss = 1.2116025065188296, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 227, train_loss = 1.2092350348830223, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 228, train_loss = 1.207313884049654, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 229, train_loss = 1.2057699747383595, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 230, train_loss = 1.2036346209351905, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 231, train_loss = 1.2014169047470205, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 232, train_loss = 1.2001843862235546, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 233, train_loss = 1.1977556447382085, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 234, train_loss = 1.1961675609345548, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 235, train_loss = 1.194563016295433, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 236, train_loss = 1.1924277084763162, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 237, train_loss = 1.1906854510307312, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 238, train_loss = 1.1890954312984832, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 239, train_loss = 1.1865371316671371, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 240, train_loss = 1.1855564080178738, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 241, train_loss = 1.183492065698374, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 242, train_loss = 1.1817010343074799, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 243, train_loss = 1.1797955271904357, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 244, train_loss = 1.1787218662793748, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 245, train_loss = 1.1765154525637627, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 246, train_loss = 1.174890797585249, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 247, train_loss = 1.1735508280689828, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 248, train_loss = 1.1715809044544585, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 249, train_loss = 1.170291659713257, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 250, train_loss = 1.168307187675964, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 251, train_loss = 1.1670668733422644, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 252, train_loss = 1.1651937700808048, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 253, train_loss = 1.1638566640322097, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 254, train_loss = 1.1617676417226903, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 255, train_loss = 1.160649189085234, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 256, train_loss = 1.1591179047827609, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 257, train_loss = 1.1572111484711058, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 258, train_loss = 1.1558423626120202, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 259, train_loss = 1.1543848887085915, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 260, train_loss = 1.152783703058958, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 261, train_loss = 1.1516398240928538, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 262, train_loss = 1.1495645034010522, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 263, train_loss = 1.1484387504751794, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 264, train_loss = 1.146807202429045, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 265, train_loss = 1.1454584511811845, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 266, train_loss = 1.1437737097148784, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 267, train_loss = 1.143027173995506, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 268, train_loss = 1.1411488863523118, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 269, train_loss = 1.139220671087969, train_acc = 0.9981369352585002\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 270, train_loss = 1.1382043014164083, train_acc = 0.9981369352585002\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 271, train_loss = 1.1365941328112967, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 272, train_loss = 1.135452815622557, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 273, train_loss = 1.1342540557379834, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 274, train_loss = 1.1325110420584679, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 275, train_loss = 1.1312843039631844, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 276, train_loss = 1.1302026584744453, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 277, train_loss = 1.1279818800394423, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 278, train_loss = 1.1269740698044188, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 279, train_loss = 1.12592562782811, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 280, train_loss = 1.124734703451395, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 281, train_loss = 1.1230276350979693, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 282, train_loss = 1.1220690558548085, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 283, train_loss = 1.1207122008199804, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 284, train_loss = 1.119611779868137, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 285, train_loss = 1.1178765396471135, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 286, train_loss = 1.1169811002910137, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 287, train_loss = 1.1155784167349339, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 288, train_loss = 1.1142222620546818, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 289, train_loss = 1.1131371061201207, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 290, train_loss = 1.1119986288249493, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 291, train_loss = 1.110023918270599, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 292, train_loss = 1.1092473777825944, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 293, train_loss = 1.1085247099399567, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 294, train_loss = 1.1071146242320538, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 295, train_loss = 1.1056007432634942, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 296, train_loss = 1.1048896896536462, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 297, train_loss = 1.1035382499103434, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 298, train_loss = 1.1022262945771217, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 299, train_loss = 1.1014073652331717, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 300, train_loss = 1.0998823928530328, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 301, train_loss = 1.0987530785496347, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 302, train_loss = 1.0978827973012812, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 303, train_loss = 1.096636054397095, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 304, train_loss = 1.095692791044712, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 305, train_loss = 1.0945721504394896, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 306, train_loss = 1.0932934234733693, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 307, train_loss = 1.0914105798001401, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 308, train_loss = 1.0913688938017003, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 309, train_loss = 1.0897719686035998, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 310, train_loss = 1.0889688829774968, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 311, train_loss = 1.0877098615164869, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 312, train_loss = 1.086779523640871, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 313, train_loss = 1.08578036603285, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 314, train_loss = 1.0846191098098643, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 315, train_loss = 1.0832735846634023, train_acc = 0.9981369352585002\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 316, train_loss = 1.0826883030240424, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 317, train_loss = 1.0815075188875198, train_acc = 0.9981369352585002\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 318, train_loss = 1.0805180395836942, train_acc = 0.9981369352585002\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 319, train_loss = 1.0796648859977722, train_acc = 0.9981369352585002\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 320, train_loss = 1.0780162724549882, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 321, train_loss = 1.077489164948929, train_acc = 0.9981369352585002\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 322, train_loss = 1.0762056211824529, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 323, train_loss = 1.0751510076224804, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 324, train_loss = 1.0744027594919316, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 325, train_loss = 1.0735117495059967, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 326, train_loss = 1.0725321546196938, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 327, train_loss = 1.0713894230430014, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 328, train_loss = 1.0704492330551147, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 329, train_loss = 1.0686979107558727, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 330, train_loss = 1.068726535886526, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 331, train_loss = 1.0675731127266772, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 332, train_loss = 1.0666253331000917, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 333, train_loss = 1.0655821127002127, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 334, train_loss = 1.0644901568884961, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 335, train_loss = 1.0636461128597148, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 336, train_loss = 1.0629984363913536, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 337, train_loss = 1.0616390369832516, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 338, train_loss = 1.060862123966217, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 339, train_loss = 1.0598847592773382, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 340, train_loss = 1.0589927149412688, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 341, train_loss = 1.057988173008198, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 342, train_loss = 1.0572972608206328, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 343, train_loss = 1.0563657904567663, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 344, train_loss = 1.0554993847908918, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 345, train_loss = 1.0543601289391518, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 346, train_loss = 1.0539300963282585, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 347, train_loss = 1.0529209909436759, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 348, train_loss = 1.0517083331942558, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 349, train_loss = 1.0508784664270934, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 350, train_loss = 1.0503379156289157, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 351, train_loss = 1.0491772567329463, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 352, train_loss = 1.0486190604569856, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 353, train_loss = 1.0474349732103292, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 354, train_loss = 1.0466643882391509, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 355, train_loss = 1.0458319000899792, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 356, train_loss = 1.0447358302772045, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 357, train_loss = 1.0444898270070553, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 358, train_loss = 1.0433360213937704, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 359, train_loss = 1.0424142330884933, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 360, train_loss = 1.0414316815731581, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 361, train_loss = 1.0409554354846478, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 362, train_loss = 1.0400780017080251, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 363, train_loss = 1.0393099474313203, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 364, train_loss = 1.0383570504782256, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 365, train_loss = 1.0378291097877081, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 366, train_loss = 1.0366056164202746, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 367, train_loss = 1.0359482541680336, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 368, train_loss = 1.0350856060686056, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 369, train_loss = 1.034139712661272, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 370, train_loss = 1.0339541025459766, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 371, train_loss = 1.0326059361395892, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 372, train_loss = 1.0320631004869938, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 373, train_loss = 1.0311779963376466, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 374, train_loss = 1.0307840170862619, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 375, train_loss = 1.0293185872433241, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 376, train_loss = 1.0288922587933484, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 377, train_loss = 1.0281290039420128, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 378, train_loss = 1.0276176532206591, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 379, train_loss = 1.0264515703020152, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 380, train_loss = 1.0257406048476696, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 381, train_loss = 1.0254551731050014, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 382, train_loss = 1.024490062147379, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 383, train_loss = 1.023415478557581, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 384, train_loss = 1.0231176229717676, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 385, train_loss = 1.021885064750677, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 386, train_loss = 1.021986855805153, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 387, train_loss = 1.0208012672665063, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 388, train_loss = 1.0203006863594055, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 389, train_loss = 1.0192104987800121, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 390, train_loss = 1.0188399702310562, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 391, train_loss = 1.018031687795883, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 392, train_loss = 1.0177771002054214, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 393, train_loss = 1.016694219171768, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 394, train_loss = 1.0157453479769174, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 395, train_loss = 1.0156728824076708, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 396, train_loss = 1.0139637154934462, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 397, train_loss = 1.0138952198030893, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 398, train_loss = 1.012513933092123, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 399, train_loss = 1.0126666761934757, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 400, train_loss = 1.0119262548687402, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 401, train_loss = 1.0108761923911516, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 402, train_loss = 1.0103203828039113, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 403, train_loss = 1.0093750593659934, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 404, train_loss = 1.008844527095789, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 405, train_loss = 1.0081264041364193, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 406, train_loss = 1.0077987636032049, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 407, train_loss = 1.0068619114754256, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 408, train_loss = 1.0064448242483195, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 409, train_loss = 1.0056036064925138, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 410, train_loss = 1.0051835055055562, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 411, train_loss = 1.0042873732745647, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 412, train_loss = 1.0038407730462495, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 413, train_loss = 1.002361780643696, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 414, train_loss = 1.0024705255927984, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 415, train_loss = 1.001381075620884, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 416, train_loss = 1.0011045759019908, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 417, train_loss = 1.0005137684347574, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 418, train_loss = 1.000009261071682, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 419, train_loss = 0.9990749011340085, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 420, train_loss = 0.998549610376358, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 421, train_loss = 0.9981113957765047, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 422, train_loss = 0.9974427384731825, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 423, train_loss = 0.9966425808670465, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 424, train_loss = 0.996247618139023, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 425, train_loss = 0.9958382323384285, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 426, train_loss = 0.9948238407669123, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 427, train_loss = 0.9946101320383605, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 428, train_loss = 0.9936514447035734, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 429, train_loss = 0.9930378111603204, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 430, train_loss = 0.9928785972297192, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 431, train_loss = 0.9915129890141543, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 432, train_loss = 0.9914190036652144, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 433, train_loss = 0.9904256723821163, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 434, train_loss = 0.9901593489048537, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 435, train_loss = 0.9897808469831944, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 436, train_loss = 0.9892265349626541, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 437, train_loss = 0.9885595093073789, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 438, train_loss = 0.9878854341804981, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 439, train_loss = 0.9873271211981773, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 440, train_loss = 0.9863648911414202, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 441, train_loss = 0.9861909002065659, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 442, train_loss = 0.9852617345750332, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 443, train_loss = 0.985284898430109, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 444, train_loss = 0.9845427088439465, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 445, train_loss = 0.9839812939462718, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 446, train_loss = 0.983008303999668, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 447, train_loss = 0.9827634779212531, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 448, train_loss = 0.9824546687304974, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 449, train_loss = 0.9816339972021524, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 450, train_loss = 0.980829024076229, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 451, train_loss = 0.9805137862858828, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 452, train_loss = 0.9800214171409607, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 453, train_loss = 0.9791513842938002, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 454, train_loss = 0.978580122202402, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 455, train_loss = 0.9782816568913404, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 456, train_loss = 0.9780509372649249, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 457, train_loss = 0.9774031924607698, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 458, train_loss = 0.976425688713789, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 459, train_loss = 0.9758887849748135, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 460, train_loss = 0.9750594372453634, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 461, train_loss = 0.9753758820297662, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 462, train_loss = 0.9748080844583455, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 463, train_loss = 0.9741401672363281, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 464, train_loss = 0.9732921322283801, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 465, train_loss = 0.9732839936914388, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 466, train_loss = 0.9724178500473499, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 467, train_loss = 0.9718324778077658, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 468, train_loss = 0.9719070705177728, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 469, train_loss = 0.9711080975830555, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 470, train_loss = 0.9701698012650013, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 471, train_loss = 0.9700150253775064, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 472, train_loss = 0.9691677826049272, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 473, train_loss = 0.9691432590188924, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 474, train_loss = 0.9678549816308077, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 475, train_loss = 0.967350747436285, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 476, train_loss = 0.9672983810305595, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 477, train_loss = 0.9665369242429733, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 478, train_loss = 0.9661660455167294, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 479, train_loss = 0.96576714143157, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 480, train_loss = 0.9648530793783721, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 481, train_loss = 0.9649175368249416, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 482, train_loss = 0.9641600897011813, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 483, train_loss = 0.9638584554195404, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 484, train_loss = 0.9635257199406624, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 485, train_loss = 0.9628455986676272, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 486, train_loss = 0.9619912815687712, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 487, train_loss = 0.9612151918408927, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 488, train_loss = 0.9613180384039879, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 489, train_loss = 0.9609799049794674, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 490, train_loss = 0.9601534828543663, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 491, train_loss = 0.9599285908043385, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 492, train_loss = 0.959680794418091, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 493, train_loss = 0.9591807474789675, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 494, train_loss = 0.9581082215008792, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 495, train_loss = 0.958126038312912, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 496, train_loss = 0.9577150444092695, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 497, train_loss = 0.9574376145901624, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 498, train_loss = 0.9563425928354263, train_acc = 0.9982533768048439\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 499, train_loss = 0.9566228936018888, train_acc = 0.9983698183511877\n",
      "test Acc 0.9762569832402235:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████████████████████████▋                                     | 14/30 [2:19:37<2:40:01, 600.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "15th- epoch: 0, train_loss = 141.84736455976963, train_acc = 0.7536096879366558\n",
      "test Acc 0.8556797020484171:\n",
      "15th- epoch: 1, train_loss = 49.80940514802933, train_acc = 0.8971821145784816\n",
      "test Acc 0.9115456238361266:\n",
      "15th- epoch: 2, train_loss = 35.64134393632412, train_acc = 0.9283884489986027\n",
      "test Acc 0.9236499068901304:\n",
      "15th- epoch: 3, train_loss = 28.37890825420618, train_acc = 0.9437587331159758\n",
      "test Acc 0.9329608938547486:\n",
      "15th- epoch: 4, train_loss = 23.78404115140438, train_acc = 0.9541220307405682\n",
      "test Acc 0.9385474860335196:\n",
      "15th- epoch: 5, train_loss = 20.597284607589245, train_acc = 0.9620400558919422\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 6, train_loss = 18.21057205274701, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 7, train_loss = 16.347446657717228, train_acc = 0.9707731718677224\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 8, train_loss = 14.83741551078856, train_acc = 0.9739170936190032\n",
      "test Acc 0.9539106145251397:\n",
      "15th- epoch: 9, train_loss = 13.59235561080277, train_acc = 0.976245924545878\n",
      "test Acc 0.9562383612662942:\n",
      "15th- epoch: 10, train_loss = 12.523471435531974, train_acc = 0.9776432231020028\n",
      "test Acc 0.957635009310987:\n",
      "15th- epoch: 11, train_loss = 11.60104981996119, train_acc = 0.9790405216581276\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 12, train_loss = 10.78715904429555, train_acc = 0.9805542617605962\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 13, train_loss = 10.067489450797439, train_acc = 0.981951560316721\n",
      "test Acc 0.9618249534450651:\n",
      "15th- epoch: 14, train_loss = 9.428212298080325, train_acc = 0.9833488588728458\n",
      "test Acc 0.9618249534450651:\n",
      "15th- epoch: 15, train_loss = 8.862844862043858, train_acc = 0.9843968327899395\n",
      "test Acc 0.962756052141527:\n",
      "15th- epoch: 16, train_loss = 8.355008633807302, train_acc = 0.9853283651606893\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 17, train_loss = 7.894004886969924, train_acc = 0.9862598975314392\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 18, train_loss = 7.4732456356287, train_acc = 0.9870749883558454\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 19, train_loss = 7.096097953617573, train_acc = 0.9876571960875641\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 20, train_loss = 6.752875152043998, train_acc = 0.9882394038192828\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 21, train_loss = 6.437731455080211, train_acc = 0.9887051700046576\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 22, train_loss = 6.151152375154197, train_acc = 0.9895202608290639\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 23, train_loss = 5.884624943137169, train_acc = 0.99033535165347\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 24, train_loss = 5.641278299503028, train_acc = 0.99033535165347\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 25, train_loss = 5.414965778589249, train_acc = 0.9911504424778761\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 26, train_loss = 5.206110608763993, train_acc = 0.9914997671169073\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 27, train_loss = 5.011515497229993, train_acc = 0.9916162086632511\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 28, train_loss = 4.832443297840655, train_acc = 0.992081974848626\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 29, train_loss = 4.664438298903406, train_acc = 0.9923148579413135\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 30, train_loss = 4.508284750394523, train_acc = 0.9926641825803446\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 31, train_loss = 4.364558408968151, train_acc = 0.9931299487657196\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 32, train_loss = 4.228872840292752, train_acc = 0.9937121564974383\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 33, train_loss = 4.102591437287629, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 34, train_loss = 3.9860926447436213, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 35, train_loss = 3.877144164405763, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 36, train_loss = 3.771838047541678, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 37, train_loss = 3.675392475910485, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 38, train_loss = 3.5816631130874157, train_acc = 0.9947601304145319\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 39, train_loss = 3.4954550564289093, train_acc = 0.9947601304145319\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 40, train_loss = 3.4125124155543745, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 41, train_loss = 3.3347697257995605, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 42, train_loss = 3.260887162294239, train_acc = 0.9951094550535631\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 43, train_loss = 3.1920852945186198, train_acc = 0.9951094550535631\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 44, train_loss = 3.1258067316375673, train_acc = 0.9953423381462506\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 45, train_loss = 3.0633394247852266, train_acc = 0.9954587796925943\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 46, train_loss = 3.0040179044008255, train_acc = 0.9954587796925943\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 47, train_loss = 2.945927806198597, train_acc = 0.9954587796925943\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 48, train_loss = 2.894032336771488, train_acc = 0.9954587796925943\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 49, train_loss = 2.841908446047455, train_acc = 0.995575221238938\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 50, train_loss = 2.793029483407736, train_acc = 0.995575221238938\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 51, train_loss = 2.7459369539283216, train_acc = 0.9958081043316255\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 52, train_loss = 2.701454897876829, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 53, train_loss = 2.6575772874057293, train_acc = 0.9959245458779693\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 54, train_loss = 2.616422366350889, train_acc = 0.9958081043316255\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 55, train_loss = 2.5778906852938235, train_acc = 0.996040987424313\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 56, train_loss = 2.539310330990702, train_acc = 0.996040987424313\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 57, train_loss = 2.5038690329529345, train_acc = 0.996040987424313\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 58, train_loss = 2.468426099512726, train_acc = 0.996040987424313\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 59, train_loss = 2.43567268922925, train_acc = 0.996040987424313\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 60, train_loss = 2.402779098600149, train_acc = 0.9963903120633442\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 61, train_loss = 2.3718688092194498, train_acc = 0.9966231951560317\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 62, train_loss = 2.3419809588231146, train_acc = 0.9967396367023754\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 63, train_loss = 2.313667830079794, train_acc = 0.9967396367023754\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 64, train_loss = 2.2859355225227773, train_acc = 0.9967396367023754\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 65, train_loss = 2.258590965066105, train_acc = 0.9967396367023754\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 66, train_loss = 2.233067027060315, train_acc = 0.9967396367023754\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 67, train_loss = 2.2082485754508525, train_acc = 0.9967396367023754\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 68, train_loss = 2.184732747497037, train_acc = 0.9967396367023754\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 69, train_loss = 2.1600992891471833, train_acc = 0.9970889613414066\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 70, train_loss = 2.1388823688030243, train_acc = 0.9969725197950629\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 71, train_loss = 2.1163750228006393, train_acc = 0.9969725197950629\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 72, train_loss = 2.096068589715287, train_acc = 0.9969725197950629\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 73, train_loss = 2.0750673338770866, train_acc = 0.9969725197950629\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 74, train_loss = 2.0551248900592327, train_acc = 0.9970889613414066\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 75, train_loss = 2.0362447388470173, train_acc = 0.9969725197950629\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 76, train_loss = 2.0177598136942834, train_acc = 0.9969725197950629\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 77, train_loss = 2.000088969944045, train_acc = 0.9970889613414066\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 78, train_loss = 1.9823305632453412, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 79, train_loss = 1.9663049939554185, train_acc = 0.9970889613414066\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 80, train_loss = 1.9490165684837848, train_acc = 0.9972054028877504\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 81, train_loss = 1.933401747373864, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "15th- epoch: 82, train_loss = 1.9182808462064713, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "15th- epoch: 83, train_loss = 1.9031321455258876, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 84, train_loss = 1.8883252914529294, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 85, train_loss = 1.8744966760277748, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 86, train_loss = 1.8607807394582778, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 87, train_loss = 1.8468119960743934, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 88, train_loss = 1.834352069767192, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 89, train_loss = 1.82105378434062, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 90, train_loss = 1.8092091556172818, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 91, train_loss = 1.796788490144536, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 92, train_loss = 1.7851656961720437, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 93, train_loss = 1.7733597047626972, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 94, train_loss = 1.7620724651496857, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 95, train_loss = 1.7503847617190331, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 96, train_loss = 1.7393831696826965, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 97, train_loss = 1.728192500770092, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 98, train_loss = 1.7179365183692425, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 99, train_loss = 1.7073245234787464, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 100, train_loss = 1.6979394294321537, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 101, train_loss = 1.6880682818591595, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 102, train_loss = 1.6783342089038342, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 103, train_loss = 1.6696677457075566, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 104, train_loss = 1.66015329468064, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 105, train_loss = 1.6514575120527297, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 106, train_loss = 1.6429841865319759, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 107, train_loss = 1.6342743672430515, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 108, train_loss = 1.6256031543016434, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 109, train_loss = 1.617696994333528, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 110, train_loss = 1.6096452040364966, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 111, train_loss = 1.6012996038189158, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 112, train_loss = 1.5938144152751192, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 113, train_loss = 1.5866412246832624, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 114, train_loss = 1.5790456533432007, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 115, train_loss = 1.5720263036200777, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 116, train_loss = 1.564504399895668, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 117, train_loss = 1.558383741765283, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 118, train_loss = 1.5510874638566747, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 119, train_loss = 1.5447784513235092, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 120, train_loss = 1.5381815371802077, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 121, train_loss = 1.5317758297314867, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 122, train_loss = 1.5252292938530445, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 123, train_loss = 1.5191389980027452, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 124, train_loss = 1.5127736888825893, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 125, train_loss = 1.5066848658025265, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 126, train_loss = 1.5008275931468233, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 127, train_loss = 1.4948126301169395, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 128, train_loss = 1.4895275024464354, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 129, train_loss = 1.483992731780745, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 130, train_loss = 1.4780246230075136, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 131, train_loss = 1.4723873734474182, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 132, train_loss = 1.4674408795544878, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 133, train_loss = 1.462441566050984, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 134, train_loss = 1.4569578232476488, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 135, train_loss = 1.4517051515867934, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 136, train_loss = 1.4472292648861185, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 137, train_loss = 1.4417596397688612, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 138, train_loss = 1.4371557781705633, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 139, train_loss = 1.4323027916252613, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 140, train_loss = 1.4280765926232561, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 141, train_loss = 1.4235170967876911, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 142, train_loss = 1.4185966165969148, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 143, train_loss = 1.4143742583692074, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 144, train_loss = 1.4100554684409872, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 145, train_loss = 1.4056299241492525, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 146, train_loss = 1.4012237936258316, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 147, train_loss = 1.3969546022126451, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 148, train_loss = 1.3934669172158465, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 149, train_loss = 1.3886352615663782, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 150, train_loss = 1.384520192979835, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 151, train_loss = 1.3804009357700124, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 152, train_loss = 1.3765324540436268, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 153, train_loss = 1.3726445647189394, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 154, train_loss = 1.3686390966176987, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 155, train_loss = 1.3652263159165159, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 156, train_loss = 1.361290962784551, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 157, train_loss = 1.3576237497618422, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 158, train_loss = 1.3540231846272945, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 159, train_loss = 1.3506688810884953, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 160, train_loss = 1.3465820824494585, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 161, train_loss = 1.3436545245349407, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 162, train_loss = 1.3400552136590704, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 163, train_loss = 1.3366229111561552, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 164, train_loss = 1.3335820460924879, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 165, train_loss = 1.3301302790641785, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 166, train_loss = 1.3265790194272995, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 167, train_loss = 1.3242484318325296, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 168, train_loss = 1.320163831114769, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 169, train_loss = 1.3174197239568457, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 170, train_loss = 1.3142692856490612, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 171, train_loss = 1.311241004616022, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 172, train_loss = 1.3082888412172906, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 173, train_loss = 1.3052304151351564, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 174, train_loss = 1.3024236758355983, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 175, train_loss = 1.2989268365199678, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 176, train_loss = 1.2963064461946487, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 177, train_loss = 1.2936289596254937, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 178, train_loss = 1.290863886475563, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 179, train_loss = 1.28761712834239, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 180, train_loss = 1.2855393663048744, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 181, train_loss = 1.2821334947948344, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 182, train_loss = 1.2799003112013452, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 183, train_loss = 1.2767029243404977, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 184, train_loss = 1.2745695114135742, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 185, train_loss = 1.2714524455368519, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 186, train_loss = 1.26879732060479, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 187, train_loss = 1.2666375550325029, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 188, train_loss = 1.2642562587861903, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 189, train_loss = 1.2614605476264842, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 190, train_loss = 1.2591041612322442, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 191, train_loss = 1.2567570880055428, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 192, train_loss = 1.2539374493062496, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 193, train_loss = 1.252019513398409, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 194, train_loss = 1.2491659919614904, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 195, train_loss = 1.246777096122969, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 196, train_loss = 1.244755458086729, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 197, train_loss = 1.242149941623211, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 198, train_loss = 1.240270537615288, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 199, train_loss = 1.2375526378746144, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 200, train_loss = 1.2353989121620543, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 201, train_loss = 1.2332047795061953, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 202, train_loss = 1.2313655950129032, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 203, train_loss = 1.2289531615679152, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 204, train_loss = 1.226506733626593, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 205, train_loss = 1.224749828397762, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 206, train_loss = 1.222422655671835, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 207, train_loss = 1.2205620718305, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 208, train_loss = 1.2180474537308328, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 209, train_loss = 1.2165257868473418, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 210, train_loss = 1.2141404722933657, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 211, train_loss = 1.2124267754261382, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 212, train_loss = 1.2102740903501399, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 213, train_loss = 1.2084795857663266, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 214, train_loss = 1.206229769915808, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 215, train_loss = 1.2044156976044178, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 216, train_loss = 1.20254947245121, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 217, train_loss = 1.2007145062088966, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 218, train_loss = 1.198394626379013, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 219, train_loss = 1.196845632046461, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 220, train_loss = 1.1949490110273473, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 221, train_loss = 1.1932514235377312, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 222, train_loss = 1.1914609571103938, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 223, train_loss = 1.1893541241879575, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 224, train_loss = 1.1878027791972272, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 225, train_loss = 1.1861188796465285, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 226, train_loss = 1.1840190974180587, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 227, train_loss = 1.1823668467695825, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 228, train_loss = 1.180374217510689, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 229, train_loss = 1.179114893078804, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 230, train_loss = 1.1775664028828032, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 231, train_loss = 1.1757847269182093, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 232, train_loss = 1.173769527405966, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 233, train_loss = 1.1722974466974847, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 234, train_loss = 1.1705208967323415, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 235, train_loss = 1.1686796682770364, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 236, train_loss = 1.1670340771670453, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 237, train_loss = 1.166004617989529, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 238, train_loss = 1.1640805055503733, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 239, train_loss = 1.1625737461145036, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 240, train_loss = 1.1611107898061164, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 241, train_loss = 1.159625640779268, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 242, train_loss = 1.1577858738601208, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 243, train_loss = 1.156242714554537, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 244, train_loss = 1.1549298775498755, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 245, train_loss = 1.1533491263980977, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 246, train_loss = 1.151866169006098, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 247, train_loss = 1.1502480556373484, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 248, train_loss = 1.1491716454620473, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 249, train_loss = 1.1473836128716357, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 250, train_loss = 1.1463441860978492, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 251, train_loss = 1.1448806909029372, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 252, train_loss = 1.1432673682575114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 253, train_loss = 1.1416966517572291, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 254, train_loss = 1.1403792749042623, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 255, train_loss = 1.1392859717016108, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 256, train_loss = 1.1376832351088524, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 257, train_loss = 1.1362350310082547, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 258, train_loss = 1.1351186012034304, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 259, train_loss = 1.1334776530857198, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 260, train_loss = 1.1321774671669118, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 261, train_loss = 1.1310125167365186, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 262, train_loss = 1.129757312417496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 263, train_loss = 1.1282264304463752, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 264, train_loss = 1.1270290252869017, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 265, train_loss = 1.1258092920179479, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 266, train_loss = 1.1244510573451407, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 267, train_loss = 1.123802125453949, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 268, train_loss = 1.12173454585718, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 269, train_loss = 1.1207014347310178, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 270, train_loss = 1.119644219696056, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 271, train_loss = 1.118271338462364, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 272, train_loss = 1.116902747482527, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 273, train_loss = 1.1154251483385451, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 274, train_loss = 1.1148137387936004, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 275, train_loss = 1.1135430485010147, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 276, train_loss = 1.111968982964754, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 277, train_loss = 1.110919778526295, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 278, train_loss = 1.1096202209591866, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 279, train_loss = 1.1087813675403595, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 280, train_loss = 1.1073869802057743, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 281, train_loss = 1.1064506769180298, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 282, train_loss = 1.105093777179718, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 283, train_loss = 1.1038787178695202, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 284, train_loss = 1.1026146511430852, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 285, train_loss = 1.1015642856364138, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 286, train_loss = 1.1007639306480996, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 287, train_loss = 1.0995581609313376, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 288, train_loss = 1.0986078307032585, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 289, train_loss = 1.097246176272165, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 290, train_loss = 1.0960310411755927, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 291, train_loss = 1.0950778871774673, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 292, train_loss = 1.094052473694319, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 293, train_loss = 1.0932423385384027, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 294, train_loss = 1.0918039915559348, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 295, train_loss = 1.0908868374826852, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 296, train_loss = 1.090025182813406, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 297, train_loss = 1.0888788228330668, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 298, train_loss = 1.087767827004427, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 299, train_loss = 1.0864663856627885, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 300, train_loss = 1.0857542070152704, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 301, train_loss = 1.0848266743123531, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 302, train_loss = 1.0834789760410786, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 303, train_loss = 1.0825624652206898, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 304, train_loss = 1.0814164193870965, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 305, train_loss = 1.080291041493183, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 306, train_loss = 1.0796678811311722, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 307, train_loss = 1.0789584033191204, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 308, train_loss = 1.0774441013636533, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 309, train_loss = 1.0766145350935403, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 310, train_loss = 1.075418828666443, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 311, train_loss = 1.0747290030121803, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 312, train_loss = 1.073925187200075, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 313, train_loss = 1.0724099514482077, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 314, train_loss = 1.0719951813516673, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 315, train_loss = 1.0708612153830472, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 316, train_loss = 1.0699712087807711, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 317, train_loss = 1.0691977789101657, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 318, train_loss = 1.0681365554628428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 319, train_loss = 1.067040991038084, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 320, train_loss = 1.0663217455148697, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 321, train_loss = 1.065350454300642, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 322, train_loss = 1.0647267314197961, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 323, train_loss = 1.0638154509069864, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 324, train_loss = 1.0627418458461761, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 325, train_loss = 1.0619234455225524, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 326, train_loss = 1.0607905623910483, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 327, train_loss = 1.0601206719875336, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 328, train_loss = 1.059140119701624, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 329, train_loss = 1.0584580413997173, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 330, train_loss = 1.0575123988091946, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 331, train_loss = 1.056362138449913, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 332, train_loss = 1.0558739552798215, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 333, train_loss = 1.0547493398189545, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 334, train_loss = 1.0540796046552714, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 335, train_loss = 1.0530022767779883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 336, train_loss = 1.0520942149159964, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 337, train_loss = 1.051426080375677, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 338, train_loss = 1.0508116744458675, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 339, train_loss = 1.049412132560974, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 340, train_loss = 1.0488383819756564, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 341, train_loss = 1.0482154749333858, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 342, train_loss = 1.047644524514908, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 343, train_loss = 1.0465523190796375, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 344, train_loss = 1.0459151975810528, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 345, train_loss = 1.0445321053266525, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 346, train_loss = 1.0441192562284414, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 347, train_loss = 1.0430680947902147, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 348, train_loss = 1.0424935383198317, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 349, train_loss = 1.0415256929991301, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 350, train_loss = 1.040783559292322, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 351, train_loss = 1.0399786469934043, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 352, train_loss = 1.0391026511788368, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 353, train_loss = 1.0385084164736327, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 354, train_loss = 1.0373577326536179, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 355, train_loss = 1.037129394710064, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 356, train_loss = 1.0361166025104467, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 357, train_loss = 1.035335823893547, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 358, train_loss = 1.0347438727912959, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 359, train_loss = 1.0338632675411645, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 360, train_loss = 1.0331399403512478, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 361, train_loss = 1.0324241183698177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 362, train_loss = 1.0318812330660876, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 363, train_loss = 1.03057030835771, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 364, train_loss = 1.0303704552352428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 365, train_loss = 1.0294602861104067, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 366, train_loss = 1.0286483230593149, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 367, train_loss = 1.0281203103659209, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 368, train_loss = 1.0272955832479056, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 369, train_loss = 1.026452086865902, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 370, train_loss = 1.0255258145334665, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 371, train_loss = 1.024981831520563, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 372, train_loss = 1.0242411643266678, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 373, train_loss = 1.0232900058326777, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 374, train_loss = 1.0231362953782082, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 375, train_loss = 1.0222779797913972, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 376, train_loss = 1.0216033967735711, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 377, train_loss = 1.0207966566085815, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 378, train_loss = 1.020263905316824, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 379, train_loss = 1.0193320935068186, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 380, train_loss = 1.0190199154021684, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 381, train_loss = 1.0181469855306204, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 382, train_loss = 1.017596402525669, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 383, train_loss = 1.0169791219232138, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 384, train_loss = 1.0158783557417337, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 385, train_loss = 1.0150088059308473, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 386, train_loss = 1.0147851618530694, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 387, train_loss = 1.0139097844657954, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 388, train_loss = 1.013483033835655, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 389, train_loss = 1.0125642754137516, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 390, train_loss = 1.0121308229863644, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 391, train_loss = 1.0111326947808266, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 392, train_loss = 1.0108190750179347, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 393, train_loss = 1.0102847827074584, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 394, train_loss = 1.0094330025312956, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 395, train_loss = 1.0086000984010752, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 396, train_loss = 1.0078050705196802, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 397, train_loss = 1.0079534227552358, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 398, train_loss = 1.007143555820221, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 399, train_loss = 1.006263750285143, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 400, train_loss = 1.005689146608347, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 401, train_loss = 1.005172253906494, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 402, train_loss = 1.0042678403260652, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 403, train_loss = 1.0040819222631399, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 404, train_loss = 1.0032400911150035, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 405, train_loss = 1.0028209201991558, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 406, train_loss = 1.002180284500355, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 407, train_loss = 1.0013258320686873, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 408, train_loss = 1.000762508570915, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 409, train_loss = 1.0003785528242588, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 410, train_loss = 0.999834205955267, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 411, train_loss = 0.999489246547455, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 412, train_loss = 0.9986054003238678, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 413, train_loss = 0.9980835517344531, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 414, train_loss = 0.997502905636793, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 415, train_loss = 0.9969198368489742, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 416, train_loss = 0.9963381936249789, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 417, train_loss = 0.9957759119570255, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 418, train_loss = 0.9954258439538535, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 419, train_loss = 0.9945643419923726, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 420, train_loss = 0.9942229092121124, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 421, train_loss = 0.9933425573108252, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 422, train_loss = 0.9929413037898485, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 423, train_loss = 0.9924296960234642, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 424, train_loss = 0.9919059885141905, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 425, train_loss = 0.991411779075861, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 426, train_loss = 0.990680700779194, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 427, train_loss = 0.9902639252541121, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 428, train_loss = 0.9896605908870697, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 429, train_loss = 0.988734882324934, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 430, train_loss = 0.988588380307192, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 431, train_loss = 0.9883060095307883, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 432, train_loss = 0.9874781146645546, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 433, train_loss = 0.9869171679019928, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 434, train_loss = 0.9865193652512971, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 435, train_loss = 0.985763876378769, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 436, train_loss = 0.9852853094635066, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 437, train_loss = 0.9848464764654636, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 438, train_loss = 0.9840008057653904, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 439, train_loss = 0.9837721586227417, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 440, train_loss = 0.983196963876253, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 441, train_loss = 0.9825082905590534, train_acc = 0.9980204937121565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 442, train_loss = 0.9820314297976438, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 443, train_loss = 0.9818070145847742, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 444, train_loss = 0.9808936193585396, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 445, train_loss = 0.9804880196752492, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 446, train_loss = 0.9802265303733293, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 447, train_loss = 0.9799481282534543, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 448, train_loss = 0.9790754889545497, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 449, train_loss = 0.9783231044712011, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 450, train_loss = 0.9780043164792005, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 451, train_loss = 0.9774896999297198, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 452, train_loss = 0.9769733870925847, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 453, train_loss = 0.9764503265323583, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 454, train_loss = 0.9757458654639777, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 455, train_loss = 0.9758522063493729, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 456, train_loss = 0.9752456756832544, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 457, train_loss = 0.9747022775409278, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 458, train_loss = 0.9740805824694689, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 459, train_loss = 0.9733981092867907, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 460, train_loss = 0.9733213558793068, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 461, train_loss = 0.972905163973337, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 462, train_loss = 0.9722076666948851, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 463, train_loss = 0.971862930804491, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 464, train_loss = 0.971363689750433, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 465, train_loss = 0.9708777541818563, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 466, train_loss = 0.9703974202275276, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 467, train_loss = 0.9697707494196948, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 468, train_loss = 0.9697399151918944, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 469, train_loss = 0.969002361089224, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 470, train_loss = 0.9685592241585255, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 471, train_loss = 0.9681128946540412, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 472, train_loss = 0.9677933951315936, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 473, train_loss = 0.9671897006628569, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 474, train_loss = 0.9667068459093571, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 475, train_loss = 0.9668475215730723, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 476, train_loss = 0.9659285073576029, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 477, train_loss = 0.9650708436965942, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 478, train_loss = 0.9651767475006636, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 479, train_loss = 0.9640511199831963, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 480, train_loss = 0.9639974435267504, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 481, train_loss = 0.963511273264885, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 482, train_loss = 0.963339027017355, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 483, train_loss = 0.9628368417324964, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 484, train_loss = 0.9622100616397802, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 485, train_loss = 0.9622442188265268, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 486, train_loss = 0.961099486798048, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 487, train_loss = 0.9609037724731024, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 488, train_loss = 0.9602644580008928, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 489, train_loss = 0.9602505999209825, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 490, train_loss = 0.9595313171448652, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 491, train_loss = 0.9592860875127371, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 492, train_loss = 0.9589012116193771, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 493, train_loss = 0.9585790882410947, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 494, train_loss = 0.9577112309634686, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 495, train_loss = 0.9576086141169071, train_acc = 0.9980204937121565\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 496, train_loss = 0.9573153642413672, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 497, train_loss = 0.9566886859538499, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 498, train_loss = 0.9563863637449685, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 499, train_loss = 0.955466623097891, train_acc = 0.9980204937121565\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████                                   | 15/30 [2:29:37<2:30:01, 600.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "16th- epoch: 0, train_loss = 142.13731163740158, train_acc = 0.7412668840242198\n",
      "test Acc 0.8296089385474861:\n",
      "16th- epoch: 1, train_loss = 52.15036651492119, train_acc = 0.88996273870517\n",
      "test Acc 0.8985102420856611:\n",
      "16th- epoch: 2, train_loss = 36.70214994251728, train_acc = 0.9247787610619469\n",
      "test Acc 0.9180633147113594:\n",
      "16th- epoch: 3, train_loss = 29.112062893807888, train_acc = 0.941895668374476\n",
      "test Acc 0.9287709497206704:\n",
      "16th- epoch: 4, train_loss = 24.302316550165415, train_acc = 0.952491849091756\n",
      "test Acc 0.9371508379888268:\n",
      "16th- epoch: 5, train_loss = 20.88670487329364, train_acc = 0.9598276665114113\n",
      "test Acc 0.9436685288640596:\n",
      "16th- epoch: 6, train_loss = 18.344160962849855, train_acc = 0.9653004191895669\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 7, train_loss = 16.39275287091732, train_acc = 0.969608756404285\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 8, train_loss = 14.816338285803795, train_acc = 0.9727526781555659\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 9, train_loss = 13.521612085402012, train_acc = 0.9750815090824406\n",
      "test Acc 0.9539106145251397:\n",
      "16th- epoch: 10, train_loss = 12.422162164002657, train_acc = 0.9777596646483465\n",
      "test Acc 0.9557728119180633:\n",
      "16th- epoch: 11, train_loss = 11.484048129990697, train_acc = 0.9796227293898463\n",
      "test Acc 0.957169459962756:\n",
      "16th- epoch: 12, train_loss = 10.67268860526383, train_acc = 0.9817186772240335\n",
      "test Acc 0.9581005586592178:\n",
      "16th- epoch: 13, train_loss = 9.967162311077118, train_acc = 0.9834653004191896\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 14, train_loss = 9.340735372155905, train_acc = 0.9846297158826269\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 15, train_loss = 8.788957824930549, train_acc = 0.985444806707033\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 16, train_loss = 8.29861300997436, train_acc = 0.986376339077783\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 17, train_loss = 7.858287446200848, train_acc = 0.9868421052631579\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 18, train_loss = 7.463418351486325, train_acc = 0.9878900791802515\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 19, train_loss = 7.103317612782121, train_acc = 0.9884722869119702\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 20, train_loss = 6.778345452621579, train_acc = 0.9892873777363763\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 21, train_loss = 6.484288554638624, train_acc = 0.9895202608290639\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 22, train_loss = 6.215202532708645, train_acc = 0.989869585468095\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 23, train_loss = 5.970422446727753, train_acc = 0.9905682347461574\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 24, train_loss = 5.744049629196525, train_acc = 0.990801117838845\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 25, train_loss = 5.535503352992237, train_acc = 0.9917326502095948\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 26, train_loss = 5.341190691106021, train_acc = 0.9921984163949698\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 27, train_loss = 5.1625044690445065, train_acc = 0.9924312994876572\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 28, train_loss = 4.994070189073682, train_acc = 0.9927806241266884\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 29, train_loss = 4.837435615248978, train_acc = 0.9930135072193759\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 30, train_loss = 4.690251365303993, train_acc = 0.9937121564974383\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 31, train_loss = 4.554023456759751, train_acc = 0.9939450395901258\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 32, train_loss = 4.423700300976634, train_acc = 0.9939450395901258\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 33, train_loss = 4.301896317861974, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 34, train_loss = 4.185795536264777, train_acc = 0.9941779226828132\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 35, train_loss = 4.078380727209151, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 36, train_loss = 3.9743285728618503, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 37, train_loss = 3.8752417927607894, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 38, train_loss = 3.7820313749834895, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 39, train_loss = 3.6925824005156755, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 40, train_loss = 3.6082775304093957, train_acc = 0.9954587796925943\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 41, train_loss = 3.5276178140193224, train_acc = 0.9954587796925943\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 42, train_loss = 3.4514829833060503, train_acc = 0.9958081043316255\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 43, train_loss = 3.3787002936005592, train_acc = 0.9958081043316255\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 44, train_loss = 3.3085919078439474, train_acc = 0.9958081043316255\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 45, train_loss = 3.2417541723698378, train_acc = 0.9958081043316255\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 46, train_loss = 3.1775186890736222, train_acc = 0.996040987424313\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 47, train_loss = 3.116902220994234, train_acc = 0.9961574289706567\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 48, train_loss = 3.058206068817526, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 49, train_loss = 3.003096826840192, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 50, train_loss = 2.948453061748296, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 51, train_loss = 2.897031153086573, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 52, train_loss = 2.8470021560788155, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 53, train_loss = 2.7988418671302497, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 54, train_loss = 2.753928195219487, train_acc = 0.9963903120633442\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 55, train_loss = 2.710632672999054, train_acc = 0.9963903120633442\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 56, train_loss = 2.6679365425370634, train_acc = 0.996506753609688\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 57, train_loss = 2.6277874507941306, train_acc = 0.9966231951560317\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 58, train_loss = 2.5895326561294496, train_acc = 0.9966231951560317\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 59, train_loss = 2.5519358702003956, train_acc = 0.9966231951560317\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 60, train_loss = 2.516523024532944, train_acc = 0.9967396367023754\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 61, train_loss = 2.4826902598142624, train_acc = 0.9968560782487191\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 62, train_loss = 2.4490208621136844, train_acc = 0.9968560782487191\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 63, train_loss = 2.4184126458130777, train_acc = 0.9968560782487191\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 64, train_loss = 2.387582733761519, train_acc = 0.9968560782487191\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 65, train_loss = 2.3594624493271112, train_acc = 0.9968560782487191\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 66, train_loss = 2.3305016891099513, train_acc = 0.9968560782487191\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 67, train_loss = 2.3047223896719515, train_acc = 0.9968560782487191\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 68, train_loss = 2.277798182796687, train_acc = 0.9969725197950629\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 69, train_loss = 2.253311062697321, train_acc = 0.9969725197950629\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 70, train_loss = 2.228853937704116, train_acc = 0.9970889613414066\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 71, train_loss = 2.205912107601762, train_acc = 0.9970889613414066\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 72, train_loss = 2.1836404874920845, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 73, train_loss = 2.161766420584172, train_acc = 0.9970889613414066\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 74, train_loss = 2.1408325671218336, train_acc = 0.9970889613414066\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 75, train_loss = 2.119832592085004, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 76, train_loss = 2.100494707468897, train_acc = 0.9970889613414066\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 77, train_loss = 2.082277377601713, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 78, train_loss = 2.0636681583710015, train_acc = 0.9972054028877504\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 79, train_loss = 2.0459274388849735, train_acc = 0.9973218444340941\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 80, train_loss = 2.0295131145976484, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 81, train_loss = 2.011618224903941, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 82, train_loss = 1.9962862157262862, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 83, train_loss = 1.980842534918338, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 84, train_loss = 1.9650933456141502, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 85, train_loss = 1.9505739707965404, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 86, train_loss = 1.935711097670719, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 87, train_loss = 1.921594062121585, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 88, train_loss = 1.9068384401034564, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 89, train_loss = 1.8925284680444747, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 90, train_loss = 1.879791670711711, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 91, train_loss = 1.8672120869159698, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 92, train_loss = 1.8544704020023346, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 93, train_loss = 1.8426844861824065, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 94, train_loss = 1.8306421290617436, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 95, train_loss = 1.81984634953551, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 96, train_loss = 1.8080283787567168, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 97, train_loss = 1.797380805015564, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 98, train_loss = 1.7863737866282463, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 99, train_loss = 1.7764063514769077, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 100, train_loss = 1.7660795722622424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 101, train_loss = 1.7565945014357567, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 102, train_loss = 1.7464370131492615, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 103, train_loss = 1.7367882691323757, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 104, train_loss = 1.7269113238435239, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 105, train_loss = 1.7185371939558536, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 106, train_loss = 1.7092404749710113, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 107, train_loss = 1.7010412439703941, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 108, train_loss = 1.691641490906477, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 109, train_loss = 1.6838103632908314, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 110, train_loss = 1.675507438601926, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 111, train_loss = 1.667127799242735, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 112, train_loss = 1.659204851835966, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 113, train_loss = 1.65165576338768, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 114, train_loss = 1.6435619506519288, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 115, train_loss = 1.6365946035366505, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 116, train_loss = 1.628809317946434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 117, train_loss = 1.6215826582629234, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 118, train_loss = 1.6147451747674495, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 119, train_loss = 1.6078265334945172, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 120, train_loss = 1.6004058234393597, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 121, train_loss = 1.5941170540172607, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 122, train_loss = 1.5874849408864975, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 123, train_loss = 1.5807403773069382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 124, train_loss = 1.5746649752836674, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 125, train_loss = 1.5679958674591035, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 126, train_loss = 1.5614929422736168, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 127, train_loss = 1.556163463741541, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 128, train_loss = 1.5494893789291382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 129, train_loss = 1.54378646123223, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 130, train_loss = 1.5383633151650429, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 131, train_loss = 1.5324125562328845, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 132, train_loss = 1.5269634102005512, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 133, train_loss = 1.5212043758947402, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 134, train_loss = 1.516050236998126, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 135, train_loss = 1.5107511777896434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 136, train_loss = 1.5048531133215874, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 137, train_loss = 1.5000989623367786, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 138, train_loss = 1.4945689179003239, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 139, train_loss = 1.4901038147509098, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 140, train_loss = 1.4847130166599527, train_acc = 0.9974382859804378\n",
      "test Acc 0.9781191806331471:\n",
      "16th- epoch: 141, train_loss = 1.4798380732536316, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 142, train_loss = 1.4748099334537983, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 143, train_loss = 1.4707449240377173, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 144, train_loss = 1.4656016578665003, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 145, train_loss = 1.4608379428973421, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 146, train_loss = 1.4566572034964338, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 147, train_loss = 1.451566199422814, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 148, train_loss = 1.447786202072166, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 149, train_loss = 1.44279269000981, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 150, train_loss = 1.4386416139313951, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 151, train_loss = 1.4347680347273126, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 152, train_loss = 1.430306389927864, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 153, train_loss = 1.4264239309122786, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 154, train_loss = 1.4220508424332365, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 155, train_loss = 1.4180658360710368, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 156, train_loss = 1.4139806292951107, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 157, train_loss = 1.4103773882379755, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 158, train_loss = 1.4061213409295306, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 159, train_loss = 1.4026190415024757, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 160, train_loss = 1.3984524855623022, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 161, train_loss = 1.3948266046354547, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 162, train_loss = 1.3910865212092176, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 163, train_loss = 1.387496573268436, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 164, train_loss = 1.3836944872746244, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 165, train_loss = 1.3802784780273214, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 166, train_loss = 1.3768930658698082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 167, train_loss = 1.3728721601655707, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 168, train_loss = 1.3699061250081286, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 169, train_loss = 1.3658889904618263, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 170, train_loss = 1.3630372969200835, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 171, train_loss = 1.3594621866941452, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 172, train_loss = 1.355876937508583, train_acc = 0.9974382859804378\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 173, train_loss = 1.353376449435018, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 174, train_loss = 1.3495963463792577, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 175, train_loss = 1.3466767184436321, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 176, train_loss = 1.3434239787748083, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 177, train_loss = 1.3400953760137782, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 178, train_loss = 1.3374702483415604, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 179, train_loss = 1.3345547653734684, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 180, train_loss = 1.3310651133069769, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 181, train_loss = 1.328741623670794, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 182, train_loss = 1.3252476738998666, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 183, train_loss = 1.3223608434200287, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 184, train_loss = 1.3193066604435444, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 185, train_loss = 1.316938430070877, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 186, train_loss = 1.3134224191308022, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 187, train_loss = 1.3107653545448557, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 188, train_loss = 1.3077762114116922, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 189, train_loss = 1.3050309481332079, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 190, train_loss = 1.3018135527381673, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 191, train_loss = 1.2999613048741594, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 192, train_loss = 1.297078532516025, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 193, train_loss = 1.2943323788931593, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 194, train_loss = 1.2915323413908482, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 195, train_loss = 1.2889579298207536, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 196, train_loss = 1.2859342010924593, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 197, train_loss = 1.2840895093977451, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 198, train_loss = 1.2808055244386196, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 199, train_loss = 1.277931671589613, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 200, train_loss = 1.2761552445590496, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 201, train_loss = 1.2731856839964166, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 202, train_loss = 1.2710175862303004, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 203, train_loss = 1.268529569148086, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 204, train_loss = 1.2664551176130772, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 205, train_loss = 1.264137846766971, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 206, train_loss = 1.2613299960503355, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 207, train_loss = 1.259113491862081, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 208, train_loss = 1.2569892555475235, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 209, train_loss = 1.2542523281881586, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 210, train_loss = 1.2524880593409762, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 211, train_loss = 1.2504260080168024, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 212, train_loss = 1.2477276833960786, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 213, train_loss = 1.2457095956197008, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 214, train_loss = 1.2438746182015166, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 215, train_loss = 1.2416797069599852, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 216, train_loss = 1.239037082879804, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 217, train_loss = 1.2370980506530032, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 218, train_loss = 1.234953691600822, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 219, train_loss = 1.2333692299434915, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 220, train_loss = 1.230930938036181, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 221, train_loss = 1.228578900336288, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 222, train_loss = 1.2267262861132622, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 223, train_loss = 1.2250385159859434, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 224, train_loss = 1.222768803476356, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 225, train_loss = 1.2209444468608126, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 226, train_loss = 1.2186677679419518, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 227, train_loss = 1.217246821790468, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 228, train_loss = 1.2151931424741633, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 229, train_loss = 1.2132358700037003, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 230, train_loss = 1.2108303879504092, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 231, train_loss = 1.2096687232260592, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 232, train_loss = 1.2074854845996015, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 233, train_loss = 1.2058076560497284, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 234, train_loss = 1.2035793314571492, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 235, train_loss = 1.2020582320983522, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 236, train_loss = 1.1999776425655, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 237, train_loss = 1.1983751517836936, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 238, train_loss = 1.1965980380773544, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 239, train_loss = 1.1946333895321004, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 240, train_loss = 1.1932339469785802, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 241, train_loss = 1.1911837880616076, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 242, train_loss = 1.1895043812692165, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 243, train_loss = 1.1881860817666166, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 244, train_loss = 1.1863275282084942, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 245, train_loss = 1.1843545113806613, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 246, train_loss = 1.1827383289928548, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 247, train_loss = 1.181194597214926, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 248, train_loss = 1.1796320391003974, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 249, train_loss = 1.1778894923627377, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 250, train_loss = 1.1762830105726607, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 251, train_loss = 1.1745497919619083, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 252, train_loss = 1.172906172752846, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 253, train_loss = 1.1712527225608937, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 254, train_loss = 1.1699686534702778, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 255, train_loss = 1.1681237407028675, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 256, train_loss = 1.166935570538044, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 257, train_loss = 1.1650510902400129, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 258, train_loss = 1.1634278098936193, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 259, train_loss = 1.1621201746165752, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 260, train_loss = 1.1604760860209353, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 261, train_loss = 1.1588187515735626, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 262, train_loss = 1.1573457668418996, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 263, train_loss = 1.1556148280506022, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 264, train_loss = 1.1544691820745356, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 265, train_loss = 1.1530895332689397, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 266, train_loss = 1.1513935451512225, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 267, train_loss = 1.1498953315312974, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 268, train_loss = 1.1485723182559013, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 269, train_loss = 1.147040254145395, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 270, train_loss = 1.1456947426195256, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 271, train_loss = 1.1444627518649213, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 272, train_loss = 1.142932080954779, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 273, train_loss = 1.1414734075660817, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 274, train_loss = 1.1403955605928786, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 275, train_loss = 1.1388171575963497, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 276, train_loss = 1.1376441605389118, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 277, train_loss = 1.136184600472916, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 278, train_loss = 1.1346836611628532, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 279, train_loss = 1.1332995842094533, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 280, train_loss = 1.1317055386607535, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 281, train_loss = 1.130815677344799, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 282, train_loss = 1.1294642848079093, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 283, train_loss = 1.1279865478281863, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 284, train_loss = 1.1268122370238416, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 285, train_loss = 1.1256848226184957, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 286, train_loss = 1.124126995622646, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 287, train_loss = 1.1229245848953724, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 288, train_loss = 1.1217501399223693, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 289, train_loss = 1.1205731469090097, train_acc = 0.9975547275267815\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 290, train_loss = 1.1194801107048988, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 291, train_loss = 1.117813915014267, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 292, train_loss = 1.116670373827219, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 293, train_loss = 1.1155948738451116, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 294, train_loss = 1.1141384827787988, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 295, train_loss = 1.1133116260170937, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 296, train_loss = 1.1120346250827424, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 297, train_loss = 1.110697594762314, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 298, train_loss = 1.1095225301687606, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 299, train_loss = 1.1083785382215865, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 300, train_loss = 1.1070594415068626, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 301, train_loss = 1.1059383861720562, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 302, train_loss = 1.1046619762782939, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 303, train_loss = 1.1040880158543587, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 304, train_loss = 1.1022340916097164, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 305, train_loss = 1.1012472373549826, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 306, train_loss = 1.100088858336676, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 307, train_loss = 1.099130370945204, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 308, train_loss = 1.0982319302856922, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 309, train_loss = 1.0966011211276054, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 310, train_loss = 1.0955720047350042, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 311, train_loss = 1.0947640960221179, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 312, train_loss = 1.0930864972178824, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 313, train_loss = 1.092341884970665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 314, train_loss = 1.0910258181393147, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 315, train_loss = 1.0901761862332933, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 316, train_loss = 1.0887719740276225, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 317, train_loss = 1.0879811110789888, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 318, train_loss = 1.0867457576096058, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 319, train_loss = 1.0855741475825198, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 320, train_loss = 1.0845263674855232, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 321, train_loss = 1.0835344021325, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 322, train_loss = 1.0830105381901376, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 323, train_loss = 1.0811895318329334, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 324, train_loss = 1.0805211539263837, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 325, train_loss = 1.0791485818917863, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 326, train_loss = 1.078289785713423, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 327, train_loss = 1.0776043124496937, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 328, train_loss = 1.0764264315366745, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 329, train_loss = 1.075180942832958, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 330, train_loss = 1.0746432803571224, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 331, train_loss = 1.073191172152292, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 332, train_loss = 1.0729940359597094, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 333, train_loss = 1.07135896012187, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 334, train_loss = 1.0704316695337184, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 335, train_loss = 1.0695500088040717, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 336, train_loss = 1.0689682264928706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 337, train_loss = 1.067694615572691, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 338, train_loss = 1.0664600009913556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 339, train_loss = 1.0655678163166158, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 340, train_loss = 1.0656520674820058, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 341, train_loss = 1.0638503829832189, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 342, train_loss = 1.0631127792294137, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 343, train_loss = 1.0623023211956024, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 344, train_loss = 1.060933019965887, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 345, train_loss = 1.0603946186602116, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 346, train_loss = 1.0595082913641818, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 347, train_loss = 1.058739238709677, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 348, train_loss = 1.0576758297975175, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 349, train_loss = 1.0568184318835847, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 350, train_loss = 1.0558947883546352, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 351, train_loss = 1.0551943083410151, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 352, train_loss = 1.0541944913566113, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 353, train_loss = 1.053169671446085, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 354, train_loss = 1.05268756049918, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 355, train_loss = 1.051426860212814, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 356, train_loss = 1.0507945828139782, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 357, train_loss = 1.0503180089290254, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 358, train_loss = 1.0488758769934066, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 359, train_loss = 1.0481122359633446, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 360, train_loss = 1.0475906605715863, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 361, train_loss = 1.0465927235782146, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 362, train_loss = 1.0457245993311517, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 363, train_loss = 1.0449291852419265, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 364, train_loss = 1.0443017619545572, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 365, train_loss = 1.0431065931916237, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 366, train_loss = 1.0424429861304816, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 367, train_loss = 1.0419668840768281, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 368, train_loss = 1.0409169656632002, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 369, train_loss = 1.0398498500289861, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 370, train_loss = 1.0398251538572367, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 371, train_loss = 1.0383570032718126, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 372, train_loss = 1.0378689803183079, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 373, train_loss = 1.0369139797985554, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 374, train_loss = 1.0362389658985194, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 375, train_loss = 1.035153048724169, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 376, train_loss = 1.0349791335465852, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 377, train_loss = 1.033803510159487, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 378, train_loss = 1.0330431473848876, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 379, train_loss = 1.0326185300946236, train_acc = 0.9977876106194691\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 380, train_loss = 1.0313840905728284, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 381, train_loss = 1.0308160247805063, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 382, train_loss = 1.0302486903965473, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 383, train_loss = 1.0289924504759256, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 384, train_loss = 1.0288627060654107, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 385, train_loss = 1.0276126240787562, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 386, train_loss = 1.0269297684135381, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 387, train_loss = 1.0268273105320986, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 388, train_loss = 1.0254717469215393, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 389, train_loss = 1.024844308703905, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 390, train_loss = 1.0243841260671616, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 391, train_loss = 1.0231563337147236, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 392, train_loss = 1.0228286944329739, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 393, train_loss = 1.0220903307199478, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 394, train_loss = 1.0214415676891804, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 395, train_loss = 1.0204395987093449, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 396, train_loss = 1.0198869047162589, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 397, train_loss = 1.0192873651685659, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 398, train_loss = 1.018541815370554, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 399, train_loss = 1.017882101237774, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 400, train_loss = 1.0173654009995516, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 401, train_loss = 1.0162439607083797, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 402, train_loss = 1.0160285755991936, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 403, train_loss = 1.014916181564331, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 404, train_loss = 1.0142591421899851, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 405, train_loss = 1.014034448802704, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 406, train_loss = 1.0129500018956605, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 407, train_loss = 1.0122732520103455, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 408, train_loss = 1.0116950199007988, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 409, train_loss = 1.010956984013319, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 410, train_loss = 1.01060825958848, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 411, train_loss = 1.0098856898548547, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 412, train_loss = 1.0092802780272905, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 413, train_loss = 1.0082692156138364, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 414, train_loss = 1.0079878965916578, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 415, train_loss = 1.0070571551623289, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 416, train_loss = 1.0062952687439974, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 417, train_loss = 1.0060092719795648, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 418, train_loss = 1.0051613822579384, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 419, train_loss = 1.004512927174801, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 420, train_loss = 1.003852978348732, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 421, train_loss = 1.0029186805186328, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 422, train_loss = 1.00313875451684, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 423, train_loss = 1.0018605676887091, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 424, train_loss = 1.0016337210836355, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 425, train_loss = 1.000606782734394, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 426, train_loss = 1.0002576361002866, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 427, train_loss = 0.9995506828126963, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 428, train_loss = 0.9991536177694798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 429, train_loss = 0.9981823613343295, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 430, train_loss = 0.9975896192190703, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 431, train_loss = 0.9974051912722643, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 432, train_loss = 0.9963168477115687, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 433, train_loss = 0.9963739862141665, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 434, train_loss = 0.9951103875937406, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 435, train_loss = 0.9947901988925878, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 436, train_loss = 0.9938608705997467, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 437, train_loss = 0.9935437093081418, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 438, train_loss = 0.9928071374597494, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 439, train_loss = 0.9923125418426935, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 440, train_loss = 0.9916626438498497, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 441, train_loss = 0.9910759242775384, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 442, train_loss = 0.9907238172891084, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 443, train_loss = 0.9895817326905672, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 444, train_loss = 0.9897616840898991, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 445, train_loss = 0.9884455725550652, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 446, train_loss = 0.9886908444168512, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 447, train_loss = 0.9874693925085012, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 448, train_loss = 0.9871984322962817, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 449, train_loss = 0.9864528489706572, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 450, train_loss = 0.986261960119009, train_acc = 0.9979040521658128\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 451, train_loss = 0.9852013364434242, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 452, train_loss = 0.9849077885446604, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 453, train_loss = 0.984282915800577, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 454, train_loss = 0.9839435468020383, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 455, train_loss = 0.9828161435725633, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 456, train_loss = 0.9827970527112484, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 457, train_loss = 0.9821076703665312, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 458, train_loss = 0.981708580016857, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 459, train_loss = 0.9806882453558501, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 460, train_loss = 0.9807759709656239, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 461, train_loss = 0.9794921564462129, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 462, train_loss = 0.979567358881468, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 463, train_loss = 0.9788098198769148, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 464, train_loss = 0.97862933203578, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 465, train_loss = 0.9776966919598635, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 466, train_loss = 0.9775164624152239, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 467, train_loss = 0.9769976139068604, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 468, train_loss = 0.9759254405798856, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 469, train_loss = 0.9758586163225118, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 470, train_loss = 0.9753030476567801, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 471, train_loss = 0.9748740444483701, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 472, train_loss = 0.9739199988543987, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 473, train_loss = 0.973841837287182, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 474, train_loss = 0.9730619328620378, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 475, train_loss = 0.9728426709771156, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 476, train_loss = 0.9716189876198769, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 477, train_loss = 0.9718889532086905, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 478, train_loss = 0.9712659604847431, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 479, train_loss = 0.9707316855492536, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 480, train_loss = 0.9703676539065782, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 481, train_loss = 0.9695422860386316, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 482, train_loss = 0.9692242170276586, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 483, train_loss = 0.9685848640801851, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 484, train_loss = 0.9682004513742868, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 485, train_loss = 0.9677033051848412, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 486, train_loss = 0.9670108519494534, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 487, train_loss = 0.9669909551739693, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 488, train_loss = 0.9658949983713683, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 489, train_loss = 0.9661653824150562, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 490, train_loss = 0.9650026671588421, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 491, train_loss = 0.9647939329443034, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 492, train_loss = 0.9642896093428135, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 493, train_loss = 0.9639461909828242, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 494, train_loss = 0.963300246745348, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 495, train_loss = 0.9626669846475124, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 496, train_loss = 0.9626827761530876, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 497, train_loss = 0.9618291358056013, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 498, train_loss = 0.9615643409488257, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 499, train_loss = 0.9608148944971617, train_acc = 0.9979040521658128\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████▎                                | 16/30 [2:39:38<2:20:03, 600.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "17th- epoch: 0, train_loss = 147.36077573895454, train_acc = 0.7384722869119702\n",
      "test Acc 0.8663873370577281:\n",
      "17th- epoch: 1, train_loss = 51.17999942600727, train_acc = 0.8997438285980438\n",
      "test Acc 0.909217877094972:\n",
      "17th- epoch: 2, train_loss = 37.34969172626734, train_acc = 0.9295528644620401\n",
      "test Acc 0.9287709497206704:\n",
      "17th- epoch: 3, train_loss = 30.291147138923407, train_acc = 0.9425943176525384\n",
      "test Acc 0.9329608938547486:\n",
      "17th- epoch: 4, train_loss = 25.684368815273046, train_acc = 0.9496972519795063\n",
      "test Acc 0.9385474860335196:\n",
      "17th- epoch: 5, train_loss = 22.33663908019662, train_acc = 0.9566837447601304\n",
      "test Acc 0.9432029795158287:\n",
      "17th- epoch: 6, train_loss = 19.774258144199848, train_acc = 0.9619236143455985\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 7, train_loss = 17.74955828115344, train_acc = 0.9651839776432231\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 8, train_loss = 16.096186673268676, train_acc = 0.9679785747554728\n",
      "test Acc 0.9539106145251397:\n",
      "17th- epoch: 9, train_loss = 14.695208074524999, train_acc = 0.970540288775035\n",
      "test Acc 0.957635009310987:\n",
      "17th- epoch: 10, train_loss = 13.503038756549358, train_acc = 0.9733348858872846\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 11, train_loss = 12.475979875773191, train_acc = 0.9763623660922217\n",
      "test Acc 0.9590316573556797:\n",
      "17th- epoch: 12, train_loss = 11.58516469039023, train_acc = 0.9776432231020028\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 13, train_loss = 10.800327217206359, train_acc = 0.9796227293898463\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 14, train_loss = 10.10877344571054, train_acc = 0.9816022356776898\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 15, train_loss = 9.484739540144801, train_acc = 0.9823008849557522\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 16, train_loss = 8.927799979224801, train_acc = 0.9838146250582208\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 17, train_loss = 8.426692800596356, train_acc = 0.9845132743362832\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 18, train_loss = 7.975822659209371, train_acc = 0.9852119236143456\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 19, train_loss = 7.558762244880199, train_acc = 0.9860270144387517\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 20, train_loss = 7.187584207393229, train_acc = 0.9874243129948765\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 21, train_loss = 6.845328642986715, train_acc = 0.9882394038192828\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 22, train_loss = 6.531471784226596, train_acc = 0.9887051700046576\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 23, train_loss = 6.239204924553633, train_acc = 0.9890544946436889\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 24, train_loss = 5.9716115621849895, train_acc = 0.98940381928272\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 25, train_loss = 5.72810186073184, train_acc = 0.989869585468095\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 26, train_loss = 5.4995414689183235, train_acc = 0.9904517931998137\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 27, train_loss = 5.291554821655154, train_acc = 0.9906846762925011\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 28, train_loss = 5.09431869443506, train_acc = 0.9912668840242198\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 29, train_loss = 4.915814037434757, train_acc = 0.9916162086632511\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 30, train_loss = 4.746330498717725, train_acc = 0.9918490917559385\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 31, train_loss = 4.5905900141224265, train_acc = 0.9921984163949698\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 32, train_loss = 4.442239427007735, train_acc = 0.9926641825803446\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 33, train_loss = 4.307756135240197, train_acc = 0.9930135072193759\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 34, train_loss = 4.18044660333544, train_acc = 0.9930135072193759\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 35, train_loss = 4.060148443095386, train_acc = 0.9930135072193759\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 36, train_loss = 3.948135289363563, train_acc = 0.9933628318584071\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 37, train_loss = 3.8421492129564285, train_acc = 0.9934792734047508\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 38, train_loss = 3.7440345687791705, train_acc = 0.9934792734047508\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 39, train_loss = 3.6539049297571182, train_acc = 0.9937121564974383\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 40, train_loss = 3.564429068006575, train_acc = 0.9939450395901258\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 41, train_loss = 3.4834774378687143, train_acc = 0.9945272473218444\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 42, train_loss = 3.4064575056545436, train_acc = 0.9946436888681882\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 43, train_loss = 3.3320579403080046, train_acc = 0.9946436888681882\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 44, train_loss = 3.2635835208930075, train_acc = 0.9949930135072194\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 45, train_loss = 3.1971156722866, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 46, train_loss = 3.1347401458770037, train_acc = 0.9949930135072194\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 47, train_loss = 3.0751220765523612, train_acc = 0.9949930135072194\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 48, train_loss = 3.0175782493315637, train_acc = 0.9949930135072194\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 49, train_loss = 2.9634891473688185, train_acc = 0.9951094550535631\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 50, train_loss = 2.9120918731205165, train_acc = 0.9952258965999069\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 51, train_loss = 2.862349007278681, train_acc = 0.9953423381462506\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 52, train_loss = 2.8145575425587595, train_acc = 0.9953423381462506\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 53, train_loss = 2.769234148785472, train_acc = 0.9953423381462506\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 54, train_loss = 2.724011111538857, train_acc = 0.9954587796925943\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 55, train_loss = 2.6842183619737625, train_acc = 0.9954587796925943\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 56, train_loss = 2.6440026774071157, train_acc = 0.9954587796925943\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 57, train_loss = 2.605764659587294, train_acc = 0.9954587796925943\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 58, train_loss = 2.569066096097231, train_acc = 0.9956916627852818\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 59, train_loss = 2.5323370755650103, train_acc = 0.9956916627852818\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 60, train_loss = 2.4995016679167747, train_acc = 0.9956916627852818\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 61, train_loss = 2.4656776785850525, train_acc = 0.9958081043316255\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 62, train_loss = 2.434945078101009, train_acc = 0.9959245458779693\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 63, train_loss = 2.405964954290539, train_acc = 0.996040987424313\n",
      "test Acc 0.9697392923649907:\n",
      "17th- epoch: 64, train_loss = 2.374703109264374, train_acc = 0.9961574289706567\n",
      "test Acc 0.9702048417132216:\n",
      "17th- epoch: 65, train_loss = 2.347758736461401, train_acc = 0.9961574289706567\n",
      "test Acc 0.9702048417132216:\n",
      "17th- epoch: 66, train_loss = 2.319077404681593, train_acc = 0.9961574289706567\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 67, train_loss = 2.293943580240011, train_acc = 0.9961574289706567\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 68, train_loss = 2.2678735605441034, train_acc = 0.9961574289706567\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 69, train_loss = 2.2436624206602573, train_acc = 0.9962738705170004\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 70, train_loss = 2.2196165919303894, train_acc = 0.9963903120633442\n",
      "test Acc 0.9702048417132216:\n",
      "17th- epoch: 71, train_loss = 2.1971205570735037, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 72, train_loss = 2.1755459010601044, train_acc = 0.996506753609688\n",
      "test Acc 0.9702048417132216:\n",
      "17th- epoch: 73, train_loss = 2.152575639542192, train_acc = 0.9966231951560317\n",
      "test Acc 0.9702048417132216:\n",
      "17th- epoch: 74, train_loss = 2.1325075863860548, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "17th- epoch: 75, train_loss = 2.1134863309562206, train_acc = 0.9966231951560317\n",
      "test Acc 0.9702048417132216:\n",
      "17th- epoch: 76, train_loss = 2.092282395809889, train_acc = 0.9966231951560317\n",
      "test Acc 0.9702048417132216:\n",
      "17th- epoch: 77, train_loss = 2.0744150951504707, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 78, train_loss = 2.055986105231568, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 79, train_loss = 2.0383404393214732, train_acc = 0.9966231951560317\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 80, train_loss = 2.0216672483365983, train_acc = 0.9966231951560317\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 81, train_loss = 2.0046108092647046, train_acc = 0.9966231951560317\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 82, train_loss = 1.9885181921999902, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 83, train_loss = 1.9737087253015488, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 84, train_loss = 1.9583150546532124, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 85, train_loss = 1.9434160303790122, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 86, train_loss = 1.9284189741592854, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 87, train_loss = 1.91479438287206, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 88, train_loss = 1.901784274727106, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 89, train_loss = 1.8873896077275276, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 90, train_loss = 1.8749548334162682, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 91, train_loss = 1.8621454797685146, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 92, train_loss = 1.8494412053842098, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 93, train_loss = 1.8375260147731751, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 94, train_loss = 1.8253144945483655, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 95, train_loss = 1.8131325903814286, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 96, train_loss = 1.8013702977914363, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 97, train_loss = 1.789981433423236, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 98, train_loss = 1.7796016409993172, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 99, train_loss = 1.7689145170152187, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 100, train_loss = 1.7596608239691705, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 101, train_loss = 1.7489653166849166, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 102, train_loss = 1.7392316323239356, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 103, train_loss = 1.7298408683855087, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 104, train_loss = 1.7199394654016942, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 105, train_loss = 1.7112096920609474, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 106, train_loss = 1.7026360121089965, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 107, train_loss = 1.6933720745146275, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 108, train_loss = 1.6848099168855697, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 109, train_loss = 1.6768506951630116, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 110, train_loss = 1.667791822226718, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 111, train_loss = 1.6597778722643852, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 112, train_loss = 1.651739452034235, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 113, train_loss = 1.6435550425667316, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 114, train_loss = 1.6364461642224342, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 115, train_loss = 1.6293178473133594, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 116, train_loss = 1.6215769264381379, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 117, train_loss = 1.614731864305213, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 118, train_loss = 1.6076070715207607, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 119, train_loss = 1.60110121848993, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 120, train_loss = 1.5938535642344505, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 121, train_loss = 1.5872639243025333, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 122, train_loss = 1.5800844456534833, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 123, train_loss = 1.5739488750696182, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 124, train_loss = 1.567853532731533, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 125, train_loss = 1.5611730467062443, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 126, train_loss = 1.5546751283109188, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 127, train_loss = 1.5490373622160405, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 128, train_loss = 1.543045510770753, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 129, train_loss = 1.5371400367002934, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 130, train_loss = 1.5310450743418187, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 131, train_loss = 1.5253993694204837, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 132, train_loss = 1.5198169637005776, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 133, train_loss = 1.5144994880538434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 134, train_loss = 1.5092460984596983, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 135, train_loss = 1.50347499048803, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 136, train_loss = 1.4984752224991098, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 137, train_loss = 1.4929632110288367, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 138, train_loss = 1.488142766058445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 139, train_loss = 1.4827901361277327, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 140, train_loss = 1.4776354158530012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 141, train_loss = 1.4731520091881976, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 142, train_loss = 1.467989103286527, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 143, train_loss = 1.4636502688517794, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 144, train_loss = 1.4589638151228428, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 145, train_loss = 1.4539598425617442, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 146, train_loss = 1.449788780300878, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 147, train_loss = 1.444997377693653, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 148, train_loss = 1.4408920196583495, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 149, train_loss = 1.4364155879011378, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 150, train_loss = 1.4318275587866083, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 151, train_loss = 1.4278025664389133, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 152, train_loss = 1.4229197651147842, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 153, train_loss = 1.4192449748516083, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 154, train_loss = 1.414333259104751, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 155, train_loss = 1.4102717824280262, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 156, train_loss = 1.4067176493117586, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 157, train_loss = 1.4020456423750147, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 158, train_loss = 1.398403481929563, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 159, train_loss = 1.3948804350802675, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 160, train_loss = 1.3904611790785566, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 161, train_loss = 1.386465591727756, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 162, train_loss = 1.3828245513141155, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 163, train_loss = 1.3792698668548837, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 164, train_loss = 1.3749066876480356, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 165, train_loss = 1.3719287825515494, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 166, train_loss = 1.3686466291546822, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 167, train_loss = 1.3652208695420995, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 168, train_loss = 1.3613437177846208, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 169, train_loss = 1.3577764307847247, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 170, train_loss = 1.354503127397038, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 171, train_loss = 1.3513688234379515, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 172, train_loss = 1.3478647345909849, train_acc = 0.9974382859804378\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 173, train_loss = 1.3447457564761862, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 174, train_loss = 1.3411674425005913, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 175, train_loss = 1.3385175293078646, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 176, train_loss = 1.3357173750409856, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 177, train_loss = 1.3322207443416119, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 178, train_loss = 1.3289978615939617, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 179, train_loss = 1.3262615613639355, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 180, train_loss = 1.3232067661592737, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 181, train_loss = 1.3202704899013042, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 182, train_loss = 1.317091559409164, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 183, train_loss = 1.3146361286053434, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 184, train_loss = 1.3113513278076425, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 185, train_loss = 1.3086141310632229, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 186, train_loss = 1.3061877390136942, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 187, train_loss = 1.3029610613593832, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 188, train_loss = 1.3005526289343834, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 189, train_loss = 1.2978169148555025, train_acc = 0.9974382859804378\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 190, train_loss = 1.2951846172800288, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 191, train_loss = 1.2926475517451763, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 192, train_loss = 1.2899236008524895, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 193, train_loss = 1.2871518582105637, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 194, train_loss = 1.2844934413442388, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 195, train_loss = 1.2819803009042516, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 196, train_loss = 1.2794329039752483, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 197, train_loss = 1.2768699700245634, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 198, train_loss = 1.2743930531432852, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 199, train_loss = 1.2719644358148798, train_acc = 0.9975547275267815\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 200, train_loss = 1.269372347742319, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 201, train_loss = 1.2674813369521871, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 202, train_loss = 1.264669969677925, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 203, train_loss = 1.2625210707774386, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 204, train_loss = 1.2601534897694364, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 205, train_loss = 1.258037426858209, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 206, train_loss = 1.2552619129419327, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 207, train_loss = 1.2527625312795863, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 208, train_loss = 1.2509672144660726, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 209, train_loss = 1.248721607029438, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 210, train_loss = 1.2462451085448265, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 211, train_loss = 1.2444220458855852, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 212, train_loss = 1.2420350027969107, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 213, train_loss = 1.2399660497903824, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 214, train_loss = 1.2376453913748264, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 215, train_loss = 1.2356739677488804, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 216, train_loss = 1.233377568423748, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 217, train_loss = 1.2313681530067697, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 218, train_loss = 1.2298505442449823, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 219, train_loss = 1.2273639924824238, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 220, train_loss = 1.2252408005297184, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 221, train_loss = 1.2236084813484922, train_acc = 0.9975547275267815\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 222, train_loss = 1.2217584066092968, train_acc = 0.9975547275267815\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 223, train_loss = 1.2192752348491922, train_acc = 0.9975547275267815\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 224, train_loss = 1.2173886448144913, train_acc = 0.9975547275267815\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 225, train_loss = 1.2148936750600114, train_acc = 0.9975547275267815\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 226, train_loss = 1.213561882614158, train_acc = 0.9975547275267815\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 227, train_loss = 1.2111239979276434, train_acc = 0.9975547275267815\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 228, train_loss = 1.2090362707385793, train_acc = 0.9975547275267815\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 229, train_loss = 1.206765572191216, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 230, train_loss = 1.2058316270122305, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 231, train_loss = 1.203287816257216, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 232, train_loss = 1.201875520288013, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 233, train_loss = 1.1995472386479378, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 234, train_loss = 1.1980781307211146, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 235, train_loss = 1.196391916484572, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 236, train_loss = 1.1945304373512045, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 237, train_loss = 1.1922613941133022, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 238, train_loss = 1.1914486499736086, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 239, train_loss = 1.188974148244597, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 240, train_loss = 1.1875637111952528, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 241, train_loss = 1.1856151781976223, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 242, train_loss = 1.1838959728484042, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 243, train_loss = 1.1825962886214256, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 244, train_loss = 1.1803221913869493, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 245, train_loss = 1.1789528752560727, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 246, train_loss = 1.1774614590103738, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 247, train_loss = 1.1757846611435525, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 248, train_loss = 1.1745480075478554, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 249, train_loss = 1.172604485123884, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 250, train_loss = 1.1709646421368234, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 251, train_loss = 1.1698537431657314, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 252, train_loss = 1.1679336465895176, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 253, train_loss = 1.1669258090551011, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 254, train_loss = 1.1642470210790634, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 255, train_loss = 1.1633284377749078, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 256, train_loss = 1.1612483610515483, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 257, train_loss = 1.1607064604759216, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 258, train_loss = 1.159064494073391, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 259, train_loss = 1.1574213442509063, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 260, train_loss = 1.1561479990486987, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 261, train_loss = 1.1547275222837925, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 262, train_loss = 1.1524124120478518, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 263, train_loss = 1.1510522949392907, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 264, train_loss = 1.149159646301996, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 265, train_loss = 1.1487643544678576, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 266, train_loss = 1.14721429097699, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 267, train_loss = 1.1464008676703088, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 268, train_loss = 1.1440050601959229, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 269, train_loss = 1.143162813037634, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 270, train_loss = 1.1417468848521821, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 271, train_loss = 1.1403874519164674, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 272, train_loss = 1.1384923619334586, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 273, train_loss = 1.1372369441087358, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 274, train_loss = 1.1352606602013111, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 275, train_loss = 1.1338426631991751, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 276, train_loss = 1.1332676323945634, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 277, train_loss = 1.132291677116882, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 278, train_loss = 1.1302417094702832, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 279, train_loss = 1.1294445780222304, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 280, train_loss = 1.1276873759925365, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 281, train_loss = 1.1262538991868496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 282, train_loss = 1.1251728248898871, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 283, train_loss = 1.1239064559340477, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 284, train_loss = 1.1230984342400916, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 285, train_loss = 1.121305721520912, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 286, train_loss = 1.1198966366355307, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 287, train_loss = 1.1198904539342038, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 288, train_loss = 1.1178214028477669, train_acc = 0.9977876106194691\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 289, train_loss = 1.11645382019924, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 290, train_loss = 1.1155183340306394, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 291, train_loss = 1.1149856957490556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 292, train_loss = 1.1127758671646006, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 293, train_loss = 1.1119885903899558, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 294, train_loss = 1.1101815489237197, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 295, train_loss = 1.1094365653698333, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 296, train_loss = 1.1078423038125038, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 297, train_loss = 1.1073267459869385, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 298, train_loss = 1.1057713094050996, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 299, train_loss = 1.1044079710845836, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 300, train_loss = 1.103281207382679, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 301, train_loss = 1.1022359803318977, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 302, train_loss = 1.1008985390071757, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 303, train_loss = 1.1001894449000247, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 304, train_loss = 1.098943271965254, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 305, train_loss = 1.0978231020271778, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 306, train_loss = 1.0965258653159253, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 307, train_loss = 1.094727152318228, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 308, train_loss = 1.094124509661924, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 309, train_loss = 1.0928699995274656, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 310, train_loss = 1.0922418721020222, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 311, train_loss = 1.0915617272257805, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 312, train_loss = 1.089447530626785, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 313, train_loss = 1.0886134331231005, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 314, train_loss = 1.0871963513200171, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 315, train_loss = 1.0864654568140395, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 316, train_loss = 1.0854353320901282, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 317, train_loss = 1.0840320127899759, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 318, train_loss = 1.082648627460003, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 319, train_loss = 1.0821095208521, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 320, train_loss = 1.0806068045203574, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 321, train_loss = 1.079128373414278, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 322, train_loss = 1.07922901090933, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 323, train_loss = 1.0772696286439896, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 324, train_loss = 1.0761307167704217, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 325, train_loss = 1.075258509546984, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 326, train_loss = 1.0741001280839555, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 327, train_loss = 1.0730936750769615, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 328, train_loss = 1.0723523696069606, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 329, train_loss = 1.0706496611237526, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 330, train_loss = 1.0704419414396398, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 331, train_loss = 1.0688349406118505, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 332, train_loss = 1.0682157799601555, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 333, train_loss = 1.06715103861643, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 334, train_loss = 1.0663568650488742, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 335, train_loss = 1.065119419246912, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 336, train_loss = 1.064265648543369, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 337, train_loss = 1.062971341132652, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 338, train_loss = 1.0622134022414684, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 339, train_loss = 1.061257477849722, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 340, train_loss = 1.0603792791371234, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 341, train_loss = 1.0593642170424573, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 342, train_loss = 1.058580490469467, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 343, train_loss = 1.057740479707718, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 344, train_loss = 1.0569768373970874, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 345, train_loss = 1.0556589141488075, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 346, train_loss = 1.0546726261381991, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 347, train_loss = 1.053895613818895, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 348, train_loss = 1.0531103213434108, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 349, train_loss = 1.0523533895611763, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 350, train_loss = 1.051353468268644, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 351, train_loss = 1.050452799827326, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 352, train_loss = 1.0493862107396126, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 353, train_loss = 1.0485207575256936, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 354, train_loss = 1.0476826640660875, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 355, train_loss = 1.0469482280313969, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 356, train_loss = 1.0461111937765963, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 357, train_loss = 1.0452841495280154, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 358, train_loss = 1.044204082340002, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 359, train_loss = 1.0434858153457753, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 360, train_loss = 1.0427692880039103, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 361, train_loss = 1.0419473983347416, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 362, train_loss = 1.0412879958748817, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 363, train_loss = 1.0401312758331187, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 364, train_loss = 1.0392745733261108, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 365, train_loss = 1.0389717904035933, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 366, train_loss = 1.0378999474341981, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 367, train_loss = 1.037562768906355, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 368, train_loss = 1.0367047103936784, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 369, train_loss = 1.0349774695932865, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 370, train_loss = 1.034949630498886, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 371, train_loss = 1.033887303143274, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 372, train_loss = 1.0329783472116105, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 373, train_loss = 1.0322975665330887, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 374, train_loss = 1.03147867199732, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 375, train_loss = 1.030565561086405, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 376, train_loss = 1.0303762356634252, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 377, train_loss = 1.0290886375005357, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 378, train_loss = 1.0281376664643176, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 379, train_loss = 1.0278689302504063, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 380, train_loss = 1.0266919608111493, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 381, train_loss = 1.0261541319196112, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 382, train_loss = 1.0253790840506554, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 383, train_loss = 1.0248499152367003, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 384, train_loss = 1.0239693447947502, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 385, train_loss = 1.0228260879521258, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 386, train_loss = 1.0224860236048698, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 387, train_loss = 1.0214326965506189, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 388, train_loss = 1.0210571425850503, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 389, train_loss = 1.019993585825432, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 390, train_loss = 1.0197253811056726, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 391, train_loss = 1.0188175017829053, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 392, train_loss = 1.0180674431030639, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 393, train_loss = 1.0174775322084315, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 394, train_loss = 1.0167147467727773, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 395, train_loss = 1.0160950012505054, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 396, train_loss = 1.0153512458200566, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 397, train_loss = 1.0144807535107248, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 398, train_loss = 1.013822476088535, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 399, train_loss = 1.0130827873945236, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 400, train_loss = 1.0128834160859697, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 401, train_loss = 1.012057899206411, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 402, train_loss = 1.0107192546129227, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 403, train_loss = 1.0103922821581364, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 404, train_loss = 1.009764913469553, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 405, train_loss = 1.0092193062300794, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 406, train_loss = 1.0084557955269702, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 407, train_loss = 1.0078483819961548, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 408, train_loss = 1.0070054071838968, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 409, train_loss = 1.006016705185175, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 410, train_loss = 1.0058550636167638, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 411, train_loss = 1.0050037267501466, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 412, train_loss = 1.0044570763711818, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 413, train_loss = 1.0033534827525727, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 414, train_loss = 1.0031365019385703, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 415, train_loss = 1.0023735339636914, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 416, train_loss = 1.0019423800404184, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 417, train_loss = 1.0017446788551752, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 418, train_loss = 1.000392018497223, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 419, train_loss = 0.9999345218238886, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 420, train_loss = 0.9993391931056976, train_acc = 0.9979040521658128\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 421, train_loss = 0.9985295335354749, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 422, train_loss = 0.9979205764830112, train_acc = 0.9979040521658128\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 423, train_loss = 0.9975855425000191, train_acc = 0.9979040521658128\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 424, train_loss = 0.99703074619174, train_acc = 0.9979040521658128\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 425, train_loss = 0.9963977982697543, train_acc = 0.9979040521658128\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 426, train_loss = 0.9955717176198959, train_acc = 0.9979040521658128\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 427, train_loss = 0.995156998425955, train_acc = 0.9979040521658128\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 428, train_loss = 0.994493655860424, train_acc = 0.9979040521658128\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 429, train_loss = 0.9939382461307105, train_acc = 0.9979040521658128\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 430, train_loss = 0.9931652657687664, train_acc = 0.9979040521658128\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 431, train_loss = 0.9925807403924409, train_acc = 0.9979040521658128\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 432, train_loss = 0.9915990730223712, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 433, train_loss = 0.9914319055678789, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 434, train_loss = 0.9907914896903094, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 435, train_loss = 0.9902564932999667, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 436, train_loss = 0.9898780534567777, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 437, train_loss = 0.9889733195304871, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 438, train_loss = 0.988209955394268, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 439, train_loss = 0.9876588098704815, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 440, train_loss = 0.9872487845423166, train_acc = 0.9980204937121565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 441, train_loss = 0.9864240114984568, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 442, train_loss = 0.9859202528896276, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 443, train_loss = 0.9856771677732468, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 444, train_loss = 0.9848437743785325, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 445, train_loss = 0.9842038340866566, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 446, train_loss = 0.9839763529598713, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 447, train_loss = 0.9834485277533531, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 448, train_loss = 0.98246274763369, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 449, train_loss = 0.9821715404686984, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 450, train_loss = 0.9815176787378732, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 451, train_loss = 0.981043570995098, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 452, train_loss = 0.9804635109903757, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 453, train_loss = 0.9802761264145374, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 454, train_loss = 0.9793311096727848, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 455, train_loss = 0.9792861019668635, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 456, train_loss = 0.9783608255384024, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 457, train_loss = 0.9777579245564993, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 458, train_loss = 0.977232771605486, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 459, train_loss = 0.9766793114540633, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 460, train_loss = 0.9758785193262156, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 461, train_loss = 0.9759444097580854, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 462, train_loss = 0.975091353058815, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 463, train_loss = 0.9746625112893526, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 464, train_loss = 0.9739326797425747, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 465, train_loss = 0.973364924400812, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 466, train_loss = 0.9729443477990571, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 467, train_loss = 0.9724635121820029, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 468, train_loss = 0.9720313735306263, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 469, train_loss = 0.971329619496828, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 470, train_loss = 0.9709143502113875, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 471, train_loss = 0.9703165354731027, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 472, train_loss = 0.9699332527816296, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 473, train_loss = 0.9695883430540562, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 474, train_loss = 0.9691269832255784, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 475, train_loss = 0.9681905135512352, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 476, train_loss = 0.9678282613458578, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 477, train_loss = 0.9675286536512431, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 478, train_loss = 0.9672034407558385, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 479, train_loss = 0.9666829630732536, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 480, train_loss = 0.9658150412142277, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 481, train_loss = 0.9652349414827768, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 482, train_loss = 0.9650162421166897, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 483, train_loss = 0.9640866977570113, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 484, train_loss = 0.9639043100178242, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 485, train_loss = 0.9635897750558797, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 486, train_loss = 0.9629684227111284, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 487, train_loss = 0.9625746818783227, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 488, train_loss = 0.9618653704819735, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 489, train_loss = 0.9612802043557167, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 490, train_loss = 0.9609243969025556, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 491, train_loss = 0.9605706507863943, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 492, train_loss = 0.9600713128747884, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 493, train_loss = 0.9594505454006139, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 494, train_loss = 0.9591293272969779, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 495, train_loss = 0.9588462971150875, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 496, train_loss = 0.9580905226466712, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 497, train_loss = 0.9575770609080791, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 498, train_loss = 0.9573417616484221, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 499, train_loss = 0.956927228718996, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████▋                              | 17/30 [2:49:38<2:10:01, 600.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "18th- epoch: 0, train_loss = 138.0338877737522, train_acc = 0.7496506753609687\n",
      "test Acc 0.8733705772811918:\n",
      "18th- epoch: 1, train_loss = 50.93073916435242, train_acc = 0.898346530041919\n",
      "test Acc 0.9138733705772812:\n",
      "18th- epoch: 2, train_loss = 36.79111433029175, train_acc = 0.9275733581741965\n",
      "test Acc 0.9320297951582868:\n",
      "18th- epoch: 3, train_loss = 29.70471628382802, train_acc = 0.9432929669306008\n",
      "test Acc 0.9399441340782123:\n",
      "18th- epoch: 4, train_loss = 25.20223729684949, train_acc = 0.952026082906381\n",
      "test Acc 0.9422718808193669:\n",
      "18th- epoch: 5, train_loss = 21.963475976139307, train_acc = 0.9583139264089428\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 6, train_loss = 19.50515618175268, train_acc = 0.9628551467163484\n",
      "test Acc 0.9511173184357542:\n",
      "18th- epoch: 7, train_loss = 17.55584138445556, train_acc = 0.966581276199348\n",
      "test Acc 0.9534450651769087:\n",
      "18th- epoch: 8, train_loss = 15.953663691878319, train_acc = 0.9693758733115976\n",
      "test Acc 0.9548417132216015:\n",
      "18th- epoch: 9, train_loss = 14.600687358528376, train_acc = 0.9721704704238472\n",
      "test Acc 0.9562383612662942:\n",
      "18th- epoch: 10, train_loss = 13.429858639836311, train_acc = 0.9742664182580345\n",
      "test Acc 0.9557728119180633:\n",
      "18th- epoch: 11, train_loss = 12.414558485150337, train_acc = 0.9765952491849091\n",
      "test Acc 0.957169459962756:\n",
      "18th- epoch: 12, train_loss = 11.515890657901764, train_acc = 0.977992547741034\n",
      "test Acc 0.957169459962756:\n",
      "18th- epoch: 13, train_loss = 10.721535062417388, train_acc = 0.9784583139264089\n",
      "test Acc 0.9585661080074488:\n",
      "18th- epoch: 14, train_loss = 10.014908485114574, train_acc = 0.9795062878435026\n",
      "test Acc 0.9599627560521415:\n",
      "18th- epoch: 15, train_loss = 9.387812100350857, train_acc = 0.98067070330694\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 16, train_loss = 8.82111026905477, train_acc = 0.9821844434094085\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 17, train_loss = 8.312080763280392, train_acc = 0.9831159757801584\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 18, train_loss = 7.850845759734511, train_acc = 0.9839310666045645\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 19, train_loss = 7.435798694379628, train_acc = 0.9855612482533768\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 20, train_loss = 7.063686405308545, train_acc = 0.9866092221704704\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 21, train_loss = 6.721097425557673, train_acc = 0.9875407545412203\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 22, train_loss = 6.414135620929301, train_acc = 0.9892873777363763\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 23, train_loss = 6.13473957311362, train_acc = 0.99033535165347\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 24, train_loss = 5.881329078227282, train_acc = 0.990801117838845\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 25, train_loss = 5.6506405575200915, train_acc = 0.9913833255705635\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 26, train_loss = 5.439756004139781, train_acc = 0.9916162086632511\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 27, train_loss = 5.245947192423046, train_acc = 0.9919655333022822\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 28, train_loss = 5.066780526190996, train_acc = 0.9921984163949698\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 29, train_loss = 4.900103130377829, train_acc = 0.9925477410340009\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 30, train_loss = 4.7442720318213105, train_acc = 0.9927806241266884\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 31, train_loss = 4.599801126867533, train_acc = 0.9930135072193759\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 32, train_loss = 4.463248562067747, train_acc = 0.9932463903120633\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 33, train_loss = 4.336531262844801, train_acc = 0.9935957149510946\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 34, train_loss = 4.21680814307183, train_acc = 0.9935957149510946\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 35, train_loss = 4.104834544472396, train_acc = 0.9935957149510946\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 36, train_loss = 3.998224743641913, train_acc = 0.9937121564974383\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 37, train_loss = 3.8971960972994566, train_acc = 0.993828598043782\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 38, train_loss = 3.8013767590746284, train_acc = 0.9940614811364695\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 39, train_loss = 3.710232425481081, train_acc = 0.9941779226828132\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 40, train_loss = 3.625531774945557, train_acc = 0.994294364229157\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 41, train_loss = 3.5435105562210083, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 42, train_loss = 3.465565912425518, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 43, train_loss = 3.3920729719102383, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 44, train_loss = 3.321518328972161, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 45, train_loss = 3.2528733080253005, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 46, train_loss = 3.188083971850574, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 47, train_loss = 3.1268680430948734, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 48, train_loss = 3.069548121653497, train_acc = 0.9952258965999069\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 49, train_loss = 3.0115255396813154, train_acc = 0.9952258965999069\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 50, train_loss = 2.959450106136501, train_acc = 0.9954587796925943\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 51, train_loss = 2.907759975641966, train_acc = 0.9954587796925943\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 52, train_loss = 2.8593037221580744, train_acc = 0.9954587796925943\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 53, train_loss = 2.8117047837004066, train_acc = 0.9954587796925943\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 54, train_loss = 2.7669854308478534, train_acc = 0.995575221238938\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 55, train_loss = 2.722782047931105, train_acc = 0.9956916627852818\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 56, train_loss = 2.6817060788162053, train_acc = 0.9958081043316255\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 57, train_loss = 2.641669605858624, train_acc = 0.996040987424313\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 58, train_loss = 2.6036649104207754, train_acc = 0.996040987424313\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 59, train_loss = 2.5658527151681483, train_acc = 0.996040987424313\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 60, train_loss = 2.530115055385977, train_acc = 0.996040987424313\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 61, train_loss = 2.496328368317336, train_acc = 0.9961574289706567\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 62, train_loss = 2.4628575169481337, train_acc = 0.9961574289706567\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 63, train_loss = 2.4319432582706213, train_acc = 0.9963903120633442\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 64, train_loss = 2.4008223083801568, train_acc = 0.9961574289706567\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 65, train_loss = 2.3713696119375527, train_acc = 0.9962738705170004\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 66, train_loss = 2.3427123515866697, train_acc = 0.9962738705170004\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 67, train_loss = 2.31524558365345, train_acc = 0.9962738705170004\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 68, train_loss = 2.2883206214755774, train_acc = 0.9963903120633442\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 69, train_loss = 2.2638569972477853, train_acc = 0.9963903120633442\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 70, train_loss = 2.2379633295349777, train_acc = 0.9963903120633442\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 71, train_loss = 2.214889987837523, train_acc = 0.996506753609688\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 72, train_loss = 2.191943436861038, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "18th- epoch: 73, train_loss = 2.1690832623280585, train_acc = 0.996506753609688\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 74, train_loss = 2.1482769562862813, train_acc = 0.9966231951560317\n",
      "test Acc 0.9711359404096834:\n",
      "18th- epoch: 75, train_loss = 2.126583753619343, train_acc = 0.9967396367023754\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 76, train_loss = 2.1075525204651058, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "18th- epoch: 77, train_loss = 2.088277760427445, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "18th- epoch: 78, train_loss = 2.0690838992595673, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "18th- epoch: 79, train_loss = 2.050784083083272, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "18th- epoch: 80, train_loss = 2.0328123793005943, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "18th- epoch: 81, train_loss = 2.0165783129632473, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 82, train_loss = 1.9997447226196527, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "18th- epoch: 83, train_loss = 1.9836048670113087, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 84, train_loss = 1.968226217199117, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 85, train_loss = 1.9536574888043106, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 86, train_loss = 1.9376203981228173, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 87, train_loss = 1.9234503735788167, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 88, train_loss = 1.910452128853649, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 89, train_loss = 1.8962006098590791, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 90, train_loss = 1.8827234762720764, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 91, train_loss = 1.8699975721538067, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 92, train_loss = 1.8573260041885078, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 93, train_loss = 1.8448894550092518, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 94, train_loss = 1.832836062181741, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 95, train_loss = 1.8203456029295921, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 96, train_loss = 1.809148820117116, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 97, train_loss = 1.7981260039377958, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 98, train_loss = 1.7864150181412697, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 99, train_loss = 1.775982452556491, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 100, train_loss = 1.765411225380376, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 101, train_loss = 1.7548226490616798, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 102, train_loss = 1.744752997532487, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 103, train_loss = 1.735266923205927, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 104, train_loss = 1.7253952238243073, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 105, train_loss = 1.7158934772014618, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 106, train_loss = 1.7066026621032506, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 107, train_loss = 1.6973156537860632, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 108, train_loss = 1.6890037909615785, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 109, train_loss = 1.6798191748093814, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 110, train_loss = 1.671372614102438, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 111, train_loss = 1.662776367738843, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 112, train_loss = 1.6545489020645618, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 113, train_loss = 1.6463834133464843, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 114, train_loss = 1.6383495554327965, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 115, train_loss = 1.6307815432082862, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 116, train_loss = 1.6230488698929548, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 117, train_loss = 1.6155936762224883, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 118, train_loss = 1.6086906101554632, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 119, train_loss = 1.6014712371397763, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 120, train_loss = 1.5940085302572697, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 121, train_loss = 1.586926828371361, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 122, train_loss = 1.5802457153331488, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 123, train_loss = 1.5731713250279427, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 124, train_loss = 1.566460070433095, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 125, train_loss = 1.560412197606638, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 126, train_loss = 1.5534585795830935, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 127, train_loss = 1.5472116358578205, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 128, train_loss = 1.5411754741799086, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 129, train_loss = 1.5346216682810336, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 130, train_loss = 1.5286158013623208, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 131, train_loss = 1.5232317342888564, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 132, train_loss = 1.5164359994232655, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 133, train_loss = 1.5110390472691506, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 134, train_loss = 1.5051302034407854, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 135, train_loss = 1.5000115893781185, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 136, train_loss = 1.494263218017295, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 137, train_loss = 1.4888297815341502, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 138, train_loss = 1.4834799349773675, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "18th- epoch: 139, train_loss = 1.4784806563984603, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 140, train_loss = 1.473160247085616, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 141, train_loss = 1.468066018074751, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 142, train_loss = 1.463541028322652, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 143, train_loss = 1.4579978082329035, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 144, train_loss = 1.4532976783812046, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 145, train_loss = 1.4479262202512473, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 146, train_loss = 1.4439545541536063, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 147, train_loss = 1.438608781201765, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 148, train_loss = 1.43427356146276, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 149, train_loss = 1.429594113258645, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 150, train_loss = 1.4250810083467513, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 151, train_loss = 1.4211916320491582, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 152, train_loss = 1.4159652888774872, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 153, train_loss = 1.412040740950033, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 154, train_loss = 1.4081405594479293, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 155, train_loss = 1.4035821438301355, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 156, train_loss = 1.3999890480190516, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 157, train_loss = 1.3952343587297946, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 158, train_loss = 1.3911459881346673, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 159, train_loss = 1.3871798105537891, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 160, train_loss = 1.3831285547930747, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 161, train_loss = 1.3790881030727178, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 162, train_loss = 1.3753779518883675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 163, train_loss = 1.3718621470034122, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 164, train_loss = 1.368637701496482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 165, train_loss = 1.3642741739749908, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 166, train_loss = 1.3599645961076021, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 167, train_loss = 1.3575348767917603, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 168, train_loss = 1.353159776655957, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 169, train_loss = 1.3497860699426383, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 170, train_loss = 1.3466762863099575, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 171, train_loss = 1.3432569534052163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 172, train_loss = 1.3399199165869504, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 173, train_loss = 1.336626031785272, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 174, train_loss = 1.332988596870564, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 175, train_loss = 1.32955533079803, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 176, train_loss = 1.3265460450202227, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 177, train_loss = 1.3229487674543634, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 178, train_loss = 1.3201458802213892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 179, train_loss = 1.3166648807236925, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 180, train_loss = 1.3134103082120419, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 181, train_loss = 1.3107641214737669, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 182, train_loss = 1.3075373818865046, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 183, train_loss = 1.3045193528523669, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 184, train_loss = 1.301191042526625, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 185, train_loss = 1.2983270516851917, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 186, train_loss = 1.2955560056725517, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 187, train_loss = 1.2925937647232786, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 188, train_loss = 1.2897248497465625, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 189, train_loss = 1.2864421997219324, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 190, train_loss = 1.2834920013556257, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 191, train_loss = 1.2812942719319835, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 192, train_loss = 1.2781204655766487, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 193, train_loss = 1.2756260937312618, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 194, train_loss = 1.2721689827740192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 195, train_loss = 1.2703805851051584, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 196, train_loss = 1.2669730173656717, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 197, train_loss = 1.264476865530014, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 198, train_loss = 1.2624395781895146, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 199, train_loss = 1.2591472963104025, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 200, train_loss = 1.2566553428769112, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 201, train_loss = 1.2544180719414726, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 202, train_loss = 1.251313941553235, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 203, train_loss = 1.2496241386979818, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 204, train_loss = 1.246962490142323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 205, train_loss = 1.2446746540954337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 206, train_loss = 1.2422128381440416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 207, train_loss = 1.2398328892886639, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 208, train_loss = 1.2371650841087103, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 209, train_loss = 1.2351070946315303, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 210, train_loss = 1.2327799847116694, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 211, train_loss = 1.2307022059103474, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 212, train_loss = 1.2283073998987675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 213, train_loss = 1.2258898578584194, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 214, train_loss = 1.2242390923202038, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 215, train_loss = 1.2220179053256288, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 216, train_loss = 1.2194184245308861, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 217, train_loss = 1.2174221593886614, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 218, train_loss = 1.2154073709389195, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 219, train_loss = 1.2132603488862514, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 220, train_loss = 1.2109113074839115, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 221, train_loss = 1.209241297096014, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 222, train_loss = 1.2064951764186844, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 223, train_loss = 1.2048738276353106, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 224, train_loss = 1.2023528659483418, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 225, train_loss = 1.2009009880712256, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 226, train_loss = 1.198408618569374, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 227, train_loss = 1.1965275220572948, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 228, train_loss = 1.194033789797686, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 229, train_loss = 1.1923023741692305, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 230, train_loss = 1.190015203668736, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 231, train_loss = 1.1881203800439835, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 232, train_loss = 1.1860528215765953, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 233, train_loss = 1.1840814104070887, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 234, train_loss = 1.1820257740328088, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 235, train_loss = 1.180604218156077, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 236, train_loss = 1.1783697722712532, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 237, train_loss = 1.1769394936272874, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 238, train_loss = 1.174668320803903, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 239, train_loss = 1.1735682841390371, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 240, train_loss = 1.1713251080363989, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 241, train_loss = 1.1696092430502176, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 242, train_loss = 1.1680418631294742, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 243, train_loss = 1.166434010490775, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 244, train_loss = 1.164474337012507, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 245, train_loss = 1.1626740569481626, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 246, train_loss = 1.1611819801619276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 247, train_loss = 1.1596231000730768, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 248, train_loss = 1.1577234031865373, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 249, train_loss = 1.1560884428909048, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 250, train_loss = 1.154510552645661, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 251, train_loss = 1.1531103929737583, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 252, train_loss = 1.151700676069595, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 253, train_loss = 1.1500762570649385, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 254, train_loss = 1.148474507033825, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 255, train_loss = 1.1467896538088098, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 256, train_loss = 1.1451473186025396, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 257, train_loss = 1.1436448892345652, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 258, train_loss = 1.1424012588104233, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 259, train_loss = 1.1406662464141846, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 260, train_loss = 1.139131909236312, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 261, train_loss = 1.1376998890191317, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 262, train_loss = 1.136281611979939, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 263, train_loss = 1.1347998306155205, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 264, train_loss = 1.1333866814384237, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 265, train_loss = 1.1319194380193949, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 266, train_loss = 1.130638549104333, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 267, train_loss = 1.1291514752665535, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 268, train_loss = 1.1274346591671929, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 269, train_loss = 1.126305308775045, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 270, train_loss = 1.1247689934680238, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 271, train_loss = 1.1234206644585356, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 272, train_loss = 1.1223842253675684, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 273, train_loss = 1.12048109062016, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 274, train_loss = 1.1191769751021639, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 275, train_loss = 1.1184497606009245, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 276, train_loss = 1.116461398662068, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 277, train_loss = 1.1156874969601631, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 278, train_loss = 1.1142926824977621, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 279, train_loss = 1.1127556258579716, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 280, train_loss = 1.1117501445114613, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 281, train_loss = 1.110087489709258, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 282, train_loss = 1.109052219777368, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 283, train_loss = 1.1077408753335476, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 284, train_loss = 1.106439913972281, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 285, train_loss = 1.1051585512468591, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 286, train_loss = 1.1040590951452032, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 287, train_loss = 1.1027315761893988, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 288, train_loss = 1.1016109281918034, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 289, train_loss = 1.1003760719904676, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 290, train_loss = 1.099074354977347, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 291, train_loss = 1.0975992729654536, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 292, train_loss = 1.0968984247883782, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 293, train_loss = 1.0954696666449308, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 294, train_loss = 1.0944824293255806, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 295, train_loss = 1.0930639834841713, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 296, train_loss = 1.0919290067395195, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 297, train_loss = 1.0910976914456114, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 298, train_loss = 1.0896669210633263, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 299, train_loss = 1.0887082094559446, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 300, train_loss = 1.0871905690291896, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 301, train_loss = 1.0863637682050467, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 302, train_loss = 1.0850585866719484, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 303, train_loss = 1.084385215654038, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 304, train_loss = 1.0830413978546858, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 305, train_loss = 1.0818309877067804, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 306, train_loss = 1.0804059089859948, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 307, train_loss = 1.0799334744224325, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 308, train_loss = 1.0785318178823218, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 309, train_loss = 1.0772884569014423, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 310, train_loss = 1.076407540589571, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 311, train_loss = 1.075326579331886, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 312, train_loss = 1.074163991957903, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 313, train_loss = 1.0732361705158837, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 314, train_loss = 1.0722376126796007, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 315, train_loss = 1.0713128938223235, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 316, train_loss = 1.069836601614952, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 317, train_loss = 1.0692426984314807, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 318, train_loss = 1.0677645833347924, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 319, train_loss = 1.0668337748502381, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 320, train_loss = 1.0663253839011304, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 321, train_loss = 1.0650612128083594, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 322, train_loss = 1.0640783961862326, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 323, train_loss = 1.0632204214925878, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 324, train_loss = 1.0619682644610293, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 325, train_loss = 1.061183578625787, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 326, train_loss = 1.060263480991125, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 327, train_loss = 1.0590350615675561, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 328, train_loss = 1.0583138621295802, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 329, train_loss = 1.0571186995948665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 330, train_loss = 1.0564981326460838, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 331, train_loss = 1.05504697188735, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 332, train_loss = 1.0541013851761818, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 333, train_loss = 1.0533576514571905, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 334, train_loss = 1.0522016758914106, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 335, train_loss = 1.0515033236588351, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 336, train_loss = 1.0507574081420898, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 337, train_loss = 1.0495097997481935, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 338, train_loss = 1.0487627616967075, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 339, train_loss = 1.0477700140327215, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 340, train_loss = 1.0470755634014495, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 341, train_loss = 1.0460182186216116, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 342, train_loss = 1.0448068522964604, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 343, train_loss = 1.0442412476986647, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 344, train_loss = 1.0431401133537292, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 345, train_loss = 1.042691446840763, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 346, train_loss = 1.0414220628445037, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 347, train_loss = 1.0405413557891734, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 348, train_loss = 1.0400421408121474, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 349, train_loss = 1.0389564863289706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 350, train_loss = 1.0381416131858714, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 351, train_loss = 1.0374876881833188, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 352, train_loss = 1.0365092257852666, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 353, train_loss = 1.0354380042408593, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 354, train_loss = 1.0350957705522887, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 355, train_loss = 1.0339297391474247, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 356, train_loss = 1.0331306916777976, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 357, train_loss = 1.0319778702105395, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 358, train_loss = 1.0315063309972174, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 359, train_loss = 1.0306087738717906, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 360, train_loss = 1.0295256301760674, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 361, train_loss = 1.028527569025755, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 362, train_loss = 1.0275303591042757, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 363, train_loss = 1.0264868519152515, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 364, train_loss = 1.0257523686741479, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 365, train_loss = 1.0251660241628997, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 366, train_loss = 1.0247440368984826, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 367, train_loss = 1.0237399023026228, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 368, train_loss = 1.0224685668945312, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 369, train_loss = 1.0219917707145214, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 370, train_loss = 1.0217059683054686, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 371, train_loss = 1.0206491847638972, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 372, train_loss = 1.0197741060401313, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 373, train_loss = 1.0189588200300932, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 374, train_loss = 1.018258346884977, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 375, train_loss = 1.017506332427729, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 376, train_loss = 1.0170967268641107, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 377, train_loss = 1.015862521424424, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 378, train_loss = 1.0152614917606115, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 379, train_loss = 1.014816941053141, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 380, train_loss = 1.0140597696299665, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 381, train_loss = 1.0129217350040562, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 382, train_loss = 1.0124132211203687, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 383, train_loss = 1.0115878234500997, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 384, train_loss = 1.0108828761731274, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 385, train_loss = 1.010730470821727, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 386, train_loss = 1.0095842666924, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 387, train_loss = 1.0089188112760894, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 388, train_loss = 1.0081536484067328, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 389, train_loss = 1.0074629063601606, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 390, train_loss = 1.0068770323996432, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 391, train_loss = 1.006059940904379, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 392, train_loss = 1.0055947576765902, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 393, train_loss = 1.0045577635173686, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 394, train_loss = 1.0040617759223096, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 395, train_loss = 1.0036694326554425, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 396, train_loss = 1.0028092290158384, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 397, train_loss = 1.0016955534811132, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 398, train_loss = 1.0014071886544116, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 399, train_loss = 1.0006070614908822, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 400, train_loss = 1.000061894475948, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 401, train_loss = 0.9995372357661836, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 402, train_loss = 0.998621576174628, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 403, train_loss = 0.9978113379329443, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 404, train_loss = 0.9974753434653394, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 405, train_loss = 0.9967795411939733, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 406, train_loss = 0.996149183542002, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 407, train_loss = 0.9953426818246953, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 408, train_loss = 0.9948947373777628, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 409, train_loss = 0.9942274522036314, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 410, train_loss = 0.9934542098199017, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 411, train_loss = 0.9929137888248079, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 412, train_loss = 0.9923707538400777, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 413, train_loss = 0.9918043594807386, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 414, train_loss = 0.9908562389318831, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 415, train_loss = 0.9904994971002452, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 416, train_loss = 0.989558991685044, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 417, train_loss = 0.9893641590024345, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 418, train_loss = 0.9885492933099158, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 419, train_loss = 0.9879187978804111, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 420, train_loss = 0.9874155856668949, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 421, train_loss = 0.9867342791403644, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 422, train_loss = 0.986027420789469, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 423, train_loss = 0.9855242595076561, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 424, train_loss = 0.9850499965250492, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 425, train_loss = 0.9843883936409838, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 426, train_loss = 0.9839347091619857, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 427, train_loss = 0.9832152159069665, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 428, train_loss = 0.9827066343277693, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 429, train_loss = 0.9821701999753714, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 430, train_loss = 0.9815178352291696, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 431, train_loss = 0.9803872182965279, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 432, train_loss = 0.9801032611285336, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 433, train_loss = 0.9800233176792972, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 434, train_loss = 0.9792347687180154, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 435, train_loss = 0.9781908933073282, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 436, train_loss = 0.9781224746257067, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 437, train_loss = 0.9773077474092133, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 438, train_loss = 0.977090300351847, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 439, train_loss = 0.9763211160898209, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 440, train_loss = 0.9756315325503238, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 441, train_loss = 0.9748515256796964, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 442, train_loss = 0.9748686458915472, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 443, train_loss = 0.9741341726039536, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 444, train_loss = 0.9734705084119923, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 445, train_loss = 0.9728185199201107, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 446, train_loss = 0.9724850964848883, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 447, train_loss = 0.9720311351120472, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 448, train_loss = 0.9717135752434842, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 449, train_loss = 0.9706979356706142, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 450, train_loss = 0.9704729194636457, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 451, train_loss = 0.9699673876166344, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 452, train_loss = 0.9692859246279113, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 453, train_loss = 0.9688417495344765, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 454, train_loss = 0.9684436228126287, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 455, train_loss = 0.9672655121539719, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 456, train_loss = 0.967274222522974, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 457, train_loss = 0.9668102127616294, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 458, train_loss = 0.9661039232159965, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 459, train_loss = 0.9652940519154072, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 460, train_loss = 0.9650920747662894, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 461, train_loss = 0.9647359643131495, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 462, train_loss = 0.9638955158297904, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 463, train_loss = 0.9634730883990414, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 464, train_loss = 0.9630429279059172, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 465, train_loss = 0.9625563099980354, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 466, train_loss = 0.962013412907254, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 467, train_loss = 0.9615520543302409, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 468, train_loss = 0.9614482249016874, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 469, train_loss = 0.9604494099621661, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 470, train_loss = 0.9600561242550611, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 471, train_loss = 0.959310642152559, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 472, train_loss = 0.9595106914639473, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 473, train_loss = 0.9585140024428256, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 474, train_loss = 0.9584676275844686, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 475, train_loss = 0.9575014282017946, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 476, train_loss = 0.9571169254486449, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 477, train_loss = 0.9565652894671075, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 478, train_loss = 0.9562696280772798, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 479, train_loss = 0.9556309326435439, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 480, train_loss = 0.955491057888139, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 481, train_loss = 0.954455163970124, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 482, train_loss = 0.9542526112054475, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 483, train_loss = 0.9536423080717213, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 484, train_loss = 0.9534006429021247, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 485, train_loss = 0.9525186382234097, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 486, train_loss = 0.9521891965414397, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 487, train_loss = 0.9518030118197203, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 488, train_loss = 0.9512244779616594, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 489, train_loss = 0.9507452690158971, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 490, train_loss = 0.9503365785931237, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 491, train_loss = 0.9501272682100534, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 492, train_loss = 0.9496637688134797, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 493, train_loss = 0.9492624836857431, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 494, train_loss = 0.9483016834710725, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 495, train_loss = 0.9478304063086398, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 496, train_loss = 0.9476416328107007, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 497, train_loss = 0.9472475697402842, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 498, train_loss = 0.946772450581193, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 499, train_loss = 0.946374524384737, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████                            | 18/30 [2:59:37<1:59:59, 599.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "19th- epoch: 0, train_loss = 154.41929411888123, train_acc = 0.7421984163949698\n",
      "test Acc 0.8594040968342644:\n",
      "19th- epoch: 1, train_loss = 54.103476859629154, train_acc = 0.887750349324639\n",
      "test Acc 0.9064245810055865:\n",
      "19th- epoch: 2, train_loss = 38.298537861555815, train_acc = 0.9217512808570097\n",
      "test Acc 0.9194599627560521:\n",
      "19th- epoch: 3, train_loss = 30.390397552400827, train_acc = 0.9388681881695389\n",
      "test Acc 0.9245810055865922:\n",
      "19th- epoch: 4, train_loss = 25.392121233046055, train_acc = 0.9487657196087564\n",
      "test Acc 0.9320297951582868:\n",
      "19th- epoch: 5, train_loss = 21.855698246508837, train_acc = 0.9550535631113182\n",
      "test Acc 0.9348230912476723:\n",
      "19th- epoch: 6, train_loss = 19.16372859477997, train_acc = 0.9611085235211924\n",
      "test Acc 0.9422718808193669:\n",
      "19th- epoch: 7, train_loss = 17.053009763360023, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 8, train_loss = 15.378524797037244, train_acc = 0.9704238472286912\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 9, train_loss = 13.99686393328011, train_acc = 0.974033535165347\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 10, train_loss = 12.833430322818458, train_acc = 0.9771774569166278\n",
      "test Acc 0.9567039106145251:\n",
      "19th- epoch: 11, train_loss = 11.8384168734774, train_acc = 0.9783418723800652\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 12, train_loss = 10.97225099708885, train_acc = 0.980204937121565\n",
      "test Acc 0.9585661080074488:\n",
      "19th- epoch: 13, train_loss = 10.21323027368635, train_acc = 0.9813693525850024\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 14, train_loss = 9.54174280911684, train_acc = 0.9825337680484397\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 15, train_loss = 8.94278436806053, train_acc = 0.983698183511877\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 16, train_loss = 8.405562679283321, train_acc = 0.9845132743362832\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 17, train_loss = 7.926166914403439, train_acc = 0.9857941313460643\n",
      "test Acc 0.9632216014897579:\n",
      "19th- epoch: 18, train_loss = 7.497201217338443, train_acc = 0.9861434559850955\n",
      "test Acc 0.9636871508379888:\n",
      "19th- epoch: 19, train_loss = 7.107781169004738, train_acc = 0.9875407545412203\n",
      "test Acc 0.9646182495344506:\n",
      "19th- epoch: 20, train_loss = 6.757383027113974, train_acc = 0.9888216115510013\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 21, train_loss = 6.435424298048019, train_acc = 0.9889380530973452\n",
      "test Acc 0.9669459962756052:\n",
      "19th- epoch: 22, train_loss = 6.145992633886635, train_acc = 0.989869585468095\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 23, train_loss = 5.878320746123791, train_acc = 0.9904517931998137\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 24, train_loss = 5.633404676802456, train_acc = 0.990801117838845\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 25, train_loss = 5.407502411864698, train_acc = 0.9912668840242198\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 26, train_loss = 5.200329372659326, train_acc = 0.9919655333022822\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 27, train_loss = 5.0065206699073315, train_acc = 0.9923148579413135\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 28, train_loss = 4.827663713134825, train_acc = 0.9925477410340009\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 29, train_loss = 4.662515474949032, train_acc = 0.9930135072193759\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 30, train_loss = 4.5084657752886415, train_acc = 0.9933628318584071\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 31, train_loss = 4.3663496589288116, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 32, train_loss = 4.233060733415186, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 33, train_loss = 4.108182725030929, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 34, train_loss = 3.9925606311298907, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 35, train_loss = 3.8854354238137603, train_acc = 0.9946436888681882\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 36, train_loss = 3.7831659950315952, train_acc = 0.9953423381462506\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 37, train_loss = 3.689775079023093, train_acc = 0.9953423381462506\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 38, train_loss = 3.6003298754803836, train_acc = 0.9954587796925943\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 39, train_loss = 3.515780445653945, train_acc = 0.995575221238938\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 40, train_loss = 3.4368478911928833, train_acc = 0.995575221238938\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 41, train_loss = 3.362219732720405, train_acc = 0.9958081043316255\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 42, train_loss = 3.2909624353051186, train_acc = 0.9959245458779693\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 43, train_loss = 3.222814680542797, train_acc = 0.996040987424313\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 44, train_loss = 3.158393518999219, train_acc = 0.9959245458779693\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 45, train_loss = 3.0976776271127164, train_acc = 0.996040987424313\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 46, train_loss = 3.040095408912748, train_acc = 0.996040987424313\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 47, train_loss = 2.9854373424313962, train_acc = 0.9962738705170004\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 48, train_loss = 2.931384607683867, train_acc = 0.9962738705170004\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 49, train_loss = 2.8813779349438846, train_acc = 0.9962738705170004\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 50, train_loss = 2.8329269154928625, train_acc = 0.9963903120633442\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 51, train_loss = 2.78677088720724, train_acc = 0.9963903120633442\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 52, train_loss = 2.7421179013326764, train_acc = 0.9963903120633442\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 53, train_loss = 2.700072242412716, train_acc = 0.9963903120633442\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 54, train_loss = 2.659016898367554, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 55, train_loss = 2.6195050324313343, train_acc = 0.9966231951560317\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 56, train_loss = 2.5816034539602697, train_acc = 0.9967396367023754\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 57, train_loss = 2.5457099196501076, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 58, train_loss = 2.510425482876599, train_acc = 0.9967396367023754\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 59, train_loss = 2.477259930688888, train_acc = 0.9967396367023754\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 60, train_loss = 2.445639570709318, train_acc = 0.9967396367023754\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 61, train_loss = 2.413811100181192, train_acc = 0.9968560782487191\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 62, train_loss = 2.383873292244971, train_acc = 0.9968560782487191\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 63, train_loss = 2.3552108998410404, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 64, train_loss = 2.327333237975836, train_acc = 0.9970889613414066\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 65, train_loss = 2.3003673208877444, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 66, train_loss = 2.2738913788925856, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 67, train_loss = 2.2489925732370466, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 68, train_loss = 2.225992684951052, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 69, train_loss = 2.2020994515623897, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 70, train_loss = 2.1789167562965304, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 71, train_loss = 2.15732873394154, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 72, train_loss = 2.134830307448283, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 73, train_loss = 2.1152763348072767, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 74, train_loss = 2.0952717803884298, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 75, train_loss = 2.075190188596025, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 76, train_loss = 2.056804765248671, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 77, train_loss = 2.0387720081489533, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 78, train_loss = 2.0204675348941237, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 79, train_loss = 2.0042227918747813, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 80, train_loss = 1.9869905181694776, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 81, train_loss = 1.970514751970768, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 82, train_loss = 1.9546536460984498, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 83, train_loss = 1.938364640576765, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 84, train_loss = 1.9238205854780972, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 85, train_loss = 1.909063072875142, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 86, train_loss = 1.895101205445826, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 87, train_loss = 1.8811770319007337, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 88, train_loss = 1.8674742521252483, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 89, train_loss = 1.853860653238371, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 90, train_loss = 1.841576929204166, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 91, train_loss = 1.8283092740457505, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 92, train_loss = 1.816712699830532, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 93, train_loss = 1.8046184740960598, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 94, train_loss = 1.7926905776839703, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 95, train_loss = 1.781949244439602, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 96, train_loss = 1.7711121791508049, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 97, train_loss = 1.760013796389103, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 98, train_loss = 1.7490440325345844, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 99, train_loss = 1.7389402261469513, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 100, train_loss = 1.728972311830148, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 101, train_loss = 1.7191209373995662, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 102, train_loss = 1.7095120896119624, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 103, train_loss = 1.7002004934474826, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 104, train_loss = 1.690956309903413, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 105, train_loss = 1.682208406040445, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 106, train_loss = 1.6730602011084557, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 107, train_loss = 1.664026222890243, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 108, train_loss = 1.6555630574002862, train_acc = 0.9979040521658128\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 109, train_loss = 1.647188181988895, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 110, train_loss = 1.6393904371652752, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 111, train_loss = 1.6308978453744203, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 112, train_loss = 1.623430221574381, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 113, train_loss = 1.6153607764281332, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 114, train_loss = 1.6083092659246176, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 115, train_loss = 1.6005025325575843, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 116, train_loss = 1.5925089641241357, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 117, train_loss = 1.5861898449948058, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 118, train_loss = 1.578997228294611, train_acc = 0.9979040521658128\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 119, train_loss = 1.571373375481926, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 120, train_loss = 1.5654473764589056, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 121, train_loss = 1.5580633546924219, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 122, train_loss = 1.5518532848218456, train_acc = 0.9979040521658128\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 123, train_loss = 1.5452229456277564, train_acc = 0.9979040521658128\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 124, train_loss = 1.5390888405963778, train_acc = 0.9979040521658128\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 125, train_loss = 1.5330911400960758, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 126, train_loss = 1.5268876814516261, train_acc = 0.9979040521658128\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 127, train_loss = 1.5207550643244758, train_acc = 0.9979040521658128\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 128, train_loss = 1.5146664382191375, train_acc = 0.9979040521658128\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 129, train_loss = 1.508835188113153, train_acc = 0.9979040521658128\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 130, train_loss = 1.50306935608387, train_acc = 0.9979040521658128\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 131, train_loss = 1.497367896954529, train_acc = 0.9979040521658128\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 132, train_loss = 1.49191584053915, train_acc = 0.9979040521658128\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 133, train_loss = 1.4862946494249627, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 134, train_loss = 1.481524801813066, train_acc = 0.9979040521658128\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 135, train_loss = 1.4754452457418665, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 136, train_loss = 1.4704732111422345, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 137, train_loss = 1.464796363725327, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 138, train_loss = 1.4600980406394228, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 139, train_loss = 1.4544290080666542, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 140, train_loss = 1.4498433420667425, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 141, train_loss = 1.444457209086977, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 142, train_loss = 1.439778876840137, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 143, train_loss = 1.434984145569615, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 144, train_loss = 1.429710506927222, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 145, train_loss = 1.4249654370360076, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 146, train_loss = 1.41999226633925, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 147, train_loss = 1.4150900482200086, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 148, train_loss = 1.4105034969979897, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 149, train_loss = 1.4057483794167638, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 150, train_loss = 1.401657447568141, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 151, train_loss = 1.39759448741097, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 152, train_loss = 1.3930360312806442, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 153, train_loss = 1.3886806648224592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 154, train_loss = 1.384723586961627, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 155, train_loss = 1.3810756281018257, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 156, train_loss = 1.3763604616979137, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 157, train_loss = 1.3727570412447676, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 158, train_loss = 1.368539472692646, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 159, train_loss = 1.3646349204936996, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 160, train_loss = 1.360451441258192, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 161, train_loss = 1.3570211781188846, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 162, train_loss = 1.352811435237527, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 163, train_loss = 1.3483883965527639, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 164, train_loss = 1.345238153473474, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 165, train_loss = 1.3411429055267945, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 166, train_loss = 1.3378701884066686, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 167, train_loss = 1.333541369647719, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 168, train_loss = 1.330357188009657, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 169, train_loss = 1.3267734097316861, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 170, train_loss = 1.3235559854656458, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 171, train_loss = 1.3198554357513785, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 172, train_loss = 1.3166067646816373, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 173, train_loss = 1.313434959971346, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 174, train_loss = 1.3103842003038153, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 175, train_loss = 1.307082618935965, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 176, train_loss = 1.3037925064563751, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 177, train_loss = 1.3012255945941433, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 178, train_loss = 1.2978196305921301, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 179, train_loss = 1.294681947096251, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 180, train_loss = 1.2914149655262008, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 181, train_loss = 1.289285009377636, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 182, train_loss = 1.2861048734048381, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 183, train_loss = 1.2835604328429326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 184, train_loss = 1.2800984904170036, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 185, train_loss = 1.2773936027660966, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 186, train_loss = 1.2746157130459324, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 187, train_loss = 1.2719183271983638, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 188, train_loss = 1.2693931882968172, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 189, train_loss = 1.2664386117830873, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 190, train_loss = 1.2640585856279358, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 191, train_loss = 1.2611298529664055, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 192, train_loss = 1.258310736157, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 193, train_loss = 1.2560536600649357, train_acc = 0.9979040521658128\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 194, train_loss = 1.253371737897396, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 195, train_loss = 1.2507010772824287, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 196, train_loss = 1.2485750180785544, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 197, train_loss = 1.2454146609525196, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 198, train_loss = 1.242984750017058, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 199, train_loss = 1.240983758121729, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 200, train_loss = 1.2387495550210588, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 201, train_loss = 1.2358544835005887, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 202, train_loss = 1.2337038926780224, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 203, train_loss = 1.2310032813693397, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 204, train_loss = 1.2290884095127694, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 205, train_loss = 1.2262355387210846, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 206, train_loss = 1.2244940185919404, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 207, train_loss = 1.2220416801865213, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 208, train_loss = 1.2194971479475498, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 209, train_loss = 1.217810747853946, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 210, train_loss = 1.2149413737352006, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 211, train_loss = 1.2130007513915189, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 212, train_loss = 1.2111662889947183, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 213, train_loss = 1.2085519134998322, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 214, train_loss = 1.2064191249082796, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 215, train_loss = 1.2041381420567632, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 216, train_loss = 1.2018379152868874, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 217, train_loss = 1.1997299849172123, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 218, train_loss = 1.1976623578811996, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 219, train_loss = 1.1958420320297591, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 220, train_loss = 1.1937457931344397, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 221, train_loss = 1.1916126025025733, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 222, train_loss = 1.1895749711547978, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 223, train_loss = 1.187349052168429, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 224, train_loss = 1.1855892722378485, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 225, train_loss = 1.1833254636148922, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 226, train_loss = 1.1820764712174423, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 227, train_loss = 1.1796324017341249, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 228, train_loss = 1.177921021997463, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 229, train_loss = 1.1760406314278953, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 230, train_loss = 1.1744646094739437, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 231, train_loss = 1.1726628153701313, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 232, train_loss = 1.1704333471134305, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 233, train_loss = 1.168783491186332, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 234, train_loss = 1.1670041137258522, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 235, train_loss = 1.1650640743901022, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 236, train_loss = 1.1634302235324867, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 237, train_loss = 1.16162920743227, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 238, train_loss = 1.1595720990444534, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 239, train_loss = 1.1581288489396684, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 240, train_loss = 1.156521373137366, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 241, train_loss = 1.1549316852469929, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 242, train_loss = 1.152704534761142, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 243, train_loss = 1.1513916244730353, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 244, train_loss = 1.1495402961154468, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 245, train_loss = 1.1481960409437306, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 246, train_loss = 1.1470331630553119, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 247, train_loss = 1.145379837602377, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 248, train_loss = 1.1431605232064612, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 249, train_loss = 1.1417395385797136, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 250, train_loss = 1.1399792612646706, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 251, train_loss = 1.1385362520813942, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 252, train_loss = 1.1370593346655369, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 253, train_loss = 1.1352531767333858, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 254, train_loss = 1.1337259511346929, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 255, train_loss = 1.1323734509642236, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 256, train_loss = 1.1308277963544242, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 257, train_loss = 1.1293155669118278, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 258, train_loss = 1.127969314053189, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 259, train_loss = 1.1264204885810614, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 260, train_loss = 1.124944010109175, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 261, train_loss = 1.1235985551029444, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 262, train_loss = 1.1226468912209384, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 263, train_loss = 1.1202949012513272, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 264, train_loss = 1.1197808751021512, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 265, train_loss = 1.117938945069909, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 266, train_loss = 1.1165299571002834, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 267, train_loss = 1.1150451650028117, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 268, train_loss = 1.1132289171218872, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 269, train_loss = 1.1121908370405436, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 270, train_loss = 1.1107594364439137, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 271, train_loss = 1.1096925673191436, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 272, train_loss = 1.1081276554614305, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 273, train_loss = 1.10665882070316, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 274, train_loss = 1.1059286768431775, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 275, train_loss = 1.104366121813655, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 276, train_loss = 1.1027447786182165, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 277, train_loss = 1.101579098671209, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 278, train_loss = 1.100189492746722, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 279, train_loss = 1.0990170582081191, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 280, train_loss = 1.0980801191180944, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 281, train_loss = 1.096316309645772, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 282, train_loss = 1.0953753379289992, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 283, train_loss = 1.0943453330546618, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 284, train_loss = 1.0926160837407224, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 285, train_loss = 1.0911777994479053, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 286, train_loss = 1.0907192081212997, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 287, train_loss = 1.0892828622017987, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 288, train_loss = 1.0881039779633284, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 289, train_loss = 1.0866180161829107, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 290, train_loss = 1.0856415461748838, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 291, train_loss = 1.0843553710728884, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 292, train_loss = 1.0831838728045113, train_acc = 0.9980204937121565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 293, train_loss = 1.0820538314874284, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 294, train_loss = 1.0808279781485908, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 295, train_loss = 1.0800423715263605, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 296, train_loss = 1.078603449568618, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 297, train_loss = 1.0774760681088082, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 298, train_loss = 1.0770071651786566, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 299, train_loss = 1.0753041474963538, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 300, train_loss = 1.0742385045741685, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 301, train_loss = 1.0730606454308145, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 302, train_loss = 1.072096472606063, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 303, train_loss = 1.0707603972405195, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 304, train_loss = 1.0696028135716915, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 305, train_loss = 1.0686536220018752, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 306, train_loss = 1.067610461905133, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 307, train_loss = 1.0670075683738105, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 308, train_loss = 1.0652081233565696, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 309, train_loss = 1.0644523774390109, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 310, train_loss = 1.0632710525242146, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 311, train_loss = 1.0620985366404057, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 312, train_loss = 1.061569376528496, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 313, train_loss = 1.0600499926658813, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 314, train_loss = 1.0588870644569397, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 315, train_loss = 1.0577804613858461, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 316, train_loss = 1.0568201821297407, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 317, train_loss = 1.0561107099056244, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 318, train_loss = 1.05460212068283, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 319, train_loss = 1.0541446500865277, train_acc = 0.9980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 320, train_loss = 1.0530875877884682, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 321, train_loss = 1.051738285139436, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 322, train_loss = 1.050905928015709, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 323, train_loss = 1.0497830423119012, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 324, train_loss = 1.0491053853183985, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 325, train_loss = 1.047887355700368, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 326, train_loss = 1.0468793213367462, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 327, train_loss = 1.0460430936363991, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 328, train_loss = 1.045204721391201, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 329, train_loss = 1.0439338268188294, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 330, train_loss = 1.0432107964006718, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 331, train_loss = 1.0424198011460248, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 332, train_loss = 1.0411605965346098, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 333, train_loss = 1.0404039664717857, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 334, train_loss = 1.0393413795682136, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 335, train_loss = 1.0384436007589102, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 336, train_loss = 1.037606588244671, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 337, train_loss = 1.0368403401225805, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 338, train_loss = 1.035776741191512, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 339, train_loss = 1.035040225222474, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 340, train_loss = 1.033810624241596, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 341, train_loss = 1.0329589800385293, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 342, train_loss = 1.0319617881032173, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 343, train_loss = 1.0315328110009432, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 344, train_loss = 1.030498814448947, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 345, train_loss = 1.0296859182417393, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 346, train_loss = 1.0287149536015932, train_acc = 0.9980204937121565\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 347, train_loss = 1.0277579867688473, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 348, train_loss = 1.0270810443907976, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 349, train_loss = 1.0258757701667491, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 350, train_loss = 1.025336761638755, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 351, train_loss = 1.0244870012102183, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 352, train_loss = 1.0233315812947694, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 353, train_loss = 1.0227605955151375, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 354, train_loss = 1.0216954188945238, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 355, train_loss = 1.0211248826235533, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 356, train_loss = 1.020446952432394, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 357, train_loss = 1.0196805987507105, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 358, train_loss = 1.0187780434789602, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 359, train_loss = 1.0179439391940832, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 360, train_loss = 1.0167733654379845, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 361, train_loss = 1.0161219357105438, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 362, train_loss = 1.0152411044982728, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 363, train_loss = 1.014639856904978, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 364, train_loss = 1.0136060435324907, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 365, train_loss = 1.0129808305355255, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 366, train_loss = 1.0123391275701579, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 367, train_loss = 1.0113719180226326, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 368, train_loss = 1.0104818480613176, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 369, train_loss = 1.0093407686799765, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 370, train_loss = 1.0090407902898733, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 371, train_loss = 1.0084721868333872, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 372, train_loss = 1.0075250416994095, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 373, train_loss = 1.0065174462797586, train_acc = 0.9980204937121565\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 374, train_loss = 1.00615924099111, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 375, train_loss = 1.00521600493812, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 376, train_loss = 1.0045357470808085, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 377, train_loss = 1.0034780787827913, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 378, train_loss = 1.0028892742993776, train_acc = 0.9980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 379, train_loss = 1.0020481621322688, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 380, train_loss = 1.0016749153437559, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 381, train_loss = 1.0011106052843388, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 382, train_loss = 1.0000788774341345, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 383, train_loss = 0.9997223410755396, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 384, train_loss = 0.9985474031418562, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 385, train_loss = 0.9978445048036519, train_acc = 0.9981369352585002\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 386, train_loss = 0.9972395474615041, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 387, train_loss = 0.9963228572160006, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 388, train_loss = 0.9957188932748977, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 389, train_loss = 0.9948429247888271, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 390, train_loss = 0.9944554697722197, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 391, train_loss = 0.9938779963704292, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 392, train_loss = 0.9928444934485015, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 393, train_loss = 0.992198975145584, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 394, train_loss = 0.9917430436762515, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 395, train_loss = 0.9911532240512315, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 396, train_loss = 0.9899072336556856, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 397, train_loss = 0.9893827407213394, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 398, train_loss = 0.9892665669322014, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 399, train_loss = 0.9880789890885353, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 400, train_loss = 0.9875666461884975, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 401, train_loss = 0.9870417689380702, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 402, train_loss = 0.9861603944154922, train_acc = 0.9981369352585002\n",
      "test Acc 0.9771880819366853:\n",
      "19th- epoch: 403, train_loss = 0.9855536315590143, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 404, train_loss = 0.9850808307528496, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 405, train_loss = 0.9842431458237115, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 406, train_loss = 0.9835502368805464, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 407, train_loss = 0.982854967325693, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 408, train_loss = 0.982513894647127, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 409, train_loss = 0.9813744997081812, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 410, train_loss = 0.9812403047981206, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 411, train_loss = 0.980425169080263, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 412, train_loss = 0.9797142948955297, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 413, train_loss = 0.9789821977319662, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 414, train_loss = 0.9788278260675725, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 415, train_loss = 0.9776679184287786, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 416, train_loss = 0.9771733762172516, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 417, train_loss = 0.976854495704174, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 418, train_loss = 0.9758502213808242, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 419, train_loss = 0.9753226985631045, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 420, train_loss = 0.974543085321784, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 421, train_loss = 0.9742466782627162, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 422, train_loss = 0.9736309411528055, train_acc = 0.9981369352585002\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 423, train_loss = 0.973018712043995, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 424, train_loss = 0.9721498880535364, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 425, train_loss = 0.9715587502869312, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 426, train_loss = 0.9711248359235469, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 427, train_loss = 0.970334325596923, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 428, train_loss = 0.9699280677887145, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 429, train_loss = 0.9691617184726056, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 430, train_loss = 0.968595715239644, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 431, train_loss = 0.9684581036271993, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 432, train_loss = 0.9675127770751715, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 433, train_loss = 0.967101426795125, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 434, train_loss = 0.9666771087795496, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 435, train_loss = 0.9654747384192888, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 436, train_loss = 0.9653120525181293, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 437, train_loss = 0.9645155016332865, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 438, train_loss = 0.9639481163176242, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 439, train_loss = 0.9634895504859742, train_acc = 0.9982533768048439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 440, train_loss = 0.9629550824465696, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 441, train_loss = 0.9621215499937534, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 442, train_loss = 0.9620629772543907, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 443, train_loss = 0.9613397419452667, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 444, train_loss = 0.9603311158716679, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 445, train_loss = 0.9601052142679691, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 446, train_loss = 0.9596799705177546, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 447, train_loss = 0.9591852370649576, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 448, train_loss = 0.9584433330746833, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 449, train_loss = 0.9578649836184923, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 450, train_loss = 0.9572870600968599, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 451, train_loss = 0.95674548795796, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 452, train_loss = 0.9562176199106034, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 453, train_loss = 0.9558867644518614, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 454, train_loss = 0.9551828031835612, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 455, train_loss = 0.9549727737903595, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 456, train_loss = 0.9539446340349969, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 457, train_loss = 0.9535842463374138, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 458, train_loss = 0.9535776618868113, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 459, train_loss = 0.9526883637008723, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 460, train_loss = 0.9518267245439347, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 461, train_loss = 0.9516943413764238, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 462, train_loss = 0.9512245313671883, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 463, train_loss = 0.950572651490802, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 464, train_loss = 0.9502674918621778, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 465, train_loss = 0.949589147552615, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 466, train_loss = 0.9488674011081457, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 467, train_loss = 0.9485966805368662, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 468, train_loss = 0.9478187145141419, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 469, train_loss = 0.9474906716495752, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 470, train_loss = 0.9468832965940237, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 471, train_loss = 0.9466705514641944, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 472, train_loss = 0.9458450488746166, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 473, train_loss = 0.945625609398121, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 474, train_loss = 0.9447931088507175, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 475, train_loss = 0.944522587582469, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 476, train_loss = 0.943933667615056, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 477, train_loss = 0.9434405565261841, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 478, train_loss = 0.9432221464812756, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 479, train_loss = 0.9427114985883236, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 480, train_loss = 0.941695548593998, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 481, train_loss = 0.941381029173499, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 482, train_loss = 0.9411688198742922, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 483, train_loss = 0.940391536190873, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 484, train_loss = 0.9400333470257465, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 485, train_loss = 0.9396918831916992, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 486, train_loss = 0.9392326697707176, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 487, train_loss = 0.9385195734503213, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 488, train_loss = 0.9379597424122039, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 489, train_loss = 0.9379265538009349, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 490, train_loss = 0.9372341012058314, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 491, train_loss = 0.9365892695786897, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 492, train_loss = 0.9362771604210138, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 493, train_loss = 0.9357638880610466, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 494, train_loss = 0.9353048298507929, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 495, train_loss = 0.9349525161087513, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 496, train_loss = 0.9346631579101086, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 497, train_loss = 0.9342905239609536, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 498, train_loss = 0.9335361495614052, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 499, train_loss = 0.9330659136176109, train_acc = 0.9982533768048439\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|████████████████████████████████████████████▎                         | 19/30 [3:09:37<1:49:59, 599.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "20th- epoch: 0, train_loss = 139.0960905700922, train_acc = 0.7444108057755007\n",
      "test Acc 0.8594040968342644:\n",
      "20th- epoch: 1, train_loss = 50.42718705534935, train_acc = 0.8940381928272008\n",
      "test Acc 0.9068901303538175:\n",
      "20th- epoch: 2, train_loss = 36.04918462783098, train_acc = 0.9251280857009782\n",
      "test Acc 0.9245810055865922:\n",
      "20th- epoch: 3, train_loss = 28.755334101617336, train_acc = 0.9411970190964136\n",
      "test Acc 0.9343575418994413:\n",
      "20th- epoch: 4, train_loss = 24.141942873597145, train_acc = 0.9513274336283186\n",
      "test Acc 0.9390130353817505:\n",
      "20th- epoch: 5, train_loss = 20.82873029075563, train_acc = 0.9569166278528178\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 6, train_loss = 18.30120206065476, train_acc = 0.9636702375407545\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 7, train_loss = 16.312966452911496, train_acc = 0.9678621332091291\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 8, train_loss = 14.688302269205451, train_acc = 0.9712389380530974\n",
      "test Acc 0.952048417132216:\n",
      "20th- epoch: 9, train_loss = 13.361662689596415, train_acc = 0.9750815090824406\n",
      "test Acc 0.9529795158286778:\n",
      "20th- epoch: 10, train_loss = 12.243569506332278, train_acc = 0.9772938984629715\n",
      "test Acc 0.9534450651769087:\n",
      "20th- epoch: 11, train_loss = 11.285607790574431, train_acc = 0.9791569632044713\n",
      "test Acc 0.9562383612662942:\n",
      "20th- epoch: 12, train_loss = 10.45899209100753, train_acc = 0.9814857941313461\n",
      "test Acc 0.9567039106145251:\n",
      "20th- epoch: 13, train_loss = 9.733330047689378, train_acc = 0.9831159757801584\n",
      "test Acc 0.957169459962756:\n",
      "20th- epoch: 14, train_loss = 9.087898361496627, train_acc = 0.9847461574289706\n",
      "test Acc 0.9585661080074488:\n",
      "20th- epoch: 15, train_loss = 8.519511341117322, train_acc = 0.9853283651606893\n",
      "test Acc 0.9585661080074488:\n",
      "20th- epoch: 16, train_loss = 8.012844012118876, train_acc = 0.9862598975314392\n",
      "test Acc 0.9594972067039106:\n",
      "20th- epoch: 17, train_loss = 7.556320113129914, train_acc = 0.9864927806241267\n",
      "test Acc 0.9594972067039106:\n",
      "20th- epoch: 18, train_loss = 7.14505663421005, train_acc = 0.9876571960875641\n",
      "test Acc 0.9604283054003724:\n",
      "20th- epoch: 19, train_loss = 6.77470566611737, train_acc = 0.9885887284583139\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 20, train_loss = 6.441704616881907, train_acc = 0.9891709361900326\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 21, train_loss = 6.138600043952465, train_acc = 0.9899860270144387\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 22, train_loss = 5.858824253082275, train_acc = 0.9904517931998137\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 23, train_loss = 5.607439818792045, train_acc = 0.9906846762925011\n",
      "test Acc 0.9632216014897579:\n",
      "20th- epoch: 24, train_loss = 5.374410167336464, train_acc = 0.9912668840242198\n",
      "test Acc 0.9641527001862198:\n",
      "20th- epoch: 25, train_loss = 5.160062852315605, train_acc = 0.9918490917559385\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 26, train_loss = 4.9619904002174735, train_acc = 0.9921984163949698\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 27, train_loss = 4.779917797539383, train_acc = 0.9924312994876572\n",
      "test Acc 0.9646182495344506:\n",
      "20th- epoch: 28, train_loss = 4.610626386944205, train_acc = 0.9924312994876572\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 29, train_loss = 4.454603305552155, train_acc = 0.9928970656730322\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 30, train_loss = 4.308217623736709, train_acc = 0.9930135072193759\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 31, train_loss = 4.170070676598698, train_acc = 0.9934792734047508\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 32, train_loss = 4.0438357554376125, train_acc = 0.9935957149510946\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 33, train_loss = 3.923302671406418, train_acc = 0.993828598043782\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 34, train_loss = 3.8126197471283376, train_acc = 0.9939450395901258\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 35, train_loss = 3.706564400345087, train_acc = 0.9944108057755007\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 36, train_loss = 3.6073164977133274, train_acc = 0.9946436888681882\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 37, train_loss = 3.5131019256077707, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 38, train_loss = 3.4250984019599855, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 39, train_loss = 3.342188584152609, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 40, train_loss = 3.2633943022228777, train_acc = 0.9952258965999069\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 41, train_loss = 3.1878130226396024, train_acc = 0.9952258965999069\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 42, train_loss = 3.116415835916996, train_acc = 0.9954587796925943\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 43, train_loss = 3.04998400202021, train_acc = 0.995575221238938\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 44, train_loss = 2.986860316246748, train_acc = 0.9954587796925943\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 45, train_loss = 2.9258873402141035, train_acc = 0.995575221238938\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 46, train_loss = 2.867749923374504, train_acc = 0.9956916627852818\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 47, train_loss = 2.8131142049096525, train_acc = 0.9956916627852818\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 48, train_loss = 2.759858733508736, train_acc = 0.9956916627852818\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 49, train_loss = 2.7108752629719675, train_acc = 0.9958081043316255\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 50, train_loss = 2.663606584072113, train_acc = 0.9959245458779693\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 51, train_loss = 2.6175480782985687, train_acc = 0.9959245458779693\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 52, train_loss = 2.5746565400622785, train_acc = 0.996040987424313\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 53, train_loss = 2.533992235781625, train_acc = 0.996040987424313\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 54, train_loss = 2.493210067274049, train_acc = 0.996040987424313\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 55, train_loss = 2.456065520644188, train_acc = 0.996040987424313\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 56, train_loss = 2.419400640996173, train_acc = 0.996040987424313\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 57, train_loss = 2.384475752711296, train_acc = 0.9959245458779693\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 58, train_loss = 2.3515948976855725, train_acc = 0.9959245458779693\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 59, train_loss = 2.3197108518797904, train_acc = 0.9959245458779693\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 60, train_loss = 2.288554646074772, train_acc = 0.996040987424313\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 61, train_loss = 2.2588506613392383, train_acc = 0.9961574289706567\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 62, train_loss = 2.230895606102422, train_acc = 0.9961574289706567\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 63, train_loss = 2.2028741650283337, train_acc = 0.9962738705170004\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 64, train_loss = 2.1770327128469944, train_acc = 0.9962738705170004\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 65, train_loss = 2.1518817481119186, train_acc = 0.9963903120633442\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 66, train_loss = 2.1277179655153304, train_acc = 0.9963903120633442\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 67, train_loss = 2.1049451257567853, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 68, train_loss = 2.082363673718646, train_acc = 0.9966231951560317\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 69, train_loss = 2.0606381718534976, train_acc = 0.9967396367023754\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 70, train_loss = 2.0395468834321946, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 71, train_loss = 2.0200437668245286, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 72, train_loss = 2.0003727588336915, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 73, train_loss = 1.9819992519915104, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 74, train_loss = 1.9638903252780437, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 75, train_loss = 1.9466140021104366, train_acc = 0.9968560782487191\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 76, train_loss = 1.9293594758491963, train_acc = 0.9968560782487191\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 77, train_loss = 1.9127686347346753, train_acc = 0.9968560782487191\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 78, train_loss = 1.8968551431316882, train_acc = 0.9968560782487191\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 79, train_loss = 1.881157846422866, train_acc = 0.9967396367023754\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 80, train_loss = 1.8662236966192722, train_acc = 0.9967396367023754\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 81, train_loss = 1.8517129097599536, train_acc = 0.9967396367023754\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 82, train_loss = 1.8376380081754178, train_acc = 0.9969725197950629\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 83, train_loss = 1.8235518622677773, train_acc = 0.9969725197950629\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 84, train_loss = 1.8102634511888027, train_acc = 0.9969725197950629\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 85, train_loss = 1.7972746689338237, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 86, train_loss = 1.7848099233815446, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 87, train_loss = 1.7725692304084077, train_acc = 0.9970889613414066\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 88, train_loss = 1.7599677009275183, train_acc = 0.9973218444340941\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 89, train_loss = 1.74917935335543, train_acc = 0.9972054028877504\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 90, train_loss = 1.7370699184248224, train_acc = 0.9973218444340941\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 91, train_loss = 1.725953017710708, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 92, train_loss = 1.7161059714853764, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 93, train_loss = 1.7050152668962255, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 94, train_loss = 1.6948208982357755, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 95, train_loss = 1.684746744693257, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 96, train_loss = 1.6746710675070062, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 97, train_loss = 1.6648164627840742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 98, train_loss = 1.655968731851317, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 99, train_loss = 1.6465741904685274, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 100, train_loss = 1.638019647449255, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 101, train_loss = 1.6287290999898687, train_acc = 0.9973218444340941\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 102, train_loss = 1.6209766293177381, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 103, train_loss = 1.6121301042148843, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 104, train_loss = 1.6039972230792046, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 105, train_loss = 1.5958957510301843, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 106, train_loss = 1.587716835201718, train_acc = 0.9972054028877504\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 107, train_loss = 1.580494798719883, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 108, train_loss = 1.5724021071800962, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 109, train_loss = 1.5656298858812079, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 110, train_loss = 1.5580882541835308, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 111, train_loss = 1.5514016039669514, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 112, train_loss = 1.5440604761242867, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 113, train_loss = 1.5371745874872431, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 114, train_loss = 1.5302850963780656, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 115, train_loss = 1.523456466733478, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 116, train_loss = 1.5164789482951164, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 117, train_loss = 1.511094673187472, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 118, train_loss = 1.504115225165151, train_acc = 0.9973218444340941\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 119, train_loss = 1.4982165930559859, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 120, train_loss = 1.4923542948672548, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 121, train_loss = 1.4860379236051813, train_acc = 0.9974382859804378\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 122, train_loss = 1.4804063973715529, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 123, train_loss = 1.4745327731361613, train_acc = 0.9975547275267815\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 124, train_loss = 1.4692326486110687, train_acc = 0.9975547275267815\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 125, train_loss = 1.4639213929185644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 126, train_loss = 1.4587154053151608, train_acc = 0.9975547275267815\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 127, train_loss = 1.4528596190502867, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 128, train_loss = 1.447896713973023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 129, train_loss = 1.4422331005334854, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 130, train_loss = 1.4374713090946898, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 131, train_loss = 1.432593890815042, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 132, train_loss = 1.427635402767919, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 133, train_loss = 1.4226116314530373, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 134, train_loss = 1.4177227566251531, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 135, train_loss = 1.4132496552774683, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 136, train_loss = 1.4084724858403206, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 137, train_loss = 1.4037209848174825, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 138, train_loss = 1.399727170704864, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 139, train_loss = 1.3949374941876158, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 140, train_loss = 1.3909665867686272, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 141, train_loss = 1.3859136514365673, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 142, train_loss = 1.381519727408886, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 143, train_loss = 1.3777156037976965, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 144, train_loss = 1.3729116767644882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 145, train_loss = 1.3690402073552832, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 146, train_loss = 1.364698844612576, train_acc = 0.9974382859804378\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 147, train_loss = 1.3607186103472486, train_acc = 0.9975547275267815\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 148, train_loss = 1.357049866230227, train_acc = 0.9975547275267815\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 149, train_loss = 1.3531254641711712, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 150, train_loss = 1.3495085363974795, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 151, train_loss = 1.345418356359005, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 152, train_loss = 1.3418825169210322, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 153, train_loss = 1.3380998484790325, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 154, train_loss = 1.3347341331536882, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 155, train_loss = 1.3308110870420933, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 156, train_loss = 1.32749068364501, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 157, train_loss = 1.3237906359136105, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 158, train_loss = 1.3206116097862832, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 159, train_loss = 1.3171830351348035, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 160, train_loss = 1.3135370996897109, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 161, train_loss = 1.3102407951955684, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 162, train_loss = 1.3071158255334012, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 163, train_loss = 1.3036580110783689, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 164, train_loss = 1.3008103482425213, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 165, train_loss = 1.2978060506284237, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 166, train_loss = 1.2944227581028827, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 167, train_loss = 1.2915377728641033, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 168, train_loss = 1.2885986790060997, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 169, train_loss = 1.2853033642168157, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 170, train_loss = 1.2824019876425155, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 171, train_loss = 1.2791423238813877, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 172, train_loss = 1.2764993731980212, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 173, train_loss = 1.2735390576417558, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 174, train_loss = 1.2705425024032593, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 175, train_loss = 1.2682188414037228, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 176, train_loss = 1.2649630407686345, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 177, train_loss = 1.2626217429642566, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 178, train_loss = 1.2596636787056923, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 179, train_loss = 1.2572968763415702, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 180, train_loss = 1.2542173365945928, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 181, train_loss = 1.2514475683565252, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 182, train_loss = 1.2492548463051207, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 183, train_loss = 1.2464265041053295, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 184, train_loss = 1.2443878700141795, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 185, train_loss = 1.2416056481306441, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 186, train_loss = 1.2387435075943358, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 187, train_loss = 1.2361779821221717, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 188, train_loss = 1.234267771244049, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 189, train_loss = 1.2314633305068128, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 190, train_loss = 1.229410106956493, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 191, train_loss = 1.2265561533276923, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 192, train_loss = 1.2246630564332008, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 193, train_loss = 1.2222235910594463, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 194, train_loss = 1.2199613054399379, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 195, train_loss = 1.2176312071387656, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 196, train_loss = 1.2156419952516444, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 197, train_loss = 1.2130960412323475, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 198, train_loss = 1.2106428767438047, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 199, train_loss = 1.2085229369695298, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 200, train_loss = 1.2060498508508317, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 201, train_loss = 1.2038284850423224, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 202, train_loss = 1.20153784629656, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 203, train_loss = 1.1993966177105904, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 204, train_loss = 1.197556873143185, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 205, train_loss = 1.1950065170531161, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 206, train_loss = 1.192819585383404, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 207, train_loss = 1.1911534468526952, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 208, train_loss = 1.1889884993433952, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 209, train_loss = 1.1867525304551236, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 210, train_loss = 1.1854127757251263, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 211, train_loss = 1.182909528433811, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 212, train_loss = 1.1814124907250516, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 213, train_loss = 1.179604412347544, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 214, train_loss = 1.1776568442583084, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 215, train_loss = 1.1758580257301219, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 216, train_loss = 1.1740051756496541, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 217, train_loss = 1.1720227387850173, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 218, train_loss = 1.1701512026484124, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 219, train_loss = 1.168453086167574, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 220, train_loss = 1.166911993175745, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 221, train_loss = 1.164527926594019, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 222, train_loss = 1.1633775308728218, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 223, train_loss = 1.1617686959798448, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 224, train_loss = 1.159466511278879, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 225, train_loss = 1.1577847339212894, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 226, train_loss = 1.1558500963146798, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 227, train_loss = 1.1544512907858007, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 228, train_loss = 1.1525126012857072, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 229, train_loss = 1.1515064512495883, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 230, train_loss = 1.1492693163454533, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 231, train_loss = 1.1478864277596585, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 232, train_loss = 1.1464681054349057, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 233, train_loss = 1.1446723130648024, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 234, train_loss = 1.1428776060347445, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 235, train_loss = 1.1413449670071714, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 236, train_loss = 1.1396614760160446, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 237, train_loss = 1.1383153435890563, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 238, train_loss = 1.13654151186347, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 239, train_loss = 1.1351050448720343, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 240, train_loss = 1.1336598508059978, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 241, train_loss = 1.131961390376091, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 242, train_loss = 1.1309765403275378, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 243, train_loss = 1.1293204526300542, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 244, train_loss = 1.127761822193861, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 245, train_loss = 1.1263872000272386, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 246, train_loss = 1.1249604225158691, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 247, train_loss = 1.123368177562952, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 248, train_loss = 1.1220491963322274, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 249, train_loss = 1.120530356944073, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 250, train_loss = 1.119253582030069, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 251, train_loss = 1.1180798026616685, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 252, train_loss = 1.1167191329295747, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 253, train_loss = 1.1149439861183055, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 254, train_loss = 1.1141063012182713, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 255, train_loss = 1.1127876813407056, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 256, train_loss = 1.1115452175145037, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 257, train_loss = 1.1099222612683661, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 258, train_loss = 1.1086235630209558, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 259, train_loss = 1.1074714474380016, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 260, train_loss = 1.1060056127607822, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 261, train_loss = 1.1049189890618436, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 262, train_loss = 1.1038381780381314, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 263, train_loss = 1.1020382928545587, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 264, train_loss = 1.1009592674672604, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 265, train_loss = 1.099689345806837, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 266, train_loss = 1.09839103493141, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 267, train_loss = 1.0973697056469973, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 268, train_loss = 1.0959378952684347, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 269, train_loss = 1.094872242450947, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 270, train_loss = 1.0939144740405027, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 271, train_loss = 1.0924899565579835, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 272, train_loss = 1.0912173005344812, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 273, train_loss = 1.0901532769203186, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 274, train_loss = 1.0888211714627687, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 275, train_loss = 1.0879773249325808, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 276, train_loss = 1.0867075398564339, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 277, train_loss = 1.0855629419384059, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 278, train_loss = 1.0844109381141607, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 279, train_loss = 1.0831485142407473, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 280, train_loss = 1.0820369124412537, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 281, train_loss = 1.0809845887124538, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 282, train_loss = 1.0801334554853383, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 283, train_loss = 1.0785281633434352, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 284, train_loss = 1.0776400839386042, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 285, train_loss = 1.0767388927342836, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 286, train_loss = 1.0750605836510658, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 287, train_loss = 1.0742145826516207, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 288, train_loss = 1.073496725410223, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 289, train_loss = 1.0718031041324139, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 290, train_loss = 1.070963071048027, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 291, train_loss = 1.070116363465786, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 292, train_loss = 1.0690298924746457, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 293, train_loss = 1.0680933395924512, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 294, train_loss = 1.0672130485472735, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 295, train_loss = 1.0662863080797251, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 296, train_loss = 1.064713679254055, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 297, train_loss = 1.0643441130814608, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 298, train_loss = 1.062871627509594, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 299, train_loss = 1.0620792657136917, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 300, train_loss = 1.0610614717006683, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 301, train_loss = 1.0601429268717766, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 302, train_loss = 1.0593127173779067, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 303, train_loss = 1.058226435125107, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 304, train_loss = 1.0570019496080931, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 305, train_loss = 1.0564895210263785, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 306, train_loss = 1.0557181301119272, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 307, train_loss = 1.0543799735605717, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 308, train_loss = 1.053545780479908, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 309, train_loss = 1.05256993448711, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 310, train_loss = 1.0517647750675678, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 311, train_loss = 1.0506570475699846, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 312, train_loss = 1.0496430359780788, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 313, train_loss = 1.0485400520265102, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 314, train_loss = 1.0483771624567453, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 315, train_loss = 1.0467579973337706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 316, train_loss = 1.046182308346033, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 317, train_loss = 1.0449439187941607, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 318, train_loss = 1.0444039565918501, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 319, train_loss = 1.043147437274456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 320, train_loss = 1.0425779484212399, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 321, train_loss = 1.041698524117237, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 322, train_loss = 1.0405998205242213, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 323, train_loss = 1.0399224261345807, train_acc = 0.9977876106194691\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 324, train_loss = 1.0390987396240234, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 325, train_loss = 1.0382358680071775, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 326, train_loss = 1.037326492369175, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 327, train_loss = 1.0362356478872243, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 328, train_loss = 1.0355095801351126, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 329, train_loss = 1.0350648971798364, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 330, train_loss = 1.0339005589485168, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 331, train_loss = 1.0331179735658225, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 332, train_loss = 1.032478917390108, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 333, train_loss = 1.03130292147398, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 334, train_loss = 1.0305315156874713, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 335, train_loss = 1.0298570940794889, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 336, train_loss = 1.029106318950653, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 337, train_loss = 1.0282462587056216, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 338, train_loss = 1.0272702500224113, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 339, train_loss = 1.0268007429840509, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 340, train_loss = 1.025975976139307, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 341, train_loss = 1.0251496943237726, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 342, train_loss = 1.0240098126232624, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 343, train_loss = 1.0235487520694733, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 344, train_loss = 1.0226431762275752, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 345, train_loss = 1.0219378819165286, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 346, train_loss = 1.0210244779882487, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 347, train_loss = 1.020498594880337, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 348, train_loss = 1.0193731250765268, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 349, train_loss = 1.0186491087079048, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 350, train_loss = 1.0179479817452375, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 351, train_loss = 1.0171962132153567, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 352, train_loss = 1.016467735171318, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 353, train_loss = 1.01575536528253, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 354, train_loss = 1.015149064362049, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 355, train_loss = 1.0141869696381036, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 356, train_loss = 1.0135333898069803, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 357, train_loss = 1.0127957127988338, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 358, train_loss = 1.011905970663065, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 359, train_loss = 1.011310870439047, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 360, train_loss = 1.0106388752756175, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 361, train_loss = 1.0098549015820026, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 362, train_loss = 1.0091880870459136, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 363, train_loss = 1.0082820616662502, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 364, train_loss = 1.0080163540842477, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 365, train_loss = 1.0074221479299013, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 366, train_loss = 1.0066362780926283, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 367, train_loss = 1.0056770307419356, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 368, train_loss = 1.0052031402883586, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 369, train_loss = 1.004335471749073, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 370, train_loss = 1.0036675756273326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 371, train_loss = 1.0030232245626394, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 372, train_loss = 1.002605135232443, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 373, train_loss = 1.0014055520296097, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 374, train_loss = 1.0010931616125163, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 375, train_loss = 1.0003928765654564, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 376, train_loss = 0.9997782185673714, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 377, train_loss = 0.9988667815923691, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 378, train_loss = 0.9982054705324117, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 379, train_loss = 0.9974866149423178, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 380, train_loss = 0.9970148044230882, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 381, train_loss = 0.9962609137000982, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 382, train_loss = 0.9952189835312311, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 383, train_loss = 0.9949323708715383, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 384, train_loss = 0.9937703137693461, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 385, train_loss = 0.9935429332253989, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 386, train_loss = 0.9929704864916857, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 387, train_loss = 0.9920959025621414, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 388, train_loss = 0.9914773715136107, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 389, train_loss = 0.9912453331053257, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 390, train_loss = 0.9901702453789767, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 391, train_loss = 0.9899715656938497, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 392, train_loss = 0.9890121842327062, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 393, train_loss = 0.9887650112214033, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 394, train_loss = 0.9878270303306635, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 395, train_loss = 0.9871367365121841, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 396, train_loss = 0.9867043110134546, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 397, train_loss = 0.9860314031539019, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 398, train_loss = 0.9854720321891364, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 399, train_loss = 0.9849406803550664, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 400, train_loss = 0.9844493269920349, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 401, train_loss = 0.9837774696352426, train_acc = 0.9977876106194691\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 402, train_loss = 0.9829633869230747, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 403, train_loss = 0.9821990318596363, train_acc = 0.9977876106194691\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 404, train_loss = 0.9819596422312316, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 405, train_loss = 0.9811465255916119, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 406, train_loss = 0.9807133873400744, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 407, train_loss = 0.9801750207843725, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 408, train_loss = 0.9794238035974558, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 409, train_loss = 0.9788845466973726, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 410, train_loss = 0.9784234551189002, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 411, train_loss = 0.9780003974738065, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 412, train_loss = 0.9771371868846472, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 413, train_loss = 0.9766612313687801, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 414, train_loss = 0.9762021837232169, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 415, train_loss = 0.9753593765199184, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 416, train_loss = 0.9750835075974464, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 417, train_loss = 0.974406319350237, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 418, train_loss = 0.9736473324301187, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 419, train_loss = 0.9732999118568841, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 420, train_loss = 0.9729457572102547, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 421, train_loss = 0.9720336248574313, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 422, train_loss = 0.9716563411056995, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 423, train_loss = 0.9712316356599331, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 424, train_loss = 0.9705775268375874, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 425, train_loss = 0.9701433343288954, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 426, train_loss = 0.9693967041966971, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 427, train_loss = 0.9689528308808804, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 428, train_loss = 0.9686377781035844, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 429, train_loss = 0.9677319352922495, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 430, train_loss = 0.9671242485346738, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 431, train_loss = 0.966850029915804, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 432, train_loss = 0.9662988148629665, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 433, train_loss = 0.9656221320328768, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 434, train_loss = 0.965234812349081, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 435, train_loss = 0.9647354297339916, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 436, train_loss = 0.9643898767826613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 437, train_loss = 0.963870819658041, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 438, train_loss = 0.9631813714804593, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 439, train_loss = 0.962831682205433, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 440, train_loss = 0.9621901834907476, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 441, train_loss = 0.9617266965506133, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 442, train_loss = 0.9612552151083946, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 443, train_loss = 0.960816470294958, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 444, train_loss = 0.9602003221807536, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 445, train_loss = 0.9597580010595266, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 446, train_loss = 0.9594306821527425, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 447, train_loss = 0.9586804360151291, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 448, train_loss = 0.9580078708531801, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 449, train_loss = 0.9577166462840978, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 450, train_loss = 0.9574370868504047, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 451, train_loss = 0.9567772746086121, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 452, train_loss = 0.9563538121583406, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 453, train_loss = 0.9560075141489506, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 454, train_loss = 0.955224027246004, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 455, train_loss = 0.9549020441772882, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 456, train_loss = 0.954469345510006, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 457, train_loss = 0.9537321900425013, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 458, train_loss = 0.9537154945137445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 459, train_loss = 0.9529698776750593, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 460, train_loss = 0.9526675703673391, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 461, train_loss = 0.9519748985767365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 462, train_loss = 0.9516546217055293, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 463, train_loss = 0.951188463717699, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 464, train_loss = 0.9507316475064727, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 465, train_loss = 0.9502400420606136, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 466, train_loss = 0.9499428781418828, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 467, train_loss = 0.9490858266799478, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 468, train_loss = 0.9490079544484615, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 469, train_loss = 0.9483141427190276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 470, train_loss = 0.9478138784616021, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 471, train_loss = 0.9472609447984723, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 472, train_loss = 0.9471453316509724, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 473, train_loss = 0.9464715905487537, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 474, train_loss = 0.9463287604303332, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 475, train_loss = 0.9456590165646048, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 476, train_loss = 0.945120436444995, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 477, train_loss = 0.9447038806974888, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 478, train_loss = 0.9444212391972542, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 479, train_loss = 0.9440446272492409, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 480, train_loss = 0.9435738722531823, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 481, train_loss = 0.9430339224636555, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 482, train_loss = 0.9429729605762986, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 483, train_loss = 0.9420973236410646, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 484, train_loss = 0.9420838095247746, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 485, train_loss = 0.9412303914577933, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 486, train_loss = 0.941005352884531, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 487, train_loss = 0.9407111679465743, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 488, train_loss = 0.940188339605811, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 489, train_loss = 0.9397793672978878, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 490, train_loss = 0.9394405509083299, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 491, train_loss = 0.9386813752353191, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 492, train_loss = 0.9382999527006177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 493, train_loss = 0.938021969050169, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 494, train_loss = 0.9375324957072735, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 495, train_loss = 0.937138223394868, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 496, train_loss = 0.9369042565376731, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 497, train_loss = 0.9361841144709615, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 498, train_loss = 0.9359241910278797, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 499, train_loss = 0.9354831414966611, train_acc = 0.9977876106194691\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████▋                       | 20/30 [3:19:39<1:40:06, 600.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "21th- epoch: 0, train_loss = 151.2073800712824, train_acc = 0.746040987424313\n",
      "test Acc 0.8491620111731844:\n",
      "21th- epoch: 1, train_loss = 52.821558855473995, train_acc = 0.8922915696320447\n",
      "test Acc 0.8915270018621974:\n",
      "21th- epoch: 2, train_loss = 37.00347354263067, train_acc = 0.9219841639496973\n",
      "test Acc 0.9143389199255121:\n",
      "21th- epoch: 3, train_loss = 28.931000776588917, train_acc = 0.9397997205402888\n",
      "test Acc 0.9269087523277467:\n",
      "21th- epoch: 4, train_loss = 23.892789099365473, train_acc = 0.9508616674429436\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 5, train_loss = 20.404083512723446, train_acc = 0.959944108057755\n",
      "test Acc 0.9413407821229051:\n",
      "21th- epoch: 6, train_loss = 17.82868967577815, train_acc = 0.9648346530041919\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 7, train_loss = 15.831494115293026, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 8, train_loss = 14.233616523444653, train_acc = 0.9711224965067536\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 9, train_loss = 12.920842729508877, train_acc = 0.9747321844434094\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 10, train_loss = 11.814241921529174, train_acc = 0.9775267815556591\n",
      "test Acc 0.952048417132216:\n",
      "21th- epoch: 11, train_loss = 10.87755723670125, train_acc = 0.9795062878435026\n",
      "test Acc 0.9548417132216015:\n",
      "21th- epoch: 12, train_loss = 10.068281790241599, train_acc = 0.98067070330694\n",
      "test Acc 0.957169459962756:\n",
      "21th- epoch: 13, train_loss = 9.368191922083497, train_acc = 0.9820680018630648\n",
      "test Acc 0.957169459962756:\n",
      "21th- epoch: 14, train_loss = 8.758569113910198, train_acc = 0.9835817419655333\n",
      "test Acc 0.9585661080074488:\n",
      "21th- epoch: 15, train_loss = 8.215353460982442, train_acc = 0.9842803912435957\n",
      "test Acc 0.9585661080074488:\n",
      "21th- epoch: 16, train_loss = 7.737713295966387, train_acc = 0.985444806707033\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 17, train_loss = 7.31238710694015, train_acc = 0.9860270144387517\n",
      "test Acc 0.9590316573556797:\n",
      "21th- epoch: 18, train_loss = 6.927856469526887, train_acc = 0.9873078714485328\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 19, train_loss = 6.582004721276462, train_acc = 0.9881229622729389\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 20, train_loss = 6.268996647559106, train_acc = 0.9890544946436889\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 21, train_loss = 5.986363212577999, train_acc = 0.9899860270144387\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 22, train_loss = 5.728181678801775, train_acc = 0.990801117838845\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 23, train_loss = 5.492084668017924, train_acc = 0.9910340009315324\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 24, train_loss = 5.274535865522921, train_acc = 0.9916162086632511\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 25, train_loss = 5.07467554230243, train_acc = 0.9918490917559385\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 26, train_loss = 4.891681511886418, train_acc = 0.9923148579413135\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 27, train_loss = 4.7204836225137115, train_acc = 0.9925477410340009\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 28, train_loss = 4.562459262087941, train_acc = 0.9927806241266884\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 29, train_loss = 4.415137861855328, train_acc = 0.9931299487657196\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 30, train_loss = 4.27726421225816, train_acc = 0.9934792734047508\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 31, train_loss = 4.1508562890812755, train_acc = 0.993828598043782\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 32, train_loss = 4.030268953181803, train_acc = 0.993828598043782\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 33, train_loss = 3.9184832014143467, train_acc = 0.9939450395901258\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 34, train_loss = 3.8134776977822185, train_acc = 0.994294364229157\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 35, train_loss = 3.7141883773729205, train_acc = 0.9946436888681882\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 36, train_loss = 3.6218281611800194, train_acc = 0.9947601304145319\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 37, train_loss = 3.5333804399706423, train_acc = 0.9949930135072194\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 38, train_loss = 3.452163714915514, train_acc = 0.9951094550535631\n",
      "test Acc 0.9674115456238361:\n",
      "21th- epoch: 39, train_loss = 3.3746891445480287, train_acc = 0.9953423381462506\n",
      "test Acc 0.9674115456238361:\n",
      "21th- epoch: 40, train_loss = 3.300738672260195, train_acc = 0.995575221238938\n",
      "test Acc 0.9674115456238361:\n",
      "21th- epoch: 41, train_loss = 3.2298913351260126, train_acc = 0.9954587796925943\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 42, train_loss = 3.163866395596415, train_acc = 0.9954587796925943\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 43, train_loss = 3.0998478047549725, train_acc = 0.9954587796925943\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 44, train_loss = 3.0394415580667555, train_acc = 0.9954587796925943\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 45, train_loss = 2.982012964785099, train_acc = 0.995575221238938\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 46, train_loss = 2.926269759889692, train_acc = 0.9958081043316255\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 47, train_loss = 2.8741095885634422, train_acc = 0.9956916627852818\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 48, train_loss = 2.8235110878013074, train_acc = 0.9958081043316255\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 49, train_loss = 2.7753290995024145, train_acc = 0.9958081043316255\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 50, train_loss = 2.730255839880556, train_acc = 0.996040987424313\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 51, train_loss = 2.6865542181767523, train_acc = 0.996040987424313\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 52, train_loss = 2.6442256532609463, train_acc = 0.9961574289706567\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 53, train_loss = 2.6046369187533855, train_acc = 0.9963903120633442\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 54, train_loss = 2.5657568187452853, train_acc = 0.9962738705170004\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 55, train_loss = 2.528882584068924, train_acc = 0.9963903120633442\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 56, train_loss = 2.493610074277967, train_acc = 0.996506753609688\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 57, train_loss = 2.460290104150772, train_acc = 0.9966231951560317\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 58, train_loss = 2.4264376647770405, train_acc = 0.9966231951560317\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 59, train_loss = 2.3952055633999407, train_acc = 0.9966231951560317\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 60, train_loss = 2.3649828620254993, train_acc = 0.9966231951560317\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 61, train_loss = 2.335663786623627, train_acc = 0.9966231951560317\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 62, train_loss = 2.3081219880841672, train_acc = 0.9966231951560317\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 63, train_loss = 2.280219227075577, train_acc = 0.9966231951560317\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 64, train_loss = 2.2542363181710243, train_acc = 0.9966231951560317\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 65, train_loss = 2.2279486223123968, train_acc = 0.9966231951560317\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 66, train_loss = 2.2037542038597167, train_acc = 0.9966231951560317\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 67, train_loss = 2.1802407591603696, train_acc = 0.9966231951560317\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 68, train_loss = 2.1569326505996287, train_acc = 0.9967396367023754\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 69, train_loss = 2.1356963242869824, train_acc = 0.9967396367023754\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 70, train_loss = 2.1144973014015704, train_acc = 0.9967396367023754\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 71, train_loss = 2.09374783677049, train_acc = 0.9968560782487191\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 72, train_loss = 2.0740850705187768, train_acc = 0.9968560782487191\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 73, train_loss = 2.0540847789961845, train_acc = 0.9968560782487191\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 74, train_loss = 2.035697180777788, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 75, train_loss = 2.01712308335118, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 76, train_loss = 1.9993809063453227, train_acc = 0.9970889613414066\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 77, train_loss = 1.982708404539153, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 78, train_loss = 1.9661298219580203, train_acc = 0.9969725197950629\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 79, train_loss = 1.9496070991735905, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 80, train_loss = 1.934011961100623, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 81, train_loss = 1.9196109175682068, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 82, train_loss = 1.9042740266304463, train_acc = 0.9972054028877504\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 83, train_loss = 1.8898402254562825, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 84, train_loss = 1.8761298034805804, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 85, train_loss = 1.8628140836954117, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 86, train_loss = 1.849325017305091, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 87, train_loss = 1.8360916662495583, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 88, train_loss = 1.823855483205989, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 89, train_loss = 1.811432582559064, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 90, train_loss = 1.7995349939446896, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 91, train_loss = 1.7879854328930378, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 92, train_loss = 1.776183519512415, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 93, train_loss = 1.7654585663694888, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 94, train_loss = 1.7544149395544082, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 95, train_loss = 1.7438724599778652, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 96, train_loss = 1.7337471295613796, train_acc = 0.9973218444340941\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 97, train_loss = 1.7238864277023822, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 98, train_loss = 1.7138249527197331, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 99, train_loss = 1.70471000415273, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 100, train_loss = 1.6952525053638965, train_acc = 0.9973218444340941\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 101, train_loss = 1.6857945148367435, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 102, train_loss = 1.6768621616065502, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 103, train_loss = 1.6683790411334485, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 104, train_loss = 1.6590907264035195, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 105, train_loss = 1.6511682521086186, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 106, train_loss = 1.6427067841868848, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 107, train_loss = 1.6348069868981838, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 108, train_loss = 1.6268562551122159, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 109, train_loss = 1.61863008630462, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 110, train_loss = 1.6113654088694602, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 111, train_loss = 1.6037551413755864, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 112, train_loss = 1.5964244604110718, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 113, train_loss = 1.589345008134842, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 114, train_loss = 1.5820746794342995, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 115, train_loss = 1.575572433648631, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 116, train_loss = 1.568382628262043, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 117, train_loss = 1.562196546467021, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 118, train_loss = 1.5552293633809313, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 119, train_loss = 1.5485695922980085, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 120, train_loss = 1.542602447210811, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 121, train_loss = 1.5362562326481566, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 122, train_loss = 1.5303142368793488, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 123, train_loss = 1.5243775820126757, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 124, train_loss = 1.5182433513691649, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 125, train_loss = 1.5129532614955679, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 126, train_loss = 1.5073820104589686, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 127, train_loss = 1.5015278147766367, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 128, train_loss = 1.4962562968721613, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 129, train_loss = 1.490600973367691, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 130, train_loss = 1.4853196243057027, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 131, train_loss = 1.4807480027666315, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 132, train_loss = 1.4752007288625464, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 133, train_loss = 1.470463023870252, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 134, train_loss = 1.4652862151851878, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 135, train_loss = 1.4601440044352785, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 136, train_loss = 1.455526027828455, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 137, train_loss = 1.4509094171226025, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 138, train_loss = 1.4462844269583002, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 139, train_loss = 1.4415849037468433, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 140, train_loss = 1.4368799614021555, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 141, train_loss = 1.4326716922223568, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 142, train_loss = 1.4276457814266905, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 143, train_loss = 1.4231845898320898, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 144, train_loss = 1.4192398661980405, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 145, train_loss = 1.414896097034216, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 146, train_loss = 1.4106894793221727, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 147, train_loss = 1.4066680260002613, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 148, train_loss = 1.4025000283727422, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 149, train_loss = 1.398763862787746, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 150, train_loss = 1.394769104779698, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 151, train_loss = 1.390905705629848, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 152, train_loss = 1.3872278617927805, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 153, train_loss = 1.3834039295325056, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 154, train_loss = 1.3792397925863042, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 155, train_loss = 1.3756636691978201, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 156, train_loss = 1.3720793587854132, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 157, train_loss = 1.3678755002329126, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 158, train_loss = 1.3635796966264024, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 159, train_loss = 1.3600890872767195, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 160, train_loss = 1.356247752904892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 161, train_loss = 1.3526981882750988, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 162, train_loss = 1.3493755161762238, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 163, train_loss = 1.345855121850036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 164, train_loss = 1.342502267449163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 165, train_loss = 1.3393666818737984, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 166, train_loss = 1.3359414810547605, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 167, train_loss = 1.3324977731099352, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 168, train_loss = 1.329769759089686, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 169, train_loss = 1.3261657344410196, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 170, train_loss = 1.3234863268444315, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 171, train_loss = 1.3204040825366974, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 172, train_loss = 1.317288488149643, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 173, train_loss = 1.3143320927629247, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 174, train_loss = 1.311552649945952, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 175, train_loss = 1.308529960573651, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 176, train_loss = 1.3058422692120075, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 177, train_loss = 1.3026726866373792, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 178, train_loss = 1.3000422479817644, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 179, train_loss = 1.2970494031906128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 180, train_loss = 1.2945834385463968, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 181, train_loss = 1.2916505659231916, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 182, train_loss = 1.2888971716165543, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 183, train_loss = 1.2862194379558787, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 184, train_loss = 1.2835004118969664, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 185, train_loss = 1.2812080482253805, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 186, train_loss = 1.2783872248837724, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 187, train_loss = 1.2757399393012747, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 188, train_loss = 1.2731545977294445, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 189, train_loss = 1.2704383929958567, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 190, train_loss = 1.2681618332862854, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 191, train_loss = 1.2653815584490076, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 192, train_loss = 1.2632311409106478, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 193, train_loss = 1.260904406546615, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 194, train_loss = 1.258335599093698, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 195, train_loss = 1.2559605041751638, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 196, train_loss = 1.2540944876964204, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 197, train_loss = 1.2510811586980708, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 198, train_loss = 1.2490136151318438, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 199, train_loss = 1.246751929342281, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 200, train_loss = 1.2441981782321818, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 201, train_loss = 1.2422052646870725, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 202, train_loss = 1.2401256623561494, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 203, train_loss = 1.2378704721922986, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 204, train_loss = 1.2353703143890016, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 205, train_loss = 1.2334744122927077, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 206, train_loss = 1.231155876070261, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 207, train_loss = 1.2288728554849513, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 208, train_loss = 1.2269473746418953, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 209, train_loss = 1.2248057089745998, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 210, train_loss = 1.2228314590756781, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 211, train_loss = 1.2210935478215106, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 212, train_loss = 1.2186817154288292, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 213, train_loss = 1.2169648061390035, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 214, train_loss = 1.2150807504658587, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 215, train_loss = 1.2132526536588557, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 216, train_loss = 1.2109045597608201, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 217, train_loss = 1.209322330832947, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 218, train_loss = 1.2073195328121074, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 219, train_loss = 1.2052533378009684, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 220, train_loss = 1.2038893451099284, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 221, train_loss = 1.2017244175076485, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 222, train_loss = 1.200117965519894, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 223, train_loss = 1.197873741388321, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 224, train_loss = 1.1962525111739524, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 225, train_loss = 1.1945117476279847, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 226, train_loss = 1.1927184350788593, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 227, train_loss = 1.190997822850477, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 228, train_loss = 1.1891527324914932, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 229, train_loss = 1.1876343240146525, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 230, train_loss = 1.1860652292962186, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 231, train_loss = 1.1840513820643537, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 232, train_loss = 1.1822330318391323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 233, train_loss = 1.1806274677510373, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 234, train_loss = 1.1791801303625107, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 235, train_loss = 1.177494992793072, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 236, train_loss = 1.1757598879630677, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 237, train_loss = 1.1745036740903743, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 238, train_loss = 1.1726813837885857, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 239, train_loss = 1.1708948512678035, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 240, train_loss = 1.169506661593914, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 241, train_loss = 1.1677486362750642, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 242, train_loss = 1.1664459320600145, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 243, train_loss = 1.1647080754046328, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 244, train_loss = 1.1631779409945011, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 245, train_loss = 1.1618860463495366, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 246, train_loss = 1.1603343437309377, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 247, train_loss = 1.1587688997387886, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 248, train_loss = 1.1573855479364283, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 249, train_loss = 1.1556807197630405, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 250, train_loss = 1.1543787035043351, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 251, train_loss = 1.152771171182394, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 252, train_loss = 1.1513757060165517, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 253, train_loss = 1.1498976697330363, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 254, train_loss = 1.1484744722838514, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 255, train_loss = 1.146985745697748, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 256, train_loss = 1.1459225304424763, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 257, train_loss = 1.144497228146065, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 258, train_loss = 1.1427485533058643, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 259, train_loss = 1.1416770194773562, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 260, train_loss = 1.140195508778561, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 261, train_loss = 1.1389746989007108, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 262, train_loss = 1.1379547268152237, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 263, train_loss = 1.1360857498948462, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 264, train_loss = 1.1350686326622963, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 265, train_loss = 1.1337647338514216, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 266, train_loss = 1.1324508811230771, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 267, train_loss = 1.1313769780099392, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 268, train_loss = 1.1294843728537671, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 269, train_loss = 1.1283690159325488, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 270, train_loss = 1.127351349859964, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 271, train_loss = 1.1259037790005095, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 272, train_loss = 1.1248672070796601, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 273, train_loss = 1.1236254933173768, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 274, train_loss = 1.1225725635886192, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 275, train_loss = 1.1210989480023272, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 276, train_loss = 1.119934592396021, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 277, train_loss = 1.1185387658770196, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 278, train_loss = 1.1174790362711065, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 279, train_loss = 1.1165062611107714, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 280, train_loss = 1.1152050718665123, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 281, train_loss = 1.1136075357790105, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 282, train_loss = 1.112863762944471, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 283, train_loss = 1.1118211547727697, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 284, train_loss = 1.1105881271068938, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 285, train_loss = 1.10913646715926, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 286, train_loss = 1.1082090238924138, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 287, train_loss = 1.107029611885082, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 288, train_loss = 1.105614858388435, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 289, train_loss = 1.1053207591176033, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 290, train_loss = 1.1036610677838326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 291, train_loss = 1.1025897115468979, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 292, train_loss = 1.101468951732386, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 293, train_loss = 1.1001742866938002, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 294, train_loss = 1.0994886097614653, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 295, train_loss = 1.0980615317821503, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 296, train_loss = 1.0970965710585006, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 297, train_loss = 1.0961088587646373, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 298, train_loss = 1.0951191646163352, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 299, train_loss = 1.0936464977567084, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 300, train_loss = 1.0929687495226972, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 301, train_loss = 1.091763490170706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 302, train_loss = 1.0905188855831511, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 303, train_loss = 1.089861763000954, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 304, train_loss = 1.0885352715849876, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 305, train_loss = 1.0877625520224683, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 306, train_loss = 1.0868031196296215, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 307, train_loss = 1.085639291733969, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 308, train_loss = 1.0844271928071976, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 309, train_loss = 1.0835660646553151, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 310, train_loss = 1.0826555850799195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 311, train_loss = 1.0819857766036876, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 312, train_loss = 1.0807822706992738, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 313, train_loss = 1.0797202314133756, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 314, train_loss = 1.0789613189990632, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 315, train_loss = 1.0775778703391552, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 316, train_loss = 1.0768215283751488, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 317, train_loss = 1.0759774980251677, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 318, train_loss = 1.0747976576094516, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 319, train_loss = 1.074318878352642, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 320, train_loss = 1.0731869476730935, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 321, train_loss = 1.0722458027303219, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 322, train_loss = 1.0710813328623772, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 323, train_loss = 1.0704051814973354, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 324, train_loss = 1.0693276238744147, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 325, train_loss = 1.0683007438783534, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 326, train_loss = 1.0675219197873957, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 327, train_loss = 1.0665954264695756, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 328, train_loss = 1.065706267952919, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 329, train_loss = 1.0650693413917907, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 330, train_loss = 1.0639494161005132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 331, train_loss = 1.0628434630925767, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 332, train_loss = 1.0620151248876937, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 333, train_loss = 1.0612759900395758, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 334, train_loss = 1.0606185607612133, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 335, train_loss = 1.0594773491029628, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 336, train_loss = 1.0586779229342937, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 337, train_loss = 1.057923446118366, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 338, train_loss = 1.0568664533493575, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 339, train_loss = 1.0562053546309471, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 340, train_loss = 1.0553387763502542, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 341, train_loss = 1.0544776171445847, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 342, train_loss = 1.0535175229015294, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 343, train_loss = 1.0529094288649503, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 344, train_loss = 1.0521067778172437, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 345, train_loss = 1.0511718566122, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 346, train_loss = 1.0502846067247447, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 347, train_loss = 1.0495947611925658, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 348, train_loss = 1.048700723797083, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 349, train_loss = 1.0478183378872927, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 350, train_loss = 1.0469347325561102, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 351, train_loss = 1.0465099873545114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 352, train_loss = 1.0455091732146684, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 353, train_loss = 1.0446079348621424, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 354, train_loss = 1.0441626186075155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 355, train_loss = 1.0431346309778746, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 356, train_loss = 1.0421480710210744, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 357, train_loss = 1.0417977670731489, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 358, train_loss = 1.040860636770958, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 359, train_loss = 1.040123829006916, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 360, train_loss = 1.0391826406121254, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 361, train_loss = 1.0386310977337416, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 362, train_loss = 1.0378826508822385, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 363, train_loss = 1.0370826870203018, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 364, train_loss = 1.0364558386208955, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 365, train_loss = 1.0354534089565277, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 366, train_loss = 1.0348566100001335, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 367, train_loss = 1.0340174374578055, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 368, train_loss = 1.0333086053433362, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 369, train_loss = 1.0327773193421308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 370, train_loss = 1.0318776816129684, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 371, train_loss = 1.0310411068203393, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 372, train_loss = 1.0305187044141348, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 373, train_loss = 1.029852064937586, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 374, train_loss = 1.029118369013304, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 375, train_loss = 1.0283752692339476, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 376, train_loss = 1.027623234927887, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 377, train_loss = 1.0268420167267323, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 378, train_loss = 1.0262422263622284, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 379, train_loss = 1.0257653383014258, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 380, train_loss = 1.0248918558063451, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 381, train_loss = 1.0242040790617466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 382, train_loss = 1.0232014978828374, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 383, train_loss = 1.0230658377113286, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 384, train_loss = 1.0221297442913055, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 385, train_loss = 1.0216828038392123, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 386, train_loss = 1.0207609372737352, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 387, train_loss = 1.0200112188758794, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 388, train_loss = 1.0195137610135134, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 389, train_loss = 1.0185746923089027, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 390, train_loss = 1.018057033419609, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 391, train_loss = 1.017603687942028, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 392, train_loss = 1.0167928449809551, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 393, train_loss = 1.0162945799529552, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 394, train_loss = 1.0152463354170322, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 395, train_loss = 1.0145842047932092, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 396, train_loss = 1.0145264888706151, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 397, train_loss = 1.0137062979338225, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 398, train_loss = 1.0129097451863345, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 399, train_loss = 1.0121717639267445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 400, train_loss = 1.011589696019655, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 401, train_loss = 1.0110021221044008, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 402, train_loss = 1.0103390216827393, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 403, train_loss = 1.009610902518034, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 404, train_loss = 1.0087465842661913, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 405, train_loss = 1.0084193559887353, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 406, train_loss = 1.007798689097399, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 407, train_loss = 1.0069610364735126, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 408, train_loss = 1.0063472750189248, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 409, train_loss = 1.0058029840292875, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 410, train_loss = 1.0055760828254279, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 411, train_loss = 1.004615164041752, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 412, train_loss = 1.0041670004429761, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 413, train_loss = 1.0038313902914524, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 414, train_loss = 1.0028704913856927, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 415, train_loss = 1.0023900369706098, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 416, train_loss = 1.0016391277313232, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 417, train_loss = 1.0011863795516547, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 418, train_loss = 1.0005906572041567, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 419, train_loss = 0.9998792298138142, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 420, train_loss = 0.9993046683666762, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 421, train_loss = 0.9989646884205285, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 422, train_loss = 0.9981566593050957, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 423, train_loss = 0.9978344589471817, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 424, train_loss = 0.9970672441122588, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 425, train_loss = 0.9965977159736212, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 426, train_loss = 0.9959094673395157, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 427, train_loss = 0.9954626324179117, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 428, train_loss = 0.9947314796445426, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 429, train_loss = 0.9939682433905546, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 430, train_loss = 0.9937820533814374, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 431, train_loss = 0.9931034681794699, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 432, train_loss = 0.9926215310988482, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 433, train_loss = 0.9918358797731344, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 434, train_loss = 0.9914338005182799, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 435, train_loss = 0.990728922188282, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 436, train_loss = 0.9903682768344879, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 437, train_loss = 0.9893757166864816, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 438, train_loss = 0.9891439229249954, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 439, train_loss = 0.9882019174692687, train_acc = 0.9977876106194691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 440, train_loss = 0.9878347578051034, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 441, train_loss = 0.9875482705829199, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 442, train_loss = 0.9867951845226344, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 443, train_loss = 0.9862753910419997, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 444, train_loss = 0.9856714618799742, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 445, train_loss = 0.9852723181247711, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 446, train_loss = 0.9848325637576636, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 447, train_loss = 0.9841130264103413, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 448, train_loss = 0.9834767232241575, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 449, train_loss = 0.9830537115631159, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 450, train_loss = 0.9826684941945132, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 451, train_loss = 0.9818598652782384, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 452, train_loss = 0.981377766787773, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 453, train_loss = 0.9809761593642179, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 454, train_loss = 0.9804369819757994, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 455, train_loss = 0.9797508219780866, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 456, train_loss = 0.97944556424045, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 457, train_loss = 0.9786856050195638, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 458, train_loss = 0.9785934587416705, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 459, train_loss = 0.9778893242182676, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 460, train_loss = 0.977512421697611, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 461, train_loss = 0.9766998080012854, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 462, train_loss = 0.9763935506343842, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 463, train_loss = 0.9760587302444037, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 464, train_loss = 0.9750652661023196, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 465, train_loss = 0.9748438137175981, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 466, train_loss = 0.9743669418094214, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 467, train_loss = 0.9739429528417531, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 468, train_loss = 0.9733068272471428, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 469, train_loss = 0.9731101455690805, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 470, train_loss = 0.9725165789423045, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 471, train_loss = 0.9718202129006386, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 472, train_loss = 0.9716340067388956, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 473, train_loss = 0.9708571657538414, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 474, train_loss = 0.9704374583961908, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 475, train_loss = 0.9701134761271533, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 476, train_loss = 0.9696473082003649, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 477, train_loss = 0.9690490836801473, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 478, train_loss = 0.9685862498881761, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 479, train_loss = 0.9681089222431183, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 480, train_loss = 0.967672628670698, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 481, train_loss = 0.9669366280140821, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 482, train_loss = 0.9667169426975306, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 483, train_loss = 0.9663129150867462, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 484, train_loss = 0.965775266289711, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 485, train_loss = 0.9652785124781076, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 486, train_loss = 0.9646061323583126, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 487, train_loss = 0.9644199137983378, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 488, train_loss = 0.9641231745481491, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 489, train_loss = 0.9635821195843164, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 490, train_loss = 0.9628801196813583, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 491, train_loss = 0.9625060372054577, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 492, train_loss = 0.9622005236742552, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 493, train_loss = 0.9618574976921082, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 494, train_loss = 0.9612785913050175, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 495, train_loss = 0.9610892422497272, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 496, train_loss = 0.9603607691824436, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 497, train_loss = 0.9599495728907641, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 498, train_loss = 0.9596318788826466, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 499, train_loss = 0.9590894120337907, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████                     | 21/30 [3:29:41<1:30:07, 600.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "22th- epoch: 0, train_loss = 150.62694111466408, train_acc = 0.7406846762925011\n",
      "test Acc 0.8524208566108007:\n",
      "22th- epoch: 1, train_loss = 52.46190697699785, train_acc = 0.8891476478807638\n",
      "test Acc 0.9008379888268156:\n",
      "22th- epoch: 2, train_loss = 37.91224742680788, train_acc = 0.9211690731252911\n",
      "test Acc 0.9185288640595903:\n",
      "22th- epoch: 3, train_loss = 30.38081346079707, train_acc = 0.9382859804378202\n",
      "test Acc 0.930633147113594:\n",
      "22th- epoch: 4, train_loss = 25.520402040332556, train_acc = 0.9474848625989754\n",
      "test Acc 0.9338919925512105:\n",
      "22th- epoch: 5, train_loss = 22.053122183308005, train_acc = 0.9542384722869119\n",
      "test Acc 0.9394785847299814:\n",
      "22th- epoch: 6, train_loss = 19.39405592903495, train_acc = 0.9611085235211924\n",
      "test Acc 0.9487895716945997:\n",
      "22th- epoch: 7, train_loss = 17.263946333900094, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 8, train_loss = 15.537307126447558, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "22th- epoch: 9, train_loss = 14.103024708107114, train_acc = 0.9711224965067536\n",
      "test Acc 0.9529795158286778:\n",
      "22th- epoch: 10, train_loss = 12.90254070982337, train_acc = 0.9738006520726595\n",
      "test Acc 0.9539106145251397:\n",
      "22th- epoch: 11, train_loss = 11.874766159802675, train_acc = 0.976245924545878\n",
      "test Acc 0.9543761638733705:\n",
      "22th- epoch: 12, train_loss = 10.997407831251621, train_acc = 0.9785747554727526\n",
      "test Acc 0.9562383612662942:\n",
      "22th- epoch: 13, train_loss = 10.230778228491545, train_acc = 0.9810200279459711\n",
      "test Acc 0.9562383612662942:\n",
      "22th- epoch: 14, train_loss = 9.562322155572474, train_acc = 0.9826502095947834\n",
      "test Acc 0.9581005586592178:\n",
      "22th- epoch: 15, train_loss = 8.97216899972409, train_acc = 0.983698183511877\n",
      "test Acc 0.9581005586592178:\n",
      "22th- epoch: 16, train_loss = 8.449747127480805, train_acc = 0.9850954820680019\n",
      "test Acc 0.9585661080074488:\n",
      "22th- epoch: 17, train_loss = 7.981333329342306, train_acc = 0.9861434559850955\n",
      "test Acc 0.9594972067039106:\n",
      "22th- epoch: 18, train_loss = 7.56165565084666, train_acc = 0.9876571960875641\n",
      "test Acc 0.9599627560521415:\n",
      "22th- epoch: 19, train_loss = 7.180869858711958, train_acc = 0.9881229622729389\n",
      "test Acc 0.9604283054003724:\n",
      "22th- epoch: 20, train_loss = 6.8367591463029385, train_acc = 0.9884722869119702\n",
      "test Acc 0.9608938547486033:\n",
      "22th- epoch: 21, train_loss = 6.525024705566466, train_acc = 0.989869585468095\n",
      "test Acc 0.9613594040968343:\n",
      "22th- epoch: 22, train_loss = 6.242330935783684, train_acc = 0.9904517931998137\n",
      "test Acc 0.9618249534450651:\n",
      "22th- epoch: 23, train_loss = 5.9836049331352115, train_acc = 0.9909175593851887\n",
      "test Acc 0.9622905027932961:\n",
      "22th- epoch: 24, train_loss = 5.746491901576519, train_acc = 0.9914997671169073\n",
      "test Acc 0.962756052141527:\n",
      "22th- epoch: 25, train_loss = 5.534183654002845, train_acc = 0.9917326502095948\n",
      "test Acc 0.9632216014897579:\n",
      "22th- epoch: 26, train_loss = 5.337013988755643, train_acc = 0.9918490917559385\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 27, train_loss = 5.153797049075365, train_acc = 0.9923148579413135\n",
      "test Acc 0.9646182495344506:\n",
      "22th- epoch: 28, train_loss = 4.985405083745718, train_acc = 0.9931299487657196\n",
      "test Acc 0.9650837988826816:\n",
      "22th- epoch: 29, train_loss = 4.83061237167567, train_acc = 0.9933628318584071\n",
      "test Acc 0.9650837988826816:\n",
      "22th- epoch: 30, train_loss = 4.684881110675633, train_acc = 0.9935957149510946\n",
      "test Acc 0.9660148975791434:\n",
      "22th- epoch: 31, train_loss = 4.549341536127031, train_acc = 0.9940614811364695\n",
      "test Acc 0.9660148975791434:\n",
      "22th- epoch: 32, train_loss = 4.421657630242407, train_acc = 0.9940614811364695\n",
      "test Acc 0.9660148975791434:\n",
      "22th- epoch: 33, train_loss = 4.302204749546945, train_acc = 0.9940614811364695\n",
      "test Acc 0.9660148975791434:\n",
      "22th- epoch: 34, train_loss = 4.1900238851085305, train_acc = 0.9941779226828132\n",
      "test Acc 0.9660148975791434:\n",
      "22th- epoch: 35, train_loss = 4.085627055726945, train_acc = 0.994294364229157\n",
      "test Acc 0.9660148975791434:\n",
      "22th- epoch: 36, train_loss = 3.9874636055901647, train_acc = 0.9944108057755007\n",
      "test Acc 0.9660148975791434:\n",
      "22th- epoch: 37, train_loss = 3.8943060087040067, train_acc = 0.9946436888681882\n",
      "test Acc 0.9660148975791434:\n",
      "22th- epoch: 38, train_loss = 3.807741826400161, train_acc = 0.9946436888681882\n",
      "test Acc 0.9655493482309124:\n",
      "22th- epoch: 39, train_loss = 3.7262928104028106, train_acc = 0.9946436888681882\n",
      "test Acc 0.9655493482309124:\n",
      "22th- epoch: 40, train_loss = 3.6490596709772944, train_acc = 0.9948765719608756\n",
      "test Acc 0.9669459962756052:\n",
      "22th- epoch: 41, train_loss = 3.575514793395996, train_acc = 0.9949930135072194\n",
      "test Acc 0.9664804469273743:\n",
      "22th- epoch: 42, train_loss = 3.506014266051352, train_acc = 0.9949930135072194\n",
      "test Acc 0.9669459962756052:\n",
      "22th- epoch: 43, train_loss = 3.437945954501629, train_acc = 0.9949930135072194\n",
      "test Acc 0.9669459962756052:\n",
      "22th- epoch: 44, train_loss = 3.3758382415398955, train_acc = 0.9951094550535631\n",
      "test Acc 0.9669459962756052:\n",
      "22th- epoch: 45, train_loss = 3.315381477586925, train_acc = 0.9951094550535631\n",
      "test Acc 0.9669459962756052:\n",
      "22th- epoch: 46, train_loss = 3.2572200023569167, train_acc = 0.9953423381462506\n",
      "test Acc 0.9669459962756052:\n",
      "22th- epoch: 47, train_loss = 3.2014203243888915, train_acc = 0.9954587796925943\n",
      "test Acc 0.9674115456238361:\n",
      "22th- epoch: 48, train_loss = 3.1489877910353243, train_acc = 0.995575221238938\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 49, train_loss = 3.096240106970072, train_acc = 0.995575221238938\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 50, train_loss = 3.0484122396446764, train_acc = 0.995575221238938\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 51, train_loss = 3.000664679799229, train_acc = 0.995575221238938\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 52, train_loss = 2.9536412321031094, train_acc = 0.995575221238938\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 53, train_loss = 2.911547361407429, train_acc = 0.995575221238938\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 54, train_loss = 2.8696415089070797, train_acc = 0.9956916627852818\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 55, train_loss = 2.828639832790941, train_acc = 0.9959245458779693\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 56, train_loss = 2.7902839183807373, train_acc = 0.9959245458779693\n",
      "test Acc 0.9669459962756052:\n",
      "22th- epoch: 57, train_loss = 2.7530075409449637, train_acc = 0.9959245458779693\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 58, train_loss = 2.7170393033884466, train_acc = 0.9959245458779693\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 59, train_loss = 2.6825537122786045, train_acc = 0.9959245458779693\n",
      "test Acc 0.9688081936685289:\n",
      "22th- epoch: 60, train_loss = 2.648908670991659, train_acc = 0.996040987424313\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 61, train_loss = 2.6163665489293635, train_acc = 0.996040987424313\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 62, train_loss = 2.58482958143577, train_acc = 0.9963903120633442\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 63, train_loss = 2.553998616989702, train_acc = 0.9963903120633442\n",
      "test Acc 0.9702048417132216:\n",
      "22th- epoch: 64, train_loss = 2.5260716476477683, train_acc = 0.9963903120633442\n",
      "test Acc 0.9702048417132216:\n",
      "22th- epoch: 65, train_loss = 2.4964282154105604, train_acc = 0.9963903120633442\n",
      "test Acc 0.9702048417132216:\n",
      "22th- epoch: 66, train_loss = 2.4685089834965765, train_acc = 0.9963903120633442\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 67, train_loss = 2.4425662606954575, train_acc = 0.9963903120633442\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 68, train_loss = 2.4160830504260957, train_acc = 0.9963903120633442\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 69, train_loss = 2.3904515020549297, train_acc = 0.9963903120633442\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 70, train_loss = 2.3650499298237264, train_acc = 0.996506753609688\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 71, train_loss = 2.340495622251183, train_acc = 0.996506753609688\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 72, train_loss = 2.3172804675996304, train_acc = 0.996506753609688\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 73, train_loss = 2.2945566908456385, train_acc = 0.996506753609688\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 74, train_loss = 2.2727588252164423, train_acc = 0.996506753609688\n",
      "test Acc 0.9697392923649907:\n",
      "22th- epoch: 75, train_loss = 2.25209171557799, train_acc = 0.996506753609688\n",
      "test Acc 0.9702048417132216:\n",
      "22th- epoch: 76, train_loss = 2.2302704812027514, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "22th- epoch: 77, train_loss = 2.210459142923355, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "22th- epoch: 78, train_loss = 2.1913564652204514, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "22th- epoch: 79, train_loss = 2.1719603524543345, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "22th- epoch: 80, train_loss = 2.153382861521095, train_acc = 0.9966231951560317\n",
      "test Acc 0.9706703910614525:\n",
      "22th- epoch: 81, train_loss = 2.135248841252178, train_acc = 0.9966231951560317\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 82, train_loss = 2.117307798471302, train_acc = 0.9966231951560317\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 83, train_loss = 2.1006124205887318, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 84, train_loss = 2.0838008509017527, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 85, train_loss = 2.0680690756998956, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 86, train_loss = 2.0519616554956883, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 87, train_loss = 2.0364016194362193, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 88, train_loss = 2.0215937334578484, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 89, train_loss = 2.0076235632877797, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 90, train_loss = 1.9933902733027935, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 91, train_loss = 1.979381627170369, train_acc = 0.9968560782487191\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 92, train_loss = 1.9658505965489894, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 93, train_loss = 1.9526792604010552, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 94, train_loss = 1.939715524436906, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 95, train_loss = 1.9263789232354611, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 96, train_loss = 1.9149084177333862, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 97, train_loss = 1.9021794970612973, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 98, train_loss = 1.890573886455968, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 99, train_loss = 1.8793278199154884, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 100, train_loss = 1.8677924510557204, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 101, train_loss = 1.8565764960367233, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 102, train_loss = 1.845541812479496, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 103, train_loss = 1.8355772260110825, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 104, train_loss = 1.8246833521407098, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 105, train_loss = 1.8143740694504231, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 106, train_loss = 1.8042451229412109, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 107, train_loss = 1.7938366532325745, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 108, train_loss = 1.7844680424313992, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 109, train_loss = 1.7756912522017956, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 110, train_loss = 1.7657137315254658, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 111, train_loss = 1.756782540353015, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 112, train_loss = 1.7480313777923584, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 113, train_loss = 1.7391364958602935, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 114, train_loss = 1.73108621686697, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 115, train_loss = 1.7219798751175404, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 116, train_loss = 1.7140818100888282, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 117, train_loss = 1.7059439558070153, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 118, train_loss = 1.697715363232419, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 119, train_loss = 1.6901379760820419, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 120, train_loss = 1.6824231569189578, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 121, train_loss = 1.674527384340763, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 122, train_loss = 1.6680431093554944, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 123, train_loss = 1.6598919481039047, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 124, train_loss = 1.6528470888733864, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 125, train_loss = 1.6458147130906582, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 126, train_loss = 1.638463981449604, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 127, train_loss = 1.6324715565424412, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 128, train_loss = 1.6250105053186417, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 129, train_loss = 1.6184889066498727, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 130, train_loss = 1.6118302333634347, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 131, train_loss = 1.6055978473741561, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 132, train_loss = 1.5992446031887084, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 133, train_loss = 1.593240560265258, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 134, train_loss = 1.5870903718750924, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 135, train_loss = 1.5809996090829372, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 136, train_loss = 1.5751792751252651, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 137, train_loss = 1.568870977847837, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 138, train_loss = 1.563442518352531, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 139, train_loss = 1.5573994008591399, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 140, train_loss = 1.5519037122139707, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 141, train_loss = 1.5464551051845774, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 142, train_loss = 1.5405177077045664, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 143, train_loss = 1.535425559966825, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 144, train_loss = 1.5299510260811076, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 145, train_loss = 1.5245683888206258, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 146, train_loss = 1.5194985704729334, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 147, train_loss = 1.513648796826601, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 148, train_loss = 1.5088731398573145, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 149, train_loss = 1.5036072445800528, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 150, train_loss = 1.4990628212690353, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 151, train_loss = 1.493479692726396, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 152, train_loss = 1.4886840233812109, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 153, train_loss = 1.4842254346003756, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 154, train_loss = 1.4800548540661111, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 155, train_loss = 1.4743788490304723, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 156, train_loss = 1.4705792492022738, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 157, train_loss = 1.4651850076625124, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 158, train_loss = 1.4614977476885542, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 159, train_loss = 1.4565692568430677, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 160, train_loss = 1.4522398622939363, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 161, train_loss = 1.4482772623887286, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 162, train_loss = 1.4435525089502335, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 163, train_loss = 1.4395054368069395, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 164, train_loss = 1.4358188224723563, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 165, train_loss = 1.4315182268619537, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 166, train_loss = 1.427566776634194, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 167, train_loss = 1.4236784353852272, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 168, train_loss = 1.419324720860459, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 169, train_loss = 1.4161132723093033, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 170, train_loss = 1.412073340266943, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 171, train_loss = 1.4082863355288282, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 172, train_loss = 1.404572680592537, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 173, train_loss = 1.4009962728014216, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 174, train_loss = 1.3973605720093474, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 175, train_loss = 1.393849095911719, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 176, train_loss = 1.389787053107284, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 177, train_loss = 1.3859258020529523, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 178, train_loss = 1.382927030324936, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 179, train_loss = 1.379244347452186, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 180, train_loss = 1.3761297451565042, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 181, train_loss = 1.3727321984479204, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 182, train_loss = 1.369238412589766, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 183, train_loss = 1.3658143766224384, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 184, train_loss = 1.3628223104169592, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 185, train_loss = 1.359503474086523, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 186, train_loss = 1.3565037486841902, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 187, train_loss = 1.3528622053563595, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 188, train_loss = 1.3500206619501114, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 189, train_loss = 1.347295722574927, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 190, train_loss = 1.3438536463072523, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 191, train_loss = 1.3407636458287016, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 192, train_loss = 1.3378913514316082, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 193, train_loss = 1.3348471820354462, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 194, train_loss = 1.3316316083073616, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 195, train_loss = 1.3288289308547974, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 196, train_loss = 1.3258913060417399, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 197, train_loss = 1.323179124505259, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 198, train_loss = 1.3202106058597565, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 199, train_loss = 1.3176640731981024, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 200, train_loss = 1.3145110023906454, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 201, train_loss = 1.3116933716228232, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 202, train_loss = 1.3097791163017973, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 203, train_loss = 1.306130419136025, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 204, train_loss = 1.303818542510271, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 205, train_loss = 1.3008382780244574, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 206, train_loss = 1.2983870530733839, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 207, train_loss = 1.2956674955785275, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 208, train_loss = 1.2928669018438086, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 209, train_loss = 1.2901730636367574, train_acc = 0.9973218444340941\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 210, train_loss = 1.288321772008203, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 211, train_loss = 1.2852905379841104, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 212, train_loss = 1.2831901783356443, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 213, train_loss = 1.2803577756276354, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 214, train_loss = 1.2779176732292399, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 215, train_loss = 1.2752615275094286, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 216, train_loss = 1.2728915611514822, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 217, train_loss = 1.2707450104644522, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 218, train_loss = 1.2685044072568417, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 219, train_loss = 1.2660172519972548, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 220, train_loss = 1.2636433305451646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 221, train_loss = 1.2614681435516104, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 222, train_loss = 1.2592854909598827, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 223, train_loss = 1.2566278589656577, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 224, train_loss = 1.2547774612903595, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 225, train_loss = 1.2523074373602867, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 226, train_loss = 1.250249853997957, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 227, train_loss = 1.2478978845174424, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 228, train_loss = 1.2458368104998954, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 229, train_loss = 1.2439258980448358, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 230, train_loss = 1.241365787864197, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 231, train_loss = 1.2397221227292903, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 232, train_loss = 1.2369264028966427, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 233, train_loss = 1.2348960898816586, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 234, train_loss = 1.2332181234960444, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 235, train_loss = 1.2307941640610807, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 236, train_loss = 1.2290191215579398, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 237, train_loss = 1.226890015124809, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 238, train_loss = 1.2250259543652646, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 239, train_loss = 1.2225964863901027, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 240, train_loss = 1.2205220299656503, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 241, train_loss = 1.2187057311530225, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 242, train_loss = 1.2168274124269374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 243, train_loss = 1.2148714872892015, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 244, train_loss = 1.2133666587178595, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 245, train_loss = 1.2107743595843203, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 246, train_loss = 1.2088214655523188, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 247, train_loss = 1.2074353520874865, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 248, train_loss = 1.2051266953349113, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 249, train_loss = 1.2033301095361821, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 250, train_loss = 1.2015670264954679, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 251, train_loss = 1.1995869179372676, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 252, train_loss = 1.1978414480690844, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 253, train_loss = 1.1960151021485217, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 254, train_loss = 1.1941249680821784, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 255, train_loss = 1.1922571125323884, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 256, train_loss = 1.1905974435503595, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 257, train_loss = 1.1885685734450817, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 258, train_loss = 1.187419316440355, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 259, train_loss = 1.1849844977259636, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 260, train_loss = 1.1833995841443539, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 261, train_loss = 1.1819188657100312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 262, train_loss = 1.1800082151894458, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 263, train_loss = 1.1781508413259871, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 264, train_loss = 1.1767961059813388, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 265, train_loss = 1.1748855362529866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 266, train_loss = 1.1730535539682023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 267, train_loss = 1.1714414954185486, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 268, train_loss = 1.1694424636662006, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 269, train_loss = 1.1682921250467189, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 270, train_loss = 1.1664242595434189, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 271, train_loss = 1.164451751857996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 272, train_loss = 1.1633402854204178, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 273, train_loss = 1.161181511997711, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 274, train_loss = 1.1607182125444524, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 275, train_loss = 1.1585193636710756, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 276, train_loss = 1.1566356954281218, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 277, train_loss = 1.1557449586689472, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 278, train_loss = 1.1533763694460504, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 279, train_loss = 1.152883296192158, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 280, train_loss = 1.1506612760131247, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 281, train_loss = 1.1492885202169418, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 282, train_loss = 1.147961714596022, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 283, train_loss = 1.1464809849858284, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 284, train_loss = 1.1452954187989235, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 285, train_loss = 1.1435008347034454, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 286, train_loss = 1.142586408823263, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 287, train_loss = 1.1408159385318868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 288, train_loss = 1.1394651370937936, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 289, train_loss = 1.138058952987194, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 290, train_loss = 1.1364553198218346, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 291, train_loss = 1.1350460176472552, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 292, train_loss = 1.1343991582398303, train_acc = 0.9975547275267815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 293, train_loss = 1.1322847467963584, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 294, train_loss = 1.1309599938686006, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 295, train_loss = 1.1296901665627956, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 296, train_loss = 1.1285665680770762, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 297, train_loss = 1.1273659753496759, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 298, train_loss = 1.1258088573813438, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 299, train_loss = 1.12455677613616, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 300, train_loss = 1.1236757089500315, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 301, train_loss = 1.1222174664144404, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 302, train_loss = 1.1207847681944259, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 303, train_loss = 1.1197346498374827, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 304, train_loss = 1.1181182749569416, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 305, train_loss = 1.1172120806877501, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 306, train_loss = 1.1157254402642138, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 307, train_loss = 1.1145827012951486, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 308, train_loss = 1.1131781488656998, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 309, train_loss = 1.111463986337185, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 310, train_loss = 1.1109056982095353, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 311, train_loss = 1.1096575111150742, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 312, train_loss = 1.1082825747434981, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 313, train_loss = 1.1076129016582854, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 314, train_loss = 1.1060633075539954, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 315, train_loss = 1.1051363845472224, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 316, train_loss = 1.1035659213666804, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 317, train_loss = 1.1027238853275776, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 318, train_loss = 1.10134456056403, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 319, train_loss = 1.1004048461909406, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 320, train_loss = 1.0993777140974998, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 321, train_loss = 1.0980779863893986, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 322, train_loss = 1.096962671726942, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 323, train_loss = 1.0955373508040793, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 324, train_loss = 1.0950292932684533, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 325, train_loss = 1.0935796213452704, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 326, train_loss = 1.092221466184128, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 327, train_loss = 1.0913684032857418, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 328, train_loss = 1.0901515421574004, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 329, train_loss = 1.089481607079506, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 330, train_loss = 1.0881820085342042, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 331, train_loss = 1.0872107396717183, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 332, train_loss = 1.0858125686645508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 333, train_loss = 1.0853383019566536, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 334, train_loss = 1.0836988054215908, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 335, train_loss = 1.0830564114148729, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 336, train_loss = 1.0815323131973855, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 337, train_loss = 1.0807397874887101, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 338, train_loss = 1.079832264513243, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 339, train_loss = 1.0789402897353284, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 340, train_loss = 1.0779033017461188, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 341, train_loss = 1.07697643089341, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 342, train_loss = 1.0750366635620594, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 343, train_loss = 1.0749345484073274, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 344, train_loss = 1.073960670561064, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 345, train_loss = 1.0724317990243435, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 346, train_loss = 1.0719890135223977, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 347, train_loss = 1.0707502749864943, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 348, train_loss = 1.0696387067437172, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 349, train_loss = 1.0687337132985704, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 350, train_loss = 1.0679081194102764, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 351, train_loss = 1.0670186690986156, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 352, train_loss = 1.0656819033320062, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 353, train_loss = 1.065044179558754, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 354, train_loss = 1.0640296812052839, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 355, train_loss = 1.0633274130523205, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 356, train_loss = 1.0619515664875507, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 357, train_loss = 1.0614068495924585, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 358, train_loss = 1.0603045970201492, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 359, train_loss = 1.0595300334389322, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 360, train_loss = 1.0580851050908677, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 361, train_loss = 1.0573806327884085, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 362, train_loss = 1.0568674591486342, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 363, train_loss = 1.0553312748670578, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 364, train_loss = 1.0549917742609978, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 365, train_loss = 1.0537596779759042, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 366, train_loss = 1.053172028332483, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 367, train_loss = 1.0517280139029026, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 368, train_loss = 1.0512356932158582, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 369, train_loss = 1.0505843932623975, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 370, train_loss = 1.0495148698682897, train_acc = 0.9977876106194691\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 371, train_loss = 1.0483292949502356, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 372, train_loss = 1.0478304873104207, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 373, train_loss = 1.0466529428958893, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 374, train_loss = 1.0458161793649197, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 375, train_loss = 1.0451793832180556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 376, train_loss = 1.0445602970721666, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 377, train_loss = 1.0429387912154198, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 378, train_loss = 1.0428247650561389, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 379, train_loss = 1.0422836653888226, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 380, train_loss = 1.0404791819455568, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 381, train_loss = 1.0404287042620126, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 382, train_loss = 1.0384301195445005, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 383, train_loss = 1.0385294941661414, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 384, train_loss = 1.0374215878546238, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 385, train_loss = 1.0367252677679062, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 386, train_loss = 1.0360824018716812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 387, train_loss = 1.035719638079172, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 388, train_loss = 1.0347169587912504, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 389, train_loss = 1.0340727927687112, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 390, train_loss = 1.0332265732286032, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 391, train_loss = 1.03207846233272, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 392, train_loss = 1.0311880608496722, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 393, train_loss = 1.030728849262232, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 394, train_loss = 1.0292656123638153, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 395, train_loss = 1.0291501320898533, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 396, train_loss = 1.0279445250926074, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 397, train_loss = 1.0273465054633562, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 398, train_loss = 1.0268615720269736, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 399, train_loss = 1.0261154460313264, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 400, train_loss = 1.0257084319891874, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 401, train_loss = 1.0246010857226793, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 402, train_loss = 1.0242700887320098, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 403, train_loss = 1.0232480714621488, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 404, train_loss = 1.0224517211318016, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 405, train_loss = 1.0219851334986743, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 406, train_loss = 1.0212342776358128, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 407, train_loss = 1.0205191162822302, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 408, train_loss = 1.0195911092159804, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 409, train_loss = 1.0181170590221882, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 410, train_loss = 1.0177341500821058, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 411, train_loss = 1.017378063261276, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 412, train_loss = 1.0160683219728526, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 413, train_loss = 1.0161987766623497, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 414, train_loss = 1.0150886414048728, train_acc = 0.9979040521658128\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 415, train_loss = 1.0148861060442869, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 416, train_loss = 1.0138678165676538, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 417, train_loss = 1.01248349994421, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 418, train_loss = 1.0117127808334772, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 419, train_loss = 1.0113867744803429, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 420, train_loss = 1.010148966073757, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 421, train_loss = 1.0106089462933596, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 422, train_loss = 1.009785267204279, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 423, train_loss = 1.0091917676327284, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 424, train_loss = 1.0084824139776174, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 425, train_loss = 1.0079388295707759, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 426, train_loss = 1.006489028543001, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 427, train_loss = 1.0057104105653707, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 428, train_loss = 1.0049937292933464, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 429, train_loss = 1.0050827960076276, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 430, train_loss = 1.0045859180390835, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 431, train_loss = 1.004205266624922, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 432, train_loss = 1.0029665678739548, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 433, train_loss = 1.0021082485618535, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 434, train_loss = 1.000586466252571, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 435, train_loss = 1.0008768364787102, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 436, train_loss = 1.0001549758017063, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 437, train_loss = 0.9994842360320035, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 438, train_loss = 0.9990409451129381, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 439, train_loss = 0.9974725097417831, train_acc = 0.9979040521658128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 440, train_loss = 0.9965743906795979, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 441, train_loss = 0.9971306547522545, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 442, train_loss = 0.9962879208324011, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 443, train_loss = 0.9959526844322681, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 444, train_loss = 0.9949744492769241, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 445, train_loss = 0.9947947511973325, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 446, train_loss = 0.9942580051720142, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 447, train_loss = 0.9931066557765007, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 448, train_loss = 0.9925658864376601, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 449, train_loss = 0.9920222721993923, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 450, train_loss = 0.991368188202614, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 451, train_loss = 0.9906632751226425, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 452, train_loss = 0.9899545013904572, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 453, train_loss = 0.9896323420107365, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 454, train_loss = 0.988798269390827, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 455, train_loss = 0.98830315968371, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 456, train_loss = 0.9874698209168855, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 457, train_loss = 0.9872207219304983, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 458, train_loss = 0.9861514208314475, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 459, train_loss = 0.9861176038684789, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 460, train_loss = 0.9851457377371844, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 461, train_loss = 0.984415457904106, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 462, train_loss = 0.9844477238657419, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 463, train_loss = 0.9834151255490724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 464, train_loss = 0.9828106636705343, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 465, train_loss = 0.9825353758933488, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 466, train_loss = 0.9816863387823105, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 467, train_loss = 0.9812535730598029, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 468, train_loss = 0.980673536658287, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 469, train_loss = 0.9802163988351822, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 470, train_loss = 0.9794982969760895, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 471, train_loss = 0.9788599908351898, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 472, train_loss = 0.9780931398272514, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 473, train_loss = 0.9781048794684466, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 474, train_loss = 0.977101950586075, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 475, train_loss = 0.9765134590270463, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 476, train_loss = 0.9759569428861141, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 477, train_loss = 0.9757761992514133, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 478, train_loss = 0.9755464320478495, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 479, train_loss = 0.9744134818611201, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 480, train_loss = 0.9736959834990557, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 481, train_loss = 0.9733787501754705, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 482, train_loss = 0.9726721445622388, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 483, train_loss = 0.9718725507555064, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 484, train_loss = 0.9716513330640737, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 485, train_loss = 0.970976105571026, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 486, train_loss = 0.9708382984099444, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 487, train_loss = 0.9699102590384427, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 488, train_loss = 0.9693448928592261, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 489, train_loss = 0.9690445798041765, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 490, train_loss = 0.9683655475673731, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 491, train_loss = 0.9678352475166321, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 492, train_loss = 0.9675183532235678, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 493, train_loss = 0.9668876702489797, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 494, train_loss = 0.9663519138994161, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 495, train_loss = 0.9654889516532421, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 496, train_loss = 0.9651187459530775, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 497, train_loss = 0.9647666724922601, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 498, train_loss = 0.9643491928873118, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 499, train_loss = 0.9636490046977997, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████████████████████████████████████████████████▎                  | 22/30 [3:39:41<1:20:06, 600.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "23th- epoch: 0, train_loss = 130.92466051876545, train_acc = 0.7559385188635305\n",
      "test Acc 0.8594040968342644:\n",
      "23th- epoch: 1, train_loss = 52.00387782603502, train_acc = 0.8885654401490451\n",
      "test Acc 0.9120111731843575:\n",
      "23th- epoch: 2, train_loss = 36.46412738785148, train_acc = 0.922100605496041\n",
      "test Acc 0.9301675977653632:\n",
      "23th- epoch: 3, train_loss = 28.844684537500143, train_acc = 0.9406148113646949\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 4, train_loss = 24.081856675446033, train_acc = 0.9517931998136935\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 5, train_loss = 20.70738466270268, train_acc = 0.9583139264089428\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 6, train_loss = 18.169982774183154, train_acc = 0.9640195621797858\n",
      "test Acc 0.9506517690875232:\n",
      "23th- epoch: 7, train_loss = 16.196162143722177, train_acc = 0.9682114578481602\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 8, train_loss = 14.618962926790118, train_acc = 0.9714718211457848\n",
      "test Acc 0.9562383612662942:\n",
      "23th- epoch: 9, train_loss = 13.315055763348937, train_acc = 0.9749650675360969\n",
      "test Acc 0.9567039106145251:\n",
      "23th- epoch: 10, train_loss = 12.201007736846805, train_acc = 0.9776432231020028\n",
      "test Acc 0.957635009310987:\n",
      "23th- epoch: 11, train_loss = 11.24603463895619, train_acc = 0.97973917093619\n",
      "test Acc 0.957635009310987:\n",
      "23th- epoch: 12, train_loss = 10.41636279784143, train_acc = 0.9810200279459711\n",
      "test Acc 0.957635009310987:\n",
      "23th- epoch: 13, train_loss = 9.695562975481153, train_acc = 0.9820680018630648\n",
      "test Acc 0.9594972067039106:\n",
      "23th- epoch: 14, train_loss = 9.069071689620614, train_acc = 0.9831159757801584\n",
      "test Acc 0.9608938547486033:\n",
      "23th- epoch: 15, train_loss = 8.512883566319942, train_acc = 0.9839310666045645\n",
      "test Acc 0.9618249534450651:\n",
      "23th- epoch: 16, train_loss = 8.01540732756257, train_acc = 0.9847461574289706\n",
      "test Acc 0.9622905027932961:\n",
      "23th- epoch: 17, train_loss = 7.566510809585452, train_acc = 0.9861434559850955\n",
      "test Acc 0.962756052141527:\n",
      "23th- epoch: 18, train_loss = 7.162057043984532, train_acc = 0.9867256637168141\n",
      "test Acc 0.9632216014897579:\n",
      "23th- epoch: 19, train_loss = 6.799168724566698, train_acc = 0.9873078714485328\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 20, train_loss = 6.466264117509127, train_acc = 0.9877736376339078\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 21, train_loss = 6.162472716532648, train_acc = 0.9887051700046576\n",
      "test Acc 0.9636871508379888:\n",
      "23th- epoch: 22, train_loss = 5.885918970219791, train_acc = 0.9897531439217513\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 23, train_loss = 5.63013509940356, train_acc = 0.9901024685607824\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 24, train_loss = 5.397655022330582, train_acc = 0.9905682347461574\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 25, train_loss = 5.182690623216331, train_acc = 0.9906846762925011\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 26, train_loss = 4.987381457351148, train_acc = 0.9913833255705635\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 27, train_loss = 4.807579406537116, train_acc = 0.9917326502095948\n",
      "test Acc 0.9650837988826816:\n",
      "23th- epoch: 28, train_loss = 4.641622704453766, train_acc = 0.9926641825803446\n",
      "test Acc 0.9664804469273743:\n",
      "23th- epoch: 29, train_loss = 4.486374889500439, train_acc = 0.9930135072193759\n",
      "test Acc 0.9664804469273743:\n",
      "23th- epoch: 30, train_loss = 4.341029376722872, train_acc = 0.9932463903120633\n",
      "test Acc 0.9674115456238361:\n",
      "23th- epoch: 31, train_loss = 4.2067878022789955, train_acc = 0.9932463903120633\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 32, train_loss = 4.080900392495096, train_acc = 0.9935957149510946\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 33, train_loss = 3.9636324690654874, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 34, train_loss = 3.8520328542217612, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 35, train_loss = 3.7488398365676403, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 36, train_loss = 3.653319467790425, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 37, train_loss = 3.560972176492214, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "23th- epoch: 38, train_loss = 3.4738859720528126, train_acc = 0.9951094550535631\n",
      "test Acc 0.9697392923649907:\n",
      "23th- epoch: 39, train_loss = 3.3931548884138465, train_acc = 0.9951094550535631\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 40, train_loss = 3.3181601567193866, train_acc = 0.9951094550535631\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 41, train_loss = 3.2442510342225432, train_acc = 0.9952258965999069\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 42, train_loss = 3.1751976385712624, train_acc = 0.9953423381462506\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 43, train_loss = 3.1094360454007983, train_acc = 0.995575221238938\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 44, train_loss = 3.0477079888805747, train_acc = 0.995575221238938\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 45, train_loss = 2.988766980357468, train_acc = 0.9959245458779693\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 46, train_loss = 2.933448100928217, train_acc = 0.9958081043316255\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 47, train_loss = 2.879517074674368, train_acc = 0.9959245458779693\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 48, train_loss = 2.8298810883425176, train_acc = 0.9963903120633442\n",
      "test Acc 0.9706703910614525:\n",
      "23th- epoch: 49, train_loss = 2.780605722218752, train_acc = 0.996506753609688\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 50, train_loss = 2.733972041402012, train_acc = 0.9966231951560317\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 51, train_loss = 2.690351026598364, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 52, train_loss = 2.646787405014038, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 53, train_loss = 2.6062255376018584, train_acc = 0.9969725197950629\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 54, train_loss = 2.568223673850298, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "23th- epoch: 55, train_loss = 2.5296302177011967, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "23th- epoch: 56, train_loss = 2.493533158209175, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "23th- epoch: 57, train_loss = 2.4598915986716747, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "23th- epoch: 58, train_loss = 2.4268629774451256, train_acc = 0.9969725197950629\n",
      "test Acc 0.9716014897579144:\n",
      "23th- epoch: 59, train_loss = 2.39541037986055, train_acc = 0.9969725197950629\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 60, train_loss = 2.3647583909332752, train_acc = 0.9969725197950629\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 61, train_loss = 2.3343839882873, train_acc = 0.9969725197950629\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 62, train_loss = 2.30596736818552, train_acc = 0.9969725197950629\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 63, train_loss = 2.2790616005659103, train_acc = 0.9969725197950629\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 64, train_loss = 2.252620683517307, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 65, train_loss = 2.226929454598576, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "23th- epoch: 66, train_loss = 2.2030911608599126, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 67, train_loss = 2.179642067756504, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 68, train_loss = 2.1560903363861144, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 69, train_loss = 2.134537769947201, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 70, train_loss = 2.1135500743985176, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 71, train_loss = 2.093123273458332, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 72, train_loss = 2.0732007189653814, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 73, train_loss = 2.0538202486932278, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 74, train_loss = 2.034800074994564, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 75, train_loss = 2.0169862671755254, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 76, train_loss = 1.9991021216847003, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 77, train_loss = 1.9826841999311, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 78, train_loss = 1.9658308413345367, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 79, train_loss = 1.9495574224274606, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 80, train_loss = 1.9338596612215042, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 81, train_loss = 1.9186118703801185, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 82, train_loss = 1.9044668029528111, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 83, train_loss = 1.8893996339756995, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 84, train_loss = 1.875459599075839, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 85, train_loss = 1.8623184661846608, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 86, train_loss = 1.8485959072131664, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 87, train_loss = 1.8361106924712658, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 88, train_loss = 1.823175686178729, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 89, train_loss = 1.8110388715285808, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 90, train_loss = 1.799351466121152, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 91, train_loss = 1.7876226417720318, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 92, train_loss = 1.7766440846025944, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 93, train_loss = 1.7656388159375638, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 94, train_loss = 1.754244075389579, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 95, train_loss = 1.7437636218965054, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 96, train_loss = 1.7342540745157748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 97, train_loss = 1.7239623728673905, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 98, train_loss = 1.7138274759054184, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 99, train_loss = 1.704391696723178, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 100, train_loss = 1.6947902999818325, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 101, train_loss = 1.6856645632069558, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 102, train_loss = 1.676701946882531, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 103, train_loss = 1.6678920213598758, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 104, train_loss = 1.6589189257938415, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 105, train_loss = 1.6507031731307507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 106, train_loss = 1.642342871753499, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 107, train_loss = 1.6341257877647877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 108, train_loss = 1.6260201185941696, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 109, train_loss = 1.6180129672866315, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 110, train_loss = 1.610682874917984, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 111, train_loss = 1.6028123225551099, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 112, train_loss = 1.595838988898322, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 113, train_loss = 1.5880675103981048, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 114, train_loss = 1.581365828635171, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 115, train_loss = 1.5742608022410423, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 116, train_loss = 1.567714213160798, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 117, train_loss = 1.5605911288876086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 118, train_loss = 1.5539077755529433, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 119, train_loss = 1.5476901691872627, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 120, train_loss = 1.5411244768183678, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 121, train_loss = 1.5349076699931175, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 122, train_loss = 1.5289082813542336, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 123, train_loss = 1.5226195629220456, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 124, train_loss = 1.5166785009205341, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 125, train_loss = 1.5110548648517579, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 126, train_loss = 1.5049542437773198, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 127, train_loss = 1.4995343697955832, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 128, train_loss = 1.4942319368710741, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 129, train_loss = 1.4884231413016096, train_acc = 0.9974382859804378\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 130, train_loss = 1.483008890063502, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 131, train_loss = 1.4779990427196026, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 132, train_loss = 1.4726890362799168, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 133, train_loss = 1.467449905932881, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 134, train_loss = 1.4621991763124242, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 135, train_loss = 1.4572652900824323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 136, train_loss = 1.4519770195474848, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 137, train_loss = 1.4476532513508573, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 138, train_loss = 1.4427088362863287, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 139, train_loss = 1.4377793595194817, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 140, train_loss = 1.4327797641744837, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 141, train_loss = 1.4288947148015723, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 142, train_loss = 1.4240515964338556, train_acc = 0.9974382859804378\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 143, train_loss = 1.4192874518921599, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 144, train_loss = 1.415677484124899, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 145, train_loss = 1.4107412049779668, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 146, train_loss = 1.4067776141455397, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 147, train_loss = 1.4022476188838482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 148, train_loss = 1.3986002864548936, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 149, train_loss = 1.3942041397094727, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 150, train_loss = 1.3900413376977667, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 151, train_loss = 1.3864316990366206, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 152, train_loss = 1.3827213397016749, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 153, train_loss = 1.3787891753017902, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 154, train_loss = 1.3746054706862196, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 155, train_loss = 1.371181802242063, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 156, train_loss = 1.3675228034844622, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 157, train_loss = 1.363461434841156, train_acc = 0.9974382859804378\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 158, train_loss = 1.3604287542402744, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 159, train_loss = 1.3564533119788393, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 160, train_loss = 1.3532601868500933, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 161, train_loss = 1.3495027708122507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 162, train_loss = 1.3465370225021616, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 163, train_loss = 1.3428024277091026, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 164, train_loss = 1.3393198264529929, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 165, train_loss = 1.3367999382317066, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 166, train_loss = 1.3333333494374529, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 167, train_loss = 1.3301092410692945, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 168, train_loss = 1.3265766315162182, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 169, train_loss = 1.3237725608050823, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 170, train_loss = 1.3202900824835524, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 171, train_loss = 1.3171187452971935, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 172, train_loss = 1.3142785107484087, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 173, train_loss = 1.3109351819148287, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 174, train_loss = 1.3076995896408334, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 175, train_loss = 1.3050389302661642, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 176, train_loss = 1.3017360406229272, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 177, train_loss = 1.298951337696053, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 178, train_loss = 1.2957604639232159, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 179, train_loss = 1.2932282102992758, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 180, train_loss = 1.2903141342103481, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 181, train_loss = 1.2877877987921238, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 182, train_loss = 1.2850460968911648, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 183, train_loss = 1.2824725471436977, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 184, train_loss = 1.2797089293599129, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 185, train_loss = 1.2767855724086985, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 186, train_loss = 1.2744387462735176, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 187, train_loss = 1.2719947571167722, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 188, train_loss = 1.269085668027401, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 189, train_loss = 1.2667607689509168, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 190, train_loss = 1.264230441302061, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 191, train_loss = 1.261819750070572, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 192, train_loss = 1.2591507956385612, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 193, train_loss = 1.2570552006363869, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 194, train_loss = 1.254379371763207, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 195, train_loss = 1.2521430104970932, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 196, train_loss = 1.2497597621986642, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 197, train_loss = 1.247579493909143, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 198, train_loss = 1.2449831701815128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 199, train_loss = 1.2426877990365028, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 200, train_loss = 1.2407491443445906, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 201, train_loss = 1.2379966378211975, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 202, train_loss = 1.2362183270743117, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 203, train_loss = 1.2341581992805004, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 204, train_loss = 1.2316899026045576, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 205, train_loss = 1.2296603383729234, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 206, train_loss = 1.2276391001651064, train_acc = 0.9975547275267815\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 207, train_loss = 1.22522332763765, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 208, train_loss = 1.2234682328999043, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 209, train_loss = 1.2212440023431554, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 210, train_loss = 1.2192798046162352, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 211, train_loss = 1.2170550437876955, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 212, train_loss = 1.2150857473025098, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 213, train_loss = 1.212774553685449, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 214, train_loss = 1.2110716998577118, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 215, train_loss = 1.2091178124537691, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 216, train_loss = 1.207046777009964, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 217, train_loss = 1.2052736816112883, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 218, train_loss = 1.2035305835306644, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 219, train_loss = 1.2013976399903186, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 220, train_loss = 1.199259967834223, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 221, train_loss = 1.197861262888182, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 222, train_loss = 1.1958497886662371, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 223, train_loss = 1.1939488127827644, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 224, train_loss = 1.1921726427972317, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 225, train_loss = 1.1905158472363837, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 226, train_loss = 1.1883690829272382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 227, train_loss = 1.1869891658425331, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 228, train_loss = 1.1851309699122794, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 229, train_loss = 1.18306640163064, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 230, train_loss = 1.1816241790656932, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 231, train_loss = 1.1797576707904227, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 232, train_loss = 1.1781184549327008, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 233, train_loss = 1.1764031648635864, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 234, train_loss = 1.1746567624504678, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 235, train_loss = 1.1732353394036181, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 236, train_loss = 1.1713781778817065, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 237, train_loss = 1.1698059191112407, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 238, train_loss = 1.168346070975531, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 239, train_loss = 1.1665475331246853, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 240, train_loss = 1.1648338586091995, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 241, train_loss = 1.1630811281502247, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 242, train_loss = 1.1614998777513392, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 243, train_loss = 1.1602360792458057, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 244, train_loss = 1.1584401093423367, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 245, train_loss = 1.1569917860324495, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 246, train_loss = 1.1554136934573762, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 247, train_loss = 1.153758252679836, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 248, train_loss = 1.1523709098692052, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 249, train_loss = 1.1509065802092664, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 250, train_loss = 1.1496698918635957, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 251, train_loss = 1.1481499063665979, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 252, train_loss = 1.1462430221145041, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 253, train_loss = 1.145111641555559, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 254, train_loss = 1.1436044499278069, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 255, train_loss = 1.142136452079285, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 256, train_loss = 1.140884030610323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 257, train_loss = 1.1393884035642259, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 258, train_loss = 1.137852845073212, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 259, train_loss = 1.136692522733938, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 260, train_loss = 1.134833175688982, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 261, train_loss = 1.1337256183032878, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 262, train_loss = 1.1324000743334182, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 263, train_loss = 1.131000928580761, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 264, train_loss = 1.1293016150593758, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 265, train_loss = 1.1278811345691793, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 266, train_loss = 1.1265209105913527, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 267, train_loss = 1.124966700852383, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 268, train_loss = 1.123636681586504, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 269, train_loss = 1.122017225890886, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 270, train_loss = 1.1208963096141815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 271, train_loss = 1.1199705215985887, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 272, train_loss = 1.1181610934436321, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 273, train_loss = 1.1173461799626239, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 274, train_loss = 1.1158687770366669, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 275, train_loss = 1.1144944168627262, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 276, train_loss = 1.1132257580757141, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 277, train_loss = 1.1122719682753086, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 278, train_loss = 1.1109053964610212, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 279, train_loss = 1.1096800069208257, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 280, train_loss = 1.1084353787009604, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 281, train_loss = 1.1071191194350831, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 282, train_loss = 1.105991154909134, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 283, train_loss = 1.104723223776091, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 284, train_loss = 1.1035466057364829, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 285, train_loss = 1.1024106268887408, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 286, train_loss = 1.1012615859508514, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 287, train_loss = 1.0998524762690067, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 288, train_loss = 1.098925078928005, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 289, train_loss = 1.09753342095064, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 290, train_loss = 1.0966847774689086, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 291, train_loss = 1.0955085170571692, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 292, train_loss = 1.0945666320621967, train_acc = 0.9975547275267815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 293, train_loss = 1.0933547367458232, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 294, train_loss = 1.0919759621028788, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 295, train_loss = 1.090857621282339, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 296, train_loss = 1.089747837453615, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 297, train_loss = 1.0888849559123628, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 298, train_loss = 1.0877879385952838, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 299, train_loss = 1.0867054015398026, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 300, train_loss = 1.0855670757591724, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 301, train_loss = 1.0844190890784375, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 302, train_loss = 1.0834309297497384, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 303, train_loss = 1.0825076922774315, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 304, train_loss = 1.0812519043684006, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 305, train_loss = 1.0801623885636218, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 306, train_loss = 1.0793172605335712, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 307, train_loss = 1.0780244680936448, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 308, train_loss = 1.0773848916287534, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 309, train_loss = 1.0761295693810098, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 310, train_loss = 1.075345038145315, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 311, train_loss = 1.0741266955737956, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 312, train_loss = 1.0730197193915956, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 313, train_loss = 1.0724580250680447, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 314, train_loss = 1.0715026197140105, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 315, train_loss = 1.070361836522352, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 316, train_loss = 1.0694946671719663, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 317, train_loss = 1.068212432146538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 318, train_loss = 1.067584800242912, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 319, train_loss = 1.0665036936406977, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 320, train_loss = 1.065620232373476, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 321, train_loss = 1.0646607466042042, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 322, train_loss = 1.0638265125453472, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 323, train_loss = 1.062782867520582, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 324, train_loss = 1.0617487480049022, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 325, train_loss = 1.061017828702461, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 326, train_loss = 1.060120860754978, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 327, train_loss = 1.059120051562786, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 328, train_loss = 1.0583275432582013, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 329, train_loss = 1.0572974408860318, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 330, train_loss = 1.0563561084563844, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 331, train_loss = 1.0557544032926671, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 332, train_loss = 1.0547169645433314, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 333, train_loss = 1.0537975008483045, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 334, train_loss = 1.053084655373823, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 335, train_loss = 1.052114533900749, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 336, train_loss = 1.0514064840972424, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 337, train_loss = 1.0502893912489526, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 338, train_loss = 1.0496731040184386, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 339, train_loss = 1.0489630438387394, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 340, train_loss = 1.048091274977196, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 341, train_loss = 1.0471474031801336, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 342, train_loss = 1.046473689377308, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 343, train_loss = 1.0453311267192475, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 344, train_loss = 1.0448192830081098, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 345, train_loss = 1.0437974967062473, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 346, train_loss = 1.043124258518219, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 347, train_loss = 1.0422945208847523, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 348, train_loss = 1.041332020133268, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 349, train_loss = 1.040543230890762, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 350, train_loss = 1.0397495192592032, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 351, train_loss = 1.038792418956291, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 352, train_loss = 1.0381996383075602, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 353, train_loss = 1.037291927903425, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 354, train_loss = 1.036561482877005, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 355, train_loss = 1.03585283952998, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 356, train_loss = 1.0351533492212184, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 357, train_loss = 1.0340971425175667, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 358, train_loss = 1.0337408793275245, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 359, train_loss = 1.0325842325692065, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 360, train_loss = 1.0321717510814779, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 361, train_loss = 1.0311481368844397, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 362, train_loss = 1.0304544369573705, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 363, train_loss = 1.0297123181517236, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 364, train_loss = 1.0290181512827985, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 365, train_loss = 1.028165026276838, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 366, train_loss = 1.027370257943403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 367, train_loss = 1.0264021754264832, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 368, train_loss = 1.0260954474215396, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 369, train_loss = 1.0253318312461488, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 370, train_loss = 1.0247013333137147, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 371, train_loss = 1.0237389405665454, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 372, train_loss = 1.0229632655682508, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 373, train_loss = 1.0224562312068883, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 374, train_loss = 1.0217451316711958, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 375, train_loss = 1.0208471789956093, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 376, train_loss = 1.0201972536742687, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 377, train_loss = 1.0194747733476106, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 378, train_loss = 1.0184746322629508, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 379, train_loss = 1.0181427523493767, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 380, train_loss = 1.017448323458666, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 381, train_loss = 1.0167792811989784, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 382, train_loss = 1.015960798918968, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 383, train_loss = 1.015627155691618, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 384, train_loss = 1.0147046335041523, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 385, train_loss = 1.0140911651251372, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 386, train_loss = 1.0131979385914747, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 387, train_loss = 1.0124945218267385, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 388, train_loss = 1.011951175838476, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 389, train_loss = 1.0113654732704163, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 390, train_loss = 1.010652662575012, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 391, train_loss = 1.0097292897698935, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 392, train_loss = 1.0088022214767989, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 393, train_loss = 1.008366717636818, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 394, train_loss = 1.007581289857626, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 395, train_loss = 1.0069020564260427, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 396, train_loss = 1.0063687575457152, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 397, train_loss = 1.005643829703331, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 398, train_loss = 1.0052054872212466, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 399, train_loss = 1.0046297883091029, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 400, train_loss = 1.0036324349639472, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 401, train_loss = 1.0031316553649958, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 402, train_loss = 1.0022813702526037, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 403, train_loss = 1.0018534362316132, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 404, train_loss = 1.0012802345154341, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 405, train_loss = 1.0006769659521524, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 406, train_loss = 1.0000857996346895, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 407, train_loss = 0.9994403682649136, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 408, train_loss = 0.9990060105919838, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 409, train_loss = 0.998220082372427, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 410, train_loss = 0.9976567526755389, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 411, train_loss = 0.9970417879521847, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 412, train_loss = 0.9966224481759127, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 413, train_loss = 0.995962917804718, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 414, train_loss = 0.9950890876352787, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 415, train_loss = 0.994813551515108, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 416, train_loss = 0.993946553528076, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 417, train_loss = 0.993503558129305, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 418, train_loss = 0.9930693407950457, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 419, train_loss = 0.9921189099550247, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 420, train_loss = 0.9917526617646217, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 421, train_loss = 0.9910995413956698, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 422, train_loss = 0.9907319458725397, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 423, train_loss = 0.9898133650422096, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 424, train_loss = 0.989165081322426, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 425, train_loss = 0.988735227525467, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 426, train_loss = 0.9881823845207691, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 427, train_loss = 0.9873531324265059, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 428, train_loss = 0.9870285714569036, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 429, train_loss = 0.9864935204386711, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 430, train_loss = 0.9857182713749353, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 431, train_loss = 0.9852312120201532, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 432, train_loss = 0.9847323025169317, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 433, train_loss = 0.984365531563526, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 434, train_loss = 0.9836593593063299, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 435, train_loss = 0.9831561980245169, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 436, train_loss = 0.9828777375223581, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 437, train_loss = 0.9819948971271515, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 438, train_loss = 0.9818131563661154, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 439, train_loss = 0.9810727747681085, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 440, train_loss = 0.9804797222313937, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 441, train_loss = 0.9799542290566023, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 442, train_loss = 0.9793183716537897, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 443, train_loss = 0.9786872963013593, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 444, train_loss = 0.9781234090623911, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 445, train_loss = 0.9777428793313447, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 446, train_loss = 0.9770359123649541, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 447, train_loss = 0.9766338008048479, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 448, train_loss = 0.9761228039860725, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 449, train_loss = 0.9756533702311572, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 450, train_loss = 0.9749808423221111, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 451, train_loss = 0.9744348699750844, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 452, train_loss = 0.9740895330905914, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 453, train_loss = 0.9734250120818615, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 454, train_loss = 0.9733069017529488, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 455, train_loss = 0.9721687895653304, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 456, train_loss = 0.9718806681630667, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 457, train_loss = 0.9714657875301782, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 458, train_loss = 0.9706164114177227, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 459, train_loss = 0.9706431453523692, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 460, train_loss = 0.9698401404020842, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 461, train_loss = 0.969403794646496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 462, train_loss = 0.9685964211821556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 463, train_loss = 0.9678883055748884, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 464, train_loss = 0.9672334641218185, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 465, train_loss = 0.9660724004206713, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 466, train_loss = 0.9654776379466057, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 467, train_loss = 0.9648186328413431, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 468, train_loss = 0.9641736460325774, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 469, train_loss = 0.9638804445567075, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 470, train_loss = 0.9631474899651948, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 471, train_loss = 0.9627532735466957, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 472, train_loss = 0.9623461986484472, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 473, train_loss = 0.9619795605540276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 474, train_loss = 0.9612317867577076, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 475, train_loss = 0.9609902538359165, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 476, train_loss = 0.9604031095805112, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 477, train_loss = 0.9597502897086088, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 478, train_loss = 0.9596511510608252, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 479, train_loss = 0.9587320946156979, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 480, train_loss = 0.9585580254497472, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 481, train_loss = 0.9581280002894346, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 482, train_loss = 0.957539619266754, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 483, train_loss = 0.9570960439741611, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 484, train_loss = 0.9566505402326584, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 485, train_loss = 0.9559124956431333, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 486, train_loss = 0.9555784960684832, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 487, train_loss = 0.9554180440900382, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 488, train_loss = 0.9544728025794029, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 489, train_loss = 0.9541810279188212, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 490, train_loss = 0.9537491065857466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 491, train_loss = 0.9534009235503618, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 492, train_loss = 0.9531368551251944, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 493, train_loss = 0.9525971549155656, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 494, train_loss = 0.9519073007104453, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 495, train_loss = 0.9515057826938573, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 496, train_loss = 0.9512073323130608, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 497, train_loss = 0.9506746331753675, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 498, train_loss = 0.9503372038307134, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 499, train_loss = 0.9501035114226397, train_acc = 0.9977876106194691\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████▋                | 23/30 [3:49:43<1:10:07, 601.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "24th- epoch: 0, train_loss = 160.1572159677744, train_acc = 0.7409175593851887\n",
      "test Acc 0.8482309124767226:\n",
      "24th- epoch: 1, train_loss = 52.09315092116594, train_acc = 0.8950861667442943\n",
      "test Acc 0.8999068901303539:\n",
      "24th- epoch: 2, train_loss = 37.083602357655764, train_acc = 0.9227992547741034\n",
      "test Acc 0.9166666666666666:\n",
      "24th- epoch: 3, train_loss = 29.413713928312063, train_acc = 0.9372380065207266\n",
      "test Acc 0.9273743016759777:\n",
      "24th- epoch: 4, train_loss = 24.54266452603042, train_acc = 0.9473684210526315\n",
      "test Acc 0.9329608938547486:\n",
      "24th- epoch: 5, train_loss = 21.10725255124271, train_acc = 0.9544713553795995\n",
      "test Acc 0.9371508379888268:\n",
      "24th- epoch: 6, train_loss = 18.520007621496916, train_acc = 0.9607591988821611\n",
      "test Acc 0.9399441340782123:\n",
      "24th- epoch: 7, train_loss = 16.481265919283032, train_acc = 0.9651839776432231\n",
      "test Acc 0.9427374301675978:\n",
      "24th- epoch: 8, train_loss = 14.85300294496119, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "24th- epoch: 9, train_loss = 13.491465801373124, train_acc = 0.9725197950628784\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 10, train_loss = 12.34332482330501, train_acc = 0.9756637168141593\n",
      "test Acc 0.952048417132216:\n",
      "24th- epoch: 11, train_loss = 11.365643946453929, train_acc = 0.9768281322775967\n",
      "test Acc 0.9553072625698324:\n",
      "24th- epoch: 12, train_loss = 10.516643637791276, train_acc = 0.9796227293898463\n",
      "test Acc 0.9567039106145251:\n",
      "24th- epoch: 13, train_loss = 9.775770984590054, train_acc = 0.9803213786679087\n",
      "test Acc 0.957635009310987:\n",
      "24th- epoch: 14, train_loss = 9.122666360810399, train_acc = 0.9820680018630648\n",
      "test Acc 0.9590316573556797:\n",
      "24th- epoch: 15, train_loss = 8.539480932056904, train_acc = 0.9831159757801584\n",
      "test Acc 0.9599627560521415:\n",
      "24th- epoch: 16, train_loss = 8.027996752411127, train_acc = 0.9840475081509082\n",
      "test Acc 0.9613594040968343:\n",
      "24th- epoch: 17, train_loss = 7.565812909044325, train_acc = 0.9849790405216581\n",
      "test Acc 0.9608938547486033:\n",
      "24th- epoch: 18, train_loss = 7.147155556827784, train_acc = 0.9856776897997206\n",
      "test Acc 0.9613594040968343:\n",
      "24th- epoch: 19, train_loss = 6.772082089446485, train_acc = 0.9868421052631579\n",
      "test Acc 0.9613594040968343:\n",
      "24th- epoch: 20, train_loss = 6.43139773234725, train_acc = 0.9880065207265952\n",
      "test Acc 0.9613594040968343:\n",
      "24th- epoch: 21, train_loss = 6.1184833236038685, train_acc = 0.9883558453656265\n",
      "test Acc 0.9622905027932961:\n",
      "24th- epoch: 22, train_loss = 5.836629413999617, train_acc = 0.9891709361900326\n",
      "test Acc 0.9636871508379888:\n",
      "24th- epoch: 23, train_loss = 5.578729771077633, train_acc = 0.9899860270144387\n",
      "test Acc 0.9650837988826816:\n",
      "24th- epoch: 24, train_loss = 5.34229588881135, train_acc = 0.9906846762925011\n",
      "test Acc 0.9655493482309124:\n",
      "24th- epoch: 25, train_loss = 5.12713045347482, train_acc = 0.9914997671169073\n",
      "test Acc 0.9655493482309124:\n",
      "24th- epoch: 26, train_loss = 4.9281431986019015, train_acc = 0.9923148579413135\n",
      "test Acc 0.9655493482309124:\n",
      "24th- epoch: 27, train_loss = 4.744766590185463, train_acc = 0.9925477410340009\n",
      "test Acc 0.9660148975791434:\n",
      "24th- epoch: 28, train_loss = 4.577689819037914, train_acc = 0.9928970656730322\n",
      "test Acc 0.9664804469273743:\n",
      "24th- epoch: 29, train_loss = 4.4237111723050475, train_acc = 0.9930135072193759\n",
      "test Acc 0.9664804469273743:\n",
      "24th- epoch: 30, train_loss = 4.2796434396877885, train_acc = 0.9933628318584071\n",
      "test Acc 0.9664804469273743:\n",
      "24th- epoch: 31, train_loss = 4.142707337625325, train_acc = 0.9937121564974383\n",
      "test Acc 0.9660148975791434:\n",
      "24th- epoch: 32, train_loss = 4.0180852534249425, train_acc = 0.9940614811364695\n",
      "test Acc 0.9660148975791434:\n",
      "24th- epoch: 33, train_loss = 3.900435728020966, train_acc = 0.994294364229157\n",
      "test Acc 0.9660148975791434:\n",
      "24th- epoch: 34, train_loss = 3.7917912304401398, train_acc = 0.9945272473218444\n",
      "test Acc 0.9664804469273743:\n",
      "24th- epoch: 35, train_loss = 3.6899756216444075, train_acc = 0.9948765719608756\n",
      "test Acc 0.9664804469273743:\n",
      "24th- epoch: 36, train_loss = 3.5952920094132423, train_acc = 0.9952258965999069\n",
      "test Acc 0.9669459962756052:\n",
      "24th- epoch: 37, train_loss = 3.5033109434880316, train_acc = 0.9952258965999069\n",
      "test Acc 0.9669459962756052:\n",
      "24th- epoch: 38, train_loss = 3.4209006875753403, train_acc = 0.9952258965999069\n",
      "test Acc 0.9669459962756052:\n",
      "24th- epoch: 39, train_loss = 3.3416036530397832, train_acc = 0.9952258965999069\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 40, train_loss = 3.2671051868237555, train_acc = 0.9952258965999069\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 41, train_loss = 3.194216309580952, train_acc = 0.9953423381462506\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 42, train_loss = 3.129598405212164, train_acc = 0.9953423381462506\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 43, train_loss = 3.0651282556355, train_acc = 0.9954587796925943\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 44, train_loss = 3.0033547007478774, train_acc = 0.9954587796925943\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 45, train_loss = 2.9472853057086468, train_acc = 0.9954587796925943\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 46, train_loss = 2.8918497427366674, train_acc = 0.9954587796925943\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 47, train_loss = 2.8397468640469015, train_acc = 0.995575221238938\n",
      "test Acc 0.9678770949720671:\n",
      "24th- epoch: 48, train_loss = 2.7899193353950977, train_acc = 0.995575221238938\n",
      "test Acc 0.9683426443202979:\n",
      "24th- epoch: 49, train_loss = 2.743095811456442, train_acc = 0.9956916627852818\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 50, train_loss = 2.696864740457386, train_acc = 0.9956916627852818\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 51, train_loss = 2.6541732004843652, train_acc = 0.9956916627852818\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 52, train_loss = 2.6131537980400026, train_acc = 0.9956916627852818\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 53, train_loss = 2.5733750886283815, train_acc = 0.9958081043316255\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 54, train_loss = 2.5362922116182745, train_acc = 0.9958081043316255\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 55, train_loss = 2.4997724778950214, train_acc = 0.9958081043316255\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 56, train_loss = 2.465617321431637, train_acc = 0.996040987424313\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 57, train_loss = 2.432142640231177, train_acc = 0.996040987424313\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 58, train_loss = 2.401544454274699, train_acc = 0.9961574289706567\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 59, train_loss = 2.3697243817150593, train_acc = 0.9962738705170004\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 60, train_loss = 2.341310599120334, train_acc = 0.9963903120633442\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 61, train_loss = 2.312950797379017, train_acc = 0.9967396367023754\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 62, train_loss = 2.2862697541713715, train_acc = 0.9966231951560317\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 63, train_loss = 2.2599899743217975, train_acc = 0.9966231951560317\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 64, train_loss = 2.2350167024414986, train_acc = 0.9966231951560317\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 65, train_loss = 2.2114419688005, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 66, train_loss = 2.1877107557374984, train_acc = 0.9968560782487191\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 67, train_loss = 2.1656292751431465, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 68, train_loss = 2.144031559349969, train_acc = 0.9969725197950629\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 69, train_loss = 2.1229647111613303, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 70, train_loss = 2.1026099883019924, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 71, train_loss = 2.0838116395752877, train_acc = 0.9969725197950629\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 72, train_loss = 2.0647953897714615, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 73, train_loss = 2.046414688229561, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 74, train_loss = 2.028213231591508, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 75, train_loss = 2.011158848879859, train_acc = 0.9970889613414066\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 76, train_loss = 1.9946562808472663, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "24th- epoch: 77, train_loss = 1.977653318317607, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "24th- epoch: 78, train_loss = 1.9629782277625054, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "24th- epoch: 79, train_loss = 1.9473549860995263, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "24th- epoch: 80, train_loss = 1.9319701429922134, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "24th- epoch: 81, train_loss = 1.9176887583453208, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "24th- epoch: 82, train_loss = 1.9037746239919215, train_acc = 0.9970889613414066\n",
      "test Acc 0.9711359404096834:\n",
      "24th- epoch: 83, train_loss = 1.8898735158145428, train_acc = 0.9970889613414066\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 84, train_loss = 1.8764719751197845, train_acc = 0.9972054028877504\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 85, train_loss = 1.8637782521545887, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 86, train_loss = 1.8497047659475356, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 87, train_loss = 1.839394349604845, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 88, train_loss = 1.8268447939772159, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 89, train_loss = 1.8147236991208047, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 90, train_loss = 1.802827838808298, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 91, train_loss = 1.7928549187490717, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 92, train_loss = 1.781575628905557, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 93, train_loss = 1.7711654789745808, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 94, train_loss = 1.7600880885729566, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 95, train_loss = 1.750831350684166, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 96, train_loss = 1.7400448234984651, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 97, train_loss = 1.7312087193131447, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 98, train_loss = 1.720956563949585, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 99, train_loss = 1.7115914536407217, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 100, train_loss = 1.7021833024919033, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 101, train_loss = 1.6934537490596995, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 102, train_loss = 1.6850466057658195, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 103, train_loss = 1.6767366006970406, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 104, train_loss = 1.6682231910526752, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 105, train_loss = 1.6600038347532973, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 106, train_loss = 1.6522196680307388, train_acc = 0.9972054028877504\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 107, train_loss = 1.6445417888462543, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 108, train_loss = 1.6367772544035688, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 109, train_loss = 1.6287181340157986, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 110, train_loss = 1.6212230051169172, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 111, train_loss = 1.6143230783054605, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 112, train_loss = 1.6064391682157293, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 113, train_loss = 1.5993982529034838, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 114, train_loss = 1.5920282689621672, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 115, train_loss = 1.5862019372871146, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 116, train_loss = 1.577893067151308, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 117, train_loss = 1.5715471195289865, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 118, train_loss = 1.5645307190716267, train_acc = 0.9972054028877504\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 119, train_loss = 1.5574254356324673, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 120, train_loss = 1.5500247565796599, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 121, train_loss = 1.5433119609951973, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 122, train_loss = 1.5367930320790038, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 123, train_loss = 1.5295488213887438, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 124, train_loss = 1.5236947325756773, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 125, train_loss = 1.5184602923691273, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 126, train_loss = 1.5114699999103323, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 127, train_loss = 1.5064336396753788, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 128, train_loss = 1.500485916971229, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 129, train_loss = 1.4954089993843809, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 130, train_loss = 1.4897688701748848, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 131, train_loss = 1.4839399581542239, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 132, train_loss = 1.4789726249873638, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 133, train_loss = 1.47365392500069, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 134, train_loss = 1.4691960426280275, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 135, train_loss = 1.463865483761765, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 136, train_loss = 1.4589020498096943, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 137, train_loss = 1.4543620211770758, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 138, train_loss = 1.448920520604588, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 139, train_loss = 1.4447111251065508, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 140, train_loss = 1.4401691518723965, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 141, train_loss = 1.435400664806366, train_acc = 0.9972054028877504\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 142, train_loss = 1.4310150630772114, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 143, train_loss = 1.427029145299457, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 144, train_loss = 1.422049593180418, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 145, train_loss = 1.4188661413500085, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 146, train_loss = 1.4138009498128667, train_acc = 0.9972054028877504\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 147, train_loss = 1.4096063300967216, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 148, train_loss = 1.4063040912151337, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 149, train_loss = 1.4021635738899931, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 150, train_loss = 1.3980302748968825, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 151, train_loss = 1.3943688794970512, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 152, train_loss = 1.3903510893578641, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 153, train_loss = 1.3862728203530423, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 154, train_loss = 1.3834278720314614, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 155, train_loss = 1.379085159569513, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 156, train_loss = 1.375890367955435, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 157, train_loss = 1.372225008904934, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 158, train_loss = 1.367701854556799, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 159, train_loss = 1.3655653347377665, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 160, train_loss = 1.3612088498775847, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 161, train_loss = 1.3580610677599907, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 162, train_loss = 1.3542060951585881, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 163, train_loss = 1.3514437775011174, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 164, train_loss = 1.348275113850832, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 165, train_loss = 1.3445629266207106, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 166, train_loss = 1.3414735533297062, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 167, train_loss = 1.3374177180230618, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 168, train_loss = 1.3353092670440674, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 169, train_loss = 1.33211449283408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 170, train_loss = 1.3283427692949772, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 171, train_loss = 1.3259117417037487, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 172, train_loss = 1.3224289380013943, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 173, train_loss = 1.3199020996689796, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 174, train_loss = 1.3168906557257287, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 175, train_loss = 1.3141054026782513, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 176, train_loss = 1.310166495561134, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 177, train_loss = 1.3078257429297082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 178, train_loss = 1.3049317163531668, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 179, train_loss = 1.3018502692575566, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 180, train_loss = 1.2993693885509856, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 181, train_loss = 1.2964767118101008, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 182, train_loss = 1.2939209205214866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 183, train_loss = 1.291392259299755, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 184, train_loss = 1.2881398077006452, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 185, train_loss = 1.2854171060025692, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 186, train_loss = 1.2832551610772498, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 187, train_loss = 1.2809683084487915, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 188, train_loss = 1.2777550493483432, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 189, train_loss = 1.2752423745696433, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 190, train_loss = 1.2733317849342711, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 191, train_loss = 1.2705755531787872, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 192, train_loss = 1.2678326715831645, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 193, train_loss = 1.2653870756621473, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 194, train_loss = 1.2633232089574449, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 195, train_loss = 1.2608519929344766, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 196, train_loss = 1.2582099226419814, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 197, train_loss = 1.2560219938750379, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 198, train_loss = 1.2530174392159097, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 199, train_loss = 1.251675833016634, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 200, train_loss = 1.2487021647393703, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 201, train_loss = 1.246287231624592, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 202, train_loss = 1.24413175258087, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 203, train_loss = 1.242169429839123, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 204, train_loss = 1.2394205803866498, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 205, train_loss = 1.2376233140821569, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 206, train_loss = 1.2358253449201584, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 207, train_loss = 1.2330073490738869, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 208, train_loss = 1.231170931190718, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 209, train_loss = 1.228922878683079, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 210, train_loss = 1.227233923971653, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 211, train_loss = 1.2245872517232783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 212, train_loss = 1.2229956264491193, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 213, train_loss = 1.2200194709002972, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 214, train_loss = 1.2185515177552588, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 215, train_loss = 1.2164951339364052, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 216, train_loss = 1.2146215625107288, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 217, train_loss = 1.2131639644503593, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 218, train_loss = 1.2102242546970956, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 219, train_loss = 1.2090563078527339, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 220, train_loss = 1.2068549431860447, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 221, train_loss = 1.204802977561485, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 222, train_loss = 1.2034023975138552, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 223, train_loss = 1.2010909889941104, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 224, train_loss = 1.19881983846426, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 225, train_loss = 1.1973003347520716, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 226, train_loss = 1.1953534384374507, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 227, train_loss = 1.1941358571057208, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 228, train_loss = 1.1920782998204231, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 229, train_loss = 1.1902805343270302, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 230, train_loss = 1.1884133306448348, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 231, train_loss = 1.1867599946563132, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 232, train_loss = 1.185214261233341, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 233, train_loss = 1.1839264568989165, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 234, train_loss = 1.1814123094081879, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 235, train_loss = 1.1800518867676146, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 236, train_loss = 1.179134466976393, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 237, train_loss = 1.1763311426038854, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 238, train_loss = 1.17512073245598, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 239, train_loss = 1.1735760644078255, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 240, train_loss = 1.1719463976914994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 241, train_loss = 1.1703874568338506, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 242, train_loss = 1.1686493220622651, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 243, train_loss = 1.1674816657905467, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 244, train_loss = 1.1656046099960804, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 245, train_loss = 1.1642273205216043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 246, train_loss = 1.1629880418186076, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 247, train_loss = 1.1614593912963755, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 248, train_loss = 1.1591941565275192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 249, train_loss = 1.1582809637184255, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 250, train_loss = 1.1565874268417247, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 251, train_loss = 1.1547715850174427, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 252, train_loss = 1.153485490649473, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 253, train_loss = 1.1522450558841228, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 254, train_loss = 1.1505554728209972, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 255, train_loss = 1.1491191225650255, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 256, train_loss = 1.1479018876852933, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 257, train_loss = 1.14649954563356, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 258, train_loss = 1.1450355338456575, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 259, train_loss = 1.1438094340264797, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 260, train_loss = 1.1423508003354073, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 261, train_loss = 1.1408134289085865, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 262, train_loss = 1.1390338018536568, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 263, train_loss = 1.1379824554023799, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 264, train_loss = 1.135864283889532, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 265, train_loss = 1.1345976789889392, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 266, train_loss = 1.1338362023234367, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 267, train_loss = 1.1317199083568994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 268, train_loss = 1.131091419607401, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 269, train_loss = 1.129481124371523, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 270, train_loss = 1.127902095526224, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 271, train_loss = 1.1266226259467658, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 272, train_loss = 1.1255046874284744, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 273, train_loss = 1.1235033745469991, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 274, train_loss = 1.122143853455782, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 275, train_loss = 1.1205838384630624, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 276, train_loss = 1.1201082257030066, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 277, train_loss = 1.1183143841626588, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 278, train_loss = 1.1175058210792486, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 279, train_loss = 1.1161164281365927, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 280, train_loss = 1.1143878673610743, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 281, train_loss = 1.1132875432667788, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 282, train_loss = 1.112408990651602, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 283, train_loss = 1.1114067224261817, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 284, train_loss = 1.1094640642404556, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 285, train_loss = 1.1086095857026521, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 286, train_loss = 1.107809183507925, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 287, train_loss = 1.1063789439795073, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 288, train_loss = 1.1052661476132926, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 289, train_loss = 1.1039754239318427, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 290, train_loss = 1.1032164009811822, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 291, train_loss = 1.1017763999698218, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 292, train_loss = 1.1008644960820675, train_acc = 0.9975547275267815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 293, train_loss = 1.1000720846059266, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 294, train_loss = 1.0980119183659554, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 295, train_loss = 1.097194084286457, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 296, train_loss = 1.0960659248230513, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 297, train_loss = 1.0951832669379655, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 298, train_loss = 1.094283423066372, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 299, train_loss = 1.0929009777901229, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 300, train_loss = 1.0916980504989624, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 301, train_loss = 1.0908000568451826, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 302, train_loss = 1.089791008591419, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 303, train_loss = 1.0887980212864932, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 304, train_loss = 1.0872949759068433, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 305, train_loss = 1.086528331041336, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 306, train_loss = 1.0858709563908633, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 307, train_loss = 1.0843365167675074, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 308, train_loss = 1.0834960204956587, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 309, train_loss = 1.0827840132114943, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 310, train_loss = 1.0814089601335581, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 311, train_loss = 1.0805228067038115, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 312, train_loss = 1.079319305717945, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 313, train_loss = 1.078370622039074, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 314, train_loss = 1.0770805267093237, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 315, train_loss = 1.0766032772662584, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 316, train_loss = 1.0751987472176552, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 317, train_loss = 1.0745646941068117, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 318, train_loss = 1.0739225881698076, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 319, train_loss = 1.0722790261206683, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 320, train_loss = 1.0717260750534479, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 321, train_loss = 1.0707859036920127, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 322, train_loss = 1.069372079015011, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 323, train_loss = 1.0691241882741451, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 324, train_loss = 1.0678631911578123, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 325, train_loss = 1.0665741662087385, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 326, train_loss = 1.0656896010041237, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 327, train_loss = 1.0650737285614014, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 328, train_loss = 1.0643848106265068, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 329, train_loss = 1.0626489495334681, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 330, train_loss = 1.0623051760194357, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 331, train_loss = 1.0614598927495535, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 332, train_loss = 1.0604718178510666, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 333, train_loss = 1.0599084682762623, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 334, train_loss = 1.0585726176796015, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 335, train_loss = 1.0580635778605938, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 336, train_loss = 1.0574002067151014, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 337, train_loss = 1.0560669973492622, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 338, train_loss = 1.054914584994549, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 339, train_loss = 1.054162318498129, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 340, train_loss = 1.0537364035844803, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 341, train_loss = 1.0528849214315414, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 342, train_loss = 1.051343767583603, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 343, train_loss = 1.0509834761323873, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 344, train_loss = 1.050033795327181, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 345, train_loss = 1.0493443136510905, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 346, train_loss = 1.0487051829695702, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 347, train_loss = 1.0475576184689999, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 348, train_loss = 1.0468135227856692, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 349, train_loss = 1.0458735426364, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 350, train_loss = 1.0450330562889576, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 351, train_loss = 1.0444485867919866, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 352, train_loss = 1.0436155734059867, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 353, train_loss = 1.0425492860376835, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 354, train_loss = 1.0423582904040813, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 355, train_loss = 1.0408642602560576, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 356, train_loss = 1.0404285167751368, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 357, train_loss = 1.0398187600076199, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 358, train_loss = 1.0390259934065398, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 359, train_loss = 1.0382018176314887, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 360, train_loss = 1.0369691910746042, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 361, train_loss = 1.0362229968013708, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 362, train_loss = 1.0357681959867477, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 363, train_loss = 1.0348170697689056, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 364, train_loss = 1.0341886207461357, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 365, train_loss = 1.0334148854017258, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 366, train_loss = 1.0324625285866205, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 367, train_loss = 1.032234969228739, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 368, train_loss = 1.0311044603586197, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 369, train_loss = 1.0299531842174474, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 370, train_loss = 1.0299750566482544, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 371, train_loss = 1.0291333993372973, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 372, train_loss = 1.0278282202780247, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 373, train_loss = 1.0275282226502895, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 374, train_loss = 1.0265539450047072, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 375, train_loss = 1.0260941746237222, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 376, train_loss = 1.0255393162369728, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 377, train_loss = 1.0244428602454718, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 378, train_loss = 1.023750115185976, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 379, train_loss = 1.0228648471238557, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 380, train_loss = 1.0225337855517864, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 381, train_loss = 1.0218139675853308, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 382, train_loss = 1.020747546106577, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 383, train_loss = 1.0202802208659705, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 384, train_loss = 1.0195434764027596, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 385, train_loss = 1.0185779929161072, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 386, train_loss = 1.018120044231182, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 387, train_loss = 1.0178086496889591, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 388, train_loss = 1.0166272781789303, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 389, train_loss = 1.0160614041087683, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 390, train_loss = 1.0152740366756916, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 391, train_loss = 1.0149598432180937, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 392, train_loss = 1.0142175368964672, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 393, train_loss = 1.0136349288222846, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 394, train_loss = 1.01283991834498, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 395, train_loss = 1.012052951991791, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 396, train_loss = 1.0117787470517214, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 397, train_loss = 1.0108099592325743, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 398, train_loss = 1.0103236635623034, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 399, train_loss = 1.0096528815629426, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 400, train_loss = 1.0083864964544773, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 401, train_loss = 1.008175853639841, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 402, train_loss = 1.0074753562512342, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 403, train_loss = 1.0071731520292815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 404, train_loss = 1.00641961893416, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 405, train_loss = 1.005998469889164, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 406, train_loss = 1.0047074804606382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 407, train_loss = 1.0046811302599963, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 408, train_loss = 1.004072399198776, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 409, train_loss = 1.0029041953384876, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 410, train_loss = 1.0028847195208073, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 411, train_loss = 1.0021346310677473, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 412, train_loss = 1.0008856480417307, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 413, train_loss = 1.000913786381716, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 414, train_loss = 1.0000083135964815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 415, train_loss = 0.9993718862533569, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 416, train_loss = 0.9989944621920586, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 417, train_loss = 0.998543806374073, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 418, train_loss = 0.9975052960216999, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 419, train_loss = 0.9971629244682845, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 420, train_loss = 0.9968481548130512, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 421, train_loss = 0.99581253901124, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 422, train_loss = 0.9954510852694511, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 423, train_loss = 0.9951025818882044, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 424, train_loss = 0.9938931415381376, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 425, train_loss = 0.9938828436133917, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 426, train_loss = 0.9931120822730009, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 427, train_loss = 0.9922162815928459, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 428, train_loss = 0.9922619983553886, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 429, train_loss = 0.991546131670475, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 430, train_loss = 0.9909285542817088, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 431, train_loss = 0.9899827862827806, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 432, train_loss = 0.9896801834256621, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 433, train_loss = 0.9889151453971863, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 434, train_loss = 0.9886019912810298, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 435, train_loss = 0.9876187456102343, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 436, train_loss = 0.9874757404177217, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 437, train_loss = 0.9867901901452569, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 438, train_loss = 0.9862365524022607, train_acc = 0.9976711690731253\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 439, train_loss = 0.9859452794044046, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 440, train_loss = 0.9845476684422465, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 441, train_loss = 0.9847762510180473, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 442, train_loss = 0.9839429967105389, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 443, train_loss = 0.9837293488235446, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 444, train_loss = 0.9831015008239774, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 445, train_loss = 0.982260562479496, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 446, train_loss = 0.9821548871695995, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 447, train_loss = 0.9814676567912102, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 448, train_loss = 0.9809590006916551, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 449, train_loss = 0.9801000182778807, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 450, train_loss = 0.9795195050537586, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 451, train_loss = 0.9792736731469631, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 452, train_loss = 0.9787805862724781, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 453, train_loss = 0.9779224395751953, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 454, train_loss = 0.9774828950612573, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 455, train_loss = 0.9772984671144513, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 456, train_loss = 0.9764596273453208, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 457, train_loss = 0.9759032465517521, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 458, train_loss = 0.9754894115030766, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 459, train_loss = 0.9750447732658358, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 460, train_loss = 0.9744258522987366, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 461, train_loss = 0.974143693849328, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 462, train_loss = 0.973429836332798, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 463, train_loss = 0.9730704625399085, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 464, train_loss = 0.9725010680704145, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 465, train_loss = 0.9722566256969003, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 466, train_loss = 0.9713247108011274, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 467, train_loss = 0.9712397729308577, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 468, train_loss = 0.970432152345893, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 469, train_loss = 0.9698782612831565, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 470, train_loss = 0.969699119523284, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 471, train_loss = 0.9689744313509436, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 472, train_loss = 0.9686682385654422, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 473, train_loss = 0.9684899884014158, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 474, train_loss = 0.9679292527289363, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 475, train_loss = 0.9670491417200537, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 476, train_loss = 0.9667482562363148, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 477, train_loss = 0.966231086596963, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 478, train_loss = 0.9655960674135713, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 479, train_loss = 0.9655052212328883, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 480, train_loss = 0.9646198662667302, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 481, train_loss = 0.9640810576529475, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 482, train_loss = 0.9639030831604032, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 483, train_loss = 0.9634862231760053, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 484, train_loss = 0.9627423336060019, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 485, train_loss = 0.9624251661152812, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 486, train_loss = 0.962112716093543, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 487, train_loss = 0.9617260371596785, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 488, train_loss = 0.9609861162753077, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 489, train_loss = 0.9606189131736755, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 490, train_loss = 0.960149480655673, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 491, train_loss = 0.9595550894737244, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 492, train_loss = 0.9592378487141104, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 493, train_loss = 0.958557474121335, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 494, train_loss = 0.9586775514035253, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 495, train_loss = 0.957885359719512, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 496, train_loss = 0.9575516519398661, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 497, train_loss = 0.9568326150329085, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 498, train_loss = 0.9565606911928626, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 499, train_loss = 0.9558141008019447, train_acc = 0.9977876106194691\n",
      "test Acc 0.9748603351955307:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████              | 24/30 [3:59:43<1:00:04, 600.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "25th- epoch: 0, train_loss = 141.9878898859024, train_acc = 0.7441779226828132\n",
      "test Acc 0.8547486033519553:\n",
      "25th- epoch: 1, train_loss = 49.54516392946243, train_acc = 0.8991616208663251\n",
      "test Acc 0.9073556797020484:\n",
      "25th- epoch: 2, train_loss = 34.69954644329846, train_acc = 0.9276897997205403\n",
      "test Acc 0.925512104283054:\n",
      "25th- epoch: 3, train_loss = 27.48380015604198, train_acc = 0.9443409408476945\n",
      "test Acc 0.9329608938547486:\n",
      "25th- epoch: 4, train_loss = 22.972137494012713, train_acc = 0.9544713553795995\n",
      "test Acc 0.9371508379888268:\n",
      "25th- epoch: 5, train_loss = 19.86863180808723, train_acc = 0.9613414066138798\n",
      "test Acc 0.9418063314711359:\n",
      "25th- epoch: 6, train_loss = 17.555108902975917, train_acc = 0.9649510945505356\n",
      "test Acc 0.9464618249534451:\n",
      "25th- epoch: 7, train_loss = 15.750913413241506, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 8, train_loss = 14.278585061430931, train_acc = 0.9712389380530974\n",
      "test Acc 0.9501862197392924:\n",
      "25th- epoch: 9, train_loss = 13.052157761529088, train_acc = 0.9741499767116907\n",
      "test Acc 0.9497206703910615:\n",
      "25th- epoch: 10, train_loss = 12.014359610155225, train_acc = 0.9774103400093154\n",
      "test Acc 0.952048417132216:\n",
      "25th- epoch: 11, train_loss = 11.11354655586183, train_acc = 0.9796227293898463\n",
      "test Acc 0.9548417132216015:\n",
      "25th- epoch: 12, train_loss = 10.339260548353195, train_acc = 0.9807871448532837\n",
      "test Acc 0.9557728119180633:\n",
      "25th- epoch: 13, train_loss = 9.658650429919362, train_acc = 0.9828830926874709\n",
      "test Acc 0.957635009310987:\n",
      "25th- epoch: 14, train_loss = 9.053584462031722, train_acc = 0.9840475081509082\n",
      "test Acc 0.9594972067039106:\n",
      "25th- epoch: 15, train_loss = 8.515323715284467, train_acc = 0.9850954820680019\n",
      "test Acc 0.9613594040968343:\n",
      "25th- epoch: 16, train_loss = 8.033538479357958, train_acc = 0.9856776897997206\n",
      "test Acc 0.9622905027932961:\n",
      "25th- epoch: 17, train_loss = 7.600397718138993, train_acc = 0.9861434559850955\n",
      "test Acc 0.962756052141527:\n",
      "25th- epoch: 18, train_loss = 7.208587176166475, train_acc = 0.9869585468095017\n",
      "test Acc 0.9636871508379888:\n",
      "25th- epoch: 19, train_loss = 6.848082769662142, train_acc = 0.9878900791802515\n",
      "test Acc 0.9646182495344506:\n",
      "25th- epoch: 20, train_loss = 6.52678048517555, train_acc = 0.9890544946436889\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 21, train_loss = 6.234698333777487, train_acc = 0.989869585468095\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 22, train_loss = 5.965409703552723, train_acc = 0.9904517931998137\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 23, train_loss = 5.720653827302158, train_acc = 0.9911504424778761\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 24, train_loss = 5.494942172430456, train_acc = 0.9912668840242198\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 25, train_loss = 5.288095734082162, train_acc = 0.9917326502095948\n",
      "test Acc 0.9664804469273743:\n",
      "25th- epoch: 26, train_loss = 5.095889825373888, train_acc = 0.9918490917559385\n",
      "test Acc 0.9669459962756052:\n",
      "25th- epoch: 27, train_loss = 4.915307275019586, train_acc = 0.9926641825803446\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 28, train_loss = 4.750286992639303, train_acc = 0.9927806241266884\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 29, train_loss = 4.591471320949495, train_acc = 0.9932463903120633\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 30, train_loss = 4.445321101695299, train_acc = 0.9935957149510946\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 31, train_loss = 4.307738929986954, train_acc = 0.9934792734047508\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 32, train_loss = 4.177664411254227, train_acc = 0.9937121564974383\n",
      "test Acc 0.9683426443202979:\n",
      "25th- epoch: 33, train_loss = 4.0563465328887105, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "25th- epoch: 34, train_loss = 3.943252799101174, train_acc = 0.9941779226828132\n",
      "test Acc 0.9688081936685289:\n",
      "25th- epoch: 35, train_loss = 3.8363132691010833, train_acc = 0.994294364229157\n",
      "test Acc 0.9688081936685289:\n",
      "25th- epoch: 36, train_loss = 3.736480792518705, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "25th- epoch: 37, train_loss = 3.642425441648811, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 38, train_loss = 3.5547083392739296, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 39, train_loss = 3.4698415831662714, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 40, train_loss = 3.39391732448712, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 41, train_loss = 3.3183247135020792, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "25th- epoch: 42, train_loss = 3.2490471974015236, train_acc = 0.9951094550535631\n",
      "test Acc 0.9711359404096834:\n",
      "25th- epoch: 43, train_loss = 3.1829816163517535, train_acc = 0.9953423381462506\n",
      "test Acc 0.9716014897579144:\n",
      "25th- epoch: 44, train_loss = 3.1208861507475376, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 45, train_loss = 3.060438683722168, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 46, train_loss = 3.0045537152327597, train_acc = 0.9956916627852818\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 47, train_loss = 2.950698059052229, train_acc = 0.9959245458779693\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 48, train_loss = 2.899381021503359, train_acc = 0.9959245458779693\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 49, train_loss = 2.851642783731222, train_acc = 0.9959245458779693\n",
      "test Acc 0.9725325884543762:\n",
      "25th- epoch: 50, train_loss = 2.8053630590438843, train_acc = 0.9961574289706567\n",
      "test Acc 0.9725325884543762:\n",
      "25th- epoch: 51, train_loss = 2.7611685642041266, train_acc = 0.9961574289706567\n",
      "test Acc 0.9725325884543762:\n",
      "25th- epoch: 52, train_loss = 2.719787312205881, train_acc = 0.9961574289706567\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 53, train_loss = 2.6804586402140558, train_acc = 0.9961574289706567\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 54, train_loss = 2.641210908535868, train_acc = 0.9961574289706567\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 55, train_loss = 2.604511807207018, train_acc = 0.9961574289706567\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 56, train_loss = 2.570120187010616, train_acc = 0.9961574289706567\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 57, train_loss = 2.536104094237089, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 58, train_loss = 2.5026456504128873, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 59, train_loss = 2.4711780226789415, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 60, train_loss = 2.4401895268820226, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 61, train_loss = 2.411813301499933, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 62, train_loss = 2.3830081508494914, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 63, train_loss = 2.3555848002433777, train_acc = 0.9963903120633442\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 64, train_loss = 2.328953754156828, train_acc = 0.9963903120633442\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 65, train_loss = 2.3039462217129767, train_acc = 0.9962738705170004\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 66, train_loss = 2.2789243012666702, train_acc = 0.9962738705170004\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 67, train_loss = 2.255599521100521, train_acc = 0.9962738705170004\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 68, train_loss = 2.2327903497498482, train_acc = 0.9962738705170004\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 69, train_loss = 2.210830895928666, train_acc = 0.9962738705170004\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 70, train_loss = 2.189822070300579, train_acc = 0.9962738705170004\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 71, train_loss = 2.168596771778539, train_acc = 0.9961574289706567\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 72, train_loss = 2.1478277668356895, train_acc = 0.9962738705170004\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 73, train_loss = 2.1284886796493083, train_acc = 0.996506753609688\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 74, train_loss = 2.110139752505347, train_acc = 0.996506753609688\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 75, train_loss = 2.0910615622997284, train_acc = 0.996506753609688\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 76, train_loss = 2.0731508668977767, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 77, train_loss = 2.0559682499151677, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 78, train_loss = 2.0385132047813386, train_acc = 0.996506753609688\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 79, train_loss = 2.0216537590604275, train_acc = 0.996506753609688\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 80, train_loss = 2.0047220699489117, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 81, train_loss = 1.9890720508992672, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 82, train_loss = 1.9729916986543685, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 83, train_loss = 1.9592070418875664, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 84, train_loss = 1.9438300281763077, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 85, train_loss = 1.9295585863292217, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 86, train_loss = 1.915975419105962, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 87, train_loss = 1.9021778379101306, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 88, train_loss = 1.8889159224927425, train_acc = 0.9966231951560317\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 89, train_loss = 1.8759598806500435, train_acc = 0.9966231951560317\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 90, train_loss = 1.8627664856612682, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 91, train_loss = 1.8507912878412753, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 92, train_loss = 1.838646199554205, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 93, train_loss = 1.826833727536723, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 94, train_loss = 1.8157076798379421, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 95, train_loss = 1.803910617949441, train_acc = 0.9966231951560317\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 96, train_loss = 1.7919643793720752, train_acc = 0.9966231951560317\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 97, train_loss = 1.7817826196551323, train_acc = 0.9966231951560317\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 98, train_loss = 1.7713274508714676, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 99, train_loss = 1.7605314936954528, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 100, train_loss = 1.750283621251583, train_acc = 0.9967396367023754\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 101, train_loss = 1.7410252268891782, train_acc = 0.9966231951560317\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 102, train_loss = 1.7310807083267719, train_acc = 0.9967396367023754\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 103, train_loss = 1.721553398994729, train_acc = 0.9967396367023754\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 104, train_loss = 1.7124521296937019, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 105, train_loss = 1.7037829782348126, train_acc = 0.9967396367023754\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 106, train_loss = 1.6946689684409648, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 107, train_loss = 1.6862261753994972, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 108, train_loss = 1.6777565192896873, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 109, train_loss = 1.6699155122041702, train_acc = 0.9967396367023754\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 110, train_loss = 1.6616504216799513, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 111, train_loss = 1.65354687476065, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 112, train_loss = 1.6461572324624285, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 113, train_loss = 1.638562649488449, train_acc = 0.9968560782487191\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 114, train_loss = 1.6312707947799936, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 115, train_loss = 1.624045611708425, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 116, train_loss = 1.6164225240936503, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 117, train_loss = 1.6103453002870083, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 118, train_loss = 1.6027337722480297, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 119, train_loss = 1.596062384545803, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 120, train_loss = 1.589634129195474, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 121, train_loss = 1.583700237213634, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 122, train_loss = 1.5770458057522774, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 123, train_loss = 1.5705577917397022, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 124, train_loss = 1.5643343093106523, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 125, train_loss = 1.5583569208392873, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 126, train_loss = 1.5525466228136793, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 127, train_loss = 1.546312334598042, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 128, train_loss = 1.5409844033420086, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 129, train_loss = 1.5349188869586214, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 130, train_loss = 1.529737763106823, train_acc = 0.9969725197950629\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 131, train_loss = 1.524212191463448, train_acc = 0.9969725197950629\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 132, train_loss = 1.5184507382800803, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 133, train_loss = 1.51372140890453, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 134, train_loss = 1.5083658123621717, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 135, train_loss = 1.5035191563656554, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 136, train_loss = 1.49749556183815, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 137, train_loss = 1.4931330122053623, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 138, train_loss = 1.4883662052452564, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 139, train_loss = 1.4832963409135118, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 140, train_loss = 1.4781669328222051, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 141, train_loss = 1.4738043261459097, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 142, train_loss = 1.4691244115820155, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 143, train_loss = 1.4641281937947497, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 144, train_loss = 1.459460755228065, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 145, train_loss = 1.4551874758908525, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 146, train_loss = 1.4505336011061445, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 147, train_loss = 1.4462691707303748, train_acc = 0.9969725197950629\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 148, train_loss = 1.4419331885874271, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 149, train_loss = 1.4372128831455484, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 150, train_loss = 1.4333633681526408, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 151, train_loss = 1.4292178563773632, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 152, train_loss = 1.4252022728323936, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 153, train_loss = 1.4211666671326384, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 154, train_loss = 1.4168552892515436, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 155, train_loss = 1.4129403991391882, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 156, train_loss = 1.409487321972847, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 157, train_loss = 1.40525446459651, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 158, train_loss = 1.4015246058115736, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 159, train_loss = 1.3978696577250957, train_acc = 0.9970889613414066\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 160, train_loss = 1.3945542871952057, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 161, train_loss = 1.3906420593848452, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 162, train_loss = 1.387110753566958, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 163, train_loss = 1.3835730204591528, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 164, train_loss = 1.3802072579273954, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 165, train_loss = 1.376169964671135, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 166, train_loss = 1.3737545075127855, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 167, train_loss = 1.3695415332913399, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 168, train_loss = 1.3661236701300368, train_acc = 0.9972054028877504\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 169, train_loss = 1.3633587149670348, train_acc = 0.9972054028877504\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 170, train_loss = 1.3599251894047484, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 171, train_loss = 1.357071366161108, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 172, train_loss = 1.353746771812439, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 173, train_loss = 1.350320529192686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 174, train_loss = 1.3472085930407047, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 175, train_loss = 1.3436241261661053, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 176, train_loss = 1.3414113571634516, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 177, train_loss = 1.3378970349440351, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 178, train_loss = 1.3349213376641273, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 179, train_loss = 1.3319560723612085, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 180, train_loss = 1.3293823152780533, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 181, train_loss = 1.3264622626593336, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 182, train_loss = 1.323777181445621, train_acc = 0.9973218444340941\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 183, train_loss = 1.3209851557621732, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 184, train_loss = 1.3179170079529285, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 185, train_loss = 1.3156261940603144, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 186, train_loss = 1.313146247237455, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 187, train_loss = 1.3100785799324512, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 188, train_loss = 1.3069288991391659, train_acc = 0.9973218444340941\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 189, train_loss = 1.3048067688941956, train_acc = 0.9973218444340941\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 190, train_loss = 1.3022494527394883, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 191, train_loss = 1.2993792842025869, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 192, train_loss = 1.2968455192749389, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 193, train_loss = 1.2947978575830348, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 194, train_loss = 1.2919868975877762, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 195, train_loss = 1.2895534510607831, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 196, train_loss = 1.2868245231802575, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 197, train_loss = 1.2845155075192451, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 198, train_loss = 1.2819356595282443, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 199, train_loss = 1.2797965978388675, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 200, train_loss = 1.277260098606348, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 201, train_loss = 1.2750507655437104, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 202, train_loss = 1.2730057388544083, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 203, train_loss = 1.2702031110529788, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 204, train_loss = 1.2685691739316098, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 205, train_loss = 1.2661739240284078, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 206, train_loss = 1.263522292196285, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 207, train_loss = 1.2615302801132202, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 208, train_loss = 1.2593592976336367, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 209, train_loss = 1.2568011556868441, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 210, train_loss = 1.2547802676563151, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 211, train_loss = 1.2525854967534542, train_acc = 0.9974382859804378\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 212, train_loss = 1.2506984795327298, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 213, train_loss = 1.248514483391773, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 214, train_loss = 1.2460571601986885, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 215, train_loss = 1.2443863973021507, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 216, train_loss = 1.2421744664316066, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 217, train_loss = 1.2401213931734674, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 218, train_loss = 1.2382817355100997, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 219, train_loss = 1.236294825852383, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 220, train_loss = 1.233912866562605, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 221, train_loss = 1.2324479557573795, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 222, train_loss = 1.2303995117545128, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 223, train_loss = 1.2283876103465445, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 224, train_loss = 1.2264150765840895, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 225, train_loss = 1.2246171061997302, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 226, train_loss = 1.2228432819247246, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 227, train_loss = 1.2204212074284442, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 228, train_loss = 1.218820545822382, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 229, train_loss = 1.2169056360726245, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 230, train_loss = 1.2151833027601242, train_acc = 0.9973218444340941\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 231, train_loss = 1.213055117696058, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 232, train_loss = 1.2115019771154039, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 233, train_loss = 1.2100143122370355, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 234, train_loss = 1.2080510507221334, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 235, train_loss = 1.2061533729429357, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 236, train_loss = 1.2047922958736308, train_acc = 0.9973218444340941\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 237, train_loss = 1.2020953185856342, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 238, train_loss = 1.2003965079784393, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 239, train_loss = 1.1984814393217675, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 240, train_loss = 1.1966168880462646, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 241, train_loss = 1.194988006085623, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 242, train_loss = 1.1931377537548542, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 243, train_loss = 1.191273485601414, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 244, train_loss = 1.1894302405416965, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 245, train_loss = 1.187851199239958, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 246, train_loss = 1.186635572463274, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 247, train_loss = 1.1847128396038897, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 248, train_loss = 1.1830727569758892, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 249, train_loss = 1.18178841721965, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 250, train_loss = 1.180042055726517, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 251, train_loss = 1.1786831878125668, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 252, train_loss = 1.1768868677318096, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 253, train_loss = 1.175139419734478, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 254, train_loss = 1.1736259472672828, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 255, train_loss = 1.1721137699787505, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 256, train_loss = 1.1708970293402672, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 257, train_loss = 1.1695393646950833, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 258, train_loss = 1.1675370906596072, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 259, train_loss = 1.1664995538885705, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 260, train_loss = 1.1653256018762477, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 261, train_loss = 1.1634594202041626, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 262, train_loss = 1.162324957549572, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 263, train_loss = 1.1606523332302459, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 264, train_loss = 1.1594191789627075, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 265, train_loss = 1.1579331693355925, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 266, train_loss = 1.1565815868671052, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 267, train_loss = 1.155013122886885, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 268, train_loss = 1.1540036238729954, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 269, train_loss = 1.1525755661423318, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 270, train_loss = 1.1510206100647338, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 271, train_loss = 1.1496609288151376, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 272, train_loss = 1.1484924567048438, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 273, train_loss = 1.1469218954443932, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 274, train_loss = 1.1460282641346566, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 275, train_loss = 1.144454751163721, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 276, train_loss = 1.1432290188968182, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 277, train_loss = 1.1417870111763477, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 278, train_loss = 1.1405548962648027, train_acc = 0.9974382859804378\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 279, train_loss = 1.1393317878246307, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 280, train_loss = 1.1382175547187217, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 281, train_loss = 1.1368888542056084, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 282, train_loss = 1.1360145782236941, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 283, train_loss = 1.1339698806405067, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 284, train_loss = 1.133140217512846, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 285, train_loss = 1.1320209639961831, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 286, train_loss = 1.130587684630882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 287, train_loss = 1.1292931486968882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 288, train_loss = 1.1283556098933332, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 289, train_loss = 1.1272313545341603, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 290, train_loss = 1.1257531593437307, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 291, train_loss = 1.1249546843464486, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 292, train_loss = 1.1231983217294328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 293, train_loss = 1.1225304491817951, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 294, train_loss = 1.120969581126701, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 295, train_loss = 1.1202059797942638, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 296, train_loss = 1.1191479675471783, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 297, train_loss = 1.1178525015711784, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 298, train_loss = 1.1165724036400206, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 299, train_loss = 1.1153358754818328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 300, train_loss = 1.1141334722633474, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 301, train_loss = 1.1133006140589714, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 302, train_loss = 1.1119728771154769, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 303, train_loss = 1.1112538154120557, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 304, train_loss = 1.1099508230690844, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 305, train_loss = 1.1089100216631778, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 306, train_loss = 1.1077734542195685, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 307, train_loss = 1.1065224694903009, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 308, train_loss = 1.105534856498707, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 309, train_loss = 1.10450965288328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 310, train_loss = 1.1035171772236936, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 311, train_loss = 1.1027719651756343, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 312, train_loss = 1.101465010404354, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 313, train_loss = 1.1002807393670082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 314, train_loss = 1.0988945277931634, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 315, train_loss = 1.0979727568628732, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 316, train_loss = 1.0969807468354702, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 317, train_loss = 1.0958636043069419, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 318, train_loss = 1.0946191710827406, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 319, train_loss = 1.093817912042141, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 320, train_loss = 1.0926702680590097, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 321, train_loss = 1.0914265178143978, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 322, train_loss = 1.0906296061875764, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 323, train_loss = 1.0893691629171371, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 324, train_loss = 1.0882761714456137, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 325, train_loss = 1.0874998147191945, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 326, train_loss = 1.0863041281700134, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 327, train_loss = 1.0852529344556388, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 328, train_loss = 1.0844815385935362, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 329, train_loss = 1.0830324962735176, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 330, train_loss = 1.0824607858958188, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 331, train_loss = 1.0816915022733156, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 332, train_loss = 1.0805655544099864, train_acc = 0.9974382859804378\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 333, train_loss = 1.0794810988008976, train_acc = 0.9974382859804378\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 334, train_loss = 1.078842107206583, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 335, train_loss = 1.0777907110750675, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 336, train_loss = 1.0769612304866314, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 337, train_loss = 1.07607963681221, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 338, train_loss = 1.075616112590069, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 339, train_loss = 1.0741026612522546, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 340, train_loss = 1.0734846740961075, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 341, train_loss = 1.0719992940721568, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 342, train_loss = 1.0714589394629002, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 343, train_loss = 1.0699778174457606, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 344, train_loss = 1.0691793064179365, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 345, train_loss = 1.0686812164785806, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 346, train_loss = 1.0674599570629653, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 347, train_loss = 1.0668803552689496, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 348, train_loss = 1.0655764515104238, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 349, train_loss = 1.0649681302311365, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 350, train_loss = 1.0641126880946103, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 351, train_loss = 1.063251511513954, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 352, train_loss = 1.0620901361107826, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 353, train_loss = 1.0613228529691696, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 354, train_loss = 1.0603984147310257, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 355, train_loss = 1.0593646106717642, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 356, train_loss = 1.0587657690048218, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 357, train_loss = 1.0580361858010292, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 358, train_loss = 1.0570968737301882, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 359, train_loss = 1.0562365328369197, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 360, train_loss = 1.0555036018195096, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 361, train_loss = 1.0546550502476748, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 362, train_loss = 1.0537706675531808, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 363, train_loss = 1.0532087956962641, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 364, train_loss = 1.0520006157457829, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 365, train_loss = 1.05164453634643, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 366, train_loss = 1.0506990626454353, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 367, train_loss = 1.0498406241240446, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 368, train_loss = 1.0493434319796506, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 369, train_loss = 1.0482791177928448, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 370, train_loss = 1.0476641865971033, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 371, train_loss = 1.0469168573617935, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 372, train_loss = 1.045943509787321, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 373, train_loss = 1.0457146242260933, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 374, train_loss = 1.0446768018009607, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 375, train_loss = 1.0440800724027213, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 376, train_loss = 1.04285148033523, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 377, train_loss = 1.0424221667053644, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 378, train_loss = 1.0415689870715141, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 379, train_loss = 1.0403044621052686, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 380, train_loss = 1.0404011656937655, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 381, train_loss = 1.038921063154703, train_acc = 0.9975547275267815\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 382, train_loss = 1.0380864503385965, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 383, train_loss = 1.037585873156786, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 384, train_loss = 1.0366945949790534, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 385, train_loss = 1.0359137070772704, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 386, train_loss = 1.0351981967687607, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 387, train_loss = 1.0346087838115636, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 388, train_loss = 1.0337517224252224, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 389, train_loss = 1.0331750574114267, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 390, train_loss = 1.0322290273907129, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 391, train_loss = 1.0316618978977203, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 392, train_loss = 1.0311174839735031, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 393, train_loss = 1.030096396803856, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 394, train_loss = 1.0296670272946358, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 395, train_loss = 1.0286337286233902, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 396, train_loss = 1.0281382352113724, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 397, train_loss = 1.0277652814984322, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 398, train_loss = 1.0266950950026512, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 399, train_loss = 1.0259747579693794, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 400, train_loss = 1.0251751902105752, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 401, train_loss = 1.0251719901862089, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 402, train_loss = 1.0240907656552736, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 403, train_loss = 1.022965574025875, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 404, train_loss = 1.0225535059871618, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 405, train_loss = 1.021905843168497, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 406, train_loss = 1.0212409608066082, train_acc = 0.9975547275267815\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 407, train_loss = 1.020602817327017, train_acc = 0.9976711690731253\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 408, train_loss = 1.0201367686095182, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 409, train_loss = 1.019244638591772, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 410, train_loss = 1.0188169615867082, train_acc = 0.9975547275267815\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 411, train_loss = 1.0178389387729112, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 412, train_loss = 1.0174745209515095, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 413, train_loss = 1.016539024800295, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 414, train_loss = 1.0159699296054896, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 415, train_loss = 1.0154573805630207, train_acc = 0.9976711690731253\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 416, train_loss = 1.014595627784729, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 417, train_loss = 1.0140643951890524, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 418, train_loss = 1.0133024478855077, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 419, train_loss = 1.012724901229376, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 420, train_loss = 1.0121123107674066, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 421, train_loss = 1.0111545311810914, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 422, train_loss = 1.0107888331112918, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 423, train_loss = 1.010137608885998, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 424, train_loss = 1.0094286538660526, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 425, train_loss = 1.0084506174025591, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 426, train_loss = 1.0080408975481987, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 427, train_loss = 1.0070631193520967, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 428, train_loss = 1.0064771907927934, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 429, train_loss = 1.006235101580387, train_acc = 0.9977876106194691\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 430, train_loss = 1.0054926872253418, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 431, train_loss = 1.0047121867537498, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 432, train_loss = 1.004060192644829, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 433, train_loss = 1.0031618289649487, train_acc = 0.9976711690731253\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 434, train_loss = 1.0023945470748004, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 435, train_loss = 1.0021262168884277, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 436, train_loss = 1.000984708458418, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 437, train_loss = 1.0010039533080999, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 438, train_loss = 1.0003535238502081, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 439, train_loss = 0.999708471208578, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 440, train_loss = 0.9991913537087385, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 441, train_loss = 0.9984465017914772, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 442, train_loss = 0.9975329289736692, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 443, train_loss = 0.9973500383493956, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 444, train_loss = 0.9972385428845882, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 445, train_loss = 0.9960107555089053, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 446, train_loss = 0.9954282070102636, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 447, train_loss = 0.9951831301150378, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 448, train_loss = 0.9942487055959646, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 449, train_loss = 0.9935249524714891, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 450, train_loss = 0.9930868869123515, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 451, train_loss = 0.9926552561519202, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 452, train_loss = 0.9926392249763012, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 453, train_loss = 0.9916460501553956, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 454, train_loss = 0.9912928479316179, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 455, train_loss = 0.9906010677514132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 456, train_loss = 0.9900105111300945, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 457, train_loss = 0.9897443937661592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 458, train_loss = 0.9892878085374832, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 459, train_loss = 0.9887557899055537, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 460, train_loss = 0.9883415214717388, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 461, train_loss = 0.9873268070223276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 462, train_loss = 0.9872449388203677, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 463, train_loss = 0.9863929226994514, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 464, train_loss = 0.9858878043887671, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 465, train_loss = 0.9852184765040874, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 466, train_loss = 0.9847571961581707, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 467, train_loss = 0.9844839212892111, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 468, train_loss = 0.9839001633226871, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 469, train_loss = 0.9833071008324623, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 470, train_loss = 0.9825276943447534, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 471, train_loss = 0.9827356239256915, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 472, train_loss = 0.9814560785889626, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 473, train_loss = 0.9812346833350603, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 474, train_loss = 0.980707156151766, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 475, train_loss = 0.980192950606579, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 476, train_loss = 0.9794920397398528, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 477, train_loss = 0.979604317486519, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 478, train_loss = 0.9785832563939039, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 479, train_loss = 0.9781244223413523, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 480, train_loss = 0.977986566722393, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 481, train_loss = 0.9771752220985945, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 482, train_loss = 0.976455961674219, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 483, train_loss = 0.9760505197045859, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 484, train_loss = 0.9758952719566878, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 485, train_loss = 0.9747065231204033, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 486, train_loss = 0.9747992716729641, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 487, train_loss = 0.9740314036607742, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 488, train_loss = 0.9736281198856886, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 489, train_loss = 0.9729139097034931, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 490, train_loss = 0.9724567557277624, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 491, train_loss = 0.9723832632007543, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 492, train_loss = 0.9716761633753777, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 493, train_loss = 0.9707377925515175, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 494, train_loss = 0.9705289627017919, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 495, train_loss = 0.9696988649666309, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 496, train_loss = 0.970108018576866, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 497, train_loss = 0.9691576498153154, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 498, train_loss = 0.9682989940047264, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 499, train_loss = 0.9683446722629014, train_acc = 0.9977876106194691\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████            | 25/30 [4:09:43<50:01, 600.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "26th- epoch: 0, train_loss = 138.4163089543581, train_acc = 0.7509315323707498\n",
      "test Acc 0.8421787709497207:\n",
      "26th- epoch: 1, train_loss = 51.692580722272396, train_acc = 0.8910107126222636\n",
      "test Acc 0.9013035381750466:\n",
      "26th- epoch: 2, train_loss = 36.779625091701746, train_acc = 0.922100605496041\n",
      "test Acc 0.9222532588454376:\n",
      "26th- epoch: 3, train_loss = 29.004756432026625, train_acc = 0.9386353050768514\n",
      "test Acc 0.9301675977653632:\n",
      "26th- epoch: 4, train_loss = 24.08485385030508, train_acc = 0.9494643688868188\n",
      "test Acc 0.936219739292365:\n",
      "26th- epoch: 5, train_loss = 20.68077564239502, train_acc = 0.9583139264089428\n",
      "test Acc 0.9390130353817505:\n",
      "26th- epoch: 6, train_loss = 18.13653303310275, train_acc = 0.9636702375407545\n",
      "test Acc 0.9427374301675978:\n",
      "26th- epoch: 7, train_loss = 16.16062095761299, train_acc = 0.9676292501164415\n",
      "test Acc 0.9455307262569832:\n",
      "26th- epoch: 8, train_loss = 14.579467134550214, train_acc = 0.9710060549604099\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 9, train_loss = 13.282631292939186, train_acc = 0.9743828598043782\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 10, train_loss = 12.193023554980755, train_acc = 0.9769445738239404\n",
      "test Acc 0.952048417132216:\n",
      "26th- epoch: 11, train_loss = 11.261053608730435, train_acc = 0.9783418723800652\n",
      "test Acc 0.9534450651769087:\n",
      "26th- epoch: 12, train_loss = 10.458117216825485, train_acc = 0.9799720540288775\n",
      "test Acc 0.9553072625698324:\n",
      "26th- epoch: 13, train_loss = 9.753632152453065, train_acc = 0.9816022356776898\n",
      "test Acc 0.957169459962756:\n",
      "26th- epoch: 14, train_loss = 9.13267263583839, train_acc = 0.9824173265020959\n",
      "test Acc 0.957169459962756:\n",
      "26th- epoch: 15, train_loss = 8.582235736772418, train_acc = 0.983698183511877\n",
      "test Acc 0.957169459962756:\n",
      "26th- epoch: 16, train_loss = 8.098514894023538, train_acc = 0.9849790405216581\n",
      "test Acc 0.957635009310987:\n",
      "26th- epoch: 17, train_loss = 7.659034613519907, train_acc = 0.9857941313460643\n",
      "test Acc 0.9585661080074488:\n",
      "26th- epoch: 18, train_loss = 7.26336520537734, train_acc = 0.9874243129948765\n",
      "test Acc 0.9581005586592178:\n",
      "26th- epoch: 19, train_loss = 6.903332092799246, train_acc = 0.9882394038192828\n",
      "test Acc 0.9599627560521415:\n",
      "26th- epoch: 20, train_loss = 6.57991886138916, train_acc = 0.9885887284583139\n",
      "test Acc 0.9608938547486033:\n",
      "26th- epoch: 21, train_loss = 6.287038430571556, train_acc = 0.98940381928272\n",
      "test Acc 0.9604283054003724:\n",
      "26th- epoch: 22, train_loss = 6.01806251052767, train_acc = 0.9897531439217513\n",
      "test Acc 0.9613594040968343:\n",
      "26th- epoch: 23, train_loss = 5.768833577632904, train_acc = 0.9902189101071263\n",
      "test Acc 0.9618249534450651:\n",
      "26th- epoch: 24, train_loss = 5.5414881175383925, train_acc = 0.9906846762925011\n",
      "test Acc 0.9618249534450651:\n",
      "26th- epoch: 25, train_loss = 5.329975890927017, train_acc = 0.9911504424778761\n",
      "test Acc 0.9641527001862198:\n",
      "26th- epoch: 26, train_loss = 5.1343447072431445, train_acc = 0.9914997671169073\n",
      "test Acc 0.9655493482309124:\n",
      "26th- epoch: 27, train_loss = 4.952345984987915, train_acc = 0.9918490917559385\n",
      "test Acc 0.9660148975791434:\n",
      "26th- epoch: 28, train_loss = 4.779415030963719, train_acc = 0.9919655333022822\n",
      "test Acc 0.9660148975791434:\n",
      "26th- epoch: 29, train_loss = 4.6234047040343285, train_acc = 0.9924312994876572\n",
      "test Acc 0.9674115456238361:\n",
      "26th- epoch: 30, train_loss = 4.473945059813559, train_acc = 0.9928970656730322\n",
      "test Acc 0.9674115456238361:\n",
      "26th- epoch: 31, train_loss = 4.336655645631254, train_acc = 0.9930135072193759\n",
      "test Acc 0.9674115456238361:\n",
      "26th- epoch: 32, train_loss = 4.206080940552056, train_acc = 0.9931299487657196\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 33, train_loss = 4.085197338834405, train_acc = 0.9933628318584071\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 34, train_loss = 3.968852009624243, train_acc = 0.9939450395901258\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 35, train_loss = 3.863248473033309, train_acc = 0.9941779226828132\n",
      "test Acc 0.9688081936685289:\n",
      "26th- epoch: 36, train_loss = 3.7608829238452017, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 37, train_loss = 3.665802612900734, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 38, train_loss = 3.5773128517903388, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 39, train_loss = 3.4925887137651443, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 40, train_loss = 3.413627883885056, train_acc = 0.9949930135072194\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 41, train_loss = 3.3391736610792577, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 42, train_loss = 3.2687495299614966, train_acc = 0.9951094550535631\n",
      "test Acc 0.9697392923649907:\n",
      "26th- epoch: 43, train_loss = 3.199909461196512, train_acc = 0.9953423381462506\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 44, train_loss = 3.1370285898447037, train_acc = 0.9952258965999069\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 45, train_loss = 3.075743291527033, train_acc = 0.9956916627852818\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 46, train_loss = 3.0175071731209755, train_acc = 0.9956916627852818\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 47, train_loss = 2.9625850468873978, train_acc = 0.9956916627852818\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 48, train_loss = 2.9105998314917088, train_acc = 0.9956916627852818\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 49, train_loss = 2.860834603663534, train_acc = 0.9958081043316255\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 50, train_loss = 2.8146194047294557, train_acc = 0.9959245458779693\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 51, train_loss = 2.769565485417843, train_acc = 0.9959245458779693\n",
      "test Acc 0.9706703910614525:\n",
      "26th- epoch: 52, train_loss = 2.727785518858582, train_acc = 0.9959245458779693\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 53, train_loss = 2.68474974995479, train_acc = 0.9959245458779693\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 54, train_loss = 2.6466940282844007, train_acc = 0.996040987424313\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 55, train_loss = 2.6091199382208288, train_acc = 0.996040987424313\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 56, train_loss = 2.5730804689228535, train_acc = 0.996040987424313\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 57, train_loss = 2.5384799353778362, train_acc = 0.996040987424313\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 58, train_loss = 2.5044626495800912, train_acc = 0.9961574289706567\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 59, train_loss = 2.4733840599656105, train_acc = 0.9963903120633442\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 60, train_loss = 2.4415297731757164, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "26th- epoch: 61, train_loss = 2.411895123543218, train_acc = 0.9963903120633442\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 62, train_loss = 2.3834329445380718, train_acc = 0.9963903120633442\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 63, train_loss = 2.355138427345082, train_acc = 0.9963903120633442\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 64, train_loss = 2.3268435783684254, train_acc = 0.9962738705170004\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 65, train_loss = 2.300954931648448, train_acc = 0.9962738705170004\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 66, train_loss = 2.275598854990676, train_acc = 0.9962738705170004\n",
      "test Acc 0.9720670391061452:\n",
      "26th- epoch: 67, train_loss = 2.2508941255509853, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "26th- epoch: 68, train_loss = 2.2274142268579453, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "26th- epoch: 69, train_loss = 2.203921050997451, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "26th- epoch: 70, train_loss = 2.1818842601496726, train_acc = 0.9963903120633442\n",
      "test Acc 0.9720670391061452:\n",
      "26th- epoch: 71, train_loss = 2.160198150901124, train_acc = 0.9963903120633442\n",
      "test Acc 0.9725325884543762:\n",
      "26th- epoch: 72, train_loss = 2.1396479334216565, train_acc = 0.9963903120633442\n",
      "test Acc 0.9725325884543762:\n",
      "26th- epoch: 73, train_loss = 2.1191040724515915, train_acc = 0.996506753609688\n",
      "test Acc 0.9725325884543762:\n",
      "26th- epoch: 74, train_loss = 2.0998646914958954, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "26th- epoch: 75, train_loss = 2.0813190292101353, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 76, train_loss = 2.0626699563581496, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 77, train_loss = 2.0452124576549977, train_acc = 0.9967396367023754\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 78, train_loss = 2.0274831119459122, train_acc = 0.9967396367023754\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 79, train_loss = 2.010115784825757, train_acc = 0.9967396367023754\n",
      "test Acc 0.9739292364990689:\n",
      "26th- epoch: 80, train_loss = 1.9945547108072788, train_acc = 0.9967396367023754\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 81, train_loss = 1.9789224390406162, train_acc = 0.9967396367023754\n",
      "test Acc 0.9739292364990689:\n",
      "26th- epoch: 82, train_loss = 1.9628829199355096, train_acc = 0.9968560782487191\n",
      "test Acc 0.9739292364990689:\n",
      "26th- epoch: 83, train_loss = 1.9483199566602707, train_acc = 0.9968560782487191\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 84, train_loss = 1.93405940127559, train_acc = 0.9968560782487191\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 85, train_loss = 1.9197966903448105, train_acc = 0.9968560782487191\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 86, train_loss = 1.9055579837877303, train_acc = 0.9968560782487191\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 87, train_loss = 1.892667592735961, train_acc = 0.9969725197950629\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 88, train_loss = 1.8789706316310912, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 89, train_loss = 1.8661418135743588, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 90, train_loss = 1.8541616797447205, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 91, train_loss = 1.8415207404177636, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 92, train_loss = 1.829607269493863, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 93, train_loss = 1.8183430272620171, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 94, train_loss = 1.8070729200262576, train_acc = 0.9972054028877504\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 95, train_loss = 1.7956319425720721, train_acc = 0.9972054028877504\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 96, train_loss = 1.785096898674965, train_acc = 0.9972054028877504\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 97, train_loss = 1.7741642456967384, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 98, train_loss = 1.7634279828052968, train_acc = 0.9972054028877504\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 99, train_loss = 1.7541064720135182, train_acc = 0.9972054028877504\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 100, train_loss = 1.743607111275196, train_acc = 0.9972054028877504\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 101, train_loss = 1.7337622058112174, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 102, train_loss = 1.7245973646640778, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 103, train_loss = 1.7151692013721913, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 104, train_loss = 1.706105331541039, train_acc = 0.9972054028877504\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 105, train_loss = 1.696853137225844, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 106, train_loss = 1.6884007850894704, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 107, train_loss = 1.6800936497747898, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 108, train_loss = 1.6714984948048368, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 109, train_loss = 1.6636902429163456, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 110, train_loss = 1.6551094589522108, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 111, train_loss = 1.647862815647386, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 112, train_loss = 1.6398847611853853, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 113, train_loss = 1.6320713957538828, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 114, train_loss = 1.6248422065982595, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 115, train_loss = 1.6172626428306103, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 116, train_loss = 1.6098834624281153, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 117, train_loss = 1.6026340672979131, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 118, train_loss = 1.5964694420108572, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 119, train_loss = 1.589186223805882, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 120, train_loss = 1.5822977101197466, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 121, train_loss = 1.5763947727391496, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 122, train_loss = 1.5693171607563272, train_acc = 0.9972054028877504\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 123, train_loss = 1.5629590699682012, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 124, train_loss = 1.5575584346661344, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 125, train_loss = 1.550228496431373, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 126, train_loss = 1.5448657585075125, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 127, train_loss = 1.5386099157622084, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 128, train_loss = 1.532335575670004, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 129, train_loss = 1.526816003024578, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 130, train_loss = 1.5213041180977598, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 131, train_loss = 1.5151202963897958, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 132, train_loss = 1.5104228953132406, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 133, train_loss = 1.50412740430329, train_acc = 0.9973218444340941\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 134, train_loss = 1.4995297119021416, train_acc = 0.9973218444340941\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 135, train_loss = 1.4939812906086445, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 136, train_loss = 1.4888228625059128, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 137, train_loss = 1.4835996689507738, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 138, train_loss = 1.4780302122235298, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 139, train_loss = 1.4735021205851808, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 140, train_loss = 1.4684001803398132, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 141, train_loss = 1.4640824683010578, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 142, train_loss = 1.459076251834631, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 143, train_loss = 1.4540524544427171, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 144, train_loss = 1.4495905712246895, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 145, train_loss = 1.4441966377198696, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 146, train_loss = 1.44079662731383, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 147, train_loss = 1.4358698800206184, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 148, train_loss = 1.4314529933035374, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 149, train_loss = 1.4275353215634823, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 150, train_loss = 1.42246188595891, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 151, train_loss = 1.418952283798717, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 152, train_loss = 1.4135207161307335, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 153, train_loss = 1.410341185866855, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 154, train_loss = 1.4048620263347402, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 155, train_loss = 1.402318648993969, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 156, train_loss = 1.3970458632102236, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 157, train_loss = 1.3935306767234579, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 158, train_loss = 1.3892446868121624, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 159, train_loss = 1.3862391225993633, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 160, train_loss = 1.3815378099679947, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 161, train_loss = 1.3784491531550884, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 162, train_loss = 1.3743748093256727, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 163, train_loss = 1.3706897335359827, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 164, train_loss = 1.3666292876005173, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 165, train_loss = 1.3637052588164806, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 166, train_loss = 1.359244121820666, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 167, train_loss = 1.356110766530037, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 168, train_loss = 1.3523611662676558, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 169, train_loss = 1.3490774929523468, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 170, train_loss = 1.345734483213164, train_acc = 0.9973218444340941\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 171, train_loss = 1.341599831939675, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 172, train_loss = 1.3389550931751728, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 173, train_loss = 1.3355128517141566, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 174, train_loss = 1.3322010338306427, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 175, train_loss = 1.3287402639398351, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 176, train_loss = 1.3258387570385821, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 177, train_loss = 1.322445662051905, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 178, train_loss = 1.3193325363099575, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 179, train_loss = 1.3163786940276623, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 180, train_loss = 1.3127836510539055, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 181, train_loss = 1.3102556194062345, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 182, train_loss = 1.307438738644123, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 183, train_loss = 1.303842178254854, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 184, train_loss = 1.3011270239949226, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 185, train_loss = 1.2984677106142044, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 186, train_loss = 1.2954991633887403, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 187, train_loss = 1.292987270921003, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 188, train_loss = 1.2892640481586568, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 189, train_loss = 1.2871976581518538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 190, train_loss = 1.2842836628551595, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 191, train_loss = 1.2816106702084653, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 192, train_loss = 1.2787284304504283, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 193, train_loss = 1.276167619973421, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 194, train_loss = 1.2736221700906754, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 195, train_loss = 1.271252537786495, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 196, train_loss = 1.2680371713940986, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 197, train_loss = 1.2658686551149003, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 198, train_loss = 1.26347566395998, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 199, train_loss = 1.2607607145910151, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 200, train_loss = 1.2579533345997334, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 201, train_loss = 1.2561601648922078, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 202, train_loss = 1.2534873746335506, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 203, train_loss = 1.251202143728733, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 204, train_loss = 1.248817863583099, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 205, train_loss = 1.2466451662476175, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 206, train_loss = 1.24452644091798, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 207, train_loss = 1.2415645606815815, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 208, train_loss = 1.239333774894476, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 209, train_loss = 1.2371798418462276, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 210, train_loss = 1.235017451166641, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 211, train_loss = 1.2329723027651198, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 212, train_loss = 1.2304746421868913, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 213, train_loss = 1.2281406956608407, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 214, train_loss = 1.226706374436617, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 215, train_loss = 1.2236863623256795, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 216, train_loss = 1.2218476732377894, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 217, train_loss = 1.2202679638867266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 218, train_loss = 1.2180224806070328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 219, train_loss = 1.2153521180152893, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 220, train_loss = 1.2142262111301534, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 221, train_loss = 1.211323821276892, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 222, train_loss = 1.2098505310714245, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 223, train_loss = 1.2080845944583416, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 224, train_loss = 1.2055731937289238, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 225, train_loss = 1.2035186837310903, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 226, train_loss = 1.2019707038998604, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 227, train_loss = 1.200085636228323, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 228, train_loss = 1.1977281023864634, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 229, train_loss = 1.196493285417091, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 230, train_loss = 1.1940944232046604, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 231, train_loss = 1.192363118112553, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 232, train_loss = 1.1903528198599815, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 233, train_loss = 1.1887938442523591, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 234, train_loss = 1.1865290912683122, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 235, train_loss = 1.184906133741606, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 236, train_loss = 1.1829751655459404, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 237, train_loss = 1.1812358548049815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 238, train_loss = 1.1798502691090107, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 239, train_loss = 1.1778047792613506, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 240, train_loss = 1.1764788503642194, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 241, train_loss = 1.1738557455246337, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 242, train_loss = 1.1730492276255973, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 243, train_loss = 1.1710190537269227, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 244, train_loss = 1.1690864289994352, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 245, train_loss = 1.1679376375977881, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 246, train_loss = 1.1661651134490967, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 247, train_loss = 1.164062691212166, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 248, train_loss = 1.1625361442565918, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 249, train_loss = 1.161674561619293, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 250, train_loss = 1.1591102654929273, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 251, train_loss = 1.1580615590210073, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 252, train_loss = 1.1565314668114297, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 253, train_loss = 1.1545404195785522, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 254, train_loss = 1.1532200537621975, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 255, train_loss = 1.151679366827011, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 256, train_loss = 1.149322344630491, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 257, train_loss = 1.1485755977337249, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 258, train_loss = 1.1474125075037591, train_acc = 0.9975547275267815\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 259, train_loss = 1.1456479579210281, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 260, train_loss = 1.1437396270339377, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 261, train_loss = 1.1427947518532164, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 262, train_loss = 1.1412791907787323, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 263, train_loss = 1.1394870492513292, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 264, train_loss = 1.1381080895662308, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 265, train_loss = 1.136695661873091, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 266, train_loss = 1.1351904434268363, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 267, train_loss = 1.1337080125813372, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 268, train_loss = 1.1325839795172215, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 269, train_loss = 1.1314213052392006, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 270, train_loss = 1.1293426540796645, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 271, train_loss = 1.12801418825984, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 272, train_loss = 1.1270416167681105, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 273, train_loss = 1.1260414024000056, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 274, train_loss = 1.1240190751850605, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 275, train_loss = 1.1227855433826335, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 276, train_loss = 1.1215976538951509, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 277, train_loss = 1.120019098103512, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 278, train_loss = 1.1190726694767363, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 279, train_loss = 1.117931890010368, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 280, train_loss = 1.1159504788811319, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 281, train_loss = 1.115043830126524, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 282, train_loss = 1.113912995904684, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 283, train_loss = 1.1124206620152108, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 284, train_loss = 1.1113622685079463, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 285, train_loss = 1.109837585419882, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 286, train_loss = 1.1088358375127427, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 287, train_loss = 1.1071948533062823, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 288, train_loss = 1.1062044203281403, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 289, train_loss = 1.1046154176001437, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 290, train_loss = 1.1039497281308286, train_acc = 0.9975547275267815\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 291, train_loss = 1.1023000690038316, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 292, train_loss = 1.1017319411039352, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 293, train_loss = 1.0998593631084077, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 294, train_loss = 1.099124291271437, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 295, train_loss = 1.0973355050082318, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 296, train_loss = 1.0964521678979509, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 297, train_loss = 1.0955682669882663, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 298, train_loss = 1.0944557711482048, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 299, train_loss = 1.0931497253477573, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 300, train_loss = 1.0916846108739264, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 301, train_loss = 1.0905886441469193, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 302, train_loss = 1.0893632036750205, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 303, train_loss = 1.0888368201558478, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 304, train_loss = 1.087323073297739, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 305, train_loss = 1.0858654901385307, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 306, train_loss = 1.0852749198675156, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 307, train_loss = 1.0837369908986147, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 308, train_loss = 1.082796860486269, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 309, train_loss = 1.0822165211138781, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 310, train_loss = 1.0807724222540855, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 311, train_loss = 1.079588462918764, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 312, train_loss = 1.078506472200388, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 313, train_loss = 1.0773858962056693, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 314, train_loss = 1.0763773769140244, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 315, train_loss = 1.0753892945649568, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 316, train_loss = 1.074958000332117, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 317, train_loss = 1.0734637392160948, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 318, train_loss = 1.0723150297999382, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 319, train_loss = 1.071314450353384, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 320, train_loss = 1.070233792066574, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 321, train_loss = 1.0699254497885704, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 322, train_loss = 1.067983998596901, train_acc = 0.9976711690731253\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 323, train_loss = 1.0671482222678605, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 324, train_loss = 1.0663407680985983, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 325, train_loss = 1.0652116127312183, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 326, train_loss = 1.064423829317093, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 327, train_loss = 1.0632278049888555, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 328, train_loss = 1.062620917946333, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 329, train_loss = 1.0610016038117465, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 330, train_loss = 1.0604898681340273, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 331, train_loss = 1.058926368743414, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 332, train_loss = 1.0586011037230492, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 333, train_loss = 1.0579817481338978, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 334, train_loss = 1.0564502216875553, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 335, train_loss = 1.0556689985096455, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 336, train_loss = 1.0543504456582014, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 337, train_loss = 1.0534458433685359, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 338, train_loss = 1.0523730131390039, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 339, train_loss = 1.0519307504000608, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 340, train_loss = 1.0510271651146468, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 341, train_loss = 1.0498237175343093, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 342, train_loss = 1.0485523852112237, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 343, train_loss = 1.048406538873678, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 344, train_loss = 1.047696122288471, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 345, train_loss = 1.046022355556488, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 346, train_loss = 1.0452570989727974, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 347, train_loss = 1.0446285394427832, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 348, train_loss = 1.0433716960251331, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 349, train_loss = 1.0429640089569148, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 350, train_loss = 1.041571414709324, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 351, train_loss = 1.0409918613731861, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 352, train_loss = 1.0405415557324886, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 353, train_loss = 1.0390128952858504, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 354, train_loss = 1.038935045391554, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 355, train_loss = 1.0374266915023327, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 356, train_loss = 1.0365744357404765, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 357, train_loss = 1.036033246666193, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 358, train_loss = 1.0350963162782136, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 359, train_loss = 1.034303398191696, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 360, train_loss = 1.0335865827801172, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 361, train_loss = 1.0323827949760016, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 362, train_loss = 1.031601082533598, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 363, train_loss = 1.0310024358332157, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 364, train_loss = 1.0300349431636278, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 365, train_loss = 1.0292588149604853, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 366, train_loss = 1.0288978517055511, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 367, train_loss = 1.027458200842375, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 368, train_loss = 1.0268901462259237, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 369, train_loss = 1.0261930214765016, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 370, train_loss = 1.0251180554332677, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 371, train_loss = 1.0242824355664197, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 372, train_loss = 1.024318940937519, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 373, train_loss = 1.0225682010350283, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 374, train_loss = 1.0220142019388732, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 375, train_loss = 1.0213505389692727, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 376, train_loss = 1.0206426456570625, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 377, train_loss = 1.019758259266382, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 378, train_loss = 1.0191776988503989, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 379, train_loss = 1.017968034982914, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 380, train_loss = 1.0177720375359058, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 381, train_loss = 1.0167013791797217, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 382, train_loss = 1.0158616503176745, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 383, train_loss = 1.0149390374717768, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 384, train_loss = 1.0147540718317032, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 385, train_loss = 1.0138718597590923, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 386, train_loss = 1.0126225650310516, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 387, train_loss = 1.0124669633805752, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 388, train_loss = 1.0115028992295265, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 389, train_loss = 1.011150370031828, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 390, train_loss = 1.0100659219024237, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 391, train_loss = 1.0094976872205734, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 392, train_loss = 1.0087324654159602, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 393, train_loss = 1.0079001175763551, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 394, train_loss = 1.0072705621423665, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 395, train_loss = 1.0070523781178053, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 396, train_loss = 1.0059259794652462, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 397, train_loss = 1.0050822223129217, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 398, train_loss = 1.004552493483061, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 399, train_loss = 1.0036776401102543, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 400, train_loss = 1.0031821789743844, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 401, train_loss = 1.002251255005831, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 402, train_loss = 1.002127771585947, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 403, train_loss = 1.0011886122229043, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 404, train_loss = 1.0007165310380515, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 405, train_loss = 0.9999012860062066, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 406, train_loss = 0.9993033719656523, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 407, train_loss = 0.9982953754661139, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 408, train_loss = 0.9980202639999334, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 409, train_loss = 0.9969745601119939, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 410, train_loss = 0.9967852669360582, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 411, train_loss = 0.9957375153899193, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 412, train_loss = 0.9948880672454834, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 413, train_loss = 0.9948392597434577, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 414, train_loss = 0.993718115001684, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 415, train_loss = 0.9932396995427553, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 416, train_loss = 0.9926747654972132, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 417, train_loss = 0.9919138116238173, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 418, train_loss = 0.991804551333189, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 419, train_loss = 0.9909548796713352, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 420, train_loss = 0.9899990484118462, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 421, train_loss = 0.9894353499112185, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 422, train_loss = 0.988952063024044, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 423, train_loss = 0.9883992175164167, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 424, train_loss = 0.9878609105944633, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 425, train_loss = 0.986972084880108, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 426, train_loss = 0.9868737558426801, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 427, train_loss = 0.985912491887575, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 428, train_loss = 0.9851281816663686, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 429, train_loss = 0.9848583526909351, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 430, train_loss = 0.9839865068497602, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 431, train_loss = 0.9838775520620402, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 432, train_loss = 0.9827181237342302, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 433, train_loss = 0.9823159848747309, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 434, train_loss = 0.9815379554929677, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 435, train_loss = 0.981239527463913, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 436, train_loss = 0.9806342509982642, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 437, train_loss = 0.9799617230892181, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 438, train_loss = 0.9789628957805689, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 439, train_loss = 0.9787925581040327, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 440, train_loss = 0.9781497580406722, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 441, train_loss = 0.9776960512099322, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 442, train_loss = 0.9768615017237607, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 443, train_loss = 0.9763317021133844, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 444, train_loss = 0.9761243276298046, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 445, train_loss = 0.9754908519389573, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 446, train_loss = 0.9749528206884861, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 447, train_loss = 0.9741504217090551, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 448, train_loss = 0.9733954133989755, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 449, train_loss = 0.973843472689623, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 450, train_loss = 0.9725467984972056, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 451, train_loss = 0.9718635802564677, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 452, train_loss = 0.971494298428297, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 453, train_loss = 0.9710674372909125, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 454, train_loss = 0.9699299173953477, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 455, train_loss = 0.9700550312700216, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 456, train_loss = 0.9688985707762185, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 457, train_loss = 0.9688560900685843, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 458, train_loss = 0.9681742079555988, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 459, train_loss = 0.9676087635161821, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 460, train_loss = 0.9675569397804793, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 461, train_loss = 0.9670881343481597, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 462, train_loss = 0.9660167979600374, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 463, train_loss = 0.965751343726879, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 464, train_loss = 0.9653798726794776, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 465, train_loss = 0.9644554257392883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 466, train_loss = 0.9643302286567632, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 467, train_loss = 0.9635006375610828, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 468, train_loss = 0.9632941322925035, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 469, train_loss = 0.962532172590727, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 470, train_loss = 0.9618861625494901, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 471, train_loss = 0.9611911276879255, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 472, train_loss = 0.9614619190397207, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 473, train_loss = 0.9603783078491688, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 474, train_loss = 0.9600970012543257, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 475, train_loss = 0.9595705208776053, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 476, train_loss = 0.9584606401622295, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 477, train_loss = 0.9580400114355143, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 478, train_loss = 0.9573954666557256, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 479, train_loss = 0.9571322028932627, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 480, train_loss = 0.9562074715795461, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 481, train_loss = 0.955769307911396, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 482, train_loss = 0.9551918283104897, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 483, train_loss = 0.9545600414276123, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 484, train_loss = 0.9547049129905645, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 485, train_loss = 0.9537074938416481, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 486, train_loss = 0.9533383920788765, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 487, train_loss = 0.9529239721596241, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 488, train_loss = 0.9521790072321892, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 489, train_loss = 0.9520118658838328, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 490, train_loss = 0.9516047847864684, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 491, train_loss = 0.9506570970115718, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 492, train_loss = 0.9503975299594458, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 493, train_loss = 0.950356762856245, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 494, train_loss = 0.9494507126510143, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 495, train_loss = 0.9492649435997009, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 496, train_loss = 0.9487850455043372, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 497, train_loss = 0.9482614733278751, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 498, train_loss = 0.9472965362074319, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 499, train_loss = 0.9476740968821105, train_acc = 0.9977876106194691\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|██████████████████████████████████████████████████████████████▍         | 26/30 [4:19:44<40:03, 600.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "27th- epoch: 0, train_loss = 127.63400320708752, train_acc = 0.7519795062878435\n",
      "test Acc 0.8431098696461825:\n",
      "27th- epoch: 1, train_loss = 49.06055061519146, train_acc = 0.8945039590125757\n",
      "test Acc 0.9008379888268156:\n",
      "27th- epoch: 2, train_loss = 34.75550312548876, train_acc = 0.9271075919888216\n",
      "test Acc 0.9194599627560521:\n",
      "27th- epoch: 3, train_loss = 27.78252149000764, train_acc = 0.9448067070330693\n",
      "test Acc 0.9301675977653632:\n",
      "27th- epoch: 4, train_loss = 23.45552946999669, train_acc = 0.9531904983698184\n",
      "test Acc 0.9366852886405959:\n",
      "27th- epoch: 5, train_loss = 20.412003841251135, train_acc = 0.9606427573358174\n",
      "test Acc 0.9394785847299814:\n",
      "27th- epoch: 6, train_loss = 18.128246549516916, train_acc = 0.9640195621797858\n",
      "test Acc 0.9422718808193669:\n",
      "27th- epoch: 7, train_loss = 16.308038160204887, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "27th- epoch: 8, train_loss = 14.818158470094204, train_acc = 0.9703074056823474\n",
      "test Acc 0.9497206703910615:\n",
      "27th- epoch: 9, train_loss = 13.563757162541151, train_acc = 0.9733348858872846\n",
      "test Acc 0.952048417132216:\n",
      "27th- epoch: 10, train_loss = 12.488020183518529, train_acc = 0.9750815090824406\n",
      "test Acc 0.9543761638733705:\n",
      "27th- epoch: 11, train_loss = 11.560416800901294, train_acc = 0.9771774569166278\n",
      "test Acc 0.9557728119180633:\n",
      "27th- epoch: 12, train_loss = 10.7476100102067, train_acc = 0.9792734047508151\n",
      "test Acc 0.9562383612662942:\n",
      "27th- epoch: 13, train_loss = 10.029129341244698, train_acc = 0.9804378202142524\n",
      "test Acc 0.9585661080074488:\n",
      "27th- epoch: 14, train_loss = 9.394243003800511, train_acc = 0.9820680018630648\n",
      "test Acc 0.9594972067039106:\n",
      "27th- epoch: 15, train_loss = 8.824730211868882, train_acc = 0.983698183511877\n",
      "test Acc 0.9613594040968343:\n",
      "27th- epoch: 16, train_loss = 8.314972387626767, train_acc = 0.9843968327899395\n",
      "test Acc 0.9613594040968343:\n",
      "27th- epoch: 17, train_loss = 7.857522824779153, train_acc = 0.985444806707033\n",
      "test Acc 0.9622905027932961:\n",
      "27th- epoch: 18, train_loss = 7.446139080449939, train_acc = 0.9866092221704704\n",
      "test Acc 0.962756052141527:\n",
      "27th- epoch: 19, train_loss = 7.073146443814039, train_acc = 0.9873078714485328\n",
      "test Acc 0.9636871508379888:\n",
      "27th- epoch: 20, train_loss = 6.734293045476079, train_acc = 0.9876571960875641\n",
      "test Acc 0.9646182495344506:\n",
      "27th- epoch: 21, train_loss = 6.42443404905498, train_acc = 0.9884722869119702\n",
      "test Acc 0.9646182495344506:\n",
      "27th- epoch: 22, train_loss = 6.144524462521076, train_acc = 0.9892873777363763\n",
      "test Acc 0.9660148975791434:\n",
      "27th- epoch: 23, train_loss = 5.88895321264863, train_acc = 0.989869585468095\n",
      "test Acc 0.9664804469273743:\n",
      "27th- epoch: 24, train_loss = 5.659301176667213, train_acc = 0.99033535165347\n",
      "test Acc 0.9664804469273743:\n",
      "27th- epoch: 25, train_loss = 5.445979734882712, train_acc = 0.9906846762925011\n",
      "test Acc 0.9664804469273743:\n",
      "27th- epoch: 26, train_loss = 5.251485939137638, train_acc = 0.990801117838845\n",
      "test Acc 0.9669459962756052:\n",
      "27th- epoch: 27, train_loss = 5.0710652424022555, train_acc = 0.9912668840242198\n",
      "test Acc 0.9674115456238361:\n",
      "27th- epoch: 28, train_loss = 4.904448986984789, train_acc = 0.9917326502095948\n",
      "test Acc 0.9674115456238361:\n",
      "27th- epoch: 29, train_loss = 4.748995411209762, train_acc = 0.992081974848626\n",
      "test Acc 0.9678770949720671:\n",
      "27th- epoch: 30, train_loss = 4.604311775416136, train_acc = 0.9924312994876572\n",
      "test Acc 0.9678770949720671:\n",
      "27th- epoch: 31, train_loss = 4.470503738150001, train_acc = 0.9925477410340009\n",
      "test Acc 0.9674115456238361:\n",
      "27th- epoch: 32, train_loss = 4.343921813182533, train_acc = 0.9927806241266884\n",
      "test Acc 0.9674115456238361:\n",
      "27th- epoch: 33, train_loss = 4.226907418109477, train_acc = 0.9930135072193759\n",
      "test Acc 0.9674115456238361:\n",
      "27th- epoch: 34, train_loss = 4.1156266601756215, train_acc = 0.9933628318584071\n",
      "test Acc 0.9678770949720671:\n",
      "27th- epoch: 35, train_loss = 4.012669476680458, train_acc = 0.9935957149510946\n",
      "test Acc 0.9678770949720671:\n",
      "27th- epoch: 36, train_loss = 3.9149261536076665, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 37, train_loss = 3.823262699879706, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 38, train_loss = 3.7371728299185634, train_acc = 0.9940614811364695\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 39, train_loss = 3.655819865874946, train_acc = 0.9940614811364695\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 40, train_loss = 3.5778700904920697, train_acc = 0.9940614811364695\n",
      "test Acc 0.9688081936685289:\n",
      "27th- epoch: 41, train_loss = 3.503819297067821, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 42, train_loss = 3.4350870186463, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 43, train_loss = 3.369935824535787, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 44, train_loss = 3.3053637156262994, train_acc = 0.9947601304145319\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 45, train_loss = 3.244880842976272, train_acc = 0.9951094550535631\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 46, train_loss = 3.18687832262367, train_acc = 0.9951094550535631\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 47, train_loss = 3.132061460055411, train_acc = 0.9951094550535631\n",
      "test Acc 0.9706703910614525:\n",
      "27th- epoch: 48, train_loss = 3.0783356251195073, train_acc = 0.9951094550535631\n",
      "test Acc 0.9706703910614525:\n",
      "27th- epoch: 49, train_loss = 3.0283355275169015, train_acc = 0.9951094550535631\n",
      "test Acc 0.9706703910614525:\n",
      "27th- epoch: 50, train_loss = 2.9786856938153505, train_acc = 0.9952258965999069\n",
      "test Acc 0.9706703910614525:\n",
      "27th- epoch: 51, train_loss = 2.932697649113834, train_acc = 0.9953423381462506\n",
      "test Acc 0.9706703910614525:\n",
      "27th- epoch: 52, train_loss = 2.8876805026084185, train_acc = 0.9953423381462506\n",
      "test Acc 0.9706703910614525:\n",
      "27th- epoch: 53, train_loss = 2.8441749149933457, train_acc = 0.9954587796925943\n",
      "test Acc 0.9706703910614525:\n",
      "27th- epoch: 54, train_loss = 2.8027868210338056, train_acc = 0.9954587796925943\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 55, train_loss = 2.76266917726025, train_acc = 0.9954587796925943\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 56, train_loss = 2.724030364304781, train_acc = 0.9954587796925943\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 57, train_loss = 2.686310898512602, train_acc = 0.995575221238938\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 58, train_loss = 2.650397951249033, train_acc = 0.995575221238938\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 59, train_loss = 2.615044407080859, train_acc = 0.9958081043316255\n",
      "test Acc 0.9720670391061452:\n",
      "27th- epoch: 60, train_loss = 2.580968403723091, train_acc = 0.9959245458779693\n",
      "test Acc 0.9720670391061452:\n",
      "27th- epoch: 61, train_loss = 2.5485388040542603, train_acc = 0.996040987424313\n",
      "test Acc 0.9720670391061452:\n",
      "27th- epoch: 62, train_loss = 2.517157221212983, train_acc = 0.996040987424313\n",
      "test Acc 0.9720670391061452:\n",
      "27th- epoch: 63, train_loss = 2.4856095192953944, train_acc = 0.9961574289706567\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 64, train_loss = 2.456983994692564, train_acc = 0.9962738705170004\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 65, train_loss = 2.427795954514295, train_acc = 0.9962738705170004\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 66, train_loss = 2.4004339748062193, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 67, train_loss = 2.372962429653853, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 68, train_loss = 2.3478174549527466, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 69, train_loss = 2.3220098237507045, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 70, train_loss = 2.297380563803017, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 71, train_loss = 2.273225690703839, train_acc = 0.9962738705170004\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 72, train_loss = 2.24927019700408, train_acc = 0.996506753609688\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 73, train_loss = 2.22647583251819, train_acc = 0.996506753609688\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 74, train_loss = 2.2044182871468365, train_acc = 0.996506753609688\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 75, train_loss = 2.1825442146509886, train_acc = 0.996506753609688\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 76, train_loss = 2.1612161793746054, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 77, train_loss = 2.1405940391123295, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 78, train_loss = 2.1213106117211282, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 79, train_loss = 2.1015522642992437, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 80, train_loss = 2.0823440104722977, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 81, train_loss = 2.063701945822686, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 82, train_loss = 2.0456312424503267, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 83, train_loss = 2.0284182112663984, train_acc = 0.996506753609688\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 84, train_loss = 2.010648441966623, train_acc = 0.996506753609688\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 85, train_loss = 1.994229978416115, train_acc = 0.996506753609688\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 86, train_loss = 1.9772408274002373, train_acc = 0.996506753609688\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 87, train_loss = 1.9617714998312294, train_acc = 0.996506753609688\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 88, train_loss = 1.9461544468067586, train_acc = 0.996506753609688\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 89, train_loss = 1.931205244269222, train_acc = 0.996506753609688\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 90, train_loss = 1.9167975899763405, train_acc = 0.996506753609688\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 91, train_loss = 1.902148091699928, train_acc = 0.9966231951560317\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 92, train_loss = 1.8884358550421894, train_acc = 0.9967396367023754\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 93, train_loss = 1.8741240431554615, train_acc = 0.9967396367023754\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 94, train_loss = 1.8618745706044137, train_acc = 0.9967396367023754\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 95, train_loss = 1.8478771559894085, train_acc = 0.9969725197950629\n",
      "test Acc 0.973463687150838:\n",
      "27th- epoch: 96, train_loss = 1.8355556253809482, train_acc = 0.9968560782487191\n",
      "test Acc 0.973463687150838:\n",
      "27th- epoch: 97, train_loss = 1.8233372543472797, train_acc = 0.9969725197950629\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 98, train_loss = 1.8111902989912778, train_acc = 0.9970889613414066\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 99, train_loss = 1.79931920603849, train_acc = 0.9970889613414066\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 100, train_loss = 1.7882562221493572, train_acc = 0.9970889613414066\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 101, train_loss = 1.777038537664339, train_acc = 0.9970889613414066\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 102, train_loss = 1.7660917611792684, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 103, train_loss = 1.7560270719695836, train_acc = 0.9972054028877504\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 104, train_loss = 1.7452369469683617, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 105, train_loss = 1.7351179234683514, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 106, train_loss = 1.725667683640495, train_acc = 0.9973218444340941\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 107, train_loss = 1.7157693963963538, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 108, train_loss = 1.7061654652934521, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 109, train_loss = 1.6970823605079204, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 110, train_loss = 1.6880702103953809, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "27th- epoch: 111, train_loss = 1.6798244181554765, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 112, train_loss = 1.6704834625124931, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 113, train_loss = 1.6626861363183707, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 114, train_loss = 1.6541729110758752, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 115, train_loss = 1.6455261253286153, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 116, train_loss = 1.6380675733089447, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 117, train_loss = 1.6301063194405288, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 118, train_loss = 1.6225217506289482, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 119, train_loss = 1.6148008268792182, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 120, train_loss = 1.607723830966279, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 121, train_loss = 1.6006330884993076, train_acc = 0.9975547275267815\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 122, train_loss = 1.593172488734126, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 123, train_loss = 1.5864611144643277, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 124, train_loss = 1.5792563036084175, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 125, train_loss = 1.5725252635311335, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 126, train_loss = 1.5656898748129606, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 127, train_loss = 1.559425137238577, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 128, train_loss = 1.5525375169236213, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 129, train_loss = 1.5463207967113703, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 130, train_loss = 1.5401458200067282, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 131, train_loss = 1.5338348411023617, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 132, train_loss = 1.5278588004875928, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 133, train_loss = 1.5216951295733452, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 134, train_loss = 1.5158212538808584, train_acc = 0.9976711690731253\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 135, train_loss = 1.5098383750300854, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 136, train_loss = 1.5041362822521478, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 137, train_loss = 1.4982248235028237, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 138, train_loss = 1.4930879019666463, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 139, train_loss = 1.4874402545392513, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 140, train_loss = 1.48191545647569, train_acc = 0.9976711690731253\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 141, train_loss = 1.4766994137316942, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 142, train_loss = 1.4713966250419617, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 143, train_loss = 1.4660245485138148, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 144, train_loss = 1.460499296663329, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 145, train_loss = 1.455358000472188, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 146, train_loss = 1.4499823835212737, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 147, train_loss = 1.444950881646946, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 148, train_loss = 1.440449558198452, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 149, train_loss = 1.4355911177117378, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 150, train_loss = 1.4309095956850797, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 151, train_loss = 1.4263096663635224, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 152, train_loss = 1.4221625856589526, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 153, train_loss = 1.4179247438441962, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 154, train_loss = 1.4132576771080494, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 155, train_loss = 1.4088625081349164, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 156, train_loss = 1.4046358473133296, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 157, train_loss = 1.4007055175025016, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 158, train_loss = 1.396477423608303, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 159, train_loss = 1.392110186861828, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 160, train_loss = 1.3882085557561368, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 161, train_loss = 1.3842890232335776, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 162, train_loss = 1.3803722839802504, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 163, train_loss = 1.3762529001105577, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 164, train_loss = 1.3728512799134478, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 165, train_loss = 1.368542875512503, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 166, train_loss = 1.364962032646872, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 167, train_loss = 1.3614746084203944, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 168, train_loss = 1.3577118143439293, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 169, train_loss = 1.3536776757100597, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 170, train_loss = 1.3509806828806177, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 171, train_loss = 1.347248969017528, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 172, train_loss = 1.3437264332314953, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 173, train_loss = 1.340883162454702, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 174, train_loss = 1.337208678945899, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 175, train_loss = 1.333705029799603, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 176, train_loss = 1.3303885584464297, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 177, train_loss = 1.3275408496847376, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 178, train_loss = 1.3246844013920054, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 179, train_loss = 1.3211708707967773, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 180, train_loss = 1.3179520411649719, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 181, train_loss = 1.315161982551217, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 182, train_loss = 1.3120180889964104, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 183, train_loss = 1.309404686675407, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 184, train_loss = 1.3057033146033064, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 185, train_loss = 1.302670968696475, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 186, train_loss = 1.3004635516554117, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 187, train_loss = 1.2968870730837807, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 188, train_loss = 1.2940941645065323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 189, train_loss = 1.2917026368668303, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 190, train_loss = 1.288509468198754, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 191, train_loss = 1.2861452661454678, train_acc = 0.9975547275267815\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 192, train_loss = 1.2827972011873499, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 193, train_loss = 1.2808209167560562, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 194, train_loss = 1.2775586061179638, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 195, train_loss = 1.2752807289361954, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 196, train_loss = 1.2723208548268303, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 197, train_loss = 1.2697380477329716, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 198, train_loss = 1.2669540283968672, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 199, train_loss = 1.264986407593824, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 200, train_loss = 1.2624783670762554, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 201, train_loss = 1.2595744902500883, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 202, train_loss = 1.2571500074118376, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 203, train_loss = 1.2542625231435522, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 204, train_loss = 1.2519924025982618, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 205, train_loss = 1.2493621172616258, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 206, train_loss = 1.2467542240628973, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 207, train_loss = 1.244305040105246, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 208, train_loss = 1.2418217124650255, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 209, train_loss = 1.2400685058673844, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 210, train_loss = 1.2372779976576567, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 211, train_loss = 1.235405863611959, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 212, train_loss = 1.2329882526537403, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 213, train_loss = 1.231250811368227, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 214, train_loss = 1.228534473106265, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 215, train_loss = 1.2265072328737006, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 216, train_loss = 1.2243434278061613, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 217, train_loss = 1.2220964139560238, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 218, train_loss = 1.2202680855989456, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 219, train_loss = 1.2176752457162365, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 220, train_loss = 1.215945277363062, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 221, train_loss = 1.213697369559668, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 222, train_loss = 1.2120289243757725, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 223, train_loss = 1.2096444703638554, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 224, train_loss = 1.2079829616704956, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 225, train_loss = 1.205862426548265, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 226, train_loss = 1.2041223415872082, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 227, train_loss = 1.2017339132726192, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 228, train_loss = 1.1999794635921717, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 229, train_loss = 1.198393303900957, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 230, train_loss = 1.19610225467477, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 231, train_loss = 1.1946366280317307, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 232, train_loss = 1.1924182897200808, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 233, train_loss = 1.1906356569379568, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 234, train_loss = 1.1888284949818626, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 235, train_loss = 1.1872287535807118, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 236, train_loss = 1.1854508282849565, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 237, train_loss = 1.1833033902803436, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 238, train_loss = 1.1817712424090132, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 239, train_loss = 1.1798615293810144, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 240, train_loss = 1.178298832848668, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 241, train_loss = 1.1765198732027784, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 242, train_loss = 1.175175761221908, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 243, train_loss = 1.1729299277067184, train_acc = 0.9975547275267815\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 244, train_loss = 1.1713395329425111, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 245, train_loss = 1.1695616667857394, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 246, train_loss = 1.1682484025368467, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 247, train_loss = 1.1663828119635582, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 248, train_loss = 1.1646689549088478, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 249, train_loss = 1.1632955049863085, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 250, train_loss = 1.16170983761549, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 251, train_loss = 1.160175058990717, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 252, train_loss = 1.1582352170953527, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 253, train_loss = 1.1569280090043321, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 254, train_loss = 1.1551990769803524, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 255, train_loss = 1.1540397567441687, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 256, train_loss = 1.151992847560905, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 257, train_loss = 1.151318141608499, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 258, train_loss = 1.1493450365960598, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 259, train_loss = 1.147681369096972, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 260, train_loss = 1.1459603793919086, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 261, train_loss = 1.144882719963789, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 262, train_loss = 1.1433230489492416, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 263, train_loss = 1.141730955510866, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 264, train_loss = 1.1403066801722161, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 265, train_loss = 1.1386871511931531, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 266, train_loss = 1.1377751280670054, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 267, train_loss = 1.1360278961365111, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 268, train_loss = 1.1342861366574652, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 269, train_loss = 1.1337686131591909, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 270, train_loss = 1.1317134636337869, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 271, train_loss = 1.130664300173521, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 272, train_loss = 1.1293998037581332, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 273, train_loss = 1.1277736921911128, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 274, train_loss = 1.1269336926634423, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 275, train_loss = 1.1250330482725985, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 276, train_loss = 1.1240397530491464, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 277, train_loss = 1.122310396283865, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 278, train_loss = 1.1215913916821592, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 279, train_loss = 1.119944692880381, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 280, train_loss = 1.118859138339758, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 281, train_loss = 1.1173720844089985, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 282, train_loss = 1.1164416683022864, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 283, train_loss = 1.1146631042356603, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 284, train_loss = 1.1139511813526042, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 285, train_loss = 1.112485721707344, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 286, train_loss = 1.1113241252605803, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 287, train_loss = 1.1098908807034604, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 288, train_loss = 1.1089885917608626, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 289, train_loss = 1.1074604839086533, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 290, train_loss = 1.106960107863415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 291, train_loss = 1.1053416430950165, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 292, train_loss = 1.1044406655128114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 293, train_loss = 1.1024353231186979, train_acc = 0.9977876106194691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 294, train_loss = 1.1019575546379201, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 295, train_loss = 1.1008231590385549, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 296, train_loss = 1.0992581670288928, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 297, train_loss = 1.0984510891139507, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 298, train_loss = 1.097268931567669, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 299, train_loss = 1.095982450991869, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 300, train_loss = 1.09526402130723, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 301, train_loss = 1.093748273968231, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 302, train_loss = 1.092998078733217, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 303, train_loss = 1.0916460144217126, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 304, train_loss = 1.0906881627743132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 305, train_loss = 1.0893068040604703, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 306, train_loss = 1.0885121772880666, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 307, train_loss = 1.0872999243438244, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 308, train_loss = 1.0865179114043713, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 309, train_loss = 1.0850496317143552, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 310, train_loss = 1.0847084385459311, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 311, train_loss = 1.0828640435938723, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 312, train_loss = 1.0824943743646145, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 313, train_loss = 1.0809867407078855, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 314, train_loss = 1.0804862901568413, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 315, train_loss = 1.078643649816513, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 316, train_loss = 1.0785358647699468, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 317, train_loss = 1.0768638041918166, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 318, train_loss = 1.0763991586863995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 319, train_loss = 1.074816182255745, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 320, train_loss = 1.0742864844505675, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 321, train_loss = 1.0729996276204474, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 322, train_loss = 1.0722151386435144, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 323, train_loss = 1.071079124987591, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 324, train_loss = 1.0703953740303405, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 325, train_loss = 1.069208348810207, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 326, train_loss = 1.0683232583105564, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 327, train_loss = 1.0672321009333245, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 328, train_loss = 1.0667988074128516, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 329, train_loss = 1.0651946378056891, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 330, train_loss = 1.0647699870169163, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 331, train_loss = 1.0637005020980723, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 332, train_loss = 1.0628885067999363, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 333, train_loss = 1.0614634429221042, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 334, train_loss = 1.0608777776360512, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 335, train_loss = 1.0597976284916513, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 336, train_loss = 1.0591154334251769, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 337, train_loss = 1.0583646719460376, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 338, train_loss = 1.05718371149851, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 339, train_loss = 1.0563180074095726, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 340, train_loss = 1.0552563506062143, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 341, train_loss = 1.054749904840719, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 342, train_loss = 1.053898148238659, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 343, train_loss = 1.0528666066820733, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 344, train_loss = 1.0518802516162395, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 345, train_loss = 1.0510420252685435, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 346, train_loss = 1.0502705101971515, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 347, train_loss = 1.0492805044050328, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 348, train_loss = 1.049154806882143, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 349, train_loss = 1.0472737054224126, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 350, train_loss = 1.047436958819162, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 351, train_loss = 1.045890988141764, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 352, train_loss = 1.045508777082432, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 353, train_loss = 1.044267373799812, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 354, train_loss = 1.044099546968937, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 355, train_loss = 1.0427796989679337, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 356, train_loss = 1.041871699213516, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 357, train_loss = 1.0412303221528418, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 358, train_loss = 1.0403327867388725, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 359, train_loss = 1.0395692636375315, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 360, train_loss = 1.0389243786339648, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 361, train_loss = 1.0378830966656096, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 362, train_loss = 1.0372474640607834, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 363, train_loss = 1.0362145838444121, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 364, train_loss = 1.0358214601874352, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 365, train_loss = 1.0347390187089331, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 366, train_loss = 1.0344760902225971, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 367, train_loss = 1.0329801800544374, train_acc = 0.9979040521658128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 368, train_loss = 1.0329158802633174, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 369, train_loss = 1.0316967529361136, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 370, train_loss = 1.031333768100012, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 371, train_loss = 1.0302147567272186, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 372, train_loss = 1.0296954587101936, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 373, train_loss = 1.0291566401720047, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 374, train_loss = 1.0277661966974847, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 375, train_loss = 1.027509284496773, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 376, train_loss = 1.0267633497714996, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 377, train_loss = 1.02592509862734, train_acc = 0.9979040521658128\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 378, train_loss = 1.0252954475581646, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 379, train_loss = 1.024322222918272, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 380, train_loss = 1.0238641227479093, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 381, train_loss = 1.0229981889133342, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 382, train_loss = 1.0222990835900418, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 383, train_loss = 1.0215988531708717, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 384, train_loss = 1.0208616803283803, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 385, train_loss = 1.020127599418629, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 386, train_loss = 1.0194812379777431, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 387, train_loss = 1.018917626410257, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 388, train_loss = 1.0185784039204009, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 389, train_loss = 1.0170372662250884, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 390, train_loss = 1.0168014976079576, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 391, train_loss = 1.0163497838075273, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 392, train_loss = 1.0152998616104014, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 393, train_loss = 1.014662058383692, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 394, train_loss = 1.0143179185688496, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 395, train_loss = 1.0133350702817552, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 396, train_loss = 1.012582449882757, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 397, train_loss = 1.0123979784548283, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 398, train_loss = 1.0112000393564813, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 399, train_loss = 1.0110967991058715, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 400, train_loss = 1.0100490972399712, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 401, train_loss = 1.009760145097971, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 402, train_loss = 1.0089287136797793, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 403, train_loss = 1.008196723938454, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 404, train_loss = 1.0073307380080223, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 405, train_loss = 1.0067926558549516, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 406, train_loss = 1.0064087882637978, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 407, train_loss = 1.005530872673262, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 408, train_loss = 1.0052214575116523, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 409, train_loss = 1.004183404147625, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 410, train_loss = 1.0035312250256538, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 411, train_loss = 1.0031273501808755, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 412, train_loss = 1.0024109768564813, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 413, train_loss = 1.0017395615577698, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 414, train_loss = 1.0015803475980647, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 415, train_loss = 1.0003804502193816, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 416, train_loss = 0.9998553718323819, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 417, train_loss = 0.9995906104450114, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 418, train_loss = 0.9987470768392086, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 419, train_loss = 0.998180394351948, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 420, train_loss = 0.9976239402894862, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 421, train_loss = 0.9969415205414407, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 422, train_loss = 0.9967341820592992, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 423, train_loss = 0.9955620032851584, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 424, train_loss = 0.9951299987733364, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 425, train_loss = 0.9948039824957959, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 426, train_loss = 0.9940990644390695, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 427, train_loss = 0.9931533547933213, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 428, train_loss = 0.9930974145536311, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 429, train_loss = 0.9922190966899507, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 430, train_loss = 0.9918197045917623, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 431, train_loss = 0.9909354957635514, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 432, train_loss = 0.9905545736546628, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 433, train_loss = 0.9897677612607367, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 434, train_loss = 0.9895569260115735, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 435, train_loss = 0.9886370810563676, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 436, train_loss = 0.9879598195548169, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 437, train_loss = 0.9877792249317281, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 438, train_loss = 0.9869204871356487, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 439, train_loss = 0.9866300697322004, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 440, train_loss = 0.9860496893525124, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 441, train_loss = 0.9852823677356355, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 442, train_loss = 0.9849053260986693, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 443, train_loss = 0.9843978844583035, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 444, train_loss = 0.9837414287030697, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 445, train_loss = 0.9833990037441254, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 446, train_loss = 0.9829850755631924, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 447, train_loss = 0.9820790986123029, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 448, train_loss = 0.9815411182644311, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 449, train_loss = 0.9812723807990551, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 450, train_loss = 0.9803061634302139, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 451, train_loss = 0.9800968952476978, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 452, train_loss = 0.9796216810646001, train_acc = 0.9979040521658128\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 453, train_loss = 0.9788722743687686, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 454, train_loss = 0.9786210445163306, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 455, train_loss = 0.9779050573706627, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 456, train_loss = 0.9772056279180106, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 457, train_loss = 0.9766755029559135, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 458, train_loss = 0.976383483648533, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 459, train_loss = 0.9757354557514191, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 460, train_loss = 0.9753755343554076, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 461, train_loss = 0.9747068583965302, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 462, train_loss = 0.9743373692035675, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 463, train_loss = 0.9734779509308282, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 464, train_loss = 0.9731793254613876, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 465, train_loss = 0.9729460030794144, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 466, train_loss = 0.9722267923352774, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 467, train_loss = 0.97175001600408, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 468, train_loss = 0.9711828654108103, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 469, train_loss = 0.9707010599377099, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 470, train_loss = 0.9703338481485844, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 471, train_loss = 0.9697798490524292, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 472, train_loss = 0.9693164390919264, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 473, train_loss = 0.9686763820645865, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 474, train_loss = 0.9681051919760648, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 475, train_loss = 0.9680771318671759, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 476, train_loss = 0.9671043058333453, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 477, train_loss = 0.9669689647853374, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 478, train_loss = 0.9660279030504171, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 479, train_loss = 0.965773062169319, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 480, train_loss = 0.9653829298913479, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 481, train_loss = 0.9643089758756105, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 482, train_loss = 0.9640472432074603, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 483, train_loss = 0.9632476183178369, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 484, train_loss = 0.96335213756538, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 485, train_loss = 0.9622229014930781, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 486, train_loss = 0.9618694248201791, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 487, train_loss = 0.961800849676365, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 488, train_loss = 0.9610178756120149, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 489, train_loss = 0.9605558961629868, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 490, train_loss = 0.9600839329359587, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 491, train_loss = 0.9598534082469996, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 492, train_loss = 0.9592793819901999, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 493, train_loss = 0.9587898217141628, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 494, train_loss = 0.9583708991704043, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 495, train_loss = 0.9575502884981688, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 496, train_loss = 0.9576615480182227, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 497, train_loss = 0.956732701510191, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 498, train_loss = 0.9568273735640105, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 499, train_loss = 0.9557043897511903, train_acc = 0.9979040521658128\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████▊       | 27/30 [4:29:46<30:03, 601.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "28th- epoch: 0, train_loss = 139.79587899148464, train_acc = 0.7501164415463437\n",
      "test Acc 0.851024208566108:\n",
      "28th- epoch: 1, train_loss = 49.30814127624035, train_acc = 0.8985794131346064\n",
      "test Acc 0.904096834264432:\n",
      "28th- epoch: 2, train_loss = 35.19730290398002, train_acc = 0.9262925011644154\n",
      "test Acc 0.9245810055865922:\n",
      "28th- epoch: 3, train_loss = 28.117874965071678, train_acc = 0.9403819282720075\n",
      "test Acc 0.9380819366852886:\n",
      "28th- epoch: 4, train_loss = 23.63491563498974, train_acc = 0.9491150442477876\n",
      "test Acc 0.9459962756052142:\n",
      "28th- epoch: 5, train_loss = 20.447700323536992, train_acc = 0.9570330693991617\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 6, train_loss = 18.035846969112754, train_acc = 0.9627387051700047\n",
      "test Acc 0.9534450651769087:\n",
      "28th- epoch: 7, train_loss = 16.117620078846812, train_acc = 0.9678621332091291\n",
      "test Acc 0.9562383612662942:\n",
      "28th- epoch: 8, train_loss = 14.56047465838492, train_acc = 0.9713553795994411\n",
      "test Acc 0.9594972067039106:\n",
      "28th- epoch: 9, train_loss = 13.27963430993259, train_acc = 0.9742664182580345\n",
      "test Acc 0.9613594040968343:\n",
      "28th- epoch: 10, train_loss = 12.204351086169481, train_acc = 0.9772938984629715\n",
      "test Acc 0.9613594040968343:\n",
      "28th- epoch: 11, train_loss = 11.282914940267801, train_acc = 0.9790405216581276\n",
      "test Acc 0.962756052141527:\n",
      "28th- epoch: 12, train_loss = 10.491621486842632, train_acc = 0.9809035863996274\n",
      "test Acc 0.9632216014897579:\n",
      "28th- epoch: 13, train_loss = 9.79961897060275, train_acc = 0.9821844434094085\n",
      "test Acc 0.9641527001862198:\n",
      "28th- epoch: 14, train_loss = 9.19054580014199, train_acc = 0.9839310666045645\n",
      "test Acc 0.9650837988826816:\n",
      "28th- epoch: 15, train_loss = 8.649644010700285, train_acc = 0.9852119236143456\n",
      "test Acc 0.9660148975791434:\n",
      "28th- epoch: 16, train_loss = 8.165185105986893, train_acc = 0.9856776897997206\n",
      "test Acc 0.9664804469273743:\n",
      "28th- epoch: 17, train_loss = 7.730563219636679, train_acc = 0.9869585468095017\n",
      "test Acc 0.9674115456238361:\n",
      "28th- epoch: 18, train_loss = 7.338936743326485, train_acc = 0.9874243129948765\n",
      "test Acc 0.9674115456238361:\n",
      "28th- epoch: 19, train_loss = 6.980494414456189, train_acc = 0.9882394038192828\n",
      "test Acc 0.9674115456238361:\n",
      "28th- epoch: 20, train_loss = 6.656769446097314, train_acc = 0.9887051700046576\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 21, train_loss = 6.362036196514964, train_acc = 0.9895202608290639\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 22, train_loss = 6.0905773947015405, train_acc = 0.9904517931998137\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 23, train_loss = 5.84139993134886, train_acc = 0.9911504424778761\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 24, train_loss = 5.612356630153954, train_acc = 0.9914997671169073\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 25, train_loss = 5.397716970182955, train_acc = 0.9919655333022822\n",
      "test Acc 0.9697392923649907:\n",
      "28th- epoch: 26, train_loss = 5.201625709421933, train_acc = 0.9924312994876572\n",
      "test Acc 0.9706703910614525:\n",
      "28th- epoch: 27, train_loss = 5.0178042920306325, train_acc = 0.9926641825803446\n",
      "test Acc 0.9706703910614525:\n",
      "28th- epoch: 28, train_loss = 4.845797471702099, train_acc = 0.9930135072193759\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 29, train_loss = 4.685441272333264, train_acc = 0.9932463903120633\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 30, train_loss = 4.537062858697027, train_acc = 0.9933628318584071\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 31, train_loss = 4.397350389044732, train_acc = 0.9934792734047508\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 32, train_loss = 4.265263876412064, train_acc = 0.9935957149510946\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 33, train_loss = 4.139927143696696, train_acc = 0.9939450395901258\n",
      "test Acc 0.9716014897579144:\n",
      "28th- epoch: 34, train_loss = 4.023974725976586, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "28th- epoch: 35, train_loss = 3.913902072701603, train_acc = 0.9941779226828132\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 36, train_loss = 3.811134039890021, train_acc = 0.9941779226828132\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 37, train_loss = 3.7148651373572648, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 38, train_loss = 3.624040925875306, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 39, train_loss = 3.5382166863419116, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "28th- epoch: 40, train_loss = 3.456491204444319, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "28th- epoch: 41, train_loss = 3.379755654837936, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 42, train_loss = 3.3077263575978577, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 43, train_loss = 3.2382298256270587, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 44, train_loss = 3.172359337564558, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 45, train_loss = 3.11013600602746, train_acc = 0.9952258965999069\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 46, train_loss = 3.0515566766262054, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 47, train_loss = 2.994737086351961, train_acc = 0.995575221238938\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 48, train_loss = 2.94031337602064, train_acc = 0.995575221238938\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 49, train_loss = 2.8887284197844565, train_acc = 0.9958081043316255\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 50, train_loss = 2.8389883562922478, train_acc = 0.9959245458779693\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 51, train_loss = 2.791881911456585, train_acc = 0.9961574289706567\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 52, train_loss = 2.746799113228917, train_acc = 0.9961574289706567\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 53, train_loss = 2.703742050100118, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 54, train_loss = 2.662375828716904, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 55, train_loss = 2.622022407595068, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 56, train_loss = 2.583990763872862, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 57, train_loss = 2.546970369759947, train_acc = 0.9962738705170004\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 58, train_loss = 2.511656503425911, train_acc = 0.9962738705170004\n",
      "test Acc 0.9739292364990689:\n",
      "28th- epoch: 59, train_loss = 2.477504015667364, train_acc = 0.9962738705170004\n",
      "test Acc 0.9739292364990689:\n",
      "28th- epoch: 60, train_loss = 2.4447232224047184, train_acc = 0.9962738705170004\n",
      "test Acc 0.9739292364990689:\n",
      "28th- epoch: 61, train_loss = 2.413299214793369, train_acc = 0.9962738705170004\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 62, train_loss = 2.382299118442461, train_acc = 0.9962738705170004\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 63, train_loss = 2.3528817128390074, train_acc = 0.9962738705170004\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 64, train_loss = 2.3249895460903645, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 65, train_loss = 2.2967248659115285, train_acc = 0.9963903120633442\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 66, train_loss = 2.270326292142272, train_acc = 0.9966231951560317\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 67, train_loss = 2.243843102827668, train_acc = 0.9966231951560317\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 68, train_loss = 2.218949506059289, train_acc = 0.9966231951560317\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 69, train_loss = 2.194837162271142, train_acc = 0.9967396367023754\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 70, train_loss = 2.171236366732046, train_acc = 0.9967396367023754\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 71, train_loss = 2.1487127367872745, train_acc = 0.9967396367023754\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 72, train_loss = 2.126613810658455, train_acc = 0.9967396367023754\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 73, train_loss = 2.1051223885733634, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 74, train_loss = 2.0839020144194365, train_acc = 0.9968560782487191\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 75, train_loss = 2.0642084907740355, train_acc = 0.9969725197950629\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 76, train_loss = 2.0447417877148837, train_acc = 0.9970889613414066\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 77, train_loss = 2.0256096243392676, train_acc = 0.9970889613414066\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 78, train_loss = 2.006607722491026, train_acc = 0.9970889613414066\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 79, train_loss = 1.9888554464560002, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 80, train_loss = 1.971381725743413, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 81, train_loss = 1.9545854341704398, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 82, train_loss = 1.9369478158187121, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 83, train_loss = 1.921979608014226, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 84, train_loss = 1.906093455152586, train_acc = 0.9970889613414066\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 85, train_loss = 1.891130456700921, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 86, train_loss = 1.8761382966767997, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 87, train_loss = 1.8624205391388386, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 88, train_loss = 1.8484985523391515, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 89, train_loss = 1.8342312623281032, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 90, train_loss = 1.8207535271067172, train_acc = 0.9972054028877504\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 91, train_loss = 1.8080046873074025, train_acc = 0.9972054028877504\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 92, train_loss = 1.7947045180480927, train_acc = 0.9973218444340941\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 93, train_loss = 1.781839979114011, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 94, train_loss = 1.7701537050306797, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 95, train_loss = 1.7577039662282914, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 96, train_loss = 1.746009737951681, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 97, train_loss = 1.7349056594539434, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 98, train_loss = 1.7233264166861773, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 99, train_loss = 1.7127712208312005, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 100, train_loss = 1.7029916525352746, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 101, train_loss = 1.6923382009845227, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 102, train_loss = 1.6822837486397475, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 103, train_loss = 1.672970587387681, train_acc = 0.9973218444340941\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 104, train_loss = 1.6630633783061057, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 105, train_loss = 1.6541049908846617, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 106, train_loss = 1.645312444656156, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 107, train_loss = 1.636319781304337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 108, train_loss = 1.6275957835605368, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 109, train_loss = 1.6192525159567595, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 110, train_loss = 1.6108387423446402, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 111, train_loss = 1.6029782512923703, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 112, train_loss = 1.595233247964643, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 113, train_loss = 1.5872417272767052, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 114, train_loss = 1.5800319289555773, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 115, train_loss = 1.5727535417536274, train_acc = 0.9974382859804378\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 116, train_loss = 1.5652779204538092, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 117, train_loss = 1.5582286398857832, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 118, train_loss = 1.5516579324612394, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 119, train_loss = 1.5445469910046086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 120, train_loss = 1.5376286966493353, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 121, train_loss = 1.5310253910720348, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 122, train_loss = 1.5250522382557392, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 123, train_loss = 1.5190509390085936, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 124, train_loss = 1.5123755472013727, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 125, train_loss = 1.5063813421875238, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 126, train_loss = 1.5004387764493003, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 127, train_loss = 1.494603756815195, train_acc = 0.9974382859804378\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 128, train_loss = 1.4887794827809557, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 129, train_loss = 1.4833702612668276, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 130, train_loss = 1.4770958455046639, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 131, train_loss = 1.4725423263153061, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 132, train_loss = 1.4665713142603636, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 133, train_loss = 1.4615611290792003, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 134, train_loss = 1.456024231389165, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 135, train_loss = 1.4510111504932866, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 136, train_loss = 1.4455099664628506, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 137, train_loss = 1.4408242522040382, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 138, train_loss = 1.4357384318718687, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 139, train_loss = 1.430635471479036, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 140, train_loss = 1.4257798077305779, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 141, train_loss = 1.421013524173759, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 142, train_loss = 1.4159542514244094, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 143, train_loss = 1.4115296906093135, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 144, train_loss = 1.406906891032122, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 145, train_loss = 1.4026581831276417, train_acc = 0.9974382859804378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 146, train_loss = 1.397525998414494, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 147, train_loss = 1.3928875109413639, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 148, train_loss = 1.388578256010078, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 149, train_loss = 1.3847234236309305, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 150, train_loss = 1.380238275974989, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 151, train_loss = 1.3766513312002644, train_acc = 0.9974382859804378\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 152, train_loss = 1.372276110574603, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 153, train_loss = 1.3679332683095708, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 154, train_loss = 1.3640666293213144, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 155, train_loss = 1.3598914289614186, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 156, train_loss = 1.355847343802452, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 157, train_loss = 1.352592577575706, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 158, train_loss = 1.3488260196754709, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 159, train_loss = 1.345005234121345, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 160, train_loss = 1.3416260251542553, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 161, train_loss = 1.3377712853252888, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 162, train_loss = 1.3340612252941355, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 163, train_loss = 1.3306470457464457, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 164, train_loss = 1.3272452714154497, train_acc = 0.9975547275267815\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 165, train_loss = 1.3239182563265786, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 166, train_loss = 1.3201920576393604, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 167, train_loss = 1.3173638744046912, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 168, train_loss = 1.314295425429009, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 169, train_loss = 1.310617762268521, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 170, train_loss = 1.3073158711194992, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 171, train_loss = 1.3042798712849617, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 172, train_loss = 1.301436472684145, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 173, train_loss = 1.2983214216073975, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 174, train_loss = 1.2949526024749503, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 175, train_loss = 1.2920534635195509, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 176, train_loss = 1.2889781277626753, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 177, train_loss = 1.2861213646829128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 178, train_loss = 1.2833293098956347, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 179, train_loss = 1.2801761738955975, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 180, train_loss = 1.2775414796778932, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 181, train_loss = 1.2743383906781673, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 182, train_loss = 1.2720646560192108, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 183, train_loss = 1.2689715381711721, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 184, train_loss = 1.266548497020267, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 185, train_loss = 1.2635148080298677, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 186, train_loss = 1.261164644092787, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 187, train_loss = 1.2579570499365218, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 188, train_loss = 1.2555008853669278, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 189, train_loss = 1.2531803387100808, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 190, train_loss = 1.2502063724095933, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 191, train_loss = 1.247634682804346, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 192, train_loss = 1.2452288586646318, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 193, train_loss = 1.2427895491127856, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 194, train_loss = 1.2402143000508659, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 195, train_loss = 1.2377720015938394, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 196, train_loss = 1.2353660017251968, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 197, train_loss = 1.2329020028118975, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 198, train_loss = 1.2305522399838082, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 199, train_loss = 1.2283551059663296, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 200, train_loss = 1.2259676704998128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 201, train_loss = 1.2237061249907129, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 202, train_loss = 1.220968956768047, train_acc = 0.9975547275267815\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 203, train_loss = 1.219063438475132, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 204, train_loss = 1.2166523300111294, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 205, train_loss = 1.2143047787249088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 206, train_loss = 1.2122580384020694, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 207, train_loss = 1.2097402910585515, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 208, train_loss = 1.2075075929169543, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 209, train_loss = 1.2056472289259546, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 210, train_loss = 1.2030891453032382, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 211, train_loss = 1.201315323531162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 212, train_loss = 1.1984620988368988, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 213, train_loss = 1.1966345186228864, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 214, train_loss = 1.1943705852027051, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 215, train_loss = 1.1915988928521983, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 216, train_loss = 1.1903165404801257, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 217, train_loss = 1.1875945565407164, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 218, train_loss = 1.1859843817655928, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 219, train_loss = 1.184072446078062, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 220, train_loss = 1.1821342923794873, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 221, train_loss = 1.1800340836052783, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 222, train_loss = 1.1782713402062654, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 223, train_loss = 1.1762252760236152, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 224, train_loss = 1.174200253561139, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 225, train_loss = 1.172913069545757, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 226, train_loss = 1.170834570482839, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 227, train_loss = 1.1687755435705185, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 228, train_loss = 1.1671328600496054, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 229, train_loss = 1.1652400828897953, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 230, train_loss = 1.1638820090447553, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 231, train_loss = 1.1619638539850712, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 232, train_loss = 1.1604424088145606, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 233, train_loss = 1.1584689021110535, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 234, train_loss = 1.156763652979862, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 235, train_loss = 1.1552587486803532, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 236, train_loss = 1.1534497042302974, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 237, train_loss = 1.1518992980127223, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 238, train_loss = 1.150661141902674, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 239, train_loss = 1.1485276414896362, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 240, train_loss = 1.147061378986109, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 241, train_loss = 1.145524547144305, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 242, train_loss = 1.1437802103464492, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 243, train_loss = 1.1426908820867538, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 244, train_loss = 1.1406571728293784, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 245, train_loss = 1.1396456025540829, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 246, train_loss = 1.1375331642921083, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 247, train_loss = 1.1362916268408298, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 248, train_loss = 1.134647527069319, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 249, train_loss = 1.1334434263408184, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 250, train_loss = 1.132056714326609, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 251, train_loss = 1.1298541600699537, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 252, train_loss = 1.1291998053784482, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 253, train_loss = 1.1274500067229383, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 254, train_loss = 1.1263487643445842, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 255, train_loss = 1.1246571391820908, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 256, train_loss = 1.1230708069051616, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 257, train_loss = 1.1216487549245358, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 258, train_loss = 1.1205946113914251, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 259, train_loss = 1.118918967724312, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 260, train_loss = 1.1176038539852016, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 261, train_loss = 1.11636245372938, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 262, train_loss = 1.1148936835234053, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 263, train_loss = 1.1136557298596017, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 264, train_loss = 1.1118890171055682, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 265, train_loss = 1.1113328884239309, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 266, train_loss = 1.109806143969763, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 267, train_loss = 1.1084695893223397, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 268, train_loss = 1.1072239838540554, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 269, train_loss = 1.1056224417989142, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 270, train_loss = 1.1045778468251228, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 271, train_loss = 1.1030134446918964, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 272, train_loss = 1.1021680273115635, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 273, train_loss = 1.100771814584732, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 274, train_loss = 1.099878590553999, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 275, train_loss = 1.0982219738070853, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 276, train_loss = 1.097278218716383, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 277, train_loss = 1.0954194888472557, train_acc = 0.9976711690731253\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 278, train_loss = 1.0945706169004552, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 279, train_loss = 1.0933803406660445, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 280, train_loss = 1.0925822357530706, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 281, train_loss = 1.0911163936252706, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 282, train_loss = 1.0902503642137162, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 283, train_loss = 1.0888610022957437, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 284, train_loss = 1.0877543998067267, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 285, train_loss = 1.0864747793530114, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 286, train_loss = 1.085517471015919, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 287, train_loss = 1.0843825303018093, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 288, train_loss = 1.0828973787720315, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 289, train_loss = 1.0821533457492478, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 290, train_loss = 1.0809156310861, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 291, train_loss = 1.0800678699160926, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 292, train_loss = 1.078555064916145, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 293, train_loss = 1.0777189638465643, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 294, train_loss = 1.0768040257389657, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 295, train_loss = 1.0753281693905592, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 296, train_loss = 1.0742623656988144, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 297, train_loss = 1.0734476900543086, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 298, train_loss = 1.072229536890518, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 299, train_loss = 1.0715106036514044, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 300, train_loss = 1.0704056930844672, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 301, train_loss = 1.0693802281166427, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 302, train_loss = 1.0680159603361972, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 303, train_loss = 1.067164609208703, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 304, train_loss = 1.0661217607557774, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 305, train_loss = 1.064911472320091, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 306, train_loss = 1.0641805318300612, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 307, train_loss = 1.0630390395526774, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 308, train_loss = 1.062112718820572, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 309, train_loss = 1.0611587179009803, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 310, train_loss = 1.0599458515644073, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 311, train_loss = 1.0590858633513562, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 312, train_loss = 1.0579501502215862, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 313, train_loss = 1.0572613018448465, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 314, train_loss = 1.0560629454848822, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 315, train_loss = 1.0550209494831506, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 316, train_loss = 1.054252232745057, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 317, train_loss = 1.0533262304961681, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 318, train_loss = 1.0522213708609343, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 319, train_loss = 1.0514003696443979, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 320, train_loss = 1.0501690364035312, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 321, train_loss = 1.049233184516197, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 322, train_loss = 1.0478336494415998, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 323, train_loss = 1.0468197129666805, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 324, train_loss = 1.045878733828431, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 325, train_loss = 1.0451494442822877, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 326, train_loss = 1.0439310502260923, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 327, train_loss = 1.0431315725145396, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 328, train_loss = 1.0420416823180858, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 329, train_loss = 1.0414148308336735, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 330, train_loss = 1.0405587522836868, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 331, train_loss = 1.039740222186083, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 332, train_loss = 1.038579643383855, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 333, train_loss = 1.0377197259513196, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 334, train_loss = 1.0366032049059868, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 335, train_loss = 1.0360142942517996, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 336, train_loss = 1.0350464321672916, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 337, train_loss = 1.0342111978679895, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 338, train_loss = 1.033208413660759, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 339, train_loss = 1.0323985572904348, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 340, train_loss = 1.0316972732543945, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 341, train_loss = 1.0309455748647451, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 342, train_loss = 1.0300391539931297, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 343, train_loss = 1.0292847274395172, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 344, train_loss = 1.028610141336685, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 345, train_loss = 1.0275415598007385, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 346, train_loss = 1.0265030885639135, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 347, train_loss = 1.026064361765748, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 348, train_loss = 1.024804975837469, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 349, train_loss = 1.0244507870229427, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 350, train_loss = 1.0236461026070174, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 351, train_loss = 1.022605918959016, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 352, train_loss = 1.0219780082406942, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 353, train_loss = 1.0210622064769268, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 354, train_loss = 1.0203737001866102, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 355, train_loss = 1.019380180776352, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 356, train_loss = 1.0190784627047833, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 357, train_loss = 1.0180575214326382, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 358, train_loss = 1.0173677075654268, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 359, train_loss = 1.0162695311009884, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 360, train_loss = 1.0159137180598918, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 361, train_loss = 1.0152748661639635, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 362, train_loss = 1.0137722150830086, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 363, train_loss = 1.0142197174427565, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 364, train_loss = 1.0124977299419697, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 365, train_loss = 1.0125016371312086, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 366, train_loss = 1.0111212513002101, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 367, train_loss = 1.010447392851347, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 368, train_loss = 1.010100662097102, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 369, train_loss = 1.0093146488070488, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 370, train_loss = 1.0082139366713818, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 371, train_loss = 1.0080459204909857, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 372, train_loss = 1.0070347817090806, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 373, train_loss = 1.0067487905325834, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 374, train_loss = 1.005627939477563, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 375, train_loss = 1.0047991958854254, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 376, train_loss = 1.0041498386708554, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 377, train_loss = 1.003453105688095, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 378, train_loss = 1.002989356085891, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 379, train_loss = 1.002040147781372, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 380, train_loss = 1.0019361606391612, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 381, train_loss = 1.000929811358219, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 382, train_loss = 1.0003293063491583, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 383, train_loss = 0.9996007482113782, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 384, train_loss = 0.9990884717553854, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 385, train_loss = 0.9982969189586584, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 386, train_loss = 0.9976428244262934, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 387, train_loss = 0.9967680163681507, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 388, train_loss = 0.9962675192800816, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 389, train_loss = 0.9955802174808923, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 390, train_loss = 0.9948626862314995, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 391, train_loss = 0.9948859947326127, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 392, train_loss = 0.9935680162161589, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 393, train_loss = 0.993116212397581, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 394, train_loss = 0.9926156594010536, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 395, train_loss = 0.992039574921364, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 396, train_loss = 0.9912780529411975, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 397, train_loss = 0.9908814492227975, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 398, train_loss = 0.9898582343012094, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 399, train_loss = 0.9895793783070985, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 400, train_loss = 0.9885506201535463, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 401, train_loss = 0.9882382204232272, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 402, train_loss = 0.9873228874057531, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 403, train_loss = 0.9868203848600388, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 404, train_loss = 0.9861405733972788, train_acc = 0.9976711690731253\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 405, train_loss = 0.9857379098830279, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 406, train_loss = 0.9851573774067219, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 407, train_loss = 0.9845943512918893, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 408, train_loss = 0.9839946584252175, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 409, train_loss = 0.9833062402904034, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 410, train_loss = 0.982689468190074, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 411, train_loss = 0.9821369735000189, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 412, train_loss = 0.9816307928413153, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 413, train_loss = 0.9809090942144394, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 414, train_loss = 0.9803460147231817, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 415, train_loss = 0.9798148907721043, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 416, train_loss = 0.9788947111519519, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 417, train_loss = 0.9788668379187584, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 418, train_loss = 0.9781528767198324, train_acc = 0.9977876106194691\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 419, train_loss = 0.977335407078499, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 420, train_loss = 0.9769167496415321, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 421, train_loss = 0.9766181781888008, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 422, train_loss = 0.9754815008491278, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 423, train_loss = 0.9753433118166868, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 424, train_loss = 0.9745432703348342, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 425, train_loss = 0.9743018212320749, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 426, train_loss = 0.9733784155396279, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 427, train_loss = 0.9729247701761778, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 428, train_loss = 0.972327940777177, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 429, train_loss = 0.9721113741397858, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 430, train_loss = 0.971001989528304, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 431, train_loss = 0.9705135698022787, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 432, train_loss = 0.9701886766997632, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 433, train_loss = 0.9697750241903123, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 434, train_loss = 0.9692665828915779, train_acc = 0.9977876106194691\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 435, train_loss = 0.9684373581258114, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 436, train_loss = 0.9680031960306223, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 437, train_loss = 0.9672546802612487, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 438, train_loss = 0.9672727113065775, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 439, train_loss = 0.9663515767606441, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 440, train_loss = 0.965909443795681, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 441, train_loss = 0.9657401225122157, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 442, train_loss = 0.9646005742251873, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 443, train_loss = 0.9641133540717419, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 444, train_loss = 0.9634688409569208, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 445, train_loss = 0.9633409834059421, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 446, train_loss = 0.9625078725221101, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 447, train_loss = 0.9622702716442291, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 448, train_loss = 0.9615666183235589, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 449, train_loss = 0.9614044930785894, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 450, train_loss = 0.9603755784628447, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 451, train_loss = 0.960353909060359, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 452, train_loss = 0.9594604410231113, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 453, train_loss = 0.9588655810803175, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 454, train_loss = 0.9585188912751619, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 455, train_loss = 0.9575009563413914, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 456, train_loss = 0.956962584197754, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 457, train_loss = 0.9560240426508244, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 458, train_loss = 0.9558892448840197, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 459, train_loss = 0.9552032606152352, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 460, train_loss = 0.9551013000309467, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 461, train_loss = 0.9539617815462407, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 462, train_loss = 0.9536301170883235, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 463, train_loss = 0.9526821853069123, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 464, train_loss = 0.952475501835579, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 465, train_loss = 0.9521490801125765, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 466, train_loss = 0.9514665566384792, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 467, train_loss = 0.9503890642372426, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 468, train_loss = 0.9506861145200673, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 469, train_loss = 0.9498480850306805, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 470, train_loss = 0.9492681908013765, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 471, train_loss = 0.9491933975368738, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 472, train_loss = 0.9482716259954032, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 473, train_loss = 0.9473899075237568, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 474, train_loss = 0.9474447853863239, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 475, train_loss = 0.9467526817170437, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 476, train_loss = 0.9461689330637455, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 477, train_loss = 0.9459592793136835, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 478, train_loss = 0.9452602888050023, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 479, train_loss = 0.944947045907611, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 480, train_loss = 0.9441990492341574, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 481, train_loss = 0.9436871639045421, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 482, train_loss = 0.9431424414215144, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 483, train_loss = 0.9433091524988413, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 484, train_loss = 0.942562535405159, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 485, train_loss = 0.941997742280364, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 486, train_loss = 0.9416073150932789, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 487, train_loss = 0.9410806726664305, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 488, train_loss = 0.9407107768056449, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 489, train_loss = 0.9404689030197915, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 490, train_loss = 0.9401325372455176, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 491, train_loss = 0.939531081035966, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 492, train_loss = 0.9389779729244765, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 493, train_loss = 0.9383330252021551, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 494, train_loss = 0.9384257160127163, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 495, train_loss = 0.9382991498860065, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 496, train_loss = 0.9372755351068918, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 497, train_loss = 0.9370365931245033, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 498, train_loss = 0.9365387534198817, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 499, train_loss = 0.9359425436705351, train_acc = 0.9979040521658128\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████▏    | 28/30 [4:38:36<19:19, 579.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "29th- epoch: 0, train_loss = 149.6169278025627, train_acc = 0.7310200279459711\n",
      "test Acc 0.8659217877094972:\n",
      "29th- epoch: 1, train_loss = 53.62474758177996, train_acc = 0.8886818816953889\n",
      "test Acc 0.9115456238361266:\n",
      "29th- epoch: 2, train_loss = 37.865694642066956, train_acc = 0.9243129948765719\n",
      "test Acc 0.9269087523277467:\n",
      "29th- epoch: 3, train_loss = 29.903529573231936, train_acc = 0.9392175128085701\n",
      "test Acc 0.9320297951582868:\n",
      "29th- epoch: 4, train_loss = 24.807492550462484, train_acc = 0.9492314857941313\n",
      "test Acc 0.9366852886405959:\n",
      "29th- epoch: 5, train_loss = 21.231363020837307, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "29th- epoch: 6, train_loss = 18.573810266330838, train_acc = 0.9619236143455985\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 7, train_loss = 16.53020779415965, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "29th- epoch: 8, train_loss = 14.909305272623897, train_acc = 0.9717047042384723\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 9, train_loss = 13.559666914865375, train_acc = 0.9749650675360969\n",
      "test Acc 0.9553072625698324:\n",
      "29th- epoch: 10, train_loss = 12.433484831824899, train_acc = 0.9772938984629715\n",
      "test Acc 0.9567039106145251:\n",
      "29th- epoch: 11, train_loss = 11.475431310012937, train_acc = 0.9789240801117839\n",
      "test Acc 0.957169459962756:\n",
      "29th- epoch: 12, train_loss = 10.649115649983287, train_acc = 0.9809035863996274\n",
      "test Acc 0.9585661080074488:\n",
      "29th- epoch: 13, train_loss = 9.936250390484929, train_acc = 0.9823008849557522\n",
      "test Acc 0.9590316573556797:\n",
      "29th- epoch: 14, train_loss = 9.305753024294972, train_acc = 0.9835817419655333\n",
      "test Acc 0.9608938547486033:\n",
      "29th- epoch: 15, train_loss = 8.759614832699299, train_acc = 0.9846297158826269\n",
      "test Acc 0.9613594040968343:\n",
      "29th- epoch: 16, train_loss = 8.270342748612165, train_acc = 0.9853283651606893\n",
      "test Acc 0.962756052141527:\n",
      "29th- epoch: 17, train_loss = 7.830575382336974, train_acc = 0.986376339077783\n",
      "test Acc 0.9636871508379888:\n",
      "29th- epoch: 18, train_loss = 7.437997285276651, train_acc = 0.9869585468095017\n",
      "test Acc 0.9646182495344506:\n",
      "29th- epoch: 19, train_loss = 7.080802768468857, train_acc = 0.9878900791802515\n",
      "test Acc 0.9660148975791434:\n",
      "29th- epoch: 20, train_loss = 6.754298806190491, train_acc = 0.9888216115510013\n",
      "test Acc 0.9660148975791434:\n",
      "29th- epoch: 21, train_loss = 6.4554005758836865, train_acc = 0.9891709361900326\n",
      "test Acc 0.9669459962756052:\n",
      "29th- epoch: 22, train_loss = 6.179545794613659, train_acc = 0.9899860270144387\n",
      "test Acc 0.9674115456238361:\n",
      "29th- epoch: 23, train_loss = 5.926850602962077, train_acc = 0.9905682347461574\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 24, train_loss = 5.691966409794986, train_acc = 0.9911504424778761\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 25, train_loss = 5.4744872292503715, train_acc = 0.9912668840242198\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 26, train_loss = 5.274001348763704, train_acc = 0.9916162086632511\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 27, train_loss = 5.086825329810381, train_acc = 0.9917326502095948\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 28, train_loss = 4.91217377781868, train_acc = 0.9921984163949698\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 29, train_loss = 4.74983396846801, train_acc = 0.9923148579413135\n",
      "test Acc 0.9688081936685289:\n",
      "29th- epoch: 30, train_loss = 4.596750509925187, train_acc = 0.9923148579413135\n",
      "test Acc 0.9688081936685289:\n",
      "29th- epoch: 31, train_loss = 4.455081447027624, train_acc = 0.9926641825803446\n",
      "test Acc 0.9688081936685289:\n",
      "29th- epoch: 32, train_loss = 4.323426283895969, train_acc = 0.9930135072193759\n",
      "test Acc 0.9688081936685289:\n",
      "29th- epoch: 33, train_loss = 4.1986332712695, train_acc = 0.9932463903120633\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 34, train_loss = 4.081655479967594, train_acc = 0.9935957149510946\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 35, train_loss = 3.9718735069036484, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 36, train_loss = 3.8692690059542656, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 37, train_loss = 3.77108518127352, train_acc = 0.994294364229157\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 38, train_loss = 3.678164786659181, train_acc = 0.994294364229157\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 39, train_loss = 3.5915647679939866, train_acc = 0.9944108057755007\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 40, train_loss = 3.5086621530354023, train_acc = 0.9944108057755007\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 41, train_loss = 3.4310192773118615, train_acc = 0.9944108057755007\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 42, train_loss = 3.354919943958521, train_acc = 0.9947601304145319\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 43, train_loss = 3.2844346882775426, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 44, train_loss = 3.2178898891434073, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 45, train_loss = 3.151592003647238, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 46, train_loss = 3.0912625514902174, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 47, train_loss = 3.0324435606598854, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 48, train_loss = 2.9786483333446085, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 49, train_loss = 2.9250137731432915, train_acc = 0.9952258965999069\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 50, train_loss = 2.8741814382374287, train_acc = 0.9953423381462506\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 51, train_loss = 2.826204054057598, train_acc = 0.9953423381462506\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 52, train_loss = 2.7789630391635, train_acc = 0.9953423381462506\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 53, train_loss = 2.735313694924116, train_acc = 0.9954587796925943\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 54, train_loss = 2.6925105205737054, train_acc = 0.9954587796925943\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 55, train_loss = 2.651206272188574, train_acc = 0.9954587796925943\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 56, train_loss = 2.6114506870508194, train_acc = 0.9954587796925943\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 57, train_loss = 2.5733495191670954, train_acc = 0.9959245458779693\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 58, train_loss = 2.53679925063625, train_acc = 0.996040987424313\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 59, train_loss = 2.5025507993996143, train_acc = 0.9961574289706567\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 60, train_loss = 2.468379785772413, train_acc = 0.9961574289706567\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 61, train_loss = 2.436751106288284, train_acc = 0.9963903120633442\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 62, train_loss = 2.4052334115840495, train_acc = 0.9963903120633442\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 63, train_loss = 2.3747638538479805, train_acc = 0.9963903120633442\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 64, train_loss = 2.34655349701643, train_acc = 0.9963903120633442\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 65, train_loss = 2.3193023675121367, train_acc = 0.9963903120633442\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 66, train_loss = 2.292306173592806, train_acc = 0.9963903120633442\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 67, train_loss = 2.266552098095417, train_acc = 0.996506753609688\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 68, train_loss = 2.2421106942929327, train_acc = 0.9967396367023754\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 69, train_loss = 2.2176072583533823, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 70, train_loss = 2.194194866809994, train_acc = 0.9967396367023754\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 71, train_loss = 2.1711449935100973, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 72, train_loss = 2.149437803775072, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 73, train_loss = 2.1280536018311977, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 74, train_loss = 2.1071535111404955, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 75, train_loss = 2.086687014903873, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 76, train_loss = 2.0685757375322282, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 77, train_loss = 2.0487598688341677, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 78, train_loss = 2.0311631858348846, train_acc = 0.9968560782487191\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 79, train_loss = 2.013146582990885, train_acc = 0.9968560782487191\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 80, train_loss = 1.9960088296793401, train_acc = 0.9968560782487191\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 81, train_loss = 1.9795338064432144, train_acc = 0.9968560782487191\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 82, train_loss = 1.9628854766488075, train_acc = 0.9968560782487191\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 83, train_loss = 1.9477363303303719, train_acc = 0.9968560782487191\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 84, train_loss = 1.9324581201653928, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "29th- epoch: 85, train_loss = 1.9176216621417552, train_acc = 0.9970889613414066\n",
      "test Acc 0.9720670391061452:\n",
      "29th- epoch: 86, train_loss = 1.9029550615232438, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "29th- epoch: 87, train_loss = 1.8891410182695836, train_acc = 0.9970889613414066\n",
      "test Acc 0.9725325884543762:\n",
      "29th- epoch: 88, train_loss = 1.8751125794369727, train_acc = 0.9969725197950629\n",
      "test Acc 0.9725325884543762:\n",
      "29th- epoch: 89, train_loss = 1.861282779602334, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 90, train_loss = 1.8487262923736125, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 91, train_loss = 1.8355944368522614, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 92, train_loss = 1.8238609917461872, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 93, train_loss = 1.810790954856202, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 94, train_loss = 1.798962990520522, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 95, train_loss = 1.787694989470765, train_acc = 0.9970889613414066\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 96, train_loss = 1.776190823642537, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 97, train_loss = 1.764682335080579, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 98, train_loss = 1.7546792279463261, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 99, train_loss = 1.7439134195446968, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 100, train_loss = 1.7328246484976262, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 101, train_loss = 1.7239032860379666, train_acc = 0.9973218444340941\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 102, train_loss = 1.7133594353217632, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 103, train_loss = 1.704045083373785, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 104, train_loss = 1.694730156334117, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 105, train_loss = 1.6857339579146355, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 106, train_loss = 1.6764862835407257, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 107, train_loss = 1.6677634094376117, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 108, train_loss = 1.658907235832885, train_acc = 0.9973218444340941\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 109, train_loss = 1.6506909728050232, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 110, train_loss = 1.6424237515311688, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 111, train_loss = 1.6341513593215495, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 112, train_loss = 1.6260665841400623, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 113, train_loss = 1.6185075987596065, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 114, train_loss = 1.610882083652541, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 115, train_loss = 1.6037139396648854, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 116, train_loss = 1.5961070992052555, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 117, train_loss = 1.5891337357461452, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 118, train_loss = 1.581866982160136, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 119, train_loss = 1.5747932631056756, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 120, train_loss = 1.5685385044198483, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 121, train_loss = 1.5610810618381947, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 122, train_loss = 1.5549913458526134, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 123, train_loss = 1.5484017096459866, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 124, train_loss = 1.5418523971457034, train_acc = 0.9974382859804378\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 125, train_loss = 1.5358705135295168, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 126, train_loss = 1.5295053906738758, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 127, train_loss = 1.5236940160393715, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 128, train_loss = 1.5182117596268654, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 129, train_loss = 1.5120036378502846, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 130, train_loss = 1.5064568482339382, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 131, train_loss = 1.5007973102619871, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 132, train_loss = 1.4951332857599482, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 133, train_loss = 1.4897776854922995, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 134, train_loss = 1.484175592660904, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 135, train_loss = 1.4793910483131185, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 136, train_loss = 1.474087425856851, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 137, train_loss = 1.4692332074046135, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 138, train_loss = 1.4638534659752622, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 139, train_loss = 1.459120592684485, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 140, train_loss = 1.4540922219166532, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 141, train_loss = 1.449364018975757, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 142, train_loss = 1.444429598748684, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 143, train_loss = 1.4400208704173565, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 144, train_loss = 1.435194974183105, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 145, train_loss = 1.4309655638644472, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 146, train_loss = 1.4260651431977749, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 147, train_loss = 1.4217095276108012, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 148, train_loss = 1.4176114773144946, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 149, train_loss = 1.4127171263098717, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 150, train_loss = 1.4089895226061344, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 151, train_loss = 1.4042449332773685, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 152, train_loss = 1.4010741909733042, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 153, train_loss = 1.3961929505458102, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 154, train_loss = 1.3926337076118216, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 155, train_loss = 1.3886529095470905, train_acc = 0.9974382859804378\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 156, train_loss = 1.3844209586968645, train_acc = 0.9975547275267815\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 157, train_loss = 1.3809911297867075, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 158, train_loss = 1.3765385001897812, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 159, train_loss = 1.3733278065919876, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 160, train_loss = 1.3692337088286877, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 161, train_loss = 1.3656113781034946, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 162, train_loss = 1.361602745950222, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 163, train_loss = 1.3578904904425144, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 164, train_loss = 1.3545729169854894, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 165, train_loss = 1.3506507476558909, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 166, train_loss = 1.3468421486904845, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 167, train_loss = 1.3437813644995913, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 168, train_loss = 1.3405020833015442, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 169, train_loss = 1.336807917803526, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 170, train_loss = 1.3335998406400904, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 171, train_loss = 1.3299271427094936, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 172, train_loss = 1.326690137386322, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 173, train_loss = 1.3234695605933666, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 174, train_loss = 1.3205524235963821, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 175, train_loss = 1.3171203769743443, train_acc = 0.9974382859804378\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 176, train_loss = 1.3138381032040343, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 177, train_loss = 1.3109198535094038, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 178, train_loss = 1.3078196396818385, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 179, train_loss = 1.3046434732386842, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 180, train_loss = 1.301716453046538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 181, train_loss = 1.299277683137916, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 182, train_loss = 1.2963362733135, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 183, train_loss = 1.2935751056065783, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 184, train_loss = 1.2902610538294539, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 185, train_loss = 1.2878375811269507, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 186, train_loss = 1.2850738912820816, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 187, train_loss = 1.2822481567272916, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 188, train_loss = 1.2794140987098217, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 189, train_loss = 1.276961013674736, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 190, train_loss = 1.2742196643957868, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 191, train_loss = 1.2721199492225423, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 192, train_loss = 1.2692756267497316, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 193, train_loss = 1.2663960395148024, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 194, train_loss = 1.2640006678411737, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 195, train_loss = 1.2620456889271736, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 196, train_loss = 1.2591873122146353, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 197, train_loss = 1.2563539656694047, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 198, train_loss = 1.2539496484096162, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 199, train_loss = 1.2520430994336493, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 200, train_loss = 1.2490481126005761, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 201, train_loss = 1.2465330598060973, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 202, train_loss = 1.2441594836418517, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 203, train_loss = 1.2421549335122108, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 204, train_loss = 1.2396116442978382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 205, train_loss = 1.2379971779882908, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 206, train_loss = 1.2350246260757558, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 207, train_loss = 1.2330849915742874, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 208, train_loss = 1.2305503872339614, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 209, train_loss = 1.228370041877497, train_acc = 0.9975547275267815\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 210, train_loss = 1.22642733406974, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 211, train_loss = 1.223827499896288, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 212, train_loss = 1.2221729407901876, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 213, train_loss = 1.2202034567599185, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 214, train_loss = 1.2180297411978245, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 215, train_loss = 1.2159972327644937, train_acc = 0.9975547275267815\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 216, train_loss = 1.2136724789743312, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 217, train_loss = 1.2116381488740444, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 218, train_loss = 1.2101281471550465, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 219, train_loss = 1.2080586006049998, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 220, train_loss = 1.2060714078252204, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 221, train_loss = 1.2041131469304673, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 222, train_loss = 1.20215567573905, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 223, train_loss = 1.1999692767858505, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 224, train_loss = 1.1980648313765414, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 225, train_loss = 1.1957866214215755, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 226, train_loss = 1.1940981671214104, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 227, train_loss = 1.1921874496038072, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 228, train_loss = 1.1908466455643065, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 229, train_loss = 1.1885074724559672, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 230, train_loss = 1.1864284847979434, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 231, train_loss = 1.1851591530139558, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 232, train_loss = 1.183062391995918, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 233, train_loss = 1.1814883698825724, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 234, train_loss = 1.1798949353396893, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 235, train_loss = 1.178161982446909, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 236, train_loss = 1.176254929334391, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 237, train_loss = 1.1743311062455177, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 238, train_loss = 1.1726095452904701, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 239, train_loss = 1.1711206212639809, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 240, train_loss = 1.1698758688871749, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 241, train_loss = 1.167896541475784, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 242, train_loss = 1.1659956239163876, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 243, train_loss = 1.164536491036415, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 244, train_loss = 1.1630279049277306, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 245, train_loss = 1.1611113126273267, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 246, train_loss = 1.159249032556545, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 247, train_loss = 1.1582698039710522, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 248, train_loss = 1.1563429062371142, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 249, train_loss = 1.1549041506950743, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 250, train_loss = 1.1533793359994888, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 251, train_loss = 1.1519980492885225, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 252, train_loss = 1.150237177789677, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 253, train_loss = 1.1487220898270607, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 254, train_loss = 1.14715127897216, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 255, train_loss = 1.1460500694811344, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 256, train_loss = 1.1442203459446318, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 257, train_loss = 1.1424781667883508, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 258, train_loss = 1.1413799623842351, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 259, train_loss = 1.140330656140577, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 260, train_loss = 1.1385357392136939, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 261, train_loss = 1.1365837802295573, train_acc = 0.9975547275267815\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 262, train_loss = 1.1359881038661115, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 263, train_loss = 1.1341485306620598, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 264, train_loss = 1.1327589191496372, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 265, train_loss = 1.1320117761497386, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 266, train_loss = 1.129989355802536, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 267, train_loss = 1.1287156392936595, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 268, train_loss = 1.127374466508627, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 269, train_loss = 1.125757495581638, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 270, train_loss = 1.124594068794977, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 271, train_loss = 1.1229994595050812, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 272, train_loss = 1.1223334856331348, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 273, train_loss = 1.1207155957818031, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 274, train_loss = 1.1192513518035412, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 275, train_loss = 1.1181626170873642, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 276, train_loss = 1.1167713577742688, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 277, train_loss = 1.115534855693113, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 278, train_loss = 1.1143317793612368, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 279, train_loss = 1.113266121596098, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 280, train_loss = 1.1114784355158918, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 281, train_loss = 1.1103345814044587, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 282, train_loss = 1.109483788430225, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 283, train_loss = 1.107965610921383, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 284, train_loss = 1.1064842392806895, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 285, train_loss = 1.1058374606072903, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 286, train_loss = 1.1045252296025865, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 287, train_loss = 1.1033173874020576, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 288, train_loss = 1.1018114524777047, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 289, train_loss = 1.100762712478172, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 290, train_loss = 1.0996277096564882, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 291, train_loss = 1.0983230409328826, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 292, train_loss = 1.0972770750522614, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 293, train_loss = 1.0964647941291332, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 294, train_loss = 1.0949915833771229, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 295, train_loss = 1.0940611970727332, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 296, train_loss = 1.0927251254324801, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 297, train_loss = 1.0918204064364545, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 298, train_loss = 1.0904386204783805, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 299, train_loss = 1.0891955618862994, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 300, train_loss = 1.0887512427871116, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 301, train_loss = 1.0871735562686808, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 302, train_loss = 1.0861283503472805, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 303, train_loss = 1.0851589180529118, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 304, train_loss = 1.0838709622621536, train_acc = 0.9976711690731253\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 305, train_loss = 1.0830160938203335, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 306, train_loss = 1.081917756528128, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 307, train_loss = 1.080914503603708, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 308, train_loss = 1.079595647752285, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 309, train_loss = 1.0787257005576976, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 310, train_loss = 1.0779506613616832, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 311, train_loss = 1.076648065180052, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 312, train_loss = 1.0756054644589312, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 313, train_loss = 1.0747513361275196, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 314, train_loss = 1.0736083972151391, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 315, train_loss = 1.072336856275797, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 316, train_loss = 1.0716489093902055, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 317, train_loss = 1.070652760565281, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 318, train_loss = 1.0698464438319206, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 319, train_loss = 1.068831975251669, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 320, train_loss = 1.067495054245228, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 321, train_loss = 1.0667887131276075, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 322, train_loss = 1.065836033463711, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 323, train_loss = 1.0647486299276352, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 324, train_loss = 1.0641355253756046, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 325, train_loss = 1.0626335255801678, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 326, train_loss = 1.061967155575985, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 327, train_loss = 1.0611835047602654, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 328, train_loss = 1.060214755445486, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 329, train_loss = 1.0590143911540508, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 330, train_loss = 1.058221872895956, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 331, train_loss = 1.0572836833598558, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 332, train_loss = 1.0563273951411247, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 333, train_loss = 1.0554504642786924, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 334, train_loss = 1.054523574799532, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 335, train_loss = 1.0536270563898142, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 336, train_loss = 1.0526864863932133, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 337, train_loss = 1.0517884331347886, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 338, train_loss = 1.0509824082255363, train_acc = 0.9976711690731253\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 339, train_loss = 1.0502321322856005, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 340, train_loss = 1.0492101348936558, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 341, train_loss = 1.048378024250269, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 342, train_loss = 1.047386651247507, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 343, train_loss = 1.0467709625663701, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 344, train_loss = 1.046005830168724, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 345, train_loss = 1.0448623920383397, train_acc = 0.9976711690731253\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 346, train_loss = 1.044051961362129, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 347, train_loss = 1.0432341272535268, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 348, train_loss = 1.042594838887453, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 349, train_loss = 1.0416548736393452, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 350, train_loss = 1.040603188186651, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 351, train_loss = 1.0397879878582899, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 352, train_loss = 1.0391095988452435, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 353, train_loss = 1.0383324064314365, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 354, train_loss = 1.0375661539437715, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 355, train_loss = 1.0365890227258205, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 356, train_loss = 1.0358096547424793, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 357, train_loss = 1.0352860713901464, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 358, train_loss = 1.0342225755157415, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 359, train_loss = 1.0333526184258517, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 360, train_loss = 1.0323824286460876, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 361, train_loss = 1.0320809856057167, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 362, train_loss = 1.0309942749736365, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 363, train_loss = 1.0299800907669123, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 364, train_loss = 1.029064475238556, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 365, train_loss = 1.0288900844752789, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 366, train_loss = 1.0279217151401099, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 367, train_loss = 1.0273183174431324, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 368, train_loss = 1.0263958163559437, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 369, train_loss = 1.0257607847452164, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 370, train_loss = 1.0249865874648094, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 371, train_loss = 1.0241078585386276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 372, train_loss = 1.0234906251134817, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 373, train_loss = 1.0228652817604598, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 374, train_loss = 1.0218417470750865, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 375, train_loss = 1.0211122570035513, train_acc = 0.9976711690731253\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 376, train_loss = 1.020599253475666, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 377, train_loss = 1.0196858495473862, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 378, train_loss = 1.0189234775898512, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 379, train_loss = 1.018544221908087, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 380, train_loss = 1.017591188341612, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 381, train_loss = 1.0169080359337386, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 382, train_loss = 1.0160166857240256, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 383, train_loss = 1.015744070202345, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 384, train_loss = 1.0148468539118767, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 385, train_loss = 1.013929375767475, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 386, train_loss = 1.0133190626802389, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 387, train_loss = 1.012516152113676, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 388, train_loss = 1.0120976939797401, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 389, train_loss = 1.0113564928469714, train_acc = 0.9977876106194691\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 390, train_loss = 1.0108254862425383, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 391, train_loss = 1.010189812630415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 392, train_loss = 1.0092123709619045, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 393, train_loss = 1.0085360445082188, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 394, train_loss = 1.008154571056366, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 395, train_loss = 1.0074110316636506, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 396, train_loss = 1.0066489788296167, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 397, train_loss = 1.0058652435836848, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 398, train_loss = 1.00536877909326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 399, train_loss = 1.0050822347402573, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 400, train_loss = 1.0041084165277425, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 401, train_loss = 1.003300927579403, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 402, train_loss = 1.0027829892933369, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 403, train_loss = 1.0021380273101386, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 404, train_loss = 1.0014861524105072, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 405, train_loss = 1.0009348528983537, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 406, train_loss = 1.0003672564926092, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 407, train_loss = 0.9995911357400473, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 408, train_loss = 0.9989490273001138, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 409, train_loss = 0.9983381181955338, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 410, train_loss = 0.99775225049234, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 411, train_loss = 0.9969380001130048, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 412, train_loss = 0.9963798386452254, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 413, train_loss = 0.995830561965704, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 414, train_loss = 0.9955124469997827, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 415, train_loss = 0.994856712728506, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 416, train_loss = 0.9940850424172822, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 417, train_loss = 0.9939236467180308, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 418, train_loss = 0.9928318721649703, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 419, train_loss = 0.9925340799090918, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 420, train_loss = 0.9916577388939913, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 421, train_loss = 0.9910611783561762, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 422, train_loss = 0.990547643363243, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 423, train_loss = 0.9901544153690338, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 424, train_loss = 0.9892287043330725, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 425, train_loss = 0.9887016527354717, train_acc = 0.9976711690731253\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 426, train_loss = 0.9882602343859617, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 427, train_loss = 0.9876302468182985, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 428, train_loss = 0.9869572421011981, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 429, train_loss = 0.9863406233489513, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 430, train_loss = 0.9859435508551542, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 431, train_loss = 0.985427030682331, train_acc = 0.9977876106194691\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 432, train_loss = 0.9852031419577543, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 433, train_loss = 0.9838145623507444, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 434, train_loss = 0.983470050006872, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 435, train_loss = 0.9830278629960958, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 436, train_loss = 0.9826026881637517, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 437, train_loss = 0.9818504949507769, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 438, train_loss = 0.9813023917376995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 439, train_loss = 0.9810486398637295, train_acc = 0.9979040521658128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 440, train_loss = 0.980447302252287, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 441, train_loss = 0.9796858665940817, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 442, train_loss = 0.9796094285848085, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 443, train_loss = 0.978645416587824, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 444, train_loss = 0.9781287871301174, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 445, train_loss = 0.9776122123003006, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 446, train_loss = 0.9769382079539355, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 447, train_loss = 0.9765566711721476, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 448, train_loss = 0.976061542838579, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 449, train_loss = 0.9753991390170995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 450, train_loss = 0.9749480398895685, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 451, train_loss = 0.9744783540663775, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 452, train_loss = 0.9738808634283487, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 453, train_loss = 0.9733362148108426, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 454, train_loss = 0.9727469719946384, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 455, train_loss = 0.9720395815966185, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 456, train_loss = 0.9718252023158129, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 457, train_loss = 0.9714628172514495, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 458, train_loss = 0.9706942451593932, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 459, train_loss = 0.9701949121954385, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 460, train_loss = 0.969650217652088, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 461, train_loss = 0.9692204209568445, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 462, train_loss = 0.9683811689319555, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 463, train_loss = 0.9682055277226027, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 464, train_loss = 0.967750359326601, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 465, train_loss = 0.9672970747051295, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 466, train_loss = 0.9667529575526714, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 467, train_loss = 0.9659955824317876, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 468, train_loss = 0.9659591019153595, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 469, train_loss = 0.9648983366787434, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 470, train_loss = 0.96477715545916, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 471, train_loss = 0.9643233815731946, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 472, train_loss = 0.9637331540288869, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 473, train_loss = 0.9632119908928871, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 474, train_loss = 0.9626973085105419, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 475, train_loss = 0.9623052912356798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 476, train_loss = 0.9619225958886091, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 477, train_loss = 0.961356128245825, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 478, train_loss = 0.9607673125865404, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 479, train_loss = 0.9604154489934444, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 480, train_loss = 0.9597599220869597, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 481, train_loss = 0.9593199504015502, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 482, train_loss = 0.9587828578951303, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 483, train_loss = 0.9586131796240807, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 484, train_loss = 0.9579557428660337, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 485, train_loss = 0.9574803771974985, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 486, train_loss = 0.9567511156201363, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 487, train_loss = 0.9565227143466473, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 488, train_loss = 0.9557969855668489, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 489, train_loss = 0.955502742290264, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 490, train_loss = 0.9554888345301151, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 491, train_loss = 0.9547821717860643, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 492, train_loss = 0.9540827622113284, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 493, train_loss = 0.9534441083669662, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 494, train_loss = 0.9531763990817126, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 495, train_loss = 0.9528344993887004, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 496, train_loss = 0.9521836948988494, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 497, train_loss = 0.9518940970301628, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 498, train_loss = 0.9511707474885043, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n",
      "29th- epoch: 499, train_loss = 0.9507911962864455, train_acc = 0.9979040521658128\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████▌  | 29/30 [4:47:11<09:20, 560.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "30th- epoch: 0, train_loss = 147.08830343186855, train_acc = 0.7186772240335352\n",
      "test Acc 0.8314711359404097:\n",
      "30th- epoch: 1, train_loss = 53.687663190066814, train_acc = 0.8821611551001397\n",
      "test Acc 0.8910614525139665:\n",
      "30th- epoch: 2, train_loss = 37.45364032685757, train_acc = 0.9175593851886353\n",
      "test Acc 0.9078212290502793:\n",
      "30th- epoch: 3, train_loss = 29.51941943541169, train_acc = 0.935724266418258\n",
      "test Acc 0.9180633147113594:\n",
      "30th- epoch: 4, train_loss = 24.622521802783012, train_acc = 0.9495808104331626\n",
      "test Acc 0.9236499068901304:\n",
      "30th- epoch: 5, train_loss = 21.18886574730277, train_acc = 0.9572659524918491\n",
      "test Acc 0.9269087523277467:\n",
      "30th- epoch: 6, train_loss = 18.60618700273335, train_acc = 0.9613414066138798\n",
      "test Acc 0.9287709497206704:\n",
      "30th- epoch: 7, train_loss = 16.56363419443369, train_acc = 0.9664648346530041\n",
      "test Acc 0.9334264432029795:\n",
      "30th- epoch: 8, train_loss = 14.915775725618005, train_acc = 0.9694923148579413\n",
      "test Acc 0.9357541899441341:\n",
      "30th- epoch: 9, train_loss = 13.54411274753511, train_acc = 0.9717047042384723\n",
      "test Acc 0.9380819366852886:\n",
      "30th- epoch: 10, train_loss = 12.404391882941127, train_acc = 0.9751979506287843\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 11, train_loss = 11.441896924749017, train_acc = 0.9771774569166278\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 12, train_loss = 10.605594966560602, train_acc = 0.9790405216581276\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 13, train_loss = 9.883215297013521, train_acc = 0.9810200279459711\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 14, train_loss = 9.246118668466806, train_acc = 0.9820680018630648\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 15, train_loss = 8.684575044550002, train_acc = 0.9832324173265021\n",
      "test Acc 0.9487895716945997:\n",
      "30th- epoch: 16, train_loss = 8.175269235856831, train_acc = 0.9846297158826269\n",
      "test Acc 0.9492551210428305:\n",
      "30th- epoch: 17, train_loss = 7.72504160925746, train_acc = 0.9862598975314392\n",
      "test Acc 0.952048417132216:\n",
      "30th- epoch: 18, train_loss = 7.323637490160763, train_acc = 0.9870749883558454\n",
      "test Acc 0.9534450651769087:\n",
      "30th- epoch: 19, train_loss = 6.957313373684883, train_acc = 0.9878900791802515\n",
      "test Acc 0.9543761638733705:\n",
      "30th- epoch: 20, train_loss = 6.6279305359348655, train_acc = 0.9891709361900326\n",
      "test Acc 0.9548417132216015:\n",
      "30th- epoch: 21, train_loss = 6.326557143591344, train_acc = 0.9896367023754076\n",
      "test Acc 0.9548417132216015:\n",
      "30th- epoch: 22, train_loss = 6.053770176135004, train_acc = 0.989869585468095\n",
      "test Acc 0.9548417132216015:\n",
      "30th- epoch: 23, train_loss = 5.807013772428036, train_acc = 0.9906846762925011\n",
      "test Acc 0.9553072625698324:\n",
      "30th- epoch: 24, train_loss = 5.577893518842757, train_acc = 0.990801117838845\n",
      "test Acc 0.9557728119180633:\n",
      "30th- epoch: 25, train_loss = 5.369193475693464, train_acc = 0.9912668840242198\n",
      "test Acc 0.9557728119180633:\n",
      "30th- epoch: 26, train_loss = 5.173970807343721, train_acc = 0.9917326502095948\n",
      "test Acc 0.9557728119180633:\n",
      "30th- epoch: 27, train_loss = 4.995410422794521, train_acc = 0.9924312994876572\n",
      "test Acc 0.9562383612662942:\n",
      "30th- epoch: 28, train_loss = 4.829411011189222, train_acc = 0.9930135072193759\n",
      "test Acc 0.9567039106145251:\n",
      "30th- epoch: 29, train_loss = 4.677800762467086, train_acc = 0.9937121564974383\n",
      "test Acc 0.9567039106145251:\n",
      "30th- epoch: 30, train_loss = 4.533607763238251, train_acc = 0.993828598043782\n",
      "test Acc 0.9567039106145251:\n",
      "30th- epoch: 31, train_loss = 4.40405302029103, train_acc = 0.993828598043782\n",
      "test Acc 0.957635009310987:\n",
      "30th- epoch: 32, train_loss = 4.279163064900786, train_acc = 0.9940614811364695\n",
      "test Acc 0.9581005586592178:\n",
      "30th- epoch: 33, train_loss = 4.165681719779968, train_acc = 0.9940614811364695\n",
      "test Acc 0.9585661080074488:\n",
      "30th- epoch: 34, train_loss = 4.058089168276638, train_acc = 0.9940614811364695\n",
      "test Acc 0.9585661080074488:\n",
      "30th- epoch: 35, train_loss = 3.9543281607329845, train_acc = 0.9940614811364695\n",
      "test Acc 0.9604283054003724:\n",
      "30th- epoch: 36, train_loss = 3.859377925749868, train_acc = 0.9940614811364695\n",
      "test Acc 0.9604283054003724:\n",
      "30th- epoch: 37, train_loss = 3.766312280204147, train_acc = 0.994294364229157\n",
      "test Acc 0.9608938547486033:\n",
      "30th- epoch: 38, train_loss = 3.684158619493246, train_acc = 0.994294364229157\n",
      "test Acc 0.9608938547486033:\n",
      "30th- epoch: 39, train_loss = 3.6011531897820532, train_acc = 0.994294364229157\n",
      "test Acc 0.9613594040968343:\n",
      "30th- epoch: 40, train_loss = 3.5237066275440156, train_acc = 0.9944108057755007\n",
      "test Acc 0.9608938547486033:\n",
      "30th- epoch: 41, train_loss = 3.450692632701248, train_acc = 0.9945272473218444\n",
      "test Acc 0.9613594040968343:\n",
      "30th- epoch: 42, train_loss = 3.380904601421207, train_acc = 0.9947601304145319\n",
      "test Acc 0.9618249534450651:\n",
      "30th- epoch: 43, train_loss = 3.312929630279541, train_acc = 0.9947601304145319\n",
      "test Acc 0.9622905027932961:\n",
      "30th- epoch: 44, train_loss = 3.2503051557578146, train_acc = 0.9948765719608756\n",
      "test Acc 0.9622905027932961:\n",
      "30th- epoch: 45, train_loss = 3.189478327985853, train_acc = 0.9952258965999069\n",
      "test Acc 0.962756052141527:\n",
      "30th- epoch: 46, train_loss = 3.1302624233067036, train_acc = 0.9953423381462506\n",
      "test Acc 0.962756052141527:\n",
      "30th- epoch: 47, train_loss = 3.0754188671708107, train_acc = 0.9953423381462506\n",
      "test Acc 0.962756052141527:\n",
      "30th- epoch: 48, train_loss = 3.0223044021986425, train_acc = 0.9953423381462506\n",
      "test Acc 0.9632216014897579:\n",
      "30th- epoch: 49, train_loss = 2.970492662396282, train_acc = 0.9953423381462506\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 50, train_loss = 2.921027125325054, train_acc = 0.9953423381462506\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 51, train_loss = 2.8741908371448517, train_acc = 0.9954587796925943\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 52, train_loss = 2.8278080844320357, train_acc = 0.995575221238938\n",
      "test Acc 0.9646182495344506:\n",
      "30th- epoch: 53, train_loss = 2.7855465784668922, train_acc = 0.9956916627852818\n",
      "test Acc 0.9646182495344506:\n",
      "30th- epoch: 54, train_loss = 2.7433901303447783, train_acc = 0.9956916627852818\n",
      "test Acc 0.9646182495344506:\n",
      "30th- epoch: 55, train_loss = 2.703159898519516, train_acc = 0.9956916627852818\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 56, train_loss = 2.663263344671577, train_acc = 0.9956916627852818\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 57, train_loss = 2.6260019852779806, train_acc = 0.9956916627852818\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 58, train_loss = 2.591190283652395, train_acc = 0.9958081043316255\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 59, train_loss = 2.5556972944177687, train_acc = 0.996040987424313\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 60, train_loss = 2.5221360051073134, train_acc = 0.9961574289706567\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 61, train_loss = 2.490467108786106, train_acc = 0.9961574289706567\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 62, train_loss = 2.4595841579139233, train_acc = 0.9961574289706567\n",
      "test Acc 0.9655493482309124:\n",
      "30th- epoch: 63, train_loss = 2.428521995898336, train_acc = 0.9961574289706567\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 64, train_loss = 2.3995997831225395, train_acc = 0.9962738705170004\n",
      "test Acc 0.9655493482309124:\n",
      "30th- epoch: 65, train_loss = 2.370633388403803, train_acc = 0.9962738705170004\n",
      "test Acc 0.9655493482309124:\n",
      "30th- epoch: 66, train_loss = 2.3427335396409035, train_acc = 0.9962738705170004\n",
      "test Acc 0.9655493482309124:\n",
      "30th- epoch: 67, train_loss = 2.315933796344325, train_acc = 0.996506753609688\n",
      "test Acc 0.9655493482309124:\n",
      "30th- epoch: 68, train_loss = 2.2912960064131767, train_acc = 0.9963903120633442\n",
      "test Acc 0.9655493482309124:\n",
      "30th- epoch: 69, train_loss = 2.2662870425265282, train_acc = 0.9963903120633442\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 70, train_loss = 2.240741695044562, train_acc = 0.9963903120633442\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 71, train_loss = 2.2177674882113934, train_acc = 0.9963903120633442\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 72, train_loss = 2.1961331504862756, train_acc = 0.9963903120633442\n",
      "test Acc 0.9646182495344506:\n",
      "30th- epoch: 73, train_loss = 2.1728583946824074, train_acc = 0.9963903120633442\n",
      "test Acc 0.9646182495344506:\n",
      "30th- epoch: 74, train_loss = 2.1508739478886127, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 75, train_loss = 2.1332198083400726, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 76, train_loss = 2.112570707919076, train_acc = 0.996506753609688\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 77, train_loss = 2.0938310499768704, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 78, train_loss = 2.0750023301225156, train_acc = 0.9966231951560317\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 79, train_loss = 2.0563482108991593, train_acc = 0.9967396367023754\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 80, train_loss = 2.038367100059986, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 81, train_loss = 2.021652876166627, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 82, train_loss = 2.005418911576271, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 83, train_loss = 1.989373880205676, train_acc = 0.9968560782487191\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 84, train_loss = 1.972333401441574, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 85, train_loss = 1.9576506067533046, train_acc = 0.9968560782487191\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 86, train_loss = 1.9427698713261634, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "30th- epoch: 87, train_loss = 1.9278394754510373, train_acc = 0.9968560782487191\n",
      "test Acc 0.9655493482309124:\n",
      "30th- epoch: 88, train_loss = 1.9125475015025586, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 89, train_loss = 1.898103542625904, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 90, train_loss = 1.8847129282075912, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 91, train_loss = 1.8702525857370347, train_acc = 0.9969725197950629\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 92, train_loss = 1.8573946096003056, train_acc = 0.9970889613414066\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 93, train_loss = 1.8447968859691173, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 94, train_loss = 1.832850081147626, train_acc = 0.9972054028877504\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 95, train_loss = 1.8202536280732602, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 96, train_loss = 1.8090739275794476, train_acc = 0.9973218444340941\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 97, train_loss = 1.7960698381066322, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 98, train_loss = 1.7864555951673537, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 99, train_loss = 1.7737021136563271, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 100, train_loss = 1.7648343902546912, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 101, train_loss = 1.7546870473306626, train_acc = 0.9974382859804378\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 102, train_loss = 1.744026544271037, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "30th- epoch: 103, train_loss = 1.734501836122945, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "30th- epoch: 104, train_loss = 1.7235475506167859, train_acc = 0.9975547275267815\n",
      "test Acc 0.9664804469273743:\n",
      "30th- epoch: 105, train_loss = 1.7152740869205445, train_acc = 0.9974382859804378\n",
      "test Acc 0.9669459962756052:\n",
      "30th- epoch: 106, train_loss = 1.7042480136733502, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 107, train_loss = 1.695831896038726, train_acc = 0.9974382859804378\n",
      "test Acc 0.9664804469273743:\n",
      "30th- epoch: 108, train_loss = 1.6866475727874786, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 109, train_loss = 1.6781323824543506, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 110, train_loss = 1.6697750824969262, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 111, train_loss = 1.6615167558193207, train_acc = 0.9974382859804378\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 112, train_loss = 1.6525458965916187, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 113, train_loss = 1.644678169162944, train_acc = 0.9975547275267815\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 114, train_loss = 1.6363518845755607, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 115, train_loss = 1.6284439601004124, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 116, train_loss = 1.621709828497842, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 117, train_loss = 1.6137033104896545, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 118, train_loss = 1.6072364274878055, train_acc = 0.9975547275267815\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 119, train_loss = 1.5992063980083913, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 120, train_loss = 1.591979544609785, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 121, train_loss = 1.5849051985424012, train_acc = 0.9975547275267815\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 122, train_loss = 1.5787756505887955, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 123, train_loss = 1.5719997126143426, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 124, train_loss = 1.5655820295214653, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 125, train_loss = 1.559015826554969, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 126, train_loss = 1.552333116531372, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 127, train_loss = 1.5460334196686745, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 128, train_loss = 1.5398988971719518, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 129, train_loss = 1.5339382216334343, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 130, train_loss = 1.5281497364630923, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 131, train_loss = 1.5212818048894405, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 132, train_loss = 1.516577930538915, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 133, train_loss = 1.5096196867525578, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 134, train_loss = 1.5045592188835144, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 135, train_loss = 1.4981939358403906, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 136, train_loss = 1.4941115751862526, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 137, train_loss = 1.4872337220003828, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 138, train_loss = 1.4837972683599219, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 139, train_loss = 1.4783915827283636, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 140, train_loss = 1.472787174046971, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 141, train_loss = 1.4675613219151273, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 142, train_loss = 1.4624436510493979, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 143, train_loss = 1.4584859572350979, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 144, train_loss = 1.4532541409134865, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 145, train_loss = 1.4488460744032636, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 146, train_loss = 1.4433293665060773, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 147, train_loss = 1.43972811603453, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 148, train_loss = 1.4341695780167356, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 149, train_loss = 1.4306511817267165, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 150, train_loss = 1.4249473871896043, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 151, train_loss = 1.4215142155298963, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 152, train_loss = 1.4169955365359783, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 153, train_loss = 1.413151760934852, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 154, train_loss = 1.4083159131696448, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 155, train_loss = 1.4039343470940366, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 156, train_loss = 1.3996135145425797, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 157, train_loss = 1.3961041023721918, train_acc = 0.9975547275267815\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 158, train_loss = 1.3911804122617468, train_acc = 0.9976711690731253\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 159, train_loss = 1.3888099851319566, train_acc = 0.9975547275267815\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 160, train_loss = 1.3835352497408167, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 161, train_loss = 1.379820927977562, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 162, train_loss = 1.3769641481339931, train_acc = 0.9976711690731253\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 163, train_loss = 1.3726193631300703, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 164, train_loss = 1.3689505284419283, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 165, train_loss = 1.364288387238048, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 166, train_loss = 1.3625595023622736, train_acc = 0.9977876106194691\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 167, train_loss = 1.3572043975582346, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 168, train_loss = 1.354025263339281, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 169, train_loss = 1.3511309139430523, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 170, train_loss = 1.3471365621080622, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 171, train_loss = 1.343223623931408, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 172, train_loss = 1.3405946245184168, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 173, train_loss = 1.336581740528345, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 174, train_loss = 1.3332679209997877, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 175, train_loss = 1.3298339484026656, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 176, train_loss = 1.3267842382192612, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 177, train_loss = 1.3234406585106626, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 178, train_loss = 1.3200311623513699, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 179, train_loss = 1.3169142790138721, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 180, train_loss = 1.3137677734484896, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 181, train_loss = 1.3102328615495935, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 182, train_loss = 1.3084737720200792, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 183, train_loss = 1.30477900931146, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 184, train_loss = 1.3014912182698026, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 185, train_loss = 1.299062238424085, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 186, train_loss = 1.2959057738771662, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 187, train_loss = 1.2927186986198649, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 188, train_loss = 1.2902797907590866, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 189, train_loss = 1.28719784936402, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 190, train_loss = 1.2840894535183907, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 191, train_loss = 1.281790359527804, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 192, train_loss = 1.278913845657371, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 193, train_loss = 1.2761120597133413, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 194, train_loss = 1.2738465728471056, train_acc = 0.9977876106194691\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 195, train_loss = 1.2706963742384687, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 196, train_loss = 1.2675845051417127, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 197, train_loss = 1.2649000957608223, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 198, train_loss = 1.2624114068457857, train_acc = 0.9977876106194691\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 199, train_loss = 1.2601376548409462, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 200, train_loss = 1.258244402706623, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 201, train_loss = 1.2556126700947061, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 202, train_loss = 1.2532827071845531, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 203, train_loss = 1.2501317312708125, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 204, train_loss = 1.2484513161471114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 205, train_loss = 1.245093277306296, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 206, train_loss = 1.2436043806374073, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 207, train_loss = 1.2413879496743903, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 208, train_loss = 1.2383116533746943, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 209, train_loss = 1.2361602609744295, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "30th- epoch: 210, train_loss = 1.2339664796600118, train_acc = 0.9977876106194691\n",
      "test Acc 0.9706703910614525:\n",
      "30th- epoch: 211, train_loss = 1.2312078265240416, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 212, train_loss = 1.2289818935096264, train_acc = 0.9977876106194691\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 213, train_loss = 1.226894799619913, train_acc = 0.9976711690731253\n",
      "test Acc 0.9706703910614525:\n",
      "30th- epoch: 214, train_loss = 1.2253588711610064, train_acc = 0.9976711690731253\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 215, train_loss = 1.2226506607839838, train_acc = 0.9977876106194691\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 216, train_loss = 1.2208219295134768, train_acc = 0.9977876106194691\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 217, train_loss = 1.2180174378445372, train_acc = 0.9977876106194691\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 218, train_loss = 1.2166495783021674, train_acc = 0.9976711690731253\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 219, train_loss = 1.2143579572439194, train_acc = 0.9976711690731253\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 220, train_loss = 1.2121436757734045, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 221, train_loss = 1.2102375378017314, train_acc = 0.9977876106194691\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 222, train_loss = 1.2078158731455915, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 223, train_loss = 1.2058496859972365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 224, train_loss = 1.2035613022744656, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 225, train_loss = 1.2021241660113446, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 226, train_loss = 1.2002503909170628, train_acc = 0.9977876106194691\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 227, train_loss = 1.1975837002391927, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 228, train_loss = 1.1956863428349607, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 229, train_loss = 1.1943460802431218, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 230, train_loss = 1.192240574688185, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 231, train_loss = 1.1900959834456444, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 232, train_loss = 1.1884912240202539, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 233, train_loss = 1.1865278258919716, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 234, train_loss = 1.184543825685978, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 235, train_loss = 1.1826419879798777, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 236, train_loss = 1.1807321881060489, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 237, train_loss = 1.1789215368335135, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 238, train_loss = 1.1771744576399215, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 239, train_loss = 1.1750388617510907, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 240, train_loss = 1.173948199779261, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 241, train_loss = 1.1718417133088224, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 242, train_loss = 1.1701383503968827, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 243, train_loss = 1.1680388040840626, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 244, train_loss = 1.1666751690208912, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 245, train_loss = 1.1649015459115617, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 246, train_loss = 1.1625463788514026, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 247, train_loss = 1.1616235226392746, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 248, train_loss = 1.1593767528538592, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 249, train_loss = 1.158120047301054, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 250, train_loss = 1.156088076531887, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 251, train_loss = 1.1546413053874858, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 252, train_loss = 1.1528971356456168, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 253, train_loss = 1.1514747341279872, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 254, train_loss = 1.1499439242179506, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 255, train_loss = 1.1482948462362401, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 256, train_loss = 1.146720254153479, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 257, train_loss = 1.1449055026168935, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 258, train_loss = 1.1434467931394465, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 259, train_loss = 1.1417664289474487, train_acc = 0.9976711690731253\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 260, train_loss = 1.140425359189976, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "30th- epoch: 261, train_loss = 1.1391083213384263, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "30th- epoch: 262, train_loss = 1.1374677307903767, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "30th- epoch: 263, train_loss = 1.1357486248016357, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 264, train_loss = 1.1347084839944728, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "30th- epoch: 265, train_loss = 1.133367535949219, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 266, train_loss = 1.1315243492717855, train_acc = 0.9976711690731253\n",
      "test Acc 0.9725325884543762:\n",
      "30th- epoch: 267, train_loss = 1.130008966953028, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 268, train_loss = 1.1291197526152246, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 269, train_loss = 1.1272598232026212, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 270, train_loss = 1.1263520158827305, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 271, train_loss = 1.1248092502355576, train_acc = 0.9976711690731253\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 272, train_loss = 1.1231002348358743, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 273, train_loss = 1.1215692088007927, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 274, train_loss = 1.1201548700337298, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 275, train_loss = 1.118683000386227, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 276, train_loss = 1.1171717953984626, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 277, train_loss = 1.116357530176174, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 278, train_loss = 1.1149237379431725, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 279, train_loss = 1.113163364410866, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 280, train_loss = 1.1125746692414396, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 281, train_loss = 1.1107191194896586, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 282, train_loss = 1.1096129938960075, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 283, train_loss = 1.1085171115701087, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 284, train_loss = 1.106644322455395, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 285, train_loss = 1.1059744482045062, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 286, train_loss = 1.1041143015027046, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 287, train_loss = 1.1031420156359673, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 288, train_loss = 1.101458451419603, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 289, train_loss = 1.1007946034078486, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 290, train_loss = 1.0992327705025673, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 291, train_loss = 1.0980321417446248, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 292, train_loss = 1.0966509369318374, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 293, train_loss = 1.0954562040860765, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 294, train_loss = 1.0941663831472397, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 295, train_loss = 1.0932078796322457, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 296, train_loss = 1.0917700144345872, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 297, train_loss = 1.0906028126482852, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 298, train_loss = 1.0898746575112455, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 299, train_loss = 1.0883434377610683, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 300, train_loss = 1.087391899258364, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 301, train_loss = 1.0860384342377074, train_acc = 0.9976711690731253\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 302, train_loss = 1.084986059635412, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 303, train_loss = 1.0839691646397114, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 304, train_loss = 1.082496490329504, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 305, train_loss = 1.0816408184473403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 306, train_loss = 1.0802303552627563, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 307, train_loss = 1.0791377574205399, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 308, train_loss = 1.0781574944849126, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 309, train_loss = 1.0773690566420555, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 310, train_loss = 1.0761471551959403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 311, train_loss = 1.0748461497132666, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 312, train_loss = 1.0742082868819125, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 313, train_loss = 1.0730843196506612, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 314, train_loss = 1.0717488887603395, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 315, train_loss = 1.070322832732927, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 316, train_loss = 1.0696326804463752, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 317, train_loss = 1.0687877709860913, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 318, train_loss = 1.0675261442665942, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 319, train_loss = 1.0667939558625221, train_acc = 0.9977876106194691\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 320, train_loss = 1.0653362981975079, train_acc = 0.9976711690731253\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 321, train_loss = 1.0643615673179738, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 322, train_loss = 1.0634140099282376, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 323, train_loss = 1.062845842272509, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 324, train_loss = 1.0613296900992282, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 325, train_loss = 1.0604255981743336, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 326, train_loss = 1.0596052284236066, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 327, train_loss = 1.058217587589752, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 328, train_loss = 1.0578092746436596, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 329, train_loss = 1.0563398686354049, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 330, train_loss = 1.05551203712821, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 331, train_loss = 1.0547349999542348, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 332, train_loss = 1.0533360156114213, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 333, train_loss = 1.0531170305912383, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 334, train_loss = 1.0514121179585345, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 335, train_loss = 1.051364826678764, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 336, train_loss = 1.0499006782774813, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 337, train_loss = 1.048855186731089, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 338, train_loss = 1.048520187556278, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 339, train_loss = 1.0468775096233003, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 340, train_loss = 1.0462140776216984, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 341, train_loss = 1.045296162366867, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 342, train_loss = 1.044310620694887, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 343, train_loss = 1.043554080009926, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 344, train_loss = 1.042589200020302, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 345, train_loss = 1.0418924341793172, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 346, train_loss = 1.0406898905639537, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 347, train_loss = 1.0400502681732178, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 348, train_loss = 1.0388843305408955, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 349, train_loss = 1.0388750011916272, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 350, train_loss = 1.0377375818789005, train_acc = 0.9979040521658128\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 351, train_loss = 1.036368967324961, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 352, train_loss = 1.035525472194422, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 353, train_loss = 1.0351502944831736, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 354, train_loss = 1.0343084335327148, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 355, train_loss = 1.0333074095542543, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 356, train_loss = 1.0325188140268438, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 357, train_loss = 1.0319723064894788, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 358, train_loss = 1.030918316275347, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 359, train_loss = 1.0302017529611476, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 360, train_loss = 1.029492651403416, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 361, train_loss = 1.0289804004132748, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 362, train_loss = 1.027919765561819, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 363, train_loss = 1.0269455835223198, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 364, train_loss = 1.0260794945061207, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 365, train_loss = 1.025189248204697, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 366, train_loss = 1.02475132670952, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 367, train_loss = 1.023424172133673, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 368, train_loss = 1.0232457096572034, train_acc = 0.9980204937121565\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 369, train_loss = 1.0220708710257895, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 370, train_loss = 1.021046354144346, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 371, train_loss = 1.0207269092206843, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 372, train_loss = 1.019940972328186, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 373, train_loss = 1.0190599610214122, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 374, train_loss = 1.0184297263622284, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 375, train_loss = 1.0173952877521515, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 376, train_loss = 1.0169409873778932, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 377, train_loss = 1.0160781182348728, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 378, train_loss = 1.0153034565155394, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 379, train_loss = 1.014692877739435, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 380, train_loss = 1.0139406385424081, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 381, train_loss = 1.012999963015318, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 382, train_loss = 1.0124020030198153, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 383, train_loss = 1.0114141913654748, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 384, train_loss = 1.0111276172101498, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 385, train_loss = 1.0105894915759563, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 386, train_loss = 1.009745574236149, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 387, train_loss = 1.0086960097250994, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 388, train_loss = 1.008158771932358, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 389, train_loss = 1.0072539945540484, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 390, train_loss = 1.0068040986952838, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 391, train_loss = 1.0060292556881905, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 392, train_loss = 1.0051350370049477, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 393, train_loss = 1.004739427327877, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 394, train_loss = 1.0035526441934053, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 395, train_loss = 1.0035483750107232, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 396, train_loss = 1.0020860259828623, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 397, train_loss = 1.0015362948179245, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 398, train_loss = 1.0007048634288367, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 399, train_loss = 0.9998481733200606, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 400, train_loss = 0.9994325240550097, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 401, train_loss = 0.998598867416149, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 402, train_loss = 0.9976999958453234, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 403, train_loss = 0.9976433614792768, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 404, train_loss = 0.9967012951674405, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 405, train_loss = 0.9959273909626063, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 406, train_loss = 0.9953705643711146, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 407, train_loss = 0.994778361171484, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 408, train_loss = 0.9939403211174067, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 409, train_loss = 0.9933646097779274, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 410, train_loss = 0.9927439875900745, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 411, train_loss = 0.9921503104269505, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 412, train_loss = 0.991311809659237, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 413, train_loss = 0.9912387008371297, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 414, train_loss = 0.9898542066512164, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 415, train_loss = 0.990173446625704, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 416, train_loss = 0.9890692072513048, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 417, train_loss = 0.9880997774598654, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 418, train_loss = 0.9879885973932687, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 419, train_loss = 0.9870376400649548, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 420, train_loss = 0.9867322059872095, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 421, train_loss = 0.9856503618357237, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 422, train_loss = 0.9853453276155051, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 423, train_loss = 0.9848129115998745, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 424, train_loss = 0.9836666459741537, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 425, train_loss = 0.9835194485785905, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 426, train_loss = 0.9829755251703318, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 427, train_loss = 0.9820066131651402, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 428, train_loss = 0.981745603174204, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 429, train_loss = 0.981029494345421, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 430, train_loss = 0.980624932795763, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 431, train_loss = 0.9799348339438438, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 432, train_loss = 0.9793592517671641, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 433, train_loss = 0.9789128986594733, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 434, train_loss = 0.9780763549206313, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 435, train_loss = 0.9777620645763818, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 436, train_loss = 0.9767553036508616, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 437, train_loss = 0.9763442029652651, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 438, train_loss = 0.9756778304872569, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 439, train_loss = 0.9752606985566672, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 440, train_loss = 0.9746304353175219, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 441, train_loss = 0.9742308109998703, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 442, train_loss = 0.9734907945094164, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 443, train_loss = 0.9730826119484846, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 444, train_loss = 0.9725885403749999, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 445, train_loss = 0.9718371480703354, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 446, train_loss = 0.9716024920344353, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 447, train_loss = 0.9706860283913556, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 448, train_loss = 0.97054217880941, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 449, train_loss = 0.9697157641348895, train_acc = 0.9980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 450, train_loss = 0.968985952436924, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 451, train_loss = 0.9688031052646693, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 452, train_loss = 0.9682488813996315, train_acc = 0.9980204937121565\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 453, train_loss = 0.9673122403619345, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 454, train_loss = 0.9669238602218684, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 455, train_loss = 0.9669597869215067, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 456, train_loss = 0.9663165882229805, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 457, train_loss = 0.9653778610227164, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 458, train_loss = 0.9649307268264238, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 459, train_loss = 0.9648710663022939, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 460, train_loss = 0.9639020375907421, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 461, train_loss = 0.9634881541132927, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 462, train_loss = 0.9628067600133363, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 463, train_loss = 0.9621913818118628, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 464, train_loss = 0.9618918336927891, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 465, train_loss = 0.9612535201013088, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 466, train_loss = 0.9609515319170896, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 467, train_loss = 0.96026181182242, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 468, train_loss = 0.9600291773676872, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 469, train_loss = 0.9591795330343302, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 470, train_loss = 0.9586776457726955, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 471, train_loss = 0.9585803424415644, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 472, train_loss = 0.9579553566873074, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 473, train_loss = 0.9573263911006507, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 474, train_loss = 0.9570317901670933, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 475, train_loss = 0.9563686611654703, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 476, train_loss = 0.9556125862000044, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 477, train_loss = 0.9556584556994494, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 478, train_loss = 0.9547858610749245, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 479, train_loss = 0.9543561314640101, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 480, train_loss = 0.9537542723119259, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 481, train_loss = 0.9533154964447021, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 482, train_loss = 0.9531736709177494, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 483, train_loss = 0.9527076395752374, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 484, train_loss = 0.9518703073263168, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 485, train_loss = 0.9514673488738481, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 486, train_loss = 0.9510958033206407, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 487, train_loss = 0.9502340791223105, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 488, train_loss = 0.9501746011374053, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 489, train_loss = 0.9496649665234145, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 490, train_loss = 0.949237080902094, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 491, train_loss = 0.9485689749417361, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 492, train_loss = 0.9479890378715936, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 493, train_loss = 0.9479253354074899, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 494, train_loss = 0.9472113375959452, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 495, train_loss = 0.9465643974544946, train_acc = 0.9980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 496, train_loss = 0.946502797305584, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 497, train_loss = 0.9457566378114279, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 498, train_loss = 0.9456954610941466, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 499, train_loss = 0.9448305666446686, train_acc = 0.9980204937121565\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 30/30 [4:55:46<00:00, 546.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4h 55min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    read_path = 'D:virus/image/4gram_768/'\n",
    "    \n",
    "    temp = [[],[]]\n",
    "    \n",
    "    Loader = D.File_loader()\n",
    "    data_a, label_a = Loader.read_files(read_path, interp = False)\n",
    "    \n",
    "    idx = np.argsort(label_a)\n",
    "    \n",
    "    sorted_data = data_a[idx].reshape(10736, -1)\n",
    "    sorted_label = sorted(label_a)\n",
    "        \n",
    "    BATCH_SIZE = 64\n",
    "    TOTAL = 30\n",
    "    EPOCH =500\n",
    "    NUM_CLASS = 9\n",
    "    LR = 0.0001\n",
    "    SEED = [s for s in range(TOTAL)]\n",
    "    Num_Nodes = 768\n",
    "    \n",
    "    CUDA_N = 'cuda:1'\n",
    "    \n",
    "    # creating data indices for spliting\n",
    "    full_dataset = CustomDataset(sorted_data, sorted_label)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # spliting\n",
    "    torch.manual_seed(10)\n",
    "    train_dataset, test_dataset = data.random_split(full_dataset, [train_size, test_size])\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    loss_total = []\n",
    "    acc_total = []\n",
    "    pred_total = []\n",
    "    true_total = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(TOTAL)):\n",
    "        \n",
    "        \n",
    "        device = torch.device(CUDA_N if torch.cuda.is_available() else 'cpu')\n",
    "        torch.manual_seed(SEED[i])\n",
    "        net = Mcslt(Num_Nodes, NUM_CLASS)\n",
    "        net.to(device)\n",
    "        print(net)\n",
    "        \n",
    "        softmax = nn.Softmax()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=LR, momentum = 0.1)\n",
    "        \n",
    "        loss_list = []\n",
    "        train_acc_list = []\n",
    "        test_acc_list = []\n",
    "        \n",
    "        pred_temp = []\n",
    "        true_temp = []\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            net.train()\n",
    "            running_loss = 0\n",
    "            total = train_size\n",
    "            correct = 0 \n",
    "            \n",
    "            for step, images_labels in enumerate(train_loader):\n",
    "                inputs, labels = images_labels\n",
    "                inputs, labels = inputs.type(torch.FloatTensor).to(device), labels.type(torch.LongTensor).to(device)\n",
    "                \n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, pred = torch.max(outputs, dim=1)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            train_acc = correct/total\n",
    "            loss_list.append(running_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "            print('{}th- epoch: {}, train_loss = {}, train_acc = {}'.format(i+1, epoch, running_loss, train_acc))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                correct = 0\n",
    "                total = test_size\n",
    "                pt, tt = [], []\n",
    "                \n",
    "                for step_t, images_labels_t in enumerate(test_loader):\n",
    "                    inputs_t, labels_t = images_labels_t\n",
    "                    inputs_t, labels_t = inputs_t.type(torch.FloatTensor).to(device), labels_t.type(torch.LongTensor).to(device)\n",
    "                    \n",
    "                    outputs_t = net(inputs_t)\n",
    "                    outputs_t = softmax(outputs_t)\n",
    "                    \n",
    "                    # test accuracy\n",
    "                    _, pred_t = torch.max(outputs_t, dim = 1)\n",
    "                    \n",
    "                    pt.append(pred_t)\n",
    "                    tt.append(labels_t)\n",
    "                    \n",
    "                    correct += (pred_t == labels_t).sum().item()\n",
    "                    \n",
    "                pred_temp.append(torch.cat(pt))\n",
    "                true_temp.append(torch.cat(tt))\n",
    "                \n",
    "                test_acc = correct/total\n",
    "                test_acc_list.append(test_acc)\n",
    "                \n",
    "                print('test Acc {}:'.format(test_acc))\n",
    "                \n",
    "        best_result_index = np.argmax(np.array(test_acc_list))\n",
    "        loss_total.append(loss_list[best_result_index])\n",
    "        acc_total.append(test_acc_list[best_result_index])\n",
    "        pred_total.append(pred_temp[best_result_index].tolist())\n",
    "        true_total.append(true_temp[best_result_index].tolist())\n",
    "        \n",
    "    file_name = 'res/Mcslt_4gram'\n",
    "    torch.save(net.state_dict(), file_name +'.pth')\n",
    "    \n",
    "    loss_DF = pd.DataFrame(loss_total)\n",
    "    loss_DF.to_csv(file_name+\" loss.csv\")\n",
    "    \n",
    "    acc_DF = pd.DataFrame(acc_total)\n",
    "    acc_DF.to_csv(file_name +\" acc.csv\")\n",
    "    \n",
    "    pred_DF = pd.DataFrame(pred_total)\n",
    "    pred_DF.to_csv(file_name +\" pred.csv\")\n",
    "    \n",
    "    true_DF = pd.DataFrame(true_total)\n",
    "    true_DF.to_csv(file_name +\" true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
