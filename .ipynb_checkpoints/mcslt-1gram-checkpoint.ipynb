{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import utility.Data_loader as D\n",
    "from utility.Model import Mcslt\n",
    "from utility.Custom import CustomDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 10736/10736 [00:01<00:00, 5742.01it/s]\n",
      "  0%|                                                                                    | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "1th- epoch: 0, train_loss = 141.51218968629837, train_acc = 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DTools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:99: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.8635940409683427:\n",
      "1th- epoch: 1, train_loss = 58.23592698574066, train_acc = 0.8813460642757336\n",
      "test Acc 0.8947858472998138:\n",
      "1th- epoch: 2, train_loss = 48.3622922450304, train_acc = 0.902771308802981\n",
      "test Acc 0.9022346368715084:\n",
      "1th- epoch: 3, train_loss = 43.494202613830566, train_acc = 0.9103400093153237\n",
      "test Acc 0.9120111731843575:\n",
      "1th- epoch: 4, train_loss = 40.261719420552254, train_acc = 0.9156963204471356\n",
      "test Acc 0.9162011173184358:\n",
      "1th- epoch: 5, train_loss = 37.85023643821478, train_acc = 0.9203539823008849\n",
      "test Acc 0.9213221601489758:\n",
      "1th- epoch: 6, train_loss = 35.90387463569641, train_acc = 0.9231485794131346\n",
      "test Acc 0.9245810055865922:\n",
      "1th- epoch: 7, train_loss = 34.435725674033165, train_acc = 0.9252445272473219\n",
      "test Acc 0.9292364990689013:\n",
      "1th- epoch: 8, train_loss = 33.12388176470995, train_acc = 0.9272240335351654\n",
      "test Acc 0.930633147113594:\n",
      "1th- epoch: 9, train_loss = 32.027555629611015, train_acc = 0.9293199813693526\n",
      "test Acc 0.9315642458100558:\n",
      "1th- epoch: 10, train_loss = 31.08527897298336, train_acc = 0.9316488122962273\n",
      "test Acc 0.9315642458100558:\n",
      "1th- epoch: 11, train_loss = 30.235565327107906, train_acc = 0.9337447601304145\n",
      "test Acc 0.9315642458100558:\n",
      "1th- epoch: 12, train_loss = 29.520416863262653, train_acc = 0.9356078248719143\n",
      "test Acc 0.9324953445065177:\n",
      "1th- epoch: 13, train_loss = 28.833943478763103, train_acc = 0.9368886818816954\n",
      "test Acc 0.9338919925512105:\n",
      "1th- epoch: 14, train_loss = 28.23533134162426, train_acc = 0.9385188635305077\n",
      "test Acc 0.9338919925512105:\n",
      "1th- epoch: 15, train_loss = 27.715476538985968, train_acc = 0.939683278993945\n",
      "test Acc 0.9348230912476723:\n",
      "1th- epoch: 16, train_loss = 27.243798952549696, train_acc = 0.9410805775500699\n",
      "test Acc 0.9352886405959032:\n",
      "1th- epoch: 17, train_loss = 26.803898561745882, train_acc = 0.9411970190964136\n",
      "test Acc 0.9357541899441341:\n",
      "1th- epoch: 18, train_loss = 26.39505786821246, train_acc = 0.9432929669306008\n",
      "test Acc 0.9357541899441341:\n",
      "1th- epoch: 19, train_loss = 26.033856581896544, train_acc = 0.9438751746623195\n",
      "test Acc 0.9366852886405959:\n",
      "1th- epoch: 20, train_loss = 25.692550897598267, train_acc = 0.9445738239403819\n",
      "test Acc 0.9371508379888268:\n",
      "1th- epoch: 21, train_loss = 25.375870514661074, train_acc = 0.945388914764788\n",
      "test Acc 0.9371508379888268:\n",
      "1th- epoch: 22, train_loss = 25.067540667951107, train_acc = 0.945854680950163\n",
      "test Acc 0.9371508379888268:\n",
      "1th- epoch: 23, train_loss = 24.77711161226034, train_acc = 0.9464368886818817\n",
      "test Acc 0.936219739292365:\n",
      "1th- epoch: 24, train_loss = 24.51961475238204, train_acc = 0.946786213320913\n",
      "test Acc 0.936219739292365:\n",
      "1th- epoch: 25, train_loss = 24.255776185542345, train_acc = 0.9474848625989754\n",
      "test Acc 0.9376163873370578:\n",
      "1th- epoch: 26, train_loss = 24.00853915885091, train_acc = 0.9484163949697252\n",
      "test Acc 0.9376163873370578:\n",
      "1th- epoch: 27, train_loss = 23.787700075656176, train_acc = 0.9485328365160689\n",
      "test Acc 0.9380819366852886:\n",
      "1th- epoch: 28, train_loss = 23.58214232698083, train_acc = 0.9489986027014439\n",
      "test Acc 0.9380819366852886:\n",
      "1th- epoch: 29, train_loss = 23.376081932336092, train_acc = 0.9491150442477876\n",
      "test Acc 0.9385474860335196:\n",
      "1th- epoch: 30, train_loss = 23.19675151631236, train_acc = 0.9499301350721937\n",
      "test Acc 0.9390130353817505:\n",
      "1th- epoch: 31, train_loss = 22.991443257778883, train_acc = 0.9503959012575687\n",
      "test Acc 0.9399441340782123:\n",
      "1th- epoch: 32, train_loss = 22.841317024081945, train_acc = 0.9505123428039124\n",
      "test Acc 0.9394785847299814:\n",
      "1th- epoch: 33, train_loss = 22.670693892985582, train_acc = 0.9513274336283186\n",
      "test Acc 0.9404096834264432:\n",
      "1th- epoch: 34, train_loss = 22.511899571865797, train_acc = 0.951560316721006\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 35, train_loss = 22.3464896120131, train_acc = 0.9522589659990685\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 36, train_loss = 22.225734554231167, train_acc = 0.9526082906380997\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 37, train_loss = 22.055574372410774, train_acc = 0.9529576152771309\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 38, train_loss = 21.919067291542888, train_acc = 0.9529576152771309\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 39, train_loss = 21.81391262821853, train_acc = 0.9534233814625058\n",
      "test Acc 0.9404096834264432:\n",
      "1th- epoch: 40, train_loss = 21.683467438444495, train_acc = 0.9536562645551933\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 41, train_loss = 21.570213040336967, train_acc = 0.9537727061015371\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 42, train_loss = 21.426067685708404, train_acc = 0.9535398230088495\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 43, train_loss = 21.2981376927346, train_acc = 0.9538891476478808\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 44, train_loss = 21.190206080675125, train_acc = 0.9538891476478808\n",
      "test Acc 0.9422718808193669:\n",
      "1th- epoch: 45, train_loss = 21.084692182019353, train_acc = 0.9541220307405682\n",
      "test Acc 0.9418063314711359:\n",
      "1th- epoch: 46, train_loss = 20.992762060835958, train_acc = 0.9545877969259432\n",
      "test Acc 0.9422718808193669:\n",
      "1th- epoch: 47, train_loss = 20.864897802472115, train_acc = 0.9547042384722869\n",
      "test Acc 0.9422718808193669:\n",
      "1th- epoch: 48, train_loss = 20.763202913105488, train_acc = 0.9547042384722869\n",
      "test Acc 0.9422718808193669:\n",
      "1th- epoch: 49, train_loss = 20.671716755256057, train_acc = 0.9549371215649743\n",
      "test Acc 0.9422718808193669:\n",
      "1th- epoch: 50, train_loss = 20.586200738325715, train_acc = 0.9549371215649743\n",
      "test Acc 0.9422718808193669:\n",
      "1th- epoch: 51, train_loss = 20.51062905602157, train_acc = 0.9550535631113182\n",
      "test Acc 0.9422718808193669:\n",
      "1th- epoch: 52, train_loss = 20.413452185690403, train_acc = 0.955519329296693\n",
      "test Acc 0.9427374301675978:\n",
      "1th- epoch: 53, train_loss = 20.31814863346517, train_acc = 0.955519329296693\n",
      "test Acc 0.9422718808193669:\n",
      "1th- epoch: 54, train_loss = 20.244523542001843, train_acc = 0.9556357708430367\n",
      "test Acc 0.9427374301675978:\n",
      "1th- epoch: 55, train_loss = 20.15557431615889, train_acc = 0.9558686539357243\n",
      "test Acc 0.9427374301675978:\n",
      "1th- epoch: 56, train_loss = 20.06868560053408, train_acc = 0.9558686539357243\n",
      "test Acc 0.9427374301675978:\n",
      "1th- epoch: 57, train_loss = 19.992192840203643, train_acc = 0.9562179785747554\n",
      "test Acc 0.9432029795158287:\n",
      "1th- epoch: 58, train_loss = 19.919313602149487, train_acc = 0.9563344201210993\n",
      "test Acc 0.9432029795158287:\n",
      "1th- epoch: 59, train_loss = 19.852441219612956, train_acc = 0.956450861667443\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 60, train_loss = 19.78318409435451, train_acc = 0.9565673032137867\n",
      "test Acc 0.9432029795158287:\n",
      "1th- epoch: 61, train_loss = 19.72783526033163, train_acc = 0.9568001863064741\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 62, train_loss = 19.641819769516587, train_acc = 0.9566837447601304\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 63, train_loss = 19.571850672364235, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 64, train_loss = 19.505282213911414, train_acc = 0.9571495109455054\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 65, train_loss = 19.444059355184436, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 66, train_loss = 19.39315023832023, train_acc = 0.9573823940381928\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 67, train_loss = 19.311796767637134, train_acc = 0.9577317186772241\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 68, train_loss = 19.267602249979973, train_acc = 0.9577317186772241\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 69, train_loss = 19.19667281769216, train_acc = 0.9578481602235678\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 70, train_loss = 19.143646273761988, train_acc = 0.9580810433162552\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 71, train_loss = 19.08312501385808, train_acc = 0.9578481602235678\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 72, train_loss = 19.02065430022776, train_acc = 0.9579646017699115\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 73, train_loss = 18.963483337312937, train_acc = 0.9583139264089428\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 74, train_loss = 18.90734126418829, train_acc = 0.9585468095016302\n",
      "test Acc 0.9445996275605214:\n",
      "1th- epoch: 75, train_loss = 18.84461692906916, train_acc = 0.9587796925943176\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 76, train_loss = 18.78983422741294, train_acc = 0.95947834187238\n",
      "test Acc 0.9445996275605214:\n",
      "1th- epoch: 77, train_loss = 18.74747752584517, train_acc = 0.9591290172333489\n",
      "test Acc 0.9445996275605214:\n",
      "1th- epoch: 78, train_loss = 18.710388695821166, train_acc = 0.9592454587796926\n",
      "test Acc 0.9436685288640596:\n",
      "1th- epoch: 79, train_loss = 18.6412966940552, train_acc = 0.95947834187238\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 80, train_loss = 18.608017917722464, train_acc = 0.9593619003260363\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 81, train_loss = 18.553652757778764, train_acc = 0.9595947834187238\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 82, train_loss = 18.50522497855127, train_acc = 0.9598276665114113\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 83, train_loss = 18.472861222922802, train_acc = 0.9597112249650676\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 84, train_loss = 18.409047504886985, train_acc = 0.959944108057755\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 85, train_loss = 18.373263949528337, train_acc = 0.959944108057755\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 86, train_loss = 18.322199292480946, train_acc = 0.959944108057755\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 87, train_loss = 18.27428421191871, train_acc = 0.9598276665114113\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 88, train_loss = 18.237221026793122, train_acc = 0.9598276665114113\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 89, train_loss = 18.197962753474712, train_acc = 0.96040987424313\n",
      "test Acc 0.9455307262569832:\n",
      "1th- epoch: 90, train_loss = 18.16706948913634, train_acc = 0.9605263157894737\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 91, train_loss = 18.110973505303264, train_acc = 0.9605263157894737\n",
      "test Acc 0.9455307262569832:\n",
      "1th- epoch: 92, train_loss = 18.06794934347272, train_acc = 0.9605263157894737\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 93, train_loss = 18.0468205306679, train_acc = 0.9607591988821611\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 94, train_loss = 18.001152329146862, train_acc = 0.9608756404285049\n",
      "test Acc 0.9450651769087524:\n",
      "1th- epoch: 95, train_loss = 17.957844423130155, train_acc = 0.9608756404285049\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 96, train_loss = 17.907367715612054, train_acc = 0.9612249650675361\n",
      "test Acc 0.9455307262569832:\n",
      "1th- epoch: 97, train_loss = 17.89724206365645, train_acc = 0.9612249650675361\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 98, train_loss = 17.851940006017685, train_acc = 0.9611085235211924\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 99, train_loss = 17.80740580894053, train_acc = 0.9609920819748486\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 100, train_loss = 17.778156315907836, train_acc = 0.9614578481602236\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 101, train_loss = 17.737822592258453, train_acc = 0.9612249650675361\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 102, train_loss = 17.699186211451888, train_acc = 0.9613414066138798\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 103, train_loss = 17.673103606328368, train_acc = 0.9613414066138798\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 104, train_loss = 17.631510637700558, train_acc = 0.9614578481602236\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 105, train_loss = 17.59878993779421, train_acc = 0.9614578481602236\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 106, train_loss = 17.561732282862067, train_acc = 0.9614578481602236\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 107, train_loss = 17.53918570280075, train_acc = 0.9614578481602236\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 108, train_loss = 17.506958143785596, train_acc = 0.961690731252911\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 109, train_loss = 17.471929758787155, train_acc = 0.9615742897065673\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 110, train_loss = 17.428927892819047, train_acc = 0.9615742897065673\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 111, train_loss = 17.413986176252365, train_acc = 0.961690731252911\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 112, train_loss = 17.381918005645275, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 113, train_loss = 17.356250720098615, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 114, train_loss = 17.32780830003321, train_acc = 0.9620400558919422\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 115, train_loss = 17.282369062304497, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 116, train_loss = 17.26750631351024, train_acc = 0.962156497438286\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 117, train_loss = 17.230231948196888, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 118, train_loss = 17.207310114987195, train_acc = 0.962156497438286\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 119, train_loss = 17.183972951956093, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 120, train_loss = 17.154817986302078, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 121, train_loss = 17.11434190440923, train_acc = 0.962156497438286\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 122, train_loss = 17.098500612191856, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 123, train_loss = 17.072445511817932, train_acc = 0.9625058220773172\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 124, train_loss = 17.052281755022705, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 125, train_loss = 17.022193618118763, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 126, train_loss = 16.996484398841858, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 127, train_loss = 16.977460029534996, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 128, train_loss = 16.949488860554993, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 129, train_loss = 16.91377853602171, train_acc = 0.9629715882626921\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 130, train_loss = 16.904860387556255, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 131, train_loss = 16.87237020302564, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 132, train_loss = 16.84594590496272, train_acc = 0.9629715882626921\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 133, train_loss = 16.83024079632014, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 134, train_loss = 16.812901817262173, train_acc = 0.9629715882626921\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 135, train_loss = 16.782651747576892, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 136, train_loss = 16.762649905867875, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 137, train_loss = 16.737634018063545, train_acc = 0.9630880298090359\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 138, train_loss = 16.711756919510663, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 139, train_loss = 16.697172358632088, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 140, train_loss = 16.676995071582496, train_acc = 0.9633209129017233\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 141, train_loss = 16.65996133815497, train_acc = 0.9634373544480671\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 142, train_loss = 16.626817206852138, train_acc = 0.9633209129017233\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 143, train_loss = 16.604307919740677, train_acc = 0.9634373544480671\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 144, train_loss = 16.59202527720481, train_acc = 0.9633209129017233\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 145, train_loss = 16.57304334361106, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 146, train_loss = 16.54595512151718, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 147, train_loss = 16.526748244650662, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 148, train_loss = 16.502347350120544, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 149, train_loss = 16.477922772057354, train_acc = 0.9634373544480671\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 150, train_loss = 16.458467577584088, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 151, train_loss = 16.437374438159168, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "1th- epoch: 152, train_loss = 16.437853108160198, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 153, train_loss = 16.404670022428036, train_acc = 0.9632044713553796\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 154, train_loss = 16.38467296678573, train_acc = 0.9633209129017233\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 155, train_loss = 16.361124138347805, train_acc = 0.9633209129017233\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 156, train_loss = 16.35290731769055, train_acc = 0.9633209129017233\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 157, train_loss = 16.325540277175605, train_acc = 0.9634373544480671\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 158, train_loss = 16.304023225791752, train_acc = 0.9633209129017233\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 159, train_loss = 16.291634187102318, train_acc = 0.9633209129017233\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 160, train_loss = 16.271196235902607, train_acc = 0.9635537959944108\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 161, train_loss = 16.248027801513672, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 162, train_loss = 16.2449315963313, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 163, train_loss = 16.211437709629536, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 164, train_loss = 16.193018945865333, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 165, train_loss = 16.17690511327237, train_acc = 0.9635537959944108\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 166, train_loss = 16.16141512989998, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 167, train_loss = 16.14040097873658, train_acc = 0.9636702375407545\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 168, train_loss = 16.12338451296091, train_acc = 0.9635537959944108\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 169, train_loss = 16.099945734255016, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 170, train_loss = 16.091926902532578, train_acc = 0.9635537959944108\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 171, train_loss = 16.070807822048664, train_acc = 0.9636702375407545\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 172, train_loss = 16.055784163065255, train_acc = 0.9636702375407545\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 173, train_loss = 16.037964317016304, train_acc = 0.9637866790870983\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 174, train_loss = 16.019471772015095, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 175, train_loss = 16.002549682743847, train_acc = 0.9637866790870983\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 176, train_loss = 15.994954410009086, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 177, train_loss = 15.968796794302762, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 178, train_loss = 15.965793646872044, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 179, train_loss = 15.939545810222626, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 180, train_loss = 15.92435545194894, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 181, train_loss = 15.91433618683368, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 182, train_loss = 15.90119391400367, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 183, train_loss = 15.87273642141372, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 184, train_loss = 15.870177663862705, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 185, train_loss = 15.85717111080885, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 186, train_loss = 15.835672281682491, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 187, train_loss = 15.826294504106045, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 188, train_loss = 15.8140683574602, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 189, train_loss = 15.785348881967366, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 190, train_loss = 15.78304333705455, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 191, train_loss = 15.768640957772732, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 192, train_loss = 15.754270325414836, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 193, train_loss = 15.72859342675656, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 194, train_loss = 15.723880271427333, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 195, train_loss = 15.707683217711747, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 196, train_loss = 15.697992931120098, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 197, train_loss = 15.67199696879834, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 198, train_loss = 15.666516400873661, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 199, train_loss = 15.644904971122742, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 200, train_loss = 15.63921545445919, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 201, train_loss = 15.616737929172814, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 202, train_loss = 15.621228744275868, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 203, train_loss = 15.597475196234882, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 204, train_loss = 15.580042514018714, train_acc = 0.9646017699115044\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 205, train_loss = 15.563247579149902, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 206, train_loss = 15.551129390485585, train_acc = 0.9646017699115044\n",
      "test Acc 0.9473929236499069:\n",
      "1th- epoch: 207, train_loss = 15.548411098308861, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 208, train_loss = 15.530668184161186, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 209, train_loss = 15.522203226573765, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 210, train_loss = 15.507498909719288, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 211, train_loss = 15.4930817829445, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 212, train_loss = 15.479516637511551, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 213, train_loss = 15.465766035020351, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 214, train_loss = 15.467686678282917, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 215, train_loss = 15.447797807864845, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 216, train_loss = 15.426633104681969, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 217, train_loss = 15.415945666842163, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 218, train_loss = 15.398394162766635, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 219, train_loss = 15.39332024473697, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 220, train_loss = 15.374204307794571, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 221, train_loss = 15.35967595409602, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 222, train_loss = 15.353491254150867, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 223, train_loss = 15.344648189842701, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 224, train_loss = 15.329855521209538, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 225, train_loss = 15.315220351330936, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 226, train_loss = 15.304611881263554, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 227, train_loss = 15.296946537680924, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 228, train_loss = 15.283240760676563, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 229, train_loss = 15.275775499641895, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 230, train_loss = 15.264005792327225, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 231, train_loss = 15.243439190089703, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 232, train_loss = 15.23326762020588, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 233, train_loss = 15.225839778780937, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 234, train_loss = 15.213240315206349, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 235, train_loss = 15.201624785549939, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 236, train_loss = 15.187850226648152, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 237, train_loss = 15.173802050761878, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 238, train_loss = 15.16417146474123, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 239, train_loss = 15.152355725876987, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 240, train_loss = 15.134184010326862, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 241, train_loss = 15.134436230175197, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 242, train_loss = 15.121073921211064, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 243, train_loss = 15.112116739153862, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 244, train_loss = 15.101866167970002, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 245, train_loss = 15.09350109566003, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 246, train_loss = 15.086718253791332, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 247, train_loss = 15.067129897885025, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 248, train_loss = 15.053675790317357, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 249, train_loss = 15.046228650026023, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 250, train_loss = 15.037603728473186, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 251, train_loss = 15.025297108106315, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 252, train_loss = 15.017139132134616, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 253, train_loss = 15.009469486773014, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 254, train_loss = 14.99441787879914, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 255, train_loss = 14.981280043721199, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 256, train_loss = 14.969735239632428, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 257, train_loss = 14.967651036567986, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 258, train_loss = 14.958781125955284, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 259, train_loss = 14.943089683540165, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 260, train_loss = 14.932608616538346, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 261, train_loss = 14.928342265076935, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 262, train_loss = 14.917179584503174, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 263, train_loss = 14.910575218498707, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 264, train_loss = 14.90199760813266, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 265, train_loss = 14.894740283489227, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 266, train_loss = 14.881791964173317, train_acc = 0.966581276199348\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 267, train_loss = 14.875632849521935, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 268, train_loss = 14.869192394427955, train_acc = 0.966581276199348\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 269, train_loss = 14.853279923088849, train_acc = 0.9669306008383791\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 270, train_loss = 14.846485893242061, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 271, train_loss = 14.838070817291737, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 272, train_loss = 14.825876181013882, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 273, train_loss = 14.825704343616962, train_acc = 0.9669306008383791\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 274, train_loss = 14.806400162633508, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 275, train_loss = 14.799460570327938, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 276, train_loss = 14.792627724818885, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 277, train_loss = 14.784099526703358, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 278, train_loss = 14.780636318027973, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 279, train_loss = 14.763920789118856, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 280, train_loss = 14.765590583439916, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 281, train_loss = 14.756714875809848, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 282, train_loss = 14.743480414152145, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 283, train_loss = 14.734988612588495, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 284, train_loss = 14.729742057621479, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 285, train_loss = 14.714667235966772, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 286, train_loss = 14.71382279181853, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 287, train_loss = 14.700842209160328, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 288, train_loss = 14.696844913065434, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 289, train_loss = 14.68292491370812, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 290, train_loss = 14.67561957007274, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 291, train_loss = 14.671879222150892, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 292, train_loss = 14.669349074363708, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 293, train_loss = 14.651605894323438, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 294, train_loss = 14.65341231226921, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 295, train_loss = 14.64179831231013, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 296, train_loss = 14.627414678689092, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 297, train_loss = 14.624243145342916, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 298, train_loss = 14.618463528808206, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 299, train_loss = 14.610351257026196, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 300, train_loss = 14.603662960231304, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 301, train_loss = 14.592954797204584, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 302, train_loss = 14.585573054850101, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 303, train_loss = 14.57369014620781, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 304, train_loss = 14.571775391697884, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 305, train_loss = 14.556932926177979, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 306, train_loss = 14.55694122845307, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 307, train_loss = 14.549049896653742, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 308, train_loss = 14.538993862923235, train_acc = 0.9678621332091291\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 309, train_loss = 14.533774418290704, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 310, train_loss = 14.523653594311327, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 311, train_loss = 14.519488448742777, train_acc = 0.9678621332091291\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 312, train_loss = 14.511318969074637, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 313, train_loss = 14.505414418876171, train_acc = 0.9677456916627852\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 314, train_loss = 14.498157729860395, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 315, train_loss = 14.489631389733404, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 316, train_loss = 14.484200005885214, train_acc = 0.9677456916627852\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 317, train_loss = 14.476521755103022, train_acc = 0.9678621332091291\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 318, train_loss = 14.466725153382868, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 319, train_loss = 14.462915666401386, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 320, train_loss = 14.453285038471222, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 321, train_loss = 14.447867082897574, train_acc = 0.9677456916627852\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 322, train_loss = 14.445849791169167, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 323, train_loss = 14.435452312231064, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 324, train_loss = 14.429360327776521, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 325, train_loss = 14.427344866096973, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 326, train_loss = 14.414953050669283, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 327, train_loss = 14.408317821566015, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 328, train_loss = 14.407705316785723, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 329, train_loss = 14.39476310228929, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 330, train_loss = 14.391642645001411, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 331, train_loss = 14.382464210037142, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 332, train_loss = 14.373167410492897, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 333, train_loss = 14.368810857180506, train_acc = 0.9683278993945039\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 334, train_loss = 14.367511255200952, train_acc = 0.9683278993945039\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 335, train_loss = 14.35967985773459, train_acc = 0.9683278993945039\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 336, train_loss = 14.353831335902214, train_acc = 0.9683278993945039\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 337, train_loss = 14.343085067812353, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 338, train_loss = 14.338855728507042, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 339, train_loss = 14.33492710441351, train_acc = 0.9683278993945039\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 340, train_loss = 14.329621570650488, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 341, train_loss = 14.329933715518564, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 342, train_loss = 14.31327377492562, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 343, train_loss = 14.305231546517462, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 344, train_loss = 14.30452855443582, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 345, train_loss = 14.291262505110353, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 346, train_loss = 14.294781386852264, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 347, train_loss = 14.281559599097818, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 348, train_loss = 14.273826509714127, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 349, train_loss = 14.268773667514324, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 350, train_loss = 14.263810651842505, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 351, train_loss = 14.262052016798407, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 352, train_loss = 14.250418519135565, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 353, train_loss = 14.247633213642985, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 354, train_loss = 14.239955248776823, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 355, train_loss = 14.231820193585008, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 356, train_loss = 14.224678749684244, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 357, train_loss = 14.218666364904493, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 358, train_loss = 14.217266919557005, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 359, train_loss = 14.206000742968172, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 360, train_loss = 14.19499308615923, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 361, train_loss = 14.196391053497791, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 362, train_loss = 14.188658048864454, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 363, train_loss = 14.18559063738212, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 364, train_loss = 14.173046179115772, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 365, train_loss = 14.17212794488296, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 366, train_loss = 14.167531363666058, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 367, train_loss = 14.157632142305374, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 368, train_loss = 14.150085853878409, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 369, train_loss = 14.15288107842207, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 370, train_loss = 14.141366066876799, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 371, train_loss = 14.135341221932322, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 372, train_loss = 14.135703293140978, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 373, train_loss = 14.124217979609966, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 374, train_loss = 14.1131256618537, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 375, train_loss = 14.121230910066515, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 376, train_loss = 14.115664137061685, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 377, train_loss = 14.102375651244074, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 378, train_loss = 14.103695422410965, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 379, train_loss = 14.09278486436233, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 380, train_loss = 14.084828624967486, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 381, train_loss = 14.081831485033035, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 382, train_loss = 14.069601349532604, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 383, train_loss = 14.068420184310526, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 384, train_loss = 14.067339060362428, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 385, train_loss = 14.058749983552843, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 386, train_loss = 14.054320879280567, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 387, train_loss = 14.04895739769563, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 388, train_loss = 14.0491623878479, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 389, train_loss = 14.043913727160543, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 390, train_loss = 14.032822261098772, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 391, train_loss = 14.030037810560316, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 392, train_loss = 14.022348371800035, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 393, train_loss = 14.020240793470293, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 394, train_loss = 14.013104982674122, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 395, train_loss = 14.006039927247912, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 396, train_loss = 14.001553582493216, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 397, train_loss = 13.999305618461221, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 398, train_loss = 13.992114908993244, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 399, train_loss = 13.982066968921572, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 400, train_loss = 13.982354534324259, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 401, train_loss = 13.980038727167994, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "1th- epoch: 402, train_loss = 13.970074293669313, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 403, train_loss = 13.968762755393982, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 404, train_loss = 13.95855317497626, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 405, train_loss = 13.956976681947708, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 406, train_loss = 13.954907631035894, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 407, train_loss = 13.94324191659689, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 408, train_loss = 13.948030499275774, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 409, train_loss = 13.93726188922301, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 410, train_loss = 13.934403382241726, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 411, train_loss = 13.9244121783413, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 412, train_loss = 13.921843039337546, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 413, train_loss = 13.91657783323899, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 414, train_loss = 13.911593578755856, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 415, train_loss = 13.909871940966696, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 416, train_loss = 13.90487460559234, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 417, train_loss = 13.898831779602915, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 418, train_loss = 13.893685268703848, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 419, train_loss = 13.88559428602457, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 420, train_loss = 13.886704497039318, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 421, train_loss = 13.876282761339098, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 422, train_loss = 13.870210714638233, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 423, train_loss = 13.864609599113464, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 424, train_loss = 13.863970851060003, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 425, train_loss = 13.860143999103457, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "1th- epoch: 426, train_loss = 13.856241419911385, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 427, train_loss = 13.84715137630701, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 428, train_loss = 13.847786324564368, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 429, train_loss = 13.839700487907976, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 430, train_loss = 13.833949781954288, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 431, train_loss = 13.838502278085798, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 432, train_loss = 13.834315113723278, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 433, train_loss = 13.825540666934103, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 434, train_loss = 13.820487732533365, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 435, train_loss = 13.82019717246294, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 436, train_loss = 13.805036986712366, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 437, train_loss = 13.808900564908981, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 438, train_loss = 13.800421126186848, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 439, train_loss = 13.795740991830826, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 440, train_loss = 13.790192584041506, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 441, train_loss = 13.787638609763235, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 442, train_loss = 13.783934138715267, train_acc = 0.9701909641360037\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 443, train_loss = 13.773557158652693, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 444, train_loss = 13.771179867442697, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 445, train_loss = 13.77013420080766, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 446, train_loss = 13.762094976846129, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 447, train_loss = 13.76476730639115, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 448, train_loss = 13.755821188446134, train_acc = 0.9698416394969726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 449, train_loss = 13.748240113258362, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 450, train_loss = 13.752988318447024, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 451, train_loss = 13.743619874119759, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 452, train_loss = 13.741098883096129, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 453, train_loss = 13.73489161580801, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 454, train_loss = 13.729323364794254, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 455, train_loss = 13.730227373540401, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 456, train_loss = 13.725483221467584, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 457, train_loss = 13.717251867055893, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 458, train_loss = 13.708953022956848, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 459, train_loss = 13.708091293927282, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 460, train_loss = 13.703981988132, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 461, train_loss = 13.699944200459868, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 462, train_loss = 13.698551414068788, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 463, train_loss = 13.698076928500086, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 464, train_loss = 13.689485130365938, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 465, train_loss = 13.690052380319685, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 466, train_loss = 13.680103994905949, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 467, train_loss = 13.676080299075693, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 468, train_loss = 13.673687236849219, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 469, train_loss = 13.6725227185525, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 470, train_loss = 13.667940810322762, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 471, train_loss = 13.665495628956705, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 472, train_loss = 13.657459005713463, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 473, train_loss = 13.65693617099896, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 474, train_loss = 13.66117321467027, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 475, train_loss = 13.647520875092596, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 476, train_loss = 13.64335567271337, train_acc = 0.9704238472286912\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 477, train_loss = 13.637304345611483, train_acc = 0.9704238472286912\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 478, train_loss = 13.632094077765942, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 479, train_loss = 13.641424278263003, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 480, train_loss = 13.628484956920147, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 481, train_loss = 13.624601339455694, train_acc = 0.9701909641360037\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 482, train_loss = 13.621572437230498, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 483, train_loss = 13.617427326738834, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 484, train_loss = 13.619990905281156, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 485, train_loss = 13.615990703459829, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 486, train_loss = 13.605644702911377, train_acc = 0.9703074056823474\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 487, train_loss = 13.60210316395387, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 488, train_loss = 13.595050036907196, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 489, train_loss = 13.601742001716048, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 490, train_loss = 13.594535825308412, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 491, train_loss = 13.58728951960802, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 492, train_loss = 13.584639152046293, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 493, train_loss = 13.582791601773351, train_acc = 0.9703074056823474\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 494, train_loss = 13.587868752423674, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 495, train_loss = 13.578009063843638, train_acc = 0.9703074056823474\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 496, train_loss = 13.566493863705546, train_acc = 0.9704238472286912\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 497, train_loss = 13.568473269697279, train_acc = 0.9701909641360037\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 498, train_loss = 13.561576848383993, train_acc = 0.9704238472286912\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 499, train_loss = 13.561041481792927, train_acc = 0.9704238472286912\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                      | 1/30 [09:02<4:22:03, 542.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "2th- epoch: 0, train_loss = 127.45502880215645, train_acc = 0.749534233814625\n",
      "test Acc 0.8119180633147114:\n",
      "2th- epoch: 1, train_loss = 59.21118600666523, train_acc = 0.8734280391243596\n",
      "test Acc 0.8566108007448789:\n",
      "2th- epoch: 2, train_loss = 49.65851204097271, train_acc = 0.8954354913833256\n",
      "test Acc 0.88268156424581:\n",
      "2th- epoch: 3, train_loss = 44.52341739833355, train_acc = 0.905798789007918\n",
      "test Acc 0.8943202979515829:\n",
      "2th- epoch: 4, train_loss = 41.05014143139124, train_acc = 0.912435957149511\n",
      "test Acc 0.9082867783985102:\n",
      "2th- epoch: 5, train_loss = 38.648760728538036, train_acc = 0.9174429436422916\n",
      "test Acc 0.9110800744878957:\n",
      "2th- epoch: 6, train_loss = 36.73273350298405, train_acc = 0.9210526315789473\n",
      "test Acc 0.9162011173184358:\n",
      "2th- epoch: 7, train_loss = 35.23891878128052, train_acc = 0.9229156963204471\n",
      "test Acc 0.9217877094972067:\n",
      "2th- epoch: 8, train_loss = 33.97499929368496, train_acc = 0.9246623195156032\n",
      "test Acc 0.9236499068901304:\n",
      "2th- epoch: 9, train_loss = 32.81522310525179, train_acc = 0.9279226828132278\n",
      "test Acc 0.9250465549348231:\n",
      "2th- epoch: 10, train_loss = 31.918881602585316, train_acc = 0.9304843968327899\n",
      "test Acc 0.9264432029795159:\n",
      "2th- epoch: 11, train_loss = 31.074374943971634, train_acc = 0.9321145784816023\n",
      "test Acc 0.9273743016759777:\n",
      "2th- epoch: 12, train_loss = 30.333088643848896, train_acc = 0.9331625523986958\n",
      "test Acc 0.9287709497206704:\n",
      "2th- epoch: 13, train_loss = 29.724955454468727, train_acc = 0.9346762925011645\n",
      "test Acc 0.9287709497206704:\n",
      "2th- epoch: 14, train_loss = 29.12038667500019, train_acc = 0.935724266418258\n",
      "test Acc 0.9292364990689013:\n",
      "2th- epoch: 15, train_loss = 28.57337660342455, train_acc = 0.9360735910572893\n",
      "test Acc 0.930633147113594:\n",
      "2th- epoch: 16, train_loss = 28.03717754036188, train_acc = 0.9389846297158826\n",
      "test Acc 0.931098696461825:\n",
      "2th- epoch: 17, train_loss = 27.592538002878428, train_acc = 0.9397997205402888\n",
      "test Acc 0.9338919925512105:\n",
      "2th- epoch: 18, train_loss = 27.159566566348076, train_acc = 0.9402654867256637\n",
      "test Acc 0.9329608938547486:\n",
      "2th- epoch: 19, train_loss = 26.797300558537245, train_acc = 0.9410805775500699\n",
      "test Acc 0.9338919925512105:\n",
      "2th- epoch: 20, train_loss = 26.435608759522438, train_acc = 0.9417792268281323\n",
      "test Acc 0.9334264432029795:\n",
      "2th- epoch: 21, train_loss = 26.107988707721233, train_acc = 0.9427107591988821\n",
      "test Acc 0.9338919925512105:\n",
      "2th- epoch: 22, train_loss = 25.798623614013195, train_acc = 0.9429436422915697\n",
      "test Acc 0.9343575418994413:\n",
      "2th- epoch: 23, train_loss = 25.50274957716465, train_acc = 0.9425943176525384\n",
      "test Acc 0.9343575418994413:\n",
      "2th- epoch: 24, train_loss = 25.238766130059958, train_acc = 0.9438751746623195\n",
      "test Acc 0.9357541899441341:\n",
      "2th- epoch: 25, train_loss = 24.941525846719742, train_acc = 0.9446902654867256\n",
      "test Acc 0.9357541899441341:\n",
      "2th- epoch: 26, train_loss = 24.69000207260251, train_acc = 0.9455053563111319\n",
      "test Acc 0.9357541899441341:\n",
      "2th- epoch: 27, train_loss = 24.46745788305998, train_acc = 0.9460875640428504\n",
      "test Acc 0.9371508379888268:\n",
      "2th- epoch: 28, train_loss = 24.230367582291365, train_acc = 0.9469026548672567\n",
      "test Acc 0.9376163873370578:\n",
      "2th- epoch: 29, train_loss = 24.025691390037537, train_acc = 0.9472519795062878\n",
      "test Acc 0.9376163873370578:\n",
      "2th- epoch: 30, train_loss = 23.815513480454683, train_acc = 0.9477177456916628\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 31, train_loss = 23.633763041347265, train_acc = 0.9479506287843502\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 32, train_loss = 23.4525763168931, train_acc = 0.9485328365160689\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 33, train_loss = 23.27009280025959, train_acc = 0.9488821611551002\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 34, train_loss = 23.113457936793566, train_acc = 0.9493479273404751\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 35, train_loss = 22.94290190190077, train_acc = 0.9496972519795063\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 36, train_loss = 22.820726491510868, train_acc = 0.9500465766185375\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 37, train_loss = 22.64313855022192, train_acc = 0.9505123428039124\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 38, train_loss = 22.506424620747566, train_acc = 0.9506287843502562\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 39, train_loss = 22.394355412572622, train_acc = 0.9509781089892874\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 40, train_loss = 22.23272554203868, train_acc = 0.9512109920819748\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 41, train_loss = 22.11548077687621, train_acc = 0.9513274336283186\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 42, train_loss = 22.007952343672514, train_acc = 0.9513274336283186\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 43, train_loss = 21.848825309425592, train_acc = 0.9512109920819748\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 44, train_loss = 21.72510217130184, train_acc = 0.9513274336283186\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 45, train_loss = 21.638000838458538, train_acc = 0.9514438751746623\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 46, train_loss = 21.535908836871386, train_acc = 0.9519096413600373\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 47, train_loss = 21.405577024444938, train_acc = 0.952491849091756\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 48, train_loss = 21.298773676156998, train_acc = 0.9523754075454122\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 49, train_loss = 21.191881272941828, train_acc = 0.952491849091756\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 50, train_loss = 21.10290550813079, train_acc = 0.9527247321844434\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 51, train_loss = 21.01967991515994, train_acc = 0.9528411737307871\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 52, train_loss = 20.94041173532605, train_acc = 0.9528411737307871\n",
      "test Acc 0.9390130353817505:\n",
      "2th- epoch: 53, train_loss = 20.8246540594846, train_acc = 0.9533069399161621\n",
      "test Acc 0.9394785847299814:\n",
      "2th- epoch: 54, train_loss = 20.75616650097072, train_acc = 0.9530740568234746\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 55, train_loss = 20.67957645840943, train_acc = 0.9536562645551933\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 56, train_loss = 20.580078404396772, train_acc = 0.9541220307405682\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 57, train_loss = 20.49900433421135, train_acc = 0.9538891476478808\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 58, train_loss = 20.41242583282292, train_acc = 0.9542384722869119\n",
      "test Acc 0.9399441340782123:\n",
      "2th- epoch: 59, train_loss = 20.30342290736735, train_acc = 0.9547042384722869\n",
      "test Acc 0.9404096834264432:\n",
      "2th- epoch: 60, train_loss = 20.206490786746144, train_acc = 0.9548206800186306\n",
      "test Acc 0.9404096834264432:\n",
      "2th- epoch: 61, train_loss = 20.14221636019647, train_acc = 0.9549371215649743\n",
      "test Acc 0.9404096834264432:\n",
      "2th- epoch: 62, train_loss = 20.074087170884013, train_acc = 0.9549371215649743\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 63, train_loss = 19.986665016040206, train_acc = 0.9549371215649743\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 64, train_loss = 19.932928580790758, train_acc = 0.9549371215649743\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 65, train_loss = 19.855768395587802, train_acc = 0.9554028877503493\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 66, train_loss = 19.77815008163452, train_acc = 0.9557522123893806\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 67, train_loss = 19.736287778243423, train_acc = 0.955519329296693\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 68, train_loss = 19.665565164759755, train_acc = 0.955985095482068\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 69, train_loss = 19.597655532881618, train_acc = 0.9558686539357243\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 70, train_loss = 19.541501758620143, train_acc = 0.955985095482068\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 71, train_loss = 19.480943504720926, train_acc = 0.9563344201210993\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 72, train_loss = 19.433372208848596, train_acc = 0.9562179785747554\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 73, train_loss = 19.35737751610577, train_acc = 0.9565673032137867\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 74, train_loss = 19.33027042634785, train_acc = 0.9570330693991617\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 75, train_loss = 19.262201452627778, train_acc = 0.9571495109455054\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 76, train_loss = 19.209435308352113, train_acc = 0.9574988355845365\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 77, train_loss = 19.168265115469694, train_acc = 0.9572659524918491\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 78, train_loss = 19.111203469336033, train_acc = 0.9574988355845365\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 79, train_loss = 19.061277294531465, train_acc = 0.9580810433162552\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 80, train_loss = 19.00651927292347, train_acc = 0.9581974848625989\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 81, train_loss = 18.95875719562173, train_acc = 0.9584303679552865\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 82, train_loss = 18.91336303949356, train_acc = 0.9585468095016302\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 83, train_loss = 18.86819097213447, train_acc = 0.9585468095016302\n",
      "test Acc 0.9422718808193669:\n",
      "2th- epoch: 84, train_loss = 18.821892427280545, train_acc = 0.9584303679552865\n",
      "test Acc 0.9422718808193669:\n",
      "2th- epoch: 85, train_loss = 18.790000706911087, train_acc = 0.9584303679552865\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 86, train_loss = 18.72375334240496, train_acc = 0.9585468095016302\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 87, train_loss = 18.69178333878517, train_acc = 0.9590125756870052\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 88, train_loss = 18.648913165554404, train_acc = 0.9587796925943176\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 89, train_loss = 18.600756557658315, train_acc = 0.9587796925943176\n",
      "test Acc 0.9422718808193669:\n",
      "2th- epoch: 90, train_loss = 18.561967432498932, train_acc = 0.9590125756870052\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 91, train_loss = 18.526485092937946, train_acc = 0.9592454587796926\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 92, train_loss = 18.4968684874475, train_acc = 0.9593619003260363\n",
      "test Acc 0.9422718808193669:\n",
      "2th- epoch: 93, train_loss = 18.43294101394713, train_acc = 0.9597112249650676\n",
      "test Acc 0.9422718808193669:\n",
      "2th- epoch: 94, train_loss = 18.403083806857467, train_acc = 0.9595947834187238\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 95, train_loss = 18.365004474297166, train_acc = 0.9597112249650676\n",
      "test Acc 0.9432029795158287:\n",
      "2th- epoch: 96, train_loss = 18.329410469159484, train_acc = 0.9597112249650676\n",
      "test Acc 0.9422718808193669:\n",
      "2th- epoch: 97, train_loss = 18.28236372023821, train_acc = 0.9598276665114113\n",
      "test Acc 0.9432029795158287:\n",
      "2th- epoch: 98, train_loss = 18.25740474462509, train_acc = 0.9600605496040987\n",
      "test Acc 0.9432029795158287:\n",
      "2th- epoch: 99, train_loss = 18.203968692570925, train_acc = 0.9606427573358174\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 100, train_loss = 18.18284604139626, train_acc = 0.96040987424313\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 101, train_loss = 18.13646143116057, train_acc = 0.9605263157894737\n",
      "test Acc 0.9432029795158287:\n",
      "2th- epoch: 102, train_loss = 18.100176515057683, train_acc = 0.9606427573358174\n",
      "test Acc 0.9441340782122905:\n",
      "2th- epoch: 103, train_loss = 18.072857649996877, train_acc = 0.9607591988821611\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 104, train_loss = 18.03026409819722, train_acc = 0.9609920819748486\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 105, train_loss = 18.00429292023182, train_acc = 0.9613414066138798\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 106, train_loss = 17.97511002421379, train_acc = 0.9612249650675361\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 107, train_loss = 17.93035194091499, train_acc = 0.9612249650675361\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 108, train_loss = 17.909775659441948, train_acc = 0.9614578481602236\n",
      "test Acc 0.9441340782122905:\n",
      "2th- epoch: 109, train_loss = 17.87158785201609, train_acc = 0.9612249650675361\n",
      "test Acc 0.9441340782122905:\n",
      "2th- epoch: 110, train_loss = 17.836098603904247, train_acc = 0.9612249650675361\n",
      "test Acc 0.9441340782122905:\n",
      "2th- epoch: 111, train_loss = 17.812009822577238, train_acc = 0.9615742897065673\n",
      "test Acc 0.9445996275605214:\n",
      "2th- epoch: 112, train_loss = 17.774050334468484, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 113, train_loss = 17.755198592320085, train_acc = 0.961690731252911\n",
      "test Acc 0.9445996275605214:\n",
      "2th- epoch: 114, train_loss = 17.71642610989511, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 115, train_loss = 17.687298875302076, train_acc = 0.9619236143455985\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 116, train_loss = 17.657634345814586, train_acc = 0.9620400558919422\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 117, train_loss = 17.62167246825993, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 118, train_loss = 17.598840219900012, train_acc = 0.962156497438286\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 119, train_loss = 17.564340630546212, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 120, train_loss = 17.533750012516975, train_acc = 0.9623893805309734\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 121, train_loss = 17.51137558929622, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 122, train_loss = 17.481562808156013, train_acc = 0.9623893805309734\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 123, train_loss = 17.454414254054427, train_acc = 0.9626222636236609\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 124, train_loss = 17.435688683763146, train_acc = 0.9623893805309734\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 125, train_loss = 17.41473157517612, train_acc = 0.9626222636236609\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 126, train_loss = 17.373198315501213, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 127, train_loss = 17.346574099734426, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 128, train_loss = 17.32481023669243, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 129, train_loss = 17.307722879573703, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 130, train_loss = 17.27592417038977, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 131, train_loss = 17.25357179902494, train_acc = 0.9628551467163484\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 132, train_loss = 17.229910366237164, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 133, train_loss = 17.21030759997666, train_acc = 0.9633209129017233\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 134, train_loss = 17.18004116602242, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 135, train_loss = 17.159028751775622, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 136, train_loss = 17.12841096147895, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 137, train_loss = 17.109402514994144, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 138, train_loss = 17.084383880719543, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 139, train_loss = 17.048674209043384, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 140, train_loss = 17.027877582237124, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 141, train_loss = 17.00004163570702, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 142, train_loss = 16.995775446295738, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 143, train_loss = 16.963550232350826, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 144, train_loss = 16.940921362489462, train_acc = 0.9632044713553796\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 145, train_loss = 16.91783561371267, train_acc = 0.9634373544480671\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 146, train_loss = 16.898614255711436, train_acc = 0.9632044713553796\n",
      "test Acc 0.9450651769087524:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 147, train_loss = 16.878104964271188, train_acc = 0.9634373544480671\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 148, train_loss = 16.861504951491952, train_acc = 0.9632044713553796\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 149, train_loss = 16.83960670232773, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 150, train_loss = 16.815933572128415, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 151, train_loss = 16.79067882709205, train_acc = 0.9633209129017233\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 152, train_loss = 16.776182325556874, train_acc = 0.9633209129017233\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 153, train_loss = 16.75211418233812, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 154, train_loss = 16.73311212658882, train_acc = 0.9636702375407545\n",
      "test Acc 0.9459962756052142:\n",
      "2th- epoch: 155, train_loss = 16.71538239903748, train_acc = 0.9634373544480671\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 156, train_loss = 16.691235652193427, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 157, train_loss = 16.67294642701745, train_acc = 0.9637866790870983\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 158, train_loss = 16.653219865635037, train_acc = 0.9636702375407545\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 159, train_loss = 16.627657171338797, train_acc = 0.9636702375407545\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 160, train_loss = 16.612680243328214, train_acc = 0.9637866790870983\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 161, train_loss = 16.59016266465187, train_acc = 0.963903120633442\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 162, train_loss = 16.57512278109789, train_acc = 0.9637866790870983\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 163, train_loss = 16.548395443707705, train_acc = 0.963903120633442\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 164, train_loss = 16.535924648866057, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "2th- epoch: 165, train_loss = 16.519336694851518, train_acc = 0.963903120633442\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 166, train_loss = 16.506867369636893, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 167, train_loss = 16.482452807947993, train_acc = 0.9641360037261295\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 168, train_loss = 16.46613541804254, train_acc = 0.9641360037261295\n",
      "test Acc 0.9459962756052142:\n",
      "2th- epoch: 169, train_loss = 16.443320589140058, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 170, train_loss = 16.43106490559876, train_acc = 0.9643688868188169\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 171, train_loss = 16.40285370312631, train_acc = 0.9641360037261295\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 172, train_loss = 16.39308310765773, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 173, train_loss = 16.372084161266685, train_acc = 0.9646017699115044\n",
      "test Acc 0.9459962756052142:\n",
      "2th- epoch: 174, train_loss = 16.35585813038051, train_acc = 0.9643688868188169\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 175, train_loss = 16.34000856243074, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 176, train_loss = 16.320161134935915, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 177, train_loss = 16.30818367563188, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 178, train_loss = 16.295194014906883, train_acc = 0.9643688868188169\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 179, train_loss = 16.271163627505302, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 180, train_loss = 16.253977997228503, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 181, train_loss = 16.236825725995004, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 182, train_loss = 16.224380418658257, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 183, train_loss = 16.208025340922177, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 184, train_loss = 16.190854069776833, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 185, train_loss = 16.175512398593128, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 186, train_loss = 16.15791634749621, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 187, train_loss = 16.142631735652685, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 188, train_loss = 16.129938911646605, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 189, train_loss = 16.116058724932373, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 190, train_loss = 16.101277084089816, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 191, train_loss = 16.083312458358705, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 192, train_loss = 16.06281356420368, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 193, train_loss = 16.057228327728808, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 194, train_loss = 16.040344952605665, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 195, train_loss = 16.024986713193357, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 196, train_loss = 16.016678624786437, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 197, train_loss = 15.997984512709081, train_acc = 0.9650675360968793\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 198, train_loss = 15.98377627786249, train_acc = 0.9648346530041919\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 199, train_loss = 15.970051827840507, train_acc = 0.9648346530041919\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 200, train_loss = 15.951034405268729, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 201, train_loss = 15.943938709795475, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 202, train_loss = 15.923328660428524, train_acc = 0.9648346530041919\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 203, train_loss = 15.913520500995219, train_acc = 0.9651839776432231\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 204, train_loss = 15.90088798198849, train_acc = 0.9653004191895669\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 205, train_loss = 15.88965464476496, train_acc = 0.9653004191895669\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 206, train_loss = 15.871973964385688, train_acc = 0.9654168607359106\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 207, train_loss = 15.858059042133391, train_acc = 0.9654168607359106\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 208, train_loss = 15.847608395852149, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 209, train_loss = 15.83423828613013, train_acc = 0.9653004191895669\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 210, train_loss = 15.821860590018332, train_acc = 0.965649743828598\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 211, train_loss = 15.812611687928438, train_acc = 0.965649743828598\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 212, train_loss = 15.791697884909809, train_acc = 0.965649743828598\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 213, train_loss = 15.782534982077777, train_acc = 0.965649743828598\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 214, train_loss = 15.771233350969851, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 215, train_loss = 15.754078101366758, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 216, train_loss = 15.746389996260405, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 217, train_loss = 15.729275107383728, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 218, train_loss = 15.716684724204242, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 219, train_loss = 15.701380035839975, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 220, train_loss = 15.694091696292162, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 221, train_loss = 15.687370907515287, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 222, train_loss = 15.661646348424256, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 223, train_loss = 15.658183168619871, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 224, train_loss = 15.64612281974405, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 225, train_loss = 15.631570607423782, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 226, train_loss = 15.618716530501842, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 227, train_loss = 15.609693580307066, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 228, train_loss = 15.593099549412727, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 229, train_loss = 15.582192878238857, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 230, train_loss = 15.575664661824703, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "2th- epoch: 231, train_loss = 15.563874401152134, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 232, train_loss = 15.551904224790633, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 233, train_loss = 15.539275988936424, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 234, train_loss = 15.526161629706621, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 235, train_loss = 15.517327568493783, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 236, train_loss = 15.505030300468206, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 237, train_loss = 15.49907137081027, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 238, train_loss = 15.489558885805309, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 239, train_loss = 15.471602980047464, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 240, train_loss = 15.461686697788537, train_acc = 0.9668141592920354\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 241, train_loss = 15.44212867692113, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 242, train_loss = 15.44027366116643, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 243, train_loss = 15.424937491305172, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 244, train_loss = 15.420471265912056, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 245, train_loss = 15.401976424269378, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 246, train_loss = 15.39416320901364, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 247, train_loss = 15.378226579166949, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 248, train_loss = 15.369486280716956, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 249, train_loss = 15.366747130639851, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 250, train_loss = 15.353321223519742, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 251, train_loss = 15.33671851735562, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 252, train_loss = 15.32968167308718, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 253, train_loss = 15.32578955590725, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 254, train_loss = 15.31383469607681, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 255, train_loss = 15.304897829890251, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 256, train_loss = 15.300973259843886, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 257, train_loss = 15.279156904667616, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 258, train_loss = 15.27205450180918, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 259, train_loss = 15.255487176589668, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 260, train_loss = 15.254495567642152, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 261, train_loss = 15.24304411560297, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 262, train_loss = 15.229547585360706, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 263, train_loss = 15.223697945475578, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 264, train_loss = 15.216497006826103, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 265, train_loss = 15.210516923107207, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 266, train_loss = 15.202373947016895, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 267, train_loss = 15.19237161707133, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 268, train_loss = 15.180695455521345, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 269, train_loss = 15.167972553521395, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 270, train_loss = 15.15337007958442, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 271, train_loss = 15.150422970764339, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 272, train_loss = 15.14204790815711, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 273, train_loss = 15.130991377867758, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 274, train_loss = 15.121809369884431, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 275, train_loss = 15.11522361356765, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 276, train_loss = 15.100419264286757, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 277, train_loss = 15.089359890669584, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 278, train_loss = 15.088010560721159, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 279, train_loss = 15.076906989328563, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 280, train_loss = 15.071445391513407, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 281, train_loss = 15.05818459391594, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 282, train_loss = 15.056243459694088, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 283, train_loss = 15.04422701895237, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 284, train_loss = 15.033009770326316, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 285, train_loss = 15.02588580083102, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 286, train_loss = 15.019447971135378, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 287, train_loss = 15.009676218032837, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 288, train_loss = 15.00010706204921, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 289, train_loss = 14.995871588587761, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 290, train_loss = 14.984848984517157, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 291, train_loss = 14.975174826569855, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 292, train_loss = 14.971971134655178, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 293, train_loss = 14.957753248512745, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 294, train_loss = 14.948226599954069, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 295, train_loss = 14.945030408911407, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 296, train_loss = 14.935797777026892, train_acc = 0.9676292501164415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 297, train_loss = 14.92519545275718, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 298, train_loss = 14.917648809961975, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 299, train_loss = 14.908299446105957, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 300, train_loss = 14.91156666353345, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 301, train_loss = 14.897472796030343, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 302, train_loss = 14.887117858044803, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 303, train_loss = 14.885658998973668, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 304, train_loss = 14.873137908987701, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 305, train_loss = 14.868231409229338, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 306, train_loss = 14.855934691615403, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 307, train_loss = 14.849117361940444, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 308, train_loss = 14.843475888483226, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 309, train_loss = 14.834110795520246, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 310, train_loss = 14.820185634307563, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 311, train_loss = 14.81837719772011, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 312, train_loss = 14.81248811725527, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 313, train_loss = 14.799410704523325, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 314, train_loss = 14.793156242929399, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 315, train_loss = 14.789047206752002, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 316, train_loss = 14.783556286245584, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 317, train_loss = 14.77009179070592, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 318, train_loss = 14.76699948310852, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 319, train_loss = 14.759162026457489, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 320, train_loss = 14.74770272988826, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 321, train_loss = 14.749816848896444, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 322, train_loss = 14.743899715133011, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 323, train_loss = 14.73326654266566, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 324, train_loss = 14.725730831734836, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 325, train_loss = 14.71758181694895, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 326, train_loss = 14.709539004601538, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 327, train_loss = 14.705501108430326, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 328, train_loss = 14.704491402953863, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 329, train_loss = 14.697900547645986, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 330, train_loss = 14.679495862685144, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 331, train_loss = 14.678833446465433, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 332, train_loss = 14.661804196424782, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 333, train_loss = 14.65972697082907, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 334, train_loss = 14.657357764430344, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 335, train_loss = 14.651737671345472, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 336, train_loss = 14.64076441526413, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 337, train_loss = 14.636538431979716, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 338, train_loss = 14.630691144615412, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 339, train_loss = 14.617800711654127, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 340, train_loss = 14.613755262456834, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 341, train_loss = 14.607741541229188, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 342, train_loss = 14.608629391528666, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 343, train_loss = 14.59725945070386, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 344, train_loss = 14.587344855070114, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 345, train_loss = 14.5853663822636, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 346, train_loss = 14.573555025272071, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 347, train_loss = 14.564767841249704, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 348, train_loss = 14.568499591201544, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 349, train_loss = 14.560690175741911, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 350, train_loss = 14.546219397336245, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 351, train_loss = 14.548280376009643, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 352, train_loss = 14.535390318371356, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 353, train_loss = 14.539032774977386, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 354, train_loss = 14.523018100298941, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 355, train_loss = 14.519794688560069, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 356, train_loss = 14.513053352944553, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 357, train_loss = 14.508643508888781, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 358, train_loss = 14.505705449730158, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 359, train_loss = 14.495741352438927, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 360, train_loss = 14.4959309482947, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 361, train_loss = 14.49033314641565, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 362, train_loss = 14.473525860346854, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 363, train_loss = 14.473228991031647, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 364, train_loss = 14.46916254144162, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 365, train_loss = 14.457957153208554, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 366, train_loss = 14.454784921370447, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 367, train_loss = 14.453931524418294, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 368, train_loss = 14.441829904913902, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 369, train_loss = 14.43433028459549, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 370, train_loss = 14.432297814637423, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 371, train_loss = 14.428979472257197, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 372, train_loss = 14.419981040991843, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 373, train_loss = 14.414042145945132, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 374, train_loss = 14.405488503165543, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 375, train_loss = 14.402681426145136, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 376, train_loss = 14.401805016212165, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 377, train_loss = 14.385430634021759, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 378, train_loss = 14.386245372705162, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 379, train_loss = 14.3811576962471, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 380, train_loss = 14.375237009488046, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 381, train_loss = 14.366174093447626, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 382, train_loss = 14.361974749714136, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 383, train_loss = 14.364832323975861, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 384, train_loss = 14.350384272634983, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 385, train_loss = 14.344141700305045, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 386, train_loss = 14.336085666902363, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 387, train_loss = 14.334565504454076, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 388, train_loss = 14.320297316648066, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 389, train_loss = 14.326578479260206, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 390, train_loss = 14.313972398638725, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 391, train_loss = 14.305911940522492, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 392, train_loss = 14.314739488996565, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 393, train_loss = 14.300894898362458, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 394, train_loss = 14.299516494385898, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 395, train_loss = 14.285078150220215, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 396, train_loss = 14.285029795020819, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 397, train_loss = 14.280386921949685, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 398, train_loss = 14.272290701977909, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 399, train_loss = 14.271927357651293, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 400, train_loss = 14.268462141044438, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 401, train_loss = 14.258241389878094, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 402, train_loss = 14.251809240318835, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 403, train_loss = 14.246393370442092, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 404, train_loss = 14.236326908227056, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 405, train_loss = 14.239466693252325, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 406, train_loss = 14.233235803432763, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 407, train_loss = 14.22193902079016, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 408, train_loss = 14.225010491907597, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 409, train_loss = 14.20665539149195, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 410, train_loss = 14.209948587231338, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 411, train_loss = 14.206781893968582, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 412, train_loss = 14.193761467002332, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 413, train_loss = 14.19449544325471, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 414, train_loss = 14.185204027686268, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 415, train_loss = 14.182923790998757, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 416, train_loss = 14.176722150295973, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 417, train_loss = 14.173622094094753, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 418, train_loss = 14.165255008731037, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 419, train_loss = 14.16226955736056, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 420, train_loss = 14.15273359650746, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 421, train_loss = 14.153138258960098, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 422, train_loss = 14.146873701363802, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 423, train_loss = 14.144430646207184, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 424, train_loss = 14.141841524746269, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 425, train_loss = 14.140044467058033, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 426, train_loss = 14.12590016424656, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 427, train_loss = 14.126645450945944, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 428, train_loss = 14.123112108558416, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 429, train_loss = 14.112759336829185, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 430, train_loss = 14.112205184064806, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 431, train_loss = 14.105164070613682, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 432, train_loss = 14.100502812769264, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 433, train_loss = 14.094320071395487, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 434, train_loss = 14.087948475033045, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 435, train_loss = 14.091802367474884, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 436, train_loss = 14.080333335790783, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 437, train_loss = 14.073053157422692, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 438, train_loss = 14.073301936034113, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 439, train_loss = 14.071420944295824, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 440, train_loss = 14.063692297786474, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 441, train_loss = 14.052851112093776, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 442, train_loss = 14.054626374039799, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 443, train_loss = 14.049249593168497, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 444, train_loss = 14.037843029946089, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 445, train_loss = 14.034782508853823, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 446, train_loss = 14.032862678170204, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 447, train_loss = 14.032205797731876, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 448, train_loss = 14.024740878492594, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 449, train_loss = 14.01280348887667, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 450, train_loss = 14.01234399387613, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 451, train_loss = 14.017632111907005, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 452, train_loss = 14.007768007460982, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 453, train_loss = 14.002687819302082, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 454, train_loss = 13.992627413477749, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 455, train_loss = 13.991087133530527, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 456, train_loss = 13.992410539183766, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 457, train_loss = 13.98052896792069, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 458, train_loss = 13.982719826046377, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 459, train_loss = 13.976352027151734, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 460, train_loss = 13.988583873957396, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 461, train_loss = 13.960564763750881, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 462, train_loss = 13.965298097580671, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 463, train_loss = 13.95759137487039, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 464, train_loss = 13.956840474158525, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 465, train_loss = 13.943015594035387, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 466, train_loss = 13.948592954780906, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 467, train_loss = 13.939005444291979, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 468, train_loss = 13.934148542582989, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 469, train_loss = 13.93667513737455, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 470, train_loss = 13.922491021454334, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 471, train_loss = 13.921068360563368, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 472, train_loss = 13.917727435473353, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 473, train_loss = 13.914710266049951, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 474, train_loss = 13.91266268119216, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 475, train_loss = 13.908909525722265, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 476, train_loss = 13.902145240455866, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 477, train_loss = 13.90633656969294, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 478, train_loss = 13.894979001488537, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 479, train_loss = 13.89298989996314, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 480, train_loss = 13.886836954858154, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 481, train_loss = 13.884311294648796, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 482, train_loss = 13.88066320354119, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 483, train_loss = 13.87620766600594, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 484, train_loss = 13.8714276724495, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 485, train_loss = 13.86894190683961, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 486, train_loss = 13.858433199580759, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 487, train_loss = 13.857264667749405, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 488, train_loss = 13.851038305554539, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 489, train_loss = 13.846075734589249, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 490, train_loss = 13.843375916127115, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 491, train_loss = 13.840744486544281, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 492, train_loss = 13.836418561637402, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 493, train_loss = 13.835563058499247, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 494, train_loss = 13.836884919553995, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 495, train_loss = 13.823240025434643, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 496, train_loss = 13.8207614175044, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 497, train_loss = 13.813515068497509, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 498, train_loss = 13.80942647298798, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "2th- epoch: 499, train_loss = 13.807658930774778, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████▊                                                                    | 2/30 [18:04<4:13:03, 542.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "3th- epoch: 0, train_loss = 116.76749747991562, train_acc = 0.7554727526781556\n",
      "test Acc 0.8519553072625698:\n",
      "3th- epoch: 1, train_loss = 59.1044575124979, train_acc = 0.8762226362366092\n",
      "test Acc 0.8854748603351955:\n",
      "3th- epoch: 2, train_loss = 49.34728763997555, train_acc = 0.8952026082906381\n",
      "test Acc 0.8994413407821229:\n",
      "3th- epoch: 3, train_loss = 44.30472859740257, train_acc = 0.9055659059152306\n",
      "test Acc 0.9064245810055865:\n",
      "3th- epoch: 4, train_loss = 40.95401853322983, train_acc = 0.9113879832324173\n",
      "test Acc 0.9106145251396648:\n",
      "3th- epoch: 5, train_loss = 38.5804136171937, train_acc = 0.9161620866325105\n",
      "test Acc 0.914804469273743:\n",
      "3th- epoch: 6, train_loss = 36.77699974179268, train_acc = 0.9201210992081975\n",
      "test Acc 0.9175977653631285:\n",
      "3th- epoch: 7, train_loss = 35.29516604542732, train_acc = 0.9230321378667908\n",
      "test Acc 0.9227188081936686:\n",
      "3th- epoch: 8, train_loss = 34.03658027946949, train_acc = 0.9271075919888216\n",
      "test Acc 0.9241154562383612:\n",
      "3th- epoch: 9, train_loss = 33.00393319129944, train_acc = 0.9294364229156963\n",
      "test Acc 0.9278398510242085:\n",
      "3th- epoch: 10, train_loss = 32.09846901893616, train_acc = 0.9304843968327899\n",
      "test Acc 0.9283054003724395:\n",
      "3th- epoch: 11, train_loss = 31.310719065368176, train_acc = 0.9315323707498836\n",
      "test Acc 0.9301675977653632:\n",
      "3th- epoch: 12, train_loss = 30.62853691726923, train_acc = 0.9329296693060084\n",
      "test Acc 0.9315642458100558:\n",
      "3th- epoch: 13, train_loss = 29.979851692914963, train_acc = 0.9344434094084769\n",
      "test Acc 0.9324953445065177:\n",
      "3th- epoch: 14, train_loss = 29.41336927562952, train_acc = 0.9354913833255706\n",
      "test Acc 0.9315642458100558:\n",
      "3th- epoch: 15, train_loss = 28.89723963290453, train_acc = 0.9368886818816954\n",
      "test Acc 0.9320297951582868:\n",
      "3th- epoch: 16, train_loss = 28.418687604367733, train_acc = 0.9378202142524453\n",
      "test Acc 0.9324953445065177:\n",
      "3th- epoch: 17, train_loss = 27.994469046592712, train_acc = 0.9392175128085701\n",
      "test Acc 0.9324953445065177:\n",
      "3th- epoch: 18, train_loss = 27.574742279946804, train_acc = 0.94014904517932\n",
      "test Acc 0.9329608938547486:\n",
      "3th- epoch: 19, train_loss = 27.193552926182747, train_acc = 0.9409641360037261\n",
      "test Acc 0.9329608938547486:\n",
      "3th- epoch: 20, train_loss = 26.851718798279762, train_acc = 0.9416627852817886\n",
      "test Acc 0.9334264432029795:\n",
      "3th- epoch: 21, train_loss = 26.523365803062916, train_acc = 0.9428272007452259\n",
      "test Acc 0.9338919925512105:\n",
      "3th- epoch: 22, train_loss = 26.220335267484188, train_acc = 0.9432929669306008\n",
      "test Acc 0.9343575418994413:\n",
      "3th- epoch: 23, train_loss = 25.9127866178751, train_acc = 0.9437587331159758\n",
      "test Acc 0.9338919925512105:\n",
      "3th- epoch: 24, train_loss = 25.634532243013382, train_acc = 0.944108057755007\n",
      "test Acc 0.9338919925512105:\n",
      "3th- epoch: 25, train_loss = 25.37827468663454, train_acc = 0.9445738239403819\n",
      "test Acc 0.9338919925512105:\n",
      "3th- epoch: 26, train_loss = 25.144275039434433, train_acc = 0.9451560316721006\n",
      "test Acc 0.9343575418994413:\n",
      "3th- epoch: 27, train_loss = 24.90061169117689, train_acc = 0.9459711224965067\n",
      "test Acc 0.9371508379888268:\n",
      "3th- epoch: 28, train_loss = 24.685035228729248, train_acc = 0.9460875640428504\n",
      "test Acc 0.9371508379888268:\n",
      "3th- epoch: 29, train_loss = 24.470348946750164, train_acc = 0.9462040055891943\n",
      "test Acc 0.9376163873370578:\n",
      "3th- epoch: 30, train_loss = 24.270531974732876, train_acc = 0.9465533302282254\n",
      "test Acc 0.9376163873370578:\n",
      "3th- epoch: 31, train_loss = 24.067400116473436, train_acc = 0.9474848625989754\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 32, train_loss = 23.890895780175924, train_acc = 0.9481835118770378\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 33, train_loss = 23.721346642822027, train_acc = 0.9486492780624126\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 34, train_loss = 23.539298113435507, train_acc = 0.9491150442477876\n",
      "test Acc 0.9385474860335196:\n",
      "3th- epoch: 35, train_loss = 23.357312005013227, train_acc = 0.94981369352585\n",
      "test Acc 0.9385474860335196:\n",
      "3th- epoch: 36, train_loss = 23.218316067010164, train_acc = 0.9499301350721937\n",
      "test Acc 0.9385474860335196:\n",
      "3th- epoch: 37, train_loss = 23.054764095693827, train_acc = 0.9503959012575687\n",
      "test Acc 0.9385474860335196:\n",
      "3th- epoch: 38, train_loss = 22.919136960059404, train_acc = 0.9506287843502562\n",
      "test Acc 0.9385474860335196:\n",
      "3th- epoch: 39, train_loss = 22.770097624510527, train_acc = 0.9507452258965999\n",
      "test Acc 0.9385474860335196:\n",
      "3th- epoch: 40, train_loss = 22.642169818282127, train_acc = 0.9507452258965999\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 41, train_loss = 22.51052912697196, train_acc = 0.9510945505356311\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 42, train_loss = 22.391786258667707, train_acc = 0.951560316721006\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 43, train_loss = 22.269207511097193, train_acc = 0.9516767582673498\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 44, train_loss = 22.14843735471368, train_acc = 0.9519096413600373\n",
      "test Acc 0.9390130353817505:\n",
      "3th- epoch: 45, train_loss = 22.03883647918701, train_acc = 0.9526082906380997\n",
      "test Acc 0.9394785847299814:\n",
      "3th- epoch: 46, train_loss = 21.922404821962118, train_acc = 0.9526082906380997\n",
      "test Acc 0.9394785847299814:\n",
      "3th- epoch: 47, train_loss = 21.81966306269169, train_acc = 0.9522589659990685\n",
      "test Acc 0.9399441340782123:\n",
      "3th- epoch: 48, train_loss = 21.7191832177341, train_acc = 0.9526082906380997\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 49, train_loss = 21.606213439255953, train_acc = 0.9529576152771309\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 50, train_loss = 21.507524821907282, train_acc = 0.9529576152771309\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 51, train_loss = 21.420169357210398, train_acc = 0.9531904983698184\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 52, train_loss = 21.33050598576665, train_acc = 0.9534233814625058\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 53, train_loss = 21.235071126371622, train_acc = 0.9537727061015371\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 54, train_loss = 21.14522150158882, train_acc = 0.9540055891942245\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 55, train_loss = 21.06012910231948, train_acc = 0.9541220307405682\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 56, train_loss = 20.97414830699563, train_acc = 0.9545877969259432\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 57, train_loss = 20.889722652733326, train_acc = 0.9548206800186306\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 58, train_loss = 20.80935288965702, train_acc = 0.9548206800186306\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 59, train_loss = 20.74012114852667, train_acc = 0.9549371215649743\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 60, train_loss = 20.641932848840952, train_acc = 0.9552864462040056\n",
      "test Acc 0.9408752327746741:\n",
      "3th- epoch: 61, train_loss = 20.58791084215045, train_acc = 0.9554028877503493\n",
      "test Acc 0.9408752327746741:\n",
      "3th- epoch: 62, train_loss = 20.50134553387761, train_acc = 0.9554028877503493\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 63, train_loss = 20.427858263254166, train_acc = 0.9554028877503493\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 64, train_loss = 20.362238571047783, train_acc = 0.955519329296693\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 65, train_loss = 20.302680127322674, train_acc = 0.9552864462040056\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 66, train_loss = 20.222742725163698, train_acc = 0.9557522123893806\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 67, train_loss = 20.16129906475544, train_acc = 0.9558686539357243\n",
      "test Acc 0.9408752327746741:\n",
      "3th- epoch: 68, train_loss = 20.103564079850912, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "3th- epoch: 69, train_loss = 20.0381689555943, train_acc = 0.9558686539357243\n",
      "test Acc 0.9413407821229051:\n",
      "3th- epoch: 70, train_loss = 19.981901958584785, train_acc = 0.9561015370284117\n",
      "test Acc 0.9413407821229051:\n",
      "3th- epoch: 71, train_loss = 19.907304290682077, train_acc = 0.9561015370284117\n",
      "test Acc 0.9418063314711359:\n",
      "3th- epoch: 72, train_loss = 19.850873719900846, train_acc = 0.956450861667443\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 73, train_loss = 19.800075877457857, train_acc = 0.955985095482068\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 74, train_loss = 19.735537964850664, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 75, train_loss = 19.685723941773176, train_acc = 0.956450861667443\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 76, train_loss = 19.628578163683414, train_acc = 0.956450861667443\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 77, train_loss = 19.580700781196356, train_acc = 0.956450861667443\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 78, train_loss = 19.53015934303403, train_acc = 0.9568001863064741\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 79, train_loss = 19.477452889084816, train_acc = 0.9568001863064741\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 80, train_loss = 19.4204411637038, train_acc = 0.9569166278528178\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 81, train_loss = 19.36338303424418, train_acc = 0.9571495109455054\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 82, train_loss = 19.321111671626568, train_acc = 0.9571495109455054\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 83, train_loss = 19.270782807841897, train_acc = 0.9572659524918491\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 84, train_loss = 19.226499788463116, train_acc = 0.9573823940381928\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 85, train_loss = 19.17958927154541, train_acc = 0.9573823940381928\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 86, train_loss = 19.13295959867537, train_acc = 0.9573823940381928\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 87, train_loss = 19.080628311261535, train_acc = 0.9574988355845365\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 88, train_loss = 19.042100064456463, train_acc = 0.9574988355845365\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 89, train_loss = 18.994903028011322, train_acc = 0.9578481602235678\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 90, train_loss = 18.950576834380627, train_acc = 0.9579646017699115\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 91, train_loss = 18.9116437304765, train_acc = 0.9579646017699115\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 92, train_loss = 18.871016403660178, train_acc = 0.9579646017699115\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 93, train_loss = 18.8306285161525, train_acc = 0.9583139264089428\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 94, train_loss = 18.789024651050568, train_acc = 0.9580810433162552\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 95, train_loss = 18.73971239477396, train_acc = 0.9583139264089428\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 96, train_loss = 18.704021029174328, train_acc = 0.9583139264089428\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 97, train_loss = 18.66456109844148, train_acc = 0.9584303679552865\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 98, train_loss = 18.621659385040402, train_acc = 0.9585468095016302\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 99, train_loss = 18.589886965230107, train_acc = 0.9586632510479739\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 100, train_loss = 18.550646513700485, train_acc = 0.9585468095016302\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 101, train_loss = 18.513915883377194, train_acc = 0.9590125756870052\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 102, train_loss = 18.472586594522, train_acc = 0.9591290172333489\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 103, train_loss = 18.445055713877082, train_acc = 0.9591290172333489\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 104, train_loss = 18.399148838594556, train_acc = 0.9591290172333489\n",
      "test Acc 0.9432029795158287:\n",
      "3th- epoch: 105, train_loss = 18.36531902104616, train_acc = 0.9591290172333489\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 106, train_loss = 18.334138860926032, train_acc = 0.9592454587796926\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 107, train_loss = 18.299676610156894, train_acc = 0.95947834187238\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 108, train_loss = 18.256212880834937, train_acc = 0.95947834187238\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 109, train_loss = 18.22636391222477, train_acc = 0.9597112249650676\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 110, train_loss = 18.199952693656087, train_acc = 0.9598276665114113\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 111, train_loss = 18.160929827019572, train_acc = 0.9598276665114113\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 112, train_loss = 18.134866738691926, train_acc = 0.9598276665114113\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 113, train_loss = 18.097835205495358, train_acc = 0.9598276665114113\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 114, train_loss = 18.067599954083562, train_acc = 0.9598276665114113\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 115, train_loss = 18.036940975114703, train_acc = 0.9598276665114113\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 116, train_loss = 18.00502703525126, train_acc = 0.959944108057755\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 117, train_loss = 17.978509517386556, train_acc = 0.9600605496040987\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 118, train_loss = 17.947246143594384, train_acc = 0.959944108057755\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 119, train_loss = 17.917308466508985, train_acc = 0.959944108057755\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 120, train_loss = 17.890776539221406, train_acc = 0.9598276665114113\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 121, train_loss = 17.865660650655627, train_acc = 0.9600605496040987\n",
      "test Acc 0.9436685288640596:\n",
      "3th- epoch: 122, train_loss = 17.830025017261505, train_acc = 0.9598276665114113\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 123, train_loss = 17.793344423174858, train_acc = 0.959944108057755\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 124, train_loss = 17.770854646340013, train_acc = 0.9600605496040987\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 125, train_loss = 17.74270035326481, train_acc = 0.9600605496040987\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 126, train_loss = 17.718633582815528, train_acc = 0.959944108057755\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 127, train_loss = 17.701091391965747, train_acc = 0.9600605496040987\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 128, train_loss = 17.673386735841632, train_acc = 0.96040987424313\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 129, train_loss = 17.643551662564278, train_acc = 0.96040987424313\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 130, train_loss = 17.618244176730514, train_acc = 0.96040987424313\n",
      "test Acc 0.9445996275605214:\n",
      "3th- epoch: 131, train_loss = 17.597848726436496, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "3th- epoch: 132, train_loss = 17.569626085460186, train_acc = 0.9606427573358174\n",
      "test Acc 0.9445996275605214:\n",
      "3th- epoch: 133, train_loss = 17.54466616921127, train_acc = 0.9605263157894737\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 134, train_loss = 17.521245313808322, train_acc = 0.9606427573358174\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 135, train_loss = 17.493434919044375, train_acc = 0.9607591988821611\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 136, train_loss = 17.469176165759563, train_acc = 0.9608756404285049\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 137, train_loss = 17.435987228527665, train_acc = 0.9611085235211924\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 138, train_loss = 17.41686550527811, train_acc = 0.9609920819748486\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 139, train_loss = 17.38673655129969, train_acc = 0.9612249650675361\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 140, train_loss = 17.372618732973933, train_acc = 0.9611085235211924\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 141, train_loss = 17.341351492330432, train_acc = 0.9613414066138798\n",
      "test Acc 0.9459962756052142:\n",
      "3th- epoch: 142, train_loss = 17.326374620199203, train_acc = 0.9613414066138798\n",
      "test Acc 0.9450651769087524:\n",
      "3th- epoch: 143, train_loss = 17.297516860067844, train_acc = 0.9614578481602236\n",
      "test Acc 0.9459962756052142:\n",
      "3th- epoch: 144, train_loss = 17.277586417272687, train_acc = 0.9614578481602236\n",
      "test Acc 0.9459962756052142:\n",
      "3th- epoch: 145, train_loss = 17.254112305119634, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 146, train_loss = 17.2278124243021, train_acc = 0.9614578481602236\n",
      "test Acc 0.9459962756052142:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 147, train_loss = 17.207624100148678, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 148, train_loss = 17.193420777097344, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 149, train_loss = 17.16484414227307, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 150, train_loss = 17.146300675347447, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "3th- epoch: 151, train_loss = 17.11153689585626, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 152, train_loss = 17.100823648273945, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "3th- epoch: 153, train_loss = 17.074683183804154, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "3th- epoch: 154, train_loss = 17.05058477073908, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "3th- epoch: 155, train_loss = 17.039342744275928, train_acc = 0.9620400558919422\n",
      "test Acc 0.9455307262569832:\n",
      "3th- epoch: 156, train_loss = 17.016626795753837, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "3th- epoch: 157, train_loss = 16.994406463578343, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "3th- epoch: 158, train_loss = 16.976954413577914, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 159, train_loss = 16.94559622555971, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 160, train_loss = 16.940568717196584, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 161, train_loss = 16.922586925327778, train_acc = 0.9630880298090359\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 162, train_loss = 16.889418249949813, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 163, train_loss = 16.872780553996563, train_acc = 0.9628551467163484\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 164, train_loss = 16.856818100437522, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 165, train_loss = 16.836829544976354, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 166, train_loss = 16.812101939693093, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 167, train_loss = 16.796453336253762, train_acc = 0.9632044713553796\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 168, train_loss = 16.77638299576938, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 169, train_loss = 16.759754583239555, train_acc = 0.9632044713553796\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 170, train_loss = 16.746990099549294, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 171, train_loss = 16.728734323754907, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 172, train_loss = 16.707444071769714, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 173, train_loss = 16.691426826640964, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 174, train_loss = 16.66444404423237, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 175, train_loss = 16.651050614193082, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 176, train_loss = 16.64129345305264, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 177, train_loss = 16.61751421354711, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "3th- epoch: 178, train_loss = 16.600538047030568, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 179, train_loss = 16.58120959252119, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 180, train_loss = 16.567775085568428, train_acc = 0.9637866790870983\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 181, train_loss = 16.548856735229492, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 182, train_loss = 16.53478587977588, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 183, train_loss = 16.5060335341841, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 184, train_loss = 16.50375205092132, train_acc = 0.9637866790870983\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 185, train_loss = 16.47758117504418, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 186, train_loss = 16.461888901889324, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 187, train_loss = 16.44482813216746, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 188, train_loss = 16.433945195749402, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 189, train_loss = 16.42091449536383, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 190, train_loss = 16.40252192504704, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 191, train_loss = 16.38761601038277, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 192, train_loss = 16.367422381415963, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 193, train_loss = 16.344650654122233, train_acc = 0.9641360037261295\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 194, train_loss = 16.33782430179417, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 195, train_loss = 16.323441883549094, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 196, train_loss = 16.305028788745403, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 197, train_loss = 16.29633167386055, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 198, train_loss = 16.276807295158505, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 199, train_loss = 16.25932183302939, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 200, train_loss = 16.249161353334785, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 201, train_loss = 16.230707300826907, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 202, train_loss = 16.217522958293557, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 203, train_loss = 16.205553537234664, train_acc = 0.9644853283651607\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 204, train_loss = 16.19602088443935, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 205, train_loss = 16.174821197986603, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 206, train_loss = 16.15974249690771, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 207, train_loss = 16.150776172056794, train_acc = 0.9644853283651607\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 208, train_loss = 16.1300225649029, train_acc = 0.9646017699115044\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 209, train_loss = 16.122237069532275, train_acc = 0.9646017699115044\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 210, train_loss = 16.115187272429466, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 211, train_loss = 16.0973350526765, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 212, train_loss = 16.07688948791474, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 213, train_loss = 16.06667015235871, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 214, train_loss = 16.05216092336923, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 215, train_loss = 16.03653979767114, train_acc = 0.9644853283651607\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 216, train_loss = 16.017528804950416, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 217, train_loss = 16.009817640297115, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 218, train_loss = 15.998156082816422, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 219, train_loss = 15.985431785695255, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 220, train_loss = 15.970394018106163, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 221, train_loss = 15.9564927816391, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 222, train_loss = 15.943526841700077, train_acc = 0.9646017699115044\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 223, train_loss = 15.930321316234767, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 224, train_loss = 15.921639576554298, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 225, train_loss = 15.912437990307808, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 226, train_loss = 15.902393181808293, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 227, train_loss = 15.884142587892711, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 228, train_loss = 15.878596554510295, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 229, train_loss = 15.858454356901348, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 230, train_loss = 15.842824664898217, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 231, train_loss = 15.844444200396538, train_acc = 0.9650675360968793\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 232, train_loss = 15.817253584973514, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 233, train_loss = 15.81013269443065, train_acc = 0.9650675360968793\n",
      "test Acc 0.9473929236499069:\n",
      "3th- epoch: 234, train_loss = 15.796692100353539, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 235, train_loss = 15.789075195789337, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 236, train_loss = 15.772674339823425, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 237, train_loss = 15.765515665523708, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 238, train_loss = 15.75588636379689, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 239, train_loss = 15.742564879357815, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 240, train_loss = 15.725486789830029, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 241, train_loss = 15.70709229260683, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 242, train_loss = 15.697556170634925, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 243, train_loss = 15.689773459918797, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 244, train_loss = 15.67320054024458, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 245, train_loss = 15.662807941436768, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 246, train_loss = 15.654685780405998, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 247, train_loss = 15.645268936641514, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 248, train_loss = 15.623001764528453, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 249, train_loss = 15.616862828843296, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 250, train_loss = 15.605111877433956, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 251, train_loss = 15.598491609096527, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 252, train_loss = 15.586379396729171, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 253, train_loss = 15.579268229193985, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 254, train_loss = 15.565396949648857, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 255, train_loss = 15.555001961998641, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 256, train_loss = 15.54352403152734, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 257, train_loss = 15.534649883396924, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 258, train_loss = 15.518882337026298, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 259, train_loss = 15.510274454951286, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 260, train_loss = 15.500046759843826, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 261, train_loss = 15.489383232779801, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 262, train_loss = 15.48168694972992, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 263, train_loss = 15.465684783644974, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 264, train_loss = 15.457593035884202, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 265, train_loss = 15.445469391532242, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 266, train_loss = 15.436628025956452, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 267, train_loss = 15.429043401964009, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 268, train_loss = 15.418717478401959, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 269, train_loss = 15.406683747656643, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 270, train_loss = 15.397136013023555, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 271, train_loss = 15.394183558411896, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 272, train_loss = 15.377761870622635, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 273, train_loss = 15.368039309978485, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 274, train_loss = 15.359364837408066, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 275, train_loss = 15.345220021903515, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 276, train_loss = 15.335293333046138, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 277, train_loss = 15.32679859828204, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 278, train_loss = 15.318824904970825, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 279, train_loss = 15.307415182702243, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 280, train_loss = 15.303598766215146, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 281, train_loss = 15.29002910386771, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 282, train_loss = 15.286389385350049, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 283, train_loss = 15.270621967501938, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 284, train_loss = 15.267777393572032, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 285, train_loss = 15.254874671809375, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 286, train_loss = 15.247515752911568, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 287, train_loss = 15.230325723998249, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 288, train_loss = 15.222966658882797, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 289, train_loss = 15.217904065735638, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 290, train_loss = 15.20073204766959, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 291, train_loss = 15.203607740812004, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 292, train_loss = 15.190804307349026, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 293, train_loss = 15.182439993135631, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 294, train_loss = 15.173635114915669, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 295, train_loss = 15.159267033450305, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 296, train_loss = 15.153619240038097, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 297, train_loss = 15.146068987436593, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 298, train_loss = 15.135366514325142, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 299, train_loss = 15.124909073114395, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 300, train_loss = 15.116426748223603, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 301, train_loss = 15.109538336284459, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 302, train_loss = 15.103071088902652, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 303, train_loss = 15.098965686745942, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 304, train_loss = 15.086336421780288, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 305, train_loss = 15.079872258007526, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 306, train_loss = 15.072331639938056, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 307, train_loss = 15.064095136709511, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 308, train_loss = 15.054117016494274, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 309, train_loss = 15.04513808619231, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 310, train_loss = 15.037486811168492, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 311, train_loss = 15.027983486652374, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 312, train_loss = 15.019044262357056, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 313, train_loss = 15.010951776988804, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "3th- epoch: 314, train_loss = 15.003300267271698, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 315, train_loss = 14.993008281104267, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 316, train_loss = 14.985669719986618, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 317, train_loss = 14.980918325483799, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 318, train_loss = 14.96876771748066, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 319, train_loss = 14.96926414500922, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 320, train_loss = 14.956505077891052, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 321, train_loss = 14.949010592885315, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 322, train_loss = 14.941090050153434, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 323, train_loss = 14.931877235881984, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 324, train_loss = 14.923079024069011, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 325, train_loss = 14.919530945830047, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 326, train_loss = 14.90794510114938, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 327, train_loss = 14.901339799165726, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 328, train_loss = 14.894059759564698, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 329, train_loss = 14.883430361747742, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 330, train_loss = 14.872265850193799, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 331, train_loss = 14.86755893100053, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 332, train_loss = 14.860604989342391, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 333, train_loss = 14.850235973484814, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 334, train_loss = 14.843722705729306, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 335, train_loss = 14.836958982050419, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 336, train_loss = 14.833300183527172, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 337, train_loss = 14.821944072842598, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 338, train_loss = 14.814534559845924, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 339, train_loss = 14.80250536929816, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 340, train_loss = 14.798712931573391, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 341, train_loss = 14.788958515040576, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 342, train_loss = 14.781900738365948, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 343, train_loss = 14.776805418543518, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 344, train_loss = 14.765904381871223, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 345, train_loss = 14.76716875564307, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 346, train_loss = 14.757874284870923, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 347, train_loss = 14.748103986494243, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 348, train_loss = 14.738995966501534, train_acc = 0.9671634839310667\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 349, train_loss = 14.73279882222414, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 350, train_loss = 14.72410009521991, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 351, train_loss = 14.722755901515484, train_acc = 0.9671634839310667\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 352, train_loss = 14.7080093966797, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 353, train_loss = 14.70421910751611, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 354, train_loss = 14.698612608015537, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 355, train_loss = 14.688593280501664, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 356, train_loss = 14.682476726360619, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 357, train_loss = 14.677472663111985, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 358, train_loss = 14.671273169107735, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 359, train_loss = 14.662007063627243, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 360, train_loss = 14.655784852802753, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 361, train_loss = 14.648640878498554, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 362, train_loss = 14.640588596463203, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 363, train_loss = 14.63343929219991, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 364, train_loss = 14.627514536492527, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 365, train_loss = 14.624213472008705, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 366, train_loss = 14.616942006163299, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 367, train_loss = 14.609465238638222, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 368, train_loss = 14.605617016553879, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "3th- epoch: 369, train_loss = 14.598828258924186, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 370, train_loss = 14.585465726442635, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 371, train_loss = 14.584428603760898, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 372, train_loss = 14.576672717928886, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 373, train_loss = 14.572047446854413, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 374, train_loss = 14.56095905881375, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 375, train_loss = 14.55700274836272, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 376, train_loss = 14.551107215695083, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 377, train_loss = 14.546920265071094, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 378, train_loss = 14.534969161264598, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 379, train_loss = 14.528545019216835, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 380, train_loss = 14.52288914192468, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 381, train_loss = 14.520364257507026, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 382, train_loss = 14.511401417665184, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 383, train_loss = 14.504792533814907, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 384, train_loss = 14.503370028920472, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 385, train_loss = 14.492626396007836, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 386, train_loss = 14.487181301228702, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 387, train_loss = 14.477563058026135, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 388, train_loss = 14.471525910310447, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 389, train_loss = 14.466833052225411, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 390, train_loss = 14.459562760777771, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 391, train_loss = 14.45210865419358, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 392, train_loss = 14.45436691492796, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 393, train_loss = 14.440938405692577, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 394, train_loss = 14.435583760030568, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 395, train_loss = 14.430836739949882, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 396, train_loss = 14.424139914102852, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 397, train_loss = 14.419767846353352, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 398, train_loss = 14.422405108809471, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 399, train_loss = 14.411217644810677, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 400, train_loss = 14.402476583607495, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 401, train_loss = 14.394815501756966, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 402, train_loss = 14.38764959294349, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 403, train_loss = 14.38109480869025, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 404, train_loss = 14.379915530793369, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 405, train_loss = 14.373644806444645, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 406, train_loss = 14.367806333117187, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 407, train_loss = 14.359178294427693, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 408, train_loss = 14.351571631617844, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 409, train_loss = 14.353410311043262, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 410, train_loss = 14.347010520286858, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 411, train_loss = 14.34462159126997, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 412, train_loss = 14.336250488646328, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 413, train_loss = 14.331152439117432, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 414, train_loss = 14.320817030966282, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 415, train_loss = 14.312961121089756, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 416, train_loss = 14.310766756534576, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 417, train_loss = 14.304881925694644, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 418, train_loss = 14.303116112947464, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 419, train_loss = 14.291963753290474, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 420, train_loss = 14.28641467075795, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 421, train_loss = 14.278690946288407, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 422, train_loss = 14.282371573150158, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 423, train_loss = 14.272216282784939, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 424, train_loss = 14.267976142466068, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 425, train_loss = 14.255868211388588, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 426, train_loss = 14.248811220284551, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 427, train_loss = 14.24097404628992, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 428, train_loss = 14.235308890696615, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 429, train_loss = 14.235195355955511, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 430, train_loss = 14.221548055764288, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 431, train_loss = 14.21799731766805, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 432, train_loss = 14.214316117111593, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 433, train_loss = 14.21006952226162, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 434, train_loss = 14.201455866452307, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 435, train_loss = 14.198392351623625, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 436, train_loss = 14.190335427876562, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 437, train_loss = 14.192221666220576, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 438, train_loss = 14.176029448863119, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 439, train_loss = 14.18037865543738, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 440, train_loss = 14.170401521027088, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 441, train_loss = 14.169160068035126, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 442, train_loss = 14.16223219037056, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 443, train_loss = 14.156579608563334, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 444, train_loss = 14.150016814470291, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 445, train_loss = 14.14616251224652, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 446, train_loss = 14.139765759464353, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 447, train_loss = 14.134732271078974, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 448, train_loss = 14.129677583929151, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 449, train_loss = 14.126035551074892, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 450, train_loss = 14.125455806497484, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 451, train_loss = 14.114192301873118, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 452, train_loss = 14.11435999488458, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 453, train_loss = 14.10849317908287, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 454, train_loss = 14.099932707846165, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 455, train_loss = 14.099738011602312, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 456, train_loss = 14.091402927879244, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 457, train_loss = 14.08755757426843, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 458, train_loss = 14.078005532268435, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 459, train_loss = 14.07756024831906, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 460, train_loss = 14.07406983524561, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 461, train_loss = 14.067283978220075, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 462, train_loss = 14.060711724217981, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 463, train_loss = 14.06025402015075, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 464, train_loss = 14.054128281772137, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 465, train_loss = 14.047075456473976, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 466, train_loss = 14.044457318726927, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 467, train_loss = 14.042070914059877, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 468, train_loss = 14.035869053099304, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 469, train_loss = 14.031891725957394, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 470, train_loss = 14.025796612259, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 471, train_loss = 14.021131763700396, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 472, train_loss = 14.019807533826679, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 473, train_loss = 14.011320100631565, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 474, train_loss = 14.010445849504322, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 475, train_loss = 14.004429838154465, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 476, train_loss = 14.001300243195146, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 477, train_loss = 13.995136780198663, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 478, train_loss = 13.990228342358023, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 479, train_loss = 13.987477386835963, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 480, train_loss = 13.98282060911879, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 481, train_loss = 13.97802513325587, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 482, train_loss = 13.97244280949235, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 483, train_loss = 13.970174377318472, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 484, train_loss = 13.963510824833065, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 485, train_loss = 13.960120605770499, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 486, train_loss = 13.951554073486477, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 487, train_loss = 13.953473895788193, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 488, train_loss = 13.944222477730364, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 489, train_loss = 13.941614754498005, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 490, train_loss = 13.939370127860457, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 491, train_loss = 13.933287640567869, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 492, train_loss = 13.931100610643625, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 493, train_loss = 13.925692424178123, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 494, train_loss = 13.922098618000746, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 495, train_loss = 13.915395809803158, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 496, train_loss = 13.914328248705715, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 497, train_loss = 13.907589573413134, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 498, train_loss = 13.9060268253088, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "3th- epoch: 499, train_loss = 13.899849650915712, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▎                                                                 | 3/30 [27:07<4:04:10, 542.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "4th- epoch: 0, train_loss = 133.66366842389107, train_acc = 0.7392873777363763\n",
      "test Acc 0.835195530726257:\n",
      "4th- epoch: 1, train_loss = 61.14858815073967, train_acc = 0.8745924545877969\n",
      "test Acc 0.8891992551210428:\n",
      "4th- epoch: 2, train_loss = 51.14849931001663, train_acc = 0.8970656730321379\n",
      "test Acc 0.9008379888268156:\n",
      "4th- epoch: 3, train_loss = 45.9944751560688, train_acc = 0.9049836981835119\n",
      "test Acc 0.9078212290502793:\n",
      "4th- epoch: 4, train_loss = 42.66969057917595, train_acc = 0.911504424778761\n",
      "test Acc 0.9124767225325885:\n",
      "4th- epoch: 5, train_loss = 40.21695948392153, train_acc = 0.916394969725198\n",
      "test Acc 0.9157355679702048:\n",
      "4th- epoch: 6, train_loss = 38.29320531338453, train_acc = 0.9191895668374476\n",
      "test Acc 0.9175977653631285:\n",
      "4th- epoch: 7, train_loss = 36.73666272312403, train_acc = 0.9210526315789473\n",
      "test Acc 0.9189944134078212:\n",
      "4th- epoch: 8, train_loss = 35.37634951621294, train_acc = 0.9237307871448532\n",
      "test Acc 0.9208566108007449:\n",
      "4th- epoch: 9, train_loss = 34.193630404770374, train_acc = 0.9251280857009782\n",
      "test Acc 0.9231843575418994:\n",
      "4th- epoch: 10, train_loss = 33.15648251026869, train_acc = 0.9272240335351654\n",
      "test Acc 0.9241154562383612:\n",
      "4th- epoch: 11, train_loss = 32.233569629490376, train_acc = 0.9296693060083838\n",
      "test Acc 0.9250465549348231:\n",
      "4th- epoch: 12, train_loss = 31.43563424050808, train_acc = 0.9310666045645086\n",
      "test Acc 0.9259776536312849:\n",
      "4th- epoch: 13, train_loss = 30.719672068953514, train_acc = 0.9318816953889147\n",
      "test Acc 0.9273743016759777:\n",
      "4th- epoch: 14, train_loss = 30.065905310213566, train_acc = 0.933977643223102\n",
      "test Acc 0.9283054003724395:\n",
      "4th- epoch: 15, train_loss = 29.459308110177517, train_acc = 0.935258500232883\n",
      "test Acc 0.9283054003724395:\n",
      "4th- epoch: 16, train_loss = 28.909480929374695, train_acc = 0.9363064741499767\n",
      "test Acc 0.930633147113594:\n",
      "4th- epoch: 17, train_loss = 28.403991650789976, train_acc = 0.9374708896134141\n",
      "test Acc 0.9315642458100558:\n",
      "4th- epoch: 18, train_loss = 27.921155281364918, train_acc = 0.9389846297158826\n",
      "test Acc 0.9329608938547486:\n",
      "4th- epoch: 19, train_loss = 27.49340694025159, train_acc = 0.9399161620866325\n",
      "test Acc 0.9329608938547486:\n",
      "4th- epoch: 20, train_loss = 27.089108254760504, train_acc = 0.9413134606427573\n",
      "test Acc 0.9334264432029795:\n",
      "4th- epoch: 21, train_loss = 26.719622809439898, train_acc = 0.9424778761061947\n",
      "test Acc 0.9338919925512105:\n",
      "4th- epoch: 22, train_loss = 26.37796362116933, train_acc = 0.9422449930135072\n",
      "test Acc 0.9338919925512105:\n",
      "4th- epoch: 23, train_loss = 26.056348156183958, train_acc = 0.9435258500232883\n",
      "test Acc 0.9348230912476723:\n",
      "4th- epoch: 24, train_loss = 25.769278429448605, train_acc = 0.9438751746623195\n",
      "test Acc 0.9348230912476723:\n",
      "4th- epoch: 25, train_loss = 25.49508187547326, train_acc = 0.9450395901257569\n",
      "test Acc 0.9352886405959032:\n",
      "4th- epoch: 26, train_loss = 25.224120978266, train_acc = 0.9457382394038193\n",
      "test Acc 0.9366852886405959:\n",
      "4th- epoch: 27, train_loss = 24.98044090718031, train_acc = 0.946320447135538\n",
      "test Acc 0.9371508379888268:\n",
      "4th- epoch: 28, train_loss = 24.7565037868917, train_acc = 0.9465533302282254\n",
      "test Acc 0.9380819366852886:\n",
      "4th- epoch: 29, train_loss = 24.531771935522556, train_acc = 0.9469026548672567\n",
      "test Acc 0.9385474860335196:\n",
      "4th- epoch: 30, train_loss = 24.336571510881186, train_acc = 0.9474848625989754\n",
      "test Acc 0.9390130353817505:\n",
      "4th- epoch: 31, train_loss = 24.13298273831606, train_acc = 0.9478341872380065\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 32, train_loss = 23.9390078894794, train_acc = 0.9484163949697252\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 33, train_loss = 23.75708742812276, train_acc = 0.9492314857941313\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 34, train_loss = 23.579352248460054, train_acc = 0.9495808104331626\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 35, train_loss = 23.41798620671034, train_acc = 0.94981369352585\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 36, train_loss = 23.259480983018875, train_acc = 0.9503959012575687\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 37, train_loss = 23.110079936683178, train_acc = 0.9506287843502562\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 38, train_loss = 22.963587172329426, train_acc = 0.9508616674429436\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 39, train_loss = 22.817323610186577, train_acc = 0.9513274336283186\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 40, train_loss = 22.682794101536274, train_acc = 0.951560316721006\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 41, train_loss = 22.555744640529156, train_acc = 0.952026082906381\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 42, train_loss = 22.424681667238474, train_acc = 0.9519096413600373\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 43, train_loss = 22.29301266744733, train_acc = 0.9523754075454122\n",
      "test Acc 0.9390130353817505:\n",
      "4th- epoch: 44, train_loss = 22.18247988447547, train_acc = 0.9527247321844434\n",
      "test Acc 0.9390130353817505:\n",
      "4th- epoch: 45, train_loss = 22.068080581724644, train_acc = 0.9530740568234746\n",
      "test Acc 0.9390130353817505:\n",
      "4th- epoch: 46, train_loss = 21.962878666818142, train_acc = 0.9530740568234746\n",
      "test Acc 0.9390130353817505:\n",
      "4th- epoch: 47, train_loss = 21.83957924693823, train_acc = 0.9534233814625058\n",
      "test Acc 0.9390130353817505:\n",
      "4th- epoch: 48, train_loss = 21.748723287135363, train_acc = 0.9534233814625058\n",
      "test Acc 0.9390130353817505:\n",
      "4th- epoch: 49, train_loss = 21.61998158507049, train_acc = 0.9538891476478808\n",
      "test Acc 0.9390130353817505:\n",
      "4th- epoch: 50, train_loss = 21.52066889218986, train_acc = 0.9540055891942245\n",
      "test Acc 0.9390130353817505:\n",
      "4th- epoch: 51, train_loss = 21.426855804398656, train_acc = 0.9538891476478808\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 52, train_loss = 21.333143597468734, train_acc = 0.9538891476478808\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 53, train_loss = 21.246504187583923, train_acc = 0.9541220307405682\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 54, train_loss = 21.160419596359134, train_acc = 0.9543549138332557\n",
      "test Acc 0.9394785847299814:\n",
      "4th- epoch: 55, train_loss = 21.078552635386586, train_acc = 0.9547042384722869\n",
      "test Acc 0.9399441340782123:\n",
      "4th- epoch: 56, train_loss = 21.001016119495034, train_acc = 0.9548206800186306\n",
      "test Acc 0.9399441340782123:\n",
      "4th- epoch: 57, train_loss = 20.91354256682098, train_acc = 0.9549371215649743\n",
      "test Acc 0.9399441340782123:\n",
      "4th- epoch: 58, train_loss = 20.842687459662557, train_acc = 0.9551700046576619\n",
      "test Acc 0.9399441340782123:\n",
      "4th- epoch: 59, train_loss = 20.760743441060185, train_acc = 0.9552864462040056\n",
      "test Acc 0.9399441340782123:\n",
      "4th- epoch: 60, train_loss = 20.708526875823736, train_acc = 0.9554028877503493\n",
      "test Acc 0.9399441340782123:\n",
      "4th- epoch: 61, train_loss = 20.608594166114926, train_acc = 0.9556357708430367\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 62, train_loss = 20.544926693663, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 63, train_loss = 20.473128525540233, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "4th- epoch: 64, train_loss = 20.40944752469659, train_acc = 0.9558686539357243\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 65, train_loss = 20.337427590042353, train_acc = 0.9558686539357243\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 66, train_loss = 20.280042631551623, train_acc = 0.9561015370284117\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 67, train_loss = 20.201396806165576, train_acc = 0.9558686539357243\n",
      "test Acc 0.9422718808193669:\n",
      "4th- epoch: 68, train_loss = 20.14796895906329, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 69, train_loss = 20.076058842241764, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 70, train_loss = 20.019671197980642, train_acc = 0.9558686539357243\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 71, train_loss = 19.954211169853806, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 72, train_loss = 19.887739477679133, train_acc = 0.9563344201210993\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 73, train_loss = 19.834170846268535, train_acc = 0.9561015370284117\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 74, train_loss = 19.771117340773344, train_acc = 0.9561015370284117\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 75, train_loss = 19.713349057361484, train_acc = 0.9561015370284117\n",
      "test Acc 0.9427374301675978:\n",
      "4th- epoch: 76, train_loss = 19.657111519947648, train_acc = 0.956450861667443\n",
      "test Acc 0.9418063314711359:\n",
      "4th- epoch: 77, train_loss = 19.60028942115605, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "4th- epoch: 78, train_loss = 19.562633907422423, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "4th- epoch: 79, train_loss = 19.5075221080333, train_acc = 0.9568001863064741\n",
      "test Acc 0.9427374301675978:\n",
      "4th- epoch: 80, train_loss = 19.44906890578568, train_acc = 0.9569166278528178\n",
      "test Acc 0.9427374301675978:\n",
      "4th- epoch: 81, train_loss = 19.407191019505262, train_acc = 0.9568001863064741\n",
      "test Acc 0.9427374301675978:\n",
      "4th- epoch: 82, train_loss = 19.347395127639174, train_acc = 0.9569166278528178\n",
      "test Acc 0.9432029795158287:\n",
      "4th- epoch: 83, train_loss = 19.302393063902855, train_acc = 0.9570330693991617\n",
      "test Acc 0.9432029795158287:\n",
      "4th- epoch: 84, train_loss = 19.245948515832424, train_acc = 0.9572659524918491\n",
      "test Acc 0.9432029795158287:\n",
      "4th- epoch: 85, train_loss = 19.210902266204357, train_acc = 0.9571495109455054\n",
      "test Acc 0.9432029795158287:\n",
      "4th- epoch: 86, train_loss = 19.166832929477096, train_acc = 0.9571495109455054\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 87, train_loss = 19.118167312815785, train_acc = 0.9570330693991617\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 88, train_loss = 19.067162653431296, train_acc = 0.9573823940381928\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 89, train_loss = 19.027440702542663, train_acc = 0.9574988355845365\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 90, train_loss = 18.984956331551075, train_acc = 0.9576152771308803\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 91, train_loss = 18.945555156096816, train_acc = 0.9576152771308803\n",
      "test Acc 0.9432029795158287:\n",
      "4th- epoch: 92, train_loss = 18.89595941081643, train_acc = 0.9577317186772241\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 93, train_loss = 18.857491394504905, train_acc = 0.9578481602235678\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 94, train_loss = 18.812312653288245, train_acc = 0.9579646017699115\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 95, train_loss = 18.770572053268552, train_acc = 0.9579646017699115\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 96, train_loss = 18.736283050850034, train_acc = 0.9577317186772241\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 97, train_loss = 18.697935642674565, train_acc = 0.9581974848625989\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 98, train_loss = 18.66123061813414, train_acc = 0.9583139264089428\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 99, train_loss = 18.617385463789105, train_acc = 0.9586632510479739\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 100, train_loss = 18.583696389570832, train_acc = 0.9586632510479739\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 101, train_loss = 18.548917723819613, train_acc = 0.9590125756870052\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 102, train_loss = 18.516498554497957, train_acc = 0.9593619003260363\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 103, train_loss = 18.471175702288747, train_acc = 0.95947834187238\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 104, train_loss = 18.437941337004304, train_acc = 0.95947834187238\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 105, train_loss = 18.409237748011947, train_acc = 0.95947834187238\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 106, train_loss = 18.36140434630215, train_acc = 0.9595947834187238\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 107, train_loss = 18.32867816835642, train_acc = 0.9597112249650676\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 108, train_loss = 18.29603340663016, train_acc = 0.9597112249650676\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 109, train_loss = 18.26253224350512, train_acc = 0.9597112249650676\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 110, train_loss = 18.226006431505084, train_acc = 0.9598276665114113\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 111, train_loss = 18.201784739270806, train_acc = 0.959944108057755\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 112, train_loss = 18.15845081396401, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 113, train_loss = 18.120105708017945, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 114, train_loss = 18.097556425258517, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 115, train_loss = 18.067235991358757, train_acc = 0.96040987424313\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 116, train_loss = 18.03972470574081, train_acc = 0.96040987424313\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 117, train_loss = 18.002524746581912, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 118, train_loss = 17.975426519289613, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "4th- epoch: 119, train_loss = 17.95239262469113, train_acc = 0.9606427573358174\n",
      "test Acc 0.9445996275605214:\n",
      "4th- epoch: 120, train_loss = 17.92108727991581, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 121, train_loss = 17.893957624211907, train_acc = 0.9606427573358174\n",
      "test Acc 0.9445996275605214:\n",
      "4th- epoch: 122, train_loss = 17.847495786845684, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "4th- epoch: 123, train_loss = 17.816872665658593, train_acc = 0.9606427573358174\n",
      "test Acc 0.9445996275605214:\n",
      "4th- epoch: 124, train_loss = 17.788873311132193, train_acc = 0.9606427573358174\n",
      "test Acc 0.9445996275605214:\n",
      "4th- epoch: 125, train_loss = 17.766861146315932, train_acc = 0.9607591988821611\n",
      "test Acc 0.9450651769087524:\n",
      "4th- epoch: 126, train_loss = 17.744897484779358, train_acc = 0.9607591988821611\n",
      "test Acc 0.9450651769087524:\n",
      "4th- epoch: 127, train_loss = 17.715438570827246, train_acc = 0.9606427573358174\n",
      "test Acc 0.9450651769087524:\n",
      "4th- epoch: 128, train_loss = 17.694157237187028, train_acc = 0.9606427573358174\n",
      "test Acc 0.9450651769087524:\n",
      "4th- epoch: 129, train_loss = 17.64951497875154, train_acc = 0.9606427573358174\n",
      "test Acc 0.9450651769087524:\n",
      "4th- epoch: 130, train_loss = 17.61810760013759, train_acc = 0.9609920819748486\n",
      "test Acc 0.9450651769087524:\n",
      "4th- epoch: 131, train_loss = 17.600721025839448, train_acc = 0.9608756404285049\n",
      "test Acc 0.9450651769087524:\n",
      "4th- epoch: 132, train_loss = 17.568670818582177, train_acc = 0.9608756404285049\n",
      "test Acc 0.9450651769087524:\n",
      "4th- epoch: 133, train_loss = 17.557208644226193, train_acc = 0.9609920819748486\n",
      "test Acc 0.9450651769087524:\n",
      "4th- epoch: 134, train_loss = 17.518932212144136, train_acc = 0.9609920819748486\n",
      "test Acc 0.9450651769087524:\n",
      "4th- epoch: 135, train_loss = 17.491590406745672, train_acc = 0.9611085235211924\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 136, train_loss = 17.46558796428144, train_acc = 0.9611085235211924\n",
      "test Acc 0.9455307262569832:\n",
      "4th- epoch: 137, train_loss = 17.464598758146167, train_acc = 0.9612249650675361\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 138, train_loss = 17.42136169783771, train_acc = 0.9609920819748486\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 139, train_loss = 17.389843011274934, train_acc = 0.9613414066138798\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 140, train_loss = 17.36530185304582, train_acc = 0.9612249650675361\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 141, train_loss = 17.341056106612086, train_acc = 0.9613414066138798\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 142, train_loss = 17.324003886431456, train_acc = 0.9613414066138798\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 143, train_loss = 17.29800047725439, train_acc = 0.9614578481602236\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 144, train_loss = 17.273287711665034, train_acc = 0.9614578481602236\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 145, train_loss = 17.252657061442733, train_acc = 0.9614578481602236\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 146, train_loss = 17.22307817824185, train_acc = 0.961690731252911\n",
      "test Acc 0.9459962756052142:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 147, train_loss = 17.199761105701327, train_acc = 0.961690731252911\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 148, train_loss = 17.182656725868583, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 149, train_loss = 17.16750002466142, train_acc = 0.961690731252911\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 150, train_loss = 17.13502380810678, train_acc = 0.961690731252911\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 151, train_loss = 17.117489647120237, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 152, train_loss = 17.097417825832963, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 153, train_loss = 17.065124599263072, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 154, train_loss = 17.052919385954738, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 155, train_loss = 17.030444918200374, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 156, train_loss = 17.0051275100559, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 157, train_loss = 16.98921231366694, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 158, train_loss = 16.96734826080501, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 159, train_loss = 16.94305051676929, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 160, train_loss = 16.924846647307277, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 161, train_loss = 16.91108574718237, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 162, train_loss = 16.88480642437935, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 163, train_loss = 16.865310641005635, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 164, train_loss = 16.846699059009552, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 165, train_loss = 16.833039255812764, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 166, train_loss = 16.806700997054577, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 167, train_loss = 16.786387369036674, train_acc = 0.962156497438286\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 168, train_loss = 16.778456134721637, train_acc = 0.962156497438286\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 169, train_loss = 16.756343744695187, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 170, train_loss = 16.728460907936096, train_acc = 0.9627387051700047\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 171, train_loss = 16.71715553291142, train_acc = 0.9627387051700047\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 172, train_loss = 16.70047504454851, train_acc = 0.9627387051700047\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 173, train_loss = 16.68060232512653, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 174, train_loss = 16.662941528484225, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 175, train_loss = 16.644321961328387, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 176, train_loss = 16.636125272139907, train_acc = 0.9627387051700047\n",
      "test Acc 0.9459962756052142:\n",
      "4th- epoch: 177, train_loss = 16.61118802241981, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 178, train_loss = 16.599055154249072, train_acc = 0.9629715882626921\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 179, train_loss = 16.57894448004663, train_acc = 0.9630880298090359\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 180, train_loss = 16.559768319129944, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 181, train_loss = 16.560443809255958, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 182, train_loss = 16.536879239603877, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 183, train_loss = 16.512671515345573, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 184, train_loss = 16.491623878479004, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 185, train_loss = 16.481896245852113, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 186, train_loss = 16.471291556954384, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 187, train_loss = 16.44954897277057, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 188, train_loss = 16.432681752368808, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 189, train_loss = 16.419802682474256, train_acc = 0.9634373544480671\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 190, train_loss = 16.394806019961834, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 191, train_loss = 16.38590973801911, train_acc = 0.963903120633442\n",
      "test Acc 0.9464618249534451:\n",
      "4th- epoch: 192, train_loss = 16.367299661040306, train_acc = 0.9641360037261295\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 193, train_loss = 16.353971214964986, train_acc = 0.9637866790870983\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 194, train_loss = 16.33828321285546, train_acc = 0.9641360037261295\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 195, train_loss = 16.322575023397803, train_acc = 0.9640195621797858\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 196, train_loss = 16.307393588125706, train_acc = 0.9640195621797858\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 197, train_loss = 16.295378103852272, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 198, train_loss = 16.274788478389382, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 199, train_loss = 16.25922129303217, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 200, train_loss = 16.240298194810748, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 201, train_loss = 16.224120631814003, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 202, train_loss = 16.215424029156566, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 203, train_loss = 16.196611339226365, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 204, train_loss = 16.184151908382773, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 205, train_loss = 16.166895516216755, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "4th- epoch: 206, train_loss = 16.15829967148602, train_acc = 0.9644853283651607\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 207, train_loss = 16.142448181286454, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 208, train_loss = 16.125569889321923, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 209, train_loss = 16.115086652338505, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "4th- epoch: 210, train_loss = 16.09778426028788, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "4th- epoch: 211, train_loss = 16.08298941142857, train_acc = 0.9648346530041919\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 212, train_loss = 16.072737015783787, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "4th- epoch: 213, train_loss = 16.054888665676117, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "4th- epoch: 214, train_loss = 16.041942412965, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 215, train_loss = 16.03497496712953, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "4th- epoch: 216, train_loss = 16.016033242456615, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 217, train_loss = 16.008464912883937, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "4th- epoch: 218, train_loss = 15.990486848168075, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "4th- epoch: 219, train_loss = 15.981253065168858, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "4th- epoch: 220, train_loss = 15.966905067674816, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 221, train_loss = 15.950741295702755, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 222, train_loss = 15.947581395506859, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 223, train_loss = 15.924028009176254, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "4th- epoch: 224, train_loss = 15.911966259591281, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 225, train_loss = 15.903061042539775, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 226, train_loss = 15.889805766753852, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 227, train_loss = 15.881184193305671, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 228, train_loss = 15.87223581969738, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "4th- epoch: 229, train_loss = 15.86565063893795, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 230, train_loss = 15.833219394087791, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 231, train_loss = 15.834094959311187, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 232, train_loss = 15.819504749961197, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 233, train_loss = 15.80908913910389, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 234, train_loss = 15.796950320713222, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 235, train_loss = 15.792078289203346, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 236, train_loss = 15.778802193701267, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 237, train_loss = 15.764853763394058, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 238, train_loss = 15.74697059392929, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 239, train_loss = 15.740927641279995, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 240, train_loss = 15.726310983300209, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 241, train_loss = 15.716815042309463, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 242, train_loss = 15.703446281142533, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 243, train_loss = 15.693276117555797, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 244, train_loss = 15.683781054802239, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 245, train_loss = 15.666179154999554, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 246, train_loss = 15.651478533633053, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 247, train_loss = 15.65098187327385, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 248, train_loss = 15.639744418673217, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 249, train_loss = 15.630770188756287, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 250, train_loss = 15.61400185059756, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 251, train_loss = 15.603979763574898, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 252, train_loss = 15.597397327423096, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 253, train_loss = 15.581565233878791, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 254, train_loss = 15.572458229959011, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 255, train_loss = 15.558614161796868, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 256, train_loss = 15.549659815616906, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 257, train_loss = 15.539993050508201, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 258, train_loss = 15.53278976213187, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 259, train_loss = 15.520325891673565, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 260, train_loss = 15.515486642718315, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 261, train_loss = 15.502107759006321, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 262, train_loss = 15.494659361429513, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 263, train_loss = 15.480070288293064, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 264, train_loss = 15.474686632864177, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 265, train_loss = 15.460521739907563, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 266, train_loss = 15.448261882178485, train_acc = 0.9658826269212856\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 267, train_loss = 15.444527658633888, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 268, train_loss = 15.431309439241886, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 269, train_loss = 15.423250620253384, train_acc = 0.9659990684676293\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 270, train_loss = 15.4169140458107, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 271, train_loss = 15.401960666291416, train_acc = 0.9662319515603167\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 272, train_loss = 15.39829144347459, train_acc = 0.966115510013973\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 273, train_loss = 15.395588758401573, train_acc = 0.9663483931066604\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 274, train_loss = 15.371232104487717, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 275, train_loss = 15.36966096330434, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 276, train_loss = 15.36628853250295, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 277, train_loss = 15.341110889799893, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 278, train_loss = 15.332943501882255, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 279, train_loss = 15.331511874683201, train_acc = 0.9664648346530041\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 280, train_loss = 15.313290623016655, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 281, train_loss = 15.307165605016053, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 282, train_loss = 15.295053742825985, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 283, train_loss = 15.298888531513512, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 284, train_loss = 15.277459874749184, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 285, train_loss = 15.268690285272896, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 286, train_loss = 15.254308007657528, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 287, train_loss = 15.253351199440658, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 288, train_loss = 15.241545123048127, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 289, train_loss = 15.235092230141163, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 290, train_loss = 15.222036275081336, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 291, train_loss = 15.212371587753296, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 292, train_loss = 15.207605980336666, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 293, train_loss = 15.195489677600563, train_acc = 0.966581276199348\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 294, train_loss = 15.190248151309788, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 295, train_loss = 15.178587269969285, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 296, train_loss = 15.17069724202156, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 297, train_loss = 15.159249517135322, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 298, train_loss = 15.158097644336522, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 299, train_loss = 15.14405029732734, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 300, train_loss = 15.141666191630065, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 301, train_loss = 15.1302245631814, train_acc = 0.9666977177456917\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 302, train_loss = 15.12825268227607, train_acc = 0.9668141592920354\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 303, train_loss = 15.114187642931938, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 304, train_loss = 15.098023449070752, train_acc = 0.9669306008383791\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 305, train_loss = 15.09775600861758, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 306, train_loss = 15.08240608125925, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 307, train_loss = 15.072522054426372, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 308, train_loss = 15.070783299393952, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 309, train_loss = 15.058095228858292, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 310, train_loss = 15.053372845053673, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 311, train_loss = 15.039362850598991, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 312, train_loss = 15.038097088225186, train_acc = 0.9671634839310667\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 313, train_loss = 15.024846668355167, train_acc = 0.9671634839310667\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 314, train_loss = 15.017904117703438, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 315, train_loss = 15.013275179080665, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 316, train_loss = 15.002209921367466, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 317, train_loss = 14.99816866684705, train_acc = 0.9671634839310667\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 318, train_loss = 14.989202943630517, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 319, train_loss = 14.98171439487487, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 320, train_loss = 14.971730425953865, train_acc = 0.9671634839310667\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 321, train_loss = 14.964068624190986, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 322, train_loss = 14.96056865900755, train_acc = 0.9671634839310667\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 323, train_loss = 14.946580518968403, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 324, train_loss = 14.945935065858066, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 325, train_loss = 14.93437457550317, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 326, train_loss = 14.925831099040806, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 327, train_loss = 14.923498943448067, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 328, train_loss = 14.9073541238904, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 329, train_loss = 14.906507824547589, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 330, train_loss = 14.889322879724205, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 331, train_loss = 14.897575587034225, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 332, train_loss = 14.881181687116623, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 333, train_loss = 14.878243411891162, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 334, train_loss = 14.870340269990265, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 335, train_loss = 14.85850906651467, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 336, train_loss = 14.847253873944283, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 337, train_loss = 14.846294164657593, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 338, train_loss = 14.836244168691337, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 339, train_loss = 14.828531327657402, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 340, train_loss = 14.824241166003048, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 341, train_loss = 14.814707480370998, train_acc = 0.9679785747554728\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 342, train_loss = 14.816564385779202, train_acc = 0.9679785747554728\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 343, train_loss = 14.805325855500996, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 344, train_loss = 14.795203070156276, train_acc = 0.9679785747554728\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 345, train_loss = 14.792280872352421, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 346, train_loss = 14.786304742097855, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 347, train_loss = 14.772911208681762, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 348, train_loss = 14.765464630909264, train_acc = 0.9683278993945039\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 349, train_loss = 14.768232491798699, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 350, train_loss = 14.752579507417977, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 351, train_loss = 14.747075433842838, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 352, train_loss = 14.742371276021004, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 353, train_loss = 14.747833860106766, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 354, train_loss = 14.724047109484673, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 355, train_loss = 14.724268890917301, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 356, train_loss = 14.709800809621811, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 357, train_loss = 14.70485683530569, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 358, train_loss = 14.698889697901905, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 359, train_loss = 14.711156281642616, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 360, train_loss = 14.697717030532658, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 361, train_loss = 14.682222433388233, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 362, train_loss = 14.677312932908535, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 363, train_loss = 14.683109824545681, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 364, train_loss = 14.661636049859226, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 365, train_loss = 14.660184214822948, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 366, train_loss = 14.655802105553448, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 367, train_loss = 14.639125262387097, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 368, train_loss = 14.633340142667294, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 369, train_loss = 14.63355206232518, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 370, train_loss = 14.626539248041809, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 371, train_loss = 14.618361346423626, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 372, train_loss = 14.60481075476855, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 373, train_loss = 14.601561531424522, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 374, train_loss = 14.59833337366581, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 375, train_loss = 14.595811414532363, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 376, train_loss = 14.58969012927264, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 377, train_loss = 14.575898009352386, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 378, train_loss = 14.56980097759515, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 379, train_loss = 14.566113886423409, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 380, train_loss = 14.564059031195939, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 381, train_loss = 14.558448043651879, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 382, train_loss = 14.54609890282154, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 383, train_loss = 14.550859262235463, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 384, train_loss = 14.539728273637593, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 385, train_loss = 14.530913300812244, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 386, train_loss = 14.52503027766943, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 387, train_loss = 14.523165044374764, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 388, train_loss = 14.517849889583886, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 389, train_loss = 14.505843753926456, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 390, train_loss = 14.501883323304355, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 391, train_loss = 14.493158881552517, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 392, train_loss = 14.49134510755539, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 393, train_loss = 14.487392569892108, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 394, train_loss = 14.478325520642102, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 395, train_loss = 14.473780679516494, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 396, train_loss = 14.461634452454746, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 397, train_loss = 14.463578537106514, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 398, train_loss = 14.455666676163673, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 399, train_loss = 14.45519397687167, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 400, train_loss = 14.450335527770221, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 401, train_loss = 14.434891052544117, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 402, train_loss = 14.432606766931713, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 403, train_loss = 14.423006284050643, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 404, train_loss = 14.421403172425926, train_acc = 0.9687936655798789\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 405, train_loss = 14.412922349758446, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 406, train_loss = 14.411744877696037, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 407, train_loss = 14.400146807543933, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 408, train_loss = 14.386312070302665, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 409, train_loss = 14.387266293168068, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 410, train_loss = 14.382074284367263, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 411, train_loss = 14.375171800144017, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 412, train_loss = 14.367810850031674, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 413, train_loss = 14.357852297835052, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 414, train_loss = 14.357894790358841, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 415, train_loss = 14.352975897490978, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 416, train_loss = 14.347204635851085, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 417, train_loss = 14.34308061003685, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 418, train_loss = 14.335228036157787, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 419, train_loss = 14.330676118843257, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 420, train_loss = 14.330504894256592, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 421, train_loss = 14.328079077415168, train_acc = 0.9689101071262226\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 422, train_loss = 14.323931057937443, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 423, train_loss = 14.309393185190856, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 424, train_loss = 14.300804148428142, train_acc = 0.9689101071262226\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 425, train_loss = 14.302289647050202, train_acc = 0.9689101071262226\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 426, train_loss = 14.295018431730568, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 427, train_loss = 14.288647249341011, train_acc = 0.9689101071262226\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 428, train_loss = 14.287442577071488, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 429, train_loss = 14.277976398356259, train_acc = 0.9689101071262226\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 430, train_loss = 14.268716469407082, train_acc = 0.9689101071262226\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 431, train_loss = 14.265526160597801, train_acc = 0.9689101071262226\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 432, train_loss = 14.262341725639999, train_acc = 0.9689101071262226\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 433, train_loss = 14.264376185834408, train_acc = 0.9689101071262226\n",
      "test Acc 0.9511173184357542:\n",
      "4th- epoch: 434, train_loss = 14.251505102030933, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 435, train_loss = 14.247818410396576, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 436, train_loss = 14.24375290889293, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 437, train_loss = 14.238766509108245, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 438, train_loss = 14.235645602457225, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 439, train_loss = 14.22695763874799, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 440, train_loss = 14.216477219946682, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 441, train_loss = 14.216900306753814, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 442, train_loss = 14.2057902244851, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 443, train_loss = 14.20178646594286, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 444, train_loss = 14.207080368883908, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 445, train_loss = 14.197924030013382, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 446, train_loss = 14.193804780952632, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 447, train_loss = 14.186047594062984, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 448, train_loss = 14.177645231131464, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 449, train_loss = 14.174020655453205, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 450, train_loss = 14.167880117893219, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 451, train_loss = 14.166562899947166, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 452, train_loss = 14.16089078783989, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 453, train_loss = 14.156286823097616, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 454, train_loss = 14.150283254683018, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 455, train_loss = 14.143311090767384, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 456, train_loss = 14.148860369808972, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 457, train_loss = 14.142664504703134, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 458, train_loss = 14.143579924944788, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 459, train_loss = 14.12577565247193, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 460, train_loss = 14.11650488525629, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 461, train_loss = 14.119597539305687, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 462, train_loss = 14.118341485504061, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 463, train_loss = 14.112521248403937, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 464, train_loss = 14.10277210175991, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 465, train_loss = 14.092005225364119, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 466, train_loss = 14.088931560516357, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 467, train_loss = 14.09057585382834, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 468, train_loss = 14.083277724683285, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 469, train_loss = 14.075514152646065, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 470, train_loss = 14.070173474494368, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 471, train_loss = 14.064435680862516, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 472, train_loss = 14.076588255818933, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 473, train_loss = 14.069751307368279, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 474, train_loss = 14.05648354953155, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 475, train_loss = 14.054459636565298, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 476, train_loss = 14.043785691261292, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 477, train_loss = 14.047959017101675, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 478, train_loss = 14.034661310259253, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 479, train_loss = 14.031748833600432, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 480, train_loss = 14.02544229477644, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 481, train_loss = 14.03249691426754, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 482, train_loss = 14.022471772972494, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 483, train_loss = 14.020967202726752, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 484, train_loss = 14.02124967193231, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 485, train_loss = 14.01872981339693, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 486, train_loss = 14.003345794975758, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 487, train_loss = 14.00431103259325, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 488, train_loss = 14.007499577943236, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 489, train_loss = 13.998645927757025, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 490, train_loss = 13.979719899594784, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 491, train_loss = 13.98950046300888, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 492, train_loss = 13.980953713413328, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 493, train_loss = 13.987736736889929, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 494, train_loss = 13.980006279889494, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 495, train_loss = 13.9777792817913, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 496, train_loss = 13.963829091284424, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 497, train_loss = 13.957190471235663, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 498, train_loss = 13.961532209068537, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "4th- epoch: 499, train_loss = 13.955379359424114, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████▋                                                               | 4/30 [36:09<3:54:59, 542.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "5th- epoch: 0, train_loss = 137.19349732995033, train_acc = 0.7261294829995343\n",
      "test Acc 0.8086592178770949:\n",
      "5th- epoch: 1, train_loss = 60.105453476309776, train_acc = 0.8678388448998603\n",
      "test Acc 0.8589385474860335:\n",
      "5th- epoch: 2, train_loss = 49.83126164972782, train_acc = 0.893921751280857\n",
      "test Acc 0.883147113594041:\n",
      "5th- epoch: 3, train_loss = 44.522868663072586, train_acc = 0.9066138798323242\n",
      "test Acc 0.9022346368715084:\n",
      "5th- epoch: 4, train_loss = 41.15682389587164, train_acc = 0.9138332557056358\n",
      "test Acc 0.9120111731843575:\n",
      "5th- epoch: 5, train_loss = 38.684550531208515, train_acc = 0.9183744760130415\n",
      "test Acc 0.914804469273743:\n",
      "5th- epoch: 6, train_loss = 36.747710801661015, train_acc = 0.9234979040521658\n",
      "test Acc 0.9185288640595903:\n",
      "5th- epoch: 7, train_loss = 35.1820202767849, train_acc = 0.9272240335351654\n",
      "test Acc 0.9203910614525139:\n",
      "5th- epoch: 8, train_loss = 33.97850101441145, train_acc = 0.9292035398230089\n",
      "test Acc 0.9231843575418994:\n",
      "5th- epoch: 9, train_loss = 32.88100417330861, train_acc = 0.9301350721937587\n",
      "test Acc 0.9259776536312849:\n",
      "5th- epoch: 10, train_loss = 31.94025194644928, train_acc = 0.9330461108523521\n",
      "test Acc 0.9273743016759777:\n",
      "5th- epoch: 11, train_loss = 31.085551276803017, train_acc = 0.9346762925011645\n",
      "test Acc 0.9283054003724395:\n",
      "5th- epoch: 12, train_loss = 30.39982234314084, train_acc = 0.9358407079646017\n",
      "test Acc 0.9301675977653632:\n",
      "5th- epoch: 13, train_loss = 29.736826848238707, train_acc = 0.9356078248719143\n",
      "test Acc 0.9301675977653632:\n",
      "5th- epoch: 14, train_loss = 29.132353499531746, train_acc = 0.9374708896134141\n",
      "test Acc 0.930633147113594:\n",
      "5th- epoch: 15, train_loss = 28.607825111597776, train_acc = 0.9385188635305077\n",
      "test Acc 0.9315642458100558:\n",
      "5th- epoch: 16, train_loss = 28.11012416705489, train_acc = 0.9393339543549138\n",
      "test Acc 0.9320297951582868:\n",
      "5th- epoch: 17, train_loss = 27.674572195857763, train_acc = 0.9399161620866325\n",
      "test Acc 0.9320297951582868:\n",
      "5th- epoch: 18, train_loss = 27.281648479402065, train_acc = 0.9410805775500699\n",
      "test Acc 0.9329608938547486:\n",
      "5th- epoch: 19, train_loss = 26.89278308674693, train_acc = 0.9427107591988821\n",
      "test Acc 0.9329608938547486:\n",
      "5th- epoch: 20, train_loss = 26.502332348376513, train_acc = 0.9430600838379134\n",
      "test Acc 0.9338919925512105:\n",
      "5th- epoch: 21, train_loss = 26.20117073878646, train_acc = 0.9436422915696321\n",
      "test Acc 0.9343575418994413:\n",
      "5th- epoch: 22, train_loss = 25.88145438581705, train_acc = 0.9445738239403819\n",
      "test Acc 0.9343575418994413:\n",
      "5th- epoch: 23, train_loss = 25.589929811656475, train_acc = 0.9446902654867256\n",
      "test Acc 0.9343575418994413:\n",
      "5th- epoch: 24, train_loss = 25.282954208552837, train_acc = 0.9455053563111319\n",
      "test Acc 0.9338919925512105:\n",
      "5th- epoch: 25, train_loss = 25.013001032173634, train_acc = 0.9459711224965067\n",
      "test Acc 0.9343575418994413:\n",
      "5th- epoch: 26, train_loss = 24.77251462265849, train_acc = 0.9466697717745691\n",
      "test Acc 0.9348230912476723:\n",
      "5th- epoch: 27, train_loss = 24.54344765469432, train_acc = 0.9469026548672567\n",
      "test Acc 0.9352886405959032:\n",
      "5th- epoch: 28, train_loss = 24.333543580025434, train_acc = 0.948067070330694\n",
      "test Acc 0.9352886405959032:\n",
      "5th- epoch: 29, train_loss = 24.116388089954853, train_acc = 0.9481835118770378\n",
      "test Acc 0.9352886405959032:\n",
      "5th- epoch: 30, train_loss = 23.918130479753017, train_acc = 0.9486492780624126\n",
      "test Acc 0.9357541899441341:\n",
      "5th- epoch: 31, train_loss = 23.712257731705904, train_acc = 0.9488821611551002\n",
      "test Acc 0.9357541899441341:\n",
      "5th- epoch: 32, train_loss = 23.546821910887957, train_acc = 0.9491150442477876\n",
      "test Acc 0.9357541899441341:\n",
      "5th- epoch: 33, train_loss = 23.37399222329259, train_acc = 0.9492314857941313\n",
      "test Acc 0.9357541899441341:\n",
      "5th- epoch: 34, train_loss = 23.202427566051483, train_acc = 0.9492314857941313\n",
      "test Acc 0.9357541899441341:\n",
      "5th- epoch: 35, train_loss = 23.04586955718696, train_acc = 0.9495808104331626\n",
      "test Acc 0.9357541899441341:\n",
      "5th- epoch: 36, train_loss = 22.905482154339552, train_acc = 0.94981369352585\n",
      "test Acc 0.9357541899441341:\n",
      "5th- epoch: 37, train_loss = 22.729147439822555, train_acc = 0.9503959012575687\n",
      "test Acc 0.9371508379888268:\n",
      "5th- epoch: 38, train_loss = 22.589742116630077, train_acc = 0.9508616674429436\n",
      "test Acc 0.9366852886405959:\n",
      "5th- epoch: 39, train_loss = 22.44025012291968, train_acc = 0.9510945505356311\n",
      "test Acc 0.9376163873370578:\n",
      "5th- epoch: 40, train_loss = 22.3028861656785, train_acc = 0.9510945505356311\n",
      "test Acc 0.9380819366852886:\n",
      "5th- epoch: 41, train_loss = 22.181332720443606, train_acc = 0.9513274336283186\n",
      "test Acc 0.9376163873370578:\n",
      "5th- epoch: 42, train_loss = 22.057610671967268, train_acc = 0.9514438751746623\n",
      "test Acc 0.9385474860335196:\n",
      "5th- epoch: 43, train_loss = 21.923932895064354, train_acc = 0.9516767582673498\n",
      "test Acc 0.9385474860335196:\n",
      "5th- epoch: 44, train_loss = 21.832953341305256, train_acc = 0.9517931998136935\n",
      "test Acc 0.9385474860335196:\n",
      "5th- epoch: 45, train_loss = 21.72167111746967, train_acc = 0.9522589659990685\n",
      "test Acc 0.9385474860335196:\n",
      "5th- epoch: 46, train_loss = 21.620342936366796, train_acc = 0.9521425244527247\n",
      "test Acc 0.9390130353817505:\n",
      "5th- epoch: 47, train_loss = 21.517299205064774, train_acc = 0.9526082906380997\n",
      "test Acc 0.9390130353817505:\n",
      "5th- epoch: 48, train_loss = 21.410589212551713, train_acc = 0.9526082906380997\n",
      "test Acc 0.9390130353817505:\n",
      "5th- epoch: 49, train_loss = 21.32515037059784, train_acc = 0.9530740568234746\n",
      "test Acc 0.9394785847299814:\n",
      "5th- epoch: 50, train_loss = 21.213712574914098, train_acc = 0.9529576152771309\n",
      "test Acc 0.9394785847299814:\n",
      "5th- epoch: 51, train_loss = 21.110584039241076, train_acc = 0.9531904983698184\n",
      "test Acc 0.9394785847299814:\n",
      "5th- epoch: 52, train_loss = 21.020971613004804, train_acc = 0.9534233814625058\n",
      "test Acc 0.9399441340782123:\n",
      "5th- epoch: 53, train_loss = 20.940896466374397, train_acc = 0.9537727061015371\n",
      "test Acc 0.9399441340782123:\n",
      "5th- epoch: 54, train_loss = 20.83792875893414, train_acc = 0.9540055891942245\n",
      "test Acc 0.9404096834264432:\n",
      "5th- epoch: 55, train_loss = 20.755593856796622, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "5th- epoch: 56, train_loss = 20.672937620431185, train_acc = 0.9541220307405682\n",
      "test Acc 0.9408752327746741:\n",
      "5th- epoch: 57, train_loss = 20.603289688006043, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "5th- epoch: 58, train_loss = 20.51727031171322, train_acc = 0.9547042384722869\n",
      "test Acc 0.9408752327746741:\n",
      "5th- epoch: 59, train_loss = 20.450877021998167, train_acc = 0.9551700046576619\n",
      "test Acc 0.9408752327746741:\n",
      "5th- epoch: 60, train_loss = 20.372076764702797, train_acc = 0.9554028877503493\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 61, train_loss = 20.29258785583079, train_acc = 0.955519329296693\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 62, train_loss = 20.218854557722807, train_acc = 0.9557522123893806\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 63, train_loss = 20.15100151859224, train_acc = 0.955985095482068\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 64, train_loss = 20.07502918317914, train_acc = 0.9558686539357243\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 65, train_loss = 19.999092621728778, train_acc = 0.9561015370284117\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 66, train_loss = 19.940292946994305, train_acc = 0.9562179785747554\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 67, train_loss = 19.878835732117295, train_acc = 0.9568001863064741\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 68, train_loss = 19.816251141950488, train_acc = 0.9568001863064741\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 69, train_loss = 19.749461352825165, train_acc = 0.9570330693991617\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 70, train_loss = 19.705700792372227, train_acc = 0.9573823940381928\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 71, train_loss = 19.634541396051645, train_acc = 0.9572659524918491\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 72, train_loss = 19.57451376132667, train_acc = 0.9576152771308803\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 73, train_loss = 19.51819789968431, train_acc = 0.9576152771308803\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 74, train_loss = 19.47076477855444, train_acc = 0.9577317186772241\n",
      "test Acc 0.9427374301675978:\n",
      "5th- epoch: 75, train_loss = 19.410578740760684, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 76, train_loss = 19.358035819604993, train_acc = 0.9578481602235678\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 77, train_loss = 19.298441000282764, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 78, train_loss = 19.24956000968814, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 79, train_loss = 19.19042849354446, train_acc = 0.9578481602235678\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 80, train_loss = 19.14459776505828, train_acc = 0.9578481602235678\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 81, train_loss = 19.088332066312432, train_acc = 0.9578481602235678\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 82, train_loss = 19.05249591358006, train_acc = 0.9578481602235678\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 83, train_loss = 19.000821018591523, train_acc = 0.9579646017699115\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 84, train_loss = 18.955984538421035, train_acc = 0.9578481602235678\n",
      "test Acc 0.9432029795158287:\n",
      "5th- epoch: 85, train_loss = 18.89799634553492, train_acc = 0.9581974848625989\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 86, train_loss = 18.85916918516159, train_acc = 0.9581974848625989\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 87, train_loss = 18.8203577529639, train_acc = 0.9583139264089428\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 88, train_loss = 18.773832205682993, train_acc = 0.9584303679552865\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 89, train_loss = 18.729833064600825, train_acc = 0.9587796925943176\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 90, train_loss = 18.683666488155723, train_acc = 0.9585468095016302\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 91, train_loss = 18.64434713125229, train_acc = 0.9588961341406614\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 92, train_loss = 18.60916514135897, train_acc = 0.9587796925943176\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 93, train_loss = 18.558568732813, train_acc = 0.9592454587796926\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 94, train_loss = 18.528254413977265, train_acc = 0.9592454587796926\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 95, train_loss = 18.48977731540799, train_acc = 0.9592454587796926\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 96, train_loss = 18.444987321272492, train_acc = 0.9593619003260363\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 97, train_loss = 18.397970555350184, train_acc = 0.9593619003260363\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 98, train_loss = 18.375787414610386, train_acc = 0.9595947834187238\n",
      "test Acc 0.9441340782122905:\n",
      "5th- epoch: 99, train_loss = 18.327111626043916, train_acc = 0.9595947834187238\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 100, train_loss = 18.283937009051442, train_acc = 0.9595947834187238\n",
      "test Acc 0.9441340782122905:\n",
      "5th- epoch: 101, train_loss = 18.248352820053697, train_acc = 0.9597112249650676\n",
      "test Acc 0.9441340782122905:\n",
      "5th- epoch: 102, train_loss = 18.21700230240822, train_acc = 0.9597112249650676\n",
      "test Acc 0.9441340782122905:\n",
      "5th- epoch: 103, train_loss = 18.177403239533305, train_acc = 0.9597112249650676\n",
      "test Acc 0.9441340782122905:\n",
      "5th- epoch: 104, train_loss = 18.135694349184632, train_acc = 0.9597112249650676\n",
      "test Acc 0.9441340782122905:\n",
      "5th- epoch: 105, train_loss = 18.11361145041883, train_acc = 0.959944108057755\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 106, train_loss = 18.076979868113995, train_acc = 0.9601769911504425\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 107, train_loss = 18.03753899410367, train_acc = 0.9602934326967862\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 108, train_loss = 18.0004052631557, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 109, train_loss = 17.97568904608488, train_acc = 0.9602934326967862\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 110, train_loss = 17.937729597091675, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 111, train_loss = 17.91726374439895, train_acc = 0.9606427573358174\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 112, train_loss = 17.871115740388632, train_acc = 0.9607591988821611\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 113, train_loss = 17.857249930500984, train_acc = 0.9608756404285049\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 114, train_loss = 17.810614997521043, train_acc = 0.9611085235211924\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 115, train_loss = 17.779664751142263, train_acc = 0.9612249650675361\n",
      "test Acc 0.9445996275605214:\n",
      "5th- epoch: 116, train_loss = 17.756748486310244, train_acc = 0.9611085235211924\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 117, train_loss = 17.735743338242173, train_acc = 0.9613414066138798\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 118, train_loss = 17.688900880515575, train_acc = 0.9613414066138798\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 119, train_loss = 17.670137936249375, train_acc = 0.9612249650675361\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 120, train_loss = 17.63098701648414, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 121, train_loss = 17.618228131905198, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 122, train_loss = 17.584318138659, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 123, train_loss = 17.547867942601442, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 124, train_loss = 17.526933383196592, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 125, train_loss = 17.497874597087502, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 126, train_loss = 17.46287270076573, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 127, train_loss = 17.453070167452097, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 128, train_loss = 17.4166208114475, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 129, train_loss = 17.386654626578093, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 130, train_loss = 17.35995005071163, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 131, train_loss = 17.33394647575915, train_acc = 0.9619236143455985\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 132, train_loss = 17.30753325484693, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 133, train_loss = 17.286328027024865, train_acc = 0.962156497438286\n",
      "test Acc 0.9455307262569832:\n",
      "5th- epoch: 134, train_loss = 17.262515895068645, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 135, train_loss = 17.238467602059245, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 136, train_loss = 17.22119828686118, train_acc = 0.9627387051700047\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 137, train_loss = 17.1976252887398, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 138, train_loss = 17.17116509564221, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 139, train_loss = 17.142515188083053, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 140, train_loss = 17.119065567851067, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 141, train_loss = 17.101447423920035, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 142, train_loss = 17.07963534258306, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 143, train_loss = 17.06150140054524, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 144, train_loss = 17.035705437883735, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 145, train_loss = 17.022183759137988, train_acc = 0.9628551467163484\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 146, train_loss = 16.992779133841395, train_acc = 0.9630880298090359\n",
      "test Acc 0.9464618249534451:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 147, train_loss = 16.974545545876026, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 148, train_loss = 16.943931927904487, train_acc = 0.9630880298090359\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 149, train_loss = 16.926802469417453, train_acc = 0.9632044713553796\n",
      "test Acc 0.946927374301676:\n",
      "5th- epoch: 150, train_loss = 16.902023872360587, train_acc = 0.9630880298090359\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 151, train_loss = 16.880329970270395, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 152, train_loss = 16.87053775601089, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 153, train_loss = 16.849531641229987, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 154, train_loss = 16.832564247772098, train_acc = 0.9634373544480671\n",
      "test Acc 0.946927374301676:\n",
      "5th- epoch: 155, train_loss = 16.797119177877903, train_acc = 0.9634373544480671\n",
      "test Acc 0.946927374301676:\n",
      "5th- epoch: 156, train_loss = 16.785774754360318, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "5th- epoch: 157, train_loss = 16.776929758489132, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 158, train_loss = 16.75040158070624, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "5th- epoch: 159, train_loss = 16.727902876213193, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "5th- epoch: 160, train_loss = 16.714625703170896, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "5th- epoch: 161, train_loss = 16.702574890106916, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "5th- epoch: 162, train_loss = 16.680682003498077, train_acc = 0.9637866790870983\n",
      "test Acc 0.946927374301676:\n",
      "5th- epoch: 163, train_loss = 16.652381574735045, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 164, train_loss = 16.64250552840531, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 165, train_loss = 16.62040733359754, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 166, train_loss = 16.60344078578055, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 167, train_loss = 16.584390576928854, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 168, train_loss = 16.56358135677874, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 169, train_loss = 16.549234753474593, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 170, train_loss = 16.530303929001093, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 171, train_loss = 16.51777402497828, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 172, train_loss = 16.49861617386341, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 173, train_loss = 16.479071279987693, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 174, train_loss = 16.46352435834706, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 175, train_loss = 16.443081023171544, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 176, train_loss = 16.433574495837092, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 177, train_loss = 16.412524478510022, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 178, train_loss = 16.391377804800868, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 179, train_loss = 16.37758463807404, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 180, train_loss = 16.36247450299561, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 181, train_loss = 16.348033169284463, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 182, train_loss = 16.335258247330785, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 183, train_loss = 16.323924342170358, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 184, train_loss = 16.302299048751593, train_acc = 0.9646017699115044\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 185, train_loss = 16.280660497024655, train_acc = 0.9646017699115044\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 186, train_loss = 16.267978344112635, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 187, train_loss = 16.259157206863165, train_acc = 0.9646017699115044\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 188, train_loss = 16.24116691760719, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 189, train_loss = 16.2229543607682, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 190, train_loss = 16.20920497365296, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 191, train_loss = 16.18346813134849, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 192, train_loss = 16.178688472136855, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 193, train_loss = 16.162458822131157, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 194, train_loss = 16.152974855154753, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 195, train_loss = 16.139819890260696, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 196, train_loss = 16.12168779410422, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 197, train_loss = 16.109046755358577, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 198, train_loss = 16.09192162193358, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 199, train_loss = 16.077013447880745, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 200, train_loss = 16.063365902751684, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 201, train_loss = 16.053822096437216, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 202, train_loss = 16.039116697385907, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 203, train_loss = 16.020498058758676, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 204, train_loss = 16.011106424964964, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 205, train_loss = 15.998830623924732, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 206, train_loss = 15.988825475797057, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 207, train_loss = 15.96282992232591, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 208, train_loss = 15.96116650942713, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 209, train_loss = 15.940817053429782, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 210, train_loss = 15.93196762073785, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 211, train_loss = 15.923981110565364, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 212, train_loss = 15.905990338884294, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 213, train_loss = 15.887988825328648, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 214, train_loss = 15.874836511909962, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 215, train_loss = 15.870705343782902, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 216, train_loss = 15.854700258933008, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 217, train_loss = 15.846558189950883, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 218, train_loss = 15.83523883484304, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 219, train_loss = 15.819465932436287, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 220, train_loss = 15.802326214499772, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 221, train_loss = 15.789828329347074, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 222, train_loss = 15.783412070944905, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 223, train_loss = 15.773659424856305, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 224, train_loss = 15.757136006839573, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 225, train_loss = 15.754359514452517, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 226, train_loss = 15.738103793933988, train_acc = 0.9654168607359106\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 227, train_loss = 15.72398512903601, train_acc = 0.965649743828598\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 228, train_loss = 15.708838704042137, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "5th- epoch: 229, train_loss = 15.698186688125134, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 230, train_loss = 15.68587234430015, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 231, train_loss = 15.67797417473048, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 232, train_loss = 15.667688526213169, train_acc = 0.9654168607359106\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 233, train_loss = 15.65080870501697, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 234, train_loss = 15.639263654127717, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 235, train_loss = 15.62995492387563, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 236, train_loss = 15.623774254694581, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 237, train_loss = 15.601946703158319, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 238, train_loss = 15.598735368810594, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 239, train_loss = 15.590149796567857, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 240, train_loss = 15.579047355800867, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 241, train_loss = 15.557005863636732, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 242, train_loss = 15.547030239365995, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 243, train_loss = 15.540359776467085, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 244, train_loss = 15.522944994270802, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 245, train_loss = 15.523557856678963, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 246, train_loss = 15.504983324557543, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 247, train_loss = 15.495367751456797, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 248, train_loss = 15.481312329880893, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 249, train_loss = 15.472397881560028, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 250, train_loss = 15.46755647007376, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 251, train_loss = 15.451555254869163, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 252, train_loss = 15.441589120775461, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 253, train_loss = 15.431123022921383, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 254, train_loss = 15.41807194519788, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 255, train_loss = 15.415928614325821, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 256, train_loss = 15.402498948387802, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 257, train_loss = 15.392639092169702, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 258, train_loss = 15.387299147434533, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 259, train_loss = 15.369117197580636, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 260, train_loss = 15.361329833976924, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 261, train_loss = 15.35388354305178, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 262, train_loss = 15.345901187509298, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 263, train_loss = 15.340577892959118, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 264, train_loss = 15.33073925320059, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 265, train_loss = 15.320070303976536, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 266, train_loss = 15.306849199347198, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 267, train_loss = 15.301424288190901, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 268, train_loss = 15.291171661578119, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 269, train_loss = 15.28015835955739, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 270, train_loss = 15.2681331532076, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 271, train_loss = 15.261402647010982, train_acc = 0.966581276199348\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 272, train_loss = 15.247876898385584, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 273, train_loss = 15.242947491817176, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 274, train_loss = 15.229618698358536, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 275, train_loss = 15.219590849243104, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 276, train_loss = 15.219065769575536, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 277, train_loss = 15.205319271422923, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 278, train_loss = 15.203067615628242, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 279, train_loss = 15.186665075831115, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 280, train_loss = 15.184455052949488, train_acc = 0.9669306008383791\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 281, train_loss = 15.173371586948633, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 282, train_loss = 15.163874520920217, train_acc = 0.9669306008383791\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 283, train_loss = 15.160334850661457, train_acc = 0.9669306008383791\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 284, train_loss = 15.14419365581125, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 285, train_loss = 15.135610728524625, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 286, train_loss = 15.12579807266593, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 287, train_loss = 15.116036075167358, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 288, train_loss = 15.109699752181768, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 289, train_loss = 15.105364850722253, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 290, train_loss = 15.092762562446296, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 291, train_loss = 15.087308400310576, train_acc = 0.9669306008383791\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 292, train_loss = 15.067686482332647, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 293, train_loss = 15.075995570980012, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 294, train_loss = 15.057754636742175, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 295, train_loss = 15.053971198387444, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 296, train_loss = 15.047016746364534, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 297, train_loss = 15.038898926228285, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 298, train_loss = 15.03156923968345, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 299, train_loss = 15.026088569313288, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 300, train_loss = 15.009218376129866, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 301, train_loss = 15.005808825604618, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 302, train_loss = 14.996310472488403, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 303, train_loss = 14.985980346798897, train_acc = 0.9672799254774104\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 304, train_loss = 14.975183228962123, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 305, train_loss = 14.969957667402923, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 306, train_loss = 14.969016983173788, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 307, train_loss = 14.957602961920202, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 308, train_loss = 14.95172629877925, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 309, train_loss = 14.945576720871031, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 310, train_loss = 14.937682434916496, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 311, train_loss = 14.928321413695812, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 312, train_loss = 14.925305069424212, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 313, train_loss = 14.908774440176785, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 314, train_loss = 14.904603015631437, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 315, train_loss = 14.900454200804234, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 316, train_loss = 14.894163987599313, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 317, train_loss = 14.878565459512174, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 318, train_loss = 14.86997148860246, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 319, train_loss = 14.873700175434351, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 320, train_loss = 14.858300455845892, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 321, train_loss = 14.85021331999451, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 322, train_loss = 14.844115912914276, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 323, train_loss = 14.835194735787809, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 324, train_loss = 14.831816694699228, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 325, train_loss = 14.825992718338966, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 326, train_loss = 14.817105795256793, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 327, train_loss = 14.806948736310005, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 328, train_loss = 14.799143961630762, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 329, train_loss = 14.79404254630208, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 330, train_loss = 14.78579453472048, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 331, train_loss = 14.78049132693559, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 332, train_loss = 14.769260436296463, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 333, train_loss = 14.764026160351932, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 334, train_loss = 14.760032325983047, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 335, train_loss = 14.758225780911744, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 336, train_loss = 14.748496734537184, train_acc = 0.9678621332091291\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 337, train_loss = 14.746035852469504, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 338, train_loss = 14.732997141778469, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 339, train_loss = 14.725671873427927, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 340, train_loss = 14.722848516888916, train_acc = 0.9676292501164415\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 341, train_loss = 14.712189533747733, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 342, train_loss = 14.710430142469704, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 343, train_loss = 14.696217644959688, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 344, train_loss = 14.686791972257197, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 345, train_loss = 14.68124280963093, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 346, train_loss = 14.675662324763834, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 347, train_loss = 14.670232441276312, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 348, train_loss = 14.659528107382357, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 349, train_loss = 14.660089124925435, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 350, train_loss = 14.648802577517927, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 351, train_loss = 14.646837740205228, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 352, train_loss = 14.639876142144203, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 353, train_loss = 14.629218377172947, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 354, train_loss = 14.627019341103733, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 355, train_loss = 14.620734660886228, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 356, train_loss = 14.615060344338417, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 357, train_loss = 14.605867384932935, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 358, train_loss = 14.603232915513217, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 359, train_loss = 14.594932727515697, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 360, train_loss = 14.5879388442263, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 361, train_loss = 14.583599895238876, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 362, train_loss = 14.575916898436844, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 363, train_loss = 14.572100266814232, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 364, train_loss = 14.564494508318603, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 365, train_loss = 14.558188156224787, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 366, train_loss = 14.55985501036048, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 367, train_loss = 14.543257284909487, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 368, train_loss = 14.542923655360937, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 369, train_loss = 14.532440775074065, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 370, train_loss = 14.53169147670269, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 371, train_loss = 14.519966526888311, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 372, train_loss = 14.5141622684896, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 373, train_loss = 14.510318749584258, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 374, train_loss = 14.505711279809475, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 375, train_loss = 14.500608897767961, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 376, train_loss = 14.498709437437356, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 377, train_loss = 14.49035707488656, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 378, train_loss = 14.48951514530927, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 379, train_loss = 14.474682583473623, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 380, train_loss = 14.472164571285248, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 381, train_loss = 14.470527698285878, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 382, train_loss = 14.46152916084975, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 383, train_loss = 14.450888000428677, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 384, train_loss = 14.446872894652188, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 385, train_loss = 14.438018058426678, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 386, train_loss = 14.43898047413677, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 387, train_loss = 14.432047071866691, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 388, train_loss = 14.421696692705154, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 389, train_loss = 14.426165167242289, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 390, train_loss = 14.423497906886041, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 391, train_loss = 14.40669093746692, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 392, train_loss = 14.403101039119065, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 393, train_loss = 14.401819345541298, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 394, train_loss = 14.394009959883988, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 395, train_loss = 14.390657372772694, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 396, train_loss = 14.386328828521073, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 397, train_loss = 14.374108455143869, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 398, train_loss = 14.37183063197881, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 399, train_loss = 14.36487699393183, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 400, train_loss = 14.357809810899198, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 401, train_loss = 14.357422228902578, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 402, train_loss = 14.349786170758307, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 403, train_loss = 14.343126672320068, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 404, train_loss = 14.341161037795246, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 405, train_loss = 14.33197411801666, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 406, train_loss = 14.324236259795725, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 407, train_loss = 14.317976432852447, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 408, train_loss = 14.312712248414755, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 409, train_loss = 14.307856913655996, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 410, train_loss = 14.304664642550051, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 411, train_loss = 14.30581175070256, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 412, train_loss = 14.298333745449781, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 413, train_loss = 14.289666439406574, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 414, train_loss = 14.286717648152262, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 415, train_loss = 14.276140798814595, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 416, train_loss = 14.265957806259394, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 417, train_loss = 14.264177622739226, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 418, train_loss = 14.269489049911499, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 419, train_loss = 14.257051383610815, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 420, train_loss = 14.252376911230385, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 421, train_loss = 14.243636776693165, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 422, train_loss = 14.239155807998031, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 423, train_loss = 14.233902256935835, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 424, train_loss = 14.230260604526848, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 425, train_loss = 14.231425071600825, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 426, train_loss = 14.222854477819055, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 427, train_loss = 14.221790534909815, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 428, train_loss = 14.21410571038723, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 429, train_loss = 14.210719604045153, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 430, train_loss = 14.201858032494783, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "5th- epoch: 431, train_loss = 14.199676243122667, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 432, train_loss = 14.191554815974087, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 433, train_loss = 14.191495849285275, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 434, train_loss = 14.182081715669483, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 435, train_loss = 14.178605740424246, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 436, train_loss = 14.175538551062346, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 437, train_loss = 14.170912811066955, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 438, train_loss = 14.164779333863407, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 439, train_loss = 14.163781377021223, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 440, train_loss = 14.149077931884676, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 441, train_loss = 14.157878648489714, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 442, train_loss = 14.150204222649336, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 443, train_loss = 14.144497359637171, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 444, train_loss = 14.140299419406801, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 445, train_loss = 14.127679458353668, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 446, train_loss = 14.12582814693451, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 447, train_loss = 14.12855883454904, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 448, train_loss = 14.115735122468323, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 449, train_loss = 14.109738774597645, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 450, train_loss = 14.106512846890837, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 451, train_loss = 14.106723272707313, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 452, train_loss = 14.100948348641396, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 453, train_loss = 14.10176783055067, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 454, train_loss = 14.090835500508547, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 455, train_loss = 14.098032949957997, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 456, train_loss = 14.087068362627178, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 457, train_loss = 14.078654033597559, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 458, train_loss = 14.077552349772304, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 459, train_loss = 14.06926546106115, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 460, train_loss = 14.076614366378635, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 461, train_loss = 14.064731292426586, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 462, train_loss = 14.061514387372881, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 463, train_loss = 14.048464847262949, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 464, train_loss = 14.050688743591309, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 465, train_loss = 14.04761112993583, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 466, train_loss = 14.039652867708355, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 467, train_loss = 14.035481998231262, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 468, train_loss = 14.0310896076262, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 469, train_loss = 14.032013884279877, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 470, train_loss = 14.031163127627224, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 471, train_loss = 14.023113229777664, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 472, train_loss = 14.01187623059377, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 473, train_loss = 14.007635506335646, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 474, train_loss = 14.008017018437386, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 475, train_loss = 14.003013722598553, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 476, train_loss = 13.999583198223263, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 477, train_loss = 13.993798735085875, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 478, train_loss = 13.985932655632496, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 479, train_loss = 13.982119669672102, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 480, train_loss = 13.978477392345667, train_acc = 0.9694923148579413\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 481, train_loss = 13.978220580611378, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 482, train_loss = 13.972066459711641, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 483, train_loss = 13.966129212174565, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 484, train_loss = 13.964874518569559, train_acc = 0.969608756404285\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 485, train_loss = 13.960994452238083, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 486, train_loss = 13.960140691604465, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 487, train_loss = 13.950634092092514, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 488, train_loss = 13.953895103186369, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 489, train_loss = 13.94354431470856, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 490, train_loss = 13.941075274255127, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 491, train_loss = 13.93080972135067, train_acc = 0.9694923148579413\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 492, train_loss = 13.929473506752402, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 493, train_loss = 13.927639655768871, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 494, train_loss = 13.92381101846695, train_acc = 0.969608756404285\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 495, train_loss = 13.915430972818285, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 496, train_loss = 13.91174502670765, train_acc = 0.9694923148579413\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 497, train_loss = 13.913599769119173, train_acc = 0.969608756404285\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 498, train_loss = 13.905690318439156, train_acc = 0.9694923148579413\n",
      "test Acc 0.9497206703910615:\n",
      "5th- epoch: 499, train_loss = 13.90255919098854, train_acc = 0.9694923148579413\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████▏                                                            | 5/30 [45:14<3:46:17, 543.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "6th- epoch: 0, train_loss = 128.24296414852142, train_acc = 0.7494177922682813\n",
      "test Acc 0.8212290502793296:\n",
      "6th- epoch: 1, train_loss = 58.3861091658473, train_acc = 0.8777363763390778\n",
      "test Acc 0.8682495344506518:\n",
      "6th- epoch: 2, train_loss = 48.60183996707201, train_acc = 0.8948532836516069\n",
      "test Acc 0.8845437616387337:\n",
      "6th- epoch: 3, train_loss = 43.74584659188986, train_acc = 0.9051001397298556\n",
      "test Acc 0.898975791433892:\n",
      "6th- epoch: 4, train_loss = 40.56760708242655, train_acc = 0.9112715416860736\n",
      "test Acc 0.9031657355679702:\n",
      "6th- epoch: 5, train_loss = 38.22667954862118, train_acc = 0.915929203539823\n",
      "test Acc 0.9115456238361266:\n",
      "6th- epoch: 6, train_loss = 36.41540186852217, train_acc = 0.9204704238472287\n",
      "test Acc 0.9152700186219739:\n",
      "6th- epoch: 7, train_loss = 35.02932774275541, train_acc = 0.9233814625058221\n",
      "test Acc 0.9199255121042831:\n",
      "6th- epoch: 8, train_loss = 33.77675024420023, train_acc = 0.9254774103400093\n",
      "test Acc 0.9245810055865922:\n",
      "6th- epoch: 9, train_loss = 32.71551375836134, train_acc = 0.9279226828132278\n",
      "test Acc 0.9273743016759777:\n",
      "6th- epoch: 10, train_loss = 31.80547820776701, train_acc = 0.9299021891010713\n",
      "test Acc 0.9278398510242085:\n",
      "6th- epoch: 11, train_loss = 31.03092796355486, train_acc = 0.9316488122962273\n",
      "test Acc 0.9292364990689013:\n",
      "6th- epoch: 12, train_loss = 30.316063784062862, train_acc = 0.9332789939450395\n",
      "test Acc 0.930633147113594:\n",
      "6th- epoch: 13, train_loss = 29.700531750917435, train_acc = 0.9349091755938519\n",
      "test Acc 0.930633147113594:\n",
      "6th- epoch: 14, train_loss = 29.142837055027485, train_acc = 0.9360735910572893\n",
      "test Acc 0.9315642458100558:\n",
      "6th- epoch: 15, train_loss = 28.607475250959396, train_acc = 0.9375873311597578\n",
      "test Acc 0.9324953445065177:\n",
      "6th- epoch: 16, train_loss = 28.146307714283466, train_acc = 0.9389846297158826\n",
      "test Acc 0.9334264432029795:\n",
      "6th- epoch: 17, train_loss = 27.72718185931444, train_acc = 0.9397997205402888\n",
      "test Acc 0.9348230912476723:\n",
      "6th- epoch: 18, train_loss = 27.340016722679138, train_acc = 0.94014904517932\n",
      "test Acc 0.9352886405959032:\n",
      "6th- epoch: 19, train_loss = 26.977937377989292, train_acc = 0.9410805775500699\n",
      "test Acc 0.9352886405959032:\n",
      "6th- epoch: 20, train_loss = 26.633350647985935, train_acc = 0.942361434559851\n",
      "test Acc 0.9357541899441341:\n",
      "6th- epoch: 21, train_loss = 26.31342624872923, train_acc = 0.9430600838379134\n",
      "test Acc 0.936219739292365:\n",
      "6th- epoch: 22, train_loss = 26.00901199877262, train_acc = 0.9430600838379134\n",
      "test Acc 0.9376163873370578:\n",
      "6th- epoch: 23, train_loss = 25.73351164907217, train_acc = 0.9432929669306008\n",
      "test Acc 0.9385474860335196:\n",
      "6th- epoch: 24, train_loss = 25.475061610341072, train_acc = 0.9445738239403819\n",
      "test Acc 0.9390130353817505:\n",
      "6th- epoch: 25, train_loss = 25.211621932685375, train_acc = 0.9451560316721006\n",
      "test Acc 0.9390130353817505:\n",
      "6th- epoch: 26, train_loss = 24.98848322033882, train_acc = 0.9459711224965067\n",
      "test Acc 0.9390130353817505:\n",
      "6th- epoch: 27, train_loss = 24.751173220574856, train_acc = 0.9465533302282254\n",
      "test Acc 0.9390130353817505:\n",
      "6th- epoch: 28, train_loss = 24.548184655606747, train_acc = 0.946786213320913\n",
      "test Acc 0.9390130353817505:\n",
      "6th- epoch: 29, train_loss = 24.347192719578743, train_acc = 0.9472519795062878\n",
      "test Acc 0.9394785847299814:\n",
      "6th- epoch: 30, train_loss = 24.145633552223444, train_acc = 0.9481835118770378\n",
      "test Acc 0.9399441340782123:\n",
      "6th- epoch: 31, train_loss = 23.943813804537058, train_acc = 0.9485328365160689\n",
      "test Acc 0.9394785847299814:\n",
      "6th- epoch: 32, train_loss = 23.769825268536806, train_acc = 0.9487657196087564\n",
      "test Acc 0.9399441340782123:\n",
      "6th- epoch: 33, train_loss = 23.5928242392838, train_acc = 0.9493479273404751\n",
      "test Acc 0.9394785847299814:\n",
      "6th- epoch: 34, train_loss = 23.430581886321306, train_acc = 0.9494643688868188\n",
      "test Acc 0.9399441340782123:\n",
      "6th- epoch: 35, train_loss = 23.265130173414946, train_acc = 0.9494643688868188\n",
      "test Acc 0.9408752327746741:\n",
      "6th- epoch: 36, train_loss = 23.105683740228415, train_acc = 0.94981369352585\n",
      "test Acc 0.9413407821229051:\n",
      "6th- epoch: 37, train_loss = 22.933291483670473, train_acc = 0.9499301350721937\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 38, train_loss = 22.777822207659483, train_acc = 0.950279459711225\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 39, train_loss = 22.641674023121595, train_acc = 0.9503959012575687\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 40, train_loss = 22.52192758023739, train_acc = 0.9507452258965999\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 41, train_loss = 22.381873596459627, train_acc = 0.9512109920819748\n",
      "test Acc 0.9427374301675978:\n",
      "6th- epoch: 42, train_loss = 22.258392464369535, train_acc = 0.951560316721006\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 43, train_loss = 22.132011018693447, train_acc = 0.9513274336283186\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 44, train_loss = 22.0154666043818, train_acc = 0.9523754075454122\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 45, train_loss = 21.90242923423648, train_acc = 0.9519096413600373\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 46, train_loss = 21.787038680166006, train_acc = 0.9528411737307871\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 47, train_loss = 21.681198235601187, train_acc = 0.9527247321844434\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 48, train_loss = 21.574163135141134, train_acc = 0.9531904983698184\n",
      "test Acc 0.9427374301675978:\n",
      "6th- epoch: 49, train_loss = 21.470486868172884, train_acc = 0.9530740568234746\n",
      "test Acc 0.9427374301675978:\n",
      "6th- epoch: 50, train_loss = 21.379089776426554, train_acc = 0.9533069399161621\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 51, train_loss = 21.28434717282653, train_acc = 0.9536562645551933\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 52, train_loss = 21.19606353715062, train_acc = 0.9536562645551933\n",
      "test Acc 0.9427374301675978:\n",
      "6th- epoch: 53, train_loss = 21.110243182629347, train_acc = 0.9541220307405682\n",
      "test Acc 0.9427374301675978:\n",
      "6th- epoch: 54, train_loss = 21.02396011725068, train_acc = 0.9544713553795995\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 55, train_loss = 20.93464232608676, train_acc = 0.9547042384722869\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 56, train_loss = 20.855550222098827, train_acc = 0.9549371215649743\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 57, train_loss = 20.764284186065197, train_acc = 0.9550535631113182\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 58, train_loss = 20.688017666339874, train_acc = 0.9549371215649743\n",
      "test Acc 0.9427374301675978:\n",
      "6th- epoch: 59, train_loss = 20.618003103882074, train_acc = 0.9551700046576619\n",
      "test Acc 0.9427374301675978:\n",
      "6th- epoch: 60, train_loss = 20.534745786339045, train_acc = 0.9552864462040056\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 61, train_loss = 20.45958971232176, train_acc = 0.9551700046576619\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 62, train_loss = 20.39035926386714, train_acc = 0.9549371215649743\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 63, train_loss = 20.31116647645831, train_acc = 0.9554028877503493\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 64, train_loss = 20.251955647021532, train_acc = 0.955519329296693\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 65, train_loss = 20.17252951860428, train_acc = 0.955519329296693\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 66, train_loss = 20.113735526800156, train_acc = 0.955519329296693\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 67, train_loss = 20.04009274020791, train_acc = 0.955519329296693\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 68, train_loss = 19.974084202200174, train_acc = 0.9558686539357243\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 69, train_loss = 19.910467095673084, train_acc = 0.956450861667443\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 70, train_loss = 19.853105954825878, train_acc = 0.9566837447601304\n",
      "test Acc 0.9441340782122905:\n",
      "6th- epoch: 71, train_loss = 19.793248545378447, train_acc = 0.956450861667443\n",
      "test Acc 0.9441340782122905:\n",
      "6th- epoch: 72, train_loss = 19.72925727441907, train_acc = 0.9568001863064741\n",
      "test Acc 0.9441340782122905:\n",
      "6th- epoch: 73, train_loss = 19.67514742538333, train_acc = 0.9570330693991617\n",
      "test Acc 0.9441340782122905:\n",
      "6th- epoch: 74, train_loss = 19.618622925132513, train_acc = 0.9571495109455054\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 75, train_loss = 19.5711862295866, train_acc = 0.9570330693991617\n",
      "test Acc 0.9441340782122905:\n",
      "6th- epoch: 76, train_loss = 19.505195073783398, train_acc = 0.9572659524918491\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 77, train_loss = 19.445214930921793, train_acc = 0.9573823940381928\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 78, train_loss = 19.383443355560303, train_acc = 0.9572659524918491\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 79, train_loss = 19.33807062730193, train_acc = 0.9574988355845365\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 80, train_loss = 19.287258964031935, train_acc = 0.9577317186772241\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 81, train_loss = 19.234883036464453, train_acc = 0.9574988355845365\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 82, train_loss = 19.191234692931175, train_acc = 0.9576152771308803\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 83, train_loss = 19.12364992685616, train_acc = 0.9577317186772241\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 84, train_loss = 19.089997427538037, train_acc = 0.9577317186772241\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 85, train_loss = 19.042421584948897, train_acc = 0.9579646017699115\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 86, train_loss = 19.002739218994975, train_acc = 0.9579646017699115\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 87, train_loss = 18.969516076147556, train_acc = 0.9579646017699115\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 88, train_loss = 18.91160768084228, train_acc = 0.9580810433162552\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 89, train_loss = 18.862424651160836, train_acc = 0.9581974848625989\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 90, train_loss = 18.82533760741353, train_acc = 0.9583139264089428\n",
      "test Acc 0.9436685288640596:\n",
      "6th- epoch: 91, train_loss = 18.778087412938476, train_acc = 0.9583139264089428\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 92, train_loss = 18.73907731100917, train_acc = 0.9583139264089428\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 93, train_loss = 18.694850163534284, train_acc = 0.9585468095016302\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 94, train_loss = 18.664682898670435, train_acc = 0.9584303679552865\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 95, train_loss = 18.633673936128616, train_acc = 0.9586632510479739\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 96, train_loss = 18.57485264725983, train_acc = 0.9590125756870052\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 97, train_loss = 18.54793299548328, train_acc = 0.9588961341406614\n",
      "test Acc 0.9427374301675978:\n",
      "6th- epoch: 98, train_loss = 18.49762881360948, train_acc = 0.9590125756870052\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 99, train_loss = 18.464296903461218, train_acc = 0.9590125756870052\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 100, train_loss = 18.424522187560797, train_acc = 0.9588961341406614\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 101, train_loss = 18.386686710640788, train_acc = 0.9590125756870052\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 102, train_loss = 18.34618783928454, train_acc = 0.9590125756870052\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 103, train_loss = 18.32295331917703, train_acc = 0.9590125756870052\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 104, train_loss = 18.282745087519288, train_acc = 0.9593619003260363\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 105, train_loss = 18.2478244099766, train_acc = 0.9595947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 106, train_loss = 18.212353326380253, train_acc = 0.959944108057755\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 107, train_loss = 18.174814589321613, train_acc = 0.9598276665114113\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 108, train_loss = 18.132522420957685, train_acc = 0.9602934326967862\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 109, train_loss = 18.1084754075855, train_acc = 0.9601769911504425\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 110, train_loss = 18.079553684219718, train_acc = 0.9602934326967862\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 111, train_loss = 18.04402339272201, train_acc = 0.9602934326967862\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 112, train_loss = 18.016180796548724, train_acc = 0.9609920819748486\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 113, train_loss = 17.986088048666716, train_acc = 0.9607591988821611\n",
      "test Acc 0.9427374301675978:\n",
      "6th- epoch: 114, train_loss = 17.94683992303908, train_acc = 0.9608756404285049\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 115, train_loss = 17.919293912127614, train_acc = 0.9606427573358174\n",
      "test Acc 0.9441340782122905:\n",
      "6th- epoch: 116, train_loss = 17.89248680509627, train_acc = 0.9609920819748486\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 117, train_loss = 17.864443141967058, train_acc = 0.9608756404285049\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 118, train_loss = 17.82523068599403, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "6th- epoch: 119, train_loss = 17.806205051019788, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "6th- epoch: 120, train_loss = 17.779770117253065, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "6th- epoch: 121, train_loss = 17.74117637053132, train_acc = 0.9611085235211924\n",
      "test Acc 0.9441340782122905:\n",
      "6th- epoch: 122, train_loss = 17.712421724572778, train_acc = 0.9612249650675361\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 123, train_loss = 17.68607112392783, train_acc = 0.9612249650675361\n",
      "test Acc 0.9441340782122905:\n",
      "6th- epoch: 124, train_loss = 17.650432525202632, train_acc = 0.9613414066138798\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 125, train_loss = 17.63507662154734, train_acc = 0.9612249650675361\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 126, train_loss = 17.59790891967714, train_acc = 0.9613414066138798\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 127, train_loss = 17.58476471155882, train_acc = 0.9612249650675361\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 128, train_loss = 17.548192834481597, train_acc = 0.9614578481602236\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 129, train_loss = 17.52343165129423, train_acc = 0.9615742897065673\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 130, train_loss = 17.499511821195483, train_acc = 0.961690731252911\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 131, train_loss = 17.46609099768102, train_acc = 0.9614578481602236\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 132, train_loss = 17.441051652655005, train_acc = 0.961690731252911\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 133, train_loss = 17.432002106681466, train_acc = 0.961690731252911\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 134, train_loss = 17.39803117327392, train_acc = 0.9618071727992548\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 135, train_loss = 17.36964047141373, train_acc = 0.9620400558919422\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 136, train_loss = 17.34212907589972, train_acc = 0.962156497438286\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 137, train_loss = 17.317945567891, train_acc = 0.9619236143455985\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 138, train_loss = 17.31176756322384, train_acc = 0.9620400558919422\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 139, train_loss = 17.2706112023443, train_acc = 0.962156497438286\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 140, train_loss = 17.251575773581862, train_acc = 0.962156497438286\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 141, train_loss = 17.22148004733026, train_acc = 0.9622729389846297\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 142, train_loss = 17.206618016585708, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 143, train_loss = 17.182409465312958, train_acc = 0.9622729389846297\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 144, train_loss = 17.16094679571688, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 145, train_loss = 17.140608051791787, train_acc = 0.9623893805309734\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 146, train_loss = 17.116069585084915, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 147, train_loss = 17.095595851540565, train_acc = 0.9623893805309734\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 148, train_loss = 17.07233594916761, train_acc = 0.9623893805309734\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 149, train_loss = 17.052076369524002, train_acc = 0.9626222636236609\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 150, train_loss = 17.024069694802165, train_acc = 0.9628551467163484\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 151, train_loss = 17.00953121483326, train_acc = 0.9628551467163484\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 152, train_loss = 16.991106376051903, train_acc = 0.9628551467163484\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 153, train_loss = 16.97119746170938, train_acc = 0.9628551467163484\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 154, train_loss = 16.949003040790558, train_acc = 0.9628551467163484\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 155, train_loss = 16.924191497266293, train_acc = 0.9629715882626921\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 156, train_loss = 16.91321830637753, train_acc = 0.9629715882626921\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 157, train_loss = 16.887105183675885, train_acc = 0.9630880298090359\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 158, train_loss = 16.865937707945704, train_acc = 0.9629715882626921\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 159, train_loss = 16.849246183410287, train_acc = 0.9629715882626921\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 160, train_loss = 16.828088967129588, train_acc = 0.9632044713553796\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 161, train_loss = 16.803537035360932, train_acc = 0.9632044713553796\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 162, train_loss = 16.786293094977736, train_acc = 0.9632044713553796\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 163, train_loss = 16.769565680995584, train_acc = 0.9632044713553796\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 164, train_loss = 16.743697492405772, train_acc = 0.9633209129017233\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 165, train_loss = 16.73774886317551, train_acc = 0.9632044713553796\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 166, train_loss = 16.710451966151595, train_acc = 0.9635537959944108\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 167, train_loss = 16.693285025656223, train_acc = 0.9633209129017233\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 168, train_loss = 16.67976356483996, train_acc = 0.9634373544480671\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 169, train_loss = 16.657695354893804, train_acc = 0.9636702375407545\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 170, train_loss = 16.63671157322824, train_acc = 0.9634373544480671\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 171, train_loss = 16.62451760470867, train_acc = 0.9635537959944108\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 172, train_loss = 16.60338775999844, train_acc = 0.9635537959944108\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 173, train_loss = 16.58722522109747, train_acc = 0.9634373544480671\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 174, train_loss = 16.576623832806945, train_acc = 0.9634373544480671\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 175, train_loss = 16.54921641200781, train_acc = 0.9635537959944108\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 176, train_loss = 16.531394911929965, train_acc = 0.9636702375407545\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 177, train_loss = 16.517377460375428, train_acc = 0.9635537959944108\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 178, train_loss = 16.510489473119378, train_acc = 0.9635537959944108\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 179, train_loss = 16.481132386252284, train_acc = 0.9636702375407545\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 180, train_loss = 16.480861879885197, train_acc = 0.9637866790870983\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 181, train_loss = 16.45043903030455, train_acc = 0.9637866790870983\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 182, train_loss = 16.43994029611349, train_acc = 0.9636702375407545\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 183, train_loss = 16.42914449609816, train_acc = 0.963903120633442\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 184, train_loss = 16.40613247640431, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 185, train_loss = 16.39076283760369, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 186, train_loss = 16.37368551455438, train_acc = 0.9637866790870983\n",
      "test Acc 0.9445996275605214:\n",
      "6th- epoch: 187, train_loss = 16.358112497255206, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 188, train_loss = 16.341500893235207, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 189, train_loss = 16.32126663811505, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 190, train_loss = 16.307978382334113, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 191, train_loss = 16.28740723244846, train_acc = 0.963903120633442\n",
      "test Acc 0.9455307262569832:\n",
      "6th- epoch: 192, train_loss = 16.28159472346306, train_acc = 0.9640195621797858\n",
      "test Acc 0.9455307262569832:\n",
      "6th- epoch: 193, train_loss = 16.265749575570226, train_acc = 0.963903120633442\n",
      "test Acc 0.9455307262569832:\n",
      "6th- epoch: 194, train_loss = 16.254436388611794, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 195, train_loss = 16.241765439510345, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 196, train_loss = 16.219155153259635, train_acc = 0.963903120633442\n",
      "test Acc 0.9455307262569832:\n",
      "6th- epoch: 197, train_loss = 16.21092165261507, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 198, train_loss = 16.186778774484992, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 199, train_loss = 16.171821027994156, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 200, train_loss = 16.152960158884525, train_acc = 0.963903120633442\n",
      "test Acc 0.9455307262569832:\n",
      "6th- epoch: 201, train_loss = 16.13638786971569, train_acc = 0.9642524452724732\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 202, train_loss = 16.119660148397088, train_acc = 0.9642524452724732\n",
      "test Acc 0.9455307262569832:\n",
      "6th- epoch: 203, train_loss = 16.106087930500507, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 204, train_loss = 16.088703334331512, train_acc = 0.9641360037261295\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 205, train_loss = 16.076257579028606, train_acc = 0.9643688868188169\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 206, train_loss = 16.06588844768703, train_acc = 0.9641360037261295\n",
      "test Acc 0.9455307262569832:\n",
      "6th- epoch: 207, train_loss = 16.05098013393581, train_acc = 0.963903120633442\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 208, train_loss = 16.040134137496352, train_acc = 0.9642524452724732\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 209, train_loss = 16.029537074267864, train_acc = 0.9642524452724732\n",
      "test Acc 0.9455307262569832:\n",
      "6th- epoch: 210, train_loss = 16.02096071280539, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 211, train_loss = 16.000851010903716, train_acc = 0.9643688868188169\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 212, train_loss = 15.985854221507907, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 213, train_loss = 15.966202879324555, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 214, train_loss = 15.95107234455645, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 215, train_loss = 15.946666486561298, train_acc = 0.9646017699115044\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 216, train_loss = 15.93655084259808, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 217, train_loss = 15.920770289376378, train_acc = 0.9646017699115044\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 218, train_loss = 15.8992241024971, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 219, train_loss = 15.896191297098994, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 220, train_loss = 15.881159828975797, train_acc = 0.9643688868188169\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 221, train_loss = 15.85770709067583, train_acc = 0.9646017699115044\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 222, train_loss = 15.854991726577282, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 223, train_loss = 15.837940083816648, train_acc = 0.9646017699115044\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 224, train_loss = 15.829095723107457, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 225, train_loss = 15.810908198356628, train_acc = 0.9646017699115044\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 226, train_loss = 15.802902879193425, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 227, train_loss = 15.791340811178088, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 228, train_loss = 15.780866973102093, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 229, train_loss = 15.762380139902234, train_acc = 0.9646017699115044\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 230, train_loss = 15.756134333088994, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 231, train_loss = 15.749371157959104, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 232, train_loss = 15.735099042765796, train_acc = 0.9646017699115044\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 233, train_loss = 15.720128489658237, train_acc = 0.9646017699115044\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 234, train_loss = 15.714809099212289, train_acc = 0.9646017699115044\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 235, train_loss = 15.694882543757558, train_acc = 0.9647182114578482\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 236, train_loss = 15.684540631249547, train_acc = 0.9648346530041919\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 237, train_loss = 15.669538348913193, train_acc = 0.9648346530041919\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 238, train_loss = 15.660165635868907, train_acc = 0.9649510945505356\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 239, train_loss = 15.650166322477162, train_acc = 0.9649510945505356\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 240, train_loss = 15.63048361428082, train_acc = 0.9649510945505356\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 241, train_loss = 15.620497000403702, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 242, train_loss = 15.614774336107075, train_acc = 0.9649510945505356\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 243, train_loss = 15.605431862175465, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 244, train_loss = 15.589404076337814, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 245, train_loss = 15.583701710216701, train_acc = 0.9651839776432231\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 246, train_loss = 15.566765330731869, train_acc = 0.9649510945505356\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 247, train_loss = 15.558388757519424, train_acc = 0.9651839776432231\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 248, train_loss = 15.542170211672783, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 249, train_loss = 15.537147082388401, train_acc = 0.9653004191895669\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 250, train_loss = 15.522730234079063, train_acc = 0.9653004191895669\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 251, train_loss = 15.512648795731366, train_acc = 0.9653004191895669\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 252, train_loss = 15.503972266800702, train_acc = 0.9654168607359106\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 253, train_loss = 15.49161135405302, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 254, train_loss = 15.477128935046494, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 255, train_loss = 15.473440204747021, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 256, train_loss = 15.456631325185299, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 257, train_loss = 15.448894806206226, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 258, train_loss = 15.43805481493473, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 259, train_loss = 15.433679960668087, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 260, train_loss = 15.419408604502678, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 261, train_loss = 15.410685680806637, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 262, train_loss = 15.404652272351086, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 263, train_loss = 15.38543925434351, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 264, train_loss = 15.374248157255352, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 265, train_loss = 15.36303099989891, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 266, train_loss = 15.353695529513061, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 267, train_loss = 15.343873714096844, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 268, train_loss = 15.331649015657604, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 269, train_loss = 15.317241017706692, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 270, train_loss = 15.309212910942733, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 271, train_loss = 15.30602724570781, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 272, train_loss = 15.297250591218472, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 273, train_loss = 15.29055707436055, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 274, train_loss = 15.285383574664593, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 275, train_loss = 15.276223448105156, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 276, train_loss = 15.254693076014519, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 277, train_loss = 15.249580085277557, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 278, train_loss = 15.238747077994049, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 279, train_loss = 15.227581803686917, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 280, train_loss = 15.225960751064122, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 281, train_loss = 15.214450530707836, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 282, train_loss = 15.200083295814693, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 283, train_loss = 15.196957836858928, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 284, train_loss = 15.189450557343662, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 285, train_loss = 15.172470532357693, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 286, train_loss = 15.162226472981274, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 287, train_loss = 15.158083151094615, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 288, train_loss = 15.144837151281536, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 289, train_loss = 15.138524969108403, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 290, train_loss = 15.131413884460926, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 291, train_loss = 15.125556540675461, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 292, train_loss = 15.118566910736263, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 293, train_loss = 15.110404402017593, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 294, train_loss = 15.100325971841812, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 295, train_loss = 15.08880480658263, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 296, train_loss = 15.086441147141159, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 297, train_loss = 15.075694997794926, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 298, train_loss = 15.069817282259464, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 299, train_loss = 15.049476030282676, train_acc = 0.966581276199348\n",
      "test Acc 0.9464618249534451:\n",
      "6th- epoch: 300, train_loss = 15.044383309781551, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 301, train_loss = 15.044191884808242, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 302, train_loss = 15.033243256621063, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 303, train_loss = 15.018927979283035, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 304, train_loss = 15.017941854894161, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 305, train_loss = 15.001993062905967, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 306, train_loss = 14.993537458591163, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 307, train_loss = 14.983027689158916, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 308, train_loss = 14.984081705100834, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 309, train_loss = 14.97643466014415, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 310, train_loss = 14.953680641949177, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 311, train_loss = 14.95715503115207, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 312, train_loss = 14.953665430657566, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 313, train_loss = 14.943243321962655, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 314, train_loss = 14.931106152944267, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 315, train_loss = 14.92963634710759, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 316, train_loss = 14.92097894102335, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 317, train_loss = 14.911138102412224, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 318, train_loss = 14.9026067154482, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 319, train_loss = 14.89726887177676, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 320, train_loss = 14.888478584587574, train_acc = 0.9675128085700978\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 321, train_loss = 14.888467103242874, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 322, train_loss = 14.873619303107262, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 323, train_loss = 14.866340587846935, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 324, train_loss = 14.859280660748482, train_acc = 0.9675128085700978\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 325, train_loss = 14.852387681603432, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 326, train_loss = 14.843058180995286, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 327, train_loss = 14.837156042456627, train_acc = 0.9675128085700978\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 328, train_loss = 14.83403676468879, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 329, train_loss = 14.819950033910573, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 330, train_loss = 14.8099664747715, train_acc = 0.9675128085700978\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 331, train_loss = 14.811498120427132, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 332, train_loss = 14.796462404541671, train_acc = 0.9675128085700978\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 333, train_loss = 14.790302733890712, train_acc = 0.9675128085700978\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 334, train_loss = 14.78400094807148, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 335, train_loss = 14.78336341958493, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 336, train_loss = 14.772048003971577, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 337, train_loss = 14.760127633810043, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 338, train_loss = 14.748327446170151, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 339, train_loss = 14.751316162757576, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 340, train_loss = 14.739812582731247, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 341, train_loss = 14.73142609745264, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 342, train_loss = 14.734832808375359, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 343, train_loss = 14.72412923257798, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 344, train_loss = 14.711335671134293, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 345, train_loss = 14.71068450063467, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 346, train_loss = 14.703429649583995, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 347, train_loss = 14.698851943016052, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 348, train_loss = 14.688000219874084, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 349, train_loss = 14.67932453751564, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 350, train_loss = 14.671353481709957, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 351, train_loss = 14.665556348860264, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 352, train_loss = 14.658686530776322, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 353, train_loss = 14.652331630699337, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 354, train_loss = 14.652107693254948, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 355, train_loss = 14.642928470857441, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 356, train_loss = 14.634172596037388, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 357, train_loss = 14.625312973745167, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 358, train_loss = 14.624169930815697, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 359, train_loss = 14.616958322934806, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 360, train_loss = 14.609528024680912, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 361, train_loss = 14.605942535214126, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 362, train_loss = 14.599362917244434, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 363, train_loss = 14.590347208082676, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 364, train_loss = 14.584157998673618, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 365, train_loss = 14.577060121111572, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 366, train_loss = 14.571503721177578, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 367, train_loss = 14.56373771559447, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 368, train_loss = 14.551663245074451, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 369, train_loss = 14.547686159610748, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 370, train_loss = 14.547935739159584, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 371, train_loss = 14.543669474311173, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 372, train_loss = 14.528025820851326, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 373, train_loss = 14.526535622775555, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 374, train_loss = 14.517005148343742, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 375, train_loss = 14.510318796150386, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 376, train_loss = 14.504777503199875, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 377, train_loss = 14.497197995893657, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 378, train_loss = 14.497239604592323, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 379, train_loss = 14.478650954551995, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 380, train_loss = 14.479231807403266, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 381, train_loss = 14.4718545852229, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 382, train_loss = 14.46722599118948, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 383, train_loss = 14.461656642146409, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 384, train_loss = 14.460366648621857, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 385, train_loss = 14.451989236287773, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 386, train_loss = 14.443550013005733, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 387, train_loss = 14.441125705838203, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 388, train_loss = 14.433099958114326, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 389, train_loss = 14.428241103887558, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 390, train_loss = 14.425515214912593, train_acc = 0.9687936655798789\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 391, train_loss = 14.41670648753643, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 392, train_loss = 14.410539197735488, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 393, train_loss = 14.403276729397476, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 394, train_loss = 14.400454506278038, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 395, train_loss = 14.392300193198025, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 396, train_loss = 14.386681514792144, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 397, train_loss = 14.380981780588627, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 398, train_loss = 14.37713127117604, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 399, train_loss = 14.371074545197189, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 400, train_loss = 14.366462220437825, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 401, train_loss = 14.36205609422177, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 402, train_loss = 14.35529912263155, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 403, train_loss = 14.348124384880066, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 404, train_loss = 14.339846548624337, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 405, train_loss = 14.341589418239892, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 406, train_loss = 14.332955623976886, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 407, train_loss = 14.327408075332642, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 408, train_loss = 14.324902120046318, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 409, train_loss = 14.310396328568459, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 410, train_loss = 14.315572935156524, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 411, train_loss = 14.303616057150066, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 412, train_loss = 14.297545455396175, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 413, train_loss = 14.294592012651265, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 414, train_loss = 14.287577964365482, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 415, train_loss = 14.283111296594143, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 416, train_loss = 14.28050706256181, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 417, train_loss = 14.269811496138573, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 418, train_loss = 14.263148526661098, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 419, train_loss = 14.26228724885732, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 420, train_loss = 14.252656956203282, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 421, train_loss = 14.249482899904251, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 422, train_loss = 14.245800602249801, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 423, train_loss = 14.243938182480633, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 424, train_loss = 14.235524587333202, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "6th- epoch: 425, train_loss = 14.235015812329948, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 426, train_loss = 14.226453105919063, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 427, train_loss = 14.223677277565002, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 428, train_loss = 14.216353039257228, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 429, train_loss = 14.21072628814727, train_acc = 0.9691429902189101\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 430, train_loss = 14.208600061945617, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 431, train_loss = 14.20227659214288, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 432, train_loss = 14.200907994993031, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 433, train_loss = 14.18969713151455, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 434, train_loss = 14.18773044180125, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 435, train_loss = 14.181646920740604, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "6th- epoch: 436, train_loss = 14.176554049365222, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 437, train_loss = 14.166269044391811, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 438, train_loss = 14.163155836053193, train_acc = 0.9691429902189101\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 439, train_loss = 14.160171590745449, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 440, train_loss = 14.156623070128262, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 441, train_loss = 14.153216143138707, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 442, train_loss = 14.14635421615094, train_acc = 0.9691429902189101\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 443, train_loss = 14.141342136077583, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 444, train_loss = 14.14008733164519, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 445, train_loss = 14.137704531662166, train_acc = 0.9693758733115976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 446, train_loss = 14.129596252925694, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 447, train_loss = 14.127021198160946, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 448, train_loss = 14.118821400217712, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 449, train_loss = 14.114262078888714, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 450, train_loss = 14.111345673911273, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 451, train_loss = 14.106897269375622, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 452, train_loss = 14.101289975456893, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 453, train_loss = 14.089052446186543, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 454, train_loss = 14.09150257986039, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 455, train_loss = 14.084739004261792, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 456, train_loss = 14.084484025835991, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 457, train_loss = 14.075131135992706, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 458, train_loss = 14.074816718697548, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 459, train_loss = 14.067164081148803, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 460, train_loss = 14.064665419049561, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 461, train_loss = 14.060408852994442, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 462, train_loss = 14.055633132345974, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 463, train_loss = 14.047999563626945, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 464, train_loss = 14.046611326746643, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 465, train_loss = 14.040019728243351, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 466, train_loss = 14.039582927711308, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 467, train_loss = 14.035067394375801, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 468, train_loss = 14.0307522341609, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 469, train_loss = 14.030252295546234, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 470, train_loss = 14.01910484302789, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 471, train_loss = 14.015742640011013, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 472, train_loss = 14.012651515193284, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 473, train_loss = 14.006960183382034, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "6th- epoch: 474, train_loss = 13.998760248534381, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 475, train_loss = 13.998354914598167, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 476, train_loss = 13.991055672056973, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 477, train_loss = 13.989462363533676, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 478, train_loss = 13.983976881019771, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 479, train_loss = 13.981452542357147, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 480, train_loss = 13.978909857571125, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 481, train_loss = 13.970094370655715, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 482, train_loss = 13.967262531630695, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 483, train_loss = 13.96564827580005, train_acc = 0.9694923148579413\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 484, train_loss = 13.957523427903652, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "6th- epoch: 485, train_loss = 13.954979379661381, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 486, train_loss = 13.949323927052319, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 487, train_loss = 13.94811725616455, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 488, train_loss = 13.94184857327491, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "6th- epoch: 489, train_loss = 13.942254302091897, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 490, train_loss = 13.930612067691982, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 491, train_loss = 13.93363965768367, train_acc = 0.969608756404285\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 492, train_loss = 13.926241126842797, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 493, train_loss = 13.921467013657093, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 494, train_loss = 13.918247304856777, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 495, train_loss = 13.915554908104241, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 496, train_loss = 13.911292277276516, train_acc = 0.969608756404285\n",
      "test Acc 0.9478584729981379:\n",
      "6th- epoch: 497, train_loss = 13.913901373744011, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 498, train_loss = 13.903384526260197, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 499, train_loss = 13.89766748715192, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████▌                                                          | 6/30 [54:18<3:37:19, 543.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "7th- epoch: 0, train_loss = 124.80583634972572, train_acc = 0.7402189101071263\n",
      "test Acc 0.8333333333333334:\n",
      "7th- epoch: 1, train_loss = 60.4703631401062, train_acc = 0.8720307405682347\n",
      "test Acc 0.8808193668528864:\n",
      "7th- epoch: 2, train_loss = 50.570172891020775, train_acc = 0.8919422449930136\n",
      "test Acc 0.8919925512104283:\n",
      "7th- epoch: 3, train_loss = 45.45087657868862, train_acc = 0.9030041918956684\n",
      "test Acc 0.9003724394785847:\n",
      "7th- epoch: 4, train_loss = 41.96814885735512, train_acc = 0.9108057755006986\n",
      "test Acc 0.909217877094972:\n",
      "7th- epoch: 5, train_loss = 39.38542552292347, train_acc = 0.9151141127154169\n",
      "test Acc 0.9185288640595903:\n",
      "7th- epoch: 6, train_loss = 37.38698007911444, train_acc = 0.9194224499301351\n",
      "test Acc 0.9217877094972067:\n",
      "7th- epoch: 7, train_loss = 35.76971438527107, train_acc = 0.9237307871448532\n",
      "test Acc 0.9227188081936686:\n",
      "7th- epoch: 8, train_loss = 34.40167876332998, train_acc = 0.9271075919888216\n",
      "test Acc 0.925512104283054:\n",
      "7th- epoch: 9, train_loss = 33.26289013028145, train_acc = 0.9297857475547275\n",
      "test Acc 0.9283054003724395:\n",
      "7th- epoch: 10, train_loss = 32.248655922710896, train_acc = 0.9325803446669771\n",
      "test Acc 0.930633147113594:\n",
      "7th- epoch: 11, train_loss = 31.421780735254288, train_acc = 0.9337447601304145\n",
      "test Acc 0.930633147113594:\n",
      "7th- epoch: 12, train_loss = 30.640524946153164, train_acc = 0.9360735910572893\n",
      "test Acc 0.931098696461825:\n",
      "7th- epoch: 13, train_loss = 29.941783152520657, train_acc = 0.9372380065207266\n",
      "test Acc 0.9315642458100558:\n",
      "7th- epoch: 14, train_loss = 29.313995987176895, train_acc = 0.9385188635305077\n",
      "test Acc 0.9320297951582868:\n",
      "7th- epoch: 15, train_loss = 28.754535488784313, train_acc = 0.9392175128085701\n",
      "test Acc 0.9320297951582868:\n",
      "7th- epoch: 16, train_loss = 28.264510482549667, train_acc = 0.94014904517932\n",
      "test Acc 0.9324953445065177:\n",
      "7th- epoch: 17, train_loss = 27.778812892735004, train_acc = 0.9416627852817886\n",
      "test Acc 0.9329608938547486:\n",
      "7th- epoch: 18, train_loss = 27.37614979594946, train_acc = 0.9424778761061947\n",
      "test Acc 0.9329608938547486:\n",
      "7th- epoch: 19, train_loss = 26.995059967041016, train_acc = 0.9428272007452259\n",
      "test Acc 0.9334264432029795:\n",
      "7th- epoch: 20, train_loss = 26.62965203821659, train_acc = 0.9436422915696321\n",
      "test Acc 0.9334264432029795:\n",
      "7th- epoch: 21, train_loss = 26.29706386849284, train_acc = 0.9446902654867256\n",
      "test Acc 0.9343575418994413:\n",
      "7th- epoch: 22, train_loss = 25.97692548111081, train_acc = 0.945388914764788\n",
      "test Acc 0.9366852886405959:\n",
      "7th- epoch: 23, train_loss = 25.680688109248877, train_acc = 0.945854680950163\n",
      "test Acc 0.936219739292365:\n",
      "7th- epoch: 24, train_loss = 25.39280227571726, train_acc = 0.9462040055891943\n",
      "test Acc 0.9366852886405959:\n",
      "7th- epoch: 25, train_loss = 25.143447697162628, train_acc = 0.9470190964136004\n",
      "test Acc 0.9366852886405959:\n",
      "7th- epoch: 26, train_loss = 24.893060471862555, train_acc = 0.9469026548672567\n",
      "test Acc 0.9366852886405959:\n",
      "7th- epoch: 27, train_loss = 24.65464796870947, train_acc = 0.9473684210526315\n",
      "test Acc 0.9366852886405959:\n",
      "7th- epoch: 28, train_loss = 24.425181716680527, train_acc = 0.948067070330694\n",
      "test Acc 0.9376163873370578:\n",
      "7th- epoch: 29, train_loss = 24.2137040682137, train_acc = 0.9485328365160689\n",
      "test Acc 0.9371508379888268:\n",
      "7th- epoch: 30, train_loss = 24.01431716233492, train_acc = 0.9488821611551002\n",
      "test Acc 0.9371508379888268:\n",
      "7th- epoch: 31, train_loss = 23.81042103841901, train_acc = 0.9488821611551002\n",
      "test Acc 0.9371508379888268:\n",
      "7th- epoch: 32, train_loss = 23.63353868201375, train_acc = 0.9492314857941313\n",
      "test Acc 0.9371508379888268:\n",
      "7th- epoch: 33, train_loss = 23.463045865297318, train_acc = 0.9493479273404751\n",
      "test Acc 0.9371508379888268:\n",
      "7th- epoch: 34, train_loss = 23.304460763931274, train_acc = 0.9496972519795063\n",
      "test Acc 0.9371508379888268:\n",
      "7th- epoch: 35, train_loss = 23.114821765571833, train_acc = 0.94981369352585\n",
      "test Acc 0.9371508379888268:\n",
      "7th- epoch: 36, train_loss = 22.972241830080748, train_acc = 0.9499301350721937\n",
      "test Acc 0.9380819366852886:\n",
      "7th- epoch: 37, train_loss = 22.810715939849615, train_acc = 0.9503959012575687\n",
      "test Acc 0.9380819366852886:\n",
      "7th- epoch: 38, train_loss = 22.677009981125593, train_acc = 0.9508616674429436\n",
      "test Acc 0.9376163873370578:\n",
      "7th- epoch: 39, train_loss = 22.519721381366253, train_acc = 0.9512109920819748\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 40, train_loss = 22.392629597336054, train_acc = 0.9516767582673498\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 41, train_loss = 22.275695495307446, train_acc = 0.951560316721006\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 42, train_loss = 22.1468545794487, train_acc = 0.952026082906381\n",
      "test Acc 0.9380819366852886:\n",
      "7th- epoch: 43, train_loss = 22.02072548121214, train_acc = 0.9517931998136935\n",
      "test Acc 0.9380819366852886:\n",
      "7th- epoch: 44, train_loss = 21.902119897305965, train_acc = 0.9523754075454122\n",
      "test Acc 0.9380819366852886:\n",
      "7th- epoch: 45, train_loss = 21.79789173603058, train_acc = 0.9523754075454122\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 46, train_loss = 21.696353171020746, train_acc = 0.952491849091756\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 47, train_loss = 21.575487937778234, train_acc = 0.9526082906380997\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 48, train_loss = 21.467298541218042, train_acc = 0.9527247321844434\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 49, train_loss = 21.378548551350832, train_acc = 0.9529576152771309\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 50, train_loss = 21.287241406738758, train_acc = 0.9529576152771309\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 51, train_loss = 21.179293729364872, train_acc = 0.9533069399161621\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 52, train_loss = 21.094110034406185, train_acc = 0.9535398230088495\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 53, train_loss = 21.001106698065996, train_acc = 0.9537727061015371\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 54, train_loss = 20.914592247456312, train_acc = 0.9538891476478808\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 55, train_loss = 20.822113275527954, train_acc = 0.9542384722869119\n",
      "test Acc 0.9385474860335196:\n",
      "7th- epoch: 56, train_loss = 20.738861735910177, train_acc = 0.9543549138332557\n",
      "test Acc 0.9390130353817505:\n",
      "7th- epoch: 57, train_loss = 20.66568936780095, train_acc = 0.9543549138332557\n",
      "test Acc 0.9390130353817505:\n",
      "7th- epoch: 58, train_loss = 20.575880859047174, train_acc = 0.9550535631113182\n",
      "test Acc 0.9390130353817505:\n",
      "7th- epoch: 59, train_loss = 20.503954209387302, train_acc = 0.9551700046576619\n",
      "test Acc 0.9390130353817505:\n",
      "7th- epoch: 60, train_loss = 20.42606905475259, train_acc = 0.955519329296693\n",
      "test Acc 0.9390130353817505:\n",
      "7th- epoch: 61, train_loss = 20.358434814959764, train_acc = 0.955519329296693\n",
      "test Acc 0.9399441340782123:\n",
      "7th- epoch: 62, train_loss = 20.285442784428596, train_acc = 0.9557522123893806\n",
      "test Acc 0.9399441340782123:\n",
      "7th- epoch: 63, train_loss = 20.221032921224833, train_acc = 0.955519329296693\n",
      "test Acc 0.9399441340782123:\n",
      "7th- epoch: 64, train_loss = 20.171194903552532, train_acc = 0.9558686539357243\n",
      "test Acc 0.9399441340782123:\n",
      "7th- epoch: 65, train_loss = 20.086458306759596, train_acc = 0.9562179785747554\n",
      "test Acc 0.9399441340782123:\n",
      "7th- epoch: 66, train_loss = 20.016250357031822, train_acc = 0.9561015370284117\n",
      "test Acc 0.9399441340782123:\n",
      "7th- epoch: 67, train_loss = 19.963079143315554, train_acc = 0.955985095482068\n",
      "test Acc 0.9399441340782123:\n",
      "7th- epoch: 68, train_loss = 19.88570823892951, train_acc = 0.9565673032137867\n",
      "test Acc 0.9399441340782123:\n",
      "7th- epoch: 69, train_loss = 19.827437330037355, train_acc = 0.9563344201210993\n",
      "test Acc 0.9399441340782123:\n",
      "7th- epoch: 70, train_loss = 19.77647490054369, train_acc = 0.956450861667443\n",
      "test Acc 0.9399441340782123:\n",
      "7th- epoch: 71, train_loss = 19.71148094907403, train_acc = 0.9565673032137867\n",
      "test Acc 0.9399441340782123:\n",
      "7th- epoch: 72, train_loss = 19.642085555940866, train_acc = 0.9566837447601304\n",
      "test Acc 0.9404096834264432:\n",
      "7th- epoch: 73, train_loss = 19.596548285335302, train_acc = 0.9568001863064741\n",
      "test Acc 0.9404096834264432:\n",
      "7th- epoch: 74, train_loss = 19.539955023676157, train_acc = 0.9569166278528178\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 75, train_loss = 19.476430788636208, train_acc = 0.9569166278528178\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 76, train_loss = 19.426906038075686, train_acc = 0.9570330693991617\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 77, train_loss = 19.37160813435912, train_acc = 0.9570330693991617\n",
      "test Acc 0.9404096834264432:\n",
      "7th- epoch: 78, train_loss = 19.323886957019567, train_acc = 0.9572659524918491\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 79, train_loss = 19.268286481499672, train_acc = 0.9573823940381928\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 80, train_loss = 19.218001559376717, train_acc = 0.9573823940381928\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 81, train_loss = 19.161877427250147, train_acc = 0.9578481602235678\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 82, train_loss = 19.122389942407608, train_acc = 0.9579646017699115\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 83, train_loss = 19.065545190125704, train_acc = 0.9579646017699115\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 84, train_loss = 19.025915771722794, train_acc = 0.9579646017699115\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 85, train_loss = 18.98014334589243, train_acc = 0.9580810433162552\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 86, train_loss = 18.93254839628935, train_acc = 0.9581974848625989\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 87, train_loss = 18.89010565727949, train_acc = 0.9581974848625989\n",
      "test Acc 0.9408752327746741:\n",
      "7th- epoch: 88, train_loss = 18.841833174228668, train_acc = 0.9581974848625989\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 89, train_loss = 18.802755646407604, train_acc = 0.9583139264089428\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 90, train_loss = 18.74839649349451, train_acc = 0.9583139264089428\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 91, train_loss = 18.712244886904955, train_acc = 0.9583139264089428\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 92, train_loss = 18.661409810185432, train_acc = 0.9584303679552865\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 93, train_loss = 18.613486867398024, train_acc = 0.9586632510479739\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 94, train_loss = 18.577758990228176, train_acc = 0.9585468095016302\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 95, train_loss = 18.538796730339527, train_acc = 0.9587796925943176\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 96, train_loss = 18.504679784178734, train_acc = 0.9585468095016302\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 97, train_loss = 18.464658848941326, train_acc = 0.9590125756870052\n",
      "test Acc 0.9422718808193669:\n",
      "7th- epoch: 98, train_loss = 18.420205149799585, train_acc = 0.9588961341406614\n",
      "test Acc 0.9418063314711359:\n",
      "7th- epoch: 99, train_loss = 18.393443677574396, train_acc = 0.9591290172333489\n",
      "test Acc 0.9422718808193669:\n",
      "7th- epoch: 100, train_loss = 18.33957812562585, train_acc = 0.9591290172333489\n",
      "test Acc 0.9427374301675978:\n",
      "7th- epoch: 101, train_loss = 18.306778013706207, train_acc = 0.9591290172333489\n",
      "test Acc 0.9422718808193669:\n",
      "7th- epoch: 102, train_loss = 18.26691959425807, train_acc = 0.9592454587796926\n",
      "test Acc 0.9427374301675978:\n",
      "7th- epoch: 103, train_loss = 18.233715638518333, train_acc = 0.9593619003260363\n",
      "test Acc 0.9427374301675978:\n",
      "7th- epoch: 104, train_loss = 18.192258846014738, train_acc = 0.9592454587796926\n",
      "test Acc 0.9432029795158287:\n",
      "7th- epoch: 105, train_loss = 18.162765469402075, train_acc = 0.9593619003260363\n",
      "test Acc 0.9427374301675978:\n",
      "7th- epoch: 106, train_loss = 18.134860683232546, train_acc = 0.95947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "7th- epoch: 107, train_loss = 18.097391791641712, train_acc = 0.95947834187238\n",
      "test Acc 0.9436685288640596:\n",
      "7th- epoch: 108, train_loss = 18.061750810593367, train_acc = 0.9597112249650676\n",
      "test Acc 0.9432029795158287:\n",
      "7th- epoch: 109, train_loss = 18.014523822814226, train_acc = 0.95947834187238\n",
      "test Acc 0.9436685288640596:\n",
      "7th- epoch: 110, train_loss = 17.97761831060052, train_acc = 0.9595947834187238\n",
      "test Acc 0.9436685288640596:\n",
      "7th- epoch: 111, train_loss = 17.946144672110677, train_acc = 0.9595947834187238\n",
      "test Acc 0.9436685288640596:\n",
      "7th- epoch: 112, train_loss = 17.925848683342338, train_acc = 0.9598276665114113\n",
      "test Acc 0.9436685288640596:\n",
      "7th- epoch: 113, train_loss = 17.87901779450476, train_acc = 0.9600605496040987\n",
      "test Acc 0.9436685288640596:\n",
      "7th- epoch: 114, train_loss = 17.85471418313682, train_acc = 0.9601769911504425\n",
      "test Acc 0.9436685288640596:\n",
      "7th- epoch: 115, train_loss = 17.828939020633698, train_acc = 0.9601769911504425\n",
      "test Acc 0.9436685288640596:\n",
      "7th- epoch: 116, train_loss = 17.80615659803152, train_acc = 0.96040987424313\n",
      "test Acc 0.9436685288640596:\n",
      "7th- epoch: 117, train_loss = 17.767803927883506, train_acc = 0.9601769911504425\n",
      "test Acc 0.9436685288640596:\n",
      "7th- epoch: 118, train_loss = 17.74593554250896, train_acc = 0.96040987424313\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 119, train_loss = 17.724121430888772, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 120, train_loss = 17.689669232815504, train_acc = 0.9606427573358174\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 121, train_loss = 17.654207956045866, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 122, train_loss = 17.614948144182563, train_acc = 0.9606427573358174\n",
      "test Acc 0.9445996275605214:\n",
      "7th- epoch: 123, train_loss = 17.589698273688555, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 124, train_loss = 17.548879753798246, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "7th- epoch: 125, train_loss = 17.523940727114677, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "7th- epoch: 126, train_loss = 17.504504492506385, train_acc = 0.9608756404285049\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 127, train_loss = 17.47245629131794, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 128, train_loss = 17.444192353636026, train_acc = 0.9609920819748486\n",
      "test Acc 0.9445996275605214:\n",
      "7th- epoch: 129, train_loss = 17.42870612256229, train_acc = 0.9609920819748486\n",
      "test Acc 0.9445996275605214:\n",
      "7th- epoch: 130, train_loss = 17.39504088461399, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 131, train_loss = 17.370611572638154, train_acc = 0.9611085235211924\n",
      "test Acc 0.9445996275605214:\n",
      "7th- epoch: 132, train_loss = 17.348378233611584, train_acc = 0.9612249650675361\n",
      "test Acc 0.9450651769087524:\n",
      "7th- epoch: 133, train_loss = 17.314598521217704, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "7th- epoch: 134, train_loss = 17.29940057359636, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "7th- epoch: 135, train_loss = 17.265864556655288, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "7th- epoch: 136, train_loss = 17.24655047059059, train_acc = 0.9613414066138798\n",
      "test Acc 0.9445996275605214:\n",
      "7th- epoch: 137, train_loss = 17.225005207583308, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 138, train_loss = 17.19467263482511, train_acc = 0.961690731252911\n",
      "test Acc 0.9450651769087524:\n",
      "7th- epoch: 139, train_loss = 17.164923468604684, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 140, train_loss = 17.153917552903295, train_acc = 0.961690731252911\n",
      "test Acc 0.9459962756052142:\n",
      "7th- epoch: 141, train_loss = 17.117178985849023, train_acc = 0.9619236143455985\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 142, train_loss = 17.101573660969734, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "7th- epoch: 143, train_loss = 17.072369564324617, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "7th- epoch: 144, train_loss = 17.05239048972726, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "7th- epoch: 145, train_loss = 17.02628650330007, train_acc = 0.9619236143455985\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 146, train_loss = 17.00465495325625, train_acc = 0.962156497438286\n",
      "test Acc 0.9455307262569832:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 147, train_loss = 16.977304125204682, train_acc = 0.9620400558919422\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 148, train_loss = 16.954186329618096, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "7th- epoch: 149, train_loss = 16.946069149300456, train_acc = 0.962156497438286\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 150, train_loss = 16.9093430172652, train_acc = 0.9625058220773172\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 151, train_loss = 16.89572488889098, train_acc = 0.9625058220773172\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 152, train_loss = 16.86653565056622, train_acc = 0.9623893805309734\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 153, train_loss = 16.84625561349094, train_acc = 0.9626222636236609\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 154, train_loss = 16.821884498000145, train_acc = 0.9627387051700047\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 155, train_loss = 16.80133350007236, train_acc = 0.9625058220773172\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 156, train_loss = 16.7938822042197, train_acc = 0.9629715882626921\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 157, train_loss = 16.763267477974296, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 158, train_loss = 16.741155674681067, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 159, train_loss = 16.72578284703195, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 160, train_loss = 16.700900761410594, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 161, train_loss = 16.688838995993137, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 162, train_loss = 16.658882699906826, train_acc = 0.9627387051700047\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 163, train_loss = 16.655692106112838, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 164, train_loss = 16.633998978883028, train_acc = 0.9628551467163484\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 165, train_loss = 16.605716813355684, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 166, train_loss = 16.58899119310081, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 167, train_loss = 16.57357880845666, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 168, train_loss = 16.56190725043416, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 169, train_loss = 16.536014763638377, train_acc = 0.9634373544480671\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 170, train_loss = 16.513569977134466, train_acc = 0.9633209129017233\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 171, train_loss = 16.500178644433618, train_acc = 0.9634373544480671\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 172, train_loss = 16.474664321169257, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 173, train_loss = 16.476352961733937, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 174, train_loss = 16.448243593797088, train_acc = 0.9635537959944108\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 175, train_loss = 16.4283030834049, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 176, train_loss = 16.407687470316887, train_acc = 0.9635537959944108\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 177, train_loss = 16.394131407141685, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 178, train_loss = 16.37910019606352, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 179, train_loss = 16.359858276322484, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 180, train_loss = 16.344099037349224, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 181, train_loss = 16.33420280739665, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 182, train_loss = 16.307116312906146, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 183, train_loss = 16.302138406783342, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 184, train_loss = 16.286508360877633, train_acc = 0.9640195621797858\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 185, train_loss = 16.262811785563827, train_acc = 0.9641360037261295\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 186, train_loss = 16.255348270758986, train_acc = 0.9640195621797858\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 187, train_loss = 16.24350214935839, train_acc = 0.9641360037261295\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 188, train_loss = 16.220888283103704, train_acc = 0.9641360037261295\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 189, train_loss = 16.214857855811715, train_acc = 0.9641360037261295\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 190, train_loss = 16.1796004306525, train_acc = 0.9644853283651607\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 191, train_loss = 16.17455356940627, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 192, train_loss = 16.16173921711743, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 193, train_loss = 16.146085219457746, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 194, train_loss = 16.127713629975915, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 195, train_loss = 16.116345098242164, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 196, train_loss = 16.097803691402078, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 197, train_loss = 16.08017803914845, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 198, train_loss = 16.07731020823121, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 199, train_loss = 16.05450809560716, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 200, train_loss = 16.034882688894868, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 201, train_loss = 16.02055344544351, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 202, train_loss = 16.006333177909255, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 203, train_loss = 15.9988335929811, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 204, train_loss = 15.972291542217135, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 205, train_loss = 15.963426947593689, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 206, train_loss = 15.9517509508878, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 207, train_loss = 15.9268584754318, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 208, train_loss = 15.928035108372569, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "7th- epoch: 209, train_loss = 15.909939587116241, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 210, train_loss = 15.895447630435228, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 211, train_loss = 15.877332547679543, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 212, train_loss = 15.864623121917248, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 213, train_loss = 15.851788777858019, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 214, train_loss = 15.843684673309326, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "7th- epoch: 215, train_loss = 15.831764770671725, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 216, train_loss = 15.811845917254686, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 217, train_loss = 15.793531024828553, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 218, train_loss = 15.784230208024383, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 219, train_loss = 15.79071850143373, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 220, train_loss = 15.759664073586464, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 221, train_loss = 15.754638778045774, train_acc = 0.9648346530041919\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 222, train_loss = 15.743707161396742, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 223, train_loss = 15.726652579382062, train_acc = 0.9648346530041919\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 224, train_loss = 15.709470635280013, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 225, train_loss = 15.701537178829312, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 226, train_loss = 15.687103483825922, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 227, train_loss = 15.678245825693011, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 228, train_loss = 15.657469855621457, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 229, train_loss = 15.64837878011167, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 230, train_loss = 15.638401797041297, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 231, train_loss = 15.622616238892078, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 232, train_loss = 15.623756581917405, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 233, train_loss = 15.60221853852272, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 234, train_loss = 15.588885322213173, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 235, train_loss = 15.57357731834054, train_acc = 0.9648346530041919\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 236, train_loss = 15.562005493789911, train_acc = 0.9648346530041919\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 237, train_loss = 15.560312835499644, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 238, train_loss = 15.544921236112714, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 239, train_loss = 15.537366667762399, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 240, train_loss = 15.518349474295974, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 241, train_loss = 15.503911597654223, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 242, train_loss = 15.492433989420533, train_acc = 0.9647182114578482\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 243, train_loss = 15.491375224664807, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 244, train_loss = 15.472482649609447, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 245, train_loss = 15.458871429786086, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 246, train_loss = 15.45399439893663, train_acc = 0.9647182114578482\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 247, train_loss = 15.435211228206754, train_acc = 0.9649510945505356\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 248, train_loss = 15.432484535500407, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 249, train_loss = 15.419385822489858, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 250, train_loss = 15.408795254305005, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 251, train_loss = 15.404430517926812, train_acc = 0.9647182114578482\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 252, train_loss = 15.385108195245266, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 253, train_loss = 15.385546622797847, train_acc = 0.9648346530041919\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 254, train_loss = 15.368056051433086, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 255, train_loss = 15.351831026375294, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 256, train_loss = 15.348221400752664, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 257, train_loss = 15.339751252904534, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 258, train_loss = 15.328513130545616, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 259, train_loss = 15.316979916766286, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 260, train_loss = 15.301588574424386, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 261, train_loss = 15.285022655501962, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 262, train_loss = 15.278042886406183, train_acc = 0.9648346530041919\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 263, train_loss = 15.279490128159523, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 264, train_loss = 15.264470236375928, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 265, train_loss = 15.243851725012064, train_acc = 0.9653004191895669\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 266, train_loss = 15.246741751208901, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 267, train_loss = 15.232248479500413, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 268, train_loss = 15.219773579388857, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 269, train_loss = 15.209706023335457, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 270, train_loss = 15.205555245280266, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 271, train_loss = 15.188131928443909, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 272, train_loss = 15.185760846361518, train_acc = 0.9650675360968793\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 273, train_loss = 15.167490025050938, train_acc = 0.9657661853749417\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 274, train_loss = 15.163504177704453, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 275, train_loss = 15.15481418557465, train_acc = 0.9649510945505356\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 276, train_loss = 15.146541734226048, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 277, train_loss = 15.13139561470598, train_acc = 0.9651839776432231\n",
      "test Acc 0.9497206703910615:\n",
      "7th- epoch: 278, train_loss = 15.134117337875068, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 279, train_loss = 15.112692892551422, train_acc = 0.9650675360968793\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 280, train_loss = 15.102374431677163, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 281, train_loss = 15.099149145185947, train_acc = 0.9655333022822543\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 282, train_loss = 15.092977280728519, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 283, train_loss = 15.086748401634395, train_acc = 0.9653004191895669\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 284, train_loss = 15.068681374192238, train_acc = 0.9651839776432231\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 285, train_loss = 15.055191022343934, train_acc = 0.9659990684676293\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 286, train_loss = 15.04380223620683, train_acc = 0.9657661853749417\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 287, train_loss = 15.05595351755619, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 288, train_loss = 15.0383309610188, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 289, train_loss = 15.02763860207051, train_acc = 0.965649743828598\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 290, train_loss = 15.024783335626125, train_acc = 0.9662319515603167\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 291, train_loss = 15.010727192275226, train_acc = 0.9664648346530041\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 292, train_loss = 15.009304635226727, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 293, train_loss = 14.999930220656097, train_acc = 0.9663483931066604\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 294, train_loss = 14.99360815063119, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 295, train_loss = 14.973676096647978, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 296, train_loss = 14.962637127377093, train_acc = 0.966115510013973\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 297, train_loss = 14.95742618944496, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 298, train_loss = 14.938251125626266, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 299, train_loss = 14.946868129074574, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 300, train_loss = 14.924102692864835, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 301, train_loss = 14.914614199660718, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 302, train_loss = 14.916640476323664, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 303, train_loss = 14.909124174155295, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 304, train_loss = 14.895127188414335, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 305, train_loss = 14.89100390393287, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 306, train_loss = 14.880246435292065, train_acc = 0.966581276199348\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 307, train_loss = 14.872487057000399, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 308, train_loss = 14.864704209379852, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 309, train_loss = 14.848574102856219, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 310, train_loss = 14.840608878992498, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 311, train_loss = 14.840757236815989, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 312, train_loss = 14.831727570854127, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 313, train_loss = 14.816123333759606, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 314, train_loss = 14.821392349898815, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 315, train_loss = 14.806162278167903, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 316, train_loss = 14.806070840917528, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 317, train_loss = 14.797329193912446, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 318, train_loss = 14.785157044418156, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 319, train_loss = 14.779766826890409, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 320, train_loss = 14.769669134169817, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 321, train_loss = 14.769856452010572, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 322, train_loss = 14.762384060770273, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 323, train_loss = 14.753058106638491, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 324, train_loss = 14.734910280443728, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 325, train_loss = 14.732907865196466, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 326, train_loss = 14.722781736403704, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 327, train_loss = 14.717349774204195, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 328, train_loss = 14.704426758922637, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 329, train_loss = 14.710421041585505, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 330, train_loss = 14.693736236542463, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 331, train_loss = 14.685804239474237, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 332, train_loss = 14.680655342526734, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 333, train_loss = 14.66842122003436, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 334, train_loss = 14.664163016714156, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 335, train_loss = 14.655900109559298, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 336, train_loss = 14.649152625352144, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 337, train_loss = 14.648733862675726, train_acc = 0.9672799254774104\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 338, train_loss = 14.638175210915506, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 339, train_loss = 14.62822974100709, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 340, train_loss = 14.631984011270106, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 341, train_loss = 14.618148669600487, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 342, train_loss = 14.608968671411276, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 343, train_loss = 14.606628018431365, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 344, train_loss = 14.598452151753008, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 345, train_loss = 14.587381142191589, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 346, train_loss = 14.583684946410358, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 347, train_loss = 14.579106924124062, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 348, train_loss = 14.57405849546194, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 349, train_loss = 14.569141200743616, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 350, train_loss = 14.569000843912363, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 351, train_loss = 14.548413193784654, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 352, train_loss = 14.55380875710398, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 353, train_loss = 14.540251567959785, train_acc = 0.9676292501164415\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 354, train_loss = 14.531326539814472, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 355, train_loss = 14.521056737750769, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 356, train_loss = 14.520523809827864, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 357, train_loss = 14.521829382516444, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 358, train_loss = 14.513018570840359, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 359, train_loss = 14.506181794218719, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 360, train_loss = 14.506543309427798, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 361, train_loss = 14.487553160637617, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 362, train_loss = 14.479790274985135, train_acc = 0.9683278993945039\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 363, train_loss = 14.475003759376705, train_acc = 0.9685607824871915\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 364, train_loss = 14.47257474064827, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 365, train_loss = 14.463466989807785, train_acc = 0.9685607824871915\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 366, train_loss = 14.460223786532879, train_acc = 0.9683278993945039\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 367, train_loss = 14.45167737826705, train_acc = 0.9686772240335352\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 368, train_loss = 14.447710860520601, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 369, train_loss = 14.437955661676824, train_acc = 0.9687936655798789\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 370, train_loss = 14.440696471370757, train_acc = 0.9685607824871915\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 371, train_loss = 14.42435396835208, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 372, train_loss = 14.415516533888876, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 373, train_loss = 14.411329827271402, train_acc = 0.9686772240335352\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 374, train_loss = 14.41359978262335, train_acc = 0.9686772240335352\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 375, train_loss = 14.412514594383538, train_acc = 0.9687936655798789\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 376, train_loss = 14.409226036630571, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 377, train_loss = 14.391975726932287, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 378, train_loss = 14.385302218608558, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 379, train_loss = 14.385096102952957, train_acc = 0.9687936655798789\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 380, train_loss = 14.38723920006305, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 381, train_loss = 14.38015412632376, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 382, train_loss = 14.365358925424516, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 383, train_loss = 14.358528189361095, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "7th- epoch: 384, train_loss = 14.354616879485548, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 385, train_loss = 14.345095015130937, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 386, train_loss = 14.34139510244131, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 387, train_loss = 14.329471822828054, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 388, train_loss = 14.326511915773153, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 389, train_loss = 14.323994994163513, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 390, train_loss = 14.31778369564563, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 391, train_loss = 14.312997397966683, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 392, train_loss = 14.320292182266712, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 393, train_loss = 14.306033295579255, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 394, train_loss = 14.302186557091773, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 395, train_loss = 14.295317395590246, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 396, train_loss = 14.282892319373786, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 397, train_loss = 14.284309588372707, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 398, train_loss = 14.27508055884391, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 399, train_loss = 14.267985429614782, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 400, train_loss = 14.273051206022501, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 401, train_loss = 14.272024932317436, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 402, train_loss = 14.260632440447807, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 403, train_loss = 14.261646386235952, train_acc = 0.9699580810433163\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 404, train_loss = 14.246822721324861, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 405, train_loss = 14.236975978128612, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 406, train_loss = 14.239154632203281, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 407, train_loss = 14.228144456632435, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 408, train_loss = 14.227276605553925, train_acc = 0.9697251979506288\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 409, train_loss = 14.213157025165856, train_acc = 0.9697251979506288\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 410, train_loss = 14.208264612592757, train_acc = 0.9697251979506288\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 411, train_loss = 14.216965907253325, train_acc = 0.9697251979506288\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 412, train_loss = 14.209833820350468, train_acc = 0.9697251979506288\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 413, train_loss = 14.19367553666234, train_acc = 0.9697251979506288\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 414, train_loss = 14.195325185544789, train_acc = 0.9699580810433163\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 415, train_loss = 14.20017750468105, train_acc = 0.9699580810433163\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 416, train_loss = 14.18885613977909, train_acc = 0.9697251979506288\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 417, train_loss = 14.184675473719835, train_acc = 0.9697251979506288\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 418, train_loss = 14.175208676606417, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 419, train_loss = 14.158325892873108, train_acc = 0.9697251979506288\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 420, train_loss = 14.15912468265742, train_acc = 0.9697251979506288\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 421, train_loss = 14.159045455045998, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 422, train_loss = 14.153438810259104, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 423, train_loss = 14.157744988799095, train_acc = 0.9699580810433163\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 424, train_loss = 14.148555558174849, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 425, train_loss = 14.13548839930445, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 426, train_loss = 14.12342959921807, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 427, train_loss = 14.124195196665823, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 428, train_loss = 14.130822099745274, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 429, train_loss = 14.123266640119255, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 430, train_loss = 14.115295593626797, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 431, train_loss = 14.107264474965632, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 432, train_loss = 14.102699968032539, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 433, train_loss = 14.09076827391982, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 434, train_loss = 14.099710096605122, train_acc = 0.9701909641360037\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 435, train_loss = 14.092174467630684, train_acc = 0.9697251979506288\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 436, train_loss = 14.081126512028277, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 437, train_loss = 14.070066473446786, train_acc = 0.9699580810433163\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 438, train_loss = 14.072205036878586, train_acc = 0.9699580810433163\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 439, train_loss = 14.061350602656603, train_acc = 0.9699580810433163\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 440, train_loss = 14.063265648670495, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 441, train_loss = 14.046711823903024, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 442, train_loss = 14.053923112340271, train_acc = 0.9699580810433163\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 443, train_loss = 14.046818614006042, train_acc = 0.9701909641360037\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 444, train_loss = 14.047163107432425, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 445, train_loss = 14.04675793275237, train_acc = 0.9699580810433163\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 446, train_loss = 14.039849866181612, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 447, train_loss = 14.030056610703468, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 448, train_loss = 14.033127567730844, train_acc = 0.9703074056823474\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 449, train_loss = 14.022106226533651, train_acc = 0.9699580810433163\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 450, train_loss = 14.023976225405931, train_acc = 0.9698416394969726\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 451, train_loss = 14.01887692231685, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 452, train_loss = 14.005274173803627, train_acc = 0.9699580810433163\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 453, train_loss = 13.994564468972385, train_acc = 0.9699580810433163\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 454, train_loss = 14.004671182483435, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 455, train_loss = 14.001816548407078, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 456, train_loss = 13.996339052915573, train_acc = 0.9703074056823474\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 457, train_loss = 13.986334130167961, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 458, train_loss = 13.971381112001836, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 459, train_loss = 13.988249003887177, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 460, train_loss = 13.972171084024012, train_acc = 0.9704238472286912\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 461, train_loss = 13.970460410229862, train_acc = 0.9701909641360037\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 462, train_loss = 13.962300073355436, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 463, train_loss = 13.95836626086384, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 464, train_loss = 13.946145414374769, train_acc = 0.9701909641360037\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 465, train_loss = 13.947329252958298, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 466, train_loss = 13.943480423651636, train_acc = 0.9701909641360037\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 467, train_loss = 13.940150771290064, train_acc = 0.9703074056823474\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 468, train_loss = 13.935522952117026, train_acc = 0.9701909641360037\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 469, train_loss = 13.94191284943372, train_acc = 0.9704238472286912\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 470, train_loss = 13.93460775911808, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 471, train_loss = 13.935028351843357, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 472, train_loss = 13.925353150814772, train_acc = 0.9701909641360037\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 473, train_loss = 13.918337397277355, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 474, train_loss = 13.908703435212374, train_acc = 0.9704238472286912\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 475, train_loss = 13.91039478033781, train_acc = 0.9701909641360037\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 476, train_loss = 13.910646095871925, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 477, train_loss = 13.90502338949591, train_acc = 0.9703074056823474\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 478, train_loss = 13.896078209392726, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 479, train_loss = 13.898494667373598, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 480, train_loss = 13.888422206044197, train_acc = 0.9701909641360037\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 481, train_loss = 13.884060381911695, train_acc = 0.9701909641360037\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 482, train_loss = 13.87454138416797, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 483, train_loss = 13.875826357863843, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 484, train_loss = 13.864834020845592, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 485, train_loss = 13.8615098670125, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 486, train_loss = 13.853201783262193, train_acc = 0.9703074056823474\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 487, train_loss = 13.84209459554404, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 488, train_loss = 13.848860814236104, train_acc = 0.9703074056823474\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 489, train_loss = 13.838254251517355, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 490, train_loss = 13.829984423704445, train_acc = 0.9704238472286912\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 491, train_loss = 13.820031255483627, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 492, train_loss = 13.830292624421418, train_acc = 0.9703074056823474\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 493, train_loss = 13.81975981965661, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 494, train_loss = 13.82234965916723, train_acc = 0.9703074056823474\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 495, train_loss = 13.810846102423966, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 496, train_loss = 13.807312822900712, train_acc = 0.9703074056823474\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 497, train_loss = 13.79524616803974, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 498, train_loss = 13.79996307566762, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 499, train_loss = 13.80463205743581, train_acc = 0.9703074056823474\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|████████████████▌                                                      | 7/30 [1:03:24<3:28:34, 544.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "8th- epoch: 0, train_loss = 129.7454314827919, train_acc = 0.7437121564974383\n",
      "test Acc 0.8654562383612663:\n",
      "8th- epoch: 1, train_loss = 61.05909751355648, train_acc = 0.8727293898462971\n",
      "test Acc 0.8961824953445066:\n",
      "8th- epoch: 2, train_loss = 50.69575181603432, train_acc = 0.8948532836516069\n",
      "test Acc 0.9078212290502793:\n",
      "8th- epoch: 3, train_loss = 45.432965695858, train_acc = 0.9044014904517932\n",
      "test Acc 0.9129422718808193:\n",
      "8th- epoch: 4, train_loss = 41.936932146549225, train_acc = 0.9109222170470423\n",
      "test Acc 0.9157355679702048:\n",
      "8th- epoch: 5, train_loss = 39.3415162563324, train_acc = 0.9149976711690732\n",
      "test Acc 0.9175977653631285:\n",
      "8th- epoch: 6, train_loss = 37.37713209539652, train_acc = 0.9197717745691663\n",
      "test Acc 0.9217877094972067:\n",
      "8th- epoch: 7, train_loss = 35.788429252803326, train_acc = 0.9230321378667908\n",
      "test Acc 0.9241154562383612:\n",
      "8th- epoch: 8, train_loss = 34.52210348844528, train_acc = 0.9241965533302282\n",
      "test Acc 0.9250465549348231:\n",
      "8th- epoch: 9, train_loss = 33.38323150575161, train_acc = 0.9258267349790406\n",
      "test Acc 0.9283054003724395:\n",
      "8th- epoch: 10, train_loss = 32.42276057600975, train_acc = 0.9292035398230089\n",
      "test Acc 0.9287709497206704:\n",
      "8th- epoch: 11, train_loss = 31.57963514328003, train_acc = 0.9304843968327899\n",
      "test Acc 0.9292364990689013:\n",
      "8th- epoch: 12, train_loss = 30.83295861631632, train_acc = 0.931765253842571\n",
      "test Acc 0.9301675977653632:\n",
      "8th- epoch: 13, train_loss = 30.13324051350355, train_acc = 0.9325803446669771\n",
      "test Acc 0.9297020484171322:\n",
      "8th- epoch: 14, train_loss = 29.525807432830334, train_acc = 0.9332789939450395\n",
      "test Acc 0.9297020484171322:\n",
      "8th- epoch: 15, train_loss = 28.997138515114784, train_acc = 0.9349091755938519\n",
      "test Acc 0.931098696461825:\n",
      "8th- epoch: 16, train_loss = 28.5045066177845, train_acc = 0.9371215649743828\n",
      "test Acc 0.9320297951582868:\n",
      "8th- epoch: 17, train_loss = 28.03165838867426, train_acc = 0.9382859804378202\n",
      "test Acc 0.9334264432029795:\n",
      "8th- epoch: 18, train_loss = 27.593775257468224, train_acc = 0.9392175128085701\n",
      "test Acc 0.9334264432029795:\n",
      "8th- epoch: 19, train_loss = 27.20016336813569, train_acc = 0.9399161620866325\n",
      "test Acc 0.9334264432029795:\n",
      "8th- epoch: 20, train_loss = 26.83606543019414, train_acc = 0.9407312529110387\n",
      "test Acc 0.9334264432029795:\n",
      "8th- epoch: 21, train_loss = 26.5002916790545, train_acc = 0.941429902189101\n",
      "test Acc 0.9343575418994413:\n",
      "8th- epoch: 22, train_loss = 26.166088335216045, train_acc = 0.941895668374476\n",
      "test Acc 0.9343575418994413:\n",
      "8th- epoch: 23, train_loss = 25.856617115437984, train_acc = 0.9427107591988821\n",
      "test Acc 0.9343575418994413:\n",
      "8th- epoch: 24, train_loss = 25.587684966623783, train_acc = 0.9443409408476945\n",
      "test Acc 0.9343575418994413:\n",
      "8th- epoch: 25, train_loss = 25.32769550010562, train_acc = 0.945388914764788\n",
      "test Acc 0.9352886405959032:\n",
      "8th- epoch: 26, train_loss = 25.055522046983242, train_acc = 0.9460875640428504\n",
      "test Acc 0.9352886405959032:\n",
      "8th- epoch: 27, train_loss = 24.818712774664164, train_acc = 0.946786213320913\n",
      "test Acc 0.9352886405959032:\n",
      "8th- epoch: 28, train_loss = 24.613273970782757, train_acc = 0.9477177456916628\n",
      "test Acc 0.9366852886405959:\n",
      "8th- epoch: 29, train_loss = 24.39980099350214, train_acc = 0.9479506287843502\n",
      "test Acc 0.9366852886405959:\n",
      "8th- epoch: 30, train_loss = 24.20958912745118, train_acc = 0.9484163949697252\n",
      "test Acc 0.9366852886405959:\n",
      "8th- epoch: 31, train_loss = 24.022605128586292, train_acc = 0.9489986027014439\n",
      "test Acc 0.9371508379888268:\n",
      "8th- epoch: 32, train_loss = 23.852219369262457, train_acc = 0.9493479273404751\n",
      "test Acc 0.9371508379888268:\n",
      "8th- epoch: 33, train_loss = 23.665947414934635, train_acc = 0.9492314857941313\n",
      "test Acc 0.9376163873370578:\n",
      "8th- epoch: 34, train_loss = 23.48454037308693, train_acc = 0.9494643688868188\n",
      "test Acc 0.9376163873370578:\n",
      "8th- epoch: 35, train_loss = 23.330642703920603, train_acc = 0.9494643688868188\n",
      "test Acc 0.9376163873370578:\n",
      "8th- epoch: 36, train_loss = 23.16296560317278, train_acc = 0.9503959012575687\n",
      "test Acc 0.9371508379888268:\n",
      "8th- epoch: 37, train_loss = 23.004424817860126, train_acc = 0.9509781089892874\n",
      "test Acc 0.9371508379888268:\n",
      "8th- epoch: 38, train_loss = 22.863833136856556, train_acc = 0.9513274336283186\n",
      "test Acc 0.9371508379888268:\n",
      "8th- epoch: 39, train_loss = 22.71912619844079, train_acc = 0.9514438751746623\n",
      "test Acc 0.9371508379888268:\n",
      "8th- epoch: 40, train_loss = 22.59611826390028, train_acc = 0.951560316721006\n",
      "test Acc 0.9376163873370578:\n",
      "8th- epoch: 41, train_loss = 22.460903722792864, train_acc = 0.9517931998136935\n",
      "test Acc 0.9376163873370578:\n",
      "8th- epoch: 42, train_loss = 22.319724414497614, train_acc = 0.9522589659990685\n",
      "test Acc 0.9385474860335196:\n",
      "8th- epoch: 43, train_loss = 22.20161773264408, train_acc = 0.9521425244527247\n",
      "test Acc 0.9385474860335196:\n",
      "8th- epoch: 44, train_loss = 22.088060047477484, train_acc = 0.952491849091756\n",
      "test Acc 0.9385474860335196:\n",
      "8th- epoch: 45, train_loss = 21.982222355902195, train_acc = 0.9526082906380997\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 46, train_loss = 21.853809569031, train_acc = 0.9526082906380997\n",
      "test Acc 0.9390130353817505:\n",
      "8th- epoch: 47, train_loss = 21.7590363137424, train_acc = 0.9526082906380997\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 48, train_loss = 21.63295179605484, train_acc = 0.9530740568234746\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 49, train_loss = 21.541792821139097, train_acc = 0.9534233814625058\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 50, train_loss = 21.43370557948947, train_acc = 0.9534233814625058\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 51, train_loss = 21.33875949308276, train_acc = 0.9537727061015371\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 52, train_loss = 21.2338511608541, train_acc = 0.9537727061015371\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 53, train_loss = 21.15325266122818, train_acc = 0.9538891476478808\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 54, train_loss = 21.071717735379934, train_acc = 0.9540055891942245\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 55, train_loss = 20.99089115485549, train_acc = 0.9540055891942245\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 56, train_loss = 20.88620689511299, train_acc = 0.9540055891942245\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 57, train_loss = 20.79854085110128, train_acc = 0.9543549138332557\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 58, train_loss = 20.714648695662618, train_acc = 0.9547042384722869\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 59, train_loss = 20.6383413169533, train_acc = 0.9547042384722869\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 60, train_loss = 20.55726552195847, train_acc = 0.9547042384722869\n",
      "test Acc 0.9394785847299814:\n",
      "8th- epoch: 61, train_loss = 20.489876663312316, train_acc = 0.9548206800186306\n",
      "test Acc 0.9399441340782123:\n",
      "8th- epoch: 62, train_loss = 20.42279682867229, train_acc = 0.9551700046576619\n",
      "test Acc 0.9399441340782123:\n",
      "8th- epoch: 63, train_loss = 20.341069286689162, train_acc = 0.9554028877503493\n",
      "test Acc 0.9399441340782123:\n",
      "8th- epoch: 64, train_loss = 20.260346787050366, train_acc = 0.955519329296693\n",
      "test Acc 0.9399441340782123:\n",
      "8th- epoch: 65, train_loss = 20.2021522577852, train_acc = 0.9556357708430367\n",
      "test Acc 0.9399441340782123:\n",
      "8th- epoch: 66, train_loss = 20.12382259592414, train_acc = 0.955985095482068\n",
      "test Acc 0.9399441340782123:\n",
      "8th- epoch: 67, train_loss = 20.055647624656558, train_acc = 0.9563344201210993\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 68, train_loss = 19.993911372497678, train_acc = 0.956450861667443\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 69, train_loss = 19.933063687756658, train_acc = 0.956450861667443\n",
      "test Acc 0.9404096834264432:\n",
      "8th- epoch: 70, train_loss = 19.872246040031314, train_acc = 0.956450861667443\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 71, train_loss = 19.8222285695374, train_acc = 0.956450861667443\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 72, train_loss = 19.753877371549606, train_acc = 0.9565673032137867\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 73, train_loss = 19.70413839817047, train_acc = 0.9568001863064741\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 74, train_loss = 19.633459312841296, train_acc = 0.9566837447601304\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 75, train_loss = 19.57868011109531, train_acc = 0.9569166278528178\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 76, train_loss = 19.525087701156735, train_acc = 0.9566837447601304\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 77, train_loss = 19.487495398148894, train_acc = 0.9571495109455054\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 78, train_loss = 19.4326895121485, train_acc = 0.9573823940381928\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 79, train_loss = 19.379225933924317, train_acc = 0.9573823940381928\n",
      "test Acc 0.9408752327746741:\n",
      "8th- epoch: 80, train_loss = 19.32246045395732, train_acc = 0.9574988355845365\n",
      "test Acc 0.9413407821229051:\n",
      "8th- epoch: 81, train_loss = 19.26954592950642, train_acc = 0.9576152771308803\n",
      "test Acc 0.9413407821229051:\n",
      "8th- epoch: 82, train_loss = 19.212798370048404, train_acc = 0.9578481602235678\n",
      "test Acc 0.9413407821229051:\n",
      "8th- epoch: 83, train_loss = 19.17669495753944, train_acc = 0.9583139264089428\n",
      "test Acc 0.9418063314711359:\n",
      "8th- epoch: 84, train_loss = 19.136748960241675, train_acc = 0.9580810433162552\n",
      "test Acc 0.9418063314711359:\n",
      "8th- epoch: 85, train_loss = 19.08987340144813, train_acc = 0.9584303679552865\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 86, train_loss = 19.03214150853455, train_acc = 0.9584303679552865\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 87, train_loss = 18.98885808326304, train_acc = 0.9587796925943176\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 88, train_loss = 18.941140953451395, train_acc = 0.9586632510479739\n",
      "test Acc 0.9432029795158287:\n",
      "8th- epoch: 89, train_loss = 18.907069021835923, train_acc = 0.9590125756870052\n",
      "test Acc 0.9432029795158287:\n",
      "8th- epoch: 90, train_loss = 18.85164614766836, train_acc = 0.9590125756870052\n",
      "test Acc 0.9432029795158287:\n",
      "8th- epoch: 91, train_loss = 18.811033422127366, train_acc = 0.9590125756870052\n",
      "test Acc 0.9432029795158287:\n",
      "8th- epoch: 92, train_loss = 18.766870064660907, train_acc = 0.9593619003260363\n",
      "test Acc 0.9432029795158287:\n",
      "8th- epoch: 93, train_loss = 18.732973843812943, train_acc = 0.9593619003260363\n",
      "test Acc 0.9432029795158287:\n",
      "8th- epoch: 94, train_loss = 18.687657361850142, train_acc = 0.9593619003260363\n",
      "test Acc 0.9432029795158287:\n",
      "8th- epoch: 95, train_loss = 18.625765765085816, train_acc = 0.9593619003260363\n",
      "test Acc 0.9436685288640596:\n",
      "8th- epoch: 96, train_loss = 18.589808447286487, train_acc = 0.9593619003260363\n",
      "test Acc 0.9436685288640596:\n",
      "8th- epoch: 97, train_loss = 18.557032646611333, train_acc = 0.95947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "8th- epoch: 98, train_loss = 18.516619266942143, train_acc = 0.95947834187238\n",
      "test Acc 0.9436685288640596:\n",
      "8th- epoch: 99, train_loss = 18.478441750630736, train_acc = 0.9598276665114113\n",
      "test Acc 0.9432029795158287:\n",
      "8th- epoch: 100, train_loss = 18.44268485158682, train_acc = 0.9597112249650676\n",
      "test Acc 0.9436685288640596:\n",
      "8th- epoch: 101, train_loss = 18.39993198402226, train_acc = 0.9598276665114113\n",
      "test Acc 0.9445996275605214:\n",
      "8th- epoch: 102, train_loss = 18.361247995868325, train_acc = 0.9597112249650676\n",
      "test Acc 0.9441340782122905:\n",
      "8th- epoch: 103, train_loss = 18.3291823733598, train_acc = 0.9598276665114113\n",
      "test Acc 0.9445996275605214:\n",
      "8th- epoch: 104, train_loss = 18.299807170405984, train_acc = 0.9600605496040987\n",
      "test Acc 0.9445996275605214:\n",
      "8th- epoch: 105, train_loss = 18.259915813803673, train_acc = 0.959944108057755\n",
      "test Acc 0.9441340782122905:\n",
      "8th- epoch: 106, train_loss = 18.231211012229323, train_acc = 0.9600605496040987\n",
      "test Acc 0.9441340782122905:\n",
      "8th- epoch: 107, train_loss = 18.189884575083852, train_acc = 0.9601769911504425\n",
      "test Acc 0.9445996275605214:\n",
      "8th- epoch: 108, train_loss = 18.151808887720108, train_acc = 0.9602934326967862\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 109, train_loss = 18.130652274936438, train_acc = 0.9602934326967862\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 110, train_loss = 18.09260070323944, train_acc = 0.96040987424313\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 111, train_loss = 18.058091612532735, train_acc = 0.96040987424313\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 112, train_loss = 18.03394108451903, train_acc = 0.96040987424313\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 113, train_loss = 17.995493872091174, train_acc = 0.9605263157894737\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 114, train_loss = 17.964356003329158, train_acc = 0.96040987424313\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 115, train_loss = 17.930186016485095, train_acc = 0.9607591988821611\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 116, train_loss = 17.90263651870191, train_acc = 0.9607591988821611\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 117, train_loss = 17.875629080459476, train_acc = 0.9607591988821611\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 118, train_loss = 17.847238121554255, train_acc = 0.9608756404285049\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 119, train_loss = 17.813475966453552, train_acc = 0.9612249650675361\n",
      "test Acc 0.9441340782122905:\n",
      "8th- epoch: 120, train_loss = 17.776541735976934, train_acc = 0.9609920819748486\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 121, train_loss = 17.752058936282992, train_acc = 0.9613414066138798\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 122, train_loss = 17.731365382671356, train_acc = 0.9613414066138798\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 123, train_loss = 17.707230167463422, train_acc = 0.9613414066138798\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 124, train_loss = 17.67987652309239, train_acc = 0.9613414066138798\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 125, train_loss = 17.63827990926802, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 126, train_loss = 17.60710253752768, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 127, train_loss = 17.602265253663063, train_acc = 0.9615742897065673\n",
      "test Acc 0.9445996275605214:\n",
      "8th- epoch: 128, train_loss = 17.564170127734542, train_acc = 0.961690731252911\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 129, train_loss = 17.5296419095248, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 130, train_loss = 17.50793062709272, train_acc = 0.9619236143455985\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 131, train_loss = 17.49104538373649, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 132, train_loss = 17.45384613238275, train_acc = 0.9620400558919422\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 133, train_loss = 17.432506227865815, train_acc = 0.9619236143455985\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 134, train_loss = 17.408954614773393, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 135, train_loss = 17.383786937221885, train_acc = 0.9619236143455985\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 136, train_loss = 17.37074832059443, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 137, train_loss = 17.336271842941642, train_acc = 0.9620400558919422\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 138, train_loss = 17.319341948255897, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 139, train_loss = 17.29689459875226, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 140, train_loss = 17.282822351902723, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 141, train_loss = 17.248035684227943, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 142, train_loss = 17.226710041984916, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 143, train_loss = 17.207089265808463, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 144, train_loss = 17.179083436727524, train_acc = 0.9623893805309734\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 145, train_loss = 17.156915383413434, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 146, train_loss = 17.131093671545386, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 147, train_loss = 17.108743665739894, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 148, train_loss = 17.07840894162655, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 149, train_loss = 17.062770884484053, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 150, train_loss = 17.04253764823079, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 151, train_loss = 17.014757746830583, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "8th- epoch: 152, train_loss = 17.00496249087155, train_acc = 0.9625058220773172\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 153, train_loss = 16.972746713086963, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 154, train_loss = 16.953646548092365, train_acc = 0.9626222636236609\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 155, train_loss = 16.945859730243683, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 156, train_loss = 16.917840173467994, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 157, train_loss = 16.88977094180882, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 158, train_loss = 16.87966571189463, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 159, train_loss = 16.864419596269727, train_acc = 0.9626222636236609\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 160, train_loss = 16.833560720086098, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 161, train_loss = 16.82373709604144, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 162, train_loss = 16.7992892395705, train_acc = 0.9629715882626921\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 163, train_loss = 16.776397651061416, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 164, train_loss = 16.765191288664937, train_acc = 0.9629715882626921\n",
      "test Acc 0.9464618249534451:\n",
      "8th- epoch: 165, train_loss = 16.75237046740949, train_acc = 0.9629715882626921\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 166, train_loss = 16.73213088326156, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 167, train_loss = 16.707661068066955, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 168, train_loss = 16.687670366838574, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 169, train_loss = 16.676395343616605, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 170, train_loss = 16.651059683412313, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 171, train_loss = 16.637000923976302, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 172, train_loss = 16.60462182573974, train_acc = 0.9637866790870983\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 173, train_loss = 16.598323963582516, train_acc = 0.9636702375407545\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 174, train_loss = 16.575779056176543, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 175, train_loss = 16.569164603948593, train_acc = 0.9636702375407545\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 176, train_loss = 16.54164700768888, train_acc = 0.9640195621797858\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 177, train_loss = 16.53086257353425, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 178, train_loss = 16.512261871248484, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 179, train_loss = 16.50211045332253, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 180, train_loss = 16.477479100227356, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 181, train_loss = 16.460417402908206, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 182, train_loss = 16.446785647422075, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 183, train_loss = 16.428461780771613, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 184, train_loss = 16.415380727499723, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 185, train_loss = 16.38892954401672, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 186, train_loss = 16.386607376858592, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 187, train_loss = 16.369384521618485, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 188, train_loss = 16.34830375574529, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 189, train_loss = 16.335734302178025, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 190, train_loss = 16.31412136554718, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 191, train_loss = 16.303504502400756, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 192, train_loss = 16.288302212953568, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 193, train_loss = 16.266011463478208, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 194, train_loss = 16.25237938389182, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 195, train_loss = 16.244113078340888, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 196, train_loss = 16.220154400914907, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 197, train_loss = 16.21613041497767, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 198, train_loss = 16.19113806076348, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 199, train_loss = 16.181189762428403, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 200, train_loss = 16.166944915428758, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 201, train_loss = 16.161119870841503, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 202, train_loss = 16.134568721055984, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 203, train_loss = 16.12444702256471, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 204, train_loss = 16.112775688059628, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 205, train_loss = 16.103808714076877, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 206, train_loss = 16.078524137847126, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 207, train_loss = 16.077121811918914, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 208, train_loss = 16.060424205847085, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 209, train_loss = 16.046697109006345, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 210, train_loss = 16.030630646273494, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 211, train_loss = 16.015679360367358, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 212, train_loss = 16.0086591206491, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 213, train_loss = 15.999390758574009, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 214, train_loss = 15.985660564154387, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 215, train_loss = 15.966765608638525, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 216, train_loss = 15.948828763328493, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 217, train_loss = 15.94224229361862, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 218, train_loss = 15.928690592758358, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 219, train_loss = 15.908784638158977, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 220, train_loss = 15.897591757588089, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 221, train_loss = 15.884613218717277, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 222, train_loss = 15.875715265981853, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 223, train_loss = 15.859117367304862, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 224, train_loss = 15.853802632540464, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 225, train_loss = 15.836144968867302, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 226, train_loss = 15.82206033822149, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 227, train_loss = 15.814438682980835, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 228, train_loss = 15.798052188009024, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 229, train_loss = 15.784501909278333, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 230, train_loss = 15.776393151842058, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 231, train_loss = 15.76481540966779, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 232, train_loss = 15.754899431020021, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 233, train_loss = 15.739280547946692, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 234, train_loss = 15.723813336342573, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 235, train_loss = 15.709545620717108, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 236, train_loss = 15.708217590115964, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 237, train_loss = 15.695709637366235, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 238, train_loss = 15.684481728821993, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 239, train_loss = 15.66551664751023, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 240, train_loss = 15.654033243656158, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 241, train_loss = 15.65193269494921, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 242, train_loss = 15.634996798820794, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 243, train_loss = 15.62113553378731, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 244, train_loss = 15.612905082292855, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 245, train_loss = 15.600179269909859, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 246, train_loss = 15.594323240220547, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 247, train_loss = 15.573664491064847, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 248, train_loss = 15.566912490874529, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 249, train_loss = 15.561128380708396, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 250, train_loss = 15.546218927949667, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 251, train_loss = 15.532096701674163, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 252, train_loss = 15.530261819250882, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 253, train_loss = 15.504363323561847, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 254, train_loss = 15.494577314704657, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 255, train_loss = 15.488957516849041, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 256, train_loss = 15.475741733796895, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 257, train_loss = 15.466707929037511, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 258, train_loss = 15.46220560465008, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 259, train_loss = 15.454773157835007, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 260, train_loss = 15.43864378053695, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 261, train_loss = 15.424332129769027, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 262, train_loss = 15.421746524982154, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 263, train_loss = 15.405594523064792, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 264, train_loss = 15.3953687986359, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 265, train_loss = 15.392458559013903, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 266, train_loss = 15.374218087643385, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 267, train_loss = 15.372895414941013, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 268, train_loss = 15.354387915693223, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 269, train_loss = 15.350747055374086, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 270, train_loss = 15.345332853496075, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 271, train_loss = 15.329000984318554, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 272, train_loss = 15.323528304696083, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 273, train_loss = 15.309670695103705, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 274, train_loss = 15.306484934873879, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 275, train_loss = 15.29863711539656, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 276, train_loss = 15.286715824157, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 277, train_loss = 15.281293128617108, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 278, train_loss = 15.268439408391714, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 279, train_loss = 15.263284186832607, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 280, train_loss = 15.246593742631376, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 281, train_loss = 15.23703132942319, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 282, train_loss = 15.233066485263407, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 283, train_loss = 15.222001924179494, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 284, train_loss = 15.208444085903466, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 285, train_loss = 15.20765735115856, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 286, train_loss = 15.191969688981771, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 287, train_loss = 15.18765699584037, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 288, train_loss = 15.186159323900938, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 289, train_loss = 15.16748973634094, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 290, train_loss = 15.165799801237881, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 291, train_loss = 15.155110157094896, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 292, train_loss = 15.143061351962388, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 293, train_loss = 15.141896676272154, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 294, train_loss = 15.126217558048666, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 295, train_loss = 15.122906118631363, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 296, train_loss = 15.10597616713494, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 297, train_loss = 15.09981144964695, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 298, train_loss = 15.095208407379687, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 299, train_loss = 15.086981347762048, train_acc = 0.9662319515603167\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 300, train_loss = 15.079387459903955, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 301, train_loss = 15.069807427935302, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 302, train_loss = 15.05872220825404, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 303, train_loss = 15.051551279611886, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 304, train_loss = 15.039174241013825, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 305, train_loss = 15.042131561785936, train_acc = 0.9662319515603167\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 306, train_loss = 15.029331971891224, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 307, train_loss = 15.022592556662858, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 308, train_loss = 15.0119488844648, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 309, train_loss = 15.0038871942088, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 310, train_loss = 15.00124069582671, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 311, train_loss = 14.988024462014437, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 312, train_loss = 14.98106852825731, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 313, train_loss = 14.97470426093787, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 314, train_loss = 14.969563432969153, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 315, train_loss = 14.95834186207503, train_acc = 0.966581276199348\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 316, train_loss = 14.948764652013779, train_acc = 0.966581276199348\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 317, train_loss = 14.945267774164677, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 318, train_loss = 14.939927532337606, train_acc = 0.966581276199348\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 319, train_loss = 14.930479084141552, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 320, train_loss = 14.920217994600534, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 321, train_loss = 14.913180126808584, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 322, train_loss = 14.90943444147706, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 323, train_loss = 14.89761274959892, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 324, train_loss = 14.892227259464562, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 325, train_loss = 14.882217626087368, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 326, train_loss = 14.873436880297959, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 327, train_loss = 14.86866934131831, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 328, train_loss = 14.85541196539998, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 329, train_loss = 14.856147569604218, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 330, train_loss = 14.849662139080465, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 331, train_loss = 14.83932277560234, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 332, train_loss = 14.83960983529687, train_acc = 0.9669306008383791\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 333, train_loss = 14.827156140469015, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 334, train_loss = 14.826362284831703, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 335, train_loss = 14.812371969223022, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 336, train_loss = 14.806334768421948, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 337, train_loss = 14.795192555524409, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 338, train_loss = 14.795228370465338, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 339, train_loss = 14.778414719738066, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 340, train_loss = 14.778402909636497, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 341, train_loss = 14.767764285206795, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 342, train_loss = 14.7634948939085, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 343, train_loss = 14.756585114635527, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 344, train_loss = 14.75260306801647, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 345, train_loss = 14.74230831116438, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 346, train_loss = 14.732125904411077, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 347, train_loss = 14.731617667712271, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 348, train_loss = 14.71976076811552, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 349, train_loss = 14.717629765160382, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 350, train_loss = 14.706092714332044, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 351, train_loss = 14.704017724841833, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 352, train_loss = 14.69119817391038, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 353, train_loss = 14.692494711838663, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 354, train_loss = 14.680612639524043, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 355, train_loss = 14.673698072321713, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 356, train_loss = 14.675810337997973, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 357, train_loss = 14.667257312685251, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 358, train_loss = 14.656020055525005, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 359, train_loss = 14.652432975359261, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 360, train_loss = 14.649371638894081, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 361, train_loss = 14.63494162634015, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 362, train_loss = 14.629950289614499, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 363, train_loss = 14.624038157053292, train_acc = 0.9677456916627852\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 364, train_loss = 14.627516196109354, train_acc = 0.9677456916627852\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 365, train_loss = 14.611438419669867, train_acc = 0.9678621332091291\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 366, train_loss = 14.611177596263587, train_acc = 0.9677456916627852\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 367, train_loss = 14.593978997319937, train_acc = 0.9678621332091291\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 368, train_loss = 14.600332672707736, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 369, train_loss = 14.584267404861748, train_acc = 0.9678621332091291\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 370, train_loss = 14.578929592855275, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 371, train_loss = 14.57723059784621, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 372, train_loss = 14.572053187526762, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 373, train_loss = 14.559294025413692, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 374, train_loss = 14.558151979930699, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 375, train_loss = 14.545493143610656, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 376, train_loss = 14.537477221339941, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 377, train_loss = 14.534703007899225, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 378, train_loss = 14.532359787262976, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 379, train_loss = 14.524800318293273, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 380, train_loss = 14.52222967427224, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 381, train_loss = 14.515659800730646, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 382, train_loss = 14.512015686370432, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 383, train_loss = 14.504027236253023, train_acc = 0.9683278993945039\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 384, train_loss = 14.504059038124979, train_acc = 0.9683278993945039\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 385, train_loss = 14.488376938737929, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 386, train_loss = 14.481387737207115, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 387, train_loss = 14.476806629449129, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 388, train_loss = 14.471592116169631, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 389, train_loss = 14.471886561252177, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 390, train_loss = 14.469002897851169, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 391, train_loss = 14.462385046295822, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 392, train_loss = 14.453233744949102, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 393, train_loss = 14.449452639557421, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 394, train_loss = 14.439351924695075, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 395, train_loss = 14.43140257615596, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 396, train_loss = 14.424040491692722, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 397, train_loss = 14.428498234599829, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 398, train_loss = 14.419513407163322, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 399, train_loss = 14.412998291663826, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 400, train_loss = 14.4076196430251, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 401, train_loss = 14.405222401954234, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 402, train_loss = 14.393726809881628, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 403, train_loss = 14.393349774181843, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 404, train_loss = 14.389931126497686, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 405, train_loss = 14.386483809910715, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 406, train_loss = 14.379139843396842, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 407, train_loss = 14.372108374722302, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 408, train_loss = 14.370216845534742, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 409, train_loss = 14.363762185908854, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 410, train_loss = 14.358572885394096, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 411, train_loss = 14.350803427398205, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 412, train_loss = 14.346506698988378, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 413, train_loss = 14.3389609195292, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 414, train_loss = 14.331057815812528, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 415, train_loss = 14.322236128151417, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 416, train_loss = 14.323493110947311, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 417, train_loss = 14.31540480721742, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 418, train_loss = 14.305779081769288, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 419, train_loss = 14.309472691267729, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 420, train_loss = 14.304964747279882, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 421, train_loss = 14.301841296255589, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 422, train_loss = 14.29604364093393, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 423, train_loss = 14.291872221976519, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 424, train_loss = 14.291781918145716, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 425, train_loss = 14.276339747011662, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 426, train_loss = 14.271928717382252, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 427, train_loss = 14.268020221032202, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 428, train_loss = 14.264885760843754, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 429, train_loss = 14.265286300331354, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 430, train_loss = 14.25915418099612, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 431, train_loss = 14.25262638553977, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 432, train_loss = 14.24431222397834, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 433, train_loss = 14.246129516512156, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 434, train_loss = 14.238809391856194, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 435, train_loss = 14.233999222517014, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 436, train_loss = 14.225454987026751, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 437, train_loss = 14.218517911620438, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 438, train_loss = 14.218456369824708, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 439, train_loss = 14.216150435619056, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 440, train_loss = 14.214775768108666, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 441, train_loss = 14.20464803557843, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 442, train_loss = 14.201062228530645, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 443, train_loss = 14.193480952642858, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 444, train_loss = 14.193080320954323, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 445, train_loss = 14.187785630114377, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 446, train_loss = 14.180721056647599, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 447, train_loss = 14.176138932816684, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 448, train_loss = 14.173438449390233, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 449, train_loss = 14.164945280645043, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 450, train_loss = 14.16275917366147, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 451, train_loss = 14.158391274511814, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 452, train_loss = 14.15331554505974, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 453, train_loss = 14.148718459997326, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 454, train_loss = 14.144757810980082, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 455, train_loss = 14.13989657908678, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 456, train_loss = 14.135742788668722, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 457, train_loss = 14.129971539136022, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 458, train_loss = 14.127762497868389, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 459, train_loss = 14.12278734985739, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 460, train_loss = 14.118082862347364, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 461, train_loss = 14.112697683274746, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 462, train_loss = 14.103937441017479, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 463, train_loss = 14.104375313967466, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 464, train_loss = 14.103425208479166, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 465, train_loss = 14.094062571879476, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 466, train_loss = 14.09406423335895, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 467, train_loss = 14.086113614495844, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 468, train_loss = 14.085468912031502, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 469, train_loss = 14.08038878440857, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 470, train_loss = 14.074607914779335, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 471, train_loss = 14.077626843005419, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 472, train_loss = 14.065522400196642, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 473, train_loss = 14.066474597901106, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 474, train_loss = 14.057915654033422, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 475, train_loss = 14.053706029895693, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 476, train_loss = 14.051704328507185, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 477, train_loss = 14.04905749624595, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 478, train_loss = 14.047866178210825, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 479, train_loss = 14.036605836357921, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 480, train_loss = 14.035174892749637, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 481, train_loss = 14.027700405567884, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 482, train_loss = 14.025933928787708, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 483, train_loss = 14.019138833042234, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 484, train_loss = 14.014508421067148, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 485, train_loss = 14.008601882960647, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 486, train_loss = 14.010479559656233, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 487, train_loss = 14.005427253898233, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 488, train_loss = 13.999878339469433, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 489, train_loss = 13.99984347447753, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 490, train_loss = 13.99408304458484, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 491, train_loss = 13.991426449269056, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 492, train_loss = 13.986467593815178, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 493, train_loss = 13.985368409659714, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 494, train_loss = 13.978184379637241, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 495, train_loss = 13.971379751805216, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 496, train_loss = 13.969829827547073, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 497, train_loss = 13.969054111745209, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 498, train_loss = 13.958964560180902, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 499, train_loss = 13.957596806343645, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██████████████████▉                                                    | 8/30 [1:12:30<3:19:45, 544.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "9th- epoch: 0, train_loss = 121.51958999037743, train_acc = 0.7550069864927806\n",
      "test Acc 0.8533519553072626:\n",
      "9th- epoch: 1, train_loss = 59.24321077764034, train_acc = 0.8773870517000466\n",
      "test Acc 0.8929236499068901:\n",
      "9th- epoch: 2, train_loss = 49.301661409437656, train_acc = 0.8996273870517001\n",
      "test Acc 0.9054934823091247:\n",
      "9th- epoch: 3, train_loss = 44.248012624680996, train_acc = 0.91022356776898\n",
      "test Acc 0.9138733705772812:\n",
      "9th- epoch: 4, train_loss = 40.889715261757374, train_acc = 0.9137168141592921\n",
      "test Acc 0.9171322160148976:\n",
      "9th- epoch: 5, train_loss = 38.38197169452906, train_acc = 0.9190731252911039\n",
      "test Acc 0.9199255121042831:\n",
      "9th- epoch: 6, train_loss = 36.54455430805683, train_acc = 0.9239636702375408\n",
      "test Acc 0.9217877094972067:\n",
      "9th- epoch: 7, train_loss = 34.97850799560547, train_acc = 0.9269911504424779\n",
      "test Acc 0.9231843575418994:\n",
      "9th- epoch: 8, train_loss = 33.73199563473463, train_acc = 0.9281555659059152\n",
      "test Acc 0.9227188081936686:\n",
      "9th- epoch: 9, train_loss = 32.646081276237965, train_acc = 0.930018630647415\n",
      "test Acc 0.925512104283054:\n",
      "9th- epoch: 10, train_loss = 31.707285679876804, train_acc = 0.9309501630181649\n",
      "test Acc 0.9245810055865922:\n",
      "9th- epoch: 11, train_loss = 30.88453870266676, train_acc = 0.9333954354913834\n",
      "test Acc 0.9283054003724395:\n",
      "9th- epoch: 12, train_loss = 30.160600639879704, train_acc = 0.9350256171401956\n",
      "test Acc 0.9283054003724395:\n",
      "9th- epoch: 13, train_loss = 29.515050277113914, train_acc = 0.9356078248719143\n",
      "test Acc 0.930633147113594:\n",
      "9th- epoch: 14, train_loss = 28.94774879515171, train_acc = 0.9375873311597578\n",
      "test Acc 0.9320297951582868:\n",
      "9th- epoch: 15, train_loss = 28.428065359592438, train_acc = 0.9385188635305077\n",
      "test Acc 0.9320297951582868:\n",
      "9th- epoch: 16, train_loss = 27.943542167544365, train_acc = 0.9403819282720075\n",
      "test Acc 0.9324953445065177:\n",
      "9th- epoch: 17, train_loss = 27.5271100923419, train_acc = 0.9408476944573824\n",
      "test Acc 0.9334264432029795:\n",
      "9th- epoch: 18, train_loss = 27.10001926124096, train_acc = 0.9415463437354448\n",
      "test Acc 0.9334264432029795:\n",
      "9th- epoch: 19, train_loss = 26.7089319601655, train_acc = 0.9420121099208197\n",
      "test Acc 0.9334264432029795:\n",
      "9th- epoch: 20, train_loss = 26.358823627233505, train_acc = 0.9424778761061947\n",
      "test Acc 0.9338919925512105:\n",
      "9th- epoch: 21, train_loss = 25.988415248692036, train_acc = 0.9438751746623195\n",
      "test Acc 0.9334264432029795:\n",
      "9th- epoch: 22, train_loss = 25.68743048608303, train_acc = 0.944108057755007\n",
      "test Acc 0.9343575418994413:\n",
      "9th- epoch: 23, train_loss = 25.42062897980213, train_acc = 0.9444573823940382\n",
      "test Acc 0.9343575418994413:\n",
      "9th- epoch: 24, train_loss = 25.136699445545673, train_acc = 0.9450395901257569\n",
      "test Acc 0.9343575418994413:\n",
      "9th- epoch: 25, train_loss = 24.865628980100155, train_acc = 0.9462040055891943\n",
      "test Acc 0.9348230912476723:\n",
      "9th- epoch: 26, train_loss = 24.615840651094913, train_acc = 0.946786213320913\n",
      "test Acc 0.9348230912476723:\n",
      "9th- epoch: 27, train_loss = 24.403241746127605, train_acc = 0.9471355379599441\n",
      "test Acc 0.9357541899441341:\n",
      "9th- epoch: 28, train_loss = 24.179166808724403, train_acc = 0.9474848625989754\n",
      "test Acc 0.9357541899441341:\n",
      "9th- epoch: 29, train_loss = 23.955263055860996, train_acc = 0.9478341872380065\n",
      "test Acc 0.936219739292365:\n",
      "9th- epoch: 30, train_loss = 23.76272976025939, train_acc = 0.948067070330694\n",
      "test Acc 0.9357541899441341:\n",
      "9th- epoch: 31, train_loss = 23.56923222914338, train_acc = 0.9486492780624126\n",
      "test Acc 0.9366852886405959:\n",
      "9th- epoch: 32, train_loss = 23.391716580837965, train_acc = 0.9493479273404751\n",
      "test Acc 0.9371508379888268:\n",
      "9th- epoch: 33, train_loss = 23.22367884963751, train_acc = 0.9495808104331626\n",
      "test Acc 0.9371508379888268:\n",
      "9th- epoch: 34, train_loss = 23.065688688308, train_acc = 0.94981369352585\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 35, train_loss = 22.905225306749344, train_acc = 0.9501630181648812\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 36, train_loss = 22.744760617613792, train_acc = 0.950279459711225\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 37, train_loss = 22.614464543759823, train_acc = 0.950279459711225\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 38, train_loss = 22.467753872275352, train_acc = 0.9503959012575687\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 39, train_loss = 22.334559682756662, train_acc = 0.9506287843502562\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 40, train_loss = 22.203953344374895, train_acc = 0.9508616674429436\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 41, train_loss = 22.078471079468727, train_acc = 0.9510945505356311\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 42, train_loss = 21.955660205334425, train_acc = 0.9512109920819748\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 43, train_loss = 21.835928838700056, train_acc = 0.9514438751746623\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 44, train_loss = 21.718544740229845, train_acc = 0.9517931998136935\n",
      "test Acc 0.9380819366852886:\n",
      "9th- epoch: 45, train_loss = 21.600442960858345, train_acc = 0.952026082906381\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 46, train_loss = 21.491843428462744, train_acc = 0.9521425244527247\n",
      "test Acc 0.9390130353817505:\n",
      "9th- epoch: 47, train_loss = 21.379198841750622, train_acc = 0.952491849091756\n",
      "test Acc 0.9394785847299814:\n",
      "9th- epoch: 48, train_loss = 21.28092012926936, train_acc = 0.9527247321844434\n",
      "test Acc 0.9394785847299814:\n",
      "9th- epoch: 49, train_loss = 21.185760725289583, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n",
      "9th- epoch: 50, train_loss = 21.08048728480935, train_acc = 0.9530740568234746\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 51, train_loss = 20.992715146392584, train_acc = 0.9534233814625058\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 52, train_loss = 20.893084675073624, train_acc = 0.9537727061015371\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 53, train_loss = 20.807880107313395, train_acc = 0.9536562645551933\n",
      "test Acc 0.9408752327746741:\n",
      "9th- epoch: 54, train_loss = 20.730521582067013, train_acc = 0.9536562645551933\n",
      "test Acc 0.9408752327746741:\n",
      "9th- epoch: 55, train_loss = 20.635920077562332, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "9th- epoch: 56, train_loss = 20.561228431761265, train_acc = 0.9541220307405682\n",
      "test Acc 0.9413407821229051:\n",
      "9th- epoch: 57, train_loss = 20.47771180793643, train_acc = 0.9544713553795995\n",
      "test Acc 0.9422718808193669:\n",
      "9th- epoch: 58, train_loss = 20.40271658450365, train_acc = 0.9544713553795995\n",
      "test Acc 0.9413407821229051:\n",
      "9th- epoch: 59, train_loss = 20.317388471215963, train_acc = 0.9547042384722869\n",
      "test Acc 0.9422718808193669:\n",
      "9th- epoch: 60, train_loss = 20.250363830477, train_acc = 0.9547042384722869\n",
      "test Acc 0.9422718808193669:\n",
      "9th- epoch: 61, train_loss = 20.18090157583356, train_acc = 0.9547042384722869\n",
      "test Acc 0.9422718808193669:\n",
      "9th- epoch: 62, train_loss = 20.105064120143652, train_acc = 0.9549371215649743\n",
      "test Acc 0.9422718808193669:\n",
      "9th- epoch: 63, train_loss = 20.024642296135426, train_acc = 0.9550535631113182\n",
      "test Acc 0.9422718808193669:\n",
      "9th- epoch: 64, train_loss = 19.964071828871965, train_acc = 0.9556357708430367\n",
      "test Acc 0.9422718808193669:\n",
      "9th- epoch: 65, train_loss = 19.885311521589756, train_acc = 0.9558686539357243\n",
      "test Acc 0.9422718808193669:\n",
      "9th- epoch: 66, train_loss = 19.829239144921303, train_acc = 0.9561015370284117\n",
      "test Acc 0.9422718808193669:\n",
      "9th- epoch: 67, train_loss = 19.76280141249299, train_acc = 0.9562179785747554\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 68, train_loss = 19.69213028997183, train_acc = 0.9568001863064741\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 69, train_loss = 19.623960684984922, train_acc = 0.9566837447601304\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 70, train_loss = 19.557576164603233, train_acc = 0.9571495109455054\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 71, train_loss = 19.50005915388465, train_acc = 0.9570330693991617\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 72, train_loss = 19.44207140803337, train_acc = 0.9569166278528178\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 73, train_loss = 19.392855394631624, train_acc = 0.9573823940381928\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 74, train_loss = 19.3343854136765, train_acc = 0.9574988355845365\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 75, train_loss = 19.27103064954281, train_acc = 0.9576152771308803\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 76, train_loss = 19.218715403228998, train_acc = 0.9577317186772241\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 77, train_loss = 19.162056662142277, train_acc = 0.9578481602235678\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 78, train_loss = 19.11800629273057, train_acc = 0.9583139264089428\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 79, train_loss = 19.061411041766405, train_acc = 0.9581974848625989\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 80, train_loss = 19.007822792977095, train_acc = 0.9584303679552865\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 81, train_loss = 18.96523056551814, train_acc = 0.9585468095016302\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 82, train_loss = 18.918727599084377, train_acc = 0.9587796925943176\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 83, train_loss = 18.874894697219133, train_acc = 0.9587796925943176\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 84, train_loss = 18.817658320069313, train_acc = 0.9588961341406614\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 85, train_loss = 18.767415910959244, train_acc = 0.9588961341406614\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 86, train_loss = 18.719410430639982, train_acc = 0.9591290172333489\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 87, train_loss = 18.685805659741163, train_acc = 0.9591290172333489\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 88, train_loss = 18.63221862912178, train_acc = 0.9591290172333489\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 89, train_loss = 18.592549789696932, train_acc = 0.9591290172333489\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 90, train_loss = 18.5471665635705, train_acc = 0.9593619003260363\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 91, train_loss = 18.490748718380928, train_acc = 0.9592454587796926\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 92, train_loss = 18.461350437253714, train_acc = 0.9593619003260363\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 93, train_loss = 18.415813732892275, train_acc = 0.9593619003260363\n",
      "test Acc 0.9427374301675978:\n",
      "9th- epoch: 94, train_loss = 18.373626202344894, train_acc = 0.95947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 95, train_loss = 18.325601030141115, train_acc = 0.95947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 96, train_loss = 18.29456326365471, train_acc = 0.9593619003260363\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 97, train_loss = 18.25758197531104, train_acc = 0.95947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 98, train_loss = 18.20268977433443, train_acc = 0.9595947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 99, train_loss = 18.169476818293333, train_acc = 0.9595947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 100, train_loss = 18.134887609630823, train_acc = 0.95947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 101, train_loss = 18.097001004964113, train_acc = 0.9597112249650676\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 102, train_loss = 18.060329526662827, train_acc = 0.9598276665114113\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 103, train_loss = 18.014468863606453, train_acc = 0.959944108057755\n",
      "test Acc 0.9436685288640596:\n",
      "9th- epoch: 104, train_loss = 17.98209087178111, train_acc = 0.9598276665114113\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 105, train_loss = 17.953282482922077, train_acc = 0.959944108057755\n",
      "test Acc 0.9436685288640596:\n",
      "9th- epoch: 106, train_loss = 17.919925823807716, train_acc = 0.959944108057755\n",
      "test Acc 0.9436685288640596:\n",
      "9th- epoch: 107, train_loss = 17.870984807610512, train_acc = 0.9600605496040987\n",
      "test Acc 0.9432029795158287:\n",
      "9th- epoch: 108, train_loss = 17.84703827649355, train_acc = 0.9600605496040987\n",
      "test Acc 0.9441340782122905:\n",
      "9th- epoch: 109, train_loss = 17.80742058157921, train_acc = 0.9600605496040987\n",
      "test Acc 0.9436685288640596:\n",
      "9th- epoch: 110, train_loss = 17.772634457796812, train_acc = 0.9601769911504425\n",
      "test Acc 0.9441340782122905:\n",
      "9th- epoch: 111, train_loss = 17.740129079669714, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "9th- epoch: 112, train_loss = 17.70933424681425, train_acc = 0.9602934326967862\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 113, train_loss = 17.675136618316174, train_acc = 0.96040987424313\n",
      "test Acc 0.9441340782122905:\n",
      "9th- epoch: 114, train_loss = 17.65112369135022, train_acc = 0.96040987424313\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 115, train_loss = 17.614576436579227, train_acc = 0.96040987424313\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 116, train_loss = 17.58833223953843, train_acc = 0.96040987424313\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 117, train_loss = 17.555602837353945, train_acc = 0.96040987424313\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 118, train_loss = 17.526877161115408, train_acc = 0.9606427573358174\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 119, train_loss = 17.503261283040047, train_acc = 0.9607591988821611\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 120, train_loss = 17.47043316066265, train_acc = 0.9608756404285049\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 121, train_loss = 17.43607972562313, train_acc = 0.9607591988821611\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 122, train_loss = 17.40563741698861, train_acc = 0.9609920819748486\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 123, train_loss = 17.36990851536393, train_acc = 0.9613414066138798\n",
      "test Acc 0.9450651769087524:\n",
      "9th- epoch: 124, train_loss = 17.352151611819863, train_acc = 0.9614578481602236\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 125, train_loss = 17.320891246199608, train_acc = 0.961690731252911\n",
      "test Acc 0.9450651769087524:\n",
      "9th- epoch: 126, train_loss = 17.286920903250575, train_acc = 0.961690731252911\n",
      "test Acc 0.9450651769087524:\n",
      "9th- epoch: 127, train_loss = 17.271899102255702, train_acc = 0.961690731252911\n",
      "test Acc 0.9450651769087524:\n",
      "9th- epoch: 128, train_loss = 17.241918679326773, train_acc = 0.9618071727992548\n",
      "test Acc 0.9450651769087524:\n",
      "9th- epoch: 129, train_loss = 17.208070935681462, train_acc = 0.9618071727992548\n",
      "test Acc 0.9450651769087524:\n",
      "9th- epoch: 130, train_loss = 17.184709187597036, train_acc = 0.9619236143455985\n",
      "test Acc 0.9450651769087524:\n",
      "9th- epoch: 131, train_loss = 17.153497176244855, train_acc = 0.962156497438286\n",
      "test Acc 0.9450651769087524:\n",
      "9th- epoch: 132, train_loss = 17.132173663005233, train_acc = 0.962156497438286\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 133, train_loss = 17.111625326797366, train_acc = 0.9620400558919422\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 134, train_loss = 17.086135195568204, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 135, train_loss = 17.056969553232193, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 136, train_loss = 17.039238713681698, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 137, train_loss = 17.020646907389164, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 138, train_loss = 16.984420774504542, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 139, train_loss = 16.963413663208485, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 140, train_loss = 16.93962911888957, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 141, train_loss = 16.91622369363904, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 142, train_loss = 16.890417970716953, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 143, train_loss = 16.87235095538199, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 144, train_loss = 16.846127400174737, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 145, train_loss = 16.817860981449485, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 146, train_loss = 16.791918590664864, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 147, train_loss = 16.779008416458964, train_acc = 0.9633209129017233\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 148, train_loss = 16.757209548726678, train_acc = 0.9633209129017233\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 149, train_loss = 16.73463685438037, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 150, train_loss = 16.716545658186078, train_acc = 0.9633209129017233\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 151, train_loss = 16.692022928968072, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 152, train_loss = 16.672588234767318, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 153, train_loss = 16.650452725589275, train_acc = 0.9633209129017233\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 154, train_loss = 16.626568725332618, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 155, train_loss = 16.60512788966298, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 156, train_loss = 16.589863726869226, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 157, train_loss = 16.56538824364543, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 158, train_loss = 16.55113455839455, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 159, train_loss = 16.525297541171312, train_acc = 0.9635537959944108\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 160, train_loss = 16.508930211886764, train_acc = 0.9635537959944108\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 161, train_loss = 16.49084396660328, train_acc = 0.9636702375407545\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 162, train_loss = 16.47392519749701, train_acc = 0.9636702375407545\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 163, train_loss = 16.45427972264588, train_acc = 0.9636702375407545\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 164, train_loss = 16.433302434161305, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 165, train_loss = 16.417824575677514, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 166, train_loss = 16.395419996231794, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 167, train_loss = 16.37202732078731, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 168, train_loss = 16.360350849106908, train_acc = 0.963903120633442\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 169, train_loss = 16.347046960145235, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 170, train_loss = 16.332606168463826, train_acc = 0.963903120633442\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 171, train_loss = 16.30849640071392, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 172, train_loss = 16.291030257940292, train_acc = 0.9641360037261295\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 173, train_loss = 16.270058328285813, train_acc = 0.963903120633442\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 174, train_loss = 16.259226623922586, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 175, train_loss = 16.24265473149717, train_acc = 0.9641360037261295\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 176, train_loss = 16.219125201925635, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 177, train_loss = 16.20080258883536, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 178, train_loss = 16.19156271032989, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 179, train_loss = 16.171967312693596, train_acc = 0.9644853283651607\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 180, train_loss = 16.156494887545705, train_acc = 0.9643688868188169\n",
      "test Acc 0.9464618249534451:\n",
      "9th- epoch: 181, train_loss = 16.150542967021465, train_acc = 0.9643688868188169\n",
      "test Acc 0.946927374301676:\n",
      "9th- epoch: 182, train_loss = 16.121878504753113, train_acc = 0.9643688868188169\n",
      "test Acc 0.946927374301676:\n",
      "9th- epoch: 183, train_loss = 16.101946998387575, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "9th- epoch: 184, train_loss = 16.086176050826907, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "9th- epoch: 185, train_loss = 16.071818994358182, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "9th- epoch: 186, train_loss = 16.06445020996034, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 187, train_loss = 16.041085727512836, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 188, train_loss = 16.02888194285333, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 189, train_loss = 16.008507654070854, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 190, train_loss = 15.995542496442795, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 191, train_loss = 15.986961927264929, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 192, train_loss = 15.967846799641848, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 193, train_loss = 15.953689061105251, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 194, train_loss = 15.935950556769967, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 195, train_loss = 15.91980180889368, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 196, train_loss = 15.90739293396473, train_acc = 0.9650675360968793\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 197, train_loss = 15.891235990449786, train_acc = 0.9650675360968793\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 198, train_loss = 15.878931449726224, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 199, train_loss = 15.861384686082602, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 200, train_loss = 15.849100204184651, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 201, train_loss = 15.829231368377805, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 202, train_loss = 15.815239544957876, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 203, train_loss = 15.812200270593166, train_acc = 0.9650675360968793\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 204, train_loss = 15.789495430886745, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 205, train_loss = 15.779670998454094, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 206, train_loss = 15.764227142557502, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 207, train_loss = 15.755207169800997, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 208, train_loss = 15.734950156882405, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 209, train_loss = 15.72435106150806, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 210, train_loss = 15.715034829452634, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 211, train_loss = 15.698977505788207, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 212, train_loss = 15.685178654268384, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 213, train_loss = 15.673362648114562, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 214, train_loss = 15.66066368110478, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 215, train_loss = 15.646476970985532, train_acc = 0.965649743828598\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 216, train_loss = 15.635388663038611, train_acc = 0.965649743828598\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 217, train_loss = 15.626281395554543, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 218, train_loss = 15.605132974684238, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 219, train_loss = 15.598839446902275, train_acc = 0.9658826269212856\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 220, train_loss = 15.586788738146424, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 221, train_loss = 15.573452973738313, train_acc = 0.9659990684676293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 222, train_loss = 15.55776690505445, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 223, train_loss = 15.542839469388127, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 224, train_loss = 15.53874565474689, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 225, train_loss = 15.519497774541378, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 226, train_loss = 15.512384420260787, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 227, train_loss = 15.494974618777633, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "9th- epoch: 228, train_loss = 15.489962752908468, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 229, train_loss = 15.47536158747971, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 230, train_loss = 15.457307187840343, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 231, train_loss = 15.448529159650207, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 232, train_loss = 15.43479117192328, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 233, train_loss = 15.425817642360926, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 234, train_loss = 15.41749113611877, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 235, train_loss = 15.399137942120433, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 236, train_loss = 15.396390063688159, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 237, train_loss = 15.381970452144742, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 238, train_loss = 15.369945406913757, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 239, train_loss = 15.360596358776093, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 240, train_loss = 15.351776717230678, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 241, train_loss = 15.331758646294475, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 242, train_loss = 15.324964029714465, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 243, train_loss = 15.316692711785436, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 244, train_loss = 15.305089609697461, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 245, train_loss = 15.290348920971155, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 246, train_loss = 15.282549418509007, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 247, train_loss = 15.27693440951407, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 248, train_loss = 15.257784401997924, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 249, train_loss = 15.250892654061317, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 250, train_loss = 15.237233428284526, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 251, train_loss = 15.230959303677082, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 252, train_loss = 15.218485213816166, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 253, train_loss = 15.210904095321894, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 254, train_loss = 15.200049897655845, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 255, train_loss = 15.189671449363232, train_acc = 0.9662319515603167\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 256, train_loss = 15.180281730368733, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 257, train_loss = 15.17044566757977, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 258, train_loss = 15.161829369142652, train_acc = 0.966581276199348\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 259, train_loss = 15.152372358366847, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 260, train_loss = 15.13810421526432, train_acc = 0.966581276199348\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 261, train_loss = 15.12973315641284, train_acc = 0.966581276199348\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 262, train_loss = 15.12523009441793, train_acc = 0.966581276199348\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 263, train_loss = 15.111336896196008, train_acc = 0.966581276199348\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 264, train_loss = 15.105301463976502, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 265, train_loss = 15.092501638457179, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 266, train_loss = 15.082984222099185, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 267, train_loss = 15.07957704178989, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 268, train_loss = 15.068595131859183, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 269, train_loss = 15.056972783058882, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 270, train_loss = 15.047468656674027, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 271, train_loss = 15.039858549833298, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 272, train_loss = 15.034836621955037, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 273, train_loss = 15.02191144041717, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 274, train_loss = 15.012308679521084, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 275, train_loss = 15.004209965467453, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 276, train_loss = 14.9970941003412, train_acc = 0.9666977177456917\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 277, train_loss = 14.98709736391902, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 278, train_loss = 14.978279398754239, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 279, train_loss = 14.972050845623016, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 280, train_loss = 14.961698522791266, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 281, train_loss = 14.952881222590804, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 282, train_loss = 14.941111849620938, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 283, train_loss = 14.929447397589684, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 284, train_loss = 14.922767443582416, train_acc = 0.9669306008383791\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 285, train_loss = 14.91748564131558, train_acc = 0.9669306008383791\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 286, train_loss = 14.908946640789509, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 287, train_loss = 14.900510488077998, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 288, train_loss = 14.887012040242553, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 289, train_loss = 14.889263987541199, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 290, train_loss = 14.873450512066483, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 291, train_loss = 14.871670634485781, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "9th- epoch: 292, train_loss = 14.86675922293216, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 293, train_loss = 14.849467589519918, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 294, train_loss = 14.841046271845698, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 295, train_loss = 14.832834961824119, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 296, train_loss = 14.827124166302383, train_acc = 0.9670470423847228\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 297, train_loss = 14.820997770875692, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 298, train_loss = 14.80966719891876, train_acc = 0.9672799254774104\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 299, train_loss = 14.806262231431901, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 300, train_loss = 14.795103992335498, train_acc = 0.9672799254774104\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 301, train_loss = 14.78965912759304, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 302, train_loss = 14.780943083576858, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 303, train_loss = 14.770710806362331, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 304, train_loss = 14.774293456226587, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 305, train_loss = 14.753650791943073, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 306, train_loss = 14.751364200375974, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 307, train_loss = 14.744777825661004, train_acc = 0.9678621332091291\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 308, train_loss = 14.731549550779164, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 309, train_loss = 14.72740585822612, train_acc = 0.9678621332091291\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 310, train_loss = 14.722304463386536, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 311, train_loss = 14.713146306574345, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 312, train_loss = 14.704256296157837, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 313, train_loss = 14.69569878000766, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 314, train_loss = 14.690898367203772, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 315, train_loss = 14.682903095148504, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "9th- epoch: 316, train_loss = 14.674917499534786, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 317, train_loss = 14.664042224176228, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 318, train_loss = 14.663362920284271, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 319, train_loss = 14.651560102589428, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 320, train_loss = 14.644429747015238, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 321, train_loss = 14.63941244687885, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 322, train_loss = 14.626256386749446, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 323, train_loss = 14.621262460015714, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 324, train_loss = 14.611779253929853, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 325, train_loss = 14.610701691359282, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 326, train_loss = 14.598332740366459, train_acc = 0.9678621332091291\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 327, train_loss = 14.595314693637192, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 328, train_loss = 14.584982349537313, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 329, train_loss = 14.573719712905586, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 330, train_loss = 14.569743480533361, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 331, train_loss = 14.561263523995876, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 332, train_loss = 14.554635328240693, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 333, train_loss = 14.547587006352842, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 334, train_loss = 14.536358344368637, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 335, train_loss = 14.533553236164153, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 336, train_loss = 14.52678199019283, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 337, train_loss = 14.520696744322777, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 338, train_loss = 14.509634044021368, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 339, train_loss = 14.496133257634938, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 340, train_loss = 14.490525334142148, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 341, train_loss = 14.482706900686026, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 342, train_loss = 14.47306086588651, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 343, train_loss = 14.464362160302699, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 344, train_loss = 14.452151297591627, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 345, train_loss = 14.450794308446348, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 346, train_loss = 14.442682697437704, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 347, train_loss = 14.43280393537134, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 348, train_loss = 14.432185494340956, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 349, train_loss = 14.424957479350269, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 350, train_loss = 14.417155644856393, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 351, train_loss = 14.414545059204102, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 352, train_loss = 14.395065974444151, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 353, train_loss = 14.39955643657595, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 354, train_loss = 14.38841541390866, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 355, train_loss = 14.376274014823139, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 356, train_loss = 14.372459389269352, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 357, train_loss = 14.363892021588981, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 358, train_loss = 14.361730826087296, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 359, train_loss = 14.351135964505374, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 360, train_loss = 14.34300772100687, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 361, train_loss = 14.342031185515225, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 362, train_loss = 14.33789615239948, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 363, train_loss = 14.330317676998675, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 364, train_loss = 14.326353563927114, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 365, train_loss = 14.318435274995863, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 366, train_loss = 14.310741298832, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 367, train_loss = 14.298801641911268, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 368, train_loss = 14.298817746341228, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 369, train_loss = 14.293676123023033, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 370, train_loss = 14.288607989437878, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 371, train_loss = 14.279566586948931, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 372, train_loss = 14.275353639386594, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 373, train_loss = 14.267533439211547, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 374, train_loss = 14.26465363893658, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 375, train_loss = 14.260802686214447, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 376, train_loss = 14.250892505981028, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 377, train_loss = 14.24510280508548, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 378, train_loss = 14.239412783645093, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 379, train_loss = 14.23168160021305, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 380, train_loss = 14.226097146980464, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 381, train_loss = 14.21991279348731, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 382, train_loss = 14.221994693391025, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 383, train_loss = 14.21176057588309, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 384, train_loss = 14.205242421478033, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 385, train_loss = 14.201137371361256, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 386, train_loss = 14.19899991992861, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 387, train_loss = 14.190896354615688, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 388, train_loss = 14.18793136253953, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 389, train_loss = 14.174930737353861, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 390, train_loss = 14.179911891929805, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 391, train_loss = 14.165333111770451, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 392, train_loss = 14.158447121270001, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 393, train_loss = 14.156887027435005, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 394, train_loss = 14.14809403102845, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 395, train_loss = 14.144692744128406, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 396, train_loss = 14.140558858402073, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 397, train_loss = 14.134830766357481, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 398, train_loss = 14.122937540523708, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 399, train_loss = 14.120779917575419, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 400, train_loss = 14.123507965356112, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 401, train_loss = 14.106584566645324, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 402, train_loss = 14.106259885244071, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 403, train_loss = 14.10773151088506, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 404, train_loss = 14.100412354804575, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 405, train_loss = 14.09315463155508, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 406, train_loss = 14.08931081276387, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 407, train_loss = 14.0819799201563, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 408, train_loss = 14.078035338781774, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 409, train_loss = 14.07190901786089, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 410, train_loss = 14.067384124733508, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 411, train_loss = 14.060050218366086, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 412, train_loss = 14.056210744194686, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 413, train_loss = 14.049774312414229, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 414, train_loss = 14.047957926988602, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 415, train_loss = 14.041798125952482, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 416, train_loss = 14.03893278259784, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 417, train_loss = 14.029716588556767, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 418, train_loss = 14.032259150408208, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 419, train_loss = 14.020176948048174, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 420, train_loss = 14.014522466808558, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 421, train_loss = 14.015425034798682, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 422, train_loss = 14.014682308770716, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 423, train_loss = 14.00614967662841, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 424, train_loss = 13.996399249881506, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 425, train_loss = 13.994166840799153, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 426, train_loss = 13.988353342749178, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 427, train_loss = 13.984120084904134, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 428, train_loss = 13.980010364204645, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 429, train_loss = 13.974874895997345, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 430, train_loss = 13.969319867901504, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 431, train_loss = 13.967776872217655, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 432, train_loss = 13.961921356618404, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 433, train_loss = 13.951285456307232, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 434, train_loss = 13.95165545027703, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 435, train_loss = 13.948670812882483, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 436, train_loss = 13.940629105083644, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 437, train_loss = 13.940031219273806, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 438, train_loss = 13.942946277558804, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 439, train_loss = 13.92964408453554, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 440, train_loss = 13.92225715238601, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 441, train_loss = 13.918182644993067, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 442, train_loss = 13.915870938450098, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 443, train_loss = 13.917329072020948, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 444, train_loss = 13.910270066000521, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 445, train_loss = 13.901550631970167, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 446, train_loss = 13.896421785466373, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 447, train_loss = 13.89488837402314, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 448, train_loss = 13.887709611095488, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 449, train_loss = 13.887514642439783, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 450, train_loss = 13.885247754864395, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 451, train_loss = 13.884000203572214, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 452, train_loss = 13.879400744102895, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 453, train_loss = 13.872579235583544, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 454, train_loss = 13.861682418733835, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 455, train_loss = 13.859649565070868, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 456, train_loss = 13.853334813378751, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 457, train_loss = 13.856657593511045, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 458, train_loss = 13.845996498130262, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 459, train_loss = 13.838616106659174, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 460, train_loss = 13.840888056904078, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 461, train_loss = 13.833519522100687, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 462, train_loss = 13.829896406270564, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 463, train_loss = 13.8273082440719, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 464, train_loss = 13.8271393366158, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 465, train_loss = 13.820051603019238, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 466, train_loss = 13.813497113995254, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 467, train_loss = 13.81289305537939, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 468, train_loss = 13.802860021591187, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 469, train_loss = 13.798438508994877, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 470, train_loss = 13.801066994667053, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 471, train_loss = 13.797633030451834, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 472, train_loss = 13.786199894733727, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 473, train_loss = 13.787969180382788, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 474, train_loss = 13.780558340251446, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 475, train_loss = 13.782694694586098, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 476, train_loss = 13.770729928277433, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 477, train_loss = 13.76728734280914, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 478, train_loss = 13.761751178652048, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 479, train_loss = 13.7698615193367, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 480, train_loss = 13.756169613450766, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 481, train_loss = 13.753986965864897, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 482, train_loss = 13.75207089772448, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 483, train_loss = 13.748741661198437, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 484, train_loss = 13.741062528453767, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 485, train_loss = 13.73744857404381, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 486, train_loss = 13.734407059848309, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 487, train_loss = 13.730436597019434, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 488, train_loss = 13.727468810044229, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 489, train_loss = 13.723562085535377, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 490, train_loss = 13.71306072268635, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 491, train_loss = 13.713236227631569, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 492, train_loss = 13.712754448410124, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 493, train_loss = 13.71071196720004, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 494, train_loss = 13.705681352410465, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 495, train_loss = 13.698492500931025, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 496, train_loss = 13.696173103060573, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 497, train_loss = 13.68948752200231, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 498, train_loss = 13.686928149312735, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "9th- epoch: 499, train_loss = 13.683415729552507, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████████████▎                                                 | 9/30 [1:21:36<3:10:44, 544.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "10th- epoch: 0, train_loss = 128.92108803987503, train_acc = 0.746506753609688\n",
      "test Acc 0.8631284916201117:\n",
      "10th- epoch: 1, train_loss = 57.772426307201385, train_acc = 0.8762226362366092\n",
      "test Acc 0.8947858472998138:\n",
      "10th- epoch: 2, train_loss = 47.93527953326702, train_acc = 0.8992780624126688\n",
      "test Acc 0.9031657355679702:\n",
      "10th- epoch: 3, train_loss = 43.049539029598236, train_acc = 0.9096413600372613\n",
      "test Acc 0.9078212290502793:\n",
      "10th- epoch: 4, train_loss = 39.96564503014088, train_acc = 0.9149976711690732\n",
      "test Acc 0.9110800744878957:\n",
      "10th- epoch: 5, train_loss = 37.7461698576808, train_acc = 0.9190731252911039\n",
      "test Acc 0.914804469273743:\n",
      "10th- epoch: 6, train_loss = 36.0916817560792, train_acc = 0.9218677224033535\n",
      "test Acc 0.9185288640595903:\n",
      "10th- epoch: 7, train_loss = 34.707434095442295, train_acc = 0.9241965533302282\n",
      "test Acc 0.9203910614525139:\n",
      "10th- epoch: 8, train_loss = 33.56021640449762, train_acc = 0.9271075919888216\n",
      "test Acc 0.9222532588454376:\n",
      "10th- epoch: 9, train_loss = 32.60030637681484, train_acc = 0.9295528644620401\n",
      "test Acc 0.9250465549348231:\n",
      "10th- epoch: 10, train_loss = 31.725801929831505, train_acc = 0.9312994876571961\n",
      "test Acc 0.9264432029795159:\n",
      "10th- epoch: 11, train_loss = 30.987951584160328, train_acc = 0.9329296693060084\n",
      "test Acc 0.9287709497206704:\n",
      "10th- epoch: 12, train_loss = 30.297465935349464, train_acc = 0.9335118770377271\n",
      "test Acc 0.9301675977653632:\n",
      "10th- epoch: 13, train_loss = 29.697752445936203, train_acc = 0.9346762925011645\n",
      "test Acc 0.9315642458100558:\n",
      "10th- epoch: 14, train_loss = 29.123994909226894, train_acc = 0.935258500232883\n",
      "test Acc 0.9320297951582868:\n",
      "10th- epoch: 15, train_loss = 28.638133704662323, train_acc = 0.9368886818816954\n",
      "test Acc 0.9324953445065177:\n",
      "10th- epoch: 16, train_loss = 28.15915185585618, train_acc = 0.937936655798789\n",
      "test Acc 0.9324953445065177:\n",
      "10th- epoch: 17, train_loss = 27.728287030011415, train_acc = 0.9393339543549138\n",
      "test Acc 0.9329608938547486:\n",
      "10th- epoch: 18, train_loss = 27.35515885055065, train_acc = 0.9400326036329762\n",
      "test Acc 0.9334264432029795:\n",
      "10th- epoch: 19, train_loss = 26.986154224723577, train_acc = 0.9408476944573824\n",
      "test Acc 0.9334264432029795:\n",
      "10th- epoch: 20, train_loss = 26.64783166348934, train_acc = 0.9415463437354448\n",
      "test Acc 0.9348230912476723:\n",
      "10th- epoch: 21, train_loss = 26.328322257846594, train_acc = 0.9421285514671635\n",
      "test Acc 0.9352886405959032:\n",
      "10th- epoch: 22, train_loss = 26.040182668715715, train_acc = 0.9428272007452259\n",
      "test Acc 0.936219739292365:\n",
      "10th- epoch: 23, train_loss = 25.77602817490697, train_acc = 0.9436422915696321\n",
      "test Acc 0.936219739292365:\n",
      "10th- epoch: 24, train_loss = 25.520129594951868, train_acc = 0.9435258500232883\n",
      "test Acc 0.9366852886405959:\n",
      "10th- epoch: 25, train_loss = 25.25645872205496, train_acc = 0.9444573823940382\n",
      "test Acc 0.9366852886405959:\n",
      "10th- epoch: 26, train_loss = 25.02623799070716, train_acc = 0.9452724732184443\n",
      "test Acc 0.9371508379888268:\n",
      "10th- epoch: 27, train_loss = 24.802961379289627, train_acc = 0.9456217978574756\n",
      "test Acc 0.9385474860335196:\n",
      "10th- epoch: 28, train_loss = 24.590164612978697, train_acc = 0.945854680950163\n",
      "test Acc 0.9385474860335196:\n",
      "10th- epoch: 29, train_loss = 24.382105592638254, train_acc = 0.946320447135538\n",
      "test Acc 0.9380819366852886:\n",
      "10th- epoch: 30, train_loss = 24.195852488279343, train_acc = 0.946786213320913\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 31, train_loss = 23.99091398343444, train_acc = 0.9472519795062878\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 32, train_loss = 23.82267439737916, train_acc = 0.9470190964136004\n",
      "test Acc 0.9390130353817505:\n",
      "10th- epoch: 33, train_loss = 23.651640314608812, train_acc = 0.9477177456916628\n",
      "test Acc 0.9390130353817505:\n",
      "10th- epoch: 34, train_loss = 23.47610792890191, train_acc = 0.9478341872380065\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 35, train_loss = 23.34636215493083, train_acc = 0.948067070330694\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 36, train_loss = 23.175636805593967, train_acc = 0.9481835118770378\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 37, train_loss = 23.013882789760828, train_acc = 0.948067070330694\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 38, train_loss = 22.875842440873384, train_acc = 0.948067070330694\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 39, train_loss = 22.735463563352823, train_acc = 0.9485328365160689\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 40, train_loss = 22.613498520106077, train_acc = 0.9487657196087564\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 41, train_loss = 22.460518281906843, train_acc = 0.9491150442477876\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 42, train_loss = 22.3178678303957, train_acc = 0.9493479273404751\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 43, train_loss = 22.20924524590373, train_acc = 0.9496972519795063\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 44, train_loss = 22.11059056594968, train_acc = 0.9499301350721937\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 45, train_loss = 21.980697248131037, train_acc = 0.9509781089892874\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 46, train_loss = 21.887522015720606, train_acc = 0.9503959012575687\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 47, train_loss = 21.78666453808546, train_acc = 0.9506287843502562\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 48, train_loss = 21.685487896203995, train_acc = 0.9506287843502562\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 49, train_loss = 21.551623594015837, train_acc = 0.9516767582673498\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 50, train_loss = 21.463811945170164, train_acc = 0.9516767582673498\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 51, train_loss = 21.36169048026204, train_acc = 0.9522589659990685\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 52, train_loss = 21.287996914237738, train_acc = 0.9523754075454122\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 53, train_loss = 21.165825366973877, train_acc = 0.9526082906380997\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 54, train_loss = 21.092280339449644, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 55, train_loss = 21.001810062676668, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 56, train_loss = 20.912995260208845, train_acc = 0.9528411737307871\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 57, train_loss = 20.808205902576447, train_acc = 0.9530740568234746\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 58, train_loss = 20.7273159455508, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 59, train_loss = 20.675421707332134, train_acc = 0.9535398230088495\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 60, train_loss = 20.593972170725465, train_acc = 0.9537727061015371\n",
      "test Acc 0.9394785847299814:\n",
      "10th- epoch: 61, train_loss = 20.5147854257375, train_acc = 0.9540055891942245\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 62, train_loss = 20.426201831549406, train_acc = 0.9541220307405682\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 63, train_loss = 20.311862060800195, train_acc = 0.9545877969259432\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 64, train_loss = 20.237406825646758, train_acc = 0.9549371215649743\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 65, train_loss = 20.16011913307011, train_acc = 0.9549371215649743\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 66, train_loss = 20.11700856126845, train_acc = 0.9550535631113182\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 67, train_loss = 20.0355064291507, train_acc = 0.9551700046576619\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 68, train_loss = 19.959418738260865, train_acc = 0.9552864462040056\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 69, train_loss = 19.905125895515084, train_acc = 0.9552864462040056\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 70, train_loss = 19.835646897554398, train_acc = 0.955519329296693\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 71, train_loss = 19.771297866478562, train_acc = 0.9556357708430367\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 72, train_loss = 19.720980124548078, train_acc = 0.9556357708430367\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 73, train_loss = 19.636266173794866, train_acc = 0.9558686539357243\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 74, train_loss = 19.596035847440362, train_acc = 0.9562179785747554\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 75, train_loss = 19.522840613499284, train_acc = 0.9562179785747554\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 76, train_loss = 19.465522449463606, train_acc = 0.9563344201210993\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 77, train_loss = 19.407022017985582, train_acc = 0.9561015370284117\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 78, train_loss = 19.368174023926258, train_acc = 0.9562179785747554\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 79, train_loss = 19.29178459942341, train_acc = 0.9562179785747554\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 80, train_loss = 19.274063615128398, train_acc = 0.956450861667443\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 81, train_loss = 19.20028287731111, train_acc = 0.9565673032137867\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 82, train_loss = 19.167752070352435, train_acc = 0.9565673032137867\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 83, train_loss = 19.13662469573319, train_acc = 0.9568001863064741\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 84, train_loss = 19.0474759247154, train_acc = 0.9568001863064741\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 85, train_loss = 18.99569994211197, train_acc = 0.9569166278528178\n",
      "test Acc 0.9404096834264432:\n",
      "10th- epoch: 86, train_loss = 18.953029438853264, train_acc = 0.9568001863064741\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 87, train_loss = 18.9583655949682, train_acc = 0.9569166278528178\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 88, train_loss = 18.884887481108308, train_acc = 0.9568001863064741\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 89, train_loss = 18.8487601429224, train_acc = 0.9569166278528178\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 90, train_loss = 18.782045675441623, train_acc = 0.9570330693991617\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 91, train_loss = 18.785185208544135, train_acc = 0.9570330693991617\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 92, train_loss = 18.716644629836082, train_acc = 0.9573823940381928\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 93, train_loss = 18.657496631145477, train_acc = 0.9573823940381928\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 94, train_loss = 18.618356058374047, train_acc = 0.9572659524918491\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 95, train_loss = 18.54624197818339, train_acc = 0.9573823940381928\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 96, train_loss = 18.551527805626392, train_acc = 0.9577317186772241\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 97, train_loss = 18.487186869606376, train_acc = 0.9578481602235678\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 98, train_loss = 18.437747599557042, train_acc = 0.9578481602235678\n",
      "test Acc 0.9413407821229051:\n",
      "10th- epoch: 99, train_loss = 18.442081041634083, train_acc = 0.9579646017699115\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 100, train_loss = 18.38345684297383, train_acc = 0.9580810433162552\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 101, train_loss = 18.316887257620692, train_acc = 0.9583139264089428\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 102, train_loss = 18.312057154253125, train_acc = 0.9581974848625989\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 103, train_loss = 18.252493927255273, train_acc = 0.9583139264089428\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 104, train_loss = 18.228912824764848, train_acc = 0.9584303679552865\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 105, train_loss = 18.197602348402143, train_acc = 0.9585468095016302\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 106, train_loss = 18.180442607030272, train_acc = 0.9587796925943176\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 107, train_loss = 18.1006396766752, train_acc = 0.9586632510479739\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 108, train_loss = 18.101733854040504, train_acc = 0.9587796925943176\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 109, train_loss = 18.039930075407028, train_acc = 0.9588961341406614\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 110, train_loss = 18.020639076828957, train_acc = 0.9590125756870052\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 111, train_loss = 18.003994934260845, train_acc = 0.9590125756870052\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 112, train_loss = 17.96115067601204, train_acc = 0.95947834187238\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 113, train_loss = 17.942276870831847, train_acc = 0.9595947834187238\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 114, train_loss = 17.876093389466405, train_acc = 0.95947834187238\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 115, train_loss = 17.886193426325917, train_acc = 0.9598276665114113\n",
      "test Acc 0.9422718808193669:\n",
      "10th- epoch: 116, train_loss = 17.8181355278939, train_acc = 0.9598276665114113\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 117, train_loss = 17.833670012652874, train_acc = 0.959944108057755\n",
      "test Acc 0.9422718808193669:\n",
      "10th- epoch: 118, train_loss = 17.78424763120711, train_acc = 0.9601769911504425\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 119, train_loss = 17.75614880770445, train_acc = 0.9605263157894737\n",
      "test Acc 0.9422718808193669:\n",
      "10th- epoch: 120, train_loss = 17.720007797703147, train_acc = 0.96040987424313\n",
      "test Acc 0.9422718808193669:\n",
      "10th- epoch: 121, train_loss = 17.71674265526235, train_acc = 0.96040987424313\n",
      "test Acc 0.9422718808193669:\n",
      "10th- epoch: 122, train_loss = 17.65661135315895, train_acc = 0.9606427573358174\n",
      "test Acc 0.9422718808193669:\n",
      "10th- epoch: 123, train_loss = 17.62587965093553, train_acc = 0.9609920819748486\n",
      "test Acc 0.9422718808193669:\n",
      "10th- epoch: 124, train_loss = 17.621507408097386, train_acc = 0.9607591988821611\n",
      "test Acc 0.9427374301675978:\n",
      "10th- epoch: 125, train_loss = 17.57955706678331, train_acc = 0.9609920819748486\n",
      "test Acc 0.9427374301675978:\n",
      "10th- epoch: 126, train_loss = 17.55571366660297, train_acc = 0.9609920819748486\n",
      "test Acc 0.9427374301675978:\n",
      "10th- epoch: 127, train_loss = 17.516151232644916, train_acc = 0.9611085235211924\n",
      "test Acc 0.9422718808193669:\n",
      "10th- epoch: 128, train_loss = 17.504623407498002, train_acc = 0.9615742897065673\n",
      "test Acc 0.9427374301675978:\n",
      "10th- epoch: 129, train_loss = 17.486878709867597, train_acc = 0.9614578481602236\n",
      "test Acc 0.9427374301675978:\n",
      "10th- epoch: 130, train_loss = 17.453492991626263, train_acc = 0.9612249650675361\n",
      "test Acc 0.9427374301675978:\n",
      "10th- epoch: 131, train_loss = 17.41366570442915, train_acc = 0.9613414066138798\n",
      "test Acc 0.9427374301675978:\n",
      "10th- epoch: 132, train_loss = 17.395782785490155, train_acc = 0.9613414066138798\n",
      "test Acc 0.9427374301675978:\n",
      "10th- epoch: 133, train_loss = 17.37303537875414, train_acc = 0.9615742897065673\n",
      "test Acc 0.9427374301675978:\n",
      "10th- epoch: 134, train_loss = 17.343755846843123, train_acc = 0.9614578481602236\n",
      "test Acc 0.9427374301675978:\n",
      "10th- epoch: 135, train_loss = 17.320076936855912, train_acc = 0.9615742897065673\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 136, train_loss = 17.306220777332783, train_acc = 0.9615742897065673\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 137, train_loss = 17.2690666988492, train_acc = 0.9619236143455985\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 138, train_loss = 17.240882577374578, train_acc = 0.9618071727992548\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 139, train_loss = 17.20385547913611, train_acc = 0.962156497438286\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 140, train_loss = 17.20612379349768, train_acc = 0.962156497438286\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 141, train_loss = 17.171897249296308, train_acc = 0.9622729389846297\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 142, train_loss = 17.133959831669927, train_acc = 0.9625058220773172\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 143, train_loss = 17.136232944205403, train_acc = 0.9623893805309734\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 144, train_loss = 17.117167809978127, train_acc = 0.9627387051700047\n",
      "test Acc 0.9436685288640596:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 145, train_loss = 17.06492362357676, train_acc = 0.9630880298090359\n",
      "test Acc 0.9436685288640596:\n",
      "10th- epoch: 146, train_loss = 17.052377127110958, train_acc = 0.9632044713553796\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 147, train_loss = 17.04756487905979, train_acc = 0.9633209129017233\n",
      "test Acc 0.9436685288640596:\n",
      "10th- epoch: 148, train_loss = 17.00769300200045, train_acc = 0.9633209129017233\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 149, train_loss = 16.999882148578763, train_acc = 0.9633209129017233\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 150, train_loss = 16.998640425503254, train_acc = 0.9632044713553796\n",
      "test Acc 0.9436685288640596:\n",
      "10th- epoch: 151, train_loss = 16.941845044493675, train_acc = 0.9634373544480671\n",
      "test Acc 0.9436685288640596:\n",
      "10th- epoch: 152, train_loss = 16.945328811183572, train_acc = 0.9632044713553796\n",
      "test Acc 0.9441340782122905:\n",
      "10th- epoch: 153, train_loss = 16.917053900659084, train_acc = 0.9636702375407545\n",
      "test Acc 0.9436685288640596:\n",
      "10th- epoch: 154, train_loss = 16.884432619437575, train_acc = 0.9635537959944108\n",
      "test Acc 0.9441340782122905:\n",
      "10th- epoch: 155, train_loss = 16.85111691057682, train_acc = 0.9636702375407545\n",
      "test Acc 0.9445996275605214:\n",
      "10th- epoch: 156, train_loss = 16.842720480635762, train_acc = 0.9636702375407545\n",
      "test Acc 0.9445996275605214:\n",
      "10th- epoch: 157, train_loss = 16.83974889665842, train_acc = 0.9636702375407545\n",
      "test Acc 0.9445996275605214:\n",
      "10th- epoch: 158, train_loss = 16.786139773204923, train_acc = 0.9637866790870983\n",
      "test Acc 0.9441340782122905:\n",
      "10th- epoch: 159, train_loss = 16.802110129967332, train_acc = 0.9637866790870983\n",
      "test Acc 0.9441340782122905:\n",
      "10th- epoch: 160, train_loss = 16.75443951226771, train_acc = 0.9637866790870983\n",
      "test Acc 0.9445996275605214:\n",
      "10th- epoch: 161, train_loss = 16.746558470651507, train_acc = 0.9637866790870983\n",
      "test Acc 0.9445996275605214:\n",
      "10th- epoch: 162, train_loss = 16.728008778765798, train_acc = 0.9637866790870983\n",
      "test Acc 0.9445996275605214:\n",
      "10th- epoch: 163, train_loss = 16.70933066494763, train_acc = 0.9636702375407545\n",
      "test Acc 0.9445996275605214:\n",
      "10th- epoch: 164, train_loss = 16.70163606852293, train_acc = 0.9637866790870983\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 165, train_loss = 16.67152481712401, train_acc = 0.9637866790870983\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 166, train_loss = 16.637175204232335, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 167, train_loss = 16.62119685858488, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 168, train_loss = 16.604341005906463, train_acc = 0.9637866790870983\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 169, train_loss = 16.617332400754094, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 170, train_loss = 16.581738444045186, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 171, train_loss = 16.56278669089079, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 172, train_loss = 16.519362598657608, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 173, train_loss = 16.520421298220754, train_acc = 0.9640195621797858\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 174, train_loss = 16.490992560982704, train_acc = 0.9642524452724732\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 175, train_loss = 16.490254348143935, train_acc = 0.963903120633442\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 176, train_loss = 16.470165302976966, train_acc = 0.9642524452724732\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 177, train_loss = 16.44783701747656, train_acc = 0.9641360037261295\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 178, train_loss = 16.42999055236578, train_acc = 0.9642524452724732\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 179, train_loss = 16.414367370307446, train_acc = 0.9642524452724732\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 180, train_loss = 16.385879391804338, train_acc = 0.9642524452724732\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 181, train_loss = 16.379322201013565, train_acc = 0.9642524452724732\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 182, train_loss = 16.352484488859773, train_acc = 0.9642524452724732\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 183, train_loss = 16.36138948239386, train_acc = 0.9642524452724732\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 184, train_loss = 16.330610567703843, train_acc = 0.9642524452724732\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 185, train_loss = 16.313373086974025, train_acc = 0.9644853283651607\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 186, train_loss = 16.297043800354004, train_acc = 0.9644853283651607\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 187, train_loss = 16.29598913155496, train_acc = 0.9646017699115044\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 188, train_loss = 16.271693104878068, train_acc = 0.9644853283651607\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 189, train_loss = 16.263359731063247, train_acc = 0.9644853283651607\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 190, train_loss = 16.221984276548028, train_acc = 0.9646017699115044\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 191, train_loss = 16.218811875209212, train_acc = 0.9644853283651607\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 192, train_loss = 16.204492898657918, train_acc = 0.9647182114578482\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 193, train_loss = 16.204823104664683, train_acc = 0.9647182114578482\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 194, train_loss = 16.1637317314744, train_acc = 0.9647182114578482\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 195, train_loss = 16.158614167943597, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 196, train_loss = 16.1421742644161, train_acc = 0.9647182114578482\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 197, train_loss = 16.127680273726583, train_acc = 0.9647182114578482\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 198, train_loss = 16.121595345437527, train_acc = 0.9647182114578482\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 199, train_loss = 16.10830287449062, train_acc = 0.9647182114578482\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 200, train_loss = 16.07643073797226, train_acc = 0.9647182114578482\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 201, train_loss = 16.0760879162699, train_acc = 0.9647182114578482\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 202, train_loss = 16.061670064926147, train_acc = 0.9647182114578482\n",
      "test Acc 0.9450651769087524:\n",
      "10th- epoch: 203, train_loss = 16.04599194228649, train_acc = 0.9648346530041919\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 204, train_loss = 16.035990487784147, train_acc = 0.9648346530041919\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 205, train_loss = 16.013240633532405, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 206, train_loss = 15.986169008538127, train_acc = 0.9650675360968793\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 207, train_loss = 15.989018024876714, train_acc = 0.9649510945505356\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 208, train_loss = 15.982098691165447, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 209, train_loss = 15.961785240098834, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 210, train_loss = 15.95106534101069, train_acc = 0.9649510945505356\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 211, train_loss = 15.928108924999833, train_acc = 0.9650675360968793\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 212, train_loss = 15.920530484989285, train_acc = 0.9651839776432231\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 213, train_loss = 15.911231035366654, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 214, train_loss = 15.887090556323528, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 215, train_loss = 15.896588051691651, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 216, train_loss = 15.867386028170586, train_acc = 0.9653004191895669\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 217, train_loss = 15.862387826666236, train_acc = 0.9654168607359106\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 218, train_loss = 15.843420925550163, train_acc = 0.9654168607359106\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 219, train_loss = 15.826778260059655, train_acc = 0.9653004191895669\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 220, train_loss = 15.821585183031857, train_acc = 0.9653004191895669\n",
      "test Acc 0.9459962756052142:\n",
      "10th- epoch: 221, train_loss = 15.81344250869006, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 222, train_loss = 15.794338154606521, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 223, train_loss = 15.788462829776108, train_acc = 0.9654168607359106\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 224, train_loss = 15.7755814390257, train_acc = 0.9654168607359106\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 225, train_loss = 15.757886536419392, train_acc = 0.9654168607359106\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 226, train_loss = 15.736675118096173, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 227, train_loss = 15.737806610763073, train_acc = 0.9654168607359106\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 228, train_loss = 15.719122875481844, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 229, train_loss = 15.723647168837488, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 230, train_loss = 15.69212634395808, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 231, train_loss = 15.680598055012524, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 232, train_loss = 15.683495386503637, train_acc = 0.965649743828598\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 233, train_loss = 15.647986534051597, train_acc = 0.965649743828598\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 234, train_loss = 15.652631963603199, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 235, train_loss = 15.635917025618255, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 236, train_loss = 15.630415871739388, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 237, train_loss = 15.611570484004915, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 238, train_loss = 15.608514931984246, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 239, train_loss = 15.584738176316023, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 240, train_loss = 15.592968697659671, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 241, train_loss = 15.582123800180852, train_acc = 0.965649743828598\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 242, train_loss = 15.559645188041031, train_acc = 0.965649743828598\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 243, train_loss = 15.549486163072288, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 244, train_loss = 15.534096591174603, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 245, train_loss = 15.532463264651597, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 246, train_loss = 15.510128177702427, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 247, train_loss = 15.511053356342018, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 248, train_loss = 15.499502047896385, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 249, train_loss = 15.497200466692448, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 250, train_loss = 15.475234535522759, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 251, train_loss = 15.468563872389495, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 252, train_loss = 15.459803901612759, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 253, train_loss = 15.435241538099945, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 254, train_loss = 15.442929838784039, train_acc = 0.9658826269212856\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 255, train_loss = 15.424066017381847, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 256, train_loss = 15.403663702309132, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 257, train_loss = 15.411205713637173, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 258, train_loss = 15.397190851159394, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 259, train_loss = 15.388089582324028, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 260, train_loss = 15.369595135562122, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 261, train_loss = 15.365592539310455, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 262, train_loss = 15.354640151374042, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 263, train_loss = 15.353318412788212, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 264, train_loss = 15.327982644550502, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 265, train_loss = 15.333587069995701, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 266, train_loss = 15.31746855378151, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 267, train_loss = 15.305206038057804, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 268, train_loss = 15.300590100698173, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 269, train_loss = 15.293298068456352, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 270, train_loss = 15.27848148625344, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 271, train_loss = 15.261235897429287, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 272, train_loss = 15.248608738183975, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 273, train_loss = 15.257688723504543, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 274, train_loss = 15.251109319739044, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 275, train_loss = 15.237843222916126, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 276, train_loss = 15.237570278346539, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 277, train_loss = 15.225863141007721, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 278, train_loss = 15.208660769276321, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 279, train_loss = 15.206699754111469, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 280, train_loss = 15.1889392985031, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 281, train_loss = 15.173731297254562, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 282, train_loss = 15.171597098000348, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 283, train_loss = 15.16435117740184, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 284, train_loss = 15.152839262969792, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 285, train_loss = 15.141761757433414, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 286, train_loss = 15.134141485206783, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 287, train_loss = 15.16733627486974, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 288, train_loss = 15.131507749669254, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 289, train_loss = 15.10344326775521, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 290, train_loss = 15.096229958347976, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 291, train_loss = 15.100996824912727, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 292, train_loss = 15.091141481883824, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 293, train_loss = 15.06946720648557, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 294, train_loss = 15.075576434843242, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 295, train_loss = 15.063597400672734, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 296, train_loss = 15.04783172160387, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 297, train_loss = 15.049453966319561, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 298, train_loss = 15.028761136345565, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 299, train_loss = 15.038362371735275, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 300, train_loss = 15.019077439792454, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 301, train_loss = 15.00457404088229, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 302, train_loss = 15.002591726370156, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 303, train_loss = 14.994755101390183, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 304, train_loss = 15.000543273985386, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 305, train_loss = 14.981324749998748, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 306, train_loss = 14.973412985913455, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 307, train_loss = 14.963703361339867, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 308, train_loss = 14.96679810155183, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 309, train_loss = 14.982016528956592, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 310, train_loss = 14.944454495795071, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 311, train_loss = 14.93061910290271, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 312, train_loss = 14.934031623415649, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 313, train_loss = 14.927530266344547, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 314, train_loss = 14.942616646178067, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 315, train_loss = 14.909256939776242, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 316, train_loss = 14.912283286452293, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 317, train_loss = 14.900778126902878, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 318, train_loss = 14.89276612084359, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 319, train_loss = 14.878201951272786, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 320, train_loss = 14.882252869196236, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 321, train_loss = 14.85551252681762, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 322, train_loss = 14.85330146830529, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 323, train_loss = 14.856614366173744, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 324, train_loss = 14.851093478500843, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 325, train_loss = 14.845045134425163, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 326, train_loss = 14.820529165677726, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 327, train_loss = 14.829005832783878, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 328, train_loss = 14.817889948375523, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 329, train_loss = 14.80326307285577, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 330, train_loss = 14.808294395916164, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 331, train_loss = 14.779075495898724, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 332, train_loss = 14.78811835963279, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 333, train_loss = 14.7991705192253, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 334, train_loss = 14.774561327882111, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 335, train_loss = 14.771643449552357, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 336, train_loss = 14.760452766902745, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 337, train_loss = 14.756796511821449, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 338, train_loss = 14.752677696757019, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 339, train_loss = 14.743906806223094, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 340, train_loss = 14.71519672870636, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 341, train_loss = 14.717434965074062, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 342, train_loss = 14.7107871202752, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 343, train_loss = 14.705497674643993, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 344, train_loss = 14.6960425125435, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 345, train_loss = 14.701572939753532, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 346, train_loss = 14.679556508548558, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 347, train_loss = 14.680979870259762, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 348, train_loss = 14.686608818359673, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 349, train_loss = 14.672664049081504, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 350, train_loss = 14.66688334196806, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 351, train_loss = 14.653793941251934, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 352, train_loss = 14.655346117913723, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 353, train_loss = 14.657775717787445, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 354, train_loss = 14.637902331538498, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 355, train_loss = 14.631259468384087, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 356, train_loss = 14.626231486909091, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 357, train_loss = 14.629892262630165, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 358, train_loss = 14.622182290069759, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 359, train_loss = 14.607075271196663, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 360, train_loss = 14.602524869143963, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 361, train_loss = 14.599792624823749, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 362, train_loss = 14.594193503260612, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 363, train_loss = 14.589094187133014, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 364, train_loss = 14.587492073886096, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 365, train_loss = 14.56736287754029, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 366, train_loss = 14.559668183326721, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 367, train_loss = 14.561362092383206, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 368, train_loss = 14.552686070092022, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 369, train_loss = 14.548429265618324, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 370, train_loss = 14.539472170174122, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 371, train_loss = 14.541478261351585, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 372, train_loss = 14.53496779780835, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 373, train_loss = 14.529478904791176, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 374, train_loss = 14.511103521101177, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 375, train_loss = 14.512414780445397, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 376, train_loss = 14.515129308216274, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 377, train_loss = 14.500503160059452, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 378, train_loss = 14.500798824243248, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 379, train_loss = 14.4865088686347, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 380, train_loss = 14.480994686484337, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 381, train_loss = 14.478804950602353, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 382, train_loss = 14.472851917147636, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 383, train_loss = 14.471414695493877, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 384, train_loss = 14.473277832381427, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 385, train_loss = 14.457750536501408, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 386, train_loss = 14.44426679611206, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 387, train_loss = 14.437628544867039, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 388, train_loss = 14.437502001412213, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 389, train_loss = 14.43682695645839, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 390, train_loss = 14.423787117004395, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 391, train_loss = 14.41340272128582, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "10th- epoch: 392, train_loss = 14.426990347914398, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 393, train_loss = 14.41371135879308, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 394, train_loss = 14.413959545083344, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 395, train_loss = 14.395250941626728, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 396, train_loss = 14.396672387607396, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 397, train_loss = 14.38374802749604, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 398, train_loss = 14.379775720648468, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 399, train_loss = 14.37565664947033, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 400, train_loss = 14.376572653651237, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 401, train_loss = 14.371500273235142, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 402, train_loss = 14.353547766804695, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 403, train_loss = 14.35860104393214, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 404, train_loss = 14.345140968449414, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 405, train_loss = 14.342644301243126, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 406, train_loss = 14.32873069215566, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 407, train_loss = 14.341315485537052, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 408, train_loss = 14.334655597805977, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 409, train_loss = 14.322583426721394, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 410, train_loss = 14.312442791648209, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 411, train_loss = 14.322368453256786, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 412, train_loss = 14.310695394873619, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 413, train_loss = 14.299459929578006, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 414, train_loss = 14.297380437143147, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 415, train_loss = 14.286776366643608, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 416, train_loss = 14.299926695413888, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 417, train_loss = 14.277325528673828, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 418, train_loss = 14.28246434777975, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 419, train_loss = 14.282977506518364, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 420, train_loss = 14.255004204809666, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 421, train_loss = 14.26055642683059, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 422, train_loss = 14.251096248626709, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 423, train_loss = 14.248903770931065, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 424, train_loss = 14.260206364095211, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 425, train_loss = 14.244864004664123, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 426, train_loss = 14.230043920688331, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 427, train_loss = 14.23428151011467, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 428, train_loss = 14.22305313218385, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 429, train_loss = 14.22355880588293, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 430, train_loss = 14.23585203755647, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 431, train_loss = 14.207187908701599, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 432, train_loss = 14.211101564578712, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 433, train_loss = 14.213632901199162, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 434, train_loss = 14.193041421473026, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 435, train_loss = 14.188117899000645, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 436, train_loss = 14.18721318244934, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 437, train_loss = 14.176107267849147, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 438, train_loss = 14.179265511222184, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 439, train_loss = 14.17005521338433, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 440, train_loss = 14.166239063255489, train_acc = 0.9690265486725663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 441, train_loss = 14.169858418405056, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 442, train_loss = 14.149388253688812, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 443, train_loss = 14.158207724802196, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 444, train_loss = 14.157701942138374, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 445, train_loss = 14.153141558170319, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 446, train_loss = 14.14605101197958, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 447, train_loss = 14.131854007951915, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 448, train_loss = 14.136824865825474, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 449, train_loss = 14.13415156584233, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 450, train_loss = 14.1236013174057, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 451, train_loss = 14.126559682190418, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 452, train_loss = 14.107526523061097, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 453, train_loss = 14.098351582884789, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 454, train_loss = 14.102156773209572, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 455, train_loss = 14.097919124178588, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 456, train_loss = 14.097409270703793, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 457, train_loss = 14.098665158264339, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 458, train_loss = 14.086624416522682, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 459, train_loss = 14.085231897421181, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 460, train_loss = 14.070095066912472, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 461, train_loss = 14.062911841087043, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 462, train_loss = 14.061085398308933, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 463, train_loss = 14.052639071829617, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 464, train_loss = 14.04666905850172, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 465, train_loss = 14.045037493109703, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 466, train_loss = 14.040562860667706, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 467, train_loss = 14.045044747181237, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 468, train_loss = 14.042881026864052, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 469, train_loss = 14.030953735113144, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 470, train_loss = 14.034882267005742, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 471, train_loss = 14.024883717298508, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 472, train_loss = 14.013064933009446, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 473, train_loss = 14.009530241601169, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 474, train_loss = 14.007695537991822, train_acc = 0.9694923148579413\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 475, train_loss = 14.00023254007101, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 476, train_loss = 13.998296442441642, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 477, train_loss = 13.988887551240623, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 478, train_loss = 13.989133100025356, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 479, train_loss = 13.991352118551731, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 480, train_loss = 13.983000409789383, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 481, train_loss = 13.9807727211155, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 482, train_loss = 13.972481166478246, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 483, train_loss = 13.965381806250662, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 484, train_loss = 13.969875147100538, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 485, train_loss = 13.97330384934321, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 486, train_loss = 13.954104853328317, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 487, train_loss = 13.95185450464487, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 488, train_loss = 13.93943885480985, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 489, train_loss = 13.938753922935575, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 490, train_loss = 13.9357221275568, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 491, train_loss = 13.932422416750342, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 492, train_loss = 13.939199330750853, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 493, train_loss = 13.921057643834502, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 494, train_loss = 13.927651683334261, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 495, train_loss = 13.914609412197024, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 496, train_loss = 13.908003328833729, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 497, train_loss = 13.906763801816851, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 498, train_loss = 13.90660485252738, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "10th- epoch: 499, train_loss = 13.903041484300047, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████▎                                              | 10/30 [1:30:40<3:01:36, 544.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "11th- epoch: 0, train_loss = 115.28072586655617, train_acc = 0.7488355845365626\n",
      "test Acc 0.8375232774674115:\n",
      "11th- epoch: 1, train_loss = 61.595390886068344, train_acc = 0.8653935724266418\n",
      "test Acc 0.8803538175046555:\n",
      "11th- epoch: 2, train_loss = 51.308166459202766, train_acc = 0.8885654401490451\n",
      "test Acc 0.8961824953445066:\n",
      "11th- epoch: 3, train_loss = 45.96796381473541, train_acc = 0.900093153237075\n",
      "test Acc 0.9082867783985102:\n",
      "11th- epoch: 4, train_loss = 42.421362459659576, train_acc = 0.908011178388449\n",
      "test Acc 0.9106145251396648:\n",
      "11th- epoch: 5, train_loss = 39.89963909238577, train_acc = 0.9142990218910108\n",
      "test Acc 0.9171322160148976:\n",
      "11th- epoch: 6, train_loss = 37.87883571535349, train_acc = 0.9179087098276665\n",
      "test Acc 0.9185288640595903:\n",
      "11th- epoch: 7, train_loss = 36.314792297780514, train_acc = 0.9214019562179786\n",
      "test Acc 0.9203910614525139:\n",
      "11th- epoch: 8, train_loss = 35.00137726217508, train_acc = 0.9245458779692595\n",
      "test Acc 0.9231843575418994:\n",
      "11th- epoch: 9, train_loss = 33.896551199257374, train_acc = 0.9274569166278528\n",
      "test Acc 0.9236499068901304:\n",
      "11th- epoch: 10, train_loss = 32.89995617419481, train_acc = 0.9295528644620401\n",
      "test Acc 0.9227188081936686:\n",
      "11th- epoch: 11, train_loss = 32.03070642054081, train_acc = 0.9314159292035398\n",
      "test Acc 0.9236499068901304:\n",
      "11th- epoch: 12, train_loss = 31.28306782990694, train_acc = 0.9326967862133209\n",
      "test Acc 0.9236499068901304:\n",
      "11th- epoch: 13, train_loss = 30.598445378243923, train_acc = 0.933977643223102\n",
      "test Acc 0.9245810055865922:\n",
      "11th- epoch: 14, train_loss = 29.971860624849796, train_acc = 0.9354913833255706\n",
      "test Acc 0.9273743016759777:\n",
      "11th- epoch: 15, train_loss = 29.406174041330814, train_acc = 0.936655798789008\n",
      "test Acc 0.9287709497206704:\n",
      "11th- epoch: 16, train_loss = 28.88710145652294, train_acc = 0.9377037727061015\n",
      "test Acc 0.9287709497206704:\n",
      "11th- epoch: 17, train_loss = 28.386794541031122, train_acc = 0.9391010712622264\n",
      "test Acc 0.930633147113594:\n",
      "11th- epoch: 18, train_loss = 27.934772592037916, train_acc = 0.9400326036329762\n",
      "test Acc 0.931098696461825:\n",
      "11th- epoch: 19, train_loss = 27.52925420179963, train_acc = 0.9402654867256637\n",
      "test Acc 0.931098696461825:\n",
      "11th- epoch: 20, train_loss = 27.127823311835527, train_acc = 0.9410805775500699\n",
      "test Acc 0.9320297951582868:\n",
      "11th- epoch: 21, train_loss = 26.762680057436228, train_acc = 0.9416627852817886\n",
      "test Acc 0.9320297951582868:\n",
      "11th- epoch: 22, train_loss = 26.42016500979662, train_acc = 0.9427107591988821\n",
      "test Acc 0.9324953445065177:\n",
      "11th- epoch: 23, train_loss = 26.106433667242527, train_acc = 0.9430600838379134\n",
      "test Acc 0.9320297951582868:\n",
      "11th- epoch: 24, train_loss = 25.82813808694482, train_acc = 0.9443409408476945\n",
      "test Acc 0.9324953445065177:\n",
      "11th- epoch: 25, train_loss = 25.53364536166191, train_acc = 0.9448067070330693\n",
      "test Acc 0.9324953445065177:\n",
      "11th- epoch: 26, train_loss = 25.265437200665474, train_acc = 0.9455053563111319\n",
      "test Acc 0.9324953445065177:\n",
      "11th- epoch: 27, train_loss = 25.034516002982855, train_acc = 0.9455053563111319\n",
      "test Acc 0.9334264432029795:\n",
      "11th- epoch: 28, train_loss = 24.816485207527876, train_acc = 0.9460875640428504\n",
      "test Acc 0.9338919925512105:\n",
      "11th- epoch: 29, train_loss = 24.585766967386007, train_acc = 0.9470190964136004\n",
      "test Acc 0.9338919925512105:\n",
      "11th- epoch: 30, train_loss = 24.3664565756917, train_acc = 0.9469026548672567\n",
      "test Acc 0.9334264432029795:\n",
      "11th- epoch: 31, train_loss = 24.170579329133034, train_acc = 0.9470190964136004\n",
      "test Acc 0.9334264432029795:\n",
      "11th- epoch: 32, train_loss = 23.993282690644264, train_acc = 0.9481835118770378\n",
      "test Acc 0.9343575418994413:\n",
      "11th- epoch: 33, train_loss = 23.830131016671658, train_acc = 0.9486492780624126\n",
      "test Acc 0.9343575418994413:\n",
      "11th- epoch: 34, train_loss = 23.645293306559324, train_acc = 0.9489986027014439\n",
      "test Acc 0.9348230912476723:\n",
      "11th- epoch: 35, train_loss = 23.471174459904432, train_acc = 0.9493479273404751\n",
      "test Acc 0.936219739292365:\n",
      "11th- epoch: 36, train_loss = 23.299859512597322, train_acc = 0.9494643688868188\n",
      "test Acc 0.936219739292365:\n",
      "11th- epoch: 37, train_loss = 23.163410793989897, train_acc = 0.9501630181648812\n",
      "test Acc 0.9376163873370578:\n",
      "11th- epoch: 38, train_loss = 23.015074633061886, train_acc = 0.9507452258965999\n",
      "test Acc 0.9376163873370578:\n",
      "11th- epoch: 39, train_loss = 22.865668531507254, train_acc = 0.9507452258965999\n",
      "test Acc 0.9376163873370578:\n",
      "11th- epoch: 40, train_loss = 22.739386286586523, train_acc = 0.9514438751746623\n",
      "test Acc 0.9376163873370578:\n",
      "11th- epoch: 41, train_loss = 22.593194294720888, train_acc = 0.9517931998136935\n",
      "test Acc 0.9376163873370578:\n",
      "11th- epoch: 42, train_loss = 22.466116338968277, train_acc = 0.952026082906381\n",
      "test Acc 0.9376163873370578:\n",
      "11th- epoch: 43, train_loss = 22.338798630982637, train_acc = 0.952491849091756\n",
      "test Acc 0.9371508379888268:\n",
      "11th- epoch: 44, train_loss = 22.2293766066432, train_acc = 0.9522589659990685\n",
      "test Acc 0.9371508379888268:\n",
      "11th- epoch: 45, train_loss = 22.10165273025632, train_acc = 0.952491849091756\n",
      "test Acc 0.9376163873370578:\n",
      "11th- epoch: 46, train_loss = 21.982610892504454, train_acc = 0.9523754075454122\n",
      "test Acc 0.9380819366852886:\n",
      "11th- epoch: 47, train_loss = 21.855954717844725, train_acc = 0.9527247321844434\n",
      "test Acc 0.9376163873370578:\n",
      "11th- epoch: 48, train_loss = 21.756826121360064, train_acc = 0.9529576152771309\n",
      "test Acc 0.9376163873370578:\n",
      "11th- epoch: 49, train_loss = 21.646861128509045, train_acc = 0.9530740568234746\n",
      "test Acc 0.9376163873370578:\n",
      "11th- epoch: 50, train_loss = 21.54529706761241, train_acc = 0.9533069399161621\n",
      "test Acc 0.9380819366852886:\n",
      "11th- epoch: 51, train_loss = 21.44213492050767, train_acc = 0.9534233814625058\n",
      "test Acc 0.9385474860335196:\n",
      "11th- epoch: 52, train_loss = 21.338510613888502, train_acc = 0.9540055891942245\n",
      "test Acc 0.9390130353817505:\n",
      "11th- epoch: 53, train_loss = 21.241966538131237, train_acc = 0.9540055891942245\n",
      "test Acc 0.9380819366852886:\n",
      "11th- epoch: 54, train_loss = 21.17409847304225, train_acc = 0.9542384722869119\n",
      "test Acc 0.9385474860335196:\n",
      "11th- epoch: 55, train_loss = 21.069211941212416, train_acc = 0.9542384722869119\n",
      "test Acc 0.9385474860335196:\n",
      "11th- epoch: 56, train_loss = 20.994993072003126, train_acc = 0.9543549138332557\n",
      "test Acc 0.9385474860335196:\n",
      "11th- epoch: 57, train_loss = 20.912753134965897, train_acc = 0.9543549138332557\n",
      "test Acc 0.9385474860335196:\n",
      "11th- epoch: 58, train_loss = 20.820029988884926, train_acc = 0.9545877969259432\n",
      "test Acc 0.9385474860335196:\n",
      "11th- epoch: 59, train_loss = 20.753162547945976, train_acc = 0.9549371215649743\n",
      "test Acc 0.9394785847299814:\n",
      "11th- epoch: 60, train_loss = 20.655641797930002, train_acc = 0.9549371215649743\n",
      "test Acc 0.9394785847299814:\n",
      "11th- epoch: 61, train_loss = 20.57144385203719, train_acc = 0.9549371215649743\n",
      "test Acc 0.9390130353817505:\n",
      "11th- epoch: 62, train_loss = 20.496771778911352, train_acc = 0.9551700046576619\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 63, train_loss = 20.428863503038883, train_acc = 0.9552864462040056\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 64, train_loss = 20.34064009040594, train_acc = 0.9556357708430367\n",
      "test Acc 0.9404096834264432:\n",
      "11th- epoch: 65, train_loss = 20.276980478316545, train_acc = 0.9557522123893806\n",
      "test Acc 0.9408752327746741:\n",
      "11th- epoch: 66, train_loss = 20.201500877738, train_acc = 0.9556357708430367\n",
      "test Acc 0.9408752327746741:\n",
      "11th- epoch: 67, train_loss = 20.139909114688635, train_acc = 0.955519329296693\n",
      "test Acc 0.9408752327746741:\n",
      "11th- epoch: 68, train_loss = 20.0708492025733, train_acc = 0.9558686539357243\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 69, train_loss = 20.00179895758629, train_acc = 0.9558686539357243\n",
      "test Acc 0.9413407821229051:\n",
      "11th- epoch: 70, train_loss = 19.93325312063098, train_acc = 0.9556357708430367\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 71, train_loss = 19.88308922946453, train_acc = 0.9557522123893806\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 72, train_loss = 19.818706516176462, train_acc = 0.9561015370284117\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 73, train_loss = 19.7435453645885, train_acc = 0.9562179785747554\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 74, train_loss = 19.692659571766853, train_acc = 0.956450861667443\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 75, train_loss = 19.63253373838961, train_acc = 0.9565673032137867\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 76, train_loss = 19.580017862841487, train_acc = 0.9569166278528178\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 77, train_loss = 19.510119991376996, train_acc = 0.9569166278528178\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 78, train_loss = 19.469536811113358, train_acc = 0.9570330693991617\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 79, train_loss = 19.41387640684843, train_acc = 0.9570330693991617\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 80, train_loss = 19.364987635985017, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 81, train_loss = 19.308987261727452, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 82, train_loss = 19.257929740473628, train_acc = 0.9576152771308803\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 83, train_loss = 19.21800959855318, train_acc = 0.9577317186772241\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 84, train_loss = 19.159159498289227, train_acc = 0.9578481602235678\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 85, train_loss = 19.11183982901275, train_acc = 0.9578481602235678\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 86, train_loss = 19.076225413009524, train_acc = 0.9580810433162552\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 87, train_loss = 19.010458948090672, train_acc = 0.9580810433162552\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 88, train_loss = 18.970110243186355, train_acc = 0.9583139264089428\n",
      "test Acc 0.9422718808193669:\n",
      "11th- epoch: 89, train_loss = 18.918348701670766, train_acc = 0.9583139264089428\n",
      "test Acc 0.9422718808193669:\n",
      "11th- epoch: 90, train_loss = 18.884206665679812, train_acc = 0.9590125756870052\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 91, train_loss = 18.827709816396236, train_acc = 0.9587796925943176\n",
      "test Acc 0.9427374301675978:\n",
      "11th- epoch: 92, train_loss = 18.797395741567016, train_acc = 0.9590125756870052\n",
      "test Acc 0.9427374301675978:\n",
      "11th- epoch: 93, train_loss = 18.75551268644631, train_acc = 0.9591290172333489\n",
      "test Acc 0.9427374301675978:\n",
      "11th- epoch: 94, train_loss = 18.71193336509168, train_acc = 0.9591290172333489\n",
      "test Acc 0.9427374301675978:\n",
      "11th- epoch: 95, train_loss = 18.66848031617701, train_acc = 0.9591290172333489\n",
      "test Acc 0.9432029795158287:\n",
      "11th- epoch: 96, train_loss = 18.609966887161136, train_acc = 0.9592454587796926\n",
      "test Acc 0.9432029795158287:\n",
      "11th- epoch: 97, train_loss = 18.574761925265193, train_acc = 0.9593619003260363\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 98, train_loss = 18.5504235252738, train_acc = 0.9593619003260363\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 99, train_loss = 18.512851536273956, train_acc = 0.95947834187238\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 100, train_loss = 18.47678217291832, train_acc = 0.95947834187238\n",
      "test Acc 0.9436685288640596:\n",
      "11th- epoch: 101, train_loss = 18.430222066119313, train_acc = 0.95947834187238\n",
      "test Acc 0.9441340782122905:\n",
      "11th- epoch: 102, train_loss = 18.397190095856786, train_acc = 0.95947834187238\n",
      "test Acc 0.9441340782122905:\n",
      "11th- epoch: 103, train_loss = 18.354576697573066, train_acc = 0.9598276665114113\n",
      "test Acc 0.9441340782122905:\n",
      "11th- epoch: 104, train_loss = 18.314256252720952, train_acc = 0.959944108057755\n",
      "test Acc 0.9441340782122905:\n",
      "11th- epoch: 105, train_loss = 18.276528174057603, train_acc = 0.959944108057755\n",
      "test Acc 0.9441340782122905:\n",
      "11th- epoch: 106, train_loss = 18.26222196035087, train_acc = 0.959944108057755\n",
      "test Acc 0.9441340782122905:\n",
      "11th- epoch: 107, train_loss = 18.206151319667697, train_acc = 0.9601769911504425\n",
      "test Acc 0.9441340782122905:\n",
      "11th- epoch: 108, train_loss = 18.182204633951187, train_acc = 0.959944108057755\n",
      "test Acc 0.9441340782122905:\n",
      "11th- epoch: 109, train_loss = 18.13816333003342, train_acc = 0.9600605496040987\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 110, train_loss = 18.110403917729855, train_acc = 0.9600605496040987\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 111, train_loss = 18.069359639659524, train_acc = 0.9602934326967862\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 112, train_loss = 18.037810953333974, train_acc = 0.9602934326967862\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 113, train_loss = 18.01587768830359, train_acc = 0.96040987424313\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 114, train_loss = 17.977199018001556, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 115, train_loss = 17.95261005498469, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 116, train_loss = 17.914963195100427, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 117, train_loss = 17.88869292847812, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 118, train_loss = 17.852079758420587, train_acc = 0.9606427573358174\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 119, train_loss = 17.82340307533741, train_acc = 0.9606427573358174\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 120, train_loss = 17.801308481022716, train_acc = 0.9607591988821611\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 121, train_loss = 17.76360336691141, train_acc = 0.9608756404285049\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 122, train_loss = 17.73439727164805, train_acc = 0.9607591988821611\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 123, train_loss = 17.699885999783874, train_acc = 0.9608756404285049\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 124, train_loss = 17.685990186408162, train_acc = 0.9609920819748486\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 125, train_loss = 17.65348344296217, train_acc = 0.9609920819748486\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 126, train_loss = 17.635887494310737, train_acc = 0.9609920819748486\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 127, train_loss = 17.60105018876493, train_acc = 0.9612249650675361\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 128, train_loss = 17.571288734674454, train_acc = 0.9612249650675361\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 129, train_loss = 17.54852607101202, train_acc = 0.9612249650675361\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 130, train_loss = 17.521044248715043, train_acc = 0.9612249650675361\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 131, train_loss = 17.48984012939036, train_acc = 0.9612249650675361\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 132, train_loss = 17.466768600046635, train_acc = 0.9612249650675361\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 133, train_loss = 17.440681731328368, train_acc = 0.9613414066138798\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 134, train_loss = 17.410387188196182, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 135, train_loss = 17.383866772055626, train_acc = 0.9613414066138798\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 136, train_loss = 17.366264870390296, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 137, train_loss = 17.34171301871538, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 138, train_loss = 17.324693731963634, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 139, train_loss = 17.29439908824861, train_acc = 0.961690731252911\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 140, train_loss = 17.270263962447643, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 141, train_loss = 17.23681055009365, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 142, train_loss = 17.218377059325576, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 143, train_loss = 17.191128654405475, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 144, train_loss = 17.171245746314526, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 145, train_loss = 17.14594973810017, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 146, train_loss = 17.125558553263545, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 147, train_loss = 17.10388650931418, train_acc = 0.962156497438286\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 148, train_loss = 17.08491138368845, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 149, train_loss = 17.04940682835877, train_acc = 0.962156497438286\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 150, train_loss = 17.024634942412376, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 151, train_loss = 17.00360683351755, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 152, train_loss = 16.988729417324066, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 153, train_loss = 16.970137821510434, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 154, train_loss = 16.941978773102164, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 155, train_loss = 16.925397768616676, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 156, train_loss = 16.901994489133358, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 157, train_loss = 16.88175476528704, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 158, train_loss = 16.863052735105157, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 159, train_loss = 16.84784778393805, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 160, train_loss = 16.824948085471988, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 161, train_loss = 16.809840977191925, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 162, train_loss = 16.787652740254998, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 163, train_loss = 16.766930075362325, train_acc = 0.9628551467163484\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 164, train_loss = 16.73969949223101, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 165, train_loss = 16.738798899576068, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 166, train_loss = 16.710062995553017, train_acc = 0.9629715882626921\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 167, train_loss = 16.698712034150958, train_acc = 0.9632044713553796\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 168, train_loss = 16.676471361890435, train_acc = 0.9633209129017233\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 169, train_loss = 16.649961851537228, train_acc = 0.9633209129017233\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 170, train_loss = 16.636759901419282, train_acc = 0.9630880298090359\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 171, train_loss = 16.610065827146173, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 172, train_loss = 16.59920414350927, train_acc = 0.9630880298090359\n",
      "test Acc 0.9445996275605214:\n",
      "11th- epoch: 173, train_loss = 16.575312862172723, train_acc = 0.9636702375407545\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 174, train_loss = 16.562632324174047, train_acc = 0.9634373544480671\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 175, train_loss = 16.551059752702713, train_acc = 0.9636702375407545\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 176, train_loss = 16.530811570584774, train_acc = 0.9636702375407545\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 177, train_loss = 16.517512150108814, train_acc = 0.9636702375407545\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 178, train_loss = 16.491082230582833, train_acc = 0.9637866790870983\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 179, train_loss = 16.472699662670493, train_acc = 0.9637866790870983\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 180, train_loss = 16.458995698019862, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 181, train_loss = 16.457776689901948, train_acc = 0.9636702375407545\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 182, train_loss = 16.43442270718515, train_acc = 0.9636702375407545\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 183, train_loss = 16.410622015595436, train_acc = 0.9637866790870983\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 184, train_loss = 16.39812463335693, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 185, train_loss = 16.379647674039006, train_acc = 0.9636702375407545\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 186, train_loss = 16.368544697761536, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 187, train_loss = 16.343665666878223, train_acc = 0.9637866790870983\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 188, train_loss = 16.330090537667274, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 189, train_loss = 16.31318422406912, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 190, train_loss = 16.30043668113649, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 191, train_loss = 16.28305752016604, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 192, train_loss = 16.264607461169362, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 193, train_loss = 16.245494754984975, train_acc = 0.9644853283651607\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 194, train_loss = 16.24522210098803, train_acc = 0.9642524452724732\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 195, train_loss = 16.222148284316063, train_acc = 0.9641360037261295\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 196, train_loss = 16.201219825074077, train_acc = 0.9644853283651607\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 197, train_loss = 16.186904111877084, train_acc = 0.9642524452724732\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 198, train_loss = 16.162467563524842, train_acc = 0.9644853283651607\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 199, train_loss = 16.153657296672463, train_acc = 0.9644853283651607\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 200, train_loss = 16.14503486454487, train_acc = 0.9646017699115044\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 201, train_loss = 16.119886064901948, train_acc = 0.9644853283651607\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 202, train_loss = 16.12533850222826, train_acc = 0.9646017699115044\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 203, train_loss = 16.099262872710824, train_acc = 0.9643688868188169\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 204, train_loss = 16.08039921708405, train_acc = 0.9644853283651607\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 205, train_loss = 16.070096030831337, train_acc = 0.9644853283651607\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 206, train_loss = 16.049046337604523, train_acc = 0.9644853283651607\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 207, train_loss = 16.0354518070817, train_acc = 0.9644853283651607\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 208, train_loss = 16.031171092763543, train_acc = 0.9644853283651607\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 209, train_loss = 16.011223755776882, train_acc = 0.9646017699115044\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 210, train_loss = 16.00082764029503, train_acc = 0.9648346530041919\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 211, train_loss = 16.010314606130123, train_acc = 0.9646017699115044\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 212, train_loss = 15.979403600096703, train_acc = 0.9648346530041919\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 213, train_loss = 15.9702869951725, train_acc = 0.9646017699115044\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 214, train_loss = 15.9549811007455, train_acc = 0.9648346530041919\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 215, train_loss = 15.948057875037193, train_acc = 0.9646017699115044\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 216, train_loss = 15.92277625668794, train_acc = 0.9647182114578482\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 217, train_loss = 15.925880487076938, train_acc = 0.9647182114578482\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 218, train_loss = 15.896673458628356, train_acc = 0.9650675360968793\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 219, train_loss = 15.890188542194664, train_acc = 0.9649510945505356\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 220, train_loss = 15.877508918754756, train_acc = 0.9650675360968793\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 221, train_loss = 15.864294740371406, train_acc = 0.9648346530041919\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 222, train_loss = 15.85262664128095, train_acc = 0.9649510945505356\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 223, train_loss = 15.842316861264408, train_acc = 0.9650675360968793\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 224, train_loss = 15.823780315928161, train_acc = 0.9647182114578482\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 225, train_loss = 15.815754626877606, train_acc = 0.9650675360968793\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 226, train_loss = 15.807459123432636, train_acc = 0.9649510945505356\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 227, train_loss = 15.792794925160706, train_acc = 0.9648346530041919\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 228, train_loss = 15.766800154931843, train_acc = 0.9648346530041919\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 229, train_loss = 15.762421660125256, train_acc = 0.9649510945505356\n",
      "test Acc 0.9450651769087524:\n",
      "11th- epoch: 230, train_loss = 15.737973268143833, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 231, train_loss = 15.735550689511001, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 232, train_loss = 15.719866898842156, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 233, train_loss = 15.712182994000614, train_acc = 0.9651839776432231\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 234, train_loss = 15.705503243021667, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 235, train_loss = 15.68612061906606, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 236, train_loss = 15.670754407532513, train_acc = 0.9651839776432231\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 237, train_loss = 15.66888916771859, train_acc = 0.9648346530041919\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 238, train_loss = 15.651166163384914, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 239, train_loss = 15.641266067512333, train_acc = 0.9649510945505356\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 240, train_loss = 15.628623105585575, train_acc = 0.9654168607359106\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 241, train_loss = 15.631622125394642, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 242, train_loss = 15.6013895990327, train_acc = 0.9651839776432231\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 243, train_loss = 15.60635939706117, train_acc = 0.9653004191895669\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 244, train_loss = 15.586486193351448, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 245, train_loss = 15.577289733104408, train_acc = 0.9649510945505356\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 246, train_loss = 15.566233125515282, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 247, train_loss = 15.554760943166912, train_acc = 0.9650675360968793\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 248, train_loss = 15.528234414756298, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 249, train_loss = 15.51295891404152, train_acc = 0.965649743828598\n",
      "test Acc 0.9459962756052142:\n",
      "11th- epoch: 250, train_loss = 15.504383104853332, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 251, train_loss = 15.496152117848396, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 252, train_loss = 15.483124531805515, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 253, train_loss = 15.471681505441666, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 254, train_loss = 15.460301615297794, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 255, train_loss = 15.44703825097531, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 256, train_loss = 15.441536140628159, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 257, train_loss = 15.433630417101085, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 258, train_loss = 15.410893048159778, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 259, train_loss = 15.410770277492702, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 260, train_loss = 15.39881398063153, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 261, train_loss = 15.386783197522163, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 262, train_loss = 15.371751924045384, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 263, train_loss = 15.367831910960376, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 264, train_loss = 15.366373561322689, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 265, train_loss = 15.348381884396076, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 266, train_loss = 15.33807206619531, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 267, train_loss = 15.323687247931957, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 268, train_loss = 15.3184067979455, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 269, train_loss = 15.309849202632904, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 270, train_loss = 15.296592730097473, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 271, train_loss = 15.284687583334744, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 272, train_loss = 15.285165945999324, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 273, train_loss = 15.265968173742294, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 274, train_loss = 15.267682897858322, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 275, train_loss = 15.25767744332552, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 276, train_loss = 15.234913443215191, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 277, train_loss = 15.23762932419777, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 278, train_loss = 15.224644455127418, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 279, train_loss = 15.220798236317933, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 280, train_loss = 15.206739421002567, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 281, train_loss = 15.195638671517372, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 282, train_loss = 15.186980791389942, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 283, train_loss = 15.173563900403678, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 284, train_loss = 15.163017225451767, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 285, train_loss = 15.152256406843662, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 286, train_loss = 15.148362453095615, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 287, train_loss = 15.136777917854488, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 288, train_loss = 15.133647319860756, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 289, train_loss = 15.126241579651833, train_acc = 0.966581276199348\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 290, train_loss = 15.114521239884198, train_acc = 0.9664648346530041\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 291, train_loss = 15.108003690838814, train_acc = 0.9664648346530041\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 292, train_loss = 15.102618080563843, train_acc = 0.9664648346530041\n",
      "test Acc 0.9464618249534451:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 293, train_loss = 15.090650756843388, train_acc = 0.9664648346530041\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 294, train_loss = 15.08202548790723, train_acc = 0.9664648346530041\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 295, train_loss = 15.06872583180666, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 296, train_loss = 15.058213852345943, train_acc = 0.966581276199348\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 297, train_loss = 15.051987846381962, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 298, train_loss = 15.05711746495217, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 299, train_loss = 15.042523130774498, train_acc = 0.9668141592920354\n",
      "test Acc 0.9464618249534451:\n",
      "11th- epoch: 300, train_loss = 15.03767551947385, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 301, train_loss = 15.01834350079298, train_acc = 0.9668141592920354\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 302, train_loss = 15.011397990398109, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 303, train_loss = 15.001310368068516, train_acc = 0.9668141592920354\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 304, train_loss = 15.004578019492328, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "11th- epoch: 305, train_loss = 14.987958173267543, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 306, train_loss = 14.983700995333493, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 307, train_loss = 14.979661623947322, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 308, train_loss = 14.964322139509022, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 309, train_loss = 14.961627659387887, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 310, train_loss = 14.949631609022617, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 311, train_loss = 14.940156730823219, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 312, train_loss = 14.936371644027531, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 313, train_loss = 14.929129620082676, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 314, train_loss = 14.921009165234864, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 315, train_loss = 14.908644606359303, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 316, train_loss = 14.904176868498325, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 317, train_loss = 14.900371983647346, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 318, train_loss = 14.887025748379529, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 319, train_loss = 14.887948878109455, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 320, train_loss = 14.872078575193882, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 321, train_loss = 14.869408424012363, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 322, train_loss = 14.852070893160999, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 323, train_loss = 14.841117625124753, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 324, train_loss = 14.839970275759697, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 325, train_loss = 14.83714194316417, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 326, train_loss = 14.82454925775528, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 327, train_loss = 14.811566303484142, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 328, train_loss = 14.808826205320656, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 329, train_loss = 14.805367740802467, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 330, train_loss = 14.798883892595768, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 331, train_loss = 14.780993697233498, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 332, train_loss = 14.780286963097751, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 333, train_loss = 14.770806434564292, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 334, train_loss = 14.77540575247258, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 335, train_loss = 14.762968721799552, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 336, train_loss = 14.758181695826352, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 337, train_loss = 14.749375161714852, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "11th- epoch: 338, train_loss = 14.747655143029988, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 339, train_loss = 14.736792328767478, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 340, train_loss = 14.732336419634521, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 341, train_loss = 14.721878397278488, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 342, train_loss = 14.726268609054387, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 343, train_loss = 14.702065370976925, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 344, train_loss = 14.694302300922573, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 345, train_loss = 14.692371170036495, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 346, train_loss = 14.68304852116853, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 347, train_loss = 14.678367279469967, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 348, train_loss = 14.673789803870022, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 349, train_loss = 14.666209717281163, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 350, train_loss = 14.660347916185856, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 351, train_loss = 14.653355891816318, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 352, train_loss = 14.644240568391979, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 353, train_loss = 14.646585452370346, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 354, train_loss = 14.632577374577522, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 355, train_loss = 14.62388971913606, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 356, train_loss = 14.616512288339436, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 357, train_loss = 14.615955953486264, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 358, train_loss = 14.598925429396331, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 359, train_loss = 14.60132294613868, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 360, train_loss = 14.600467413663864, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 361, train_loss = 14.583996959030628, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 362, train_loss = 14.583296564407647, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 363, train_loss = 14.579583031125367, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 364, train_loss = 14.576265719719231, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 365, train_loss = 14.56045129429549, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 366, train_loss = 14.552085037343204, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 367, train_loss = 14.546783213503659, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 368, train_loss = 14.541116987355053, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 369, train_loss = 14.537399689666927, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 370, train_loss = 14.523802454583347, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 371, train_loss = 14.519625462591648, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 372, train_loss = 14.519788553006947, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 373, train_loss = 14.507935951463878, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 374, train_loss = 14.506669774651527, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 375, train_loss = 14.492569486610591, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 376, train_loss = 14.498105240054429, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 377, train_loss = 14.488022461533546, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 378, train_loss = 14.483677719719708, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 379, train_loss = 14.471422811038792, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 380, train_loss = 14.47074198257178, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 381, train_loss = 14.464262813329697, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 382, train_loss = 14.458374288864434, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 383, train_loss = 14.455889284610748, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 384, train_loss = 14.448707555420697, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 385, train_loss = 14.436914871446788, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 386, train_loss = 14.425583690404892, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 387, train_loss = 14.43230306636542, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 388, train_loss = 14.422727164812386, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 389, train_loss = 14.418759656138718, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 390, train_loss = 14.415660430677235, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 391, train_loss = 14.406478859484196, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 392, train_loss = 14.403468199074268, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 393, train_loss = 14.396755111403763, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 394, train_loss = 14.38912846148014, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 395, train_loss = 14.380753631703556, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 396, train_loss = 14.37907346803695, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 397, train_loss = 14.373355214484036, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 398, train_loss = 14.370549440383911, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 399, train_loss = 14.361446559429169, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 400, train_loss = 14.354720597155392, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 401, train_loss = 14.345732380636036, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 402, train_loss = 14.340866600163281, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 403, train_loss = 14.335411344654858, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 404, train_loss = 14.334194605238736, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 405, train_loss = 14.330157752148807, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 406, train_loss = 14.327627097256482, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 407, train_loss = 14.314268998801708, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 408, train_loss = 14.316088122315705, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 409, train_loss = 14.308031137101352, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 410, train_loss = 14.305693559348583, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 411, train_loss = 14.29940225649625, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 412, train_loss = 14.293602203018963, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 413, train_loss = 14.286234284751117, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 414, train_loss = 14.272597352974117, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 415, train_loss = 14.271921860985458, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 416, train_loss = 14.273745715618134, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 417, train_loss = 14.27154057752341, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 418, train_loss = 14.271326296031475, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 419, train_loss = 14.256610509939492, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 420, train_loss = 14.25331221241504, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 421, train_loss = 14.250954441726208, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 422, train_loss = 14.2378851743415, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 423, train_loss = 14.234551392495632, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 424, train_loss = 14.228388640098274, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 425, train_loss = 14.230202578008175, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 426, train_loss = 14.222420630045235, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 427, train_loss = 14.209358084015548, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 428, train_loss = 14.21420765388757, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 429, train_loss = 14.200208094902337, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 430, train_loss = 14.196387812495232, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 431, train_loss = 14.191164250485599, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 432, train_loss = 14.184739870019257, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 433, train_loss = 14.182743144221604, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 434, train_loss = 14.181041568517685, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 435, train_loss = 14.169117505662143, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 436, train_loss = 14.169850304722786, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 437, train_loss = 14.164129503071308, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 438, train_loss = 14.160755502991378, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 439, train_loss = 14.156790219247341, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 440, train_loss = 14.147065158002079, train_acc = 0.9691429902189101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 441, train_loss = 14.137011255137622, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 442, train_loss = 14.130592110566795, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 443, train_loss = 14.132968145422637, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 444, train_loss = 14.133935186080635, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 445, train_loss = 14.130808453075588, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 446, train_loss = 14.127703885547817, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 447, train_loss = 14.113116391003132, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 448, train_loss = 14.10908321570605, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 449, train_loss = 14.10837783664465, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 450, train_loss = 14.097390224225819, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 451, train_loss = 14.09451202582568, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 452, train_loss = 14.09379321616143, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 453, train_loss = 14.076297722756863, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 454, train_loss = 14.073017221875489, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 455, train_loss = 14.065585270524025, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 456, train_loss = 14.06435705255717, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 457, train_loss = 14.057090173475444, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 458, train_loss = 14.05846381187439, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 459, train_loss = 14.04741724068299, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 460, train_loss = 14.045541840139776, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 461, train_loss = 14.05048904567957, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 462, train_loss = 14.037597154732794, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 463, train_loss = 14.03482853109017, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 464, train_loss = 14.031497972551733, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 465, train_loss = 14.017673201858997, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 466, train_loss = 14.019550434313715, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 467, train_loss = 14.021295174956322, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 468, train_loss = 14.011983210686594, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 469, train_loss = 14.006314106285572, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 470, train_loss = 13.997834260109812, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 471, train_loss = 13.99748652940616, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 472, train_loss = 13.993490768130869, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 473, train_loss = 13.99395409738645, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 474, train_loss = 13.980573160108179, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 475, train_loss = 13.978487136308104, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 476, train_loss = 13.972938744816929, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 477, train_loss = 13.977207938674837, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 478, train_loss = 13.967900265008211, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 479, train_loss = 13.965828557964414, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 480, train_loss = 13.95993497222662, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 481, train_loss = 13.950725866016, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 482, train_loss = 13.955857495311648, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 483, train_loss = 13.947198055684566, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 484, train_loss = 13.94303503120318, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 485, train_loss = 13.943183604627848, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 486, train_loss = 13.928301786538213, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 487, train_loss = 13.928031466901302, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 488, train_loss = 13.924967476632446, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 489, train_loss = 13.922117906156927, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 490, train_loss = 13.927321463823318, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 491, train_loss = 13.911560373846442, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 492, train_loss = 13.900292951613665, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 493, train_loss = 13.90661639207974, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 494, train_loss = 13.903884412255138, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 495, train_loss = 13.895814994815737, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 496, train_loss = 13.891039290931076, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 497, train_loss = 13.882326528429985, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 498, train_loss = 13.87924263998866, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "11th- epoch: 499, train_loss = 13.882819067686796, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████▋                                            | 11/30 [1:39:42<2:52:16, 544.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "12th- epoch: 0, train_loss = 135.24134570360184, train_acc = 0.720540288775035\n",
      "test Acc 0.8272811918063314:\n",
      "12th- epoch: 1, train_loss = 62.9997153878212, train_acc = 0.8663251047973917\n",
      "test Acc 0.8770949720670391:\n",
      "12th- epoch: 2, train_loss = 51.31371168792248, train_acc = 0.8913600372612949\n",
      "test Acc 0.9003724394785847:\n",
      "12th- epoch: 3, train_loss = 45.642023265361786, train_acc = 0.9034699580810434\n",
      "test Acc 0.9078212290502793:\n",
      "12th- epoch: 4, train_loss = 42.066577434539795, train_acc = 0.9106893339543549\n",
      "test Acc 0.9180633147113594:\n",
      "12th- epoch: 5, train_loss = 39.395015604794025, train_acc = 0.9151141127154169\n",
      "test Acc 0.9194599627560521:\n",
      "12th- epoch: 6, train_loss = 37.34252028167248, train_acc = 0.9196553330228225\n",
      "test Acc 0.9231843575418994:\n",
      "12th- epoch: 7, train_loss = 35.67358274757862, train_acc = 0.9217512808570097\n",
      "test Acc 0.9241154562383612:\n",
      "12th- epoch: 8, train_loss = 34.36069496721029, train_acc = 0.9246623195156032\n",
      "test Acc 0.9264432029795159:\n",
      "12th- epoch: 9, train_loss = 33.239620469510555, train_acc = 0.9262925011644154\n",
      "test Acc 0.9264432029795159:\n",
      "12th- epoch: 10, train_loss = 32.28683066368103, train_acc = 0.9290870982766651\n",
      "test Acc 0.925512104283054:\n",
      "12th- epoch: 11, train_loss = 31.439281091094017, train_acc = 0.930018630647415\n",
      "test Acc 0.9259776536312849:\n",
      "12th- epoch: 12, train_loss = 30.681959345936775, train_acc = 0.9316488122962273\n",
      "test Acc 0.9283054003724395:\n",
      "12th- epoch: 13, train_loss = 30.0308428555727, train_acc = 0.9330461108523521\n",
      "test Acc 0.9283054003724395:\n",
      "12th- epoch: 14, train_loss = 29.423230729997158, train_acc = 0.9343269678621332\n",
      "test Acc 0.9301675977653632:\n",
      "12th- epoch: 15, train_loss = 28.87427093833685, train_acc = 0.9353749417792269\n",
      "test Acc 0.930633147113594:\n",
      "12th- epoch: 16, train_loss = 28.388493306934834, train_acc = 0.936190032603633\n",
      "test Acc 0.931098696461825:\n",
      "12th- epoch: 17, train_loss = 27.92088992893696, train_acc = 0.936655798789008\n",
      "test Acc 0.9315642458100558:\n",
      "12th- epoch: 18, train_loss = 27.48829661309719, train_acc = 0.9373544480670704\n",
      "test Acc 0.9324953445065177:\n",
      "12th- epoch: 19, train_loss = 27.112300973385572, train_acc = 0.9386353050768514\n",
      "test Acc 0.9334264432029795:\n",
      "12th- epoch: 20, train_loss = 26.7531267516315, train_acc = 0.9389846297158826\n",
      "test Acc 0.9334264432029795:\n",
      "12th- epoch: 21, train_loss = 26.41793568432331, train_acc = 0.9399161620866325\n",
      "test Acc 0.9348230912476723:\n",
      "12th- epoch: 22, train_loss = 26.095018349587917, train_acc = 0.9402654867256637\n",
      "test Acc 0.9343575418994413:\n",
      "12th- epoch: 23, train_loss = 25.782509736716747, train_acc = 0.9415463437354448\n",
      "test Acc 0.9352886405959032:\n",
      "12th- epoch: 24, train_loss = 25.524396497756243, train_acc = 0.9422449930135072\n",
      "test Acc 0.9357541899441341:\n",
      "12th- epoch: 25, train_loss = 25.264198623597622, train_acc = 0.9430600838379134\n",
      "test Acc 0.9357541899441341:\n",
      "12th- epoch: 26, train_loss = 24.992565035820007, train_acc = 0.9432929669306008\n",
      "test Acc 0.9357541899441341:\n",
      "12th- epoch: 27, train_loss = 24.758830681443214, train_acc = 0.9436422915696321\n",
      "test Acc 0.936219739292365:\n",
      "12th- epoch: 28, train_loss = 24.5267664603889, train_acc = 0.9451560316721006\n",
      "test Acc 0.936219739292365:\n",
      "12th- epoch: 29, train_loss = 24.319428987801075, train_acc = 0.945854680950163\n",
      "test Acc 0.9366852886405959:\n",
      "12th- epoch: 30, train_loss = 24.133903831243515, train_acc = 0.9462040055891943\n",
      "test Acc 0.9371508379888268:\n",
      "12th- epoch: 31, train_loss = 23.93936762958765, train_acc = 0.9472519795062878\n",
      "test Acc 0.9371508379888268:\n",
      "12th- epoch: 32, train_loss = 23.752684272825718, train_acc = 0.9478341872380065\n",
      "test Acc 0.9376163873370578:\n",
      "12th- epoch: 33, train_loss = 23.580897353589535, train_acc = 0.9482999534233815\n",
      "test Acc 0.9380819366852886:\n",
      "12th- epoch: 34, train_loss = 23.43017939850688, train_acc = 0.9492314857941313\n",
      "test Acc 0.9380819366852886:\n",
      "12th- epoch: 35, train_loss = 23.267434131354094, train_acc = 0.9495808104331626\n",
      "test Acc 0.9390130353817505:\n",
      "12th- epoch: 36, train_loss = 23.09842161461711, train_acc = 0.9495808104331626\n",
      "test Acc 0.9390130353817505:\n",
      "12th- epoch: 37, train_loss = 22.957326415926218, train_acc = 0.9495808104331626\n",
      "test Acc 0.9394785847299814:\n",
      "12th- epoch: 38, train_loss = 22.801561750471592, train_acc = 0.9501630181648812\n",
      "test Acc 0.9399441340782123:\n",
      "12th- epoch: 39, train_loss = 22.663429088890553, train_acc = 0.950279459711225\n",
      "test Acc 0.9404096834264432:\n",
      "12th- epoch: 40, train_loss = 22.50971569120884, train_acc = 0.9503959012575687\n",
      "test Acc 0.9408752327746741:\n",
      "12th- epoch: 41, train_loss = 22.380637641996145, train_acc = 0.9508616674429436\n",
      "test Acc 0.9408752327746741:\n",
      "12th- epoch: 42, train_loss = 22.253411799669266, train_acc = 0.9513274336283186\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 43, train_loss = 22.124942529946566, train_acc = 0.9517931998136935\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 44, train_loss = 22.02794136852026, train_acc = 0.952026082906381\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 45, train_loss = 21.908941976726055, train_acc = 0.9522589659990685\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 46, train_loss = 21.808245111256838, train_acc = 0.9528411737307871\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 47, train_loss = 21.682969994843006, train_acc = 0.9528411737307871\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 48, train_loss = 21.590715050697327, train_acc = 0.9530740568234746\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 49, train_loss = 21.4884000569582, train_acc = 0.9529576152771309\n",
      "test Acc 0.9413407821229051:\n",
      "12th- epoch: 50, train_loss = 21.38868982717395, train_acc = 0.9531904983698184\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 51, train_loss = 21.29695536568761, train_acc = 0.9531904983698184\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 52, train_loss = 21.209942921996117, train_acc = 0.9534233814625058\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 53, train_loss = 21.108265049755573, train_acc = 0.9544713553795995\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 54, train_loss = 21.030534356832504, train_acc = 0.9534233814625058\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 55, train_loss = 20.946488197892904, train_acc = 0.9535398230088495\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 56, train_loss = 20.879653185606003, train_acc = 0.9538891476478808\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 57, train_loss = 20.77625075355172, train_acc = 0.9549371215649743\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 58, train_loss = 20.72359263151884, train_acc = 0.9550535631113182\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 59, train_loss = 20.63282895833254, train_acc = 0.9550535631113182\n",
      "test Acc 0.9422718808193669:\n",
      "12th- epoch: 60, train_loss = 20.557486709207296, train_acc = 0.9552864462040056\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 61, train_loss = 20.479637902230024, train_acc = 0.9550535631113182\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 62, train_loss = 20.427254553884268, train_acc = 0.955519329296693\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 63, train_loss = 20.339984226971865, train_acc = 0.9554028877503493\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 64, train_loss = 20.289375618100166, train_acc = 0.9557522123893806\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 65, train_loss = 20.228544805198908, train_acc = 0.9558686539357243\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 66, train_loss = 20.159413520246744, train_acc = 0.955985095482068\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 67, train_loss = 20.10223811119795, train_acc = 0.9562179785747554\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 68, train_loss = 20.045212265104055, train_acc = 0.9562179785747554\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 69, train_loss = 19.98752017132938, train_acc = 0.9568001863064741\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 70, train_loss = 19.910929737612605, train_acc = 0.9569166278528178\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 71, train_loss = 19.847525477409363, train_acc = 0.9573823940381928\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 72, train_loss = 19.79779109545052, train_acc = 0.9573823940381928\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 73, train_loss = 19.737064780667424, train_acc = 0.9574988355845365\n",
      "test Acc 0.9427374301675978:\n",
      "12th- epoch: 74, train_loss = 19.676737347617745, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "12th- epoch: 75, train_loss = 19.625256966799498, train_acc = 0.9578481602235678\n",
      "test Acc 0.9432029795158287:\n",
      "12th- epoch: 76, train_loss = 19.57249421067536, train_acc = 0.9578481602235678\n",
      "test Acc 0.9432029795158287:\n",
      "12th- epoch: 77, train_loss = 19.52512021921575, train_acc = 0.9578481602235678\n",
      "test Acc 0.9432029795158287:\n",
      "12th- epoch: 78, train_loss = 19.465812811627984, train_acc = 0.9580810433162552\n",
      "test Acc 0.9441340782122905:\n",
      "12th- epoch: 79, train_loss = 19.427520720288157, train_acc = 0.9579646017699115\n",
      "test Acc 0.9441340782122905:\n",
      "12th- epoch: 80, train_loss = 19.375058200210333, train_acc = 0.9581974848625989\n",
      "test Acc 0.9441340782122905:\n",
      "12th- epoch: 81, train_loss = 19.326633125543594, train_acc = 0.9581974848625989\n",
      "test Acc 0.9441340782122905:\n",
      "12th- epoch: 82, train_loss = 19.276761885732412, train_acc = 0.9581974848625989\n",
      "test Acc 0.9441340782122905:\n",
      "12th- epoch: 83, train_loss = 19.23654985241592, train_acc = 0.9583139264089428\n",
      "test Acc 0.9445996275605214:\n",
      "12th- epoch: 84, train_loss = 19.184157950803638, train_acc = 0.9581974848625989\n",
      "test Acc 0.9445996275605214:\n",
      "12th- epoch: 85, train_loss = 19.14553933404386, train_acc = 0.9581974848625989\n",
      "test Acc 0.9445996275605214:\n",
      "12th- epoch: 86, train_loss = 19.093916749581695, train_acc = 0.9584303679552865\n",
      "test Acc 0.9445996275605214:\n",
      "12th- epoch: 87, train_loss = 19.04815542139113, train_acc = 0.9580810433162552\n",
      "test Acc 0.9445996275605214:\n",
      "12th- epoch: 88, train_loss = 19.0096055585891, train_acc = 0.9584303679552865\n",
      "test Acc 0.9445996275605214:\n",
      "12th- epoch: 89, train_loss = 18.967423049733043, train_acc = 0.9586632510479739\n",
      "test Acc 0.9445996275605214:\n",
      "12th- epoch: 90, train_loss = 18.92800184339285, train_acc = 0.9586632510479739\n",
      "test Acc 0.9445996275605214:\n",
      "12th- epoch: 91, train_loss = 18.884944109246135, train_acc = 0.9587796925943176\n",
      "test Acc 0.9450651769087524:\n",
      "12th- epoch: 92, train_loss = 18.857341147959232, train_acc = 0.9588961341406614\n",
      "test Acc 0.9445996275605214:\n",
      "12th- epoch: 93, train_loss = 18.798503521829844, train_acc = 0.9590125756870052\n",
      "test Acc 0.9445996275605214:\n",
      "12th- epoch: 94, train_loss = 18.75885900296271, train_acc = 0.9592454587796926\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 95, train_loss = 18.709443436935544, train_acc = 0.9591290172333489\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 96, train_loss = 18.676023095846176, train_acc = 0.9593619003260363\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 97, train_loss = 18.63410667143762, train_acc = 0.9593619003260363\n",
      "test Acc 0.9450651769087524:\n",
      "12th- epoch: 98, train_loss = 18.60172730498016, train_acc = 0.9593619003260363\n",
      "test Acc 0.9450651769087524:\n",
      "12th- epoch: 99, train_loss = 18.56329164467752, train_acc = 0.9593619003260363\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 100, train_loss = 18.521568946540356, train_acc = 0.9593619003260363\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 101, train_loss = 18.49018039740622, train_acc = 0.95947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 102, train_loss = 18.453191854059696, train_acc = 0.9595947834187238\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 103, train_loss = 18.42825618572533, train_acc = 0.9597112249650676\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 104, train_loss = 18.38559795729816, train_acc = 0.9598276665114113\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 105, train_loss = 18.342758120968938, train_acc = 0.9598276665114113\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 106, train_loss = 18.315755693241954, train_acc = 0.9598276665114113\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 107, train_loss = 18.281280582770705, train_acc = 0.9600605496040987\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 108, train_loss = 18.248133612796664, train_acc = 0.9602934326967862\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 109, train_loss = 18.212659442797303, train_acc = 0.9601769911504425\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 110, train_loss = 18.180200492963195, train_acc = 0.96040987424313\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 111, train_loss = 18.153884578496218, train_acc = 0.9606427573358174\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 112, train_loss = 18.12147719413042, train_acc = 0.9606427573358174\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 113, train_loss = 18.089258501306176, train_acc = 0.9607591988821611\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 114, train_loss = 18.066347302868962, train_acc = 0.9607591988821611\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 115, train_loss = 18.04672665335238, train_acc = 0.9607591988821611\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 116, train_loss = 17.997960010543466, train_acc = 0.9607591988821611\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 117, train_loss = 17.975080320611596, train_acc = 0.9608756404285049\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 118, train_loss = 17.931705635041, train_acc = 0.9608756404285049\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 119, train_loss = 17.906631648540497, train_acc = 0.9611085235211924\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 120, train_loss = 17.87200196273625, train_acc = 0.9609920819748486\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 121, train_loss = 17.85595093667507, train_acc = 0.9612249650675361\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 122, train_loss = 17.81981812044978, train_acc = 0.9612249650675361\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 123, train_loss = 17.800430845469236, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 124, train_loss = 17.762435687705874, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 125, train_loss = 17.734080197289586, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 126, train_loss = 17.712320948019624, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 127, train_loss = 17.68068210594356, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 128, train_loss = 17.67170355655253, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 129, train_loss = 17.627230210229754, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 130, train_loss = 17.61123356036842, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 131, train_loss = 17.571896087378263, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 132, train_loss = 17.54678588733077, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 133, train_loss = 17.530747512355447, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 134, train_loss = 17.500884236767888, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 135, train_loss = 17.483876764774323, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 136, train_loss = 17.463325245305896, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 137, train_loss = 17.4272369351238, train_acc = 0.9620400558919422\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 138, train_loss = 17.40671099536121, train_acc = 0.962156497438286\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 139, train_loss = 17.383152151480317, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 140, train_loss = 17.3634870108217, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 141, train_loss = 17.33102073520422, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 142, train_loss = 17.31706544570625, train_acc = 0.9622729389846297\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 143, train_loss = 17.29048828408122, train_acc = 0.9627387051700047\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 144, train_loss = 17.2503252197057, train_acc = 0.9627387051700047\n",
      "test Acc 0.9459962756052142:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 145, train_loss = 17.229709416627884, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 146, train_loss = 17.217738704755902, train_acc = 0.9628551467163484\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 147, train_loss = 17.202303010970354, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 148, train_loss = 17.169874308630824, train_acc = 0.9629715882626921\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 149, train_loss = 17.146025344729424, train_acc = 0.9628551467163484\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 150, train_loss = 17.120003938674927, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 151, train_loss = 17.103226287290454, train_acc = 0.9630880298090359\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 152, train_loss = 17.08506701886654, train_acc = 0.9628551467163484\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 153, train_loss = 17.050918390974402, train_acc = 0.9628551467163484\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 154, train_loss = 17.048917520791292, train_acc = 0.9630880298090359\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 155, train_loss = 17.01849718950689, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 156, train_loss = 16.980090895667672, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 157, train_loss = 16.967421082779765, train_acc = 0.9630880298090359\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 158, train_loss = 16.946967354044318, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 159, train_loss = 16.922469697892666, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 160, train_loss = 16.90664087422192, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 161, train_loss = 16.872481931000948, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 162, train_loss = 16.853030756115913, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 163, train_loss = 16.83982972614467, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 164, train_loss = 16.833838449791074, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 165, train_loss = 16.793537076562643, train_acc = 0.9635537959944108\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 166, train_loss = 16.781114062294364, train_acc = 0.9636702375407545\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 167, train_loss = 16.761581795290112, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 168, train_loss = 16.739678289741278, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 169, train_loss = 16.72074469923973, train_acc = 0.9635537959944108\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 170, train_loss = 16.70747290737927, train_acc = 0.9636702375407545\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 171, train_loss = 16.684719843789935, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 172, train_loss = 16.664008110761642, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 173, train_loss = 16.661948604509234, train_acc = 0.963903120633442\n",
      "test Acc 0.9455307262569832:\n",
      "12th- epoch: 174, train_loss = 16.62925892882049, train_acc = 0.963903120633442\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 175, train_loss = 16.616444427520037, train_acc = 0.9637866790870983\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 176, train_loss = 16.60467043146491, train_acc = 0.9637866790870983\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 177, train_loss = 16.577900361269712, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 178, train_loss = 16.563699312508106, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 179, train_loss = 16.54848943464458, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 180, train_loss = 16.525595551356673, train_acc = 0.963903120633442\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 181, train_loss = 16.508569587022066, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 182, train_loss = 16.503866782411933, train_acc = 0.963903120633442\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 183, train_loss = 16.486173355951905, train_acc = 0.963903120633442\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 184, train_loss = 16.46015960164368, train_acc = 0.963903120633442\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 185, train_loss = 16.473469888791442, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 186, train_loss = 16.433148588985205, train_acc = 0.963903120633442\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 187, train_loss = 16.412668630480766, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 188, train_loss = 16.40821960940957, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 189, train_loss = 16.391156205907464, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 190, train_loss = 16.385384565219283, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 191, train_loss = 16.355944076552987, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 192, train_loss = 16.340044289827347, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 193, train_loss = 16.32466990314424, train_acc = 0.9640195621797858\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 194, train_loss = 16.311735935509205, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 195, train_loss = 16.290903786197305, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 196, train_loss = 16.281394839286804, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 197, train_loss = 16.263618553057313, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 198, train_loss = 16.255843652412295, train_acc = 0.9641360037261295\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 199, train_loss = 16.231044286862016, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 200, train_loss = 16.23516301624477, train_acc = 0.9641360037261295\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 201, train_loss = 16.202304733917117, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 202, train_loss = 16.191289288923144, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 203, train_loss = 16.195670444518328, train_acc = 0.9641360037261295\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 204, train_loss = 16.15942715294659, train_acc = 0.9641360037261295\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 205, train_loss = 16.14777277223766, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 206, train_loss = 16.145257035270333, train_acc = 0.9641360037261295\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 207, train_loss = 16.1083198543638, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 208, train_loss = 16.096207046881318, train_acc = 0.9641360037261295\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 209, train_loss = 16.096250865608454, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 210, train_loss = 16.074031056836247, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 211, train_loss = 16.067983515560627, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 212, train_loss = 16.048818735405803, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 213, train_loss = 16.038978980854154, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 214, train_loss = 16.021535532549024, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 215, train_loss = 16.00471947528422, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 216, train_loss = 15.990514598786831, train_acc = 0.9643688868188169\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 217, train_loss = 15.973777268081903, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 218, train_loss = 15.95734379813075, train_acc = 0.9643688868188169\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 219, train_loss = 15.965742748230696, train_acc = 0.9642524452724732\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 220, train_loss = 15.9349310323596, train_acc = 0.9643688868188169\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 221, train_loss = 15.925352190621197, train_acc = 0.9643688868188169\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 222, train_loss = 15.89907065127045, train_acc = 0.9643688868188169\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 223, train_loss = 15.914886864833534, train_acc = 0.9644853283651607\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 224, train_loss = 15.896754343993962, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 225, train_loss = 15.887181881815195, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 226, train_loss = 15.866112787276506, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 227, train_loss = 15.855537588708103, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 228, train_loss = 15.824579036794603, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 229, train_loss = 15.822320979088545, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 230, train_loss = 15.803696598857641, train_acc = 0.9648346530041919\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 231, train_loss = 15.800974901765585, train_acc = 0.9648346530041919\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 232, train_loss = 15.781398550607264, train_acc = 0.9648346530041919\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 233, train_loss = 15.807586564682424, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 234, train_loss = 15.76130447909236, train_acc = 0.9648346530041919\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 235, train_loss = 15.755418728105724, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 236, train_loss = 15.744207662530243, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 237, train_loss = 15.732909988611937, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 238, train_loss = 15.721964522264898, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 239, train_loss = 15.707753296941519, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 240, train_loss = 15.696234199218452, train_acc = 0.9650675360968793\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 241, train_loss = 15.70671174582094, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 242, train_loss = 15.673725441098213, train_acc = 0.9651839776432231\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 243, train_loss = 15.68561265617609, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 244, train_loss = 15.652317247353494, train_acc = 0.9651839776432231\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 245, train_loss = 15.655622764490545, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 246, train_loss = 15.643569555133581, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 247, train_loss = 15.611987754702568, train_acc = 0.9653004191895669\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 248, train_loss = 15.612501416355371, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 249, train_loss = 15.589426598511636, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 250, train_loss = 15.593824598006904, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 251, train_loss = 15.578787181526423, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 252, train_loss = 15.565972522832453, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 253, train_loss = 15.553925701417029, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 254, train_loss = 15.542068011127412, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 255, train_loss = 15.530408937484026, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 256, train_loss = 15.531402450986207, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 257, train_loss = 15.51545017119497, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 258, train_loss = 15.50751422252506, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 259, train_loss = 15.492061006836593, train_acc = 0.965649743828598\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 260, train_loss = 15.491873902268708, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 261, train_loss = 15.486097970046103, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 262, train_loss = 15.469506139867008, train_acc = 0.9658826269212856\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 263, train_loss = 15.452795290388167, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 264, train_loss = 15.450133274309337, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 265, train_loss = 15.432152251712978, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 266, train_loss = 15.431463487446308, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 267, train_loss = 15.418022471480072, train_acc = 0.9658826269212856\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 268, train_loss = 15.410585198551416, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 269, train_loss = 15.394930005073547, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 270, train_loss = 15.39212713483721, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 271, train_loss = 15.382845346815884, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 272, train_loss = 15.369970824569464, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 273, train_loss = 15.353208196349442, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 274, train_loss = 15.346985871903598, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 275, train_loss = 15.336958788335323, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 276, train_loss = 15.333028831519186, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 277, train_loss = 15.318572434596717, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "12th- epoch: 278, train_loss = 15.312779572792351, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 279, train_loss = 15.312848300673068, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 280, train_loss = 15.30206869263202, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 281, train_loss = 15.281571269966662, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 282, train_loss = 15.275346204638481, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 283, train_loss = 15.279372136108577, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 284, train_loss = 15.263516993261874, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 285, train_loss = 15.241516824811697, train_acc = 0.9662319515603167\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 286, train_loss = 15.248672117479146, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 287, train_loss = 15.233556353487074, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 288, train_loss = 15.228703851811588, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 289, train_loss = 15.2130843764171, train_acc = 0.9662319515603167\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 290, train_loss = 15.21609327942133, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 291, train_loss = 15.193782920949161, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 292, train_loss = 15.19376511592418, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 293, train_loss = 15.175265991128981, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 294, train_loss = 15.179737276397645, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 295, train_loss = 15.159586392343044, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 296, train_loss = 15.158377938903868, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 297, train_loss = 15.143397034145892, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 298, train_loss = 15.141530535183847, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 299, train_loss = 15.12413448188454, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 300, train_loss = 15.131431422196329, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 301, train_loss = 15.102364521473646, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 302, train_loss = 15.104288562200963, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 303, train_loss = 15.096722143702209, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 304, train_loss = 15.091421428136528, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 305, train_loss = 15.078519695438445, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 306, train_loss = 15.066926031373441, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 307, train_loss = 15.063708405941725, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 308, train_loss = 15.056501208804548, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 309, train_loss = 15.046426213346422, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 310, train_loss = 15.037159916944802, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 311, train_loss = 15.036415260285139, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 312, train_loss = 15.029319538734853, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 313, train_loss = 15.01238061953336, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 314, train_loss = 15.006349891424179, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 315, train_loss = 15.000502035953104, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 316, train_loss = 14.999289103783667, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 317, train_loss = 14.986175693571568, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 318, train_loss = 14.975061410106719, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 319, train_loss = 14.974117099307477, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 320, train_loss = 14.957873248495162, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 321, train_loss = 14.959871456027031, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 322, train_loss = 14.955637485720217, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 323, train_loss = 14.942802689038217, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 324, train_loss = 14.93362798448652, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 325, train_loss = 14.926461129449308, train_acc = 0.9669306008383791\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 326, train_loss = 14.922552906908095, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 327, train_loss = 14.913109033368528, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 328, train_loss = 14.90441657230258, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 329, train_loss = 14.899223322980106, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 330, train_loss = 14.888777130283415, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 331, train_loss = 14.876766576431692, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 332, train_loss = 14.868744052946568, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 333, train_loss = 14.865816337056458, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 334, train_loss = 14.860755071043968, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 335, train_loss = 14.847463221289217, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 336, train_loss = 14.842953711748123, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 337, train_loss = 14.828117127530277, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 338, train_loss = 14.824883677996695, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 339, train_loss = 14.821815419010818, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 340, train_loss = 14.811047562398016, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 341, train_loss = 14.80911969859153, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 342, train_loss = 14.799432594329119, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 343, train_loss = 14.796977419406176, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 344, train_loss = 14.77856947015971, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 345, train_loss = 14.789199136197567, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 346, train_loss = 14.768555575050414, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 347, train_loss = 14.756698501296341, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 348, train_loss = 14.763590193353593, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 349, train_loss = 14.746838727034628, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 350, train_loss = 14.734610696323216, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 351, train_loss = 14.727153382264078, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 352, train_loss = 14.716648697853088, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 353, train_loss = 14.709419794380665, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 354, train_loss = 14.706420228816569, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 355, train_loss = 14.706872012466192, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 356, train_loss = 14.710847347043455, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 357, train_loss = 14.689773184247315, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 358, train_loss = 14.69683514162898, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 359, train_loss = 14.679048906080425, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 360, train_loss = 14.670860932208598, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 361, train_loss = 14.660994418896735, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 362, train_loss = 14.650539585389197, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 363, train_loss = 14.644221850670874, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 364, train_loss = 14.645745084621012, train_acc = 0.9677456916627852\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 365, train_loss = 14.639662481844425, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 366, train_loss = 14.638860530219972, train_acc = 0.9677456916627852\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 367, train_loss = 14.624069400131702, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 368, train_loss = 14.610985624603927, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 369, train_loss = 14.604855281300843, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 370, train_loss = 14.605925302021205, train_acc = 0.9678621332091291\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 371, train_loss = 14.607065481133759, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 372, train_loss = 14.58538228739053, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 373, train_loss = 14.586712674237788, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 374, train_loss = 14.587829518131912, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 375, train_loss = 14.58151385281235, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 376, train_loss = 14.576871438883245, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 377, train_loss = 14.553405339829624, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "12th- epoch: 378, train_loss = 14.552528872154653, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 379, train_loss = 14.546919199638069, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 380, train_loss = 14.547085386700928, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 381, train_loss = 14.53022542130202, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 382, train_loss = 14.526768941432238, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 383, train_loss = 14.515475378371775, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 384, train_loss = 14.511482938192785, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 385, train_loss = 14.510492295958102, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 386, train_loss = 14.50064096506685, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 387, train_loss = 14.488488364964724, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 388, train_loss = 14.48309662565589, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 389, train_loss = 14.480585531331599, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 390, train_loss = 14.473835404962301, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 391, train_loss = 14.468767903745174, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 392, train_loss = 14.461923006922007, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 393, train_loss = 14.461654589511454, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "12th- epoch: 394, train_loss = 14.450882647186518, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 395, train_loss = 14.444796480238438, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 396, train_loss = 14.436032102443278, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "12th- epoch: 397, train_loss = 14.425332519225776, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 398, train_loss = 14.436486075632274, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "12th- epoch: 399, train_loss = 14.43026293348521, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "12th- epoch: 400, train_loss = 14.427891831845045, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "12th- epoch: 401, train_loss = 14.420561444945633, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "12th- epoch: 402, train_loss = 14.408426309935749, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 403, train_loss = 14.392701066099107, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 404, train_loss = 14.392789469100535, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 405, train_loss = 14.383805281482637, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 406, train_loss = 14.379875333048403, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 407, train_loss = 14.37377689871937, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 408, train_loss = 14.371939054690301, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 409, train_loss = 14.36369466688484, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 410, train_loss = 14.36168960109353, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 411, train_loss = 14.349247721023858, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 412, train_loss = 14.350172211416066, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 413, train_loss = 14.344072222709656, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 414, train_loss = 14.333772748708725, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 415, train_loss = 14.333928252570331, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 416, train_loss = 14.332236687652767, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 417, train_loss = 14.325233296491206, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 418, train_loss = 14.311249219812453, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 419, train_loss = 14.304619755595922, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 420, train_loss = 14.302347959019244, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 421, train_loss = 14.302999368868768, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 422, train_loss = 14.294622880406678, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 423, train_loss = 14.28653281647712, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 424, train_loss = 14.28664620500058, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 425, train_loss = 14.279930412769318, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 426, train_loss = 14.278570804744959, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 427, train_loss = 14.266621054150164, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 428, train_loss = 14.269170532934368, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 429, train_loss = 14.255550406873226, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 430, train_loss = 14.2507339194417, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 431, train_loss = 14.245841189287603, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 432, train_loss = 14.23934956267476, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 433, train_loss = 14.239456862211227, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 434, train_loss = 14.231549702584743, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 435, train_loss = 14.225346747785807, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 436, train_loss = 14.215486757457256, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 437, train_loss = 14.21580099221319, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 438, train_loss = 14.21956445556134, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 439, train_loss = 14.203845982439816, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 440, train_loss = 14.198719386011362, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 441, train_loss = 14.196031064726412, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 442, train_loss = 14.192805618979037, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 443, train_loss = 14.185138790868223, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 444, train_loss = 14.181323205120862, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 445, train_loss = 14.178882011212409, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 446, train_loss = 14.183547589927912, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 447, train_loss = 14.178386949002743, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 448, train_loss = 14.17171041527763, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 449, train_loss = 14.161668424960226, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 450, train_loss = 14.153299443423748, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 451, train_loss = 14.161142022814602, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 452, train_loss = 14.153952736407518, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 453, train_loss = 14.135543961077929, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 454, train_loss = 14.13206605380401, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 455, train_loss = 14.128128020558506, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 456, train_loss = 14.119400916155428, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 457, train_loss = 14.117386829108, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 458, train_loss = 14.11553701525554, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 459, train_loss = 14.108017813414335, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 460, train_loss = 14.09961852291599, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 461, train_loss = 14.108306544367224, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 462, train_loss = 14.093761894851923, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 463, train_loss = 14.090419770684093, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 464, train_loss = 14.091110970824957, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 465, train_loss = 14.087581355124712, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 466, train_loss = 14.082680966705084, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 467, train_loss = 14.083748873323202, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 468, train_loss = 14.073016883339733, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 469, train_loss = 14.068689157720655, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 470, train_loss = 14.066980006638914, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 471, train_loss = 14.057369017507881, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 472, train_loss = 14.05196629324928, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 473, train_loss = 14.065039332956076, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 474, train_loss = 14.050978733692318, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 475, train_loss = 14.034474442247301, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 476, train_loss = 14.026815032120794, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 477, train_loss = 14.03881598636508, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 478, train_loss = 14.027054452802986, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 479, train_loss = 14.023034220095724, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 480, train_loss = 14.024703396018595, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 481, train_loss = 14.011365746613592, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 482, train_loss = 14.012772177811712, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 483, train_loss = 14.000623226165771, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 484, train_loss = 14.002120836172253, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 485, train_loss = 13.998182757291943, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 486, train_loss = 13.98692935705185, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 487, train_loss = 13.984901070594788, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 488, train_loss = 13.97743202233687, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 489, train_loss = 13.974247510079294, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 490, train_loss = 13.972794579807669, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 491, train_loss = 13.970104100648314, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 492, train_loss = 13.96744334185496, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 493, train_loss = 13.955091626849025, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 494, train_loss = 13.953736515250057, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 495, train_loss = 13.954501384403557, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 496, train_loss = 13.944518325384706, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 497, train_loss = 13.942825259175152, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 498, train_loss = 13.938172748778015, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 499, train_loss = 13.939597482327372, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████                                          | 12/30 [1:48:46<2:43:08, 543.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "13th- epoch: 0, train_loss = 117.53854861855507, train_acc = 0.7552398695854681\n",
      "test Acc 0.851024208566108:\n",
      "13th- epoch: 1, train_loss = 59.90960466861725, train_acc = 0.8754075454122031\n",
      "test Acc 0.8687150837988827:\n",
      "13th- epoch: 2, train_loss = 50.66846892237663, train_acc = 0.8952026082906381\n",
      "test Acc 0.8761638733705773:\n",
      "13th- epoch: 3, train_loss = 45.750662475824356, train_acc = 0.904052165812762\n",
      "test Acc 0.8854748603351955:\n",
      "13th- epoch: 4, train_loss = 42.34278203547001, train_acc = 0.9096413600372613\n",
      "test Acc 0.8980446927374302:\n",
      "13th- epoch: 5, train_loss = 39.739959962666035, train_acc = 0.9140661387983232\n",
      "test Acc 0.909217877094972:\n",
      "13th- epoch: 6, train_loss = 37.68308274447918, train_acc = 0.918141592920354\n",
      "test Acc 0.9115456238361266:\n",
      "13th- epoch: 7, train_loss = 36.04147943109274, train_acc = 0.9214019562179786\n",
      "test Acc 0.9129422718808193:\n",
      "13th- epoch: 8, train_loss = 34.682032123208046, train_acc = 0.9248952026082906\n",
      "test Acc 0.9171322160148976:\n",
      "13th- epoch: 9, train_loss = 33.53381337225437, train_acc = 0.9275733581741965\n",
      "test Acc 0.9194599627560521:\n",
      "13th- epoch: 10, train_loss = 32.52288460731506, train_acc = 0.9299021891010713\n",
      "test Acc 0.9231843575418994:\n",
      "13th- epoch: 11, train_loss = 31.613288439810276, train_acc = 0.9325803446669771\n",
      "test Acc 0.925512104283054:\n",
      "13th- epoch: 12, train_loss = 30.84025603532791, train_acc = 0.9345598509548206\n",
      "test Acc 0.9283054003724395:\n",
      "13th- epoch: 13, train_loss = 30.17265623807907, train_acc = 0.9365393572426641\n",
      "test Acc 0.9315642458100558:\n",
      "13th- epoch: 14, train_loss = 29.59155421704054, train_acc = 0.9381695388914765\n",
      "test Acc 0.9320297951582868:\n",
      "13th- epoch: 15, train_loss = 29.032957538962364, train_acc = 0.9394503959012576\n",
      "test Acc 0.9320297951582868:\n",
      "13th- epoch: 16, train_loss = 28.550987541675568, train_acc = 0.9403819282720075\n",
      "test Acc 0.9329608938547486:\n",
      "13th- epoch: 17, train_loss = 28.061804220080376, train_acc = 0.9410805775500699\n",
      "test Acc 0.9338919925512105:\n",
      "13th- epoch: 18, train_loss = 27.670273333787918, train_acc = 0.9415463437354448\n",
      "test Acc 0.9343575418994413:\n",
      "13th- epoch: 19, train_loss = 27.250489726662636, train_acc = 0.9424778761061947\n",
      "test Acc 0.9338919925512105:\n",
      "13th- epoch: 20, train_loss = 26.87297733128071, train_acc = 0.9430600838379134\n",
      "test Acc 0.9338919925512105:\n",
      "13th- epoch: 21, train_loss = 26.527231238782406, train_acc = 0.9437587331159758\n",
      "test Acc 0.9343575418994413:\n",
      "13th- epoch: 22, train_loss = 26.214896984398365, train_acc = 0.9446902654867256\n",
      "test Acc 0.9343575418994413:\n",
      "13th- epoch: 23, train_loss = 25.911765530705452, train_acc = 0.9451560316721006\n",
      "test Acc 0.9343575418994413:\n",
      "13th- epoch: 24, train_loss = 25.62769066542387, train_acc = 0.9456217978574756\n",
      "test Acc 0.9343575418994413:\n",
      "13th- epoch: 25, train_loss = 25.37233266234398, train_acc = 0.945854680950163\n",
      "test Acc 0.9348230912476723:\n",
      "13th- epoch: 26, train_loss = 25.11495177447796, train_acc = 0.9464368886818817\n",
      "test Acc 0.9348230912476723:\n",
      "13th- epoch: 27, train_loss = 24.87786925956607, train_acc = 0.9471355379599441\n",
      "test Acc 0.9348230912476723:\n",
      "13th- epoch: 28, train_loss = 24.652281023561954, train_acc = 0.9474848625989754\n",
      "test Acc 0.9343575418994413:\n",
      "13th- epoch: 29, train_loss = 24.421268433332443, train_acc = 0.9477177456916628\n",
      "test Acc 0.9348230912476723:\n",
      "13th- epoch: 30, train_loss = 24.217768330127, train_acc = 0.9484163949697252\n",
      "test Acc 0.9357541899441341:\n",
      "13th- epoch: 31, train_loss = 24.033818278461695, train_acc = 0.9479506287843502\n",
      "test Acc 0.9366852886405959:\n",
      "13th- epoch: 32, train_loss = 23.854629691690207, train_acc = 0.9484163949697252\n",
      "test Acc 0.936219739292365:\n",
      "13th- epoch: 33, train_loss = 23.67748024687171, train_acc = 0.9482999534233815\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 34, train_loss = 23.50074404105544, train_acc = 0.9486492780624126\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 35, train_loss = 23.340984515845776, train_acc = 0.9488821611551002\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 36, train_loss = 23.18841614574194, train_acc = 0.9489986027014439\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 37, train_loss = 23.036543533205986, train_acc = 0.9494643688868188\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 38, train_loss = 22.881507601588964, train_acc = 0.9495808104331626\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 39, train_loss = 22.756370402872562, train_acc = 0.94981369352585\n",
      "test Acc 0.9394785847299814:\n",
      "13th- epoch: 40, train_loss = 22.622217148542404, train_acc = 0.9499301350721937\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 41, train_loss = 22.489365864545107, train_acc = 0.950279459711225\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 42, train_loss = 22.35260719060898, train_acc = 0.9505123428039124\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 43, train_loss = 22.22721814736724, train_acc = 0.9507452258965999\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 44, train_loss = 22.105571262538433, train_acc = 0.9509781089892874\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 45, train_loss = 21.99370175972581, train_acc = 0.9510945505356311\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 46, train_loss = 21.875875737518072, train_acc = 0.9514438751746623\n",
      "test Acc 0.9394785847299814:\n",
      "13th- epoch: 47, train_loss = 21.761558137834072, train_acc = 0.9517931998136935\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 48, train_loss = 21.66233003512025, train_acc = 0.952026082906381\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 49, train_loss = 21.545426215976477, train_acc = 0.9521425244527247\n",
      "test Acc 0.9394785847299814:\n",
      "13th- epoch: 50, train_loss = 21.455071661621332, train_acc = 0.9522589659990685\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 51, train_loss = 21.349896170198917, train_acc = 0.9521425244527247\n",
      "test Acc 0.9394785847299814:\n",
      "13th- epoch: 52, train_loss = 21.265154872089624, train_acc = 0.952491849091756\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 53, train_loss = 21.170762926340103, train_acc = 0.9529576152771309\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 54, train_loss = 21.070560734719038, train_acc = 0.9530740568234746\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 55, train_loss = 20.99271149933338, train_acc = 0.9534233814625058\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 56, train_loss = 20.907975737005472, train_acc = 0.9534233814625058\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 57, train_loss = 20.83259680122137, train_acc = 0.9535398230088495\n",
      "test Acc 0.9394785847299814:\n",
      "13th- epoch: 58, train_loss = 20.749522145837545, train_acc = 0.9541220307405682\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 59, train_loss = 20.670821603387594, train_acc = 0.9540055891942245\n",
      "test Acc 0.9399441340782123:\n",
      "13th- epoch: 60, train_loss = 20.587825767695904, train_acc = 0.9543549138332557\n",
      "test Acc 0.9399441340782123:\n",
      "13th- epoch: 61, train_loss = 20.51750173047185, train_acc = 0.9547042384722869\n",
      "test Acc 0.9390130353817505:\n",
      "13th- epoch: 62, train_loss = 20.4358413182199, train_acc = 0.9543549138332557\n",
      "test Acc 0.9399441340782123:\n",
      "13th- epoch: 63, train_loss = 20.36731308326125, train_acc = 0.9549371215649743\n",
      "test Acc 0.9399441340782123:\n",
      "13th- epoch: 64, train_loss = 20.29732148721814, train_acc = 0.9554028877503493\n",
      "test Acc 0.9399441340782123:\n",
      "13th- epoch: 65, train_loss = 20.22083565965295, train_acc = 0.9554028877503493\n",
      "test Acc 0.9399441340782123:\n",
      "13th- epoch: 66, train_loss = 20.15966647490859, train_acc = 0.9558686539357243\n",
      "test Acc 0.9399441340782123:\n",
      "13th- epoch: 67, train_loss = 20.102934759110212, train_acc = 0.9561015370284117\n",
      "test Acc 0.9394785847299814:\n",
      "13th- epoch: 68, train_loss = 20.029225504025817, train_acc = 0.956450861667443\n",
      "test Acc 0.9394785847299814:\n",
      "13th- epoch: 69, train_loss = 19.962687565013766, train_acc = 0.9563344201210993\n",
      "test Acc 0.9394785847299814:\n",
      "13th- epoch: 70, train_loss = 19.89597219787538, train_acc = 0.9565673032137867\n",
      "test Acc 0.9404096834264432:\n",
      "13th- epoch: 71, train_loss = 19.837506690993905, train_acc = 0.9566837447601304\n",
      "test Acc 0.9404096834264432:\n",
      "13th- epoch: 72, train_loss = 19.781039161607623, train_acc = 0.9569166278528178\n",
      "test Acc 0.9404096834264432:\n",
      "13th- epoch: 73, train_loss = 19.71861214749515, train_acc = 0.9571495109455054\n",
      "test Acc 0.9404096834264432:\n",
      "13th- epoch: 74, train_loss = 19.670969255268574, train_acc = 0.9569166278528178\n",
      "test Acc 0.9404096834264432:\n",
      "13th- epoch: 75, train_loss = 19.606847723945975, train_acc = 0.9576152771308803\n",
      "test Acc 0.9404096834264432:\n",
      "13th- epoch: 76, train_loss = 19.546342089772224, train_acc = 0.9574988355845365\n",
      "test Acc 0.9404096834264432:\n",
      "13th- epoch: 77, train_loss = 19.504076851531863, train_acc = 0.9576152771308803\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 78, train_loss = 19.456739032641053, train_acc = 0.9578481602235678\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 79, train_loss = 19.389197865501046, train_acc = 0.9580810433162552\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 80, train_loss = 19.34663805551827, train_acc = 0.9585468095016302\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 81, train_loss = 19.294189900159836, train_acc = 0.9583139264089428\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 82, train_loss = 19.250144528225064, train_acc = 0.9584303679552865\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 83, train_loss = 19.20535003952682, train_acc = 0.9587796925943176\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 84, train_loss = 19.1553550735116, train_acc = 0.9590125756870052\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 85, train_loss = 19.103182746097445, train_acc = 0.9587796925943176\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 86, train_loss = 19.055760903283954, train_acc = 0.9591290172333489\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 87, train_loss = 19.022241147235036, train_acc = 0.9591290172333489\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 88, train_loss = 18.97779766470194, train_acc = 0.9590125756870052\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 89, train_loss = 18.930762326344848, train_acc = 0.9590125756870052\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 90, train_loss = 18.883036037907004, train_acc = 0.9593619003260363\n",
      "test Acc 0.9408752327746741:\n",
      "13th- epoch: 91, train_loss = 18.849617309868336, train_acc = 0.9593619003260363\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 92, train_loss = 18.80568401515484, train_acc = 0.95947834187238\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 93, train_loss = 18.764565525576472, train_acc = 0.9597112249650676\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 94, train_loss = 18.722534703090787, train_acc = 0.9597112249650676\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 95, train_loss = 18.684546010568738, train_acc = 0.9597112249650676\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 96, train_loss = 18.64684523642063, train_acc = 0.9598276665114113\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 97, train_loss = 18.60739456117153, train_acc = 0.9598276665114113\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 98, train_loss = 18.57301665842533, train_acc = 0.9600605496040987\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 99, train_loss = 18.531286388635635, train_acc = 0.9601769911504425\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 100, train_loss = 18.50147690065205, train_acc = 0.9601769911504425\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 101, train_loss = 18.455219404771924, train_acc = 0.9602934326967862\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 102, train_loss = 18.417323069646955, train_acc = 0.9602934326967862\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 103, train_loss = 18.384742876514792, train_acc = 0.9602934326967862\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 104, train_loss = 18.3430180773139, train_acc = 0.96040987424313\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 105, train_loss = 18.308573776856065, train_acc = 0.96040987424313\n",
      "test Acc 0.9418063314711359:\n",
      "13th- epoch: 106, train_loss = 18.27861743234098, train_acc = 0.96040987424313\n",
      "test Acc 0.9418063314711359:\n",
      "13th- epoch: 107, train_loss = 18.23975464142859, train_acc = 0.96040987424313\n",
      "test Acc 0.9418063314711359:\n",
      "13th- epoch: 108, train_loss = 18.19989130087197, train_acc = 0.96040987424313\n",
      "test Acc 0.9422718808193669:\n",
      "13th- epoch: 109, train_loss = 18.176804868504405, train_acc = 0.9605263157894737\n",
      "test Acc 0.9422718808193669:\n",
      "13th- epoch: 110, train_loss = 18.141760053113103, train_acc = 0.9605263157894737\n",
      "test Acc 0.9422718808193669:\n",
      "13th- epoch: 111, train_loss = 18.10639508999884, train_acc = 0.9605263157894737\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 112, train_loss = 18.076202243566513, train_acc = 0.9605263157894737\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 113, train_loss = 18.03818273358047, train_acc = 0.96040987424313\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 114, train_loss = 18.000519627705216, train_acc = 0.96040987424313\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 115, train_loss = 17.973306581377983, train_acc = 0.96040987424313\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 116, train_loss = 17.957956364378333, train_acc = 0.9605263157894737\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 117, train_loss = 17.914769558236003, train_acc = 0.9607591988821611\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 118, train_loss = 17.88766974210739, train_acc = 0.9608756404285049\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 119, train_loss = 17.856695069000125, train_acc = 0.9608756404285049\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 120, train_loss = 17.836937045678496, train_acc = 0.9612249650675361\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 121, train_loss = 17.793636871501803, train_acc = 0.9611085235211924\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 122, train_loss = 17.763433903455734, train_acc = 0.9612249650675361\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 123, train_loss = 17.739662455394864, train_acc = 0.9611085235211924\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 124, train_loss = 17.718475587666035, train_acc = 0.9614578481602236\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 125, train_loss = 17.687490044161677, train_acc = 0.9615742897065673\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 126, train_loss = 17.65524379350245, train_acc = 0.961690731252911\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 127, train_loss = 17.627641459926963, train_acc = 0.961690731252911\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 128, train_loss = 17.596564078703523, train_acc = 0.9618071727992548\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 129, train_loss = 17.56719659268856, train_acc = 0.9618071727992548\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 130, train_loss = 17.53703543357551, train_acc = 0.9618071727992548\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 131, train_loss = 17.517404928803444, train_acc = 0.9619236143455985\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 132, train_loss = 17.497779339551926, train_acc = 0.9620400558919422\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 133, train_loss = 17.475877858698368, train_acc = 0.962156497438286\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 134, train_loss = 17.443587167188525, train_acc = 0.9620400558919422\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 135, train_loss = 17.41872814297676, train_acc = 0.962156497438286\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 136, train_loss = 17.391335874795914, train_acc = 0.9622729389846297\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 137, train_loss = 17.369206061586738, train_acc = 0.9622729389846297\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 138, train_loss = 17.3478821888566, train_acc = 0.9623893805309734\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 139, train_loss = 17.320413284003735, train_acc = 0.962156497438286\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 140, train_loss = 17.291523752734065, train_acc = 0.9623893805309734\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 141, train_loss = 17.274003252387047, train_acc = 0.9625058220773172\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 142, train_loss = 17.25306472182274, train_acc = 0.9626222636236609\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 143, train_loss = 17.226485446095467, train_acc = 0.9622729389846297\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 144, train_loss = 17.199521591886878, train_acc = 0.9626222636236609\n",
      "test Acc 0.9427374301675978:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 145, train_loss = 17.176623629406095, train_acc = 0.9627387051700047\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 146, train_loss = 17.16008897870779, train_acc = 0.9627387051700047\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 147, train_loss = 17.134454296901822, train_acc = 0.9627387051700047\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 148, train_loss = 17.10775432176888, train_acc = 0.9627387051700047\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 149, train_loss = 17.088879680261016, train_acc = 0.9627387051700047\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 150, train_loss = 17.072477035224438, train_acc = 0.9628551467163484\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 151, train_loss = 17.038788491860032, train_acc = 0.9627387051700047\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 152, train_loss = 17.02271924726665, train_acc = 0.9629715882626921\n",
      "test Acc 0.9436685288640596:\n",
      "13th- epoch: 153, train_loss = 17.008288526907563, train_acc = 0.9632044713553796\n",
      "test Acc 0.9436685288640596:\n",
      "13th- epoch: 154, train_loss = 16.983951872214675, train_acc = 0.9629715882626921\n",
      "test Acc 0.9441340782122905:\n",
      "13th- epoch: 155, train_loss = 16.965972051024437, train_acc = 0.9629715882626921\n",
      "test Acc 0.9436685288640596:\n",
      "13th- epoch: 156, train_loss = 16.946208184584975, train_acc = 0.9629715882626921\n",
      "test Acc 0.9432029795158287:\n",
      "13th- epoch: 157, train_loss = 16.92450870014727, train_acc = 0.9632044713553796\n",
      "test Acc 0.9441340782122905:\n",
      "13th- epoch: 158, train_loss = 16.901750588789582, train_acc = 0.9632044713553796\n",
      "test Acc 0.9441340782122905:\n",
      "13th- epoch: 159, train_loss = 16.878378881141543, train_acc = 0.9632044713553796\n",
      "test Acc 0.9441340782122905:\n",
      "13th- epoch: 160, train_loss = 16.863599309697747, train_acc = 0.9632044713553796\n",
      "test Acc 0.9441340782122905:\n",
      "13th- epoch: 161, train_loss = 16.844761224463582, train_acc = 0.9632044713553796\n",
      "test Acc 0.9441340782122905:\n",
      "13th- epoch: 162, train_loss = 16.826126592233777, train_acc = 0.9633209129017233\n",
      "test Acc 0.9441340782122905:\n",
      "13th- epoch: 163, train_loss = 16.802773704752326, train_acc = 0.9633209129017233\n",
      "test Acc 0.9441340782122905:\n",
      "13th- epoch: 164, train_loss = 16.785889022052288, train_acc = 0.9629715882626921\n",
      "test Acc 0.9441340782122905:\n",
      "13th- epoch: 165, train_loss = 16.768535347655416, train_acc = 0.9633209129017233\n",
      "test Acc 0.9445996275605214:\n",
      "13th- epoch: 166, train_loss = 16.743571477010846, train_acc = 0.9633209129017233\n",
      "test Acc 0.9441340782122905:\n",
      "13th- epoch: 167, train_loss = 16.725649056956172, train_acc = 0.9633209129017233\n",
      "test Acc 0.9445996275605214:\n",
      "13th- epoch: 168, train_loss = 16.71395093202591, train_acc = 0.9633209129017233\n",
      "test Acc 0.9445996275605214:\n",
      "13th- epoch: 169, train_loss = 16.690899707376957, train_acc = 0.9634373544480671\n",
      "test Acc 0.9445996275605214:\n",
      "13th- epoch: 170, train_loss = 16.674736125394702, train_acc = 0.9633209129017233\n",
      "test Acc 0.9445996275605214:\n",
      "13th- epoch: 171, train_loss = 16.654510328546166, train_acc = 0.9634373544480671\n",
      "test Acc 0.9445996275605214:\n",
      "13th- epoch: 172, train_loss = 16.63859662413597, train_acc = 0.9634373544480671\n",
      "test Acc 0.9445996275605214:\n",
      "13th- epoch: 173, train_loss = 16.623229598626494, train_acc = 0.9632044713553796\n",
      "test Acc 0.9450651769087524:\n",
      "13th- epoch: 174, train_loss = 16.60427369363606, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "13th- epoch: 175, train_loss = 16.582727923989296, train_acc = 0.9634373544480671\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 176, train_loss = 16.564121520146728, train_acc = 0.9634373544480671\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 177, train_loss = 16.55738695524633, train_acc = 0.9635537959944108\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 178, train_loss = 16.536474908702075, train_acc = 0.9635537959944108\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 179, train_loss = 16.515913158655167, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 180, train_loss = 16.49548606853932, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 181, train_loss = 16.478695951402187, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 182, train_loss = 16.473513801582158, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 183, train_loss = 16.4528265343979, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 184, train_loss = 16.432000462897122, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 185, train_loss = 16.409858752973378, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 186, train_loss = 16.39925103634596, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 187, train_loss = 16.382553592324257, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 188, train_loss = 16.368212468922138, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 189, train_loss = 16.355889250524342, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 190, train_loss = 16.33759226370603, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 191, train_loss = 16.317404076457024, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 192, train_loss = 16.30807100702077, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 193, train_loss = 16.285863183438778, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 194, train_loss = 16.280004744417965, train_acc = 0.9637866790870983\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 195, train_loss = 16.26539310067892, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 196, train_loss = 16.247574776411057, train_acc = 0.9637866790870983\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 197, train_loss = 16.231983803212643, train_acc = 0.9637866790870983\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 198, train_loss = 16.219336953945458, train_acc = 0.963903120633442\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 199, train_loss = 16.196620106697083, train_acc = 0.963903120633442\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 200, train_loss = 16.185678037814796, train_acc = 0.963903120633442\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 201, train_loss = 16.177201367914677, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 202, train_loss = 16.161330928094685, train_acc = 0.963903120633442\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 203, train_loss = 16.140433222055435, train_acc = 0.9641360037261295\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 204, train_loss = 16.126191921532154, train_acc = 0.9640195621797858\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 205, train_loss = 16.121887718327343, train_acc = 0.963903120633442\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 206, train_loss = 16.102751021273434, train_acc = 0.963903120633442\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 207, train_loss = 16.097133934497833, train_acc = 0.9641360037261295\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 208, train_loss = 16.081941559910774, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 209, train_loss = 16.065174479968846, train_acc = 0.9642524452724732\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 210, train_loss = 16.051029361784458, train_acc = 0.9641360037261295\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 211, train_loss = 16.038925391621888, train_acc = 0.9642524452724732\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 212, train_loss = 16.030645455233753, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 213, train_loss = 16.009566803462803, train_acc = 0.9644853283651607\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 214, train_loss = 15.998113456182182, train_acc = 0.9642524452724732\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 215, train_loss = 15.984761822037399, train_acc = 0.9643688868188169\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 216, train_loss = 15.96584555041045, train_acc = 0.9644853283651607\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 217, train_loss = 15.954972065985203, train_acc = 0.9646017699115044\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 218, train_loss = 15.946465253829956, train_acc = 0.9644853283651607\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 219, train_loss = 15.936480264179409, train_acc = 0.9644853283651607\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 220, train_loss = 15.918798794038594, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 221, train_loss = 15.912460289895535, train_acc = 0.9643688868188169\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 222, train_loss = 15.890626882202923, train_acc = 0.9644853283651607\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 223, train_loss = 15.888019087724388, train_acc = 0.9647182114578482\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 224, train_loss = 15.871940329670906, train_acc = 0.9647182114578482\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 225, train_loss = 15.864544180221856, train_acc = 0.9647182114578482\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 226, train_loss = 15.844419218599796, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 227, train_loss = 15.83306439500302, train_acc = 0.9644853283651607\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 228, train_loss = 15.822297975420952, train_acc = 0.9644853283651607\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 229, train_loss = 15.812099901027977, train_acc = 0.9647182114578482\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 230, train_loss = 15.79960285872221, train_acc = 0.9649510945505356\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 231, train_loss = 15.790862028487027, train_acc = 0.9649510945505356\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 232, train_loss = 15.779251851141453, train_acc = 0.9654168607359106\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 233, train_loss = 15.76610965281725, train_acc = 0.9649510945505356\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 234, train_loss = 15.749318055808544, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 235, train_loss = 15.743428017012775, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 236, train_loss = 15.732600050978363, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 237, train_loss = 15.718432846479118, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 238, train_loss = 15.70850318390876, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 239, train_loss = 15.696245096623898, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 240, train_loss = 15.688843511044979, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 241, train_loss = 15.678242784924805, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 242, train_loss = 15.665624849498272, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 243, train_loss = 15.647584822960198, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 244, train_loss = 15.639158640988171, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 245, train_loss = 15.629313294775784, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 246, train_loss = 15.616467647254467, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 247, train_loss = 15.608368950895965, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 248, train_loss = 15.594003734178841, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 249, train_loss = 15.587984976358712, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 250, train_loss = 15.578963592648506, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 251, train_loss = 15.575549711473286, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 252, train_loss = 15.558914966881275, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 253, train_loss = 15.548309035599232, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 254, train_loss = 15.538855227641761, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 255, train_loss = 15.525295920670033, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 256, train_loss = 15.51776426564902, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 257, train_loss = 15.505020302720368, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 258, train_loss = 15.495198423974216, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 259, train_loss = 15.488096624612808, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 260, train_loss = 15.471854436211288, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 261, train_loss = 15.467752896249294, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 262, train_loss = 15.455512109212577, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 263, train_loss = 15.445302084088326, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 264, train_loss = 15.441092550754547, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 265, train_loss = 15.427683795802295, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 266, train_loss = 15.419649203307927, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 267, train_loss = 15.41326389182359, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 268, train_loss = 15.394492417573929, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 269, train_loss = 15.385617814958096, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 270, train_loss = 15.38521607965231, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 271, train_loss = 15.371370104141533, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 272, train_loss = 15.36139469128102, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 273, train_loss = 15.35028934199363, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 274, train_loss = 15.34020695835352, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 275, train_loss = 15.330657464452088, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 276, train_loss = 15.317942209541798, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 277, train_loss = 15.316366523504257, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 278, train_loss = 15.300167493522167, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 279, train_loss = 15.296018689870834, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 280, train_loss = 15.286066442728043, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 281, train_loss = 15.277136705815792, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 282, train_loss = 15.265057702548802, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 283, train_loss = 15.253816559910774, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 284, train_loss = 15.252622929401696, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 285, train_loss = 15.242347903549671, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 286, train_loss = 15.231445995159447, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 287, train_loss = 15.22336282581091, train_acc = 0.966581276199348\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 288, train_loss = 15.219076323322952, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 289, train_loss = 15.209210093133152, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 290, train_loss = 15.196951839141548, train_acc = 0.966581276199348\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 291, train_loss = 15.192260946147144, train_acc = 0.966581276199348\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 292, train_loss = 15.171074044890702, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 293, train_loss = 15.167005479335785, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 294, train_loss = 15.163597330451012, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 295, train_loss = 15.150734876282513, train_acc = 0.9664648346530041\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 296, train_loss = 15.141268935985863, train_acc = 0.966581276199348\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 297, train_loss = 15.131502960808575, train_acc = 0.9664648346530041\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 298, train_loss = 15.122319434769452, train_acc = 0.9664648346530041\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 299, train_loss = 15.115279726684093, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 300, train_loss = 15.100906322710216, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 301, train_loss = 15.097637005150318, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 302, train_loss = 15.088539518415928, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 303, train_loss = 15.079695503227413, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 304, train_loss = 15.071352575905621, train_acc = 0.9668141592920354\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 305, train_loss = 15.059459134936333, train_acc = 0.9668141592920354\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 306, train_loss = 15.058850566856563, train_acc = 0.9666977177456917\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 307, train_loss = 15.045150257647038, train_acc = 0.9668141592920354\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 308, train_loss = 15.038743001408875, train_acc = 0.9668141592920354\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 309, train_loss = 15.028895360417664, train_acc = 0.9668141592920354\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 310, train_loss = 15.021115777082741, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 311, train_loss = 15.017548319883645, train_acc = 0.9668141592920354\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 312, train_loss = 15.00472402293235, train_acc = 0.9668141592920354\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 313, train_loss = 14.996821294538677, train_acc = 0.9669306008383791\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 314, train_loss = 14.98884194623679, train_acc = 0.9668141592920354\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 315, train_loss = 14.981475706212223, train_acc = 0.9670470423847228\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 316, train_loss = 14.971630829386413, train_acc = 0.9673963670237541\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 317, train_loss = 14.963796220719814, train_acc = 0.9669306008383791\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 318, train_loss = 14.958276736550033, train_acc = 0.9669306008383791\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 319, train_loss = 14.951787645928562, train_acc = 0.9671634839310667\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 320, train_loss = 14.942780974321067, train_acc = 0.9670470423847228\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 321, train_loss = 14.935231355018914, train_acc = 0.9671634839310667\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 322, train_loss = 14.92806104850024, train_acc = 0.9672799254774104\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 323, train_loss = 14.92146561294794, train_acc = 0.9673963670237541\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 324, train_loss = 14.913349996320903, train_acc = 0.9671634839310667\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 325, train_loss = 14.90691863000393, train_acc = 0.9671634839310667\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 326, train_loss = 14.897665706463158, train_acc = 0.9671634839310667\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 327, train_loss = 14.894440449774265, train_acc = 0.9672799254774104\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 328, train_loss = 14.885023939423263, train_acc = 0.9672799254774104\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 329, train_loss = 14.876763110049069, train_acc = 0.9672799254774104\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 330, train_loss = 14.868274944834411, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 331, train_loss = 14.864207905717194, train_acc = 0.9672799254774104\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 332, train_loss = 14.855928371660411, train_acc = 0.9671634839310667\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 333, train_loss = 14.843443423509598, train_acc = 0.9672799254774104\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 334, train_loss = 14.84062587749213, train_acc = 0.9672799254774104\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 335, train_loss = 14.831442892551422, train_acc = 0.9672799254774104\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 336, train_loss = 14.83419054467231, train_acc = 0.9672799254774104\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 337, train_loss = 14.81758464872837, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 338, train_loss = 14.808435673825443, train_acc = 0.9672799254774104\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 339, train_loss = 14.804751105606556, train_acc = 0.9672799254774104\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 340, train_loss = 14.796508774161339, train_acc = 0.9672799254774104\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 341, train_loss = 14.791509528644383, train_acc = 0.9673963670237541\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 342, train_loss = 14.784409274347126, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 343, train_loss = 14.782893079333007, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 344, train_loss = 14.773199480958283, train_acc = 0.9673963670237541\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 345, train_loss = 14.76206514518708, train_acc = 0.9673963670237541\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 346, train_loss = 14.755150911398232, train_acc = 0.9672799254774104\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 347, train_loss = 14.748990873806179, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 348, train_loss = 14.74596096854657, train_acc = 0.9672799254774104\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 349, train_loss = 14.734703245572746, train_acc = 0.9673963670237541\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 350, train_loss = 14.73020016681403, train_acc = 0.9675128085700978\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 351, train_loss = 14.717884224839509, train_acc = 0.9673963670237541\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 352, train_loss = 14.716010883450508, train_acc = 0.9673963670237541\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 353, train_loss = 14.711336215026677, train_acc = 0.9673963670237541\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 354, train_loss = 14.701088465750217, train_acc = 0.9675128085700978\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 355, train_loss = 14.694170974195004, train_acc = 0.9675128085700978\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 356, train_loss = 14.693837776780128, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 357, train_loss = 14.677778380922973, train_acc = 0.9675128085700978\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 358, train_loss = 14.672352907247841, train_acc = 0.9676292501164415\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 359, train_loss = 14.669000089168549, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 360, train_loss = 14.660184857435524, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 361, train_loss = 14.651900229044259, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 362, train_loss = 14.648620906285942, train_acc = 0.9677456916627852\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 363, train_loss = 14.642656552605331, train_acc = 0.9677456916627852\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 364, train_loss = 14.63500075507909, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 365, train_loss = 14.627424684353173, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 366, train_loss = 14.619808207266033, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 367, train_loss = 14.617628514766693, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 368, train_loss = 14.609223522245884, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 369, train_loss = 14.603455481119454, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 370, train_loss = 14.595349237322807, train_acc = 0.9678621332091291\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 371, train_loss = 14.59274047613144, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 372, train_loss = 14.587035064585507, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 373, train_loss = 14.575582851655781, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 374, train_loss = 14.573618571273983, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 375, train_loss = 14.56526165921241, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 376, train_loss = 14.55821406841278, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 377, train_loss = 14.559020921587944, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 378, train_loss = 14.546710972674191, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 379, train_loss = 14.538715024478734, train_acc = 0.9680950163018165\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 380, train_loss = 14.539313214831054, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 381, train_loss = 14.52773880213499, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 382, train_loss = 14.527503721415997, train_acc = 0.9680950163018165\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 383, train_loss = 14.518545406870544, train_acc = 0.9682114578481602\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 384, train_loss = 14.512504468671978, train_acc = 0.9680950163018165\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 385, train_loss = 14.508138599805534, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 386, train_loss = 14.499062339775264, train_acc = 0.9680950163018165\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 387, train_loss = 14.497114856727421, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 388, train_loss = 14.485941879451275, train_acc = 0.9680950163018165\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 389, train_loss = 14.487442794255912, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 390, train_loss = 14.475436580367386, train_acc = 0.9682114578481602\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 391, train_loss = 14.46573931723833, train_acc = 0.9682114578481602\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 392, train_loss = 14.469355623237789, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 393, train_loss = 14.46384708583355, train_acc = 0.9682114578481602\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 394, train_loss = 14.452414512634277, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 395, train_loss = 14.451108165085316, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 396, train_loss = 14.44340667873621, train_acc = 0.9682114578481602\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 397, train_loss = 14.437649642117321, train_acc = 0.9682114578481602\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 398, train_loss = 14.43497636448592, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 399, train_loss = 14.422777908854187, train_acc = 0.9682114578481602\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 400, train_loss = 14.42398274410516, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 401, train_loss = 14.41457722056657, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 402, train_loss = 14.407802772708237, train_acc = 0.9683278993945039\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 403, train_loss = 14.406950634904206, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 404, train_loss = 14.394257095642388, train_acc = 0.9684443409408477\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 405, train_loss = 14.390681308694184, train_acc = 0.9683278993945039\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 406, train_loss = 14.388343845494092, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 407, train_loss = 14.38253454118967, train_acc = 0.9684443409408477\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 408, train_loss = 14.376975744962692, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 409, train_loss = 14.367040095385164, train_acc = 0.9684443409408477\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 410, train_loss = 14.363516229204834, train_acc = 0.9684443409408477\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 411, train_loss = 14.359146515838802, train_acc = 0.9684443409408477\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 412, train_loss = 14.357659474015236, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 413, train_loss = 14.340168200433254, train_acc = 0.9684443409408477\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 414, train_loss = 14.34474053233862, train_acc = 0.9684443409408477\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 415, train_loss = 14.339754790067673, train_acc = 0.9684443409408477\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 416, train_loss = 14.33460196852684, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 417, train_loss = 14.323097256477922, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 418, train_loss = 14.324823451694101, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 419, train_loss = 14.316569566726685, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 420, train_loss = 14.308495769742876, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 421, train_loss = 14.30527018988505, train_acc = 0.9684443409408477\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 422, train_loss = 14.30112445121631, train_acc = 0.9684443409408477\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 423, train_loss = 14.297920922748744, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 424, train_loss = 14.289004194084555, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 425, train_loss = 14.287179440259933, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 426, train_loss = 14.281011529266834, train_acc = 0.9685607824871915\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 427, train_loss = 14.279256261885166, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 428, train_loss = 14.272668294608593, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 429, train_loss = 14.269213611725718, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 430, train_loss = 14.259707309305668, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 431, train_loss = 14.259158486966044, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 432, train_loss = 14.250784228090197, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 433, train_loss = 14.244133988860995, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 434, train_loss = 14.241097139660269, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 435, train_loss = 14.231312783900648, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 436, train_loss = 14.233089285437018, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 437, train_loss = 14.227599769830704, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 438, train_loss = 14.220932707190514, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 439, train_loss = 14.22444028640166, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 440, train_loss = 14.212234517093748, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 441, train_loss = 14.211578843649477, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 442, train_loss = 14.19936173921451, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 443, train_loss = 14.200440478976816, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 444, train_loss = 14.197762513998896, train_acc = 0.9685607824871915\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 445, train_loss = 14.19097383087501, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 446, train_loss = 14.187913993839175, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 447, train_loss = 14.182847355958074, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 448, train_loss = 14.175051229540259, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "13th- epoch: 449, train_loss = 14.171367754694074, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 450, train_loss = 14.16948356712237, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 451, train_loss = 14.159421101212502, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 452, train_loss = 14.158219198230654, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 453, train_loss = 14.15260768448934, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 454, train_loss = 14.146638731006533, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 455, train_loss = 14.141724226530641, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 456, train_loss = 14.138338106218725, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 457, train_loss = 14.13403312349692, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 458, train_loss = 14.131056614220142, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 459, train_loss = 14.126566464547068, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 460, train_loss = 14.118848050478846, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 461, train_loss = 14.11137684667483, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 462, train_loss = 14.11431328440085, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 463, train_loss = 14.10694032907486, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 464, train_loss = 14.098354183137417, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 465, train_loss = 14.09287660336122, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 466, train_loss = 14.093706811312586, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 467, train_loss = 14.087811104953289, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 468, train_loss = 14.085317214485258, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 469, train_loss = 14.085335398558527, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 470, train_loss = 14.070613650139421, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 471, train_loss = 14.066406024154276, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 472, train_loss = 14.068071121815592, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 473, train_loss = 14.058719091117382, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 474, train_loss = 14.06074953591451, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 475, train_loss = 14.048015534877777, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 476, train_loss = 14.052099446300417, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 477, train_loss = 14.046699220780283, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 478, train_loss = 14.040660085622221, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 479, train_loss = 14.03253577137366, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 480, train_loss = 14.034680423792452, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 481, train_loss = 14.026488356292248, train_acc = 0.9691429902189101\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 482, train_loss = 14.021827293094248, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 483, train_loss = 14.020832893904299, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 484, train_loss = 14.012844294309616, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 485, train_loss = 14.013852439820766, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 486, train_loss = 14.00561836361885, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 487, train_loss = 14.000291250646114, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 488, train_loss = 14.000827364623547, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 489, train_loss = 13.9935432523489, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 490, train_loss = 13.994966223835945, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 491, train_loss = 13.985474208835512, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 492, train_loss = 13.981768473982811, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 493, train_loss = 13.981279117520899, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 494, train_loss = 13.9722177288495, train_acc = 0.9691429902189101\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 495, train_loss = 13.968266732990742, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 496, train_loss = 13.96249415492639, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 497, train_loss = 13.96884016180411, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 498, train_loss = 13.961934106890112, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 499, train_loss = 13.95143616432324, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████▎                                       | 13/30 [1:57:48<2:33:58, 543.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "14th- epoch: 0, train_loss = 122.24854975938797, train_acc = 0.7432463903120633\n",
      "test Acc 0.8258845437616388:\n",
      "14th- epoch: 1, train_loss = 58.653245240449905, train_acc = 0.8752911038658593\n",
      "test Acc 0.8687150837988827:\n",
      "14th- epoch: 2, train_loss = 49.66527110338211, train_acc = 0.895668374476013\n",
      "test Acc 0.8915270018621974:\n",
      "14th- epoch: 3, train_loss = 44.666166961193085, train_acc = 0.9055659059152306\n",
      "test Acc 0.8994413407821229:\n",
      "14th- epoch: 4, train_loss = 41.3081961274147, train_acc = 0.911970190964136\n",
      "test Acc 0.9087523277467412:\n",
      "14th- epoch: 5, train_loss = 38.89223250746727, train_acc = 0.9156963204471356\n",
      "test Acc 0.9124767225325885:\n",
      "14th- epoch: 6, train_loss = 36.93071508407593, train_acc = 0.9202375407545412\n",
      "test Acc 0.9157355679702048:\n",
      "14th- epoch: 7, train_loss = 35.34466464817524, train_acc = 0.9230321378667908\n",
      "test Acc 0.9208566108007449:\n",
      "14th- epoch: 8, train_loss = 34.06727010756731, train_acc = 0.9267582673497904\n",
      "test Acc 0.9236499068901304:\n",
      "14th- epoch: 9, train_loss = 32.9326586201787, train_acc = 0.9296693060083838\n",
      "test Acc 0.9241154562383612:\n",
      "14th- epoch: 10, train_loss = 31.96361829340458, train_acc = 0.9330461108523521\n",
      "test Acc 0.9264432029795159:\n",
      "14th- epoch: 11, train_loss = 31.097956739366055, train_acc = 0.933977643223102\n",
      "test Acc 0.9269087523277467:\n",
      "14th- epoch: 12, train_loss = 30.352854654192924, train_acc = 0.9353749417792269\n",
      "test Acc 0.9273743016759777:\n",
      "14th- epoch: 13, train_loss = 29.697901114821434, train_acc = 0.9374708896134141\n",
      "test Acc 0.930633147113594:\n",
      "14th- epoch: 14, train_loss = 29.10200060904026, train_acc = 0.9385188635305077\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 15, train_loss = 28.561286218464375, train_acc = 0.9391010712622264\n",
      "test Acc 0.9320297951582868:\n",
      "14th- epoch: 16, train_loss = 28.087093085050583, train_acc = 0.94014904517932\n",
      "test Acc 0.9315642458100558:\n",
      "14th- epoch: 17, train_loss = 27.634006515145302, train_acc = 0.9408476944573824\n",
      "test Acc 0.9320297951582868:\n",
      "14th- epoch: 18, train_loss = 27.219854295253754, train_acc = 0.9420121099208197\n",
      "test Acc 0.9320297951582868:\n",
      "14th- epoch: 19, train_loss = 26.84176718443632, train_acc = 0.9431765253842571\n",
      "test Acc 0.9320297951582868:\n",
      "14th- epoch: 20, train_loss = 26.47777123749256, train_acc = 0.9439916162086632\n",
      "test Acc 0.9329608938547486:\n",
      "14th- epoch: 21, train_loss = 26.151409953832626, train_acc = 0.9444573823940382\n",
      "test Acc 0.9320297951582868:\n",
      "14th- epoch: 22, train_loss = 25.844257414340973, train_acc = 0.9446902654867256\n",
      "test Acc 0.9334264432029795:\n",
      "14th- epoch: 23, train_loss = 25.550627790391445, train_acc = 0.9448067070330693\n",
      "test Acc 0.9334264432029795:\n",
      "14th- epoch: 24, train_loss = 25.279716156423092, train_acc = 0.9452724732184443\n",
      "test Acc 0.9329608938547486:\n",
      "14th- epoch: 25, train_loss = 25.03604893386364, train_acc = 0.945388914764788\n",
      "test Acc 0.9338919925512105:\n",
      "14th- epoch: 26, train_loss = 24.786657318472862, train_acc = 0.9455053563111319\n",
      "test Acc 0.9352886405959032:\n",
      "14th- epoch: 27, train_loss = 24.54598566889763, train_acc = 0.9457382394038193\n",
      "test Acc 0.9357541899441341:\n",
      "14th- epoch: 28, train_loss = 24.33429281413555, train_acc = 0.9466697717745691\n",
      "test Acc 0.9357541899441341:\n",
      "14th- epoch: 29, train_loss = 24.12006613612175, train_acc = 0.9470190964136004\n",
      "test Acc 0.936219739292365:\n",
      "14th- epoch: 30, train_loss = 23.918064136058092, train_acc = 0.9471355379599441\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 31, train_loss = 23.7322245426476, train_acc = 0.9474848625989754\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 32, train_loss = 23.549726627767086, train_acc = 0.9473684210526315\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 33, train_loss = 23.369449850171804, train_acc = 0.9479506287843502\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 34, train_loss = 23.20303240418434, train_acc = 0.9482999534233815\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 35, train_loss = 23.047418504953384, train_acc = 0.9485328365160689\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 36, train_loss = 22.895527731627226, train_acc = 0.9486492780624126\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 37, train_loss = 22.743005860596895, train_acc = 0.9487657196087564\n",
      "test Acc 0.9371508379888268:\n",
      "14th- epoch: 38, train_loss = 22.59339600428939, train_acc = 0.9492314857941313\n",
      "test Acc 0.9371508379888268:\n",
      "14th- epoch: 39, train_loss = 22.45504879578948, train_acc = 0.9495808104331626\n",
      "test Acc 0.9376163873370578:\n",
      "14th- epoch: 40, train_loss = 22.334573805332184, train_acc = 0.9496972519795063\n",
      "test Acc 0.9385474860335196:\n",
      "14th- epoch: 41, train_loss = 22.193843357264996, train_acc = 0.950279459711225\n",
      "test Acc 0.9385474860335196:\n",
      "14th- epoch: 42, train_loss = 22.070229653269053, train_acc = 0.9505123428039124\n",
      "test Acc 0.9385474860335196:\n",
      "14th- epoch: 43, train_loss = 21.949899058789015, train_acc = 0.9506287843502562\n",
      "test Acc 0.9385474860335196:\n",
      "14th- epoch: 44, train_loss = 21.825645871460438, train_acc = 0.9512109920819748\n",
      "test Acc 0.9385474860335196:\n",
      "14th- epoch: 45, train_loss = 21.711474295705557, train_acc = 0.9516767582673498\n",
      "test Acc 0.9380819366852886:\n",
      "14th- epoch: 46, train_loss = 21.609098978340626, train_acc = 0.952026082906381\n",
      "test Acc 0.9385474860335196:\n",
      "14th- epoch: 47, train_loss = 21.501433186233044, train_acc = 0.9521425244527247\n",
      "test Acc 0.9390130353817505:\n",
      "14th- epoch: 48, train_loss = 21.394625645130873, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 49, train_loss = 21.29948055371642, train_acc = 0.9527247321844434\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 50, train_loss = 21.202598575502634, train_acc = 0.9533069399161621\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 51, train_loss = 21.107479330152273, train_acc = 0.9535398230088495\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 52, train_loss = 21.01815367117524, train_acc = 0.9536562645551933\n",
      "test Acc 0.9394785847299814:\n",
      "14th- epoch: 53, train_loss = 20.92794645577669, train_acc = 0.9538891476478808\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 54, train_loss = 20.837453216314316, train_acc = 0.9538891476478808\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 55, train_loss = 20.75054257363081, train_acc = 0.9538891476478808\n",
      "test Acc 0.9399441340782123:\n",
      "14th- epoch: 56, train_loss = 20.672508768737316, train_acc = 0.9538891476478808\n",
      "test Acc 0.9408752327746741:\n",
      "14th- epoch: 57, train_loss = 20.587233632802963, train_acc = 0.9541220307405682\n",
      "test Acc 0.9408752327746741:\n",
      "14th- epoch: 58, train_loss = 20.506486978381872, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "14th- epoch: 59, train_loss = 20.43218582123518, train_acc = 0.9541220307405682\n",
      "test Acc 0.9408752327746741:\n",
      "14th- epoch: 60, train_loss = 20.355808969587088, train_acc = 0.9542384722869119\n",
      "test Acc 0.9408752327746741:\n",
      "14th- epoch: 61, train_loss = 20.28570617362857, train_acc = 0.9541220307405682\n",
      "test Acc 0.9408752327746741:\n",
      "14th- epoch: 62, train_loss = 20.207232639193535, train_acc = 0.9542384722869119\n",
      "test Acc 0.9408752327746741:\n",
      "14th- epoch: 63, train_loss = 20.135184690356255, train_acc = 0.9544713553795995\n",
      "test Acc 0.9408752327746741:\n",
      "14th- epoch: 64, train_loss = 20.070264887064695, train_acc = 0.9547042384722869\n",
      "test Acc 0.9413407821229051:\n",
      "14th- epoch: 65, train_loss = 19.989884797483683, train_acc = 0.9545877969259432\n",
      "test Acc 0.9418063314711359:\n",
      "14th- epoch: 66, train_loss = 19.929515291005373, train_acc = 0.9547042384722869\n",
      "test Acc 0.9422718808193669:\n",
      "14th- epoch: 67, train_loss = 19.861730989068747, train_acc = 0.9548206800186306\n",
      "test Acc 0.9418063314711359:\n",
      "14th- epoch: 68, train_loss = 19.80181698873639, train_acc = 0.9549371215649743\n",
      "test Acc 0.9422718808193669:\n",
      "14th- epoch: 69, train_loss = 19.738208457827568, train_acc = 0.9551700046576619\n",
      "test Acc 0.9422718808193669:\n",
      "14th- epoch: 70, train_loss = 19.67129011079669, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "14th- epoch: 71, train_loss = 19.61362935230136, train_acc = 0.9556357708430367\n",
      "test Acc 0.9422718808193669:\n",
      "14th- epoch: 72, train_loss = 19.557245027273893, train_acc = 0.9556357708430367\n",
      "test Acc 0.9422718808193669:\n",
      "14th- epoch: 73, train_loss = 19.49493993446231, train_acc = 0.9558686539357243\n",
      "test Acc 0.9422718808193669:\n",
      "14th- epoch: 74, train_loss = 19.43997702561319, train_acc = 0.9558686539357243\n",
      "test Acc 0.9422718808193669:\n",
      "14th- epoch: 75, train_loss = 19.38084884546697, train_acc = 0.955985095482068\n",
      "test Acc 0.9422718808193669:\n",
      "14th- epoch: 76, train_loss = 19.32441857457161, train_acc = 0.955985095482068\n",
      "test Acc 0.9422718808193669:\n",
      "14th- epoch: 77, train_loss = 19.265835124999285, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "14th- epoch: 78, train_loss = 19.21311798132956, train_acc = 0.9563344201210993\n",
      "test Acc 0.9427374301675978:\n",
      "14th- epoch: 79, train_loss = 19.163962269201875, train_acc = 0.9566837447601304\n",
      "test Acc 0.9427374301675978:\n",
      "14th- epoch: 80, train_loss = 19.109819339588284, train_acc = 0.9568001863064741\n",
      "test Acc 0.9427374301675978:\n",
      "14th- epoch: 81, train_loss = 19.064823819324374, train_acc = 0.9572659524918491\n",
      "test Acc 0.9427374301675978:\n",
      "14th- epoch: 82, train_loss = 19.009853230789304, train_acc = 0.9570330693991617\n",
      "test Acc 0.9427374301675978:\n",
      "14th- epoch: 83, train_loss = 18.961598429828882, train_acc = 0.9569166278528178\n",
      "test Acc 0.9432029795158287:\n",
      "14th- epoch: 84, train_loss = 18.91254731453955, train_acc = 0.9574988355845365\n",
      "test Acc 0.9432029795158287:\n",
      "14th- epoch: 85, train_loss = 18.863087041303515, train_acc = 0.9574988355845365\n",
      "test Acc 0.9432029795158287:\n",
      "14th- epoch: 86, train_loss = 18.823150403797626, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "14th- epoch: 87, train_loss = 18.780267365276814, train_acc = 0.9578481602235678\n",
      "test Acc 0.9432029795158287:\n",
      "14th- epoch: 88, train_loss = 18.734747538343072, train_acc = 0.9579646017699115\n",
      "test Acc 0.9432029795158287:\n",
      "14th- epoch: 89, train_loss = 18.69207524880767, train_acc = 0.9583139264089428\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 90, train_loss = 18.641642294824123, train_acc = 0.9581974848625989\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 91, train_loss = 18.59770213253796, train_acc = 0.9584303679552865\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 92, train_loss = 18.552067609503865, train_acc = 0.9584303679552865\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 93, train_loss = 18.518504410982132, train_acc = 0.9586632510479739\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 94, train_loss = 18.477461280301213, train_acc = 0.9586632510479739\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 95, train_loss = 18.44075395911932, train_acc = 0.9587796925943176\n",
      "test Acc 0.9441340782122905:\n",
      "14th- epoch: 96, train_loss = 18.40477412752807, train_acc = 0.9587796925943176\n",
      "test Acc 0.9445996275605214:\n",
      "14th- epoch: 97, train_loss = 18.366273606196046, train_acc = 0.9587796925943176\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 98, train_loss = 18.318600123748183, train_acc = 0.9592454587796926\n",
      "test Acc 0.9445996275605214:\n",
      "14th- epoch: 99, train_loss = 18.285379845649004, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 100, train_loss = 18.253654964268208, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 101, train_loss = 18.21496219933033, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 102, train_loss = 18.18525691702962, train_acc = 0.9593619003260363\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 103, train_loss = 18.143083477392793, train_acc = 0.9595947834187238\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 104, train_loss = 18.121353143826127, train_acc = 0.9595947834187238\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 105, train_loss = 18.079203823581338, train_acc = 0.9595947834187238\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 106, train_loss = 18.04635268636048, train_acc = 0.95947834187238\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 107, train_loss = 18.004944417625666, train_acc = 0.9597112249650676\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 108, train_loss = 17.979264365509152, train_acc = 0.9597112249650676\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 109, train_loss = 17.950997034087777, train_acc = 0.9597112249650676\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 110, train_loss = 17.913476450368762, train_acc = 0.9598276665114113\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 111, train_loss = 17.8846641946584, train_acc = 0.9598276665114113\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 112, train_loss = 17.854637229815125, train_acc = 0.959944108057755\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 113, train_loss = 17.81867616251111, train_acc = 0.9600605496040987\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 114, train_loss = 17.788401287049055, train_acc = 0.9600605496040987\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 115, train_loss = 17.76525778323412, train_acc = 0.9601769911504425\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 116, train_loss = 17.733686197549105, train_acc = 0.9602934326967862\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 117, train_loss = 17.701390402391553, train_acc = 0.9601769911504425\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 118, train_loss = 17.677313642576337, train_acc = 0.9602934326967862\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 119, train_loss = 17.655127046629786, train_acc = 0.9602934326967862\n",
      "test Acc 0.9445996275605214:\n",
      "14th- epoch: 120, train_loss = 17.618382850661874, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "14th- epoch: 121, train_loss = 17.59456636570394, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "14th- epoch: 122, train_loss = 17.563282093033195, train_acc = 0.9605263157894737\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 123, train_loss = 17.540429705753922, train_acc = 0.9607591988821611\n",
      "test Acc 0.9445996275605214:\n",
      "14th- epoch: 124, train_loss = 17.51067596115172, train_acc = 0.9607591988821611\n",
      "test Acc 0.9445996275605214:\n",
      "14th- epoch: 125, train_loss = 17.490540888160467, train_acc = 0.9605263157894737\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 126, train_loss = 17.45833974517882, train_acc = 0.9607591988821611\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 127, train_loss = 17.435695627704263, train_acc = 0.9605263157894737\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 128, train_loss = 17.41242972575128, train_acc = 0.9605263157894737\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 129, train_loss = 17.381806157529354, train_acc = 0.9608756404285049\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 130, train_loss = 17.360152885317802, train_acc = 0.9611085235211924\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 131, train_loss = 17.343278700485826, train_acc = 0.9608756404285049\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 132, train_loss = 17.32180937938392, train_acc = 0.9608756404285049\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 133, train_loss = 17.288543347269297, train_acc = 0.9611085235211924\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 134, train_loss = 17.27135751955211, train_acc = 0.9609920819748486\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 135, train_loss = 17.243248151615262, train_acc = 0.9612249650675361\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 136, train_loss = 17.219604583457112, train_acc = 0.9612249650675361\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 137, train_loss = 17.198732087388635, train_acc = 0.9613414066138798\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 138, train_loss = 17.173788433894515, train_acc = 0.9612249650675361\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 139, train_loss = 17.154951268807054, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 140, train_loss = 17.13417418114841, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 141, train_loss = 17.111495370045304, train_acc = 0.9613414066138798\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 142, train_loss = 17.08665406703949, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 143, train_loss = 17.067665254697204, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 144, train_loss = 17.044150644913316, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 145, train_loss = 17.026321286335588, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 146, train_loss = 17.007378231734037, train_acc = 0.9618071727992548\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 147, train_loss = 16.9813129324466, train_acc = 0.961690731252911\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 148, train_loss = 16.96913835592568, train_acc = 0.9619236143455985\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 149, train_loss = 16.942189510911703, train_acc = 0.9619236143455985\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 150, train_loss = 16.926392150111496, train_acc = 0.9620400558919422\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 151, train_loss = 16.91119034588337, train_acc = 0.9619236143455985\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 152, train_loss = 16.884683216921985, train_acc = 0.9620400558919422\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 153, train_loss = 16.874256224371493, train_acc = 0.9620400558919422\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 154, train_loss = 16.857631948776543, train_acc = 0.9620400558919422\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 155, train_loss = 16.831937520764768, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 156, train_loss = 16.812175183556974, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 157, train_loss = 16.786452368833125, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 158, train_loss = 16.774225550703704, train_acc = 0.962156497438286\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 159, train_loss = 16.751384197734296, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 160, train_loss = 16.731917372904718, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 161, train_loss = 16.716839318163693, train_acc = 0.962156497438286\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 162, train_loss = 16.69689325708896, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 163, train_loss = 16.682116675190628, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 164, train_loss = 16.663366325199604, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 165, train_loss = 16.64426490664482, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 166, train_loss = 16.62558200210333, train_acc = 0.9623893805309734\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 167, train_loss = 16.606849282979965, train_acc = 0.9623893805309734\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 168, train_loss = 16.593931298702955, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 169, train_loss = 16.572419163770974, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 170, train_loss = 16.55623720958829, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 171, train_loss = 16.539454395882785, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 172, train_loss = 16.52352675329894, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "14th- epoch: 173, train_loss = 16.51264299452305, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "14th- epoch: 174, train_loss = 16.489865978248417, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "14th- epoch: 175, train_loss = 16.473528345115483, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "14th- epoch: 176, train_loss = 16.458982054144144, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "14th- epoch: 177, train_loss = 16.44333810824901, train_acc = 0.9628551467163484\n",
      "test Acc 0.9459962756052142:\n",
      "14th- epoch: 178, train_loss = 16.429867322556674, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 179, train_loss = 16.412546244449914, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 180, train_loss = 16.398726752959192, train_acc = 0.9629715882626921\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 181, train_loss = 16.382452230900526, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 182, train_loss = 16.36134349834174, train_acc = 0.9628551467163484\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 183, train_loss = 16.348156942985952, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 184, train_loss = 16.332928438670933, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 185, train_loss = 16.32685040216893, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 186, train_loss = 16.30732440482825, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 187, train_loss = 16.293979215435684, train_acc = 0.9629715882626921\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 188, train_loss = 16.280895681120455, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 189, train_loss = 16.26312955468893, train_acc = 0.9630880298090359\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 190, train_loss = 16.2514445213601, train_acc = 0.9630880298090359\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 191, train_loss = 16.232425178401172, train_acc = 0.9630880298090359\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 192, train_loss = 16.21721309889108, train_acc = 0.9633209129017233\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 193, train_loss = 16.204811870120466, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 194, train_loss = 16.1911593163386, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 195, train_loss = 16.179374515078962, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 196, train_loss = 16.163963577710092, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 197, train_loss = 16.144853156991303, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 198, train_loss = 16.140545144677162, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 199, train_loss = 16.124591030180454, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 200, train_loss = 16.110215456224978, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 201, train_loss = 16.102753427810967, train_acc = 0.9635537959944108\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 202, train_loss = 16.08090466633439, train_acc = 0.9635537959944108\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 203, train_loss = 16.070840091444552, train_acc = 0.9636702375407545\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 204, train_loss = 16.05730539560318, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 205, train_loss = 16.038892973214388, train_acc = 0.9636702375407545\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 206, train_loss = 16.023949089460075, train_acc = 0.9636702375407545\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 207, train_loss = 16.0188246704638, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 208, train_loss = 16.001612465828657, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 209, train_loss = 15.987427350133657, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 210, train_loss = 15.979247759096324, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 211, train_loss = 15.964795916341245, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 212, train_loss = 15.95229805726558, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 213, train_loss = 15.941867507062852, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 214, train_loss = 15.927515796385705, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 215, train_loss = 15.915323226712644, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 216, train_loss = 15.904838763177395, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 217, train_loss = 15.896373454481363, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 218, train_loss = 15.877624526619911, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 219, train_loss = 15.869976638816297, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 220, train_loss = 15.851326148025692, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 221, train_loss = 15.842783905565739, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 222, train_loss = 15.825633954256773, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 223, train_loss = 15.816193853504956, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 224, train_loss = 15.803265658207238, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 225, train_loss = 15.788003741763532, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 226, train_loss = 15.781576939858496, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 227, train_loss = 15.770283789373934, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 228, train_loss = 15.761729224584997, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 229, train_loss = 15.746433067135513, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 230, train_loss = 15.737377437762916, train_acc = 0.9646017699115044\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 231, train_loss = 15.73146293964237, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 232, train_loss = 15.719027399085462, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 233, train_loss = 15.708588890731335, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 234, train_loss = 15.69926396664232, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 235, train_loss = 15.685476857237518, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 236, train_loss = 15.6757772276178, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 237, train_loss = 15.657666195183992, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 238, train_loss = 15.648894247598946, train_acc = 0.9650675360968793\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 239, train_loss = 15.647185727022588, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 240, train_loss = 15.632214594632387, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 241, train_loss = 15.62436951417476, train_acc = 0.9651839776432231\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 242, train_loss = 15.608134818263352, train_acc = 0.9648346530041919\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 243, train_loss = 15.598016544245183, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 244, train_loss = 15.585279303602874, train_acc = 0.9651839776432231\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 245, train_loss = 15.578499966301024, train_acc = 0.9651839776432231\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 246, train_loss = 15.57111797761172, train_acc = 0.9651839776432231\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 247, train_loss = 15.559853807091713, train_acc = 0.9651839776432231\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 248, train_loss = 15.55045486241579, train_acc = 0.9651839776432231\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 249, train_loss = 15.537463079206645, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 250, train_loss = 15.53355175908655, train_acc = 0.9651839776432231\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 251, train_loss = 15.51712483447045, train_acc = 0.9650675360968793\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 252, train_loss = 15.51039320230484, train_acc = 0.9654168607359106\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 253, train_loss = 15.498600631952286, train_acc = 0.9653004191895669\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 254, train_loss = 15.486182726919651, train_acc = 0.9650675360968793\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 255, train_loss = 15.476268437691033, train_acc = 0.9653004191895669\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 256, train_loss = 15.464225582778454, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 257, train_loss = 15.463905793614686, train_acc = 0.9654168607359106\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 258, train_loss = 15.448171901516616, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 259, train_loss = 15.43811107892543, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 260, train_loss = 15.430721093900502, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 261, train_loss = 15.42233394831419, train_acc = 0.965649743828598\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 262, train_loss = 15.414813351817429, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 263, train_loss = 15.400332403369248, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 264, train_loss = 15.39472294319421, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 265, train_loss = 15.386739939451218, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 266, train_loss = 15.3734120009467, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 267, train_loss = 15.366430607624352, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 268, train_loss = 15.358522586524487, train_acc = 0.9662319515603167\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 269, train_loss = 15.352448783814907, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 270, train_loss = 15.336044217459857, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 271, train_loss = 15.330609533004463, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 272, train_loss = 15.330196003429592, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 273, train_loss = 15.310146478004754, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 274, train_loss = 15.301909361965954, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 275, train_loss = 15.293385540135205, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 276, train_loss = 15.28525126259774, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 277, train_loss = 15.283796091564, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 278, train_loss = 15.267764274962246, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 279, train_loss = 15.260544031858444, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 280, train_loss = 15.24837189912796, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 281, train_loss = 15.24149440228939, train_acc = 0.9662319515603167\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 282, train_loss = 15.232269500382245, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 283, train_loss = 15.225369525142014, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 284, train_loss = 15.21874213218689, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 285, train_loss = 15.20878205448389, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 286, train_loss = 15.205286796204746, train_acc = 0.9662319515603167\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 287, train_loss = 15.188880614936352, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 288, train_loss = 15.183399367146194, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 289, train_loss = 15.173293138854206, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 290, train_loss = 15.16639081388712, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 291, train_loss = 15.161015790887177, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 292, train_loss = 15.152055829763412, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 293, train_loss = 15.143184803426266, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 294, train_loss = 15.131994985044003, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 295, train_loss = 15.126794303767383, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 296, train_loss = 15.116991381160915, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 297, train_loss = 15.112143454141915, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 298, train_loss = 15.098033818416297, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 299, train_loss = 15.087751577608287, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 300, train_loss = 15.085744678974152, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 301, train_loss = 15.078492730855942, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 302, train_loss = 15.06933020055294, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 303, train_loss = 15.060483400709927, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 304, train_loss = 15.055020235478878, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 305, train_loss = 15.045847825706005, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 306, train_loss = 15.04123467206955, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 307, train_loss = 15.031766206026077, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 308, train_loss = 15.029385427944362, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 309, train_loss = 15.013743269257247, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 310, train_loss = 15.012816046364605, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 311, train_loss = 15.000478841364384, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 312, train_loss = 14.995410750620067, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 313, train_loss = 14.98579965531826, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 314, train_loss = 14.978359584696591, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 315, train_loss = 14.969901057891548, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 316, train_loss = 14.971148195676506, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 317, train_loss = 14.958417408168316, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 318, train_loss = 14.951796554028988, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 319, train_loss = 14.939770971424878, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 320, train_loss = 14.941524021327496, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 321, train_loss = 14.929562990553677, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 322, train_loss = 14.919639286585152, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 323, train_loss = 14.915744128637016, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 324, train_loss = 14.905960969626904, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 325, train_loss = 14.904776319861412, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 326, train_loss = 14.89367950707674, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 327, train_loss = 14.88924756925553, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 328, train_loss = 14.878612977452576, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 329, train_loss = 14.870405259542167, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 330, train_loss = 14.864633984863758, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 331, train_loss = 14.855950236320496, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 332, train_loss = 14.85051205009222, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 333, train_loss = 14.848252676427364, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 334, train_loss = 14.837519091553986, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 335, train_loss = 14.83510881382972, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 336, train_loss = 14.81964606512338, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 337, train_loss = 14.822767175734043, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 338, train_loss = 14.808336555957794, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 339, train_loss = 14.80662968289107, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 340, train_loss = 14.796626947820187, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 341, train_loss = 14.788573950529099, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 342, train_loss = 14.781640795059502, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 343, train_loss = 14.783597777597606, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 344, train_loss = 14.766712079755962, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 345, train_loss = 14.761714704334736, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 346, train_loss = 14.74886369984597, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 347, train_loss = 14.742121542803943, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 348, train_loss = 14.738587555475533, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 349, train_loss = 14.731661607511342, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 350, train_loss = 14.724323225207627, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 351, train_loss = 14.722075964324176, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 352, train_loss = 14.72000848222524, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 353, train_loss = 14.70764034241438, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 354, train_loss = 14.700687008909881, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 355, train_loss = 14.696588869206607, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 356, train_loss = 14.689327930100262, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 357, train_loss = 14.686636027880013, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 358, train_loss = 14.67882635910064, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 359, train_loss = 14.67203538119793, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 360, train_loss = 14.6623977990821, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 361, train_loss = 14.656729876995087, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 362, train_loss = 14.655057121999562, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 363, train_loss = 14.64398180693388, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 364, train_loss = 14.639524373225868, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 365, train_loss = 14.631162936799228, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 366, train_loss = 14.62605893611908, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 367, train_loss = 14.619855771772563, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 368, train_loss = 14.617364359088242, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 369, train_loss = 14.60727282334119, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 370, train_loss = 14.603564471006393, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 371, train_loss = 14.595222786068916, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 372, train_loss = 14.59473767131567, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 373, train_loss = 14.585445960052311, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 374, train_loss = 14.585282243788242, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 375, train_loss = 14.577255713753402, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 376, train_loss = 14.570039075799286, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 377, train_loss = 14.563987928442657, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 378, train_loss = 14.554143627174199, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 379, train_loss = 14.551484495401382, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 380, train_loss = 14.5430709971115, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 381, train_loss = 14.539916562847793, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 382, train_loss = 14.531176023185253, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 383, train_loss = 14.528165340423584, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 384, train_loss = 14.5207973793149, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 385, train_loss = 14.516403411515057, train_acc = 0.9687936655798789\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 386, train_loss = 14.51410920638591, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 387, train_loss = 14.505589825101197, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 388, train_loss = 14.502987876534462, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 389, train_loss = 14.491628090385348, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 390, train_loss = 14.484165348112583, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 391, train_loss = 14.47798394644633, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 392, train_loss = 14.475662360433489, train_acc = 0.9687936655798789\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 393, train_loss = 14.47098242258653, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 394, train_loss = 14.463717865291983, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 395, train_loss = 14.460645973682404, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 396, train_loss = 14.452151050325483, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 397, train_loss = 14.4466378740035, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 398, train_loss = 14.4477832862176, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 399, train_loss = 14.435536473989487, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 400, train_loss = 14.436551595572382, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 401, train_loss = 14.432275660336018, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 402, train_loss = 14.41562977200374, train_acc = 0.9692594317652539\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 403, train_loss = 14.414222727064043, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 404, train_loss = 14.40872510522604, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 405, train_loss = 14.408618099987507, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 406, train_loss = 14.401360665913671, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 407, train_loss = 14.3993219435215, train_acc = 0.9692594317652539\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 408, train_loss = 14.394911726471037, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 409, train_loss = 14.391341850161552, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 410, train_loss = 14.376902282238007, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 411, train_loss = 14.375748639460653, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 412, train_loss = 14.370434209704399, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 413, train_loss = 14.360748069826514, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 414, train_loss = 14.3583480194211, train_acc = 0.9693758733115976\n",
      "test Acc 0.946927374301676:\n",
      "14th- epoch: 415, train_loss = 14.356720805168152, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 416, train_loss = 14.350581286009401, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 417, train_loss = 14.341080866754055, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 418, train_loss = 14.336230635643005, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 419, train_loss = 14.331245265901089, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 420, train_loss = 14.326877027750015, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 421, train_loss = 14.320803391281515, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 422, train_loss = 14.31937593454495, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 423, train_loss = 14.310160122811794, train_acc = 0.9694923148579413\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 424, train_loss = 14.302320530172437, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 425, train_loss = 14.299737160559744, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 426, train_loss = 14.295285674277693, train_acc = 0.969608756404285\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 427, train_loss = 14.294107703026384, train_acc = 0.9694923148579413\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 428, train_loss = 14.283029951155186, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 429, train_loss = 14.282232403755188, train_acc = 0.969608756404285\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 430, train_loss = 14.279479429125786, train_acc = 0.969608756404285\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 431, train_loss = 14.269977370742708, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 432, train_loss = 14.262789078056812, train_acc = 0.969608756404285\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 433, train_loss = 14.263850992079824, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "14th- epoch: 434, train_loss = 14.255448719020933, train_acc = 0.969608756404285\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 435, train_loss = 14.25324118649587, train_acc = 0.969608756404285\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 436, train_loss = 14.248037951532751, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 437, train_loss = 14.242817377205938, train_acc = 0.969608756404285\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 438, train_loss = 14.2418538085185, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 439, train_loss = 14.237971370574087, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 440, train_loss = 14.227975276764482, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 441, train_loss = 14.22471001977101, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 442, train_loss = 14.218261793255806, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 443, train_loss = 14.212029899004847, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 444, train_loss = 14.208678901195526, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 445, train_loss = 14.200793117284775, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 446, train_loss = 14.200006254017353, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 447, train_loss = 14.194653084035963, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 448, train_loss = 14.19086846197024, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 449, train_loss = 14.189475653227419, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 450, train_loss = 14.18457085872069, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 451, train_loss = 14.180156198795885, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 452, train_loss = 14.17587830638513, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 453, train_loss = 14.170525595545769, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 454, train_loss = 14.16259790211916, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 455, train_loss = 14.16480233008042, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 456, train_loss = 14.158238349016756, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 457, train_loss = 14.148787535727024, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 458, train_loss = 14.146663283463567, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 459, train_loss = 14.141558972653002, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 460, train_loss = 14.137150382157415, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 461, train_loss = 14.131819404661655, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 462, train_loss = 14.127859137952328, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 463, train_loss = 14.122308790683746, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 464, train_loss = 14.118614122271538, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 465, train_loss = 14.112512449268252, train_acc = 0.969608756404285\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 466, train_loss = 14.112728869076818, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 467, train_loss = 14.10683453315869, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 468, train_loss = 14.104509664233774, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 469, train_loss = 14.092652487102896, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 470, train_loss = 14.092979582492262, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 471, train_loss = 14.086836889386177, train_acc = 0.969608756404285\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 472, train_loss = 14.081142430659384, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 473, train_loss = 14.074518059846014, train_acc = 0.969608756404285\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 474, train_loss = 14.072172371204942, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 475, train_loss = 14.066485367715359, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 476, train_loss = 14.065676545258611, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n",
      "14th- epoch: 477, train_loss = 14.06134894490242, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 478, train_loss = 14.056139707565308, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 479, train_loss = 14.050915541592985, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 480, train_loss = 14.040370824281126, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 481, train_loss = 14.038275490049273, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 482, train_loss = 14.034896939992905, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 483, train_loss = 14.029962949454784, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 484, train_loss = 14.026164822280407, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 485, train_loss = 14.021165599580854, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 486, train_loss = 14.022012854460627, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 487, train_loss = 14.017725077923387, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 488, train_loss = 14.009086971636862, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 489, train_loss = 14.008578854147345, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 490, train_loss = 14.0016755387187, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 491, train_loss = 13.998545691370964, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 492, train_loss = 13.992359953466803, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 493, train_loss = 13.994566517416388, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 494, train_loss = 13.988468354102224, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 495, train_loss = 13.982343293726444, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 496, train_loss = 13.979946094099432, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 497, train_loss = 13.976107982452959, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "14th- epoch: 498, train_loss = 13.972595719154924, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "14th- epoch: 499, train_loss = 13.965321352239698, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████████████████████████▋                                     | 14/30 [2:06:50<2:24:45, 542.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "15th- epoch: 0, train_loss = 117.56422618031502, train_acc = 0.7738705170004657\n",
      "test Acc 0.8165735567970205:\n",
      "15th- epoch: 1, train_loss = 53.4420832246542, train_acc = 0.8851886353050769\n",
      "test Acc 0.8766294227188082:\n",
      "15th- epoch: 2, train_loss = 44.753689125180244, train_acc = 0.904052165812762\n",
      "test Acc 0.9022346368715084:\n",
      "15th- epoch: 3, train_loss = 40.27193704992533, train_acc = 0.9138332557056358\n",
      "test Acc 0.9138733705772812:\n",
      "15th- epoch: 4, train_loss = 37.34017127752304, train_acc = 0.9204704238472287\n",
      "test Acc 0.9241154562383612:\n",
      "15th- epoch: 5, train_loss = 35.20771073549986, train_acc = 0.925593851886353\n",
      "test Acc 0.925512104283054:\n",
      "15th- epoch: 6, train_loss = 33.535545632243156, train_acc = 0.9279226828132278\n",
      "test Acc 0.9278398510242085:\n",
      "15th- epoch: 7, train_loss = 32.218019753694534, train_acc = 0.9311830461108523\n",
      "test Acc 0.9283054003724395:\n",
      "15th- epoch: 8, train_loss = 31.167764522135258, train_acc = 0.9333954354913834\n",
      "test Acc 0.930633147113594:\n",
      "15th- epoch: 9, train_loss = 30.315123297274113, train_acc = 0.9346762925011645\n",
      "test Acc 0.9334264432029795:\n",
      "15th- epoch: 10, train_loss = 29.5500483289361, train_acc = 0.9356078248719143\n",
      "test Acc 0.9334264432029795:\n",
      "15th- epoch: 11, train_loss = 28.899370916187763, train_acc = 0.9368886818816954\n",
      "test Acc 0.9348230912476723:\n",
      "15th- epoch: 12, train_loss = 28.290478717535734, train_acc = 0.9382859804378202\n",
      "test Acc 0.9357541899441341:\n",
      "15th- epoch: 13, train_loss = 27.813482359051704, train_acc = 0.939683278993945\n",
      "test Acc 0.936219739292365:\n",
      "15th- epoch: 14, train_loss = 27.296454958617687, train_acc = 0.9408476944573824\n",
      "test Acc 0.936219739292365:\n",
      "15th- epoch: 15, train_loss = 26.874082271009684, train_acc = 0.9406148113646949\n",
      "test Acc 0.936219739292365:\n",
      "15th- epoch: 16, train_loss = 26.454677384346724, train_acc = 0.9413134606427573\n",
      "test Acc 0.9352886405959032:\n",
      "15th- epoch: 17, train_loss = 26.08069583028555, train_acc = 0.9425943176525384\n",
      "test Acc 0.9352886405959032:\n",
      "15th- epoch: 18, train_loss = 25.735359251499176, train_acc = 0.944108057755007\n",
      "test Acc 0.936219739292365:\n",
      "15th- epoch: 19, train_loss = 25.411827441304922, train_acc = 0.9449231485794132\n",
      "test Acc 0.9371508379888268:\n",
      "15th- epoch: 20, train_loss = 25.105432529002428, train_acc = 0.945854680950163\n",
      "test Acc 0.9371508379888268:\n",
      "15th- epoch: 21, train_loss = 24.83678625896573, train_acc = 0.9465533302282254\n",
      "test Acc 0.9366852886405959:\n",
      "15th- epoch: 22, train_loss = 24.580343320965767, train_acc = 0.9470190964136004\n",
      "test Acc 0.9366852886405959:\n",
      "15th- epoch: 23, train_loss = 24.313364930450916, train_acc = 0.948067070330694\n",
      "test Acc 0.9366852886405959:\n",
      "15th- epoch: 24, train_loss = 24.08625629916787, train_acc = 0.9479506287843502\n",
      "test Acc 0.9366852886405959:\n",
      "15th- epoch: 25, train_loss = 23.862671352922916, train_acc = 0.9481835118770378\n",
      "test Acc 0.9371508379888268:\n",
      "15th- epoch: 26, train_loss = 23.660417430102825, train_acc = 0.9486492780624126\n",
      "test Acc 0.9371508379888268:\n",
      "15th- epoch: 27, train_loss = 23.43375338986516, train_acc = 0.9501630181648812\n",
      "test Acc 0.9371508379888268:\n",
      "15th- epoch: 28, train_loss = 23.25590890645981, train_acc = 0.94981369352585\n",
      "test Acc 0.9371508379888268:\n",
      "15th- epoch: 29, train_loss = 23.068844839930534, train_acc = 0.94981369352585\n",
      "test Acc 0.9376163873370578:\n",
      "15th- epoch: 30, train_loss = 22.890439428389072, train_acc = 0.9501630181648812\n",
      "test Acc 0.9371508379888268:\n",
      "15th- epoch: 31, train_loss = 22.7294994443655, train_acc = 0.951560316721006\n",
      "test Acc 0.9371508379888268:\n",
      "15th- epoch: 32, train_loss = 22.55928162112832, train_acc = 0.952026082906381\n",
      "test Acc 0.9380819366852886:\n",
      "15th- epoch: 33, train_loss = 22.390401232987642, train_acc = 0.9523754075454122\n",
      "test Acc 0.9385474860335196:\n",
      "15th- epoch: 34, train_loss = 22.227110255509615, train_acc = 0.9523754075454122\n",
      "test Acc 0.9385474860335196:\n",
      "15th- epoch: 35, train_loss = 22.085798770189285, train_acc = 0.9526082906380997\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 36, train_loss = 21.95251104980707, train_acc = 0.9527247321844434\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 37, train_loss = 21.799431778490543, train_acc = 0.9529576152771309\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 38, train_loss = 21.67615308240056, train_acc = 0.9534233814625058\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 39, train_loss = 21.542254257947206, train_acc = 0.9536562645551933\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 40, train_loss = 21.421349465847015, train_acc = 0.9540055891942245\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 41, train_loss = 21.31084370985627, train_acc = 0.9537727061015371\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 42, train_loss = 21.19745894894004, train_acc = 0.9540055891942245\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 43, train_loss = 21.07965798303485, train_acc = 0.9542384722869119\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 44, train_loss = 20.980297196656466, train_acc = 0.9543549138332557\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 45, train_loss = 20.87857747823, train_acc = 0.9544713553795995\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 46, train_loss = 20.779076777398586, train_acc = 0.9547042384722869\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 47, train_loss = 20.680406916886568, train_acc = 0.9548206800186306\n",
      "test Acc 0.9394785847299814:\n",
      "15th- epoch: 48, train_loss = 20.599863182753325, train_acc = 0.9551700046576619\n",
      "test Acc 0.9385474860335196:\n",
      "15th- epoch: 49, train_loss = 20.507420502603054, train_acc = 0.9550535631113182\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 50, train_loss = 20.410077285021544, train_acc = 0.9554028877503493\n",
      "test Acc 0.9390130353817505:\n",
      "15th- epoch: 51, train_loss = 20.315345663577318, train_acc = 0.9557522123893806\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 52, train_loss = 20.237891640514135, train_acc = 0.9557522123893806\n",
      "test Acc 0.9394785847299814:\n",
      "15th- epoch: 53, train_loss = 20.15669508650899, train_acc = 0.955985095482068\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 54, train_loss = 20.07472065463662, train_acc = 0.9561015370284117\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 55, train_loss = 19.996736019849777, train_acc = 0.9561015370284117\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 56, train_loss = 19.915499299764633, train_acc = 0.9563344201210993\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 57, train_loss = 19.844888176769018, train_acc = 0.9563344201210993\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 58, train_loss = 19.76859947666526, train_acc = 0.956450861667443\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 59, train_loss = 19.70159337297082, train_acc = 0.956450861667443\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 60, train_loss = 19.629098989069462, train_acc = 0.956450861667443\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 61, train_loss = 19.560812268406153, train_acc = 0.956450861667443\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 62, train_loss = 19.4993855394423, train_acc = 0.956450861667443\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 63, train_loss = 19.440108869224787, train_acc = 0.9565673032137867\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 64, train_loss = 19.369349371641874, train_acc = 0.9565673032137867\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 65, train_loss = 19.311806801706553, train_acc = 0.9569166278528178\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 66, train_loss = 19.252432018518448, train_acc = 0.9571495109455054\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 67, train_loss = 19.18498683348298, train_acc = 0.9571495109455054\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 68, train_loss = 19.115536607801914, train_acc = 0.9572659524918491\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 69, train_loss = 19.053075183182955, train_acc = 0.9576152771308803\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 70, train_loss = 19.005586873739958, train_acc = 0.9577317186772241\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 71, train_loss = 18.939887780696154, train_acc = 0.9578481602235678\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 72, train_loss = 18.880314636975527, train_acc = 0.9578481602235678\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 73, train_loss = 18.83616739138961, train_acc = 0.9578481602235678\n",
      "test Acc 0.9399441340782123:\n",
      "15th- epoch: 74, train_loss = 18.775956619530916, train_acc = 0.9580810433162552\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 75, train_loss = 18.738476488739252, train_acc = 0.9583139264089428\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 76, train_loss = 18.67197597026825, train_acc = 0.9585468095016302\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 77, train_loss = 18.6344824321568, train_acc = 0.9584303679552865\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 78, train_loss = 18.582682322710752, train_acc = 0.9585468095016302\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 79, train_loss = 18.5345847196877, train_acc = 0.9585468095016302\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 80, train_loss = 18.490322552621365, train_acc = 0.9586632510479739\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 81, train_loss = 18.442899730056524, train_acc = 0.9588961341406614\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 82, train_loss = 18.395077811554074, train_acc = 0.9587796925943176\n",
      "test Acc 0.9408752327746741:\n",
      "15th- epoch: 83, train_loss = 18.34550891071558, train_acc = 0.9588961341406614\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 84, train_loss = 18.30784479342401, train_acc = 0.9591290172333489\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 85, train_loss = 18.25564797781408, train_acc = 0.9592454587796926\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 86, train_loss = 18.21099360473454, train_acc = 0.9592454587796926\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 87, train_loss = 18.170250652357936, train_acc = 0.95947834187238\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 88, train_loss = 18.127290790900588, train_acc = 0.95947834187238\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 89, train_loss = 18.086410323157907, train_acc = 0.9597112249650676\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 90, train_loss = 18.04456957988441, train_acc = 0.9595947834187238\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 91, train_loss = 18.00064359419048, train_acc = 0.959944108057755\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 92, train_loss = 17.965552670881152, train_acc = 0.959944108057755\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 93, train_loss = 17.919583717361093, train_acc = 0.959944108057755\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 94, train_loss = 17.88802195712924, train_acc = 0.9600605496040987\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 95, train_loss = 17.851256992667913, train_acc = 0.9601769911504425\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 96, train_loss = 17.80276953242719, train_acc = 0.96040987424313\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 97, train_loss = 17.772301826626062, train_acc = 0.9602934326967862\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 98, train_loss = 17.738260259851813, train_acc = 0.9605263157894737\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 99, train_loss = 17.708367811515927, train_acc = 0.9606427573358174\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 100, train_loss = 17.66898731328547, train_acc = 0.9606427573358174\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 101, train_loss = 17.63847274519503, train_acc = 0.9607591988821611\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 102, train_loss = 17.591349931433797, train_acc = 0.9606427573358174\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 103, train_loss = 17.563537560403347, train_acc = 0.9607591988821611\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 104, train_loss = 17.536241494119167, train_acc = 0.9609920819748486\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 105, train_loss = 17.502051627263427, train_acc = 0.9611085235211924\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 106, train_loss = 17.458629624918103, train_acc = 0.9611085235211924\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 107, train_loss = 17.430062735453248, train_acc = 0.9611085235211924\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 108, train_loss = 17.401078222319484, train_acc = 0.9613414066138798\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 109, train_loss = 17.367162514477968, train_acc = 0.961690731252911\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 110, train_loss = 17.329662710428238, train_acc = 0.961690731252911\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 111, train_loss = 17.308151060715318, train_acc = 0.9618071727992548\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 112, train_loss = 17.275229666382074, train_acc = 0.9619236143455985\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 113, train_loss = 17.253042364493012, train_acc = 0.9618071727992548\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 114, train_loss = 17.221032734960318, train_acc = 0.961690731252911\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 115, train_loss = 17.187181940302253, train_acc = 0.9619236143455985\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 116, train_loss = 17.16478075645864, train_acc = 0.9620400558919422\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 117, train_loss = 17.13569393567741, train_acc = 0.9620400558919422\n",
      "test Acc 0.9422718808193669:\n",
      "15th- epoch: 118, train_loss = 17.10583647340536, train_acc = 0.9619236143455985\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 119, train_loss = 17.084520949050784, train_acc = 0.9620400558919422\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 120, train_loss = 17.05988529138267, train_acc = 0.9620400558919422\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 121, train_loss = 17.02573682181537, train_acc = 0.962156497438286\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 122, train_loss = 17.005292765796185, train_acc = 0.962156497438286\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 123, train_loss = 16.98131819628179, train_acc = 0.9623893805309734\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 124, train_loss = 16.954732099547982, train_acc = 0.9623893805309734\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 125, train_loss = 16.919930428266525, train_acc = 0.9623893805309734\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 126, train_loss = 16.90088709630072, train_acc = 0.9623893805309734\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 127, train_loss = 16.880288794636726, train_acc = 0.9625058220773172\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 128, train_loss = 16.852234860882163, train_acc = 0.9623893805309734\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 129, train_loss = 16.83092744089663, train_acc = 0.9626222636236609\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 130, train_loss = 16.806115936487913, train_acc = 0.9625058220773172\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 131, train_loss = 16.778792537748814, train_acc = 0.9626222636236609\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 132, train_loss = 16.75793086923659, train_acc = 0.9625058220773172\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 133, train_loss = 16.735875925049186, train_acc = 0.9626222636236609\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 134, train_loss = 16.71515933610499, train_acc = 0.9627387051700047\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 135, train_loss = 16.688192510977387, train_acc = 0.9629715882626921\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 136, train_loss = 16.669483674690127, train_acc = 0.9629715882626921\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 137, train_loss = 16.6460112798959, train_acc = 0.9627387051700047\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 138, train_loss = 16.618462407961488, train_acc = 0.9629715882626921\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 139, train_loss = 16.603761976584792, train_acc = 0.9632044713553796\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 140, train_loss = 16.58135681413114, train_acc = 0.9630880298090359\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 141, train_loss = 16.563246494159102, train_acc = 0.9633209129017233\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 142, train_loss = 16.54017156176269, train_acc = 0.9635537959944108\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 143, train_loss = 16.523490875959396, train_acc = 0.9635537959944108\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 144, train_loss = 16.50255906023085, train_acc = 0.9634373544480671\n",
      "test Acc 0.9432029795158287:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 145, train_loss = 16.480969278141856, train_acc = 0.9635537959944108\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 146, train_loss = 16.461873142048717, train_acc = 0.9637866790870983\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 147, train_loss = 16.43736564554274, train_acc = 0.963903120633442\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 148, train_loss = 16.411487573757768, train_acc = 0.9640195621797858\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 149, train_loss = 16.398932492360473, train_acc = 0.9642524452724732\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 150, train_loss = 16.380388075485826, train_acc = 0.9641360037261295\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 151, train_loss = 16.363679798319936, train_acc = 0.9641360037261295\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 152, train_loss = 16.344989638775587, train_acc = 0.9641360037261295\n",
      "test Acc 0.9436685288640596:\n",
      "15th- epoch: 153, train_loss = 16.332819186151028, train_acc = 0.963903120633442\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 154, train_loss = 16.31335255689919, train_acc = 0.9641360037261295\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 155, train_loss = 16.283990874886513, train_acc = 0.9640195621797858\n",
      "test Acc 0.9432029795158287:\n",
      "15th- epoch: 156, train_loss = 16.26980848237872, train_acc = 0.9641360037261295\n",
      "test Acc 0.9436685288640596:\n",
      "15th- epoch: 157, train_loss = 16.249405093491077, train_acc = 0.9644853283651607\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 158, train_loss = 16.235254384577274, train_acc = 0.9643688868188169\n",
      "test Acc 0.9441340782122905:\n",
      "15th- epoch: 159, train_loss = 16.216317960992455, train_acc = 0.9644853283651607\n",
      "test Acc 0.9441340782122905:\n",
      "15th- epoch: 160, train_loss = 16.198092160746455, train_acc = 0.9644853283651607\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 161, train_loss = 16.182787515223026, train_acc = 0.9646017699115044\n",
      "test Acc 0.9441340782122905:\n",
      "15th- epoch: 162, train_loss = 16.161106748506427, train_acc = 0.9647182114578482\n",
      "test Acc 0.9441340782122905:\n",
      "15th- epoch: 163, train_loss = 16.146899418905377, train_acc = 0.9647182114578482\n",
      "test Acc 0.9441340782122905:\n",
      "15th- epoch: 164, train_loss = 16.132912155240774, train_acc = 0.9647182114578482\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 165, train_loss = 16.1150203961879, train_acc = 0.9648346530041919\n",
      "test Acc 0.9445996275605214:\n",
      "15th- epoch: 166, train_loss = 16.09632682055235, train_acc = 0.9651839776432231\n",
      "test Acc 0.9450651769087524:\n",
      "15th- epoch: 167, train_loss = 16.082419347018003, train_acc = 0.9649510945505356\n",
      "test Acc 0.9450651769087524:\n",
      "15th- epoch: 168, train_loss = 16.070738760754466, train_acc = 0.9650675360968793\n",
      "test Acc 0.9450651769087524:\n",
      "15th- epoch: 169, train_loss = 16.042550889775157, train_acc = 0.9654168607359106\n",
      "test Acc 0.9450651769087524:\n",
      "15th- epoch: 170, train_loss = 16.035660894587636, train_acc = 0.9651839776432231\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 171, train_loss = 16.022961458191276, train_acc = 0.9653004191895669\n",
      "test Acc 0.9450651769087524:\n",
      "15th- epoch: 172, train_loss = 16.004434375092387, train_acc = 0.9653004191895669\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 173, train_loss = 15.986617501825094, train_acc = 0.9653004191895669\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 174, train_loss = 15.97538574039936, train_acc = 0.9653004191895669\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 175, train_loss = 15.954430181533098, train_acc = 0.9651839776432231\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 176, train_loss = 15.935978960245848, train_acc = 0.9653004191895669\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 177, train_loss = 15.92248361185193, train_acc = 0.9654168607359106\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 178, train_loss = 15.913337126374245, train_acc = 0.9655333022822543\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 179, train_loss = 15.89539877511561, train_acc = 0.9655333022822543\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 180, train_loss = 15.879510561004281, train_acc = 0.965649743828598\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 181, train_loss = 15.856504175812006, train_acc = 0.965649743828598\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 182, train_loss = 15.853817546740174, train_acc = 0.965649743828598\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 183, train_loss = 15.835961205884814, train_acc = 0.965649743828598\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 184, train_loss = 15.816176237538457, train_acc = 0.965649743828598\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 185, train_loss = 15.802063787356019, train_acc = 0.965649743828598\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 186, train_loss = 15.79448470659554, train_acc = 0.965649743828598\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 187, train_loss = 15.780118927359581, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 188, train_loss = 15.765904061496258, train_acc = 0.965649743828598\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 189, train_loss = 15.74817100726068, train_acc = 0.9658826269212856\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 190, train_loss = 15.737520204856992, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 191, train_loss = 15.724110040813684, train_acc = 0.9657661853749417\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 192, train_loss = 15.714148646220565, train_acc = 0.9657661853749417\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 193, train_loss = 15.70172250829637, train_acc = 0.9658826269212856\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 194, train_loss = 15.678618578240275, train_acc = 0.9658826269212856\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 195, train_loss = 15.673951158300042, train_acc = 0.9659990684676293\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 196, train_loss = 15.653945526108146, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 197, train_loss = 15.647027399390936, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 198, train_loss = 15.638160044327378, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 199, train_loss = 15.625145016238093, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 200, train_loss = 15.610514242202044, train_acc = 0.9659990684676293\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 201, train_loss = 15.595453122630715, train_acc = 0.966115510013973\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 202, train_loss = 15.575055422261357, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 203, train_loss = 15.557354429736733, train_acc = 0.966115510013973\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 204, train_loss = 15.54817408323288, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 205, train_loss = 15.52524353004992, train_acc = 0.966115510013973\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 206, train_loss = 15.521455435082316, train_acc = 0.966115510013973\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 207, train_loss = 15.50442193634808, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 208, train_loss = 15.489678030833602, train_acc = 0.966115510013973\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 209, train_loss = 15.478799998760223, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 210, train_loss = 15.464799685403705, train_acc = 0.9659990684676293\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 211, train_loss = 15.456205509603024, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 212, train_loss = 15.444165401160717, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 213, train_loss = 15.433337748982012, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 214, train_loss = 15.4235318005085, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 215, train_loss = 15.408620335161686, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 216, train_loss = 15.399013979360461, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 217, train_loss = 15.386212917044759, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 218, train_loss = 15.38104005344212, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 219, train_loss = 15.364496209658682, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 220, train_loss = 15.349587822332978, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 221, train_loss = 15.342865974642336, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 222, train_loss = 15.341742581687868, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 223, train_loss = 15.320133876055479, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 224, train_loss = 15.310183115303516, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 225, train_loss = 15.304385051131248, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 226, train_loss = 15.295471631921828, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 227, train_loss = 15.28471128642559, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 228, train_loss = 15.267729095183313, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 229, train_loss = 15.265175554901361, train_acc = 0.9662319515603167\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 230, train_loss = 15.25168118532747, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 231, train_loss = 15.237614374607801, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 232, train_loss = 15.230423650704324, train_acc = 0.9662319515603167\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 233, train_loss = 15.219847086817026, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 234, train_loss = 15.206496868282557, train_acc = 0.9663483931066604\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 235, train_loss = 15.200542874634266, train_acc = 0.9663483931066604\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 236, train_loss = 15.193969569168985, train_acc = 0.9663483931066604\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 237, train_loss = 15.178594932891428, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 238, train_loss = 15.169911686331034, train_acc = 0.9662319515603167\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 239, train_loss = 15.16037782561034, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 240, train_loss = 15.140950308181345, train_acc = 0.9664648346530041\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 241, train_loss = 15.134211052209139, train_acc = 0.9664648346530041\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 242, train_loss = 15.12170059606433, train_acc = 0.9664648346530041\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 243, train_loss = 15.113515470176935, train_acc = 0.9663483931066604\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 244, train_loss = 15.102519537322223, train_acc = 0.9664648346530041\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 245, train_loss = 15.096672379411757, train_acc = 0.9664648346530041\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 246, train_loss = 15.086126598529518, train_acc = 0.9664648346530041\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 247, train_loss = 15.076519258320332, train_acc = 0.9664648346530041\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 248, train_loss = 15.072949069552124, train_acc = 0.966581276199348\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 249, train_loss = 15.057692053727806, train_acc = 0.9664648346530041\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 250, train_loss = 15.050383046269417, train_acc = 0.966581276199348\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 251, train_loss = 15.037713247351348, train_acc = 0.966581276199348\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 252, train_loss = 15.030180177651346, train_acc = 0.9666977177456917\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 253, train_loss = 15.02449236344546, train_acc = 0.9668141592920354\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 254, train_loss = 15.008966623805463, train_acc = 0.9668141592920354\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 255, train_loss = 15.00791412498802, train_acc = 0.9668141592920354\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 256, train_loss = 14.98857409413904, train_acc = 0.9668141592920354\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 257, train_loss = 14.986037538386881, train_acc = 0.9668141592920354\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 258, train_loss = 14.973238155245781, train_acc = 0.9669306008383791\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 259, train_loss = 14.965915723703802, train_acc = 0.9668141592920354\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 260, train_loss = 14.955353397876024, train_acc = 0.9668141592920354\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 261, train_loss = 14.948836692608893, train_acc = 0.9668141592920354\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 262, train_loss = 14.94325019326061, train_acc = 0.9666977177456917\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 263, train_loss = 14.925745037384331, train_acc = 0.9668141592920354\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 264, train_loss = 14.920593219809234, train_acc = 0.9666977177456917\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 265, train_loss = 14.912099133245647, train_acc = 0.9669306008383791\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 266, train_loss = 14.904411648400128, train_acc = 0.9668141592920354\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 267, train_loss = 14.89230077341199, train_acc = 0.9668141592920354\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 268, train_loss = 14.891137682832778, train_acc = 0.9668141592920354\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 269, train_loss = 14.88115658517927, train_acc = 0.9666977177456917\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 270, train_loss = 14.872093341313303, train_acc = 0.9669306008383791\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 271, train_loss = 14.861168544739485, train_acc = 0.9669306008383791\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 272, train_loss = 14.860270626842976, train_acc = 0.9668141592920354\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 273, train_loss = 14.848266742192209, train_acc = 0.9669306008383791\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 274, train_loss = 14.835217089392245, train_acc = 0.9669306008383791\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 275, train_loss = 14.82574373204261, train_acc = 0.9669306008383791\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 276, train_loss = 14.81994713936001, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 277, train_loss = 14.812331470660865, train_acc = 0.9669306008383791\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 278, train_loss = 14.804628220386803, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 279, train_loss = 14.797370966523886, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 280, train_loss = 14.786020416766405, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 281, train_loss = 14.773574776016176, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 282, train_loss = 14.768865653313696, train_acc = 0.9670470423847228\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 283, train_loss = 14.763627459295094, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 284, train_loss = 14.75723420176655, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 285, train_loss = 14.746156740933657, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 286, train_loss = 14.741062246263027, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 287, train_loss = 14.730332867242396, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 288, train_loss = 14.72744571045041, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 289, train_loss = 14.719382386654615, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 290, train_loss = 14.707117521204054, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 291, train_loss = 14.70470467582345, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 292, train_loss = 14.695955719798803, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 293, train_loss = 14.686766958795488, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 294, train_loss = 14.683611743152142, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 295, train_loss = 14.672070864588022, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 296, train_loss = 14.664515551179647, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 297, train_loss = 14.659246698953211, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 298, train_loss = 14.65441772621125, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 299, train_loss = 14.64360545296222, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 300, train_loss = 14.63565902877599, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 301, train_loss = 14.626225966960192, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 302, train_loss = 14.624098550528288, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 303, train_loss = 14.61928580980748, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 304, train_loss = 14.605196670629084, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 305, train_loss = 14.602217982523143, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 306, train_loss = 14.597665560431778, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 307, train_loss = 14.589421782642603, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 308, train_loss = 14.578933549113572, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 309, train_loss = 14.571648143231869, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 310, train_loss = 14.567893142811954, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 311, train_loss = 14.550937294960022, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 312, train_loss = 14.551622405648232, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 313, train_loss = 14.543031550943851, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 314, train_loss = 14.535714509896934, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 315, train_loss = 14.534587055444717, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 316, train_loss = 14.520304997451603, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 317, train_loss = 14.520467706024647, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 318, train_loss = 14.511023630388081, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 319, train_loss = 14.505913329310715, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 320, train_loss = 14.497310475446284, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 321, train_loss = 14.490646339952946, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 322, train_loss = 14.484074502252042, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 323, train_loss = 14.480117374099791, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 324, train_loss = 14.4786322042346, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 325, train_loss = 14.464184719137847, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 326, train_loss = 14.456274596042931, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 327, train_loss = 14.45511572342366, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 328, train_loss = 14.4460594849661, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 329, train_loss = 14.437045988626778, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 330, train_loss = 14.439577925018966, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 331, train_loss = 14.434173718094826, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 332, train_loss = 14.422788147814572, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 333, train_loss = 14.410561143420637, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 334, train_loss = 14.411187029443681, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 335, train_loss = 14.403151626698673, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 336, train_loss = 14.396113091148436, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 337, train_loss = 14.393003373406827, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 338, train_loss = 14.380592306144536, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 339, train_loss = 14.378104597330093, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 340, train_loss = 14.37629824411124, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 341, train_loss = 14.367034077644348, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 342, train_loss = 14.36137751210481, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 343, train_loss = 14.352591981180012, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 344, train_loss = 14.348525524139404, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 345, train_loss = 14.339200819842517, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 346, train_loss = 14.338192026130855, train_acc = 0.9683278993945039\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 347, train_loss = 14.323210400529206, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 348, train_loss = 14.326875350438058, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 349, train_loss = 14.316202000714839, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 350, train_loss = 14.306855612434447, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 351, train_loss = 14.305066730827093, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 352, train_loss = 14.303942035883665, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 353, train_loss = 14.289918296970427, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 354, train_loss = 14.289645377546549, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 355, train_loss = 14.28039414063096, train_acc = 0.9684443409408477\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 356, train_loss = 14.278294398449361, train_acc = 0.9685607824871915\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 357, train_loss = 14.269391659647226, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 358, train_loss = 14.269116555340588, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 359, train_loss = 14.255482114851475, train_acc = 0.9686772240335352\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 360, train_loss = 14.25158628821373, train_acc = 0.9687936655798789\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 361, train_loss = 14.24289120733738, train_acc = 0.9687936655798789\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 362, train_loss = 14.24489325657487, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 363, train_loss = 14.232940599322319, train_acc = 0.9687936655798789\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 364, train_loss = 14.23309017997235, train_acc = 0.9687936655798789\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 365, train_loss = 14.228333829902112, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 366, train_loss = 14.222358657978475, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 367, train_loss = 14.214952256530523, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 368, train_loss = 14.206533611752093, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 369, train_loss = 14.202728562057018, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 370, train_loss = 14.199627512134612, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 371, train_loss = 14.190649905242026, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 372, train_loss = 14.183476530946791, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 373, train_loss = 14.179929181933403, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 374, train_loss = 14.177117695100605, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 375, train_loss = 14.16770229768008, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 376, train_loss = 14.169819690287113, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 377, train_loss = 14.162658452056348, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 378, train_loss = 14.15681950841099, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 379, train_loss = 14.151257465593517, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 380, train_loss = 14.144876641221344, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 381, train_loss = 14.14238418173045, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 382, train_loss = 14.132359080016613, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 383, train_loss = 14.12858098000288, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 384, train_loss = 14.123355634510517, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 385, train_loss = 14.120954394340515, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 386, train_loss = 14.114949035458267, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 387, train_loss = 14.11133635416627, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 388, train_loss = 14.102774091996253, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 389, train_loss = 14.102444625459611, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 390, train_loss = 14.088494368828833, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 391, train_loss = 14.085856545716524, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 392, train_loss = 14.082060783170164, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 393, train_loss = 14.076207243837416, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 394, train_loss = 14.071109973825514, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 395, train_loss = 14.063404883258045, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 396, train_loss = 14.056916669011116, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 397, train_loss = 14.055962137877941, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 398, train_loss = 14.049794021062553, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 399, train_loss = 14.049993866123259, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 400, train_loss = 14.041638816706836, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 401, train_loss = 14.037032089196146, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 402, train_loss = 14.035890304483473, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 403, train_loss = 14.030120150186121, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 404, train_loss = 14.024022468365729, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 405, train_loss = 14.014686181209981, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 406, train_loss = 14.012370684184134, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 407, train_loss = 14.012252423912287, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 408, train_loss = 14.007692168466747, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 409, train_loss = 14.000093631446362, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 410, train_loss = 13.992161662317812, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 411, train_loss = 13.989329979754984, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 412, train_loss = 13.982618178240955, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 413, train_loss = 13.979361526668072, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 414, train_loss = 13.975574565120041, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 415, train_loss = 13.967308935709298, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 416, train_loss = 13.966983067803085, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 417, train_loss = 13.962517902255058, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 418, train_loss = 13.958951011300087, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 419, train_loss = 13.953504398465157, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 420, train_loss = 13.944366152398288, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 421, train_loss = 13.940659071318805, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 422, train_loss = 13.943184602074325, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 423, train_loss = 13.937939560972154, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 424, train_loss = 13.927491082809865, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 425, train_loss = 13.921643561683595, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 426, train_loss = 13.923352170735598, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 427, train_loss = 13.917081723921001, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 428, train_loss = 13.928203263320029, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 429, train_loss = 13.905733042396605, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 430, train_loss = 13.901347607374191, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 431, train_loss = 13.901530572213233, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 432, train_loss = 13.892729628831148, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 433, train_loss = 13.888971253298223, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 434, train_loss = 13.891744717024267, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 435, train_loss = 13.895569016225636, train_acc = 0.9698416394969726\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 436, train_loss = 13.889028892852366, train_acc = 0.9698416394969726\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 437, train_loss = 13.866088580340147, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 438, train_loss = 13.862060601823032, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 439, train_loss = 13.876682507805526, train_acc = 0.9698416394969726\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 440, train_loss = 13.856910523958504, train_acc = 0.9698416394969726\n",
      "test Acc 0.9473929236499069:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 441, train_loss = 13.854382428340614, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 442, train_loss = 13.862274901010096, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 443, train_loss = 13.841005627065897, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 444, train_loss = 13.837905335240066, train_acc = 0.9698416394969726\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 445, train_loss = 13.83099774364382, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 446, train_loss = 13.829939741641283, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 447, train_loss = 13.82444631960243, train_acc = 0.9698416394969726\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 448, train_loss = 13.820664721541107, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 449, train_loss = 13.813918924890459, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 450, train_loss = 13.814583540894091, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 451, train_loss = 13.813191482331604, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 452, train_loss = 13.801536524202675, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 453, train_loss = 13.803469517733902, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 454, train_loss = 13.804146811366081, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 455, train_loss = 13.789548905100673, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 456, train_loss = 13.788587959948927, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 457, train_loss = 13.803840062115341, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 458, train_loss = 13.778847401496023, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 459, train_loss = 13.776740851346403, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 460, train_loss = 13.772504152264446, train_acc = 0.97007452258966\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 461, train_loss = 13.767058104276657, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 462, train_loss = 13.76288733119145, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 463, train_loss = 13.759954702109098, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 464, train_loss = 13.75415913388133, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 465, train_loss = 13.754599797073752, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 466, train_loss = 13.76070906361565, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 467, train_loss = 13.74281737813726, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 468, train_loss = 13.743335177656263, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 469, train_loss = 13.736860743258148, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 470, train_loss = 13.73289447510615, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 471, train_loss = 13.731408109422773, train_acc = 0.97007452258966\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 472, train_loss = 13.739228623453528, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 473, train_loss = 13.716634768992662, train_acc = 0.97007452258966\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 474, train_loss = 13.730211647693068, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 475, train_loss = 13.715360432863235, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 476, train_loss = 13.704129945486784, train_acc = 0.9699580810433163\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 477, train_loss = 13.706451987382025, train_acc = 0.9701909641360037\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 478, train_loss = 13.70134598389268, train_acc = 0.97007452258966\n",
      "test Acc 0.9473929236499069:\n",
      "15th- epoch: 479, train_loss = 13.700368782039732, train_acc = 0.97007452258966\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 480, train_loss = 13.694022320210934, train_acc = 0.97007452258966\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 481, train_loss = 13.690476608928293, train_acc = 0.9701909641360037\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 482, train_loss = 13.685845746193081, train_acc = 0.9701909641360037\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 483, train_loss = 13.685828875750303, train_acc = 0.9701909641360037\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 484, train_loss = 13.70125476270914, train_acc = 0.9699580810433163\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 485, train_loss = 13.670081205666065, train_acc = 0.9701909641360037\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 486, train_loss = 13.689431426580995, train_acc = 0.9701909641360037\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 487, train_loss = 13.66344471508637, train_acc = 0.9701909641360037\n",
      "test Acc 0.9478584729981379:\n",
      "15th- epoch: 488, train_loss = 13.665036503225565, train_acc = 0.9701909641360037\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 489, train_loss = 13.6598377735354, train_acc = 0.9701909641360037\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 490, train_loss = 13.658096980303526, train_acc = 0.9703074056823474\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 491, train_loss = 13.67324090981856, train_acc = 0.9703074056823474\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 492, train_loss = 13.649460391607136, train_acc = 0.9703074056823474\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 493, train_loss = 13.648514902684838, train_acc = 0.9701909641360037\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 494, train_loss = 13.645649254322052, train_acc = 0.9703074056823474\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 495, train_loss = 13.637350148055702, train_acc = 0.9703074056823474\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 496, train_loss = 13.635867262724787, train_acc = 0.9703074056823474\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 497, train_loss = 13.633200693875551, train_acc = 0.9703074056823474\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 498, train_loss = 13.626249976456165, train_acc = 0.9703074056823474\n",
      "test Acc 0.9483240223463687:\n",
      "15th- epoch: 499, train_loss = 13.625615525990725, train_acc = 0.9703074056823474\n",
      "test Acc 0.9483240223463687:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████                                   | 15/30 [2:15:52<2:15:38, 542.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "16th- epoch: 0, train_loss = 119.80422616004944, train_acc = 0.757918025151374\n",
      "test Acc 0.8594040968342644:\n",
      "16th- epoch: 1, train_loss = 57.76751586794853, train_acc = 0.8813460642757336\n",
      "test Acc 0.8845437616387337:\n",
      "16th- epoch: 2, train_loss = 49.15712831914425, train_acc = 0.8960176991150443\n",
      "test Acc 0.8999068901303539:\n",
      "16th- epoch: 3, train_loss = 44.31117305904627, train_acc = 0.9055659059152306\n",
      "test Acc 0.904562383612663:\n",
      "16th- epoch: 4, train_loss = 41.03763162344694, train_acc = 0.9120866325104797\n",
      "test Acc 0.9124767225325885:\n",
      "16th- epoch: 5, train_loss = 38.5909256413579, train_acc = 0.915929203539823\n",
      "test Acc 0.9138733705772812:\n",
      "16th- epoch: 6, train_loss = 36.64635415375233, train_acc = 0.9205868653935724\n",
      "test Acc 0.9166666666666666:\n",
      "16th- epoch: 7, train_loss = 35.05115453153849, train_acc = 0.9234979040521658\n",
      "test Acc 0.9203910614525139:\n",
      "16th- epoch: 8, train_loss = 33.75160989910364, train_acc = 0.9262925011644154\n",
      "test Acc 0.9208566108007449:\n",
      "16th- epoch: 9, train_loss = 32.62522131204605, train_acc = 0.9285048905449464\n",
      "test Acc 0.9236499068901304:\n",
      "16th- epoch: 10, train_loss = 31.66793754696846, train_acc = 0.9307172799254774\n",
      "test Acc 0.9259776536312849:\n",
      "16th- epoch: 11, train_loss = 30.80791862308979, train_acc = 0.9325803446669771\n",
      "test Acc 0.9283054003724395:\n",
      "16th- epoch: 12, train_loss = 30.071349266916513, train_acc = 0.9343269678621332\n",
      "test Acc 0.9287709497206704:\n",
      "16th- epoch: 13, train_loss = 29.403188452124596, train_acc = 0.936190032603633\n",
      "test Acc 0.9287709497206704:\n",
      "16th- epoch: 14, train_loss = 28.7849642932415, train_acc = 0.9375873311597578\n",
      "test Acc 0.9287709497206704:\n",
      "16th- epoch: 15, train_loss = 28.257719110697508, train_acc = 0.9381695388914765\n",
      "test Acc 0.9301675977653632:\n",
      "16th- epoch: 16, train_loss = 27.756116911768913, train_acc = 0.9400326036329762\n",
      "test Acc 0.931098696461825:\n",
      "16th- epoch: 17, train_loss = 27.29244789481163, train_acc = 0.9406148113646949\n",
      "test Acc 0.9334264432029795:\n",
      "16th- epoch: 18, train_loss = 26.879974350333214, train_acc = 0.9416627852817886\n",
      "test Acc 0.9338919925512105:\n",
      "16th- epoch: 19, train_loss = 26.490082044154406, train_acc = 0.9428272007452259\n",
      "test Acc 0.9343575418994413:\n",
      "16th- epoch: 20, train_loss = 26.13983066380024, train_acc = 0.9438751746623195\n",
      "test Acc 0.9343575418994413:\n",
      "16th- epoch: 21, train_loss = 25.815000791102648, train_acc = 0.9444573823940382\n",
      "test Acc 0.9348230912476723:\n",
      "16th- epoch: 22, train_loss = 25.489380799233913, train_acc = 0.9445738239403819\n",
      "test Acc 0.9348230912476723:\n",
      "16th- epoch: 23, train_loss = 25.173566158860922, train_acc = 0.9457382394038193\n",
      "test Acc 0.9343575418994413:\n",
      "16th- epoch: 24, train_loss = 24.89727061241865, train_acc = 0.946320447135538\n",
      "test Acc 0.9352886405959032:\n",
      "16th- epoch: 25, train_loss = 24.63100853562355, train_acc = 0.9470190964136004\n",
      "test Acc 0.9357541899441341:\n",
      "16th- epoch: 26, train_loss = 24.383820448070765, train_acc = 0.9474848625989754\n",
      "test Acc 0.9366852886405959:\n",
      "16th- epoch: 27, train_loss = 24.165591094642878, train_acc = 0.9481835118770378\n",
      "test Acc 0.936219739292365:\n",
      "16th- epoch: 28, train_loss = 23.92985750734806, train_acc = 0.9489986027014439\n",
      "test Acc 0.9371508379888268:\n",
      "16th- epoch: 29, train_loss = 23.711470384150743, train_acc = 0.9492314857941313\n",
      "test Acc 0.9376163873370578:\n",
      "16th- epoch: 30, train_loss = 23.520891673862934, train_acc = 0.9499301350721937\n",
      "test Acc 0.9380819366852886:\n",
      "16th- epoch: 31, train_loss = 23.33939563855529, train_acc = 0.9503959012575687\n",
      "test Acc 0.9376163873370578:\n",
      "16th- epoch: 32, train_loss = 23.15963541343808, train_acc = 0.9510945505356311\n",
      "test Acc 0.9376163873370578:\n",
      "16th- epoch: 33, train_loss = 22.995220627635717, train_acc = 0.9513274336283186\n",
      "test Acc 0.9380819366852886:\n",
      "16th- epoch: 34, train_loss = 22.83140739798546, train_acc = 0.9512109920819748\n",
      "test Acc 0.9371508379888268:\n",
      "16th- epoch: 35, train_loss = 22.693190701305866, train_acc = 0.9513274336283186\n",
      "test Acc 0.9376163873370578:\n",
      "16th- epoch: 36, train_loss = 22.528194073587656, train_acc = 0.9514438751746623\n",
      "test Acc 0.9371508379888268:\n",
      "16th- epoch: 37, train_loss = 22.367891062051058, train_acc = 0.9519096413600373\n",
      "test Acc 0.9376163873370578:\n",
      "16th- epoch: 38, train_loss = 22.245661921799183, train_acc = 0.952026082906381\n",
      "test Acc 0.9371508379888268:\n",
      "16th- epoch: 39, train_loss = 22.105316560715437, train_acc = 0.9521425244527247\n",
      "test Acc 0.9371508379888268:\n",
      "16th- epoch: 40, train_loss = 21.975020967423916, train_acc = 0.9521425244527247\n",
      "test Acc 0.9385474860335196:\n",
      "16th- epoch: 41, train_loss = 21.863736622035503, train_acc = 0.9522589659990685\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 42, train_loss = 21.731933008879423, train_acc = 0.9523754075454122\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 43, train_loss = 21.61729310080409, train_acc = 0.952491849091756\n",
      "test Acc 0.9380819366852886:\n",
      "16th- epoch: 44, train_loss = 21.512400195002556, train_acc = 0.9528411737307871\n",
      "test Acc 0.9385474860335196:\n",
      "16th- epoch: 45, train_loss = 21.410530794411898, train_acc = 0.9529576152771309\n",
      "test Acc 0.9385474860335196:\n",
      "16th- epoch: 46, train_loss = 21.290496557950974, train_acc = 0.9529576152771309\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 47, train_loss = 21.197854354977608, train_acc = 0.9531904983698184\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 48, train_loss = 21.087980780750513, train_acc = 0.9534233814625058\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 49, train_loss = 20.99188467487693, train_acc = 0.9534233814625058\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 50, train_loss = 20.8784289509058, train_acc = 0.9536562645551933\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 51, train_loss = 20.787856459617615, train_acc = 0.9537727061015371\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 52, train_loss = 20.700865995138884, train_acc = 0.9538891476478808\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 53, train_loss = 20.6138871666044, train_acc = 0.9537727061015371\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 54, train_loss = 20.523691169917583, train_acc = 0.9540055891942245\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 55, train_loss = 20.44767419807613, train_acc = 0.9541220307405682\n",
      "test Acc 0.9390130353817505:\n",
      "16th- epoch: 56, train_loss = 20.369483165442944, train_acc = 0.9544713553795995\n",
      "test Acc 0.9394785847299814:\n",
      "16th- epoch: 57, train_loss = 20.283803725615144, train_acc = 0.9542384722869119\n",
      "test Acc 0.9394785847299814:\n",
      "16th- epoch: 58, train_loss = 20.213706171140075, train_acc = 0.9545877969259432\n",
      "test Acc 0.9404096834264432:\n",
      "16th- epoch: 59, train_loss = 20.14622917957604, train_acc = 0.9547042384722869\n",
      "test Acc 0.9399441340782123:\n",
      "16th- epoch: 60, train_loss = 20.065381722524762, train_acc = 0.9550535631113182\n",
      "test Acc 0.9404096834264432:\n",
      "16th- epoch: 61, train_loss = 20.008901672437787, train_acc = 0.9550535631113182\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 62, train_loss = 19.936103070154786, train_acc = 0.9550535631113182\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 63, train_loss = 19.855163076892495, train_acc = 0.955519329296693\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 64, train_loss = 19.79550838842988, train_acc = 0.9556357708430367\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 65, train_loss = 19.748187514021993, train_acc = 0.955519329296693\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 66, train_loss = 19.689632335677743, train_acc = 0.9561015370284117\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 67, train_loss = 19.624118780717254, train_acc = 0.9561015370284117\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 68, train_loss = 19.551794597879052, train_acc = 0.9561015370284117\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 69, train_loss = 19.506400467827916, train_acc = 0.9563344201210993\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 70, train_loss = 19.44477715715766, train_acc = 0.9563344201210993\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 71, train_loss = 19.379511564970016, train_acc = 0.9568001863064741\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 72, train_loss = 19.340586487203836, train_acc = 0.9563344201210993\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 73, train_loss = 19.274810526520014, train_acc = 0.9566837447601304\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 74, train_loss = 19.225421400740743, train_acc = 0.9566837447601304\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 75, train_loss = 19.18381810747087, train_acc = 0.9569166278528178\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 76, train_loss = 19.120641285553575, train_acc = 0.9572659524918491\n",
      "test Acc 0.9413407821229051:\n",
      "16th- epoch: 77, train_loss = 19.07184153981507, train_acc = 0.9572659524918491\n",
      "test Acc 0.9418063314711359:\n",
      "16th- epoch: 78, train_loss = 19.025715176016092, train_acc = 0.9573823940381928\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 79, train_loss = 18.977928733453155, train_acc = 0.9572659524918491\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 80, train_loss = 18.930600693449378, train_acc = 0.9574988355845365\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 81, train_loss = 18.86596949212253, train_acc = 0.9577317186772241\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 82, train_loss = 18.830810183659196, train_acc = 0.9579646017699115\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 83, train_loss = 18.78828744404018, train_acc = 0.9579646017699115\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 84, train_loss = 18.74285649880767, train_acc = 0.9579646017699115\n",
      "test Acc 0.9432029795158287:\n",
      "16th- epoch: 85, train_loss = 18.702626682817936, train_acc = 0.9581974848625989\n",
      "test Acc 0.9432029795158287:\n",
      "16th- epoch: 86, train_loss = 18.672532672062516, train_acc = 0.9583139264089428\n",
      "test Acc 0.9432029795158287:\n",
      "16th- epoch: 87, train_loss = 18.597555307671428, train_acc = 0.9583139264089428\n",
      "test Acc 0.9432029795158287:\n",
      "16th- epoch: 88, train_loss = 18.577151337638497, train_acc = 0.9584303679552865\n",
      "test Acc 0.9432029795158287:\n",
      "16th- epoch: 89, train_loss = 18.537656197324395, train_acc = 0.9586632510479739\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 90, train_loss = 18.49373802728951, train_acc = 0.9588961341406614\n",
      "test Acc 0.9432029795158287:\n",
      "16th- epoch: 91, train_loss = 18.44796053506434, train_acc = 0.9587796925943176\n",
      "test Acc 0.9432029795158287:\n",
      "16th- epoch: 92, train_loss = 18.405382880941033, train_acc = 0.9588961341406614\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 93, train_loss = 18.362339993938804, train_acc = 0.9590125756870052\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 94, train_loss = 18.34066229686141, train_acc = 0.9590125756870052\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 95, train_loss = 18.280548674985766, train_acc = 0.9588961341406614\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 96, train_loss = 18.25507503002882, train_acc = 0.9590125756870052\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 97, train_loss = 18.209880324080586, train_acc = 0.9590125756870052\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 98, train_loss = 18.18255521915853, train_acc = 0.9592454587796926\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 99, train_loss = 18.149497305974364, train_acc = 0.9593619003260363\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 100, train_loss = 18.109259130433202, train_acc = 0.95947834187238\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 101, train_loss = 18.067596590146422, train_acc = 0.95947834187238\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 102, train_loss = 18.048410763964057, train_acc = 0.9597112249650676\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 103, train_loss = 17.999877201393247, train_acc = 0.9597112249650676\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 104, train_loss = 17.967105543240905, train_acc = 0.9597112249650676\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 105, train_loss = 17.95149781368673, train_acc = 0.9595947834187238\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 106, train_loss = 17.90672172792256, train_acc = 0.9597112249650676\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 107, train_loss = 17.889149710536003, train_acc = 0.9597112249650676\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 108, train_loss = 17.83179661631584, train_acc = 0.9598276665114113\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 109, train_loss = 17.809988429769874, train_acc = 0.9597112249650676\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 110, train_loss = 17.778480175882578, train_acc = 0.959944108057755\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 111, train_loss = 17.73119872994721, train_acc = 0.959944108057755\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 112, train_loss = 17.70478322543204, train_acc = 0.959944108057755\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 113, train_loss = 17.673000287264585, train_acc = 0.9601769911504425\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 114, train_loss = 17.644043669104576, train_acc = 0.959944108057755\n",
      "test Acc 0.9432029795158287:\n",
      "16th- epoch: 115, train_loss = 17.62677315622568, train_acc = 0.9601769911504425\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 116, train_loss = 17.598870674148202, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 117, train_loss = 17.54781307466328, train_acc = 0.9601769911504425\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 118, train_loss = 17.52911934070289, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 119, train_loss = 17.510992350056767, train_acc = 0.96040987424313\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 120, train_loss = 17.463431231677532, train_acc = 0.96040987424313\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 121, train_loss = 17.461485924199224, train_acc = 0.9602934326967862\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 122, train_loss = 17.420123171061277, train_acc = 0.9605263157894737\n",
      "test Acc 0.9445996275605214:\n",
      "16th- epoch: 123, train_loss = 17.400251757353544, train_acc = 0.9608756404285049\n",
      "test Acc 0.9445996275605214:\n",
      "16th- epoch: 124, train_loss = 17.377981340512633, train_acc = 0.9605263157894737\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 125, train_loss = 17.351904878392816, train_acc = 0.9608756404285049\n",
      "test Acc 0.9445996275605214:\n",
      "16th- epoch: 126, train_loss = 17.32909302227199, train_acc = 0.9607591988821611\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 127, train_loss = 17.307359222322702, train_acc = 0.9607591988821611\n",
      "test Acc 0.9445996275605214:\n",
      "16th- epoch: 128, train_loss = 17.27166643552482, train_acc = 0.9609920819748486\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 129, train_loss = 17.244317850098014, train_acc = 0.9608756404285049\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 130, train_loss = 17.23157426714897, train_acc = 0.9609920819748486\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 131, train_loss = 17.203904097899795, train_acc = 0.9608756404285049\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 132, train_loss = 17.183942129835486, train_acc = 0.9609920819748486\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 133, train_loss = 17.15388146787882, train_acc = 0.9611085235211924\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 134, train_loss = 17.126871343702078, train_acc = 0.9609920819748486\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 135, train_loss = 17.1188937202096, train_acc = 0.9612249650675361\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 136, train_loss = 17.073296109214425, train_acc = 0.9613414066138798\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 137, train_loss = 17.04950195737183, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 138, train_loss = 17.029416497796774, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 139, train_loss = 17.010090611875057, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 140, train_loss = 16.98435513675213, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 141, train_loss = 16.96532654762268, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 142, train_loss = 16.952350322157145, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 143, train_loss = 16.932141641154885, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 144, train_loss = 16.893058782443404, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 145, train_loss = 16.885147040709853, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 146, train_loss = 16.86186933517456, train_acc = 0.961690731252911\n",
      "test Acc 0.9450651769087524:\n",
      "16th- epoch: 147, train_loss = 16.843024348840117, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 148, train_loss = 16.826095620170236, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 149, train_loss = 16.794677570462227, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 150, train_loss = 16.778973903506994, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 151, train_loss = 16.761325618252158, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 152, train_loss = 16.750682352110744, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 153, train_loss = 16.723219415172935, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 154, train_loss = 16.704923814162612, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 155, train_loss = 16.67988925240934, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 156, train_loss = 16.667838959023356, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 157, train_loss = 16.647180050611496, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 158, train_loss = 16.62072252854705, train_acc = 0.9619236143455985\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 159, train_loss = 16.608598068356514, train_acc = 0.9619236143455985\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 160, train_loss = 16.59062766842544, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 161, train_loss = 16.577651752159, train_acc = 0.9619236143455985\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 162, train_loss = 16.556546853855252, train_acc = 0.962156497438286\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 163, train_loss = 16.538750598207116, train_acc = 0.9620400558919422\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 164, train_loss = 16.515527518466115, train_acc = 0.9623893805309734\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 165, train_loss = 16.48838695883751, train_acc = 0.9623893805309734\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 166, train_loss = 16.47159324027598, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 167, train_loss = 16.465709265321493, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 168, train_loss = 16.435953449457884, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 169, train_loss = 16.42489148117602, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 170, train_loss = 16.408717652782798, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 171, train_loss = 16.39033635146916, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 172, train_loss = 16.37740444391966, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 173, train_loss = 16.358912272378802, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 174, train_loss = 16.341416213661432, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 175, train_loss = 16.322070697322488, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 176, train_loss = 16.312227059155703, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 177, train_loss = 16.295467184856534, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 178, train_loss = 16.2694494407624, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 179, train_loss = 16.25773859024048, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 180, train_loss = 16.245376015082, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 181, train_loss = 16.226643348112702, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "16th- epoch: 182, train_loss = 16.214159606024623, train_acc = 0.9633209129017233\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 183, train_loss = 16.198295027017593, train_acc = 0.9635537959944108\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 184, train_loss = 16.182095346972346, train_acc = 0.9634373544480671\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 185, train_loss = 16.171359503641725, train_acc = 0.9635537959944108\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 186, train_loss = 16.143714286386967, train_acc = 0.9635537959944108\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 187, train_loss = 16.12576267682016, train_acc = 0.9636702375407545\n",
      "test Acc 0.9459962756052142:\n",
      "16th- epoch: 188, train_loss = 16.12128370720893, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "16th- epoch: 189, train_loss = 16.102959901094437, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "16th- epoch: 190, train_loss = 16.086510786786675, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "16th- epoch: 191, train_loss = 16.07561832293868, train_acc = 0.9637866790870983\n",
      "test Acc 0.9464618249534451:\n",
      "16th- epoch: 192, train_loss = 16.06287309434265, train_acc = 0.9637866790870983\n",
      "test Acc 0.9464618249534451:\n",
      "16th- epoch: 193, train_loss = 16.04843306634575, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 194, train_loss = 16.038625847548246, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 195, train_loss = 16.02235793787986, train_acc = 0.9637866790870983\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 196, train_loss = 15.993588755838573, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 197, train_loss = 15.98919540643692, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 198, train_loss = 15.973478599451482, train_acc = 0.9640195621797858\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 199, train_loss = 15.96679599955678, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 200, train_loss = 15.950060782022774, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 201, train_loss = 15.933990368619561, train_acc = 0.9640195621797858\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 202, train_loss = 15.92094914894551, train_acc = 0.9640195621797858\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 203, train_loss = 15.907143010757864, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 204, train_loss = 15.894391854293644, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 205, train_loss = 15.879990917630494, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 206, train_loss = 15.865127359516919, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 207, train_loss = 15.856401112861931, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 208, train_loss = 15.843649849295616, train_acc = 0.9640195621797858\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 209, train_loss = 15.83121504355222, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "16th- epoch: 210, train_loss = 15.820607689209282, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "16th- epoch: 211, train_loss = 15.805373434908688, train_acc = 0.9640195621797858\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 212, train_loss = 15.787227458320558, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "16th- epoch: 213, train_loss = 15.779481176286936, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 214, train_loss = 15.773664772510529, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 215, train_loss = 15.76000373903662, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 216, train_loss = 15.75101624429226, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "16th- epoch: 217, train_loss = 15.731108653359115, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 218, train_loss = 15.712114416994154, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 219, train_loss = 15.710003212094307, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 220, train_loss = 15.709559136070311, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 221, train_loss = 15.677014430053532, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 222, train_loss = 15.664066801778972, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 223, train_loss = 15.652303776703775, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 224, train_loss = 15.6465495666489, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 225, train_loss = 15.638504859060049, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 226, train_loss = 15.633198495954275, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 227, train_loss = 15.614124541170895, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 228, train_loss = 15.607391570694745, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 229, train_loss = 15.589897303842008, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 230, train_loss = 15.575316593050957, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 231, train_loss = 15.564096086658537, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 232, train_loss = 15.560162310488522, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 233, train_loss = 15.549315422773361, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 234, train_loss = 15.536299160681665, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 235, train_loss = 15.521060426719487, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 236, train_loss = 15.508731320500374, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 237, train_loss = 15.500137862749398, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 238, train_loss = 15.491762491874397, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 239, train_loss = 15.475060335360467, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 240, train_loss = 15.473807156085968, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 241, train_loss = 15.458484075963497, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 242, train_loss = 15.449295270256698, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 243, train_loss = 15.433957040309906, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 244, train_loss = 15.426122937351465, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 245, train_loss = 15.419631290249527, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 246, train_loss = 15.400239199399948, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 247, train_loss = 15.39804819598794, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 248, train_loss = 15.38585947547108, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 249, train_loss = 15.380206033587456, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 250, train_loss = 15.367723836563528, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 251, train_loss = 15.359039741568267, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 252, train_loss = 15.341721218079329, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 253, train_loss = 15.336397550068796, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 254, train_loss = 15.328871626406908, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 255, train_loss = 15.319231745786965, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 256, train_loss = 15.309519458562136, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 257, train_loss = 15.296864174306393, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 258, train_loss = 15.282578668557107, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 259, train_loss = 15.283287290483713, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 260, train_loss = 15.265045390464365, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 261, train_loss = 15.260133020579815, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 262, train_loss = 15.250581006519496, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 263, train_loss = 15.2425029091537, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 264, train_loss = 15.226831540465355, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 265, train_loss = 15.223242574371397, train_acc = 0.9662319515603167\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 266, train_loss = 15.215805269777775, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 267, train_loss = 15.202928059734404, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 268, train_loss = 15.193868332542479, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 269, train_loss = 15.194949202239513, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 270, train_loss = 15.182675519026816, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 271, train_loss = 15.165784236043692, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 272, train_loss = 15.150925972498953, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 273, train_loss = 15.154955805279315, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 274, train_loss = 15.132715177722275, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 275, train_loss = 15.128860122524202, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 276, train_loss = 15.122673239558935, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 277, train_loss = 15.11570979654789, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 278, train_loss = 15.103096726350486, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 279, train_loss = 15.094939667731524, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 280, train_loss = 15.08683850709349, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 281, train_loss = 15.078783323056996, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 282, train_loss = 15.072478040121496, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 283, train_loss = 15.057206152938306, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 284, train_loss = 15.051103097386658, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 285, train_loss = 15.04135914426297, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 286, train_loss = 15.038267784751952, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 287, train_loss = 15.029954180121422, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 288, train_loss = 15.017829570919275, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 289, train_loss = 15.009410814382136, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 290, train_loss = 15.00829103589058, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 291, train_loss = 14.991484735161066, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 292, train_loss = 14.98453667666763, train_acc = 0.9670470423847228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 293, train_loss = 14.97449332755059, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 294, train_loss = 14.970880164764822, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 295, train_loss = 14.960427685640752, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 296, train_loss = 14.959224049933255, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 297, train_loss = 14.948863244615495, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 298, train_loss = 14.932836689986289, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 299, train_loss = 14.92943203728646, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 300, train_loss = 14.929755259305239, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 301, train_loss = 14.913889371789992, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 302, train_loss = 14.912171891890466, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 303, train_loss = 14.906537652947009, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "16th- epoch: 304, train_loss = 14.896335232071579, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 305, train_loss = 14.87918798532337, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 306, train_loss = 14.880605117417872, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 307, train_loss = 14.86415136512369, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 308, train_loss = 14.860655180178583, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 309, train_loss = 14.863957793451846, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 310, train_loss = 14.850887231528759, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 311, train_loss = 14.83556377980858, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 312, train_loss = 14.83385734912008, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 313, train_loss = 14.824329007416964, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 314, train_loss = 14.815962575376034, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 315, train_loss = 14.814387507736683, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 316, train_loss = 14.796662596054375, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 317, train_loss = 14.798834518529475, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 318, train_loss = 14.78783539030701, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 319, train_loss = 14.786143080331385, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 320, train_loss = 14.77810451388359, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 321, train_loss = 14.769642586819828, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 322, train_loss = 14.760355182923377, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "16th- epoch: 323, train_loss = 14.75775480736047, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "16th- epoch: 324, train_loss = 14.745128921233118, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "16th- epoch: 325, train_loss = 14.740239343605936, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "16th- epoch: 326, train_loss = 14.733711906708777, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 327, train_loss = 14.722487059421837, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "16th- epoch: 328, train_loss = 14.719262561760843, train_acc = 0.9676292501164415\n",
      "test Acc 0.9487895716945997:\n",
      "16th- epoch: 329, train_loss = 14.71071965713054, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 330, train_loss = 14.705455570481718, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 331, train_loss = 14.699601513333619, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 332, train_loss = 14.697935766540468, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 333, train_loss = 14.683137918822467, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 334, train_loss = 14.680954866111279, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 335, train_loss = 14.675232558511198, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 336, train_loss = 14.668863631784916, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 337, train_loss = 14.65867576468736, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 338, train_loss = 14.657909411936998, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 339, train_loss = 14.645197581499815, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 340, train_loss = 14.636991579085588, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 341, train_loss = 14.630494934506714, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 342, train_loss = 14.625274047255516, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 343, train_loss = 14.615722612477839, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 344, train_loss = 14.610412345267832, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 345, train_loss = 14.603753932751715, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 346, train_loss = 14.596267186105251, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 347, train_loss = 14.589727562852204, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 348, train_loss = 14.58381737023592, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 349, train_loss = 14.5747410049662, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 350, train_loss = 14.570358202792704, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 351, train_loss = 14.56307013798505, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 352, train_loss = 14.552608386613429, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 353, train_loss = 14.5412541879341, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 354, train_loss = 14.539291241206229, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 355, train_loss = 14.542304255068302, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 356, train_loss = 14.53015800472349, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 357, train_loss = 14.526660940609872, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 358, train_loss = 14.51620111335069, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 359, train_loss = 14.514254533685744, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 360, train_loss = 14.507210516370833, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 361, train_loss = 14.49827956687659, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 362, train_loss = 14.493775905109942, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 363, train_loss = 14.48940724413842, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 364, train_loss = 14.483657238073647, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 365, train_loss = 14.473271519877017, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 366, train_loss = 14.474204007536173, train_acc = 0.9683278993945039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 367, train_loss = 14.462470307946205, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 368, train_loss = 14.46241291705519, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 369, train_loss = 14.452631399035454, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 370, train_loss = 14.449682153761387, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 371, train_loss = 14.444843423552811, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 372, train_loss = 14.431025079451501, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 373, train_loss = 14.433106943033636, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 374, train_loss = 14.420217965729535, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 375, train_loss = 14.417228642851114, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 376, train_loss = 14.41356996446848, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 377, train_loss = 14.406659349799156, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 378, train_loss = 14.396825158037245, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 379, train_loss = 14.394322113133967, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 380, train_loss = 14.391001875512302, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 381, train_loss = 14.381370567716658, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 382, train_loss = 14.379033633507788, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 383, train_loss = 14.3761035380885, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 384, train_loss = 14.367429272271693, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 385, train_loss = 14.361474376171827, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 386, train_loss = 14.353829752653837, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 387, train_loss = 14.34877893794328, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 388, train_loss = 14.34092924091965, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 389, train_loss = 14.335497464984655, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 390, train_loss = 14.336533606052399, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 391, train_loss = 14.320744986645877, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 392, train_loss = 14.320636183023453, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 393, train_loss = 14.31511924508959, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 394, train_loss = 14.311885707080364, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 395, train_loss = 14.30808459687978, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 396, train_loss = 14.303878010250628, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 397, train_loss = 14.292434765957296, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 398, train_loss = 14.28655482083559, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 399, train_loss = 14.283628638833761, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 400, train_loss = 14.27445690240711, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 401, train_loss = 14.278356231749058, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 402, train_loss = 14.266761138103902, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 403, train_loss = 14.261500486172736, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "16th- epoch: 404, train_loss = 14.256459846161306, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 405, train_loss = 14.247617832385004, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 406, train_loss = 14.244836460798979, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 407, train_loss = 14.242392187006772, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 408, train_loss = 14.235339093953371, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 409, train_loss = 14.23107246030122, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 410, train_loss = 14.228686441667378, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 411, train_loss = 14.226792681030929, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 412, train_loss = 14.216452262364328, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 413, train_loss = 14.21341211348772, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 414, train_loss = 14.207091151736677, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 415, train_loss = 14.200433212332428, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 416, train_loss = 14.195853244513273, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 417, train_loss = 14.188101102598011, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 418, train_loss = 14.187291643582284, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 419, train_loss = 14.179191350005567, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 420, train_loss = 14.177905374206603, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 421, train_loss = 14.16876380611211, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 422, train_loss = 14.166395026259124, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 423, train_loss = 14.155666000209749, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 424, train_loss = 14.156850186176598, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 425, train_loss = 14.15120821353048, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 426, train_loss = 14.143525868654251, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 427, train_loss = 14.137865626253188, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 428, train_loss = 14.13569965120405, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 429, train_loss = 14.132844568230212, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 430, train_loss = 14.125594437122345, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 431, train_loss = 14.122543076984584, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 432, train_loss = 14.113262771628797, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 433, train_loss = 14.110991318710148, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 434, train_loss = 14.108427765779197, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 435, train_loss = 14.103506789542735, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 436, train_loss = 14.096551242284477, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 437, train_loss = 14.09409957099706, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 438, train_loss = 14.090632386505604, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 439, train_loss = 14.081292592920363, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 440, train_loss = 14.07863740902394, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 441, train_loss = 14.076262624002993, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 442, train_loss = 14.076730026863515, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 443, train_loss = 14.066583927720785, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 444, train_loss = 14.062978501431644, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 445, train_loss = 14.059129987843335, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 446, train_loss = 14.053559715859592, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 447, train_loss = 14.04654364939779, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 448, train_loss = 14.042577306739986, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 449, train_loss = 14.043507513590157, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 450, train_loss = 14.038833003491163, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 451, train_loss = 14.026639067567885, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 452, train_loss = 14.027963695116341, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 453, train_loss = 14.018642812035978, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 454, train_loss = 14.012872159481049, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 455, train_loss = 14.015780442394316, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 456, train_loss = 14.011871471069753, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 457, train_loss = 13.998005352914333, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 458, train_loss = 13.999026144854724, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 459, train_loss = 13.99282016698271, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 460, train_loss = 13.987823698669672, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 461, train_loss = 13.989497181028128, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 462, train_loss = 13.982153919525445, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 463, train_loss = 13.97678504139185, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 464, train_loss = 13.97684167791158, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 465, train_loss = 13.969594064168632, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 466, train_loss = 13.966707210056484, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 467, train_loss = 13.966479741968215, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 468, train_loss = 13.95468486752361, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 469, train_loss = 13.955606845207512, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 470, train_loss = 13.946765943430364, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 471, train_loss = 13.944812513887882, train_acc = 0.9691429902189101\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 472, train_loss = 13.943055824376643, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 473, train_loss = 13.938201767392457, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 474, train_loss = 13.928391600959003, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 475, train_loss = 13.929005980491638, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 476, train_loss = 13.924745894037187, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 477, train_loss = 13.922516159713268, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 478, train_loss = 13.912131771445274, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 479, train_loss = 13.909372210502625, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 480, train_loss = 13.908113660756499, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 481, train_loss = 13.904200501739979, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 482, train_loss = 13.89856586465612, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 483, train_loss = 13.890853458084166, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 484, train_loss = 13.895369247999042, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 485, train_loss = 13.87642873218283, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 486, train_loss = 13.882232915610075, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 487, train_loss = 13.874076400883496, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 488, train_loss = 13.869126497302204, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 489, train_loss = 13.869973310269415, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 490, train_loss = 13.868516568094492, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 491, train_loss = 13.854921460151672, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 492, train_loss = 13.85607281466946, train_acc = 0.9694923148579413\n",
      "test Acc 0.9497206703910615:\n",
      "16th- epoch: 493, train_loss = 13.851517288479954, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 494, train_loss = 13.850170795805752, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 495, train_loss = 13.842569707427174, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 496, train_loss = 13.836058972869068, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 497, train_loss = 13.83395241945982, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 498, train_loss = 13.838307932950556, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "16th- epoch: 499, train_loss = 13.820051353424788, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████▎                                | 16/30 [2:24:53<2:06:31, 542.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "17th- epoch: 0, train_loss = 123.35105806589127, train_acc = 0.7469725197950629\n",
      "test Acc 0.8337988826815642:\n",
      "17th- epoch: 1, train_loss = 59.712867587804794, train_acc = 0.8706334420121099\n",
      "test Acc 0.8943202979515829:\n",
      "17th- epoch: 2, train_loss = 49.4197196662426, train_acc = 0.8959012575687005\n",
      "test Acc 0.9050279329608939:\n",
      "17th- epoch: 3, train_loss = 44.33423639088869, train_acc = 0.9052165812761993\n",
      "test Acc 0.9110800744878957:\n",
      "17th- epoch: 4, train_loss = 40.93861739337444, train_acc = 0.9111551001397299\n",
      "test Acc 0.9162011173184358:\n",
      "17th- epoch: 5, train_loss = 38.529023826122284, train_acc = 0.9160456450861667\n",
      "test Acc 0.9203910614525139:\n",
      "17th- epoch: 6, train_loss = 36.66660661995411, train_acc = 0.9211690731252911\n",
      "test Acc 0.9213221601489758:\n",
      "17th- epoch: 7, train_loss = 35.16859308630228, train_acc = 0.9243129948765719\n",
      "test Acc 0.9250465549348231:\n",
      "17th- epoch: 8, train_loss = 33.94761334359646, train_acc = 0.9264089427107592\n",
      "test Acc 0.9264432029795159:\n",
      "17th- epoch: 9, train_loss = 32.86742652207613, train_acc = 0.9283884489986027\n",
      "test Acc 0.9287709497206704:\n",
      "17th- epoch: 10, train_loss = 31.967298679053783, train_acc = 0.9307172799254774\n",
      "test Acc 0.9292364990689013:\n",
      "17th- epoch: 11, train_loss = 31.18466182053089, train_acc = 0.9314159292035398\n",
      "test Acc 0.930633147113594:\n",
      "17th- epoch: 12, train_loss = 30.493789047002792, train_acc = 0.9324639031206334\n",
      "test Acc 0.9315642458100558:\n",
      "17th- epoch: 13, train_loss = 29.84697352349758, train_acc = 0.935258500232883\n",
      "test Acc 0.9320297951582868:\n",
      "17th- epoch: 14, train_loss = 29.258201777935028, train_acc = 0.936655798789008\n",
      "test Acc 0.9315642458100558:\n",
      "17th- epoch: 15, train_loss = 28.73874109238386, train_acc = 0.9365393572426641\n",
      "test Acc 0.9315642458100558:\n",
      "17th- epoch: 16, train_loss = 28.258985735476017, train_acc = 0.937936655798789\n",
      "test Acc 0.9320297951582868:\n",
      "17th- epoch: 17, train_loss = 27.829377934336662, train_acc = 0.9381695388914765\n",
      "test Acc 0.9315642458100558:\n",
      "17th- epoch: 18, train_loss = 27.418928995728493, train_acc = 0.9394503959012576\n",
      "test Acc 0.9315642458100558:\n",
      "17th- epoch: 19, train_loss = 27.050601713359356, train_acc = 0.9394503959012576\n",
      "test Acc 0.9320297951582868:\n",
      "17th- epoch: 20, train_loss = 26.696466755121946, train_acc = 0.9400326036329762\n",
      "test Acc 0.9329608938547486:\n",
      "17th- epoch: 21, train_loss = 26.361589156091213, train_acc = 0.9408476944573824\n",
      "test Acc 0.9329608938547486:\n",
      "17th- epoch: 22, train_loss = 26.05460700765252, train_acc = 0.942361434559851\n",
      "test Acc 0.9329608938547486:\n",
      "17th- epoch: 23, train_loss = 25.74103646352887, train_acc = 0.9429436422915697\n",
      "test Acc 0.9329608938547486:\n",
      "17th- epoch: 24, train_loss = 25.459729187190533, train_acc = 0.9434094084769445\n",
      "test Acc 0.9329608938547486:\n",
      "17th- epoch: 25, train_loss = 25.20437168329954, train_acc = 0.9439916162086632\n",
      "test Acc 0.9338919925512105:\n",
      "17th- epoch: 26, train_loss = 24.953865606337786, train_acc = 0.9448067070330693\n",
      "test Acc 0.9338919925512105:\n",
      "17th- epoch: 27, train_loss = 24.73036154732108, train_acc = 0.9455053563111319\n",
      "test Acc 0.9343575418994413:\n",
      "17th- epoch: 28, train_loss = 24.507414113730192, train_acc = 0.9459711224965067\n",
      "test Acc 0.9352886405959032:\n",
      "17th- epoch: 29, train_loss = 24.29508625343442, train_acc = 0.9464368886818817\n",
      "test Acc 0.936219739292365:\n",
      "17th- epoch: 30, train_loss = 24.090977676212788, train_acc = 0.9469026548672567\n",
      "test Acc 0.9366852886405959:\n",
      "17th- epoch: 31, train_loss = 23.90247232839465, train_acc = 0.9473684210526315\n",
      "test Acc 0.9371508379888268:\n",
      "17th- epoch: 32, train_loss = 23.717542447149754, train_acc = 0.9477177456916628\n",
      "test Acc 0.9380819366852886:\n",
      "17th- epoch: 33, train_loss = 23.54473089426756, train_acc = 0.9479506287843502\n",
      "test Acc 0.9385474860335196:\n",
      "17th- epoch: 34, train_loss = 23.378484837710857, train_acc = 0.9482999534233815\n",
      "test Acc 0.9385474860335196:\n",
      "17th- epoch: 35, train_loss = 23.21262315288186, train_acc = 0.9484163949697252\n",
      "test Acc 0.9385474860335196:\n",
      "17th- epoch: 36, train_loss = 23.06276150047779, train_acc = 0.9487657196087564\n",
      "test Acc 0.9390130353817505:\n",
      "17th- epoch: 37, train_loss = 22.913455355912447, train_acc = 0.9487657196087564\n",
      "test Acc 0.9390130353817505:\n",
      "17th- epoch: 38, train_loss = 22.77562962844968, train_acc = 0.9503959012575687\n",
      "test Acc 0.9390130353817505:\n",
      "17th- epoch: 39, train_loss = 22.636642698198557, train_acc = 0.9503959012575687\n",
      "test Acc 0.9390130353817505:\n",
      "17th- epoch: 40, train_loss = 22.50002756714821, train_acc = 0.9508616674429436\n",
      "test Acc 0.9390130353817505:\n",
      "17th- epoch: 41, train_loss = 22.37043596804142, train_acc = 0.9512109920819748\n",
      "test Acc 0.9394785847299814:\n",
      "17th- epoch: 42, train_loss = 22.24566461518407, train_acc = 0.9513274336283186\n",
      "test Acc 0.9394785847299814:\n",
      "17th- epoch: 43, train_loss = 22.13089518994093, train_acc = 0.9517931998136935\n",
      "test Acc 0.9394785847299814:\n",
      "17th- epoch: 44, train_loss = 22.012421157211065, train_acc = 0.952026082906381\n",
      "test Acc 0.9394785847299814:\n",
      "17th- epoch: 45, train_loss = 21.900056976825, train_acc = 0.952491849091756\n",
      "test Acc 0.9390130353817505:\n",
      "17th- epoch: 46, train_loss = 21.79170271754265, train_acc = 0.952491849091756\n",
      "test Acc 0.9394785847299814:\n",
      "17th- epoch: 47, train_loss = 21.68277684599161, train_acc = 0.9528411737307871\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 48, train_loss = 21.580457497388124, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 49, train_loss = 21.484197333455086, train_acc = 0.9535398230088495\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 50, train_loss = 21.384261075407267, train_acc = 0.9536562645551933\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 51, train_loss = 21.292531687766314, train_acc = 0.9540055891942245\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 52, train_loss = 21.203014694154263, train_acc = 0.9541220307405682\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 53, train_loss = 21.114548109471798, train_acc = 0.9541220307405682\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 54, train_loss = 21.02811586856842, train_acc = 0.9542384722869119\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 55, train_loss = 20.94150874018669, train_acc = 0.9544713553795995\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 56, train_loss = 20.857046265155077, train_acc = 0.9547042384722869\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 57, train_loss = 20.77685960754752, train_acc = 0.9548206800186306\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 58, train_loss = 20.69852726534009, train_acc = 0.9552864462040056\n",
      "test Acc 0.9404096834264432:\n",
      "17th- epoch: 59, train_loss = 20.62224581092596, train_acc = 0.9556357708430367\n",
      "test Acc 0.9413407821229051:\n",
      "17th- epoch: 60, train_loss = 20.550391629338264, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "17th- epoch: 61, train_loss = 20.47376289218664, train_acc = 0.9556357708430367\n",
      "test Acc 0.9413407821229051:\n",
      "17th- epoch: 62, train_loss = 20.40462599694729, train_acc = 0.955985095482068\n",
      "test Acc 0.9413407821229051:\n",
      "17th- epoch: 63, train_loss = 20.33325883373618, train_acc = 0.9561015370284117\n",
      "test Acc 0.9413407821229051:\n",
      "17th- epoch: 64, train_loss = 20.27027039602399, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "17th- epoch: 65, train_loss = 20.200320947915316, train_acc = 0.9562179785747554\n",
      "test Acc 0.9413407821229051:\n",
      "17th- epoch: 66, train_loss = 20.13219492509961, train_acc = 0.956450861667443\n",
      "test Acc 0.9413407821229051:\n",
      "17th- epoch: 67, train_loss = 20.075998172163963, train_acc = 0.9565673032137867\n",
      "test Acc 0.9413407821229051:\n",
      "17th- epoch: 68, train_loss = 20.006998281925917, train_acc = 0.9565673032137867\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 69, train_loss = 19.946842528879642, train_acc = 0.9565673032137867\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 70, train_loss = 19.889945283532143, train_acc = 0.9565673032137867\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 71, train_loss = 19.827107027173042, train_acc = 0.9566837447601304\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 72, train_loss = 19.768723487854004, train_acc = 0.9568001863064741\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 73, train_loss = 19.71419507265091, train_acc = 0.9572659524918491\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 74, train_loss = 19.654888212680817, train_acc = 0.9572659524918491\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 75, train_loss = 19.601177640259266, train_acc = 0.9574988355845365\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 76, train_loss = 19.550783403217793, train_acc = 0.9574988355845365\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 77, train_loss = 19.493902545422316, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 78, train_loss = 19.442904509603977, train_acc = 0.9579646017699115\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 79, train_loss = 19.39223063364625, train_acc = 0.9579646017699115\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 80, train_loss = 19.335531190037727, train_acc = 0.9580810433162552\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 81, train_loss = 19.288794368505478, train_acc = 0.9580810433162552\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 82, train_loss = 19.237130023539066, train_acc = 0.9583139264089428\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 83, train_loss = 19.18808962404728, train_acc = 0.9585468095016302\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 84, train_loss = 19.14534866809845, train_acc = 0.9586632510479739\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 85, train_loss = 19.095726761966944, train_acc = 0.9588961341406614\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 86, train_loss = 19.04912608116865, train_acc = 0.9590125756870052\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 87, train_loss = 19.00569351017475, train_acc = 0.9591290172333489\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 88, train_loss = 18.96303839981556, train_acc = 0.9592454587796926\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 89, train_loss = 18.920306779444218, train_acc = 0.9593619003260363\n",
      "test Acc 0.9418063314711359:\n",
      "17th- epoch: 90, train_loss = 18.876892544329166, train_acc = 0.95947834187238\n",
      "test Acc 0.9422718808193669:\n",
      "17th- epoch: 91, train_loss = 18.8354148901999, train_acc = 0.95947834187238\n",
      "test Acc 0.9422718808193669:\n",
      "17th- epoch: 92, train_loss = 18.792402021586895, train_acc = 0.9593619003260363\n",
      "test Acc 0.9427374301675978:\n",
      "17th- epoch: 93, train_loss = 18.75103710591793, train_acc = 0.9595947834187238\n",
      "test Acc 0.9427374301675978:\n",
      "17th- epoch: 94, train_loss = 18.711842507123947, train_acc = 0.9595947834187238\n",
      "test Acc 0.9427374301675978:\n",
      "17th- epoch: 95, train_loss = 18.67596299946308, train_acc = 0.9595947834187238\n",
      "test Acc 0.9427374301675978:\n",
      "17th- epoch: 96, train_loss = 18.635286040604115, train_acc = 0.9598276665114113\n",
      "test Acc 0.9427374301675978:\n",
      "17th- epoch: 97, train_loss = 18.599296029657125, train_acc = 0.9597112249650676\n",
      "test Acc 0.9432029795158287:\n",
      "17th- epoch: 98, train_loss = 18.560516756027937, train_acc = 0.9600605496040987\n",
      "test Acc 0.9432029795158287:\n",
      "17th- epoch: 99, train_loss = 18.52537466213107, train_acc = 0.9600605496040987\n",
      "test Acc 0.9432029795158287:\n",
      "17th- epoch: 100, train_loss = 18.491181548684835, train_acc = 0.9600605496040987\n",
      "test Acc 0.9432029795158287:\n",
      "17th- epoch: 101, train_loss = 18.450319949537516, train_acc = 0.9600605496040987\n",
      "test Acc 0.9432029795158287:\n",
      "17th- epoch: 102, train_loss = 18.416467856615782, train_acc = 0.9602934326967862\n",
      "test Acc 0.9432029795158287:\n",
      "17th- epoch: 103, train_loss = 18.380337368696928, train_acc = 0.9602934326967862\n",
      "test Acc 0.9432029795158287:\n",
      "17th- epoch: 104, train_loss = 18.348649438470602, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 105, train_loss = 18.313410308212042, train_acc = 0.9602934326967862\n",
      "test Acc 0.9436685288640596:\n",
      "17th- epoch: 106, train_loss = 18.27998912706971, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 107, train_loss = 18.24685825407505, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 108, train_loss = 18.215507097542286, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 109, train_loss = 18.179720923304558, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 110, train_loss = 18.145288944244385, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 111, train_loss = 18.11645058915019, train_acc = 0.96040987424313\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 112, train_loss = 18.0830187946558, train_acc = 0.96040987424313\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 113, train_loss = 18.055330641567707, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 114, train_loss = 18.022413305938244, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 115, train_loss = 17.9909539334476, train_acc = 0.9606427573358174\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 116, train_loss = 17.962731279432774, train_acc = 0.9607591988821611\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 117, train_loss = 17.935054782778025, train_acc = 0.9607591988821611\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 118, train_loss = 17.902813505381346, train_acc = 0.9608756404285049\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 119, train_loss = 17.871127359569073, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 120, train_loss = 17.847905721515417, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 121, train_loss = 17.81899158284068, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 122, train_loss = 17.79209442809224, train_acc = 0.9613414066138798\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 123, train_loss = 17.761039335280657, train_acc = 0.9611085235211924\n",
      "test Acc 0.9441340782122905:\n",
      "17th- epoch: 124, train_loss = 17.73520895652473, train_acc = 0.9612249650675361\n",
      "test Acc 0.9445996275605214:\n",
      "17th- epoch: 125, train_loss = 17.70678279735148, train_acc = 0.9611085235211924\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 126, train_loss = 17.676469275727868, train_acc = 0.9613414066138798\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 127, train_loss = 17.6523467451334, train_acc = 0.9613414066138798\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 128, train_loss = 17.630447458475828, train_acc = 0.9613414066138798\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 129, train_loss = 17.60392145998776, train_acc = 0.9612249650675361\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 130, train_loss = 17.574345897883177, train_acc = 0.9613414066138798\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 131, train_loss = 17.55141564644873, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 132, train_loss = 17.525404350832105, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 133, train_loss = 17.49904557131231, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 134, train_loss = 17.47974474541843, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 135, train_loss = 17.453640146180987, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 136, train_loss = 17.42790738865733, train_acc = 0.961690731252911\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 137, train_loss = 17.404927922412753, train_acc = 0.961690731252911\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 138, train_loss = 17.384256104007363, train_acc = 0.961690731252911\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 139, train_loss = 17.35653308033943, train_acc = 0.9619236143455985\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 140, train_loss = 17.332637349143624, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 141, train_loss = 17.311705788597465, train_acc = 0.9618071727992548\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 142, train_loss = 17.289092587307096, train_acc = 0.9618071727992548\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 143, train_loss = 17.268517941236496, train_acc = 0.9619236143455985\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 144, train_loss = 17.24278473109007, train_acc = 0.9619236143455985\n",
      "test Acc 0.9450651769087524:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 145, train_loss = 17.222914503887296, train_acc = 0.9619236143455985\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 146, train_loss = 17.197084380313754, train_acc = 0.9619236143455985\n",
      "test Acc 0.9450651769087524:\n",
      "17th- epoch: 147, train_loss = 17.181572748348117, train_acc = 0.9619236143455985\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 148, train_loss = 17.15967532247305, train_acc = 0.962156497438286\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 149, train_loss = 17.140128729864955, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 150, train_loss = 17.118523193523288, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 151, train_loss = 17.098150359466672, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 152, train_loss = 17.07721335068345, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 153, train_loss = 17.05819496884942, train_acc = 0.9623893805309734\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 154, train_loss = 17.03659929148853, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 155, train_loss = 17.016308329999447, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 156, train_loss = 17.000553326681256, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 157, train_loss = 16.98026523180306, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 158, train_loss = 16.954362792894244, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 159, train_loss = 16.940661400556564, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 160, train_loss = 16.922808779403567, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 161, train_loss = 16.900461750105023, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 162, train_loss = 16.880371375009418, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 163, train_loss = 16.867893191054463, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 164, train_loss = 16.84454912133515, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 165, train_loss = 16.826256981119514, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 166, train_loss = 16.808755103498697, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 167, train_loss = 16.78900026343763, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 168, train_loss = 16.772858595475554, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 169, train_loss = 16.74992903880775, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 170, train_loss = 16.737253427505493, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 171, train_loss = 16.718710681423545, train_acc = 0.9629715882626921\n",
      "test Acc 0.9459962756052142:\n",
      "17th- epoch: 172, train_loss = 16.69912896491587, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 173, train_loss = 16.683969324454665, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 174, train_loss = 16.66621876694262, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 175, train_loss = 16.652785999700427, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 176, train_loss = 16.635606260970235, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 177, train_loss = 16.61518518999219, train_acc = 0.9633209129017233\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 178, train_loss = 16.59953404404223, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "17th- epoch: 179, train_loss = 16.580786671489477, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 180, train_loss = 16.567487994208932, train_acc = 0.9633209129017233\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 181, train_loss = 16.54478231072426, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "17th- epoch: 182, train_loss = 16.524781472980976, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 183, train_loss = 16.497592305764556, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 184, train_loss = 16.48190087452531, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 185, train_loss = 16.468968933448195, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 186, train_loss = 16.452116230502725, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 187, train_loss = 16.432559609413147, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 188, train_loss = 16.423343632370234, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 189, train_loss = 16.402127481997013, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 190, train_loss = 16.386246221140027, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "17th- epoch: 191, train_loss = 16.370700793340802, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 192, train_loss = 16.357079090550542, train_acc = 0.9637866790870983\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 193, train_loss = 16.33823179639876, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 194, train_loss = 16.32266073487699, train_acc = 0.9640195621797858\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 195, train_loss = 16.304430229589343, train_acc = 0.9640195621797858\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 196, train_loss = 16.288381300866604, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 197, train_loss = 16.27449576370418, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 198, train_loss = 16.262012984603643, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 199, train_loss = 16.247928455471992, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 200, train_loss = 16.22952270694077, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 201, train_loss = 16.22223449498415, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 202, train_loss = 16.205545151606202, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 203, train_loss = 16.192193066701293, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 204, train_loss = 16.178840432316065, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 205, train_loss = 16.161280805245042, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 206, train_loss = 16.149276420474052, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 207, train_loss = 16.136396707966924, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 208, train_loss = 16.12466922029853, train_acc = 0.9643688868188169\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 209, train_loss = 16.109897824004292, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 210, train_loss = 16.100075324997306, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 211, train_loss = 16.083160024136305, train_acc = 0.9646017699115044\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 212, train_loss = 16.07088795863092, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 213, train_loss = 16.054998887702823, train_acc = 0.9646017699115044\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 214, train_loss = 16.042952524498105, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 215, train_loss = 16.029726391658187, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 216, train_loss = 16.020646527409554, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 217, train_loss = 16.006892824545503, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 218, train_loss = 15.994985790923238, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 219, train_loss = 15.98194014467299, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 220, train_loss = 15.964615909382701, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 221, train_loss = 15.95422494970262, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 222, train_loss = 15.946074472740293, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 223, train_loss = 15.93300985172391, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 224, train_loss = 15.91953724808991, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "17th- epoch: 225, train_loss = 15.907583737745881, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 226, train_loss = 15.896096600219607, train_acc = 0.9650675360968793\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 227, train_loss = 15.871535090729594, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 228, train_loss = 15.856274360790849, train_acc = 0.9650675360968793\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 229, train_loss = 15.841359686106443, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 230, train_loss = 15.83378073386848, train_acc = 0.9650675360968793\n",
      "test Acc 0.9473929236499069:\n",
      "17th- epoch: 231, train_loss = 15.818441534414887, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 232, train_loss = 15.808437066152692, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 233, train_loss = 15.795390600338578, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 234, train_loss = 15.789573788642883, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 235, train_loss = 15.77271549217403, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 236, train_loss = 15.770294578745961, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 237, train_loss = 15.754166511818767, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 238, train_loss = 15.74357652105391, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 239, train_loss = 15.73444683663547, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 240, train_loss = 15.71990505605936, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 241, train_loss = 15.70620477385819, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 242, train_loss = 15.699747145175934, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 243, train_loss = 15.683951644226909, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 244, train_loss = 15.677508501335979, train_acc = 0.9654168607359106\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 245, train_loss = 15.661106267943978, train_acc = 0.9654168607359106\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 246, train_loss = 15.653779730200768, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 247, train_loss = 15.648033050820231, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 248, train_loss = 15.636998679488897, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 249, train_loss = 15.62378155440092, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 250, train_loss = 15.613539973273873, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 251, train_loss = 15.603299792855978, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 252, train_loss = 15.596617301926017, train_acc = 0.9654168607359106\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 253, train_loss = 15.58816498145461, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 254, train_loss = 15.571843106299639, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 255, train_loss = 15.564334413036704, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 256, train_loss = 15.553498106077313, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 257, train_loss = 15.543127534911036, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 258, train_loss = 15.536101086065173, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 259, train_loss = 15.522712239995599, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 260, train_loss = 15.520487340167165, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 261, train_loss = 15.506762003526092, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 262, train_loss = 15.491323130205274, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 263, train_loss = 15.490471079945564, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 264, train_loss = 15.48049658536911, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 265, train_loss = 15.471089528873563, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 266, train_loss = 15.456745220348239, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 267, train_loss = 15.448586205020547, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 268, train_loss = 15.439238781109452, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "17th- epoch: 269, train_loss = 15.430531112477183, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 270, train_loss = 15.42162812128663, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 271, train_loss = 15.412554208189249, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 272, train_loss = 15.399051586166024, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 273, train_loss = 15.391370508819818, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 274, train_loss = 15.38162312284112, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 275, train_loss = 15.375663125887513, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 276, train_loss = 15.363342974334955, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 277, train_loss = 15.353748340159655, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 278, train_loss = 15.338230948895216, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 279, train_loss = 15.337215529754758, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 280, train_loss = 15.329482223838568, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 281, train_loss = 15.316475773230195, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 282, train_loss = 15.307221872732043, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 283, train_loss = 15.299495274201035, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 284, train_loss = 15.287133855745196, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 285, train_loss = 15.282687744125724, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 286, train_loss = 15.272196093574166, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "17th- epoch: 287, train_loss = 15.266081027686596, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 288, train_loss = 15.257817018777132, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 289, train_loss = 15.249040921218693, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 290, train_loss = 15.238305004313588, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 291, train_loss = 15.233388083055615, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 292, train_loss = 15.222440274432302, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 293, train_loss = 15.212992310523987, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 294, train_loss = 15.203111201524734, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 295, train_loss = 15.19955523032695, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 296, train_loss = 15.187715099193156, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 297, train_loss = 15.181237093172967, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 298, train_loss = 15.17287628352642, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 299, train_loss = 15.169114299118519, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 300, train_loss = 15.161694183014333, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 301, train_loss = 15.154742929153144, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 302, train_loss = 15.14918303117156, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 303, train_loss = 15.139672189950943, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 304, train_loss = 15.130459844134748, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 305, train_loss = 15.122882722876966, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 306, train_loss = 15.112972849048674, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 307, train_loss = 15.105412391014397, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 308, train_loss = 15.094688578508794, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 309, train_loss = 15.095717087388039, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 310, train_loss = 15.081472695805132, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 311, train_loss = 15.07419644203037, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 312, train_loss = 15.066635663621128, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 313, train_loss = 15.056081051938236, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 314, train_loss = 15.051698002964258, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 315, train_loss = 15.043268733657897, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 316, train_loss = 15.037093632854521, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 317, train_loss = 15.029731786809862, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 318, train_loss = 15.022667308337986, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 319, train_loss = 15.013235211372375, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 320, train_loss = 15.008029025048018, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 321, train_loss = 14.99729971587658, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 322, train_loss = 14.993520635180175, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 323, train_loss = 14.985800347290933, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 324, train_loss = 14.9776890873909, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 325, train_loss = 14.96898028999567, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 326, train_loss = 14.964641786180437, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 327, train_loss = 14.957986324094236, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 328, train_loss = 14.951759599149227, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 329, train_loss = 14.946222861297429, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 330, train_loss = 14.938166875392199, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 331, train_loss = 14.933155122213066, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 332, train_loss = 14.921144836582243, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 333, train_loss = 14.91656331345439, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 334, train_loss = 14.907165705226362, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 335, train_loss = 14.89840782340616, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 336, train_loss = 14.892616136930883, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 337, train_loss = 14.88312669005245, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 338, train_loss = 14.881110064685345, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 339, train_loss = 14.874188845045865, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 340, train_loss = 14.865187116898596, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 341, train_loss = 14.86268117558211, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 342, train_loss = 14.853417377918959, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 343, train_loss = 14.847566592507064, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 344, train_loss = 14.842219650745392, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 345, train_loss = 14.833293731324375, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 346, train_loss = 14.822336811572313, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 347, train_loss = 14.821078144013882, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 348, train_loss = 14.812546096742153, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 349, train_loss = 14.807618985883892, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 350, train_loss = 14.797820199280977, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 351, train_loss = 14.793910425156355, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 352, train_loss = 14.78494023438543, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 353, train_loss = 14.779893398284912, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 354, train_loss = 14.774316965602338, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 355, train_loss = 14.767267038114369, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 356, train_loss = 14.762268950231373, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 357, train_loss = 14.757493332959712, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 358, train_loss = 14.750335634686053, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 359, train_loss = 14.741942907683551, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 360, train_loss = 14.73610183596611, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 361, train_loss = 14.726534050889313, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 362, train_loss = 14.722302961163223, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 363, train_loss = 14.713480908423662, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 364, train_loss = 14.711394655518234, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 365, train_loss = 14.702383336611092, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 366, train_loss = 14.697077099233866, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 367, train_loss = 14.693024094216526, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 368, train_loss = 14.686474741436541, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 369, train_loss = 14.681646972894669, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 370, train_loss = 14.675709255039692, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 371, train_loss = 14.668192989192903, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 372, train_loss = 14.66238381806761, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 373, train_loss = 14.655606522224844, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 374, train_loss = 14.649798404425383, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 375, train_loss = 14.641396353952587, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 376, train_loss = 14.639442826621234, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 377, train_loss = 14.63093535695225, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 378, train_loss = 14.627230954356492, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 379, train_loss = 14.618909346871078, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 380, train_loss = 14.615939191542566, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 381, train_loss = 14.608543093316257, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 382, train_loss = 14.60198409575969, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 383, train_loss = 14.597024778835475, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 384, train_loss = 14.590599455870688, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 385, train_loss = 14.585835486650467, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 386, train_loss = 14.578625038266182, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 387, train_loss = 14.571271914057434, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 388, train_loss = 14.567823621444404, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 389, train_loss = 14.562089256942272, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 390, train_loss = 14.559261947870255, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 391, train_loss = 14.550240728072822, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 392, train_loss = 14.545678001828492, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 393, train_loss = 14.542092844843864, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 394, train_loss = 14.53510557860136, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 395, train_loss = 14.532994727604091, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 396, train_loss = 14.522231723181903, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 397, train_loss = 14.519517528824508, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 398, train_loss = 14.51182931382209, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 399, train_loss = 14.50904546212405, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 400, train_loss = 14.505410593934357, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 401, train_loss = 14.498830544762313, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 402, train_loss = 14.491281020455062, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 403, train_loss = 14.487811925821006, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 404, train_loss = 14.480214265175164, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 405, train_loss = 14.476896479725838, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 406, train_loss = 14.474747668020427, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 407, train_loss = 14.462834467180073, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 408, train_loss = 14.464333482086658, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 409, train_loss = 14.457223385572433, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 410, train_loss = 14.451885685324669, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 411, train_loss = 14.450340576469898, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 412, train_loss = 14.440760587342083, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 413, train_loss = 14.437113876454532, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 414, train_loss = 14.431703455746174, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 415, train_loss = 14.425433047115803, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 416, train_loss = 14.420497514307499, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 417, train_loss = 14.416218298487365, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 418, train_loss = 14.41041665058583, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 419, train_loss = 14.406389601528645, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 420, train_loss = 14.40426332782954, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 421, train_loss = 14.395628894679248, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 422, train_loss = 14.394438304007053, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 423, train_loss = 14.387445564381778, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 424, train_loss = 14.385857529938221, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 425, train_loss = 14.38203997630626, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 426, train_loss = 14.375038872472942, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 427, train_loss = 14.366593144834042, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 428, train_loss = 14.363097335211933, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 429, train_loss = 14.364398467354476, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 430, train_loss = 14.356029083020985, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 431, train_loss = 14.34941702336073, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 432, train_loss = 14.346024026162922, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 433, train_loss = 14.343734447844326, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 434, train_loss = 14.33299046754837, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 435, train_loss = 14.333166030235589, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 436, train_loss = 14.330172565765679, train_acc = 0.9690265486725663\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 437, train_loss = 14.322233855724335, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 438, train_loss = 14.319052425213158, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 439, train_loss = 14.313114265911281, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 440, train_loss = 14.302563458681107, train_acc = 0.9692594317652539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 441, train_loss = 14.29953183233738, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 442, train_loss = 14.300118598155677, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 443, train_loss = 14.29622308164835, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 444, train_loss = 14.291083787567914, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 445, train_loss = 14.285791437141597, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 446, train_loss = 14.282711084000766, train_acc = 0.9692594317652539\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 447, train_loss = 14.272465710528195, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 448, train_loss = 14.273824592120945, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 449, train_loss = 14.2671126909554, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 450, train_loss = 14.264139321632683, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 451, train_loss = 14.255046066828072, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 452, train_loss = 14.248363703489304, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 453, train_loss = 14.24835765734315, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 454, train_loss = 14.245677554048598, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 455, train_loss = 14.241860651411116, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 456, train_loss = 14.240864128805697, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 457, train_loss = 14.235628365539014, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 458, train_loss = 14.226731625385582, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 459, train_loss = 14.22131393570453, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 460, train_loss = 14.217618412338197, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 461, train_loss = 14.214223840273917, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 462, train_loss = 14.212764519266784, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 463, train_loss = 14.20795863494277, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 464, train_loss = 14.201160163618624, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 465, train_loss = 14.195586423389614, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 466, train_loss = 14.194457195699215, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 467, train_loss = 14.192060343921185, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 468, train_loss = 14.184128225781024, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 469, train_loss = 14.18526119273156, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 470, train_loss = 14.179249682463706, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 471, train_loss = 14.171027135103941, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 472, train_loss = 14.168985646218061, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 473, train_loss = 14.159208431839943, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 474, train_loss = 14.158918996341527, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 475, train_loss = 14.156099383719265, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 476, train_loss = 14.152361303567886, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 477, train_loss = 14.147097458131611, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 478, train_loss = 14.141576937399805, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 479, train_loss = 14.138808597810566, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 480, train_loss = 14.131701201200485, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 481, train_loss = 14.124368046410382, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 482, train_loss = 14.12542741280049, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 483, train_loss = 14.122040703892708, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 484, train_loss = 14.123182659037411, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 485, train_loss = 14.11311602871865, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 486, train_loss = 14.109031323343515, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 487, train_loss = 14.104461520910263, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 488, train_loss = 14.098585044033825, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 489, train_loss = 14.094042460434139, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 490, train_loss = 14.094260789453983, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 491, train_loss = 14.08685489743948, train_acc = 0.9693758733115976\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 492, train_loss = 14.081084134522825, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "17th- epoch: 493, train_loss = 14.081786451395601, train_acc = 0.9694923148579413\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 494, train_loss = 14.074835042469203, train_acc = 0.9694923148579413\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 495, train_loss = 14.072338484227657, train_acc = 0.9694923148579413\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 496, train_loss = 14.065583015792072, train_acc = 0.9694923148579413\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 497, train_loss = 14.063081863336265, train_acc = 0.9694923148579413\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 498, train_loss = 14.058128450997174, train_acc = 0.9694923148579413\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 499, train_loss = 14.060326573438942, train_acc = 0.9694923148579413\n",
      "test Acc 0.9497206703910615:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████▋                              | 17/30 [2:33:56<1:57:32, 542.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "18th- epoch: 0, train_loss = 126.22205558419228, train_acc = 0.746506753609688\n",
      "test Acc 0.8580074487895717:\n",
      "18th- epoch: 1, train_loss = 57.62270247936249, train_acc = 0.875873311597578\n",
      "test Acc 0.8957169459962756:\n",
      "18th- epoch: 2, train_loss = 48.54898066818714, train_acc = 0.8949697251979506\n",
      "test Acc 0.9059590316573557:\n",
      "18th- epoch: 3, train_loss = 43.68787541985512, train_acc = 0.9038192827200745\n",
      "test Acc 0.9115456238361266:\n",
      "18th- epoch: 4, train_loss = 40.45688892155886, train_acc = 0.9116208663251048\n",
      "test Acc 0.914804469273743:\n",
      "18th- epoch: 5, train_loss = 38.06871249526739, train_acc = 0.9174429436422916\n",
      "test Acc 0.9185288640595903:\n",
      "18th- epoch: 6, train_loss = 36.23591507226229, train_acc = 0.9215183977643223\n",
      "test Acc 0.9222532588454376:\n",
      "18th- epoch: 7, train_loss = 34.83482887595892, train_acc = 0.9243129948765719\n",
      "test Acc 0.9222532588454376:\n",
      "18th- epoch: 8, train_loss = 33.61230234056711, train_acc = 0.9269911504424779\n",
      "test Acc 0.9236499068901304:\n",
      "18th- epoch: 9, train_loss = 32.59137609601021, train_acc = 0.9287377736376339\n",
      "test Acc 0.925512104283054:\n",
      "18th- epoch: 10, train_loss = 31.740254528820515, train_acc = 0.930018630647415\n",
      "test Acc 0.9264432029795159:\n",
      "18th- epoch: 11, train_loss = 30.977114111185074, train_acc = 0.9311830461108523\n",
      "test Acc 0.9269087523277467:\n",
      "18th- epoch: 12, train_loss = 30.318318113684654, train_acc = 0.9326967862133209\n",
      "test Acc 0.9278398510242085:\n",
      "18th- epoch: 13, train_loss = 29.652553014457226, train_acc = 0.9356078248719143\n",
      "test Acc 0.9278398510242085:\n",
      "18th- epoch: 14, train_loss = 29.107407562434673, train_acc = 0.9365393572426641\n",
      "test Acc 0.9292364990689013:\n",
      "18th- epoch: 15, train_loss = 28.58520171791315, train_acc = 0.9378202142524453\n",
      "test Acc 0.9292364990689013:\n",
      "18th- epoch: 16, train_loss = 28.105182740837336, train_acc = 0.9400326036329762\n",
      "test Acc 0.9292364990689013:\n",
      "18th- epoch: 17, train_loss = 27.698615711182356, train_acc = 0.9409641360037261\n",
      "test Acc 0.9301675977653632:\n",
      "18th- epoch: 18, train_loss = 27.278125293552876, train_acc = 0.9417792268281323\n",
      "test Acc 0.931098696461825:\n",
      "18th- epoch: 19, train_loss = 26.896140553057194, train_acc = 0.9422449930135072\n",
      "test Acc 0.9320297951582868:\n",
      "18th- epoch: 20, train_loss = 26.543494824320078, train_acc = 0.9430600838379134\n",
      "test Acc 0.9320297951582868:\n",
      "18th- epoch: 21, train_loss = 26.16847911477089, train_acc = 0.9432929669306008\n",
      "test Acc 0.9324953445065177:\n",
      "18th- epoch: 22, train_loss = 25.87535848468542, train_acc = 0.9437587331159758\n",
      "test Acc 0.9324953445065177:\n",
      "18th- epoch: 23, train_loss = 25.59575666487217, train_acc = 0.944108057755007\n",
      "test Acc 0.9329608938547486:\n",
      "18th- epoch: 24, train_loss = 25.327069953083992, train_acc = 0.9443409408476945\n",
      "test Acc 0.9324953445065177:\n",
      "18th- epoch: 25, train_loss = 25.08026910200715, train_acc = 0.9455053563111319\n",
      "test Acc 0.9338919925512105:\n",
      "18th- epoch: 26, train_loss = 24.834457837045193, train_acc = 0.946320447135538\n",
      "test Acc 0.9343575418994413:\n",
      "18th- epoch: 27, train_loss = 24.61869128793478, train_acc = 0.9466697717745691\n",
      "test Acc 0.9348230912476723:\n",
      "18th- epoch: 28, train_loss = 24.372123297303915, train_acc = 0.9473684210526315\n",
      "test Acc 0.9343575418994413:\n",
      "18th- epoch: 29, train_loss = 24.180769611150026, train_acc = 0.9476013041453191\n",
      "test Acc 0.9343575418994413:\n",
      "18th- epoch: 30, train_loss = 23.972629979252815, train_acc = 0.9481835118770378\n",
      "test Acc 0.9343575418994413:\n",
      "18th- epoch: 31, train_loss = 23.798270870000124, train_acc = 0.9486492780624126\n",
      "test Acc 0.9357541899441341:\n",
      "18th- epoch: 32, train_loss = 23.604526735842228, train_acc = 0.9486492780624126\n",
      "test Acc 0.9357541899441341:\n",
      "18th- epoch: 33, train_loss = 23.41682206839323, train_acc = 0.9491150442477876\n",
      "test Acc 0.9366852886405959:\n",
      "18th- epoch: 34, train_loss = 23.260401021689177, train_acc = 0.9493479273404751\n",
      "test Acc 0.9366852886405959:\n",
      "18th- epoch: 35, train_loss = 23.088747147470713, train_acc = 0.9494643688868188\n",
      "test Acc 0.9371508379888268:\n",
      "18th- epoch: 36, train_loss = 22.90297269821167, train_acc = 0.9496972519795063\n",
      "test Acc 0.9371508379888268:\n",
      "18th- epoch: 37, train_loss = 22.770092453807592, train_acc = 0.9501630181648812\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 38, train_loss = 22.63538385182619, train_acc = 0.9508616674429436\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 39, train_loss = 22.50969610363245, train_acc = 0.9509781089892874\n",
      "test Acc 0.9380819366852886:\n",
      "18th- epoch: 40, train_loss = 22.358523055911064, train_acc = 0.951560316721006\n",
      "test Acc 0.9385474860335196:\n",
      "18th- epoch: 41, train_loss = 22.231009293347597, train_acc = 0.9517931998136935\n",
      "test Acc 0.9385474860335196:\n",
      "18th- epoch: 42, train_loss = 22.11312348768115, train_acc = 0.9522589659990685\n",
      "test Acc 0.9380819366852886:\n",
      "18th- epoch: 43, train_loss = 22.00032141059637, train_acc = 0.9523754075454122\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 44, train_loss = 21.888660974800587, train_acc = 0.9527247321844434\n",
      "test Acc 0.9380819366852886:\n",
      "18th- epoch: 45, train_loss = 21.767160702496767, train_acc = 0.9526082906380997\n",
      "test Acc 0.9380819366852886:\n",
      "18th- epoch: 46, train_loss = 21.655315432697535, train_acc = 0.9530740568234746\n",
      "test Acc 0.9380819366852886:\n",
      "18th- epoch: 47, train_loss = 21.5575882345438, train_acc = 0.9531904983698184\n",
      "test Acc 0.9380819366852886:\n",
      "18th- epoch: 48, train_loss = 21.447482515126467, train_acc = 0.9535398230088495\n",
      "test Acc 0.9385474860335196:\n",
      "18th- epoch: 49, train_loss = 21.344270180910826, train_acc = 0.9535398230088495\n",
      "test Acc 0.9399441340782123:\n",
      "18th- epoch: 50, train_loss = 21.253016866743565, train_acc = 0.9537727061015371\n",
      "test Acc 0.9399441340782123:\n",
      "18th- epoch: 51, train_loss = 21.15721472352743, train_acc = 0.9541220307405682\n",
      "test Acc 0.9394785847299814:\n",
      "18th- epoch: 52, train_loss = 21.056877825409174, train_acc = 0.9543549138332557\n",
      "test Acc 0.9404096834264432:\n",
      "18th- epoch: 53, train_loss = 20.952438194304705, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "18th- epoch: 54, train_loss = 20.87707059457898, train_acc = 0.9545877969259432\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 55, train_loss = 20.784747771918774, train_acc = 0.9549371215649743\n",
      "test Acc 0.9413407821229051:\n",
      "18th- epoch: 56, train_loss = 20.720621664077044, train_acc = 0.9550535631113182\n",
      "test Acc 0.9422718808193669:\n",
      "18th- epoch: 57, train_loss = 20.64650372043252, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "18th- epoch: 58, train_loss = 20.544945523142815, train_acc = 0.9552864462040056\n",
      "test Acc 0.9422718808193669:\n",
      "18th- epoch: 59, train_loss = 20.46419020369649, train_acc = 0.9554028877503493\n",
      "test Acc 0.9422718808193669:\n",
      "18th- epoch: 60, train_loss = 20.38277431949973, train_acc = 0.955519329296693\n",
      "test Acc 0.9422718808193669:\n",
      "18th- epoch: 61, train_loss = 20.306401282548904, train_acc = 0.955519329296693\n",
      "test Acc 0.9422718808193669:\n",
      "18th- epoch: 62, train_loss = 20.237137012183666, train_acc = 0.9558686539357243\n",
      "test Acc 0.9422718808193669:\n",
      "18th- epoch: 63, train_loss = 20.17616056650877, train_acc = 0.955985095482068\n",
      "test Acc 0.9422718808193669:\n",
      "18th- epoch: 64, train_loss = 20.095412641763687, train_acc = 0.9562179785747554\n",
      "test Acc 0.9422718808193669:\n",
      "18th- epoch: 65, train_loss = 20.036132909357548, train_acc = 0.956450861667443\n",
      "test Acc 0.9422718808193669:\n",
      "18th- epoch: 66, train_loss = 19.96988971158862, train_acc = 0.956450861667443\n",
      "test Acc 0.9432029795158287:\n",
      "18th- epoch: 67, train_loss = 19.916130110621452, train_acc = 0.9563344201210993\n",
      "test Acc 0.9436685288640596:\n",
      "18th- epoch: 68, train_loss = 19.84526995755732, train_acc = 0.956450861667443\n",
      "test Acc 0.9436685288640596:\n",
      "18th- epoch: 69, train_loss = 19.779836932197213, train_acc = 0.9565673032137867\n",
      "test Acc 0.9436685288640596:\n",
      "18th- epoch: 70, train_loss = 19.715660974383354, train_acc = 0.9565673032137867\n",
      "test Acc 0.9436685288640596:\n",
      "18th- epoch: 71, train_loss = 19.670988019555807, train_acc = 0.9565673032137867\n",
      "test Acc 0.9441340782122905:\n",
      "18th- epoch: 72, train_loss = 19.603390848264098, train_acc = 0.9565673032137867\n",
      "test Acc 0.9441340782122905:\n",
      "18th- epoch: 73, train_loss = 19.54337104782462, train_acc = 0.9565673032137867\n",
      "test Acc 0.9441340782122905:\n",
      "18th- epoch: 74, train_loss = 19.49749638698995, train_acc = 0.9565673032137867\n",
      "test Acc 0.9441340782122905:\n",
      "18th- epoch: 75, train_loss = 19.446910483762622, train_acc = 0.9566837447601304\n",
      "test Acc 0.9441340782122905:\n",
      "18th- epoch: 76, train_loss = 19.40310795791447, train_acc = 0.9566837447601304\n",
      "test Acc 0.9436685288640596:\n",
      "18th- epoch: 77, train_loss = 19.33418409898877, train_acc = 0.9566837447601304\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 78, train_loss = 19.269335098564625, train_acc = 0.9568001863064741\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 79, train_loss = 19.214665764942765, train_acc = 0.9568001863064741\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 80, train_loss = 19.16558758355677, train_acc = 0.9569166278528178\n",
      "test Acc 0.9436685288640596:\n",
      "18th- epoch: 81, train_loss = 19.135805604979396, train_acc = 0.9572659524918491\n",
      "test Acc 0.9441340782122905:\n",
      "18th- epoch: 82, train_loss = 19.06993922404945, train_acc = 0.9573823940381928\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 83, train_loss = 19.02673700079322, train_acc = 0.9576152771308803\n",
      "test Acc 0.9441340782122905:\n",
      "18th- epoch: 84, train_loss = 18.979718754068017, train_acc = 0.9576152771308803\n",
      "test Acc 0.9441340782122905:\n",
      "18th- epoch: 85, train_loss = 18.921588476747274, train_acc = 0.9577317186772241\n",
      "test Acc 0.9441340782122905:\n",
      "18th- epoch: 86, train_loss = 18.88704778254032, train_acc = 0.9578481602235678\n",
      "test Acc 0.9441340782122905:\n",
      "18th- epoch: 87, train_loss = 18.841180423274636, train_acc = 0.9578481602235678\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 88, train_loss = 18.799500979483128, train_acc = 0.9583139264089428\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 89, train_loss = 18.749011293053627, train_acc = 0.9583139264089428\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 90, train_loss = 18.696937285363674, train_acc = 0.9583139264089428\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 91, train_loss = 18.64584676362574, train_acc = 0.9587796925943176\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 92, train_loss = 18.627827133983374, train_acc = 0.9588961341406614\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 93, train_loss = 18.592665689066052, train_acc = 0.9588961341406614\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 94, train_loss = 18.54061871021986, train_acc = 0.9587796925943176\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 95, train_loss = 18.506294621154666, train_acc = 0.9588961341406614\n",
      "test Acc 0.9445996275605214:\n",
      "18th- epoch: 96, train_loss = 18.462970659136772, train_acc = 0.9591290172333489\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 97, train_loss = 18.424582842737436, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 98, train_loss = 18.379562536254525, train_acc = 0.95947834187238\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 99, train_loss = 18.347534557804465, train_acc = 0.95947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 100, train_loss = 18.311194013804197, train_acc = 0.9595947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 101, train_loss = 18.261634334921837, train_acc = 0.9595947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 102, train_loss = 18.21311050467193, train_acc = 0.9595947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 103, train_loss = 18.206869326531887, train_acc = 0.9595947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 104, train_loss = 18.161959391087294, train_acc = 0.9595947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 105, train_loss = 18.11646985821426, train_acc = 0.9598276665114113\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 106, train_loss = 18.072767643257976, train_acc = 0.9600605496040987\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 107, train_loss = 18.062377693131566, train_acc = 0.9601769911504425\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 108, train_loss = 18.02156437933445, train_acc = 0.9600605496040987\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 109, train_loss = 17.975733743980527, train_acc = 0.9601769911504425\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 110, train_loss = 17.9461769182235, train_acc = 0.9602934326967862\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 111, train_loss = 17.914150346070528, train_acc = 0.9605263157894737\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 112, train_loss = 17.8904074896127, train_acc = 0.9605263157894737\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 113, train_loss = 17.853315833956003, train_acc = 0.9607591988821611\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 114, train_loss = 17.823134453967214, train_acc = 0.9608756404285049\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 115, train_loss = 17.79275614209473, train_acc = 0.9607591988821611\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 116, train_loss = 17.762677451595664, train_acc = 0.9608756404285049\n",
      "test Acc 0.9450651769087524:\n",
      "18th- epoch: 117, train_loss = 17.726380510255694, train_acc = 0.9612249650675361\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 118, train_loss = 17.709234170615673, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 119, train_loss = 17.68464614637196, train_acc = 0.9614578481602236\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 120, train_loss = 17.646117735654116, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 121, train_loss = 17.616590412333608, train_acc = 0.961690731252911\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 122, train_loss = 17.581011785194278, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 123, train_loss = 17.561227267608047, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 124, train_loss = 17.538577534258366, train_acc = 0.961690731252911\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 125, train_loss = 17.50146723538637, train_acc = 0.9620400558919422\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 126, train_loss = 17.480911679565907, train_acc = 0.9615742897065673\n",
      "test Acc 0.9459962756052142:\n",
      "18th- epoch: 127, train_loss = 17.461792079731822, train_acc = 0.961690731252911\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 128, train_loss = 17.435696436092257, train_acc = 0.9619236143455985\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 129, train_loss = 17.401659578084946, train_acc = 0.9620400558919422\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 130, train_loss = 17.376431422308087, train_acc = 0.9619236143455985\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 131, train_loss = 17.34859211742878, train_acc = 0.9619236143455985\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 132, train_loss = 17.32614648528397, train_acc = 0.9623893805309734\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 133, train_loss = 17.304561538621783, train_acc = 0.962156497438286\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 134, train_loss = 17.289447620511055, train_acc = 0.9622729389846297\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 135, train_loss = 17.25893226824701, train_acc = 0.9622729389846297\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 136, train_loss = 17.231488337740302, train_acc = 0.9623893805309734\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 137, train_loss = 17.21395074389875, train_acc = 0.9622729389846297\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 138, train_loss = 17.177031526342034, train_acc = 0.9625058220773172\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 139, train_loss = 17.171613804996014, train_acc = 0.9626222636236609\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 140, train_loss = 17.138154292479157, train_acc = 0.9623893805309734\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 141, train_loss = 17.10762873850763, train_acc = 0.9625058220773172\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 142, train_loss = 17.100871983915567, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 143, train_loss = 17.076118184253573, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 144, train_loss = 17.042338958010077, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 145, train_loss = 17.015915313735604, train_acc = 0.9626222636236609\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 146, train_loss = 17.005121832713485, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 147, train_loss = 16.98474551178515, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 148, train_loss = 16.95886513032019, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 149, train_loss = 16.930529575794935, train_acc = 0.9628551467163484\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 150, train_loss = 16.90895688906312, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 151, train_loss = 16.88355179876089, train_acc = 0.9629715882626921\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 152, train_loss = 16.859851328656077, train_acc = 0.9629715882626921\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 153, train_loss = 16.84830735437572, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 154, train_loss = 16.82964358665049, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 155, train_loss = 16.798249930143356, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 156, train_loss = 16.789555121213198, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 157, train_loss = 16.767835658043623, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 158, train_loss = 16.750365177169442, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 159, train_loss = 16.731058217585087, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 160, train_loss = 16.711846444755793, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 161, train_loss = 16.69061561487615, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 162, train_loss = 16.66986956074834, train_acc = 0.9630880298090359\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 163, train_loss = 16.653089435771108, train_acc = 0.9629715882626921\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 164, train_loss = 16.63626073114574, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 165, train_loss = 16.625765508040786, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 166, train_loss = 16.59850112348795, train_acc = 0.9630880298090359\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 167, train_loss = 16.573211008682847, train_acc = 0.9633209129017233\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 168, train_loss = 16.562316784635186, train_acc = 0.9630880298090359\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 169, train_loss = 16.548257414251566, train_acc = 0.9633209129017233\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 170, train_loss = 16.53898242302239, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 171, train_loss = 16.502153223380446, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 172, train_loss = 16.493736689910293, train_acc = 0.9635537959944108\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 173, train_loss = 16.481988226994872, train_acc = 0.9635537959944108\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 174, train_loss = 16.456601390615106, train_acc = 0.9636702375407545\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 175, train_loss = 16.452959099784493, train_acc = 0.9634373544480671\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 176, train_loss = 16.42075859941542, train_acc = 0.9636702375407545\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 177, train_loss = 16.409348610788584, train_acc = 0.9634373544480671\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 178, train_loss = 16.380100823938847, train_acc = 0.9636702375407545\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 179, train_loss = 16.370133250951767, train_acc = 0.9636702375407545\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 180, train_loss = 16.363064289093018, train_acc = 0.963903120633442\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 181, train_loss = 16.33541263267398, train_acc = 0.9637866790870983\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 182, train_loss = 16.33434727974236, train_acc = 0.9637866790870983\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 183, train_loss = 16.31709454767406, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 184, train_loss = 16.296834841370583, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 185, train_loss = 16.281883044168353, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 186, train_loss = 16.267792655155063, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 187, train_loss = 16.24753071926534, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 188, train_loss = 16.23103915527463, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 189, train_loss = 16.209420444443822, train_acc = 0.9643688868188169\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 190, train_loss = 16.198235308751464, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 191, train_loss = 16.213053660467267, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 192, train_loss = 16.17474819533527, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 193, train_loss = 16.156673271209, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 194, train_loss = 16.14335817657411, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 195, train_loss = 16.13018869049847, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 196, train_loss = 16.1055816616863, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 197, train_loss = 16.11043298151344, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 198, train_loss = 16.099420113489032, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 199, train_loss = 16.07677953131497, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 200, train_loss = 16.063331497833133, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 201, train_loss = 16.036053270101547, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 202, train_loss = 16.023376351222396, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 203, train_loss = 16.010414024814963, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 204, train_loss = 16.00139476917684, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 205, train_loss = 15.983490558341146, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 206, train_loss = 15.96511041931808, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 207, train_loss = 15.974522212520242, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 208, train_loss = 15.948160357773304, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 209, train_loss = 15.935811995528638, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 210, train_loss = 15.915946999564767, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 211, train_loss = 15.901336296461523, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 212, train_loss = 15.891573526896536, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 213, train_loss = 15.89715581573546, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 214, train_loss = 15.862521412782371, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 215, train_loss = 15.853932264260948, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 216, train_loss = 15.830116068013012, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 217, train_loss = 15.822838281281292, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 218, train_loss = 15.8064881330356, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 219, train_loss = 15.791554891504347, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 220, train_loss = 15.787085925228894, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 221, train_loss = 15.778948546387255, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 222, train_loss = 15.762472294270992, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 223, train_loss = 15.745645181275904, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 224, train_loss = 15.737217237241566, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 225, train_loss = 15.728067413903773, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 226, train_loss = 15.714805032126606, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 227, train_loss = 15.709681036882102, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 228, train_loss = 15.685906738042831, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 229, train_loss = 15.67743780463934, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 230, train_loss = 15.659471490420401, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 231, train_loss = 15.656004727818072, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 232, train_loss = 15.626159120351076, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 233, train_loss = 15.625854113139212, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 234, train_loss = 15.61117609590292, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 235, train_loss = 15.60534403566271, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 236, train_loss = 15.593699621967971, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 237, train_loss = 15.585888956673443, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 238, train_loss = 15.57395751774311, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 239, train_loss = 15.555184341035783, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 240, train_loss = 15.571398654021323, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 241, train_loss = 15.54162197932601, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 242, train_loss = 15.523810558952391, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 243, train_loss = 15.50335652846843, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 244, train_loss = 15.513420902192593, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 245, train_loss = 15.490280442871153, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 246, train_loss = 15.478787709958851, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 247, train_loss = 15.473480585031211, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 248, train_loss = 15.465606953017414, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 249, train_loss = 15.460107799619436, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 250, train_loss = 15.454783949069679, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 251, train_loss = 15.428997156210244, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 252, train_loss = 15.417005223222077, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 253, train_loss = 15.420726847834885, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 254, train_loss = 15.399490001611412, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 255, train_loss = 15.389372588135302, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 256, train_loss = 15.373157343827188, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 257, train_loss = 15.374106490053236, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 258, train_loss = 15.35401301458478, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 259, train_loss = 15.356125240214169, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 260, train_loss = 15.333218858577311, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 261, train_loss = 15.32811580132693, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 262, train_loss = 15.32223626319319, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 263, train_loss = 15.311669304966927, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 264, train_loss = 15.309387822635472, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 265, train_loss = 15.297741804271936, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 266, train_loss = 15.27373616117984, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 267, train_loss = 15.274355746805668, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 268, train_loss = 15.249560362659395, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 269, train_loss = 15.274489142931998, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 270, train_loss = 15.245075068436563, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 271, train_loss = 15.244267348200083, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 272, train_loss = 15.2323042973876, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 273, train_loss = 15.215029614977539, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 274, train_loss = 15.207230632193387, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 275, train_loss = 15.197466395795345, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 276, train_loss = 15.192994967103004, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 277, train_loss = 15.18405647482723, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 278, train_loss = 15.16729662194848, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 279, train_loss = 15.15847394336015, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 280, train_loss = 15.158776330761611, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 281, train_loss = 15.136471881531179, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 282, train_loss = 15.137178841978312, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 283, train_loss = 15.117100371979177, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 284, train_loss = 15.127090913243592, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 285, train_loss = 15.102360613644123, train_acc = 0.9662319515603167\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 286, train_loss = 15.117568275891244, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 287, train_loss = 15.084948692470789, train_acc = 0.9662319515603167\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 288, train_loss = 15.072518040426075, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 289, train_loss = 15.074195795692503, train_acc = 0.9662319515603167\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 290, train_loss = 15.069232466630638, train_acc = 0.9662319515603167\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 291, train_loss = 15.051846771501005, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 292, train_loss = 15.06084656342864, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 293, train_loss = 15.044670478440821, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 294, train_loss = 15.03825334366411, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 295, train_loss = 15.023275207728148, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 296, train_loss = 15.0091054700315, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 297, train_loss = 15.019738052040339, train_acc = 0.9662319515603167\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 298, train_loss = 15.000595617108047, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 299, train_loss = 14.989837699569762, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 300, train_loss = 14.98551105428487, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 301, train_loss = 14.974606181494892, train_acc = 0.9669306008383791\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 302, train_loss = 14.96180157456547, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 303, train_loss = 14.965433957986534, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 304, train_loss = 14.949160483665764, train_acc = 0.9663483931066604\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 305, train_loss = 14.953428995795548, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 306, train_loss = 14.93463911768049, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 307, train_loss = 14.935330077074468, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 308, train_loss = 14.920209298841655, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 309, train_loss = 14.91814811900258, train_acc = 0.9670470423847228\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 310, train_loss = 14.905760486610234, train_acc = 0.9668141592920354\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 311, train_loss = 14.902006302028894, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 312, train_loss = 14.892697747796774, train_acc = 0.9669306008383791\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 313, train_loss = 14.882834191434085, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 314, train_loss = 14.877200410701334, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 315, train_loss = 14.886182415299118, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 316, train_loss = 14.871241554617882, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 317, train_loss = 14.857934636063874, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 318, train_loss = 14.862657497636974, train_acc = 0.9670470423847228\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 319, train_loss = 14.84629013389349, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 320, train_loss = 14.841677777469158, train_acc = 0.9671634839310667\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 321, train_loss = 14.825770455412567, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 322, train_loss = 14.82055037934333, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 323, train_loss = 14.800884450785816, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 324, train_loss = 14.80121464561671, train_acc = 0.9671634839310667\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 325, train_loss = 14.799802504479885, train_acc = 0.9671634839310667\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 326, train_loss = 14.776940389536321, train_acc = 0.9672799254774104\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 327, train_loss = 14.777407176792622, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 328, train_loss = 14.774051525630057, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 329, train_loss = 14.777598817832768, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 330, train_loss = 14.768161982297897, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 331, train_loss = 14.748508959077299, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 332, train_loss = 14.742418040521443, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 333, train_loss = 14.746354069560766, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 334, train_loss = 14.736158266663551, train_acc = 0.9672799254774104\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 335, train_loss = 14.724751562811434, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 336, train_loss = 14.7201689472422, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 337, train_loss = 14.71195675432682, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 338, train_loss = 14.707890585064888, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 339, train_loss = 14.69132949411869, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 340, train_loss = 14.694865860044956, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 341, train_loss = 14.678513281978667, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 342, train_loss = 14.68364064116031, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 343, train_loss = 14.678881424479187, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 344, train_loss = 14.6612887121737, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 345, train_loss = 14.658630213700235, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 346, train_loss = 14.643520400859416, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 347, train_loss = 14.648872138001025, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 348, train_loss = 14.639312538318336, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 349, train_loss = 14.624808497726917, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 350, train_loss = 14.63126680161804, train_acc = 0.9672799254774104\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 351, train_loss = 14.623281328938901, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 352, train_loss = 14.603969271294773, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 353, train_loss = 14.603590444661677, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "18th- epoch: 354, train_loss = 14.595815003849566, train_acc = 0.9676292501164415\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 355, train_loss = 14.587894619442523, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 356, train_loss = 14.591362255625427, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 357, train_loss = 14.575761690735817, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 358, train_loss = 14.580215132795274, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 359, train_loss = 14.564098436385393, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 360, train_loss = 14.56578103452921, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "18th- epoch: 361, train_loss = 14.557818955741823, train_acc = 0.9676292501164415\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 362, train_loss = 14.536762746982276, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 363, train_loss = 14.54844310414046, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 364, train_loss = 14.534429871477187, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 365, train_loss = 14.529615593142807, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 366, train_loss = 14.524629469029605, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 367, train_loss = 14.507154033519328, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 368, train_loss = 14.522236223332584, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 369, train_loss = 14.505827850662172, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 370, train_loss = 14.489152145572007, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 371, train_loss = 14.487070810049772, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 372, train_loss = 14.481245293281972, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 373, train_loss = 14.48102867975831, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 374, train_loss = 14.47108695935458, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 375, train_loss = 14.475853341631591, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 376, train_loss = 14.464142045937479, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 377, train_loss = 14.451636754907668, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 378, train_loss = 14.449636068195105, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 379, train_loss = 14.4362956546247, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 380, train_loss = 14.43946849834174, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 381, train_loss = 14.433813624083996, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 382, train_loss = 14.432829053141177, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 383, train_loss = 14.418686806224287, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 384, train_loss = 14.403516707010567, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "18th- epoch: 385, train_loss = 14.417759629897773, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 386, train_loss = 14.409767560660839, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 387, train_loss = 14.400136842392385, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 388, train_loss = 14.411159377545118, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 389, train_loss = 14.406687906943262, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 390, train_loss = 14.39627590123564, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 391, train_loss = 14.39135509263724, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 392, train_loss = 14.384288377128541, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 393, train_loss = 14.382962855510414, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 394, train_loss = 14.373857940547168, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 395, train_loss = 14.369627300649881, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 396, train_loss = 14.370070858858526, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 397, train_loss = 14.356614771299064, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 398, train_loss = 14.35799748916179, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 399, train_loss = 14.356594771146774, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 400, train_loss = 14.34646177943796, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 401, train_loss = 14.343014396727085, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 402, train_loss = 14.33406212925911, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 403, train_loss = 14.327001973055303, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 404, train_loss = 14.323564768768847, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 405, train_loss = 14.313149546273053, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 406, train_loss = 14.318295341916382, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 407, train_loss = 14.319239445962012, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 408, train_loss = 14.29060535132885, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 409, train_loss = 14.303517617285252, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 410, train_loss = 14.292365286499262, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 411, train_loss = 14.283455163240433, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 412, train_loss = 14.28748403210193, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 413, train_loss = 14.275815571658313, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 414, train_loss = 14.272799489088356, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 415, train_loss = 14.255572299472988, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 416, train_loss = 14.266637798398733, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 417, train_loss = 14.248530749231577, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 418, train_loss = 14.250921758823097, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 419, train_loss = 14.250545657239854, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 420, train_loss = 14.24323137383908, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 421, train_loss = 14.232675262726843, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 422, train_loss = 14.22874978557229, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 423, train_loss = 14.230609904043376, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 424, train_loss = 14.215853224508464, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 425, train_loss = 14.214198228903115, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 426, train_loss = 14.213016626425087, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 427, train_loss = 14.19943882431835, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 428, train_loss = 14.196253512054682, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 429, train_loss = 14.210982341319323, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 430, train_loss = 14.185892167501152, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 431, train_loss = 14.187473218888044, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 432, train_loss = 14.17944668000564, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 433, train_loss = 14.178634972311556, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 434, train_loss = 14.166443879716098, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 435, train_loss = 14.16621042508632, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 436, train_loss = 14.16839525476098, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 437, train_loss = 14.153622300364077, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 438, train_loss = 14.1530103078112, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 439, train_loss = 14.153720666654408, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 440, train_loss = 14.148127841763198, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 441, train_loss = 14.13454352831468, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 442, train_loss = 14.136705715209246, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 443, train_loss = 14.126457667443901, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 444, train_loss = 14.130977562163025, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 445, train_loss = 14.12238742550835, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 446, train_loss = 14.115852528717369, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 447, train_loss = 14.101799266878515, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 448, train_loss = 14.101594539824873, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 449, train_loss = 14.103881102055311, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 450, train_loss = 14.091915171593428, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 451, train_loss = 14.079968937672675, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 452, train_loss = 14.077081870287657, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 453, train_loss = 14.076410961803049, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 454, train_loss = 14.083406093064696, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 455, train_loss = 14.065884031355381, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 456, train_loss = 14.06241251155734, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 457, train_loss = 14.051669552922249, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 458, train_loss = 14.052291354630142, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 459, train_loss = 14.03486126800999, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 460, train_loss = 14.050569206476212, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 461, train_loss = 14.046532535459846, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 462, train_loss = 14.02843215689063, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 463, train_loss = 14.03232534462586, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 464, train_loss = 14.029318694025278, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 465, train_loss = 14.0300039104186, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 466, train_loss = 14.017172762658447, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 467, train_loss = 14.01484297355637, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 468, train_loss = 14.009961144533008, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 469, train_loss = 14.002562530338764, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 470, train_loss = 14.000582333654165, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 471, train_loss = 13.994096654001623, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 472, train_loss = 13.986059783492237, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 473, train_loss = 13.988443301524967, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 474, train_loss = 13.978904807474464, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 475, train_loss = 13.976689348462969, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 476, train_loss = 13.97769020870328, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 477, train_loss = 13.972524395678192, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 478, train_loss = 13.964475434273481, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 479, train_loss = 13.963248939719051, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 480, train_loss = 13.964677952229977, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 481, train_loss = 13.961281498428434, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 482, train_loss = 13.950000958051533, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 483, train_loss = 13.940135394688696, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 484, train_loss = 13.943060075398535, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 485, train_loss = 13.935467418283224, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 486, train_loss = 13.924734567757696, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 487, train_loss = 13.92290106927976, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 488, train_loss = 13.926451791077852, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 489, train_loss = 13.924157531466335, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 490, train_loss = 13.915439408272505, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 491, train_loss = 13.908247139304876, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 492, train_loss = 13.903228975832462, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 493, train_loss = 13.912313563283533, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 494, train_loss = 13.895471351686865, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 495, train_loss = 13.901311311870813, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 496, train_loss = 13.891948444303125, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 497, train_loss = 13.895797975361347, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 498, train_loss = 13.892156725283712, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "18th- epoch: 499, train_loss = 13.884751133620739, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████                            | 18/30 [2:43:00<1:48:33, 542.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "19th- epoch: 0, train_loss = 130.95724514126778, train_acc = 0.7654867256637168\n",
      "test Acc 0.8417132216014898:\n",
      "19th- epoch: 1, train_loss = 54.34340439736843, train_acc = 0.8870517000465766\n",
      "test Acc 0.8929236499068901:\n",
      "19th- epoch: 2, train_loss = 46.20507165789604, train_acc = 0.901839776432231\n",
      "test Acc 0.904562383612663:\n",
      "19th- epoch: 3, train_loss = 41.70541572570801, train_acc = 0.9090591523055426\n",
      "test Acc 0.9124767225325885:\n",
      "19th- epoch: 4, train_loss = 38.74282340705395, train_acc = 0.9131346064275734\n",
      "test Acc 0.9175977653631285:\n",
      "19th- epoch: 5, train_loss = 36.502392411231995, train_acc = 0.918141592920354\n",
      "test Acc 0.9208566108007449:\n",
      "19th- epoch: 6, train_loss = 34.7057982981205, train_acc = 0.9223334885887284\n",
      "test Acc 0.9222532588454376:\n",
      "19th- epoch: 7, train_loss = 33.21390972286463, train_acc = 0.925593851886353\n",
      "test Acc 0.9245810055865922:\n",
      "19th- epoch: 8, train_loss = 31.987120620906353, train_acc = 0.9275733581741965\n",
      "test Acc 0.9283054003724395:\n",
      "19th- epoch: 9, train_loss = 30.952631689608097, train_acc = 0.9299021891010713\n",
      "test Acc 0.9297020484171322:\n",
      "19th- epoch: 10, train_loss = 30.05771718174219, train_acc = 0.9316488122962273\n",
      "test Acc 0.9292364990689013:\n",
      "19th- epoch: 11, train_loss = 29.266462214291096, train_acc = 0.9333954354913834\n",
      "test Acc 0.930633147113594:\n",
      "19th- epoch: 12, train_loss = 28.57964301109314, train_acc = 0.9346762925011645\n",
      "test Acc 0.9315642458100558:\n",
      "19th- epoch: 13, train_loss = 27.956749379634857, train_acc = 0.9372380065207266\n",
      "test Acc 0.931098696461825:\n",
      "19th- epoch: 14, train_loss = 27.40928216278553, train_acc = 0.9385188635305077\n",
      "test Acc 0.9315642458100558:\n",
      "19th- epoch: 15, train_loss = 26.930349491536617, train_acc = 0.9394503959012576\n",
      "test Acc 0.9329608938547486:\n",
      "19th- epoch: 16, train_loss = 26.485894545912743, train_acc = 0.941429902189101\n",
      "test Acc 0.9338919925512105:\n",
      "19th- epoch: 17, train_loss = 26.084718007594347, train_acc = 0.9424778761061947\n",
      "test Acc 0.9329608938547486:\n",
      "19th- epoch: 18, train_loss = 25.727947771549225, train_acc = 0.9434094084769445\n",
      "test Acc 0.9343575418994413:\n",
      "19th- epoch: 19, train_loss = 25.39869163930416, train_acc = 0.9448067070330693\n",
      "test Acc 0.9343575418994413:\n",
      "19th- epoch: 20, train_loss = 25.08601089194417, train_acc = 0.9446902654867256\n",
      "test Acc 0.9343575418994413:\n",
      "19th- epoch: 21, train_loss = 24.801038272678852, train_acc = 0.946320447135538\n",
      "test Acc 0.9343575418994413:\n",
      "19th- epoch: 22, train_loss = 24.518761835992336, train_acc = 0.9470190964136004\n",
      "test Acc 0.9348230912476723:\n",
      "19th- epoch: 23, train_loss = 24.285468190908432, train_acc = 0.9476013041453191\n",
      "test Acc 0.9357541899441341:\n",
      "19th- epoch: 24, train_loss = 24.019752722233534, train_acc = 0.9482999534233815\n",
      "test Acc 0.9357541899441341:\n",
      "19th- epoch: 25, train_loss = 23.799226008355618, train_acc = 0.9488821611551002\n",
      "test Acc 0.9357541899441341:\n",
      "19th- epoch: 26, train_loss = 23.589437413960695, train_acc = 0.9489986027014439\n",
      "test Acc 0.936219739292365:\n",
      "19th- epoch: 27, train_loss = 23.403556156903505, train_acc = 0.9492314857941313\n",
      "test Acc 0.9371508379888268:\n",
      "19th- epoch: 28, train_loss = 23.209022097289562, train_acc = 0.9495808104331626\n",
      "test Acc 0.9371508379888268:\n",
      "19th- epoch: 29, train_loss = 23.030159521847963, train_acc = 0.9500465766185375\n",
      "test Acc 0.9380819366852886:\n",
      "19th- epoch: 30, train_loss = 22.863737668842077, train_acc = 0.950279459711225\n",
      "test Acc 0.9380819366852886:\n",
      "19th- epoch: 31, train_loss = 22.70984312519431, train_acc = 0.9507452258965999\n",
      "test Acc 0.9385474860335196:\n",
      "19th- epoch: 32, train_loss = 22.557721104472876, train_acc = 0.9509781089892874\n",
      "test Acc 0.9380819366852886:\n",
      "19th- epoch: 33, train_loss = 22.40843666344881, train_acc = 0.9510945505356311\n",
      "test Acc 0.9380819366852886:\n",
      "19th- epoch: 34, train_loss = 22.264764931052923, train_acc = 0.9517931998136935\n",
      "test Acc 0.9385474860335196:\n",
      "19th- epoch: 35, train_loss = 22.137552466243505, train_acc = 0.9521425244527247\n",
      "test Acc 0.9385474860335196:\n",
      "19th- epoch: 36, train_loss = 22.003466434776783, train_acc = 0.9521425244527247\n",
      "test Acc 0.9385474860335196:\n",
      "19th- epoch: 37, train_loss = 21.88662426918745, train_acc = 0.9523754075454122\n",
      "test Acc 0.9385474860335196:\n",
      "19th- epoch: 38, train_loss = 21.767818305641413, train_acc = 0.9526082906380997\n",
      "test Acc 0.9385474860335196:\n",
      "19th- epoch: 39, train_loss = 21.64792551100254, train_acc = 0.9529576152771309\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 40, train_loss = 21.543585568666458, train_acc = 0.9533069399161621\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 41, train_loss = 21.443922121077776, train_acc = 0.9533069399161621\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 42, train_loss = 21.33796175196767, train_acc = 0.9531904983698184\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 43, train_loss = 21.237116627395153, train_acc = 0.9536562645551933\n",
      "test Acc 0.9394785847299814:\n",
      "19th- epoch: 44, train_loss = 21.1424269862473, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 45, train_loss = 21.053664065897465, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 46, train_loss = 20.95731870085001, train_acc = 0.9543549138332557\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 47, train_loss = 20.8712402805686, train_acc = 0.9547042384722869\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 48, train_loss = 20.77993394061923, train_acc = 0.9549371215649743\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 49, train_loss = 20.69888585433364, train_acc = 0.9550535631113182\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 50, train_loss = 20.612923119217157, train_acc = 0.955519329296693\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 51, train_loss = 20.539111018180847, train_acc = 0.9557522123893806\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 52, train_loss = 20.458410378545523, train_acc = 0.9557522123893806\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 53, train_loss = 20.385034300386906, train_acc = 0.9557522123893806\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 54, train_loss = 20.31758396886289, train_acc = 0.955985095482068\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 55, train_loss = 20.236988039687276, train_acc = 0.9562179785747554\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 56, train_loss = 20.167588217183948, train_acc = 0.9563344201210993\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 57, train_loss = 20.100829938426614, train_acc = 0.9562179785747554\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 58, train_loss = 20.049982069060206, train_acc = 0.9566837447601304\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 59, train_loss = 19.968272315338254, train_acc = 0.9565673032137867\n",
      "test Acc 0.9413407821229051:\n",
      "19th- epoch: 60, train_loss = 19.904765287414193, train_acc = 0.9569166278528178\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 61, train_loss = 19.8460213560611, train_acc = 0.9570330693991617\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 62, train_loss = 19.786610949784517, train_acc = 0.9571495109455054\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 63, train_loss = 19.72369982674718, train_acc = 0.9572659524918491\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 64, train_loss = 19.680135207250714, train_acc = 0.9573823940381928\n",
      "test Acc 0.9413407821229051:\n",
      "19th- epoch: 65, train_loss = 19.618921402841806, train_acc = 0.9572659524918491\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 66, train_loss = 19.558994518592954, train_acc = 0.9573823940381928\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 67, train_loss = 19.499571342021227, train_acc = 0.9576152771308803\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 68, train_loss = 19.456786427646875, train_acc = 0.9576152771308803\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 69, train_loss = 19.39325718395412, train_acc = 0.9576152771308803\n",
      "test Acc 0.9413407821229051:\n",
      "19th- epoch: 70, train_loss = 19.343309920281172, train_acc = 0.9577317186772241\n",
      "test Acc 0.9413407821229051:\n",
      "19th- epoch: 71, train_loss = 19.28803355805576, train_acc = 0.9579646017699115\n",
      "test Acc 0.9427374301675978:\n",
      "19th- epoch: 72, train_loss = 19.246308989822865, train_acc = 0.9580810433162552\n",
      "test Acc 0.9422718808193669:\n",
      "19th- epoch: 73, train_loss = 19.201635407283902, train_acc = 0.9580810433162552\n",
      "test Acc 0.9427374301675978:\n",
      "19th- epoch: 74, train_loss = 19.143771335482597, train_acc = 0.9580810433162552\n",
      "test Acc 0.9427374301675978:\n",
      "19th- epoch: 75, train_loss = 19.097150010988116, train_acc = 0.9580810433162552\n",
      "test Acc 0.9427374301675978:\n",
      "19th- epoch: 76, train_loss = 19.04788802936673, train_acc = 0.9584303679552865\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 77, train_loss = 19.02008361183107, train_acc = 0.9585468095016302\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 78, train_loss = 18.967797288671136, train_acc = 0.9584303679552865\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 79, train_loss = 18.90767066553235, train_acc = 0.9584303679552865\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 80, train_loss = 18.874412942677736, train_acc = 0.9586632510479739\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 81, train_loss = 18.839605011045933, train_acc = 0.9587796925943176\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 82, train_loss = 18.787279952317476, train_acc = 0.9586632510479739\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 83, train_loss = 18.746119746938348, train_acc = 0.9587796925943176\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 84, train_loss = 18.715390753000975, train_acc = 0.9591290172333489\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 85, train_loss = 18.66982884518802, train_acc = 0.9591290172333489\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 86, train_loss = 18.632584918290377, train_acc = 0.9591290172333489\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 87, train_loss = 18.600786734372377, train_acc = 0.9591290172333489\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 88, train_loss = 18.557142609730363, train_acc = 0.9592454587796926\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 89, train_loss = 18.525676185265183, train_acc = 0.9592454587796926\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 90, train_loss = 18.478678476065397, train_acc = 0.9592454587796926\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 91, train_loss = 18.446282429620624, train_acc = 0.9592454587796926\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 92, train_loss = 18.408234229311347, train_acc = 0.9592454587796926\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 93, train_loss = 18.37446033768356, train_acc = 0.9593619003260363\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 94, train_loss = 18.341408027336, train_acc = 0.95947834187238\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 95, train_loss = 18.310204854235053, train_acc = 0.9597112249650676\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 96, train_loss = 18.278546867892146, train_acc = 0.9598276665114113\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 97, train_loss = 18.24252475053072, train_acc = 0.9598276665114113\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 98, train_loss = 18.20638315938413, train_acc = 0.9600605496040987\n",
      "test Acc 0.9436685288640596:\n",
      "19th- epoch: 99, train_loss = 18.174985457211733, train_acc = 0.959944108057755\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 100, train_loss = 18.146181751042604, train_acc = 0.959944108057755\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 101, train_loss = 18.109763279557228, train_acc = 0.9600605496040987\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 102, train_loss = 18.075512582436204, train_acc = 0.9601769911504425\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 103, train_loss = 18.049300426617265, train_acc = 0.9601769911504425\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 104, train_loss = 18.01867880485952, train_acc = 0.9600605496040987\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 105, train_loss = 17.981774227693677, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 106, train_loss = 17.967485819011927, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 107, train_loss = 17.931772105395794, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 108, train_loss = 17.89838131144643, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 109, train_loss = 17.86501827649772, train_acc = 0.9601769911504425\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 110, train_loss = 17.84490865468979, train_acc = 0.9606427573358174\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 111, train_loss = 17.80756795592606, train_acc = 0.9606427573358174\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 112, train_loss = 17.786031739786267, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 113, train_loss = 17.748915795236826, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 114, train_loss = 17.727243894711137, train_acc = 0.9607591988821611\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 115, train_loss = 17.697955906391144, train_acc = 0.9606427573358174\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 116, train_loss = 17.666196877136827, train_acc = 0.9607591988821611\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 117, train_loss = 17.648675801232457, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 118, train_loss = 17.61868914589286, train_acc = 0.9608756404285049\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 119, train_loss = 17.59119082801044, train_acc = 0.9608756404285049\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 120, train_loss = 17.565018931403756, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 121, train_loss = 17.5412971470505, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 122, train_loss = 17.51839493587613, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 123, train_loss = 17.497012624517083, train_acc = 0.9611085235211924\n",
      "test Acc 0.9441340782122905:\n",
      "19th- epoch: 124, train_loss = 17.470948200672865, train_acc = 0.9612249650675361\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 125, train_loss = 17.441827500239015, train_acc = 0.9614578481602236\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 126, train_loss = 17.416225461289287, train_acc = 0.9614578481602236\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 127, train_loss = 17.395922102034092, train_acc = 0.9614578481602236\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 128, train_loss = 17.37167135812342, train_acc = 0.9614578481602236\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 129, train_loss = 17.349157193675637, train_acc = 0.9615742897065673\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 130, train_loss = 17.326117299497128, train_acc = 0.9618071727992548\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 131, train_loss = 17.300304358825088, train_acc = 0.9618071727992548\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 132, train_loss = 17.285550506785512, train_acc = 0.9618071727992548\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 133, train_loss = 17.259570194408298, train_acc = 0.9620400558919422\n",
      "test Acc 0.9445996275605214:\n",
      "19th- epoch: 134, train_loss = 17.237866880372167, train_acc = 0.962156497438286\n",
      "test Acc 0.9450651769087524:\n",
      "19th- epoch: 135, train_loss = 17.214322524145246, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "19th- epoch: 136, train_loss = 17.19927710480988, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "19th- epoch: 137, train_loss = 17.176007317379117, train_acc = 0.9623893805309734\n",
      "test Acc 0.9450651769087524:\n",
      "19th- epoch: 138, train_loss = 17.151750864461064, train_acc = 0.9623893805309734\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 139, train_loss = 17.132377864792943, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 140, train_loss = 17.115919154137373, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 141, train_loss = 17.08469427190721, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 142, train_loss = 17.072598146274686, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 143, train_loss = 17.046211004257202, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 144, train_loss = 17.032234190031886, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 145, train_loss = 17.006689386442304, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 146, train_loss = 16.98910623975098, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 147, train_loss = 16.968417463824153, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 148, train_loss = 16.957724129781127, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 149, train_loss = 16.935577923431993, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "19th- epoch: 150, train_loss = 16.911019971594214, train_acc = 0.9630880298090359\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 151, train_loss = 16.896105429157615, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 152, train_loss = 16.880163004621863, train_acc = 0.9630880298090359\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 153, train_loss = 16.859674675390124, train_acc = 0.9630880298090359\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 154, train_loss = 16.843890680000186, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 155, train_loss = 16.821816259995103, train_acc = 0.9630880298090359\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 156, train_loss = 16.808883560821414, train_acc = 0.9630880298090359\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 157, train_loss = 16.78673163242638, train_acc = 0.9630880298090359\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 158, train_loss = 16.76842433027923, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 159, train_loss = 16.7539752535522, train_acc = 0.9633209129017233\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 160, train_loss = 16.736180746927857, train_acc = 0.9633209129017233\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 161, train_loss = 16.71280469186604, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 162, train_loss = 16.700775483623147, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 163, train_loss = 16.68292312696576, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 164, train_loss = 16.664074728265405, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 165, train_loss = 16.65315456315875, train_acc = 0.9634373544480671\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 166, train_loss = 16.627810338512063, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 167, train_loss = 16.621234394609928, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 168, train_loss = 16.597520504146814, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 169, train_loss = 16.584902765229344, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 170, train_loss = 16.570274021476507, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 171, train_loss = 16.549530770629644, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 172, train_loss = 16.538019554689527, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 173, train_loss = 16.517582228407264, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 174, train_loss = 16.503120621666312, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 175, train_loss = 16.491893872618675, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 176, train_loss = 16.47482261247933, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 177, train_loss = 16.465455995872617, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 178, train_loss = 16.443712474778295, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 179, train_loss = 16.427346156910062, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 180, train_loss = 16.42272592149675, train_acc = 0.9637866790870983\n",
      "test Acc 0.946927374301676:\n",
      "19th- epoch: 181, train_loss = 16.39802415110171, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 182, train_loss = 16.383042696863413, train_acc = 0.9635537959944108\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 183, train_loss = 16.370236970484257, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 184, train_loss = 16.36016950942576, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 185, train_loss = 16.34824858047068, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 186, train_loss = 16.327294182032347, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 187, train_loss = 16.321452436968684, train_acc = 0.9636702375407545\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 188, train_loss = 16.30056140758097, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 189, train_loss = 16.289958653971553, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 190, train_loss = 16.27183943428099, train_acc = 0.9637866790870983\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 191, train_loss = 16.262891786172986, train_acc = 0.9640195621797858\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 192, train_loss = 16.247811749577522, train_acc = 0.9643688868188169\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 193, train_loss = 16.237988520413637, train_acc = 0.9643688868188169\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 194, train_loss = 16.220768151804805, train_acc = 0.9643688868188169\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 195, train_loss = 16.20720395259559, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 196, train_loss = 16.190594227984548, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 197, train_loss = 16.17867523059249, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 198, train_loss = 16.163997620344162, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 199, train_loss = 16.15276120044291, train_acc = 0.9647182114578482\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 200, train_loss = 16.14515433087945, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 201, train_loss = 16.130192505195737, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 202, train_loss = 16.11660741828382, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 203, train_loss = 16.094892032444477, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 204, train_loss = 16.09112750738859, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 205, train_loss = 16.075687743723392, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 206, train_loss = 16.06721545010805, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 207, train_loss = 16.054465955123305, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 208, train_loss = 16.03396128769964, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 209, train_loss = 16.026327276602387, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 210, train_loss = 16.01093968283385, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 211, train_loss = 16.003255985677242, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 212, train_loss = 15.989700589329004, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 213, train_loss = 15.977217412553728, train_acc = 0.9650675360968793\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 214, train_loss = 15.964831288903952, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 215, train_loss = 15.953196001239121, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 216, train_loss = 15.939958904869854, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 217, train_loss = 15.924587867222726, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 218, train_loss = 15.921620621345937, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 219, train_loss = 15.906585264019668, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 220, train_loss = 15.90144254360348, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 221, train_loss = 15.884373421780765, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 222, train_loss = 15.866037112660706, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 223, train_loss = 15.855700638145208, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 224, train_loss = 15.84687277674675, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 225, train_loss = 15.834558150731027, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 226, train_loss = 15.824254520237446, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 227, train_loss = 15.813389332033694, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 228, train_loss = 15.800681154243648, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 229, train_loss = 15.788120049983263, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 230, train_loss = 15.780263281427324, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 231, train_loss = 15.772654901258647, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 232, train_loss = 15.756362303160131, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 233, train_loss = 15.74991134274751, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 234, train_loss = 15.73924669995904, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 235, train_loss = 15.730572863481939, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 236, train_loss = 15.71453105751425, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 237, train_loss = 15.707161039113998, train_acc = 0.965649743828598\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 238, train_loss = 15.692791461013258, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 239, train_loss = 15.684361963532865, train_acc = 0.965649743828598\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 240, train_loss = 15.674260932952166, train_acc = 0.965649743828598\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 241, train_loss = 15.666553553193808, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 242, train_loss = 15.656579550355673, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "19th- epoch: 243, train_loss = 15.645029987208545, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 244, train_loss = 15.628078367561102, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 245, train_loss = 15.624501830898225, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 246, train_loss = 15.612593301571906, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 247, train_loss = 15.606357774697244, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 248, train_loss = 15.595102187246084, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 249, train_loss = 15.584272080101073, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 250, train_loss = 15.573399319313467, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 251, train_loss = 15.563987153582275, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 252, train_loss = 15.557259641587734, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 253, train_loss = 15.543747163377702, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 254, train_loss = 15.53357329312712, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 255, train_loss = 15.527508854866028, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 256, train_loss = 15.518997118808329, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 257, train_loss = 15.507549337111413, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 258, train_loss = 15.499775015749037, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 259, train_loss = 15.486351548694074, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 260, train_loss = 15.474725533276796, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 261, train_loss = 15.468302104622126, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 262, train_loss = 15.463969509117305, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 263, train_loss = 15.450961095280945, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 264, train_loss = 15.441662543453276, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 265, train_loss = 15.435236210934818, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 266, train_loss = 15.423675368539989, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 267, train_loss = 15.415649875067174, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 268, train_loss = 15.410130401141942, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 269, train_loss = 15.396543926559389, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 270, train_loss = 15.38576228171587, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 271, train_loss = 15.374838415533304, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 272, train_loss = 15.367920890450478, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 273, train_loss = 15.36231015715748, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 274, train_loss = 15.350517357699573, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 275, train_loss = 15.345319238491356, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 276, train_loss = 15.335530669428408, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 277, train_loss = 15.323687969706953, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 278, train_loss = 15.313165708445013, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 279, train_loss = 15.311482935212553, train_acc = 0.9657661853749417\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 280, train_loss = 15.302390904165804, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 281, train_loss = 15.28677771706134, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 282, train_loss = 15.283100972883403, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 283, train_loss = 15.271733552217484, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 284, train_loss = 15.267539971508086, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 285, train_loss = 15.253992795944214, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 286, train_loss = 15.249282048083842, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 287, train_loss = 15.240507633425295, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 288, train_loss = 15.233199539594352, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 289, train_loss = 15.224189821630716, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 290, train_loss = 15.218772783875465, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 291, train_loss = 15.211235634982586, train_acc = 0.9658826269212856\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 292, train_loss = 15.196221430785954, train_acc = 0.9659990684676293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 293, train_loss = 15.191284307278693, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 294, train_loss = 15.18153625819832, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 295, train_loss = 15.172568685375154, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 296, train_loss = 15.168129096738994, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 297, train_loss = 15.15981720853597, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 298, train_loss = 15.154210954904556, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 299, train_loss = 15.139248449355364, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 300, train_loss = 15.130185960792005, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 301, train_loss = 15.1230677543208, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 302, train_loss = 15.122179887257516, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 303, train_loss = 15.109570876695216, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 304, train_loss = 15.106021120212972, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 305, train_loss = 15.095328827388585, train_acc = 0.9662319515603167\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 306, train_loss = 15.08722074702382, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 307, train_loss = 15.078033388592303, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 308, train_loss = 15.073523527942598, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 309, train_loss = 15.067259562201798, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 310, train_loss = 15.059065838344395, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 311, train_loss = 15.049931235611439, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 312, train_loss = 15.040535267442465, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 313, train_loss = 15.035436276346445, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 314, train_loss = 15.021435361355543, train_acc = 0.9663483931066604\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 315, train_loss = 15.019948395900428, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 316, train_loss = 15.014965184032917, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 317, train_loss = 15.006132531911135, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 318, train_loss = 15.000084977596998, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 319, train_loss = 14.990583612583578, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 320, train_loss = 14.984661341644824, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 321, train_loss = 14.974563545547426, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 322, train_loss = 14.964786455966532, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 323, train_loss = 14.96040307264775, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 324, train_loss = 14.952840537764132, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 325, train_loss = 14.945560339838266, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 326, train_loss = 14.937331225723028, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 327, train_loss = 14.933225457556546, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 328, train_loss = 14.924647812731564, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 329, train_loss = 14.918956890702248, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 330, train_loss = 14.914677799679339, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 331, train_loss = 14.903778837062418, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 332, train_loss = 14.900984823703766, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 333, train_loss = 14.896878230385482, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 334, train_loss = 14.884691904298961, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 335, train_loss = 14.880702245980501, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 336, train_loss = 14.869731866754591, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 337, train_loss = 14.866262237541378, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 338, train_loss = 14.861032732762396, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 339, train_loss = 14.850649636238813, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 340, train_loss = 14.842262379825115, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 341, train_loss = 14.832691106945276, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 342, train_loss = 14.832037745974958, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 343, train_loss = 14.819052525795996, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 344, train_loss = 14.81588726118207, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 345, train_loss = 14.807714781723917, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 346, train_loss = 14.80239325389266, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 347, train_loss = 14.798372372984886, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 348, train_loss = 14.789863295853138, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 349, train_loss = 14.780097720213234, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 350, train_loss = 14.774612624198198, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 351, train_loss = 14.7651751851663, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 352, train_loss = 14.760748461820185, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 353, train_loss = 14.752697019837797, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 354, train_loss = 14.747520074248314, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 355, train_loss = 14.739359952509403, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 356, train_loss = 14.729735287837684, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 357, train_loss = 14.726644470356405, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 358, train_loss = 14.719679935835302, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 359, train_loss = 14.714418977499008, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 360, train_loss = 14.70417904574424, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 361, train_loss = 14.70046083535999, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 362, train_loss = 14.69557398185134, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 363, train_loss = 14.69061682652682, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 364, train_loss = 14.680264352820814, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 365, train_loss = 14.674830730073154, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 366, train_loss = 14.672497087158263, train_acc = 0.9679785747554728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 367, train_loss = 14.667027451097965, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 368, train_loss = 14.656824707053602, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 369, train_loss = 14.650346866808832, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 370, train_loss = 14.645844105631113, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 371, train_loss = 14.643723651766777, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 372, train_loss = 14.634391237981617, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 373, train_loss = 14.627238523215055, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 374, train_loss = 14.61788350623101, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 375, train_loss = 14.614925571717322, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 376, train_loss = 14.611869767308235, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 377, train_loss = 14.605533977039158, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 378, train_loss = 14.598940485157073, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 379, train_loss = 14.59395782649517, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 380, train_loss = 14.591561272740364, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 381, train_loss = 14.584366507828236, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 382, train_loss = 14.573890374042094, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 383, train_loss = 14.571844545193017, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 384, train_loss = 14.569484279491007, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 385, train_loss = 14.559004072099924, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 386, train_loss = 14.553150163032115, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 387, train_loss = 14.546756348572671, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 388, train_loss = 14.545247424393892, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 389, train_loss = 14.538350579328835, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 390, train_loss = 14.53369781281799, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 391, train_loss = 14.527992564253509, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 392, train_loss = 14.519732967019081, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 393, train_loss = 14.51698283944279, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 394, train_loss = 14.507522170431912, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 395, train_loss = 14.506875622086227, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 396, train_loss = 14.504911522381008, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 397, train_loss = 14.495511404238641, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 398, train_loss = 14.494344047270715, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 399, train_loss = 14.483014249242842, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 400, train_loss = 14.481739040464163, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 401, train_loss = 14.47325774282217, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 402, train_loss = 14.47468411643058, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 403, train_loss = 14.459447011351585, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 404, train_loss = 14.46095700096339, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 405, train_loss = 14.45353716891259, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 406, train_loss = 14.449566963128746, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 407, train_loss = 14.439751581288874, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 408, train_loss = 14.43531742785126, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 409, train_loss = 14.435264038853347, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 410, train_loss = 14.42796457838267, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 411, train_loss = 14.419586066156626, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 412, train_loss = 14.415025100111961, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "19th- epoch: 413, train_loss = 14.412919524125755, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 414, train_loss = 14.407531905919313, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 415, train_loss = 14.397520954720676, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 416, train_loss = 14.395994109101593, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 417, train_loss = 14.393590210936964, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 418, train_loss = 14.382249392569065, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 419, train_loss = 14.374899689108133, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 420, train_loss = 14.373562409542501, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 421, train_loss = 14.369959904812276, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 422, train_loss = 14.359024160541594, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 423, train_loss = 14.363308317959309, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 424, train_loss = 14.35231725499034, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 425, train_loss = 14.34918664302677, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 426, train_loss = 14.338179904036224, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 427, train_loss = 14.336305112577975, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 428, train_loss = 14.330467860214412, train_acc = 0.9689101071262226\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 429, train_loss = 14.33198472019285, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 430, train_loss = 14.31928528379649, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 431, train_loss = 14.321016379632056, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 432, train_loss = 14.309799506329, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 433, train_loss = 14.315893086604774, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 434, train_loss = 14.30473614949733, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 435, train_loss = 14.298183601349592, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 436, train_loss = 14.298177026212215, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 437, train_loss = 14.286508557386696, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 438, train_loss = 14.284077345393598, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 439, train_loss = 14.281358558684587, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 440, train_loss = 14.277663957327604, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 441, train_loss = 14.270078706555068, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 442, train_loss = 14.26268118340522, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 443, train_loss = 14.265161828137934, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 444, train_loss = 14.254843353293836, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 445, train_loss = 14.253842862788588, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 446, train_loss = 14.246082324534655, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 447, train_loss = 14.241625071968883, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 448, train_loss = 14.23623144859448, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 449, train_loss = 14.23525225231424, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 450, train_loss = 14.231245771050453, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 451, train_loss = 14.222567846532911, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 452, train_loss = 14.220962654799223, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 453, train_loss = 14.220052444841713, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 454, train_loss = 14.211594899650663, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 455, train_loss = 14.20289364317432, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 456, train_loss = 14.205565545707941, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 457, train_loss = 14.195901434868574, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 458, train_loss = 14.195204234216362, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 459, train_loss = 14.191517102066427, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 460, train_loss = 14.184908761177212, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 461, train_loss = 14.183447973337024, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 462, train_loss = 14.172769183758646, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 463, train_loss = 14.172663871198893, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 464, train_loss = 14.163753612432629, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 465, train_loss = 14.160214750561863, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 466, train_loss = 14.1571134054102, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 467, train_loss = 14.14835591847077, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 468, train_loss = 14.150618551764637, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 469, train_loss = 14.14467610931024, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 470, train_loss = 14.14168213820085, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 471, train_loss = 14.135749321430922, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 472, train_loss = 14.12698773527518, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 473, train_loss = 14.128947829362005, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 474, train_loss = 14.119971553329378, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 475, train_loss = 14.116712120827287, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 476, train_loss = 14.115282531827688, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 477, train_loss = 14.109340991824865, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 478, train_loss = 14.105630427598953, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 479, train_loss = 14.10261420533061, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 480, train_loss = 14.09550161426887, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 481, train_loss = 14.087846846785396, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 482, train_loss = 14.089560098946095, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 483, train_loss = 14.084900827612728, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 484, train_loss = 14.078425526618958, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 485, train_loss = 14.077338457107544, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 486, train_loss = 14.070342043880373, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 487, train_loss = 14.063763956073672, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 488, train_loss = 14.070229951292276, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 489, train_loss = 14.06277139345184, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 490, train_loss = 14.053728245198727, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 491, train_loss = 14.051103919744492, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 492, train_loss = 14.051189883146435, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 493, train_loss = 14.043995710555464, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 494, train_loss = 14.03857662761584, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 495, train_loss = 14.034882871899754, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "19th- epoch: 496, train_loss = 14.033536439295858, train_acc = 0.9697251979506288\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 497, train_loss = 14.028238302562386, train_acc = 0.9697251979506288\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 498, train_loss = 14.024538492318243, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 499, train_loss = 14.021244944538921, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|████████████████████████████████████████████▎                         | 19/30 [2:52:02<1:39:29, 542.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "20th- epoch: 0, train_loss = 132.30161106586456, train_acc = 0.7481369352585002\n",
      "test Acc 0.8435754189944135:\n",
      "20th- epoch: 1, train_loss = 64.00464470684528, train_acc = 0.8665579878900792\n",
      "test Acc 0.8817504655493482:\n",
      "20th- epoch: 2, train_loss = 53.64158695936203, train_acc = 0.8856544014904518\n",
      "test Acc 0.8966480446927374:\n",
      "20th- epoch: 3, train_loss = 47.89222050458193, train_acc = 0.8950861667442943\n",
      "test Acc 0.904562383612663:\n",
      "20th- epoch: 4, train_loss = 44.07895132154226, train_acc = 0.9037028411737308\n",
      "test Acc 0.9115456238361266:\n",
      "20th- epoch: 5, train_loss = 41.14436190575361, train_acc = 0.9097578015836051\n",
      "test Acc 0.9157355679702048:\n",
      "20th- epoch: 6, train_loss = 38.924615643918514, train_acc = 0.9141825803446669\n",
      "test Acc 0.9194599627560521:\n",
      "20th- epoch: 7, train_loss = 37.070274747908115, train_acc = 0.9197717745691663\n",
      "test Acc 0.9208566108007449:\n",
      "20th- epoch: 8, train_loss = 35.52646419405937, train_acc = 0.9224499301350721\n",
      "test Acc 0.9241154562383612:\n",
      "20th- epoch: 9, train_loss = 34.19973091036081, train_acc = 0.9248952026082906\n",
      "test Acc 0.9250465549348231:\n",
      "20th- epoch: 10, train_loss = 33.10184517502785, train_acc = 0.9264089427107592\n",
      "test Acc 0.9250465549348231:\n",
      "20th- epoch: 11, train_loss = 32.09869682043791, train_acc = 0.9290870982766651\n",
      "test Acc 0.9273743016759777:\n",
      "20th- epoch: 12, train_loss = 31.270984821021557, train_acc = 0.9310666045645086\n",
      "test Acc 0.9283054003724395:\n",
      "20th- epoch: 13, train_loss = 30.516561903059483, train_acc = 0.931765253842571\n",
      "test Acc 0.9283054003724395:\n",
      "20th- epoch: 14, train_loss = 29.86789671704173, train_acc = 0.9331625523986958\n",
      "test Acc 0.9297020484171322:\n",
      "20th- epoch: 15, train_loss = 29.271349500864744, train_acc = 0.935724266418258\n",
      "test Acc 0.930633147113594:\n",
      "20th- epoch: 16, train_loss = 28.728023517876863, train_acc = 0.9363064741499767\n",
      "test Acc 0.9315642458100558:\n",
      "20th- epoch: 17, train_loss = 28.219851080328226, train_acc = 0.9371215649743828\n",
      "test Acc 0.9315642458100558:\n",
      "20th- epoch: 18, train_loss = 27.75318631529808, train_acc = 0.9372380065207266\n",
      "test Acc 0.9315642458100558:\n",
      "20th- epoch: 19, train_loss = 27.3440852612257, train_acc = 0.9384024219841639\n",
      "test Acc 0.9320297951582868:\n",
      "20th- epoch: 20, train_loss = 26.96791809797287, train_acc = 0.9392175128085701\n",
      "test Acc 0.9329608938547486:\n",
      "20th- epoch: 21, train_loss = 26.578759722411633, train_acc = 0.94014904517932\n",
      "test Acc 0.9329608938547486:\n",
      "20th- epoch: 22, train_loss = 26.24390446767211, train_acc = 0.9408476944573824\n",
      "test Acc 0.9334264432029795:\n",
      "20th- epoch: 23, train_loss = 25.941848907619715, train_acc = 0.9416627852817886\n",
      "test Acc 0.9343575418994413:\n",
      "20th- epoch: 24, train_loss = 25.63856054469943, train_acc = 0.9431765253842571\n",
      "test Acc 0.9348230912476723:\n",
      "20th- epoch: 25, train_loss = 25.3617354221642, train_acc = 0.9434094084769445\n",
      "test Acc 0.9348230912476723:\n",
      "20th- epoch: 26, train_loss = 25.077538948506117, train_acc = 0.9448067070330693\n",
      "test Acc 0.9352886405959032:\n",
      "20th- epoch: 27, train_loss = 24.834633868187666, train_acc = 0.9450395901257569\n",
      "test Acc 0.9352886405959032:\n",
      "20th- epoch: 28, train_loss = 24.60624260827899, train_acc = 0.9455053563111319\n",
      "test Acc 0.9357541899441341:\n",
      "20th- epoch: 29, train_loss = 24.381893284618855, train_acc = 0.945854680950163\n",
      "test Acc 0.936219739292365:\n",
      "20th- epoch: 30, train_loss = 24.160193663090467, train_acc = 0.9462040055891943\n",
      "test Acc 0.936219739292365:\n",
      "20th- epoch: 31, train_loss = 23.963518109172583, train_acc = 0.9470190964136004\n",
      "test Acc 0.936219739292365:\n",
      "20th- epoch: 32, train_loss = 23.766790125519037, train_acc = 0.9474848625989754\n",
      "test Acc 0.9357541899441341:\n",
      "20th- epoch: 33, train_loss = 23.590344827622175, train_acc = 0.9479506287843502\n",
      "test Acc 0.936219739292365:\n",
      "20th- epoch: 34, train_loss = 23.418981961905956, train_acc = 0.9485328365160689\n",
      "test Acc 0.9357541899441341:\n",
      "20th- epoch: 35, train_loss = 23.21722261980176, train_acc = 0.9491150442477876\n",
      "test Acc 0.9366852886405959:\n",
      "20th- epoch: 36, train_loss = 23.07957559451461, train_acc = 0.9494643688868188\n",
      "test Acc 0.9366852886405959:\n",
      "20th- epoch: 37, train_loss = 22.91639957949519, train_acc = 0.94981369352585\n",
      "test Acc 0.936219739292365:\n",
      "20th- epoch: 38, train_loss = 22.753352031111717, train_acc = 0.9501630181648812\n",
      "test Acc 0.936219739292365:\n",
      "20th- epoch: 39, train_loss = 22.62431473657489, train_acc = 0.9503959012575687\n",
      "test Acc 0.9371508379888268:\n",
      "20th- epoch: 40, train_loss = 22.46308968961239, train_acc = 0.9506287843502562\n",
      "test Acc 0.9376163873370578:\n",
      "20th- epoch: 41, train_loss = 22.345797441899776, train_acc = 0.9506287843502562\n",
      "test Acc 0.9380819366852886:\n",
      "20th- epoch: 42, train_loss = 22.211296029388905, train_acc = 0.9506287843502562\n",
      "test Acc 0.9385474860335196:\n",
      "20th- epoch: 43, train_loss = 22.102577965706587, train_acc = 0.9512109920819748\n",
      "test Acc 0.9380819366852886:\n",
      "20th- epoch: 44, train_loss = 21.970488384366035, train_acc = 0.9512109920819748\n",
      "test Acc 0.9380819366852886:\n",
      "20th- epoch: 45, train_loss = 21.83394641429186, train_acc = 0.9516767582673498\n",
      "test Acc 0.9385474860335196:\n",
      "20th- epoch: 46, train_loss = 21.73423221707344, train_acc = 0.9521425244527247\n",
      "test Acc 0.9385474860335196:\n",
      "20th- epoch: 47, train_loss = 21.613304927945137, train_acc = 0.9522589659990685\n",
      "test Acc 0.9385474860335196:\n",
      "20th- epoch: 48, train_loss = 21.526190232485533, train_acc = 0.952491849091756\n",
      "test Acc 0.9390130353817505:\n",
      "20th- epoch: 49, train_loss = 21.409013357013464, train_acc = 0.9526082906380997\n",
      "test Acc 0.9390130353817505:\n",
      "20th- epoch: 50, train_loss = 21.32066063210368, train_acc = 0.9528411737307871\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 51, train_loss = 21.198970964178443, train_acc = 0.9530740568234746\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 52, train_loss = 21.111280532553792, train_acc = 0.9531904983698184\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 53, train_loss = 21.027214961126447, train_acc = 0.9538891476478808\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 54, train_loss = 20.939171010628343, train_acc = 0.9541220307405682\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 55, train_loss = 20.84635460935533, train_acc = 0.9540055891942245\n",
      "test Acc 0.9390130353817505:\n",
      "20th- epoch: 56, train_loss = 20.76673020608723, train_acc = 0.9542384722869119\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 57, train_loss = 20.68420763872564, train_acc = 0.9542384722869119\n",
      "test Acc 0.9399441340782123:\n",
      "20th- epoch: 58, train_loss = 20.606436954811215, train_acc = 0.9542384722869119\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 59, train_loss = 20.512303424999118, train_acc = 0.9544713553795995\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 60, train_loss = 20.438034219667315, train_acc = 0.9548206800186306\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 61, train_loss = 20.356555292382836, train_acc = 0.9549371215649743\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 62, train_loss = 20.280297489836812, train_acc = 0.955985095482068\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 63, train_loss = 20.20766713283956, train_acc = 0.9562179785747554\n",
      "test Acc 0.9399441340782123:\n",
      "20th- epoch: 64, train_loss = 20.146909104660153, train_acc = 0.9557522123893806\n",
      "test Acc 0.9399441340782123:\n",
      "20th- epoch: 65, train_loss = 20.06797938235104, train_acc = 0.9566837447601304\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 66, train_loss = 20.000911282375455, train_acc = 0.9569166278528178\n",
      "test Acc 0.9399441340782123:\n",
      "20th- epoch: 67, train_loss = 19.927214736118913, train_acc = 0.9568001863064741\n",
      "test Acc 0.9399441340782123:\n",
      "20th- epoch: 68, train_loss = 19.86493545770645, train_acc = 0.9571495109455054\n",
      "test Acc 0.9394785847299814:\n",
      "20th- epoch: 69, train_loss = 19.800967076793313, train_acc = 0.9573823940381928\n",
      "test Acc 0.9399441340782123:\n",
      "20th- epoch: 70, train_loss = 19.754525389522314, train_acc = 0.9573823940381928\n",
      "test Acc 0.9404096834264432:\n",
      "20th- epoch: 71, train_loss = 19.686295989900827, train_acc = 0.9576152771308803\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 72, train_loss = 19.625706497579813, train_acc = 0.9574988355845365\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 73, train_loss = 19.567785389721394, train_acc = 0.9576152771308803\n",
      "test Acc 0.9404096834264432:\n",
      "20th- epoch: 74, train_loss = 19.5065591763705, train_acc = 0.9576152771308803\n",
      "test Acc 0.9404096834264432:\n",
      "20th- epoch: 75, train_loss = 19.448908543214202, train_acc = 0.9577317186772241\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 76, train_loss = 19.39866590499878, train_acc = 0.9577317186772241\n",
      "test Acc 0.9408752327746741:\n",
      "20th- epoch: 77, train_loss = 19.340917624533176, train_acc = 0.9579646017699115\n",
      "test Acc 0.9413407821229051:\n",
      "20th- epoch: 78, train_loss = 19.28223515301943, train_acc = 0.9579646017699115\n",
      "test Acc 0.9413407821229051:\n",
      "20th- epoch: 79, train_loss = 19.236520500853658, train_acc = 0.9579646017699115\n",
      "test Acc 0.9422718808193669:\n",
      "20th- epoch: 80, train_loss = 19.188459610566497, train_acc = 0.9581974848625989\n",
      "test Acc 0.9422718808193669:\n",
      "20th- epoch: 81, train_loss = 19.128558369353414, train_acc = 0.9581974848625989\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 82, train_loss = 19.075228108093143, train_acc = 0.9580810433162552\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 83, train_loss = 19.01983105018735, train_acc = 0.9583139264089428\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 84, train_loss = 18.96851680241525, train_acc = 0.9581974848625989\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 85, train_loss = 18.932302299886942, train_acc = 0.9581974848625989\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 86, train_loss = 18.88267177529633, train_acc = 0.9586632510479739\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 87, train_loss = 18.831082735210657, train_acc = 0.9587796925943176\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 88, train_loss = 18.787830034270883, train_acc = 0.9587796925943176\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 89, train_loss = 18.743125783279538, train_acc = 0.9586632510479739\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 90, train_loss = 18.69450757652521, train_acc = 0.9586632510479739\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 91, train_loss = 18.64565926976502, train_acc = 0.9587796925943176\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 92, train_loss = 18.600986110046506, train_acc = 0.95947834187238\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 93, train_loss = 18.567104237154126, train_acc = 0.9591290172333489\n",
      "test Acc 0.9432029795158287:\n",
      "20th- epoch: 94, train_loss = 18.534120842814445, train_acc = 0.9591290172333489\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 95, train_loss = 18.487277787178755, train_acc = 0.9593619003260363\n",
      "test Acc 0.9432029795158287:\n",
      "20th- epoch: 96, train_loss = 18.454328015446663, train_acc = 0.95947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "20th- epoch: 97, train_loss = 18.41029309667647, train_acc = 0.9597112249650676\n",
      "test Acc 0.9432029795158287:\n",
      "20th- epoch: 98, train_loss = 18.37383078970015, train_acc = 0.9600605496040987\n",
      "test Acc 0.9432029795158287:\n",
      "20th- epoch: 99, train_loss = 18.329460920765996, train_acc = 0.9598276665114113\n",
      "test Acc 0.9432029795158287:\n",
      "20th- epoch: 100, train_loss = 18.290546976029873, train_acc = 0.9598276665114113\n",
      "test Acc 0.9432029795158287:\n",
      "20th- epoch: 101, train_loss = 18.253985138610005, train_acc = 0.9601769911504425\n",
      "test Acc 0.9432029795158287:\n",
      "20th- epoch: 102, train_loss = 18.219827020540833, train_acc = 0.9602934326967862\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 103, train_loss = 18.186909087002277, train_acc = 0.9606427573358174\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 104, train_loss = 18.14172131381929, train_acc = 0.9607591988821611\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 105, train_loss = 18.099978221580386, train_acc = 0.9608756404285049\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 106, train_loss = 18.08098722435534, train_acc = 0.9607591988821611\n",
      "test Acc 0.9432029795158287:\n",
      "20th- epoch: 107, train_loss = 18.03393912501633, train_acc = 0.9606427573358174\n",
      "test Acc 0.9441340782122905:\n",
      "20th- epoch: 108, train_loss = 18.014466255903244, train_acc = 0.9612249650675361\n",
      "test Acc 0.9441340782122905:\n",
      "20th- epoch: 109, train_loss = 17.98115228675306, train_acc = 0.9608756404285049\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 110, train_loss = 17.94487521611154, train_acc = 0.9612249650675361\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 111, train_loss = 17.91123447753489, train_acc = 0.9612249650675361\n",
      "test Acc 0.9441340782122905:\n",
      "20th- epoch: 112, train_loss = 17.88968188688159, train_acc = 0.9613414066138798\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 113, train_loss = 17.847239907830954, train_acc = 0.9613414066138798\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 114, train_loss = 17.817183619365096, train_acc = 0.9614578481602236\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 115, train_loss = 17.779481459409, train_acc = 0.961690731252911\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 116, train_loss = 17.747345620766282, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "20th- epoch: 117, train_loss = 17.728876588866115, train_acc = 0.9615742897065673\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 118, train_loss = 17.69732734747231, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "20th- epoch: 119, train_loss = 17.650666987523437, train_acc = 0.9619236143455985\n",
      "test Acc 0.9441340782122905:\n",
      "20th- epoch: 120, train_loss = 17.626566968858242, train_acc = 0.9618071727992548\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 121, train_loss = 17.620001235976815, train_acc = 0.961690731252911\n",
      "test Acc 0.9445996275605214:\n",
      "20th- epoch: 122, train_loss = 17.573281422257423, train_acc = 0.9618071727992548\n",
      "test Acc 0.9450651769087524:\n",
      "20th- epoch: 123, train_loss = 17.540233552455902, train_acc = 0.9618071727992548\n",
      "test Acc 0.9450651769087524:\n",
      "20th- epoch: 124, train_loss = 17.523107381537557, train_acc = 0.9618071727992548\n",
      "test Acc 0.9450651769087524:\n",
      "20th- epoch: 125, train_loss = 17.487505784258246, train_acc = 0.9620400558919422\n",
      "test Acc 0.9450651769087524:\n",
      "20th- epoch: 126, train_loss = 17.460665671154857, train_acc = 0.9620400558919422\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 127, train_loss = 17.44146143645048, train_acc = 0.962156497438286\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 128, train_loss = 17.414480665698647, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "20th- epoch: 129, train_loss = 17.401341278105974, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "20th- epoch: 130, train_loss = 17.36833974532783, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 131, train_loss = 17.336816292256117, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 132, train_loss = 17.30749130435288, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 133, train_loss = 17.2865472137928, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 134, train_loss = 17.25527081824839, train_acc = 0.9623893805309734\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 135, train_loss = 17.23542524687946, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 136, train_loss = 17.20732112042606, train_acc = 0.9623893805309734\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 137, train_loss = 17.18277014605701, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 138, train_loss = 17.166494453325868, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 139, train_loss = 17.152974983677268, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 140, train_loss = 17.124307818710804, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 141, train_loss = 17.087241077795625, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 142, train_loss = 17.06818686053157, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 143, train_loss = 17.048856427893043, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 144, train_loss = 17.031799010932446, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 145, train_loss = 16.996531972661614, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 146, train_loss = 16.978619685396552, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 147, train_loss = 16.95713079907, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 148, train_loss = 16.938389813527465, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "20th- epoch: 149, train_loss = 16.918447632342577, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "20th- epoch: 150, train_loss = 16.892038950696588, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 151, train_loss = 16.873648412525654, train_acc = 0.9633209129017233\n",
      "test Acc 0.9459962756052142:\n",
      "20th- epoch: 152, train_loss = 16.85057575441897, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "20th- epoch: 153, train_loss = 16.838076170533895, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "20th- epoch: 154, train_loss = 16.810742175206542, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "20th- epoch: 155, train_loss = 16.791399950161576, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 156, train_loss = 16.77650215663016, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "20th- epoch: 157, train_loss = 16.75050320290029, train_acc = 0.9633209129017233\n",
      "test Acc 0.9459962756052142:\n",
      "20th- epoch: 158, train_loss = 16.731854354962707, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 159, train_loss = 16.71207801438868, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 160, train_loss = 16.693493138998747, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 161, train_loss = 16.674891399219632, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 162, train_loss = 16.657226843759418, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 163, train_loss = 16.63011891581118, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 164, train_loss = 16.614226089790463, train_acc = 0.9635537959944108\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 165, train_loss = 16.60380755364895, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "20th- epoch: 166, train_loss = 16.581882517784834, train_acc = 0.9636702375407545\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 167, train_loss = 16.564076429232955, train_acc = 0.9637866790870983\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 168, train_loss = 16.541416704654694, train_acc = 0.9637866790870983\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 169, train_loss = 16.525482645258307, train_acc = 0.9637866790870983\n",
      "test Acc 0.946927374301676:\n",
      "20th- epoch: 170, train_loss = 16.51140663214028, train_acc = 0.9637866790870983\n",
      "test Acc 0.946927374301676:\n",
      "20th- epoch: 171, train_loss = 16.497320188209414, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "20th- epoch: 172, train_loss = 16.473424622789025, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "20th- epoch: 173, train_loss = 16.467043122276664, train_acc = 0.963903120633442\n",
      "test Acc 0.946927374301676:\n",
      "20th- epoch: 174, train_loss = 16.439962442964315, train_acc = 0.9641360037261295\n",
      "test Acc 0.946927374301676:\n",
      "20th- epoch: 175, train_loss = 16.42703091725707, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "20th- epoch: 176, train_loss = 16.410529417917132, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "20th- epoch: 177, train_loss = 16.389229925349355, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "20th- epoch: 178, train_loss = 16.38065741211176, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 179, train_loss = 16.355321619659662, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 180, train_loss = 16.339655367657542, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "20th- epoch: 181, train_loss = 16.321981076151133, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "20th- epoch: 182, train_loss = 16.30238006450236, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "20th- epoch: 183, train_loss = 16.28681492060423, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 184, train_loss = 16.28678704611957, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 185, train_loss = 16.265763459727168, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 186, train_loss = 16.242412948980927, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 187, train_loss = 16.223929090425372, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 188, train_loss = 16.223458839580417, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 189, train_loss = 16.19736343063414, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 190, train_loss = 16.178419770672917, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 191, train_loss = 16.166135672479868, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 192, train_loss = 16.149729643017054, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 193, train_loss = 16.134094150736928, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 194, train_loss = 16.12629691697657, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 195, train_loss = 16.100768815726042, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 196, train_loss = 16.093911081552505, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 197, train_loss = 16.087278021499515, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 198, train_loss = 16.05948861129582, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 199, train_loss = 16.050222424790263, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 200, train_loss = 16.039943853393197, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 201, train_loss = 16.021577313542366, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 202, train_loss = 16.001885591074824, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 203, train_loss = 15.996099388226867, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 204, train_loss = 15.976066950708628, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 205, train_loss = 15.966115908697248, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 206, train_loss = 15.95190853253007, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 207, train_loss = 15.932870941236615, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 208, train_loss = 15.932013516314328, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 209, train_loss = 15.912019716575742, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 210, train_loss = 15.893491661176085, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 211, train_loss = 15.880545854568481, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 212, train_loss = 15.882607537321746, train_acc = 0.9648346530041919\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 213, train_loss = 15.855790561065078, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 214, train_loss = 15.84307612478733, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 215, train_loss = 15.83496315125376, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 216, train_loss = 15.823870303109288, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 217, train_loss = 15.802092134952545, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 218, train_loss = 15.788995177485049, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 219, train_loss = 15.77425317838788, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 220, train_loss = 15.767426162026823, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 221, train_loss = 15.75584361422807, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 222, train_loss = 15.742808625102043, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 223, train_loss = 15.730556778609753, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 224, train_loss = 15.712626322172582, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 225, train_loss = 15.707191038876772, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 226, train_loss = 15.696465599350631, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 227, train_loss = 15.67359324451536, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 228, train_loss = 15.672303481958807, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 229, train_loss = 15.65737286861986, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 230, train_loss = 15.639753452502191, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 231, train_loss = 15.632964104413986, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 232, train_loss = 15.618089407682419, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 233, train_loss = 15.605427350848913, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 234, train_loss = 15.592402163892984, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 235, train_loss = 15.582700558006763, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 236, train_loss = 15.574100942350924, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 237, train_loss = 15.567133098840714, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 238, train_loss = 15.555223760195076, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 239, train_loss = 15.536495664156973, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 240, train_loss = 15.529522991739213, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 241, train_loss = 15.512331019155681, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 242, train_loss = 15.50302953645587, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 243, train_loss = 15.501140471547842, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 244, train_loss = 15.486710391938686, train_acc = 0.9658826269212856\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 245, train_loss = 15.470274864695966, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 246, train_loss = 15.458631880581379, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 247, train_loss = 15.450246865861118, train_acc = 0.9659990684676293\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 248, train_loss = 15.440798837691545, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 249, train_loss = 15.425531223416328, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 250, train_loss = 15.419163707643747, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 251, train_loss = 15.409111555665731, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 252, train_loss = 15.397858384996653, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 253, train_loss = 15.391826685518026, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 254, train_loss = 15.376044723205268, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 255, train_loss = 15.365670423954725, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 256, train_loss = 15.357220939360559, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 257, train_loss = 15.346877354197204, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 258, train_loss = 15.331672851927578, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 259, train_loss = 15.32548217382282, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 260, train_loss = 15.320436333306134, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 261, train_loss = 15.307838891632855, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 262, train_loss = 15.299780578352511, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 263, train_loss = 15.285633019171655, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 264, train_loss = 15.278622131794691, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 265, train_loss = 15.270727057941258, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 266, train_loss = 15.262358120642602, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 267, train_loss = 15.24846064671874, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 268, train_loss = 15.236032993532717, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 269, train_loss = 15.23379226680845, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 270, train_loss = 15.21934552397579, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 271, train_loss = 15.209831717424095, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 272, train_loss = 15.19785747025162, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 273, train_loss = 15.184518956579268, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 274, train_loss = 15.189640470780432, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 275, train_loss = 15.175878445617855, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 276, train_loss = 15.160460907034576, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 277, train_loss = 15.159069526009262, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 278, train_loss = 15.146390940994024, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 279, train_loss = 15.138063442893326, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 280, train_loss = 15.126781883649528, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 281, train_loss = 15.121410220861435, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 282, train_loss = 15.10845551174134, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 283, train_loss = 15.101928465999663, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 284, train_loss = 15.092435985803604, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 285, train_loss = 15.08459534868598, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 286, train_loss = 15.076530287973583, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 287, train_loss = 15.06402735505253, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 288, train_loss = 15.062615354545414, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 289, train_loss = 15.049584723077714, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 290, train_loss = 15.048303086310625, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 291, train_loss = 15.035466401837766, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 292, train_loss = 15.02706787455827, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 293, train_loss = 15.018155883997679, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 294, train_loss = 15.013691536150873, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 295, train_loss = 15.002440846525133, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 296, train_loss = 14.987071649171412, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 297, train_loss = 14.974180082790554, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 298, train_loss = 14.961968407034874, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 299, train_loss = 14.951524985022843, train_acc = 0.9671634839310667\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 300, train_loss = 14.947222427465022, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 301, train_loss = 14.938237153925002, train_acc = 0.9670470423847228\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 302, train_loss = 14.929772934876382, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 303, train_loss = 14.919666918925941, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 304, train_loss = 14.910314093343914, train_acc = 0.9672799254774104\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 305, train_loss = 14.906870075501502, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 306, train_loss = 14.897064290940762, train_acc = 0.9671634839310667\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 307, train_loss = 14.884392634034157, train_acc = 0.9672799254774104\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 308, train_loss = 14.881425553001463, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 309, train_loss = 14.867580671794713, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 310, train_loss = 14.855076340027153, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 311, train_loss = 14.845852181315422, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 312, train_loss = 14.840762477368116, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 313, train_loss = 14.831311480142176, train_acc = 0.9671634839310667\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 314, train_loss = 14.826662785373628, train_acc = 0.9672799254774104\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 315, train_loss = 14.819454334676266, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 316, train_loss = 14.807568867690861, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 317, train_loss = 14.799919538199902, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 318, train_loss = 14.792069391347468, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 319, train_loss = 14.783186213113368, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 320, train_loss = 14.778522371314466, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 321, train_loss = 14.772423155605793, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 322, train_loss = 14.763334404677153, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 323, train_loss = 14.760155233554542, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 324, train_loss = 14.747629857622087, train_acc = 0.9672799254774104\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 325, train_loss = 14.73921447340399, train_acc = 0.9672799254774104\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 326, train_loss = 14.732717857696116, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 327, train_loss = 14.727014645934105, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 328, train_loss = 14.721088853664696, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 329, train_loss = 14.70924649760127, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 330, train_loss = 14.699985939078033, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 331, train_loss = 14.69259549677372, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 332, train_loss = 14.68629627674818, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 333, train_loss = 14.682592774741352, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 334, train_loss = 14.670602508820593, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 335, train_loss = 14.663843057118356, train_acc = 0.9673963670237541\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 336, train_loss = 14.65996182244271, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 337, train_loss = 14.650750669650733, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 338, train_loss = 14.639468138106167, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 339, train_loss = 14.638304397463799, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 340, train_loss = 14.630964241921902, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 341, train_loss = 14.62474799901247, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 342, train_loss = 14.614507250487804, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 343, train_loss = 14.61024569068104, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 344, train_loss = 14.600508350878954, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 345, train_loss = 14.599756154231727, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 346, train_loss = 14.590244750492275, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 347, train_loss = 14.57969409506768, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 348, train_loss = 14.578907302580774, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 349, train_loss = 14.57016662042588, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 350, train_loss = 14.561565462499857, train_acc = 0.9675128085700978\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 351, train_loss = 14.55225095152855, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 352, train_loss = 14.547924396581948, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 353, train_loss = 14.539075172506273, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 354, train_loss = 14.532380543649197, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 355, train_loss = 14.53071766719222, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 356, train_loss = 14.5195530988276, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 357, train_loss = 14.51137151569128, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 358, train_loss = 14.509476465173066, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 359, train_loss = 14.503370181657374, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 360, train_loss = 14.492417733184993, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 361, train_loss = 14.485711724497378, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 362, train_loss = 14.4827591041103, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 363, train_loss = 14.474240095354617, train_acc = 0.9679785747554728\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 364, train_loss = 14.466799476183951, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 365, train_loss = 14.459544082172215, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 366, train_loss = 14.45971407275647, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 367, train_loss = 14.451769162900746, train_acc = 0.9679785747554728\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 368, train_loss = 14.441613115370274, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 369, train_loss = 14.440573730506003, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 370, train_loss = 14.437479841522872, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 371, train_loss = 14.431078637950122, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 372, train_loss = 14.422214492224157, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 373, train_loss = 14.419134312309325, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 374, train_loss = 14.408528267405927, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 375, train_loss = 14.404613882303238, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 376, train_loss = 14.397839806042612, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 377, train_loss = 14.390155545435846, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 378, train_loss = 14.385971491225064, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 379, train_loss = 14.382826435379684, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 380, train_loss = 14.376206710003316, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 381, train_loss = 14.371416542679071, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 382, train_loss = 14.363862135447562, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 383, train_loss = 14.360124693252146, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 384, train_loss = 14.350071970373392, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 385, train_loss = 14.350851502269506, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 386, train_loss = 14.338183045387268, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 387, train_loss = 14.338465663604438, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 388, train_loss = 14.329644251614809, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 389, train_loss = 14.320592044852674, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 390, train_loss = 14.319031951017678, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 391, train_loss = 14.314658519811928, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 392, train_loss = 14.303864862769842, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 393, train_loss = 14.299224889837205, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 394, train_loss = 14.293647878803313, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 395, train_loss = 14.290720294229686, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 396, train_loss = 14.28258952498436, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 397, train_loss = 14.278193366713822, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 398, train_loss = 14.27149538230151, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 399, train_loss = 14.267941956408322, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 400, train_loss = 14.259760831482708, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 401, train_loss = 14.255085174925625, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 402, train_loss = 14.25032702088356, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 403, train_loss = 14.24136860575527, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 404, train_loss = 14.239381079562008, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 405, train_loss = 14.236750225536525, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 406, train_loss = 14.228842481039464, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 407, train_loss = 14.230431292206049, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 408, train_loss = 14.21778046619147, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 409, train_loss = 14.210828181356192, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 410, train_loss = 14.20965463668108, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 411, train_loss = 14.201703651808202, train_acc = 0.9692594317652539\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 412, train_loss = 14.196558422408998, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 413, train_loss = 14.193337916396558, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 414, train_loss = 14.18137413263321, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 415, train_loss = 14.177490000613034, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 416, train_loss = 14.173716426827013, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 417, train_loss = 14.171990330331028, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 418, train_loss = 14.170279420912266, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 419, train_loss = 14.163507866673172, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 420, train_loss = 14.154220285825431, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 421, train_loss = 14.15433878917247, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 422, train_loss = 14.147457972168922, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 423, train_loss = 14.138381675817072, train_acc = 0.9693758733115976\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 424, train_loss = 14.13310765195638, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 425, train_loss = 14.125083756633103, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 426, train_loss = 14.126567493192852, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 427, train_loss = 14.120554968714714, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 428, train_loss = 14.114969327114522, train_acc = 0.9694923148579413\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 429, train_loss = 14.11059243697673, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 430, train_loss = 14.109159976243973, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 431, train_loss = 14.100959683768451, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 432, train_loss = 14.09673931542784, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 433, train_loss = 14.091323894448578, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 434, train_loss = 14.082675256766379, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 435, train_loss = 14.080559086054564, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 436, train_loss = 14.073629046790302, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 437, train_loss = 14.06956297531724, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 438, train_loss = 14.066032179631293, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 439, train_loss = 14.06030132714659, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 440, train_loss = 14.05575739312917, train_acc = 0.969608756404285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9497206703910615:\n",
      "20th- epoch: 441, train_loss = 14.054735090583563, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 442, train_loss = 14.044214977882802, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 443, train_loss = 14.04055008199066, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 444, train_loss = 14.037055951543152, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 445, train_loss = 14.03016175236553, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 446, train_loss = 14.025108396075666, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 447, train_loss = 14.022069830447435, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 448, train_loss = 14.019978768192232, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 449, train_loss = 14.013579304330051, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 450, train_loss = 14.01074057072401, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 451, train_loss = 14.002729326486588, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 452, train_loss = 13.999583721160889, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 453, train_loss = 13.99380171019584, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 454, train_loss = 13.989413670264184, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 455, train_loss = 13.984852652065456, train_acc = 0.969608756404285\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 456, train_loss = 13.982120686210692, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 457, train_loss = 13.97721064183861, train_acc = 0.969608756404285\n",
      "test Acc 0.9501862197392924:\n",
      "20th- epoch: 458, train_loss = 13.969562575221062, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 459, train_loss = 13.972942556254566, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 460, train_loss = 13.960162200964987, train_acc = 0.969608756404285\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 461, train_loss = 13.959142990410328, train_acc = 0.969608756404285\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 462, train_loss = 13.9571199901402, train_acc = 0.9697251979506288\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 463, train_loss = 13.947666171938181, train_acc = 0.969608756404285\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 464, train_loss = 13.943619921803474, train_acc = 0.9697251979506288\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 465, train_loss = 13.942246075719595, train_acc = 0.9697251979506288\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 466, train_loss = 13.939047290477902, train_acc = 0.9697251979506288\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 467, train_loss = 13.933929143939167, train_acc = 0.9697251979506288\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 468, train_loss = 13.927979305386543, train_acc = 0.9697251979506288\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 469, train_loss = 13.929264885839075, train_acc = 0.9697251979506288\n",
      "test Acc 0.9515828677839852:\n",
      "20th- epoch: 470, train_loss = 13.916323269251734, train_acc = 0.9697251979506288\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 471, train_loss = 13.917615287005901, train_acc = 0.9698416394969726\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 472, train_loss = 13.90544761205092, train_acc = 0.9698416394969726\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 473, train_loss = 13.904504352714866, train_acc = 0.9698416394969726\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 474, train_loss = 13.900012829806656, train_acc = 0.9698416394969726\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 475, train_loss = 13.896547017153352, train_acc = 0.9698416394969726\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 476, train_loss = 13.894556276500225, train_acc = 0.9699580810433163\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 477, train_loss = 13.890675368253142, train_acc = 0.9699580810433163\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 478, train_loss = 13.88479865109548, train_acc = 0.9699580810433163\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 479, train_loss = 13.878763545304537, train_acc = 0.97007452258966\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 480, train_loss = 13.879450467880815, train_acc = 0.97007452258966\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 481, train_loss = 13.875168894883245, train_acc = 0.9699580810433163\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 482, train_loss = 13.87168788164854, train_acc = 0.9699580810433163\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 483, train_loss = 13.867926293518394, train_acc = 0.9699580810433163\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 484, train_loss = 13.860580147709697, train_acc = 0.9699580810433163\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 485, train_loss = 13.857516076415777, train_acc = 0.9699580810433163\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 486, train_loss = 13.854293590877205, train_acc = 0.97007452258966\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 487, train_loss = 13.853635255247355, train_acc = 0.97007452258966\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 488, train_loss = 13.843000320252031, train_acc = 0.97007452258966\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 489, train_loss = 13.838888370897621, train_acc = 0.97007452258966\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 490, train_loss = 13.831526912748814, train_acc = 0.9699580810433163\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 491, train_loss = 13.829963320400566, train_acc = 0.9699580810433163\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 492, train_loss = 13.824665892869234, train_acc = 0.9699580810433163\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 493, train_loss = 13.825589498970658, train_acc = 0.97007452258966\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 494, train_loss = 13.816649608314037, train_acc = 0.97007452258966\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 495, train_loss = 13.815539060626179, train_acc = 0.9701909641360037\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 496, train_loss = 13.81086174538359, train_acc = 0.9699580810433163\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 497, train_loss = 13.806691019330174, train_acc = 0.9699580810433163\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 498, train_loss = 13.805313353892416, train_acc = 0.9701909641360037\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 499, train_loss = 13.799602001905441, train_acc = 0.97007452258966\n",
      "test Acc 0.9511173184357542:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████▋                       | 20/30 [3:01:04<1:30:23, 542.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "21th- epoch: 0, train_loss = 127.7598928809166, train_acc = 0.7382394038192828\n",
      "test Acc 0.8594040968342644:\n",
      "21th- epoch: 1, train_loss = 58.70052136480808, train_acc = 0.873660922217047\n",
      "test Acc 0.8924581005586593:\n",
      "21th- epoch: 2, train_loss = 49.3637013733387, train_acc = 0.8942710759198882\n",
      "test Acc 0.9050279329608939:\n",
      "21th- epoch: 3, train_loss = 44.39538785815239, train_acc = 0.9046343735444806\n",
      "test Acc 0.9078212290502793:\n",
      "21th- epoch: 4, train_loss = 41.21347515285015, train_acc = 0.9109222170470423\n",
      "test Acc 0.909683426443203:\n",
      "21th- epoch: 5, train_loss = 38.78637910634279, train_acc = 0.9170936190032604\n",
      "test Acc 0.9134078212290503:\n",
      "21th- epoch: 6, train_loss = 36.8641888871789, train_acc = 0.9218677224033535\n",
      "test Acc 0.9152700186219739:\n",
      "21th- epoch: 7, train_loss = 35.26692968606949, train_acc = 0.9254774103400093\n",
      "test Acc 0.9157355679702048:\n",
      "21th- epoch: 8, train_loss = 33.92983974516392, train_acc = 0.9292035398230089\n",
      "test Acc 0.9180633147113594:\n",
      "21th- epoch: 9, train_loss = 32.852952234447, train_acc = 0.9307172799254774\n",
      "test Acc 0.9213221601489758:\n",
      "21th- epoch: 10, train_loss = 31.900516495108604, train_acc = 0.9324639031206334\n",
      "test Acc 0.9222532588454376:\n",
      "21th- epoch: 11, train_loss = 31.11048001050949, train_acc = 0.9332789939450395\n",
      "test Acc 0.9231843575418994:\n",
      "21th- epoch: 12, train_loss = 30.374966360628605, train_acc = 0.9343269678621332\n",
      "test Acc 0.9250465549348231:\n",
      "21th- epoch: 13, train_loss = 29.70979618281126, train_acc = 0.9358407079646017\n",
      "test Acc 0.9264432029795159:\n",
      "21th- epoch: 14, train_loss = 29.106599375605583, train_acc = 0.9375873311597578\n",
      "test Acc 0.9283054003724395:\n",
      "21th- epoch: 15, train_loss = 28.554730862379074, train_acc = 0.9393339543549138\n",
      "test Acc 0.9297020484171322:\n",
      "21th- epoch: 16, train_loss = 28.04061781615019, train_acc = 0.9409641360037261\n",
      "test Acc 0.9297020484171322:\n",
      "21th- epoch: 17, train_loss = 27.590392351150513, train_acc = 0.9417792268281323\n",
      "test Acc 0.9301675977653632:\n",
      "21th- epoch: 18, train_loss = 27.157619915902615, train_acc = 0.9422449930135072\n",
      "test Acc 0.9320297951582868:\n",
      "21th- epoch: 19, train_loss = 26.737584367394447, train_acc = 0.9428272007452259\n",
      "test Acc 0.9329608938547486:\n",
      "21th- epoch: 20, train_loss = 26.348106309771538, train_acc = 0.9437587331159758\n",
      "test Acc 0.9329608938547486:\n",
      "21th- epoch: 21, train_loss = 26.012407019734383, train_acc = 0.9444573823940382\n",
      "test Acc 0.9334264432029795:\n",
      "21th- epoch: 22, train_loss = 25.696098543703556, train_acc = 0.9448067070330693\n",
      "test Acc 0.9324953445065177:\n",
      "21th- epoch: 23, train_loss = 25.389016047120094, train_acc = 0.9452724732184443\n",
      "test Acc 0.9329608938547486:\n",
      "21th- epoch: 24, train_loss = 25.104670468717813, train_acc = 0.9456217978574756\n",
      "test Acc 0.9338919925512105:\n",
      "21th- epoch: 25, train_loss = 24.855265222489834, train_acc = 0.9465533302282254\n",
      "test Acc 0.9338919925512105:\n",
      "21th- epoch: 26, train_loss = 24.59982755407691, train_acc = 0.946786213320913\n",
      "test Acc 0.9334264432029795:\n",
      "21th- epoch: 27, train_loss = 24.367956586182117, train_acc = 0.9471355379599441\n",
      "test Acc 0.9338919925512105:\n",
      "21th- epoch: 28, train_loss = 24.15953203290701, train_acc = 0.9474848625989754\n",
      "test Acc 0.9343575418994413:\n",
      "21th- epoch: 29, train_loss = 23.92693953588605, train_acc = 0.948067070330694\n",
      "test Acc 0.9338919925512105:\n",
      "21th- epoch: 30, train_loss = 23.732648499310017, train_acc = 0.9486492780624126\n",
      "test Acc 0.9343575418994413:\n",
      "21th- epoch: 31, train_loss = 23.546749610453844, train_acc = 0.9493479273404751\n",
      "test Acc 0.9348230912476723:\n",
      "21th- epoch: 32, train_loss = 23.362452421337366, train_acc = 0.9499301350721937\n",
      "test Acc 0.9348230912476723:\n",
      "21th- epoch: 33, train_loss = 23.183424655348063, train_acc = 0.9500465766185375\n",
      "test Acc 0.9357541899441341:\n",
      "21th- epoch: 34, train_loss = 23.004021294414997, train_acc = 0.9506287843502562\n",
      "test Acc 0.9357541899441341:\n",
      "21th- epoch: 35, train_loss = 22.845577642321587, train_acc = 0.9509781089892874\n",
      "test Acc 0.936219739292365:\n",
      "21th- epoch: 36, train_loss = 22.69447587430477, train_acc = 0.951560316721006\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 37, train_loss = 22.535987872630358, train_acc = 0.9519096413600373\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 38, train_loss = 22.39228481799364, train_acc = 0.9517931998136935\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 39, train_loss = 22.254478339105844, train_acc = 0.9519096413600373\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 40, train_loss = 22.10764465481043, train_acc = 0.9521425244527247\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 41, train_loss = 21.985403954982758, train_acc = 0.9522589659990685\n",
      "test Acc 0.9371508379888268:\n",
      "21th- epoch: 42, train_loss = 21.862231206148863, train_acc = 0.9522589659990685\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 43, train_loss = 21.742495212703943, train_acc = 0.9526082906380997\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 44, train_loss = 21.610544089227915, train_acc = 0.9526082906380997\n",
      "test Acc 0.9385474860335196:\n",
      "21th- epoch: 45, train_loss = 21.50094137713313, train_acc = 0.9527247321844434\n",
      "test Acc 0.9385474860335196:\n",
      "21th- epoch: 46, train_loss = 21.404326867312193, train_acc = 0.9529576152771309\n",
      "test Acc 0.9390130353817505:\n",
      "21th- epoch: 47, train_loss = 21.278899129480124, train_acc = 0.9530740568234746\n",
      "test Acc 0.9394785847299814:\n",
      "21th- epoch: 48, train_loss = 21.17906853556633, train_acc = 0.9530740568234746\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 49, train_loss = 21.08681818470359, train_acc = 0.9531904983698184\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 50, train_loss = 20.985082805156708, train_acc = 0.9538891476478808\n",
      "test Acc 0.9399441340782123:\n",
      "21th- epoch: 51, train_loss = 20.890038635581732, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "21th- epoch: 52, train_loss = 20.794255509972572, train_acc = 0.9540055891942245\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 53, train_loss = 20.700251907110214, train_acc = 0.9541220307405682\n",
      "test Acc 0.9408752327746741:\n",
      "21th- epoch: 54, train_loss = 20.619372595101595, train_acc = 0.9542384722869119\n",
      "test Acc 0.9408752327746741:\n",
      "21th- epoch: 55, train_loss = 20.52401502802968, train_acc = 0.9543549138332557\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 56, train_loss = 20.445222560316324, train_acc = 0.9543549138332557\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 57, train_loss = 20.36881858482957, train_acc = 0.9544713553795995\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 58, train_loss = 20.299269318580627, train_acc = 0.9544713553795995\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 59, train_loss = 20.213861256837845, train_acc = 0.9544713553795995\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 60, train_loss = 20.147952929139137, train_acc = 0.9547042384722869\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 61, train_loss = 20.077807489782572, train_acc = 0.9549371215649743\n",
      "test Acc 0.9408752327746741:\n",
      "21th- epoch: 62, train_loss = 20.008029367774725, train_acc = 0.9552864462040056\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 63, train_loss = 19.938658695667982, train_acc = 0.9554028877503493\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 64, train_loss = 19.867098700255156, train_acc = 0.955519329296693\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 65, train_loss = 19.80151904001832, train_acc = 0.9557522123893806\n",
      "test Acc 0.9408752327746741:\n",
      "21th- epoch: 66, train_loss = 19.743011493235826, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "21th- epoch: 67, train_loss = 19.66615165397525, train_acc = 0.9557522123893806\n",
      "test Acc 0.9418063314711359:\n",
      "21th- epoch: 68, train_loss = 19.60975069925189, train_acc = 0.9556357708430367\n",
      "test Acc 0.9413407821229051:\n",
      "21th- epoch: 69, train_loss = 19.555938001722097, train_acc = 0.9558686539357243\n",
      "test Acc 0.9413407821229051:\n",
      "21th- epoch: 70, train_loss = 19.49404513835907, train_acc = 0.955985095482068\n",
      "test Acc 0.9418063314711359:\n",
      "21th- epoch: 71, train_loss = 19.42994114384055, train_acc = 0.9563344201210993\n",
      "test Acc 0.9422718808193669:\n",
      "21th- epoch: 72, train_loss = 19.37711650505662, train_acc = 0.9565673032137867\n",
      "test Acc 0.9418063314711359:\n",
      "21th- epoch: 73, train_loss = 19.323549162596464, train_acc = 0.9565673032137867\n",
      "test Acc 0.9422718808193669:\n",
      "21th- epoch: 74, train_loss = 19.26876176148653, train_acc = 0.9566837447601304\n",
      "test Acc 0.9422718808193669:\n",
      "21th- epoch: 75, train_loss = 19.213616881519556, train_acc = 0.9569166278528178\n",
      "test Acc 0.9422718808193669:\n",
      "21th- epoch: 76, train_loss = 19.157641880214214, train_acc = 0.9569166278528178\n",
      "test Acc 0.9422718808193669:\n",
      "21th- epoch: 77, train_loss = 19.119699247181416, train_acc = 0.9572659524918491\n",
      "test Acc 0.9427374301675978:\n",
      "21th- epoch: 78, train_loss = 19.053476221859455, train_acc = 0.9572659524918491\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 79, train_loss = 18.994489926844835, train_acc = 0.9574988355845365\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 80, train_loss = 18.942656114697456, train_acc = 0.9578481602235678\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 81, train_loss = 18.89615361765027, train_acc = 0.9581974848625989\n",
      "test Acc 0.9436685288640596:\n",
      "21th- epoch: 82, train_loss = 18.856111705303192, train_acc = 0.9583139264089428\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 83, train_loss = 18.79844380170107, train_acc = 0.9583139264089428\n",
      "test Acc 0.9436685288640596:\n",
      "21th- epoch: 84, train_loss = 18.75967201590538, train_acc = 0.9585468095016302\n",
      "test Acc 0.9436685288640596:\n",
      "21th- epoch: 85, train_loss = 18.715636514127254, train_acc = 0.9586632510479739\n",
      "test Acc 0.9436685288640596:\n",
      "21th- epoch: 86, train_loss = 18.677907813340425, train_acc = 0.9585468095016302\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 87, train_loss = 18.613864239305258, train_acc = 0.9587796925943176\n",
      "test Acc 0.9436685288640596:\n",
      "21th- epoch: 88, train_loss = 18.586025670170784, train_acc = 0.9586632510479739\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 89, train_loss = 18.54147851653397, train_acc = 0.9586632510479739\n",
      "test Acc 0.9432029795158287:\n",
      "21th- epoch: 90, train_loss = 18.49178740940988, train_acc = 0.9587796925943176\n",
      "test Acc 0.9436685288640596:\n",
      "21th- epoch: 91, train_loss = 18.451300721615553, train_acc = 0.9588961341406614\n",
      "test Acc 0.9441340782122905:\n",
      "21th- epoch: 92, train_loss = 18.40436108596623, train_acc = 0.9588961341406614\n",
      "test Acc 0.9436685288640596:\n",
      "21th- epoch: 93, train_loss = 18.36962472833693, train_acc = 0.9590125756870052\n",
      "test Acc 0.9436685288640596:\n",
      "21th- epoch: 94, train_loss = 18.328356815502048, train_acc = 0.9591290172333489\n",
      "test Acc 0.9441340782122905:\n",
      "21th- epoch: 95, train_loss = 18.292919224128127, train_acc = 0.9591290172333489\n",
      "test Acc 0.9441340782122905:\n",
      "21th- epoch: 96, train_loss = 18.256264615803957, train_acc = 0.9592454587796926\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 97, train_loss = 18.21897747926414, train_acc = 0.9592454587796926\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 98, train_loss = 18.168427232652903, train_acc = 0.9592454587796926\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 99, train_loss = 18.132559018209577, train_acc = 0.9592454587796926\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 100, train_loss = 18.101698653772473, train_acc = 0.9593619003260363\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 101, train_loss = 18.070258317515254, train_acc = 0.9593619003260363\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 102, train_loss = 18.015596989542246, train_acc = 0.9593619003260363\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 103, train_loss = 18.006890354678035, train_acc = 0.9593619003260363\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 104, train_loss = 17.958255488425493, train_acc = 0.95947834187238\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 105, train_loss = 17.92151310481131, train_acc = 0.9595947834187238\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 106, train_loss = 17.890794718638062, train_acc = 0.9597112249650676\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 107, train_loss = 17.852225260809064, train_acc = 0.9595947834187238\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 108, train_loss = 17.832988874986768, train_acc = 0.9595947834187238\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 109, train_loss = 17.774805450811982, train_acc = 0.9597112249650676\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 110, train_loss = 17.759836809709668, train_acc = 0.959944108057755\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 111, train_loss = 17.72528657875955, train_acc = 0.959944108057755\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 112, train_loss = 17.69226922094822, train_acc = 0.9601769911504425\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 113, train_loss = 17.665439384058118, train_acc = 0.9602934326967862\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 114, train_loss = 17.628037886694074, train_acc = 0.9602934326967862\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 115, train_loss = 17.605763545259833, train_acc = 0.96040987424313\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 116, train_loss = 17.579600846394897, train_acc = 0.96040987424313\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 117, train_loss = 17.552121756598353, train_acc = 0.9605263157894737\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 118, train_loss = 17.51646649464965, train_acc = 0.9605263157894737\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 119, train_loss = 17.494230825453997, train_acc = 0.9606427573358174\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 120, train_loss = 17.47283759713173, train_acc = 0.96040987424313\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 121, train_loss = 17.441212132573128, train_acc = 0.96040987424313\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 122, train_loss = 17.395292857661843, train_acc = 0.9607591988821611\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 123, train_loss = 17.37728720717132, train_acc = 0.9607591988821611\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 124, train_loss = 17.346557104960084, train_acc = 0.9608756404285049\n",
      "test Acc 0.9450651769087524:\n",
      "21th- epoch: 125, train_loss = 17.332195596769452, train_acc = 0.9608756404285049\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 126, train_loss = 17.306056147441268, train_acc = 0.9607591988821611\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 127, train_loss = 17.270520713180304, train_acc = 0.9611085235211924\n",
      "test Acc 0.9459962756052142:\n",
      "21th- epoch: 128, train_loss = 17.236414009705186, train_acc = 0.9609920819748486\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 129, train_loss = 17.230309076607227, train_acc = 0.9611085235211924\n",
      "test Acc 0.9459962756052142:\n",
      "21th- epoch: 130, train_loss = 17.188772363588214, train_acc = 0.9612249650675361\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 131, train_loss = 17.16593181155622, train_acc = 0.9615742897065673\n",
      "test Acc 0.9459962756052142:\n",
      "21th- epoch: 132, train_loss = 17.154693730175495, train_acc = 0.9615742897065673\n",
      "test Acc 0.9459962756052142:\n",
      "21th- epoch: 133, train_loss = 17.11961522884667, train_acc = 0.9618071727992548\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 134, train_loss = 17.08218657039106, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "21th- epoch: 135, train_loss = 17.06103259511292, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "21th- epoch: 136, train_loss = 17.045339526608586, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "21th- epoch: 137, train_loss = 17.033163437619805, train_acc = 0.962156497438286\n",
      "test Acc 0.9459962756052142:\n",
      "21th- epoch: 138, train_loss = 17.01008673198521, train_acc = 0.962156497438286\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 139, train_loss = 16.97727876342833, train_acc = 0.9620400558919422\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 140, train_loss = 16.955595379695296, train_acc = 0.9622729389846297\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 141, train_loss = 16.927013704553246, train_acc = 0.9622729389846297\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 142, train_loss = 16.894188256934285, train_acc = 0.9622729389846297\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 143, train_loss = 16.884608425199986, train_acc = 0.962156497438286\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 144, train_loss = 16.867501677945256, train_acc = 0.9622729389846297\n",
      "test Acc 0.9464618249534451:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 145, train_loss = 16.82685431279242, train_acc = 0.9622729389846297\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 146, train_loss = 16.831890942528844, train_acc = 0.9622729389846297\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 147, train_loss = 16.787476690486073, train_acc = 0.9622729389846297\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 148, train_loss = 16.78196564130485, train_acc = 0.9622729389846297\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 149, train_loss = 16.760724959895015, train_acc = 0.9622729389846297\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 150, train_loss = 16.71957208402455, train_acc = 0.9625058220773172\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 151, train_loss = 16.709359753876925, train_acc = 0.9623893805309734\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 152, train_loss = 16.687459932640195, train_acc = 0.9625058220773172\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 153, train_loss = 16.66246755234897, train_acc = 0.9625058220773172\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 154, train_loss = 16.64484701305628, train_acc = 0.9627387051700047\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 155, train_loss = 16.625029634684324, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 156, train_loss = 16.607590151950717, train_acc = 0.9628551467163484\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 157, train_loss = 16.607044955715537, train_acc = 0.9623893805309734\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 158, train_loss = 16.56505867280066, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "21th- epoch: 159, train_loss = 16.558837866410613, train_acc = 0.9627387051700047\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 160, train_loss = 16.52641054801643, train_acc = 0.9628551467163484\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 161, train_loss = 16.518959837034345, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 162, train_loss = 16.512624386698008, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 163, train_loss = 16.498020362108946, train_acc = 0.9627387051700047\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 164, train_loss = 16.451697919517756, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 165, train_loss = 16.444023391231894, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 166, train_loss = 16.447030674666166, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 167, train_loss = 16.41840506531298, train_acc = 0.9628551467163484\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 168, train_loss = 16.390810050070286, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 169, train_loss = 16.379484171047807, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 170, train_loss = 16.373772459104657, train_acc = 0.9632044713553796\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 171, train_loss = 16.349605344235897, train_acc = 0.9632044713553796\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 172, train_loss = 16.315612141042948, train_acc = 0.9632044713553796\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 173, train_loss = 16.306594245135784, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 174, train_loss = 16.275799738243222, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 175, train_loss = 16.269197152927518, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "21th- epoch: 176, train_loss = 16.24564415961504, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 177, train_loss = 16.227275542914867, train_acc = 0.9633209129017233\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 178, train_loss = 16.22789960168302, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 179, train_loss = 16.201015941798687, train_acc = 0.9633209129017233\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 180, train_loss = 16.180678939446807, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 181, train_loss = 16.174770863726735, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 182, train_loss = 16.14806653559208, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 183, train_loss = 16.14707317762077, train_acc = 0.9633209129017233\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 184, train_loss = 16.129118291661143, train_acc = 0.9635537959944108\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 185, train_loss = 16.1290622074157, train_acc = 0.9635537959944108\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 186, train_loss = 16.084854122251272, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 187, train_loss = 16.09016172774136, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 188, train_loss = 16.072839530184865, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 189, train_loss = 16.036919420585036, train_acc = 0.9636702375407545\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 190, train_loss = 16.039403846487403, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 191, train_loss = 16.002463053911924, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 192, train_loss = 15.994475005194545, train_acc = 0.9635537959944108\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 193, train_loss = 15.987927598878741, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 194, train_loss = 15.968109471723437, train_acc = 0.9640195621797858\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 195, train_loss = 15.956722093746066, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 196, train_loss = 15.936334043741226, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 197, train_loss = 15.921363340690732, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 198, train_loss = 15.912354867905378, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 199, train_loss = 15.895988281816244, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 200, train_loss = 15.883390543982387, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 201, train_loss = 15.871231248602271, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 202, train_loss = 15.85901995562017, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 203, train_loss = 15.84112842939794, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 204, train_loss = 15.824250556528568, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 205, train_loss = 15.816573232412338, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 206, train_loss = 15.814458338543773, train_acc = 0.9646017699115044\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 207, train_loss = 15.791608853265643, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 208, train_loss = 15.769201209768653, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 209, train_loss = 15.760635916143656, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 210, train_loss = 15.758703835308552, train_acc = 0.9644853283651607\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 211, train_loss = 15.756641106680036, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 212, train_loss = 15.732941398397088, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 213, train_loss = 15.711370460689068, train_acc = 0.9646017699115044\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 214, train_loss = 15.698444429785013, train_acc = 0.9649510945505356\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 215, train_loss = 15.684881405904889, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 216, train_loss = 15.670653680339456, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 217, train_loss = 15.660813629627228, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 218, train_loss = 15.647965600714087, train_acc = 0.9651839776432231\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 219, train_loss = 15.64900184608996, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "21th- epoch: 220, train_loss = 15.616023467853665, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 221, train_loss = 15.623945505358279, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 222, train_loss = 15.602328537032008, train_acc = 0.9653004191895669\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 223, train_loss = 15.585035545751452, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 224, train_loss = 15.587818566709757, train_acc = 0.965649743828598\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 225, train_loss = 15.566678986884654, train_acc = 0.9655333022822543\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 226, train_loss = 15.546457719057798, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 227, train_loss = 15.528593816794455, train_acc = 0.9654168607359106\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 228, train_loss = 15.523313269019127, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 229, train_loss = 15.515990774147213, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 230, train_loss = 15.505363036878407, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 231, train_loss = 15.488570287823677, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 232, train_loss = 15.471491971053183, train_acc = 0.9659990684676293\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 233, train_loss = 15.466309264302254, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 234, train_loss = 15.45222991425544, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 235, train_loss = 15.440412350930274, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 236, train_loss = 15.425391995348036, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 237, train_loss = 15.415667161345482, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 238, train_loss = 15.409744759090245, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 239, train_loss = 15.399401155300438, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 240, train_loss = 15.377315416932106, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 241, train_loss = 15.376387205906212, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 242, train_loss = 15.37606409471482, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 243, train_loss = 15.354209263809025, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 244, train_loss = 15.3427664777264, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 245, train_loss = 15.332962080836296, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 246, train_loss = 15.328066166490316, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 247, train_loss = 15.305524322204292, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 248, train_loss = 15.295573998242617, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 249, train_loss = 15.293607729487121, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 250, train_loss = 15.27927956636995, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 251, train_loss = 15.271852362900972, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 252, train_loss = 15.261497281491756, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 253, train_loss = 15.241527029313147, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 254, train_loss = 15.238837573677301, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 255, train_loss = 15.225374643690884, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 256, train_loss = 15.218310189433396, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 257, train_loss = 15.209120404906571, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 258, train_loss = 15.206055982969701, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 259, train_loss = 15.18675163667649, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 260, train_loss = 15.172447266988456, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 261, train_loss = 15.167452726513147, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 262, train_loss = 15.155295211821795, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 263, train_loss = 15.164693258702755, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 264, train_loss = 15.162906070239842, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 265, train_loss = 15.131606752984226, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 266, train_loss = 15.114983242936432, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 267, train_loss = 15.110983454622328, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 268, train_loss = 15.095557603985071, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 269, train_loss = 15.099850371479988, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 270, train_loss = 15.083196200430393, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 271, train_loss = 15.083541470579803, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 272, train_loss = 15.070434547029436, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 273, train_loss = 15.063261593692005, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 274, train_loss = 15.045730133540928, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 275, train_loss = 15.046509086154401, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 276, train_loss = 15.031485836021602, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 277, train_loss = 15.025224142707884, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 278, train_loss = 15.01957939285785, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 279, train_loss = 15.004728927277029, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 280, train_loss = 14.996014767326415, train_acc = 0.9670470423847228\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 281, train_loss = 14.978484994731843, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 282, train_loss = 14.987811714410782, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 283, train_loss = 14.971927150152624, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 284, train_loss = 14.960146787576377, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 285, train_loss = 14.953744097612798, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 286, train_loss = 14.944188687950373, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 287, train_loss = 14.93637207429856, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 288, train_loss = 14.918301696889102, train_acc = 0.9670470423847228\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 289, train_loss = 14.920255142264068, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 290, train_loss = 14.916508831083775, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 291, train_loss = 14.902925624512136, train_acc = 0.9670470423847228\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 292, train_loss = 14.887295256368816, train_acc = 0.9670470423847228\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 293, train_loss = 14.889920013956726, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 294, train_loss = 14.877917694859207, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 295, train_loss = 14.865217008627951, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 296, train_loss = 14.863484416157007, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 297, train_loss = 14.849959989078343, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 298, train_loss = 14.8423404796049, train_acc = 0.9671634839310667\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 299, train_loss = 14.83514104411006, train_acc = 0.9671634839310667\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 300, train_loss = 14.817682161927223, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 301, train_loss = 14.817533045075834, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 302, train_loss = 14.807654391042888, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 303, train_loss = 14.805786202661693, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 304, train_loss = 14.797689347527921, train_acc = 0.9673963670237541\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 305, train_loss = 14.782580763101578, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 306, train_loss = 14.771795480512083, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 307, train_loss = 14.766565631143749, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 308, train_loss = 14.758090138435364, train_acc = 0.9672799254774104\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 309, train_loss = 14.751184358261526, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 310, train_loss = 14.74100487306714, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 311, train_loss = 14.738091804087162, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 312, train_loss = 14.722988021560013, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 313, train_loss = 14.721022676676512, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 314, train_loss = 14.720303054898977, train_acc = 0.9675128085700978\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 315, train_loss = 14.701926528476179, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 316, train_loss = 14.700268611311913, train_acc = 0.9676292501164415\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 317, train_loss = 14.685640048235655, train_acc = 0.9678621332091291\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 318, train_loss = 14.683030330576003, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 319, train_loss = 14.67051100358367, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 320, train_loss = 14.66733490023762, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 321, train_loss = 14.653679038397968, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 322, train_loss = 14.647208633832633, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 323, train_loss = 14.640598104335368, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 324, train_loss = 14.634911209344864, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 325, train_loss = 14.635236408561468, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 326, train_loss = 14.617960564792156, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 327, train_loss = 14.606932387687266, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 328, train_loss = 14.604458410292864, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 329, train_loss = 14.594913409091532, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 330, train_loss = 14.590155364014208, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 331, train_loss = 14.579241686500609, train_acc = 0.9678621332091291\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 332, train_loss = 14.573700733482838, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 333, train_loss = 14.56856660824269, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 334, train_loss = 14.554624874144793, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 335, train_loss = 14.553340380080044, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 336, train_loss = 14.545465093106031, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 337, train_loss = 14.53907099366188, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 338, train_loss = 14.533468627370894, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 339, train_loss = 14.522726166062057, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 340, train_loss = 14.516560573130846, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 341, train_loss = 14.50912211369723, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 342, train_loss = 14.509776551276445, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 343, train_loss = 14.500900462269783, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 344, train_loss = 14.495255428366363, train_acc = 0.9683278993945039\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 345, train_loss = 14.486557487398386, train_acc = 0.9683278993945039\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 346, train_loss = 14.474230099469423, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 347, train_loss = 14.473120934329927, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 348, train_loss = 14.463392417877913, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 349, train_loss = 14.458205624483526, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 350, train_loss = 14.456612431444228, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 351, train_loss = 14.448901182971895, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 352, train_loss = 14.438602086156607, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 353, train_loss = 14.433599018491805, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 354, train_loss = 14.42329728603363, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 355, train_loss = 14.419260072521865, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 356, train_loss = 14.409340144135058, train_acc = 0.9685607824871915\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 357, train_loss = 14.408128403127193, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 358, train_loss = 14.397855796851218, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 359, train_loss = 14.388684760779142, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 360, train_loss = 14.381815664470196, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 361, train_loss = 14.37973100785166, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 362, train_loss = 14.373200579546392, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 363, train_loss = 14.364482545293868, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 364, train_loss = 14.35957442689687, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 365, train_loss = 14.354962800629437, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 366, train_loss = 14.348158035427332, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 367, train_loss = 14.337978101335466, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 368, train_loss = 14.334016968496144, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 369, train_loss = 14.331919182091951, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 370, train_loss = 14.31749555002898, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 371, train_loss = 14.315377856604755, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 372, train_loss = 14.304442417807877, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 373, train_loss = 14.302540797740221, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 374, train_loss = 14.297675111331046, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 375, train_loss = 14.291326346807182, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 376, train_loss = 14.28405475243926, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 377, train_loss = 14.282298132777214, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 378, train_loss = 14.270954702049494, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 379, train_loss = 14.269034801982343, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 380, train_loss = 14.260092987678945, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 381, train_loss = 14.255350943654776, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 382, train_loss = 14.25422206055373, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 383, train_loss = 14.248645362444222, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 384, train_loss = 14.23782425839454, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 385, train_loss = 14.240176332183182, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 386, train_loss = 14.227221245877445, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 387, train_loss = 14.219398354180157, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 388, train_loss = 14.219315528869629, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 389, train_loss = 14.209530156105757, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 390, train_loss = 14.205540470778942, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 391, train_loss = 14.200615085661411, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 392, train_loss = 14.188147362321615, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 393, train_loss = 14.19004401192069, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 394, train_loss = 14.177256821654737, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 395, train_loss = 14.17754836473614, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 396, train_loss = 14.163693930953741, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 397, train_loss = 14.170124392956495, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 398, train_loss = 14.160474215634167, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 399, train_loss = 14.153668455779552, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 400, train_loss = 14.155624552629888, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 401, train_loss = 14.149096480570734, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 402, train_loss = 14.13407756248489, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 403, train_loss = 14.132718092761934, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 404, train_loss = 14.13792726257816, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 405, train_loss = 14.12195382034406, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 406, train_loss = 14.11573419580236, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 407, train_loss = 14.11109588900581, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 408, train_loss = 14.104381263256073, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 409, train_loss = 14.09933228418231, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 410, train_loss = 14.0949652986601, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 411, train_loss = 14.08963560918346, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 412, train_loss = 14.086418164428324, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 413, train_loss = 14.082632014062256, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 414, train_loss = 14.073018753435463, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 415, train_loss = 14.069053405430168, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 416, train_loss = 14.06461076810956, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 417, train_loss = 14.060875704046339, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 418, train_loss = 14.052572432905436, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 419, train_loss = 14.047248241957277, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 420, train_loss = 14.04723638156429, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 421, train_loss = 14.038143428508192, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 422, train_loss = 14.033507106360048, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 423, train_loss = 14.030698109418154, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 424, train_loss = 14.025953681673855, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 425, train_loss = 14.017270552460104, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 426, train_loss = 14.010715283453465, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 427, train_loss = 14.003768969327211, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 428, train_loss = 13.99903125083074, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 429, train_loss = 13.999416710343212, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 430, train_loss = 13.98870521178469, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 431, train_loss = 13.986185062676668, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 432, train_loss = 13.976472573820502, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 433, train_loss = 13.97709783911705, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 434, train_loss = 13.970126906875521, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 435, train_loss = 13.962484846357256, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 436, train_loss = 13.956552926450968, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 437, train_loss = 13.953234224114567, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 438, train_loss = 13.949654547963291, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 439, train_loss = 13.941290075425059, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 440, train_loss = 13.9454091116786, train_acc = 0.9697251979506288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 441, train_loss = 13.935277646873146, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 442, train_loss = 13.92812030762434, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 443, train_loss = 13.925829868763685, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 444, train_loss = 13.924685148987919, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 445, train_loss = 13.92018742626533, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 446, train_loss = 13.909833960235119, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 447, train_loss = 13.921625728253275, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 448, train_loss = 13.903665613383055, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 449, train_loss = 13.902461498975754, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 450, train_loss = 13.895007409155369, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 451, train_loss = 13.887842702213675, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 452, train_loss = 13.887298434972763, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 453, train_loss = 13.877253446727991, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 454, train_loss = 13.878430190030485, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 455, train_loss = 13.872852475848049, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 456, train_loss = 13.87535493960604, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 457, train_loss = 13.862343959510326, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 458, train_loss = 13.862504951655865, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 459, train_loss = 13.85606241459027, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 460, train_loss = 13.847514048218727, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 461, train_loss = 13.839733425527811, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 462, train_loss = 13.842247237917036, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 463, train_loss = 13.833782786969095, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 464, train_loss = 13.837979964911938, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 465, train_loss = 13.823197145015001, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 466, train_loss = 13.824891814496368, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 467, train_loss = 13.821077553089708, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 468, train_loss = 13.811019758228213, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 469, train_loss = 13.809600391890854, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 470, train_loss = 13.807371032889932, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 471, train_loss = 13.798321874346584, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 472, train_loss = 13.798572208732367, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 473, train_loss = 13.797717295587063, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 474, train_loss = 13.789423997048289, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 475, train_loss = 13.787848059087992, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 476, train_loss = 13.77893827483058, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 477, train_loss = 13.77356531471014, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 478, train_loss = 13.768633297178894, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 479, train_loss = 13.766499988734722, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 480, train_loss = 13.762287133838981, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 481, train_loss = 13.762432458344847, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 482, train_loss = 13.758262568619102, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 483, train_loss = 13.747018819209188, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 484, train_loss = 13.748569313436747, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 485, train_loss = 13.747612657491118, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 486, train_loss = 13.743067903909832, train_acc = 0.9701909641360037\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 487, train_loss = 13.737465269863605, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 488, train_loss = 13.72784943273291, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 489, train_loss = 13.723531369119883, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 490, train_loss = 13.72205150872469, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 491, train_loss = 13.716446744743735, train_acc = 0.9703074056823474\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 492, train_loss = 13.715189427137375, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 493, train_loss = 13.711184506770223, train_acc = 0.9701909641360037\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 494, train_loss = 13.706824825610965, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 495, train_loss = 13.702209779527038, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 496, train_loss = 13.703230369836092, train_acc = 0.9701909641360037\n",
      "test Acc 0.9487895716945997:\n",
      "21th- epoch: 497, train_loss = 13.69571795547381, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 498, train_loss = 13.69262894615531, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "21th- epoch: 499, train_loss = 13.685507430229336, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████                     | 21/30 [3:10:05<1:21:19, 542.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "22th- epoch: 0, train_loss = 133.22568610310555, train_acc = 0.7430135072193759\n",
      "test Acc 0.8663873370577281:\n",
      "22th- epoch: 1, train_loss = 56.289796844124794, train_acc = 0.881578947368421\n",
      "test Acc 0.8947858472998138:\n",
      "22th- epoch: 2, train_loss = 47.66492983698845, train_acc = 0.8981136469492315\n",
      "test Acc 0.9054934823091247:\n",
      "22th- epoch: 3, train_loss = 43.12902471423149, train_acc = 0.9076618537494178\n",
      "test Acc 0.9115456238361266:\n",
      "22th- epoch: 4, train_loss = 40.080603182315826, train_acc = 0.9141825803446669\n",
      "test Acc 0.914804469273743:\n",
      "22th- epoch: 5, train_loss = 37.85172309726477, train_acc = 0.9183744760130415\n",
      "test Acc 0.9194599627560521:\n",
      "22th- epoch: 6, train_loss = 36.094157353043556, train_acc = 0.9211690731252911\n",
      "test Acc 0.9227188081936686:\n",
      "22th- epoch: 7, train_loss = 34.61391193419695, train_acc = 0.9245458779692595\n",
      "test Acc 0.9245810055865922:\n",
      "22th- epoch: 8, train_loss = 33.36697298288345, train_acc = 0.9266418258034467\n",
      "test Acc 0.925512104283054:\n",
      "22th- epoch: 9, train_loss = 32.309352338314056, train_acc = 0.928272007452259\n",
      "test Acc 0.9259776536312849:\n",
      "22th- epoch: 10, train_loss = 31.38666031509638, train_acc = 0.9310666045645086\n",
      "test Acc 0.9259776536312849:\n",
      "22th- epoch: 11, train_loss = 30.57753086835146, train_acc = 0.9325803446669771\n",
      "test Acc 0.925512104283054:\n",
      "22th- epoch: 12, train_loss = 29.859335623681545, train_acc = 0.9342105263157895\n",
      "test Acc 0.925512104283054:\n",
      "22th- epoch: 13, train_loss = 29.250932715833187, train_acc = 0.9365393572426641\n",
      "test Acc 0.9264432029795159:\n",
      "22th- epoch: 14, train_loss = 28.653632409870625, train_acc = 0.9387517466231952\n",
      "test Acc 0.9283054003724395:\n",
      "22th- epoch: 15, train_loss = 28.147186420857906, train_acc = 0.939683278993945\n",
      "test Acc 0.9287709497206704:\n",
      "22th- epoch: 16, train_loss = 27.67441575974226, train_acc = 0.9408476944573824\n",
      "test Acc 0.9287709497206704:\n",
      "22th- epoch: 17, train_loss = 27.24273332953453, train_acc = 0.9417792268281323\n",
      "test Acc 0.9292364990689013:\n",
      "22th- epoch: 18, train_loss = 26.83017524331808, train_acc = 0.9424778761061947\n",
      "test Acc 0.9297020484171322:\n",
      "22th- epoch: 19, train_loss = 26.476813469082117, train_acc = 0.9428272007452259\n",
      "test Acc 0.9297020484171322:\n",
      "22th- epoch: 20, train_loss = 26.12910395860672, train_acc = 0.9430600838379134\n",
      "test Acc 0.931098696461825:\n",
      "22th- epoch: 21, train_loss = 25.818670514971018, train_acc = 0.9437587331159758\n",
      "test Acc 0.9315642458100558:\n",
      "22th- epoch: 22, train_loss = 25.515308763831854, train_acc = 0.944108057755007\n",
      "test Acc 0.9315642458100558:\n",
      "22th- epoch: 23, train_loss = 25.24107461795211, train_acc = 0.9445738239403819\n",
      "test Acc 0.9324953445065177:\n",
      "22th- epoch: 24, train_loss = 24.977294895797968, train_acc = 0.9449231485794132\n",
      "test Acc 0.9324953445065177:\n",
      "22th- epoch: 25, train_loss = 24.734038077294827, train_acc = 0.945854680950163\n",
      "test Acc 0.9320297951582868:\n",
      "22th- epoch: 26, train_loss = 24.49686088785529, train_acc = 0.9464368886818817\n",
      "test Acc 0.9320297951582868:\n",
      "22th- epoch: 27, train_loss = 24.289109755307436, train_acc = 0.9470190964136004\n",
      "test Acc 0.9324953445065177:\n",
      "22th- epoch: 28, train_loss = 24.06576831638813, train_acc = 0.9476013041453191\n",
      "test Acc 0.9324953445065177:\n",
      "22th- epoch: 29, train_loss = 23.851121481508017, train_acc = 0.9477177456916628\n",
      "test Acc 0.9329608938547486:\n",
      "22th- epoch: 30, train_loss = 23.661016404628754, train_acc = 0.948067070330694\n",
      "test Acc 0.9334264432029795:\n",
      "22th- epoch: 31, train_loss = 23.4872627556324, train_acc = 0.9484163949697252\n",
      "test Acc 0.9338919925512105:\n",
      "22th- epoch: 32, train_loss = 23.287327628582716, train_acc = 0.9482999534233815\n",
      "test Acc 0.9338919925512105:\n",
      "22th- epoch: 33, train_loss = 23.118888307362795, train_acc = 0.9493479273404751\n",
      "test Acc 0.9348230912476723:\n",
      "22th- epoch: 34, train_loss = 22.958533629775047, train_acc = 0.9496972519795063\n",
      "test Acc 0.9352886405959032:\n",
      "22th- epoch: 35, train_loss = 22.795203860849142, train_acc = 0.9501630181648812\n",
      "test Acc 0.9357541899441341:\n",
      "22th- epoch: 36, train_loss = 22.65592673420906, train_acc = 0.9505123428039124\n",
      "test Acc 0.9366852886405959:\n",
      "22th- epoch: 37, train_loss = 22.51922530680895, train_acc = 0.9506287843502562\n",
      "test Acc 0.936219739292365:\n",
      "22th- epoch: 38, train_loss = 22.372250884771347, train_acc = 0.9508616674429436\n",
      "test Acc 0.9366852886405959:\n",
      "22th- epoch: 39, train_loss = 22.234439462423325, train_acc = 0.9514438751746623\n",
      "test Acc 0.936219739292365:\n",
      "22th- epoch: 40, train_loss = 22.108479909598827, train_acc = 0.9512109920819748\n",
      "test Acc 0.9366852886405959:\n",
      "22th- epoch: 41, train_loss = 21.99402655288577, train_acc = 0.951560316721006\n",
      "test Acc 0.9366852886405959:\n",
      "22th- epoch: 42, train_loss = 21.864440243691206, train_acc = 0.951560316721006\n",
      "test Acc 0.9366852886405959:\n",
      "22th- epoch: 43, train_loss = 21.74087857082486, train_acc = 0.9519096413600373\n",
      "test Acc 0.9376163873370578:\n",
      "22th- epoch: 44, train_loss = 21.628532245755196, train_acc = 0.9521425244527247\n",
      "test Acc 0.9371508379888268:\n",
      "22th- epoch: 45, train_loss = 21.52125145494938, train_acc = 0.9523754075454122\n",
      "test Acc 0.9371508379888268:\n",
      "22th- epoch: 46, train_loss = 21.404546037316322, train_acc = 0.9526082906380997\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 47, train_loss = 21.310225121676922, train_acc = 0.9527247321844434\n",
      "test Acc 0.9371508379888268:\n",
      "22th- epoch: 48, train_loss = 21.212148915976286, train_acc = 0.9526082906380997\n",
      "test Acc 0.9376163873370578:\n",
      "22th- epoch: 49, train_loss = 21.117305178195238, train_acc = 0.9529576152771309\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 50, train_loss = 21.031147114932537, train_acc = 0.9529576152771309\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 51, train_loss = 20.93177855014801, train_acc = 0.9531904983698184\n",
      "test Acc 0.9385474860335196:\n",
      "22th- epoch: 52, train_loss = 20.84461634233594, train_acc = 0.9533069399161621\n",
      "test Acc 0.9390130353817505:\n",
      "22th- epoch: 53, train_loss = 20.75183630734682, train_acc = 0.9537727061015371\n",
      "test Acc 0.9390130353817505:\n",
      "22th- epoch: 54, train_loss = 20.677501011639833, train_acc = 0.9537727061015371\n",
      "test Acc 0.9394785847299814:\n",
      "22th- epoch: 55, train_loss = 20.588419888168573, train_acc = 0.9541220307405682\n",
      "test Acc 0.9394785847299814:\n",
      "22th- epoch: 56, train_loss = 20.519172202795744, train_acc = 0.9545877969259432\n",
      "test Acc 0.9399441340782123:\n",
      "22th- epoch: 57, train_loss = 20.421036064624786, train_acc = 0.9542384722869119\n",
      "test Acc 0.9399441340782123:\n",
      "22th- epoch: 58, train_loss = 20.34414852038026, train_acc = 0.9544713553795995\n",
      "test Acc 0.9404096834264432:\n",
      "22th- epoch: 59, train_loss = 20.26249836012721, train_acc = 0.9545877969259432\n",
      "test Acc 0.9408752327746741:\n",
      "22th- epoch: 60, train_loss = 20.194133806973696, train_acc = 0.9544713553795995\n",
      "test Acc 0.9408752327746741:\n",
      "22th- epoch: 61, train_loss = 20.12365186959505, train_acc = 0.9548206800186306\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 62, train_loss = 20.05329229310155, train_acc = 0.9551700046576619\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 63, train_loss = 19.98769987747073, train_acc = 0.9552864462040056\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 64, train_loss = 19.918529223650694, train_acc = 0.9554028877503493\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 65, train_loss = 19.848378404974937, train_acc = 0.9554028877503493\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 66, train_loss = 19.791101813316345, train_acc = 0.955519329296693\n",
      "test Acc 0.9418063314711359:\n",
      "22th- epoch: 67, train_loss = 19.7380615696311, train_acc = 0.955519329296693\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 68, train_loss = 19.652319982647896, train_acc = 0.9556357708430367\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 69, train_loss = 19.600254897028208, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 70, train_loss = 19.533289950340986, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 71, train_loss = 19.473741974681616, train_acc = 0.955985095482068\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 72, train_loss = 19.413858046755195, train_acc = 0.955985095482068\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 73, train_loss = 19.373621206730604, train_acc = 0.956450861667443\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 74, train_loss = 19.300846233963966, train_acc = 0.9563344201210993\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 75, train_loss = 19.246014684438705, train_acc = 0.956450861667443\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 76, train_loss = 19.195709383115172, train_acc = 0.956450861667443\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 77, train_loss = 19.150763815268874, train_acc = 0.9565673032137867\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 78, train_loss = 19.100068474188447, train_acc = 0.9566837447601304\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 79, train_loss = 19.043918998911977, train_acc = 0.9569166278528178\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 80, train_loss = 18.98941366188228, train_acc = 0.9569166278528178\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 81, train_loss = 18.942464884370565, train_acc = 0.9570330693991617\n",
      "test Acc 0.9418063314711359:\n",
      "22th- epoch: 82, train_loss = 18.893218306824565, train_acc = 0.9571495109455054\n",
      "test Acc 0.9422718808193669:\n",
      "22th- epoch: 83, train_loss = 18.8471863809973, train_acc = 0.9570330693991617\n",
      "test Acc 0.9418063314711359:\n",
      "22th- epoch: 84, train_loss = 18.814414251595736, train_acc = 0.9570330693991617\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 85, train_loss = 18.749416954815388, train_acc = 0.9574988355845365\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 86, train_loss = 18.708360478281975, train_acc = 0.9576152771308803\n",
      "test Acc 0.9418063314711359:\n",
      "22th- epoch: 87, train_loss = 18.66071347333491, train_acc = 0.9574988355845365\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 88, train_loss = 18.630455082282424, train_acc = 0.9574988355845365\n",
      "test Acc 0.9422718808193669:\n",
      "22th- epoch: 89, train_loss = 18.56395268253982, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 90, train_loss = 18.546046946197748, train_acc = 0.9577317186772241\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 91, train_loss = 18.497641323134303, train_acc = 0.9581974848625989\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 92, train_loss = 18.442870788276196, train_acc = 0.9581974848625989\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 93, train_loss = 18.408776653930545, train_acc = 0.9580810433162552\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 94, train_loss = 18.376730704680085, train_acc = 0.9580810433162552\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 95, train_loss = 18.33488186635077, train_acc = 0.9583139264089428\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 96, train_loss = 18.291210697963834, train_acc = 0.9580810433162552\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 97, train_loss = 18.246712224557996, train_acc = 0.9583139264089428\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 98, train_loss = 18.221461618319154, train_acc = 0.9584303679552865\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 99, train_loss = 18.16957033611834, train_acc = 0.9584303679552865\n",
      "test Acc 0.9422718808193669:\n",
      "22th- epoch: 100, train_loss = 18.144958132877946, train_acc = 0.9584303679552865\n",
      "test Acc 0.9436685288640596:\n",
      "22th- epoch: 101, train_loss = 18.10524994134903, train_acc = 0.9584303679552865\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 102, train_loss = 18.079874409362674, train_acc = 0.9591290172333489\n",
      "test Acc 0.9436685288640596:\n",
      "22th- epoch: 103, train_loss = 18.041480721905828, train_acc = 0.9591290172333489\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 104, train_loss = 18.00910748168826, train_acc = 0.9591290172333489\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 105, train_loss = 17.981761192902923, train_acc = 0.9592454587796926\n",
      "test Acc 0.9436685288640596:\n",
      "22th- epoch: 106, train_loss = 17.94025948084891, train_acc = 0.9592454587796926\n",
      "test Acc 0.9436685288640596:\n",
      "22th- epoch: 107, train_loss = 17.90749929845333, train_acc = 0.9597112249650676\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 108, train_loss = 17.867259105667472, train_acc = 0.9597112249650676\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 109, train_loss = 17.82370669580996, train_acc = 0.9597112249650676\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 110, train_loss = 17.79112938977778, train_acc = 0.9595947834187238\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 111, train_loss = 17.770771134644747, train_acc = 0.9595947834187238\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 112, train_loss = 17.74874184280634, train_acc = 0.9595947834187238\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 113, train_loss = 17.70616747252643, train_acc = 0.9598276665114113\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 114, train_loss = 17.68395852483809, train_acc = 0.9598276665114113\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 115, train_loss = 17.644112104550004, train_acc = 0.9600605496040987\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 116, train_loss = 17.62356954999268, train_acc = 0.959944108057755\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 117, train_loss = 17.584292747080326, train_acc = 0.959944108057755\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 118, train_loss = 17.556792898103595, train_acc = 0.9601769911504425\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 119, train_loss = 17.52002244628966, train_acc = 0.959944108057755\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 120, train_loss = 17.506649939343333, train_acc = 0.9601769911504425\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 121, train_loss = 17.463587002828717, train_acc = 0.9601769911504425\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 122, train_loss = 17.43662422709167, train_acc = 0.96040987424313\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 123, train_loss = 17.41347825527191, train_acc = 0.96040987424313\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 124, train_loss = 17.391318639740348, train_acc = 0.9605263157894737\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 125, train_loss = 17.35182866640389, train_acc = 0.9605263157894737\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 126, train_loss = 17.33918510377407, train_acc = 0.9608756404285049\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 127, train_loss = 17.311161985620856, train_acc = 0.9606427573358174\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 128, train_loss = 17.286932507529855, train_acc = 0.9606427573358174\n",
      "test Acc 0.9427374301675978:\n",
      "22th- epoch: 129, train_loss = 17.26437334343791, train_acc = 0.9605263157894737\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 130, train_loss = 17.227501993998885, train_acc = 0.9605263157894737\n",
      "test Acc 0.9432029795158287:\n",
      "22th- epoch: 131, train_loss = 17.201821073889732, train_acc = 0.9607591988821611\n",
      "test Acc 0.9436685288640596:\n",
      "22th- epoch: 132, train_loss = 17.173911778256297, train_acc = 0.9608756404285049\n",
      "test Acc 0.9436685288640596:\n",
      "22th- epoch: 133, train_loss = 17.147374151274562, train_acc = 0.9608756404285049\n",
      "test Acc 0.9436685288640596:\n",
      "22th- epoch: 134, train_loss = 17.14953044988215, train_acc = 0.9612249650675361\n",
      "test Acc 0.9441340782122905:\n",
      "22th- epoch: 135, train_loss = 17.1052332110703, train_acc = 0.9613414066138798\n",
      "test Acc 0.9436685288640596:\n",
      "22th- epoch: 136, train_loss = 17.073158914223313, train_acc = 0.9619236143455985\n",
      "test Acc 0.9441340782122905:\n",
      "22th- epoch: 137, train_loss = 17.053716199472547, train_acc = 0.9614578481602236\n",
      "test Acc 0.9441340782122905:\n",
      "22th- epoch: 138, train_loss = 17.034382827579975, train_acc = 0.9618071727992548\n",
      "test Acc 0.9441340782122905:\n",
      "22th- epoch: 139, train_loss = 17.0077222622931, train_acc = 0.9613414066138798\n",
      "test Acc 0.9441340782122905:\n",
      "22th- epoch: 140, train_loss = 16.987048968672752, train_acc = 0.9619236143455985\n",
      "test Acc 0.9445996275605214:\n",
      "22th- epoch: 141, train_loss = 16.960784826427698, train_acc = 0.9619236143455985\n",
      "test Acc 0.9441340782122905:\n",
      "22th- epoch: 142, train_loss = 16.940705763176084, train_acc = 0.9615742897065673\n",
      "test Acc 0.9445996275605214:\n",
      "22th- epoch: 143, train_loss = 16.91666200570762, train_acc = 0.9618071727992548\n",
      "test Acc 0.9445996275605214:\n",
      "22th- epoch: 144, train_loss = 16.893381103873253, train_acc = 0.9619236143455985\n",
      "test Acc 0.9441340782122905:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 145, train_loss = 16.883248263970017, train_acc = 0.961690731252911\n",
      "test Acc 0.9450651769087524:\n",
      "22th- epoch: 146, train_loss = 16.85499901883304, train_acc = 0.9618071727992548\n",
      "test Acc 0.9445996275605214:\n",
      "22th- epoch: 147, train_loss = 16.850221613422036, train_acc = 0.9619236143455985\n",
      "test Acc 0.9450651769087524:\n",
      "22th- epoch: 148, train_loss = 16.804639441892505, train_acc = 0.962156497438286\n",
      "test Acc 0.9445996275605214:\n",
      "22th- epoch: 149, train_loss = 16.769400734454393, train_acc = 0.9620400558919422\n",
      "test Acc 0.9450651769087524:\n",
      "22th- epoch: 150, train_loss = 16.77832391113043, train_acc = 0.9623893805309734\n",
      "test Acc 0.9450651769087524:\n",
      "22th- epoch: 151, train_loss = 16.75160658918321, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "22th- epoch: 152, train_loss = 16.727989392355084, train_acc = 0.962156497438286\n",
      "test Acc 0.9441340782122905:\n",
      "22th- epoch: 153, train_loss = 16.71132661961019, train_acc = 0.9622729389846297\n",
      "test Acc 0.9445996275605214:\n",
      "22th- epoch: 154, train_loss = 16.688800053671002, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "22th- epoch: 155, train_loss = 16.66811134852469, train_acc = 0.9625058220773172\n",
      "test Acc 0.9445996275605214:\n",
      "22th- epoch: 156, train_loss = 16.665603516623378, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 157, train_loss = 16.637183552607894, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "22th- epoch: 158, train_loss = 16.628163415938616, train_acc = 0.9627387051700047\n",
      "test Acc 0.9450651769087524:\n",
      "22th- epoch: 159, train_loss = 16.596926430240273, train_acc = 0.9625058220773172\n",
      "test Acc 0.9450651769087524:\n",
      "22th- epoch: 160, train_loss = 16.572326662018895, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "22th- epoch: 161, train_loss = 16.568535102531314, train_acc = 0.9627387051700047\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 162, train_loss = 16.54568251222372, train_acc = 0.9628551467163484\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 163, train_loss = 16.52629129588604, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "22th- epoch: 164, train_loss = 16.497209830209613, train_acc = 0.9628551467163484\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 165, train_loss = 16.485619369894266, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "22th- epoch: 166, train_loss = 16.47893311828375, train_acc = 0.9628551467163484\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 167, train_loss = 16.43437359854579, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "22th- epoch: 168, train_loss = 16.44131795875728, train_acc = 0.9635537959944108\n",
      "test Acc 0.9455307262569832:\n",
      "22th- epoch: 169, train_loss = 16.42478007823229, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 170, train_loss = 16.392444249242544, train_acc = 0.9629715882626921\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 171, train_loss = 16.381033686921, train_acc = 0.9636702375407545\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 172, train_loss = 16.359693760052323, train_acc = 0.9630880298090359\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 173, train_loss = 16.349337777122855, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "22th- epoch: 174, train_loss = 16.331289764493704, train_acc = 0.9640195621797858\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 175, train_loss = 16.30242331698537, train_acc = 0.963903120633442\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 176, train_loss = 16.289555253461003, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 177, train_loss = 16.295088469982147, train_acc = 0.9634373544480671\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 178, train_loss = 16.259568409994245, train_acc = 0.963903120633442\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 179, train_loss = 16.24596039019525, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 180, train_loss = 16.239952640607953, train_acc = 0.9633209129017233\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 181, train_loss = 16.230690153315663, train_acc = 0.9640195621797858\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 182, train_loss = 16.209615932777524, train_acc = 0.963903120633442\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 183, train_loss = 16.177505673840642, train_acc = 0.9640195621797858\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 184, train_loss = 16.171848237514496, train_acc = 0.963903120633442\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 185, train_loss = 16.140534350648522, train_acc = 0.9642524452724732\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 186, train_loss = 16.134072419255972, train_acc = 0.9640195621797858\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 187, train_loss = 16.12032183073461, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 188, train_loss = 16.111883714795113, train_acc = 0.9642524452724732\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 189, train_loss = 16.077798502519727, train_acc = 0.9643688868188169\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 190, train_loss = 16.06887648999691, train_acc = 0.9643688868188169\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 191, train_loss = 16.05566774494946, train_acc = 0.9642524452724732\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 192, train_loss = 16.04007219336927, train_acc = 0.9643688868188169\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 193, train_loss = 16.02492026425898, train_acc = 0.9644853283651607\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 194, train_loss = 16.01113636791706, train_acc = 0.9647182114578482\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 195, train_loss = 15.997566798701882, train_acc = 0.9647182114578482\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 196, train_loss = 15.992902165278792, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 197, train_loss = 15.977623658254743, train_acc = 0.9641360037261295\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 198, train_loss = 15.962045259773731, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 199, train_loss = 15.940376905724406, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 200, train_loss = 15.94108016230166, train_acc = 0.9648346530041919\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 201, train_loss = 15.920724907889962, train_acc = 0.9648346530041919\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 202, train_loss = 15.925918027758598, train_acc = 0.9643688868188169\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 203, train_loss = 15.88768251426518, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 204, train_loss = 15.867865895852447, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 205, train_loss = 15.856267938390374, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 206, train_loss = 15.842034064233303, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 207, train_loss = 15.828007076866925, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 208, train_loss = 15.813454192131758, train_acc = 0.9647182114578482\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 209, train_loss = 15.807417383417487, train_acc = 0.9650675360968793\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 210, train_loss = 15.804921317845583, train_acc = 0.9650675360968793\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 211, train_loss = 15.78448750730604, train_acc = 0.9650675360968793\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 212, train_loss = 15.75701135583222, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 213, train_loss = 15.7701285360381, train_acc = 0.9650675360968793\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 214, train_loss = 15.746808030642569, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 215, train_loss = 15.735357977449894, train_acc = 0.9651839776432231\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 216, train_loss = 15.720743345096707, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 217, train_loss = 15.70058799162507, train_acc = 0.9650675360968793\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 218, train_loss = 15.69651327189058, train_acc = 0.9653004191895669\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 219, train_loss = 15.684109762310982, train_acc = 0.9650675360968793\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 220, train_loss = 15.67493698373437, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 221, train_loss = 15.648744792677462, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 222, train_loss = 15.645031807012856, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 223, train_loss = 15.631986825726926, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 224, train_loss = 15.629696269519627, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 225, train_loss = 15.619320396333933, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 226, train_loss = 15.593271962366998, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 227, train_loss = 15.598696082830429, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 228, train_loss = 15.587906911037862, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 229, train_loss = 15.55275106523186, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 230, train_loss = 15.56256414577365, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 231, train_loss = 15.529024321585894, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 232, train_loss = 15.541022927500308, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 233, train_loss = 15.522626645863056, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 234, train_loss = 15.516612521372736, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 235, train_loss = 15.493388123810291, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 236, train_loss = 15.497912679798901, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 237, train_loss = 15.471641283482313, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 238, train_loss = 15.464934182353318, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 239, train_loss = 15.461806452833116, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 240, train_loss = 15.440616899169981, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 241, train_loss = 15.441063176840544, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 242, train_loss = 15.434073131531477, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 243, train_loss = 15.418671536259353, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 244, train_loss = 15.397504762746394, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 245, train_loss = 15.392060179263353, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 246, train_loss = 15.379637188278139, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 247, train_loss = 15.384486702270806, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 248, train_loss = 15.37624592334032, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 249, train_loss = 15.344540799967945, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 250, train_loss = 15.342294353991747, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 251, train_loss = 15.334211735986173, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 252, train_loss = 15.329158075153828, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 253, train_loss = 15.307039055041969, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 254, train_loss = 15.297947677783668, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 255, train_loss = 15.30118202418089, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 256, train_loss = 15.286288206465542, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 257, train_loss = 15.269857387058437, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 258, train_loss = 15.277683011256158, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 259, train_loss = 15.253139086999, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 260, train_loss = 15.25071171298623, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 261, train_loss = 15.24742366373539, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 262, train_loss = 15.243102109991014, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 263, train_loss = 15.221449707634747, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 264, train_loss = 15.219860992394388, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 265, train_loss = 15.204628114588559, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 266, train_loss = 15.177998028695583, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 267, train_loss = 15.180335968732834, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 268, train_loss = 15.185037319548428, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 269, train_loss = 15.158465831540525, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 270, train_loss = 15.141983397305012, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 271, train_loss = 15.148398491553962, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 272, train_loss = 15.127872493118048, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 273, train_loss = 15.118939391337335, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 274, train_loss = 15.117255947552621, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 275, train_loss = 15.109259940683842, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 276, train_loss = 15.089692816138268, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 277, train_loss = 15.086415741592646, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 278, train_loss = 15.082058367319405, train_acc = 0.9664648346530041\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 279, train_loss = 15.0831833248958, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 280, train_loss = 15.07183478679508, train_acc = 0.9664648346530041\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 281, train_loss = 15.057186253368855, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 282, train_loss = 15.046849429607391, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 283, train_loss = 15.04054097738117, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 284, train_loss = 15.030402953736484, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 285, train_loss = 15.026117295958102, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 286, train_loss = 15.015091671608388, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 287, train_loss = 15.009592052549124, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 288, train_loss = 14.996983437798917, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 289, train_loss = 14.989634991623461, train_acc = 0.9666977177456917\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 290, train_loss = 14.975759978406131, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 291, train_loss = 14.980483400635421, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 292, train_loss = 14.956258226186037, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 293, train_loss = 14.957335873506963, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 294, train_loss = 14.94596682395786, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 295, train_loss = 14.93087499216199, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 296, train_loss = 14.932758208364248, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 297, train_loss = 14.923568564467132, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 298, train_loss = 14.913986663334072, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 299, train_loss = 14.917296814732254, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 300, train_loss = 14.90176048874855, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 301, train_loss = 14.904123671352863, train_acc = 0.9670470423847228\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 302, train_loss = 14.88723994512111, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 303, train_loss = 14.870463100261986, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 304, train_loss = 14.875295418314636, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 305, train_loss = 14.862501586787403, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 306, train_loss = 14.873981242068112, train_acc = 0.9668141592920354\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 307, train_loss = 14.85292677488178, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 308, train_loss = 14.836930521763861, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 309, train_loss = 14.829503032378852, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 310, train_loss = 14.817525795660913, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 311, train_loss = 14.81437621731311, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 312, train_loss = 14.809978186152875, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 313, train_loss = 14.817006166093051, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 314, train_loss = 14.791870310902596, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 315, train_loss = 14.793149375356734, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 316, train_loss = 14.777946990914643, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 317, train_loss = 14.772899068892002, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 318, train_loss = 14.765752392821014, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 319, train_loss = 14.761367031373084, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 320, train_loss = 14.75554768461734, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 321, train_loss = 14.741945412941277, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 322, train_loss = 14.728704468347132, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 323, train_loss = 14.742779887281358, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 324, train_loss = 14.728352916426957, train_acc = 0.9671634839310667\n",
      "test Acc 0.9487895716945997:\n",
      "22th- epoch: 325, train_loss = 14.707426466979086, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 326, train_loss = 14.708673792891204, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 327, train_loss = 14.695048880763352, train_acc = 0.9675128085700978\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 328, train_loss = 14.693961560726166, train_acc = 0.9673963670237541\n",
      "test Acc 0.9464618249534451:\n",
      "22th- epoch: 329, train_loss = 14.685492843389511, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 330, train_loss = 14.679997943341732, train_acc = 0.9675128085700978\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 331, train_loss = 14.669912215322256, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 332, train_loss = 14.661222609691322, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 333, train_loss = 14.66395369824022, train_acc = 0.9675128085700978\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 334, train_loss = 14.645539984107018, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 335, train_loss = 14.64771693199873, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 336, train_loss = 14.636043798178434, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 337, train_loss = 14.638424192555249, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "22th- epoch: 338, train_loss = 14.626523655839264, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 339, train_loss = 14.620392658747733, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 340, train_loss = 14.627990604378283, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 341, train_loss = 14.613388241268694, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 342, train_loss = 14.601112357340753, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 343, train_loss = 14.600035924464464, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 344, train_loss = 14.593884602189064, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 345, train_loss = 14.575660612434149, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 346, train_loss = 14.587048925459385, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 347, train_loss = 14.576347631402314, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 348, train_loss = 14.561361742205918, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 349, train_loss = 14.55822501797229, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 350, train_loss = 14.549388155341148, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 351, train_loss = 14.544445847161114, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 352, train_loss = 14.541202023625374, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 353, train_loss = 14.531365073285997, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 354, train_loss = 14.525588493794203, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 355, train_loss = 14.517294344492257, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 356, train_loss = 14.528209186159074, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 357, train_loss = 14.499676045961678, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 358, train_loss = 14.507093665190041, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 359, train_loss = 14.495602797716856, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 360, train_loss = 14.489696045406163, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 361, train_loss = 14.491638023406267, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 362, train_loss = 14.475160963833332, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 363, train_loss = 14.477131936699152, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 364, train_loss = 14.465051081031561, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 365, train_loss = 14.462446991354227, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 366, train_loss = 14.45554177928716, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 367, train_loss = 14.451134192757308, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 368, train_loss = 14.442053134553134, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 369, train_loss = 14.427324649877846, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 370, train_loss = 14.426795899868011, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 371, train_loss = 14.417570429854095, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 372, train_loss = 14.409439481794834, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 373, train_loss = 14.415889631025493, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 374, train_loss = 14.398288648575544, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 375, train_loss = 14.396824762225151, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 376, train_loss = 14.399086989462376, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 377, train_loss = 14.377890776842833, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 378, train_loss = 14.377670128829777, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 379, train_loss = 14.382741416804492, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 380, train_loss = 14.37698945403099, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 381, train_loss = 14.361108875833452, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 382, train_loss = 14.35867464542389, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 383, train_loss = 14.35620893817395, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 384, train_loss = 14.352368020452559, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 385, train_loss = 14.34224143344909, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 386, train_loss = 14.33837525639683, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 387, train_loss = 14.330576717853546, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 388, train_loss = 14.325319464318454, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 389, train_loss = 14.317818954586983, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 390, train_loss = 14.320858023129404, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 391, train_loss = 14.303900595754385, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 392, train_loss = 14.308453250676394, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 393, train_loss = 14.29007123876363, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 394, train_loss = 14.280799637548625, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 395, train_loss = 14.28990339487791, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 396, train_loss = 14.279307924211025, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 397, train_loss = 14.279337889514863, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 398, train_loss = 14.268733310513198, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 399, train_loss = 14.257345688529313, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 400, train_loss = 14.255738177336752, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 401, train_loss = 14.254151925444603, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 402, train_loss = 14.241045129485428, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 403, train_loss = 14.253076408058405, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 404, train_loss = 14.24994274135679, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 405, train_loss = 14.232448800466955, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 406, train_loss = 14.228433794341981, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 407, train_loss = 14.216487602330744, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 408, train_loss = 14.215956710278988, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 409, train_loss = 14.20804312825203, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 410, train_loss = 14.209903094917536, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 411, train_loss = 14.205900426022708, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 412, train_loss = 14.191996357403696, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 413, train_loss = 14.193076458759606, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 414, train_loss = 14.186889878474176, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 415, train_loss = 14.18439768254757, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 416, train_loss = 14.172672216780484, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 417, train_loss = 14.16847316455096, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 418, train_loss = 14.160118096508086, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 419, train_loss = 14.155189742334187, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 420, train_loss = 14.14989732671529, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 421, train_loss = 14.143566589802504, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 422, train_loss = 14.133258000947535, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 423, train_loss = 14.132878712378442, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 424, train_loss = 14.121372359804809, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 425, train_loss = 14.120363579131663, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 426, train_loss = 14.128028340637684, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 427, train_loss = 14.119454726576805, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 428, train_loss = 14.106152427382767, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 429, train_loss = 14.096448292024434, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 430, train_loss = 14.098536926321685, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 431, train_loss = 14.089856646955013, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 432, train_loss = 14.089121449738741, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 433, train_loss = 14.084411017596722, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 434, train_loss = 14.076621457003057, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 435, train_loss = 14.074485807679594, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 436, train_loss = 14.0671620182693, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 437, train_loss = 14.061822429299355, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 438, train_loss = 14.056824223138392, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 439, train_loss = 14.053833734244108, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 440, train_loss = 14.050006247125566, train_acc = 0.9691429902189101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 441, train_loss = 14.038272007368505, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 442, train_loss = 14.039077155292034, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 443, train_loss = 14.038365174084902, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 444, train_loss = 14.031206118874252, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 445, train_loss = 14.018884946592152, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 446, train_loss = 14.019570473581553, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 447, train_loss = 14.018724702298641, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 448, train_loss = 14.007078927010298, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 449, train_loss = 14.017195398919284, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 450, train_loss = 13.994891222566366, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 451, train_loss = 13.995468760840595, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 452, train_loss = 13.994460080750287, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 453, train_loss = 13.982000383548439, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 454, train_loss = 13.987452407367527, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 455, train_loss = 13.985416074283421, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 456, train_loss = 13.974565893411636, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 457, train_loss = 13.97022432461381, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 458, train_loss = 13.967439441941679, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 459, train_loss = 13.96007614582777, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 460, train_loss = 13.961901216767728, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 461, train_loss = 13.950847337953746, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 462, train_loss = 13.949781783856452, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 463, train_loss = 13.938786529935896, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 464, train_loss = 13.940729687921703, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 465, train_loss = 13.928031382150948, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 466, train_loss = 13.9331442033872, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 467, train_loss = 13.926961857825518, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 468, train_loss = 13.92407888546586, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 469, train_loss = 13.923521789722145, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 470, train_loss = 13.913100954145193, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 471, train_loss = 13.909957099705935, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 472, train_loss = 13.89740903954953, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 473, train_loss = 13.913034264929593, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 474, train_loss = 13.894034083001316, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 475, train_loss = 13.891405624337494, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 476, train_loss = 13.886180404573679, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 477, train_loss = 13.887237786315382, train_acc = 0.9694923148579413\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 478, train_loss = 13.88155745062977, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 479, train_loss = 13.875520310364664, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 480, train_loss = 13.876491052098572, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 481, train_loss = 13.865068808197975, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 482, train_loss = 13.866792847402394, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 483, train_loss = 13.858584806323051, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 484, train_loss = 13.861464238725603, train_acc = 0.9694923148579413\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 485, train_loss = 13.848928537219763, train_acc = 0.9694923148579413\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 486, train_loss = 13.841672338545322, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 487, train_loss = 13.841075076721609, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 488, train_loss = 13.837107688188553, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 489, train_loss = 13.828697726130486, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 490, train_loss = 13.828975644893944, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 491, train_loss = 13.821859034709632, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 492, train_loss = 13.826429127715528, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "22th- epoch: 493, train_loss = 13.82032844889909, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 494, train_loss = 13.812242514453828, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 495, train_loss = 13.802272524684668, train_acc = 0.9694923148579413\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 496, train_loss = 13.813688916154206, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 497, train_loss = 13.802975608967245, train_acc = 0.9694923148579413\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 498, train_loss = 13.794588037766516, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "22th- epoch: 499, train_loss = 13.795688365586102, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████████████████████████████████████████████████▎                  | 22/30 [3:19:08<1:12:17, 542.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "23th- epoch: 0, train_loss = 129.01631951332092, train_acc = 0.7564042850489054\n",
      "test Acc 0.8342644320297952:\n",
      "23th- epoch: 1, train_loss = 62.09029261767864, train_acc = 0.8699347927340475\n",
      "test Acc 0.861731843575419:\n",
      "23th- epoch: 2, train_loss = 52.252997785806656, train_acc = 0.8872845831392641\n",
      "test Acc 0.8803538175046555:\n",
      "23th- epoch: 3, train_loss = 46.992271453142166, train_acc = 0.8989287377736377\n",
      "test Acc 0.8878026070763501:\n",
      "23th- epoch: 4, train_loss = 43.51921145617962, train_acc = 0.9068467629250117\n",
      "test Acc 0.904562383612663:\n",
      "23th- epoch: 5, train_loss = 40.98732936382294, train_acc = 0.911504424778761\n",
      "test Acc 0.9120111731843575:\n",
      "23th- epoch: 6, train_loss = 39.00532902777195, train_acc = 0.9167442943642291\n",
      "test Acc 0.9143389199255121:\n",
      "23th- epoch: 7, train_loss = 37.38586784899235, train_acc = 0.9194224499301351\n",
      "test Acc 0.9180633147113594:\n",
      "23th- epoch: 8, train_loss = 36.02001670002937, train_acc = 0.9236143455985095\n",
      "test Acc 0.9199255121042831:\n",
      "23th- epoch: 9, train_loss = 34.83694088459015, train_acc = 0.9258267349790406\n",
      "test Acc 0.9203910614525139:\n",
      "23th- epoch: 10, train_loss = 33.820897564291954, train_acc = 0.9269911504424779\n",
      "test Acc 0.9217877094972067:\n",
      "23th- epoch: 11, train_loss = 32.88710478693247, train_acc = 0.9285048905449464\n",
      "test Acc 0.9227188081936686:\n",
      "23th- epoch: 12, train_loss = 32.08923590183258, train_acc = 0.9303679552864462\n",
      "test Acc 0.9236499068901304:\n",
      "23th- epoch: 13, train_loss = 31.35141333937645, train_acc = 0.9321145784816023\n",
      "test Acc 0.9273743016759777:\n",
      "23th- epoch: 14, train_loss = 30.696919970214367, train_acc = 0.9332789939450395\n",
      "test Acc 0.9297020484171322:\n",
      "23th- epoch: 15, train_loss = 30.09160166233778, train_acc = 0.9344434094084769\n",
      "test Acc 0.9320297951582868:\n",
      "23th- epoch: 16, train_loss = 29.558937780559063, train_acc = 0.935724266418258\n",
      "test Acc 0.9320297951582868:\n",
      "23th- epoch: 17, train_loss = 29.058074921369553, train_acc = 0.9370051234280391\n",
      "test Acc 0.9324953445065177:\n",
      "23th- epoch: 18, train_loss = 28.598051883280277, train_acc = 0.937936655798789\n",
      "test Acc 0.9334264432029795:\n",
      "23th- epoch: 19, train_loss = 28.17684955149889, train_acc = 0.9387517466231952\n",
      "test Acc 0.9329608938547486:\n",
      "23th- epoch: 20, train_loss = 27.786239355802536, train_acc = 0.9397997205402888\n",
      "test Acc 0.9343575418994413:\n",
      "23th- epoch: 21, train_loss = 27.40313921868801, train_acc = 0.9406148113646949\n",
      "test Acc 0.9352886405959032:\n",
      "23th- epoch: 22, train_loss = 27.046149265021086, train_acc = 0.941429902189101\n",
      "test Acc 0.936219739292365:\n",
      "23th- epoch: 23, train_loss = 26.723106767982244, train_acc = 0.9415463437354448\n",
      "test Acc 0.9366852886405959:\n",
      "23th- epoch: 24, train_loss = 26.41657967492938, train_acc = 0.9417792268281323\n",
      "test Acc 0.9371508379888268:\n",
      "23th- epoch: 25, train_loss = 26.13450649380684, train_acc = 0.9429436422915697\n",
      "test Acc 0.9371508379888268:\n",
      "23th- epoch: 26, train_loss = 25.863403916358948, train_acc = 0.9438751746623195\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 27, train_loss = 25.602073214948177, train_acc = 0.9444573823940382\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 28, train_loss = 25.35227568075061, train_acc = 0.9445738239403819\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 29, train_loss = 25.12059958279133, train_acc = 0.9450395901257569\n",
      "test Acc 0.9380819366852886:\n",
      "23th- epoch: 30, train_loss = 24.89152630791068, train_acc = 0.9457382394038193\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 31, train_loss = 24.679893098771572, train_acc = 0.9457382394038193\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 32, train_loss = 24.471167985349894, train_acc = 0.9457382394038193\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 33, train_loss = 24.279441222548485, train_acc = 0.9460875640428504\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 34, train_loss = 24.08451234176755, train_acc = 0.9464368886818817\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 35, train_loss = 23.905817050486803, train_acc = 0.9465533302282254\n",
      "test Acc 0.9380819366852886:\n",
      "23th- epoch: 36, train_loss = 23.73665937408805, train_acc = 0.9466697717745691\n",
      "test Acc 0.9380819366852886:\n",
      "23th- epoch: 37, train_loss = 23.561250656843185, train_acc = 0.9470190964136004\n",
      "test Acc 0.9380819366852886:\n",
      "23th- epoch: 38, train_loss = 23.41008097678423, train_acc = 0.9473684210526315\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 39, train_loss = 23.2497524805367, train_acc = 0.9476013041453191\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 40, train_loss = 23.106969609856606, train_acc = 0.9478341872380065\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 41, train_loss = 22.963520102202892, train_acc = 0.9478341872380065\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 42, train_loss = 22.815095361322165, train_acc = 0.9479506287843502\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 43, train_loss = 22.6756970025599, train_acc = 0.9485328365160689\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 44, train_loss = 22.54745039716363, train_acc = 0.9488821611551002\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 45, train_loss = 22.419934034347534, train_acc = 0.9493479273404751\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 46, train_loss = 22.2947198189795, train_acc = 0.9495808104331626\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 47, train_loss = 22.177946850657463, train_acc = 0.9506287843502562\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 48, train_loss = 22.05308996886015, train_acc = 0.9503959012575687\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 49, train_loss = 21.943136125802994, train_acc = 0.9513274336283186\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 50, train_loss = 21.847262497991323, train_acc = 0.9513274336283186\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 51, train_loss = 21.7374434620142, train_acc = 0.951560316721006\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 52, train_loss = 21.639903713017702, train_acc = 0.9519096413600373\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 53, train_loss = 21.539415940642357, train_acc = 0.9521425244527247\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 54, train_loss = 21.43825563415885, train_acc = 0.952491849091756\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 55, train_loss = 21.351508244872093, train_acc = 0.9526082906380997\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 56, train_loss = 21.269215766340494, train_acc = 0.9530740568234746\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 57, train_loss = 21.17119662091136, train_acc = 0.9531904983698184\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 58, train_loss = 21.077908139675856, train_acc = 0.9534233814625058\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 59, train_loss = 20.993648525327444, train_acc = 0.9534233814625058\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 60, train_loss = 20.912185553461313, train_acc = 0.9535398230088495\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 61, train_loss = 20.82945166155696, train_acc = 0.9537727061015371\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 62, train_loss = 20.744940515607595, train_acc = 0.9537727061015371\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 63, train_loss = 20.673914577811956, train_acc = 0.9540055891942245\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 64, train_loss = 20.585897117853165, train_acc = 0.9541220307405682\n",
      "test Acc 0.9394785847299814:\n",
      "23th- epoch: 65, train_loss = 20.529688749462366, train_acc = 0.9545877969259432\n",
      "test Acc 0.9394785847299814:\n",
      "23th- epoch: 66, train_loss = 20.446222189813852, train_acc = 0.9549371215649743\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 67, train_loss = 20.38003259524703, train_acc = 0.9550535631113182\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 68, train_loss = 20.299442768096924, train_acc = 0.9551700046576619\n",
      "test Acc 0.9394785847299814:\n",
      "23th- epoch: 69, train_loss = 20.22827671840787, train_acc = 0.955519329296693\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 70, train_loss = 20.163312401622534, train_acc = 0.9556357708430367\n",
      "test Acc 0.9390130353817505:\n",
      "23th- epoch: 71, train_loss = 20.101963084191084, train_acc = 0.9557522123893806\n",
      "test Acc 0.9394785847299814:\n",
      "23th- epoch: 72, train_loss = 20.029906541109085, train_acc = 0.9561015370284117\n",
      "test Acc 0.9404096834264432:\n",
      "23th- epoch: 73, train_loss = 19.97512014210224, train_acc = 0.9562179785747554\n",
      "test Acc 0.9404096834264432:\n",
      "23th- epoch: 74, train_loss = 19.904503636062145, train_acc = 0.9562179785747554\n",
      "test Acc 0.9399441340782123:\n",
      "23th- epoch: 75, train_loss = 19.849340863525867, train_acc = 0.9562179785747554\n",
      "test Acc 0.9408752327746741:\n",
      "23th- epoch: 76, train_loss = 19.780691415071487, train_acc = 0.956450861667443\n",
      "test Acc 0.9408752327746741:\n",
      "23th- epoch: 77, train_loss = 19.72764916345477, train_acc = 0.956450861667443\n",
      "test Acc 0.9404096834264432:\n",
      "23th- epoch: 78, train_loss = 19.671537594869733, train_acc = 0.956450861667443\n",
      "test Acc 0.9408752327746741:\n",
      "23th- epoch: 79, train_loss = 19.626452669501305, train_acc = 0.956450861667443\n",
      "test Acc 0.9408752327746741:\n",
      "23th- epoch: 80, train_loss = 19.564766455441713, train_acc = 0.9568001863064741\n",
      "test Acc 0.9413407821229051:\n",
      "23th- epoch: 81, train_loss = 19.504732931032777, train_acc = 0.9569166278528178\n",
      "test Acc 0.9413407821229051:\n",
      "23th- epoch: 82, train_loss = 19.463329633697867, train_acc = 0.9570330693991617\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 83, train_loss = 19.387870959937572, train_acc = 0.9570330693991617\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 84, train_loss = 19.338960772380233, train_acc = 0.9571495109455054\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 85, train_loss = 19.28698386438191, train_acc = 0.9572659524918491\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 86, train_loss = 19.22317566536367, train_acc = 0.9574988355845365\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 87, train_loss = 19.17883443273604, train_acc = 0.9577317186772241\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 88, train_loss = 19.12582646869123, train_acc = 0.9576152771308803\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 89, train_loss = 19.087053690105677, train_acc = 0.9576152771308803\n",
      "test Acc 0.9422718808193669:\n",
      "23th- epoch: 90, train_loss = 19.034345464780927, train_acc = 0.9577317186772241\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 91, train_loss = 18.99316593259573, train_acc = 0.9574988355845365\n",
      "test Acc 0.9418063314711359:\n",
      "23th- epoch: 92, train_loss = 18.93959474004805, train_acc = 0.9578481602235678\n",
      "test Acc 0.9422718808193669:\n",
      "23th- epoch: 93, train_loss = 18.899914717301726, train_acc = 0.9578481602235678\n",
      "test Acc 0.9422718808193669:\n",
      "23th- epoch: 94, train_loss = 18.85743155889213, train_acc = 0.9578481602235678\n",
      "test Acc 0.9422718808193669:\n",
      "23th- epoch: 95, train_loss = 18.814488895237446, train_acc = 0.9581974848625989\n",
      "test Acc 0.9422718808193669:\n",
      "23th- epoch: 96, train_loss = 18.76614019833505, train_acc = 0.9583139264089428\n",
      "test Acc 0.9422718808193669:\n",
      "23th- epoch: 97, train_loss = 18.718965785577893, train_acc = 0.9584303679552865\n",
      "test Acc 0.9422718808193669:\n",
      "23th- epoch: 98, train_loss = 18.679631914943457, train_acc = 0.9585468095016302\n",
      "test Acc 0.9422718808193669:\n",
      "23th- epoch: 99, train_loss = 18.63118921779096, train_acc = 0.9586632510479739\n",
      "test Acc 0.9427374301675978:\n",
      "23th- epoch: 100, train_loss = 18.60007326491177, train_acc = 0.9586632510479739\n",
      "test Acc 0.9422718808193669:\n",
      "23th- epoch: 101, train_loss = 18.55955616571009, train_acc = 0.9587796925943176\n",
      "test Acc 0.9427374301675978:\n",
      "23th- epoch: 102, train_loss = 18.530933232977986, train_acc = 0.9588961341406614\n",
      "test Acc 0.9427374301675978:\n",
      "23th- epoch: 103, train_loss = 18.48611562512815, train_acc = 0.9588961341406614\n",
      "test Acc 0.9427374301675978:\n",
      "23th- epoch: 104, train_loss = 18.456872196868062, train_acc = 0.9588961341406614\n",
      "test Acc 0.9427374301675978:\n",
      "23th- epoch: 105, train_loss = 18.416473699733615, train_acc = 0.9588961341406614\n",
      "test Acc 0.9427374301675978:\n",
      "23th- epoch: 106, train_loss = 18.374741742387414, train_acc = 0.9591290172333489\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 107, train_loss = 18.336550636216998, train_acc = 0.9592454587796926\n",
      "test Acc 0.9427374301675978:\n",
      "23th- epoch: 108, train_loss = 18.30096453242004, train_acc = 0.9592454587796926\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 109, train_loss = 18.25728794746101, train_acc = 0.9593619003260363\n",
      "test Acc 0.9427374301675978:\n",
      "23th- epoch: 110, train_loss = 18.237417344003916, train_acc = 0.95947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 111, train_loss = 18.191447069868445, train_acc = 0.95947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 112, train_loss = 18.16147786565125, train_acc = 0.9595947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 113, train_loss = 18.125624284148216, train_acc = 0.9595947834187238\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 114, train_loss = 18.092205660417676, train_acc = 0.959944108057755\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 115, train_loss = 18.060896582901478, train_acc = 0.959944108057755\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 116, train_loss = 18.032271230593324, train_acc = 0.959944108057755\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 117, train_loss = 17.997953863814473, train_acc = 0.959944108057755\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 118, train_loss = 17.96442510187626, train_acc = 0.959944108057755\n",
      "test Acc 0.9436685288640596:\n",
      "23th- epoch: 119, train_loss = 17.949156120419502, train_acc = 0.9600605496040987\n",
      "test Acc 0.9436685288640596:\n",
      "23th- epoch: 120, train_loss = 17.908936519175768, train_acc = 0.9602934326967862\n",
      "test Acc 0.9441340782122905:\n",
      "23th- epoch: 121, train_loss = 17.876530094072223, train_acc = 0.9602934326967862\n",
      "test Acc 0.9432029795158287:\n",
      "23th- epoch: 122, train_loss = 17.844007113948464, train_acc = 0.9602934326967862\n",
      "test Acc 0.9436685288640596:\n",
      "23th- epoch: 123, train_loss = 17.807744642719626, train_acc = 0.9601769911504425\n",
      "test Acc 0.9436685288640596:\n",
      "23th- epoch: 124, train_loss = 17.782965334132314, train_acc = 0.9602934326967862\n",
      "test Acc 0.9436685288640596:\n",
      "23th- epoch: 125, train_loss = 17.75763333030045, train_acc = 0.9602934326967862\n",
      "test Acc 0.9436685288640596:\n",
      "23th- epoch: 126, train_loss = 17.72288445569575, train_acc = 0.9605263157894737\n",
      "test Acc 0.9436685288640596:\n",
      "23th- epoch: 127, train_loss = 17.6948053073138, train_acc = 0.9606427573358174\n",
      "test Acc 0.9436685288640596:\n",
      "23th- epoch: 128, train_loss = 17.670848382636905, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "23th- epoch: 129, train_loss = 17.643742240965366, train_acc = 0.9606427573358174\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 130, train_loss = 17.62046709097922, train_acc = 0.9607591988821611\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 131, train_loss = 17.59116076491773, train_acc = 0.9608756404285049\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 132, train_loss = 17.555884135887027, train_acc = 0.9609920819748486\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 133, train_loss = 17.533254969865084, train_acc = 0.9609920819748486\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 134, train_loss = 17.503897102549672, train_acc = 0.9608756404285049\n",
      "test Acc 0.9450651769087524:\n",
      "23th- epoch: 135, train_loss = 17.47934440895915, train_acc = 0.9607591988821611\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 136, train_loss = 17.451624175533652, train_acc = 0.9609920819748486\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 137, train_loss = 17.43299688771367, train_acc = 0.9611085235211924\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 138, train_loss = 17.402169017121196, train_acc = 0.9611085235211924\n",
      "test Acc 0.9450651769087524:\n",
      "23th- epoch: 139, train_loss = 17.372772701084614, train_acc = 0.9611085235211924\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 140, train_loss = 17.347779750823975, train_acc = 0.9612249650675361\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 141, train_loss = 17.325850296765566, train_acc = 0.9612249650675361\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 142, train_loss = 17.298263516277075, train_acc = 0.9612249650675361\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 143, train_loss = 17.2751648966223, train_acc = 0.9612249650675361\n",
      "test Acc 0.9450651769087524:\n",
      "23th- epoch: 144, train_loss = 17.256051959469914, train_acc = 0.9614578481602236\n",
      "test Acc 0.9455307262569832:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 145, train_loss = 17.23046671040356, train_acc = 0.9614578481602236\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 146, train_loss = 17.21131880581379, train_acc = 0.9615742897065673\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 147, train_loss = 17.18770349957049, train_acc = 0.9615742897065673\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 148, train_loss = 17.160665983334184, train_acc = 0.961690731252911\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 149, train_loss = 17.135444397106767, train_acc = 0.9619236143455985\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 150, train_loss = 17.120236299932003, train_acc = 0.9618071727992548\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 151, train_loss = 17.09171306155622, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 152, train_loss = 17.068922959268093, train_acc = 0.9618071727992548\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 153, train_loss = 17.056475771591067, train_acc = 0.9619236143455985\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 154, train_loss = 17.030032470822334, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 155, train_loss = 17.018090521916747, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 156, train_loss = 16.99044948630035, train_acc = 0.962156497438286\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 157, train_loss = 16.976204043254256, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 158, train_loss = 16.951263032853603, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 159, train_loss = 16.92723754607141, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 160, train_loss = 16.911461846902966, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 161, train_loss = 16.888259744271636, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 162, train_loss = 16.87248840369284, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 163, train_loss = 16.848940711468458, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 164, train_loss = 16.82932866923511, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 165, train_loss = 16.813446540385485, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 166, train_loss = 16.800190897658467, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 167, train_loss = 16.77297611348331, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 168, train_loss = 16.75259255617857, train_acc = 0.9625058220773172\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 169, train_loss = 16.733622612431645, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 170, train_loss = 16.711972627788782, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 171, train_loss = 16.70383940078318, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 172, train_loss = 16.67940329387784, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 173, train_loss = 16.662792848423123, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 174, train_loss = 16.639533123001456, train_acc = 0.9627387051700047\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 175, train_loss = 16.632635662332177, train_acc = 0.9627387051700047\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 176, train_loss = 16.622400937601924, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 177, train_loss = 16.593861619010568, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 178, train_loss = 16.565884774550796, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 179, train_loss = 16.552703632041812, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 180, train_loss = 16.530976301059127, train_acc = 0.9627387051700047\n",
      "test Acc 0.9459962756052142:\n",
      "23th- epoch: 181, train_loss = 16.515536220744252, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 182, train_loss = 16.49783087708056, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 183, train_loss = 16.489687083289027, train_acc = 0.9628551467163484\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 184, train_loss = 16.46526502072811, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 185, train_loss = 16.472904725000262, train_acc = 0.9628551467163484\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 186, train_loss = 16.436871645972133, train_acc = 0.9628551467163484\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 187, train_loss = 16.422890543937683, train_acc = 0.9630880298090359\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 188, train_loss = 16.406701175495982, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 189, train_loss = 16.387982996180654, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 190, train_loss = 16.37487735413015, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 191, train_loss = 16.35370004735887, train_acc = 0.9630880298090359\n",
      "test Acc 0.946927374301676:\n",
      "23th- epoch: 192, train_loss = 16.334156850352883, train_acc = 0.9630880298090359\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 193, train_loss = 16.32204796373844, train_acc = 0.9630880298090359\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 194, train_loss = 16.308822752907872, train_acc = 0.9630880298090359\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 195, train_loss = 16.28822575137019, train_acc = 0.9630880298090359\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 196, train_loss = 16.274693915620446, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 197, train_loss = 16.262135596945882, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 198, train_loss = 16.246178472414613, train_acc = 0.9636702375407545\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 199, train_loss = 16.236866584047675, train_acc = 0.9636702375407545\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 200, train_loss = 16.220148526132107, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 201, train_loss = 16.201993068680167, train_acc = 0.9633209129017233\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 202, train_loss = 16.19538312405348, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 203, train_loss = 16.172379622235894, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 204, train_loss = 16.16008074581623, train_acc = 0.9635537959944108\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 205, train_loss = 16.143650690093637, train_acc = 0.9636702375407545\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 206, train_loss = 16.128374755382538, train_acc = 0.963903120633442\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 207, train_loss = 16.11091168783605, train_acc = 0.9636702375407545\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 208, train_loss = 16.10487795062363, train_acc = 0.963903120633442\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 209, train_loss = 16.091965230181813, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 210, train_loss = 16.071208169683814, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "23th- epoch: 211, train_loss = 16.05784799158573, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 212, train_loss = 16.047628805041313, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 213, train_loss = 16.03236041776836, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 214, train_loss = 16.01336328499019, train_acc = 0.9640195621797858\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 215, train_loss = 16.005490938201547, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 216, train_loss = 15.987717835232615, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 217, train_loss = 15.978988097980618, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 218, train_loss = 15.97616395354271, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 219, train_loss = 15.953005528077483, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 220, train_loss = 15.941400423645973, train_acc = 0.9642524452724732\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 221, train_loss = 15.925465449690819, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 222, train_loss = 15.919107688590884, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 223, train_loss = 15.898894293233752, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "23th- epoch: 224, train_loss = 15.885616645216942, train_acc = 0.9644853283651607\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 225, train_loss = 15.881235325708985, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 226, train_loss = 15.8691821154207, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 227, train_loss = 15.851729854941368, train_acc = 0.9643688868188169\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 228, train_loss = 15.836149515584111, train_acc = 0.9642524452724732\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 229, train_loss = 15.824518175795674, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 230, train_loss = 15.817397693172097, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 231, train_loss = 15.803840650245547, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 232, train_loss = 15.789915658533573, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 233, train_loss = 15.784382348880172, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 234, train_loss = 15.769314882345498, train_acc = 0.9644853283651607\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 235, train_loss = 15.753299492411315, train_acc = 0.9643688868188169\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 236, train_loss = 15.74198985658586, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 237, train_loss = 15.723394125699997, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 238, train_loss = 15.722243706695735, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 239, train_loss = 15.702242310158908, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 240, train_loss = 15.701425853185356, train_acc = 0.9646017699115044\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 241, train_loss = 15.683539003133774, train_acc = 0.9648346530041919\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 242, train_loss = 15.66992964129895, train_acc = 0.9648346530041919\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 243, train_loss = 15.661819663830101, train_acc = 0.9649510945505356\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 244, train_loss = 15.644050280563533, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 245, train_loss = 15.642556317150593, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 246, train_loss = 15.624259863980114, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 247, train_loss = 15.616197049617767, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 248, train_loss = 15.605299438349903, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 249, train_loss = 15.590681071393192, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 250, train_loss = 15.581540741026402, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 251, train_loss = 15.571099244058132, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 252, train_loss = 15.563031350262463, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 253, train_loss = 15.54687436670065, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 254, train_loss = 15.542309421114624, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 255, train_loss = 15.529290934093297, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 256, train_loss = 15.521926867775619, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 257, train_loss = 15.510655030608177, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 258, train_loss = 15.495886291377246, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 259, train_loss = 15.492709453217685, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 260, train_loss = 15.475220836699009, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 261, train_loss = 15.4683096408844, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 262, train_loss = 15.452321164309978, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 263, train_loss = 15.446086776442826, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 264, train_loss = 15.440728123299778, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 265, train_loss = 15.43027274031192, train_acc = 0.9650675360968793\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 266, train_loss = 15.417344257235527, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 267, train_loss = 15.406561814248562, train_acc = 0.9651839776432231\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 268, train_loss = 15.396983292885125, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 269, train_loss = 15.38476639520377, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 270, train_loss = 15.372375850565732, train_acc = 0.9653004191895669\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 271, train_loss = 15.3632572889328, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 272, train_loss = 15.362315182574093, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 273, train_loss = 15.350101347081363, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 274, train_loss = 15.339765544049442, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 275, train_loss = 15.333644218742847, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 276, train_loss = 15.326762315817177, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 277, train_loss = 15.316582515835762, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 278, train_loss = 15.30037257540971, train_acc = 0.9654168607359106\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 279, train_loss = 15.291598476469517, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 280, train_loss = 15.283435354940593, train_acc = 0.9655333022822543\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 281, train_loss = 15.274912603199482, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 282, train_loss = 15.264956858940423, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 283, train_loss = 15.253735463134944, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 284, train_loss = 15.255169332027435, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 285, train_loss = 15.23328226339072, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 286, train_loss = 15.229943302460015, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 287, train_loss = 15.219630755484104, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 288, train_loss = 15.213738694787025, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 289, train_loss = 15.209006662480533, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 290, train_loss = 15.192359074950218, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 291, train_loss = 15.18104762583971, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 292, train_loss = 15.180169326253235, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 293, train_loss = 15.169652502052486, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 294, train_loss = 15.157115451991558, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 295, train_loss = 15.149116180837154, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 296, train_loss = 15.138272449374199, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 297, train_loss = 15.129759755916893, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 298, train_loss = 15.122808150947094, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 299, train_loss = 15.115309529006481, train_acc = 0.9657661853749417\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 300, train_loss = 15.104643069207668, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 301, train_loss = 15.102997948415577, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 302, train_loss = 15.097150526940823, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 303, train_loss = 15.080907923169434, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 304, train_loss = 15.07898981589824, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 305, train_loss = 15.069412338547409, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 306, train_loss = 15.055336597375572, train_acc = 0.9658826269212856\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 307, train_loss = 15.049876836128533, train_acc = 0.9659990684676293\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 308, train_loss = 15.03928507398814, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 309, train_loss = 15.034900560975075, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 310, train_loss = 15.033064615912735, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 311, train_loss = 15.017380009405315, train_acc = 0.9664648346530041\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 312, train_loss = 15.00782971829176, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 313, train_loss = 15.004865507595241, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 314, train_loss = 14.98906894493848, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 315, train_loss = 14.987296618521214, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 316, train_loss = 14.978707800619304, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "23th- epoch: 317, train_loss = 14.97215433139354, train_acc = 0.966581276199348\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 318, train_loss = 14.964000180363655, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 319, train_loss = 14.95724515337497, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 320, train_loss = 14.943890854716301, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 321, train_loss = 14.944184417836368, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 322, train_loss = 14.931876465678215, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 323, train_loss = 14.920214022509754, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 324, train_loss = 14.920955310575664, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 325, train_loss = 14.91101773828268, train_acc = 0.966115510013973\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 326, train_loss = 14.906584471464157, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 327, train_loss = 14.893513892777264, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 328, train_loss = 14.885760110802948, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 329, train_loss = 14.876113715581596, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 330, train_loss = 14.871188290417194, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 331, train_loss = 14.866792815737426, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 332, train_loss = 14.854033174924552, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 333, train_loss = 14.84428324829787, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 334, train_loss = 14.845179225318134, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 335, train_loss = 14.836977171711624, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 336, train_loss = 14.829589056782424, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 337, train_loss = 14.823211248032749, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 338, train_loss = 14.81633556354791, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 339, train_loss = 14.801985383033752, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 340, train_loss = 14.801515164785087, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 341, train_loss = 14.790900533087552, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 342, train_loss = 14.78706365544349, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 343, train_loss = 14.777455757372081, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 344, train_loss = 14.76931819319725, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 345, train_loss = 14.766191733069718, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 346, train_loss = 14.765486960299313, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 347, train_loss = 14.753548015840352, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 348, train_loss = 14.742687148042023, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 349, train_loss = 14.73594896774739, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 350, train_loss = 14.733863420784473, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 351, train_loss = 14.717896317131817, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 352, train_loss = 14.710369599051774, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 353, train_loss = 14.715455609373748, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 354, train_loss = 14.70814413856715, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 355, train_loss = 14.695411364547908, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 356, train_loss = 14.691709320060909, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 357, train_loss = 14.682291296310723, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 358, train_loss = 14.668026966042817, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 359, train_loss = 14.67171046603471, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 360, train_loss = 14.663391381502151, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 361, train_loss = 14.66414791624993, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 362, train_loss = 14.659989662468433, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 363, train_loss = 14.645733649842441, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 364, train_loss = 14.64150905329734, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 365, train_loss = 14.632469144649804, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 366, train_loss = 14.626517129130661, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 367, train_loss = 14.618997171521187, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 368, train_loss = 14.616631257347763, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 369, train_loss = 14.61601737421006, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 370, train_loss = 14.599410124123096, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 371, train_loss = 14.597419209778309, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 372, train_loss = 14.585106042213738, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 373, train_loss = 14.577279838733375, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 374, train_loss = 14.579092599451542, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 375, train_loss = 14.569581757299602, train_acc = 0.9676292501164415\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 376, train_loss = 14.565413512289524, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 377, train_loss = 14.559856685809791, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 378, train_loss = 14.552670885808766, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 379, train_loss = 14.54418982565403, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 380, train_loss = 14.543464615941048, train_acc = 0.9677456916627852\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 381, train_loss = 14.53279760479927, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 382, train_loss = 14.533313184976578, train_acc = 0.9677456916627852\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 383, train_loss = 14.516955442726612, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 384, train_loss = 14.517235438339412, train_acc = 0.9678621332091291\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 385, train_loss = 14.508283858187497, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 386, train_loss = 14.503323999233544, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 387, train_loss = 14.493800136260688, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 388, train_loss = 14.492671000771224, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 389, train_loss = 14.4817919684574, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 390, train_loss = 14.484202255494893, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 391, train_loss = 14.47422693669796, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 392, train_loss = 14.468319189734757, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 393, train_loss = 14.465462793596089, train_acc = 0.9682114578481602\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 394, train_loss = 14.456419150345027, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 395, train_loss = 14.456942829303443, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 396, train_loss = 14.44892801810056, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 397, train_loss = 14.443314157426357, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 398, train_loss = 14.434534569270909, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 399, train_loss = 14.422633779235184, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 400, train_loss = 14.422254557721317, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 401, train_loss = 14.414447166025639, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 402, train_loss = 14.408781345002353, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 403, train_loss = 14.406376250088215, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 404, train_loss = 14.392686195671558, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 405, train_loss = 14.389225919730961, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 406, train_loss = 14.38872196804732, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 407, train_loss = 14.387130685150623, train_acc = 0.9683278993945039\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 408, train_loss = 14.377109018154442, train_acc = 0.9684443409408477\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 409, train_loss = 14.370140773244202, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 410, train_loss = 14.362035654485226, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 411, train_loss = 14.358084770850837, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 412, train_loss = 14.351099282503128, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 413, train_loss = 14.3536233631894, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 414, train_loss = 14.34575688559562, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 415, train_loss = 14.336318689398468, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 416, train_loss = 14.334075443446636, train_acc = 0.9685607824871915\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 417, train_loss = 14.329046850092709, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 418, train_loss = 14.31877547223121, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 419, train_loss = 14.315354849211872, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 420, train_loss = 14.312016226351261, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 421, train_loss = 14.304017037153244, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 422, train_loss = 14.301070615649223, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 423, train_loss = 14.298495466820896, train_acc = 0.9687936655798789\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 424, train_loss = 14.294349295087159, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 425, train_loss = 14.28597601223737, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 426, train_loss = 14.27297733258456, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 427, train_loss = 14.270106300711632, train_acc = 0.9686772240335352\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 428, train_loss = 14.266840058378875, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 429, train_loss = 14.261417403817177, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 430, train_loss = 14.251824870705605, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 431, train_loss = 14.252778415568173, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 432, train_loss = 14.246233534999192, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 433, train_loss = 14.240268300287426, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 434, train_loss = 14.231710359454155, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 435, train_loss = 14.225855007767677, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 436, train_loss = 14.219311721622944, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 437, train_loss = 14.222344015724957, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 438, train_loss = 14.21160878520459, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 439, train_loss = 14.204298782162368, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 440, train_loss = 14.202222351916134, train_acc = 0.9689101071262226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 441, train_loss = 14.197105864994228, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 442, train_loss = 14.191013765521348, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 443, train_loss = 14.184821779839694, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 444, train_loss = 14.18379523884505, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 445, train_loss = 14.17985922563821, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 446, train_loss = 14.175763060338795, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 447, train_loss = 14.171798340976238, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 448, train_loss = 14.16432508546859, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 449, train_loss = 14.161488249897957, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 450, train_loss = 14.155749837867916, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 451, train_loss = 14.153109702281654, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 452, train_loss = 14.14338890183717, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 453, train_loss = 14.139924583025277, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 454, train_loss = 14.137015166692436, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 455, train_loss = 14.137433163821697, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 456, train_loss = 14.129869751632214, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 457, train_loss = 14.121946264989674, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 458, train_loss = 14.128224432468414, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 459, train_loss = 14.118436564691365, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 460, train_loss = 14.1095508961007, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 461, train_loss = 14.106559527106583, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 462, train_loss = 14.105521015822887, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 463, train_loss = 14.09908443968743, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 464, train_loss = 14.09028813522309, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 465, train_loss = 14.090716992504895, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 466, train_loss = 14.083916676230729, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 467, train_loss = 14.080849014222622, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 468, train_loss = 14.078442379832268, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 469, train_loss = 14.07314023654908, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 470, train_loss = 14.066444131545722, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 471, train_loss = 14.058297042734921, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 472, train_loss = 14.058368613012135, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 473, train_loss = 14.056259189732373, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 474, train_loss = 14.04963319003582, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 475, train_loss = 14.042769904248416, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 476, train_loss = 14.041968792676926, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 477, train_loss = 14.034739141352475, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 478, train_loss = 14.033103200607002, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 479, train_loss = 14.02989122737199, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 480, train_loss = 14.025735947303474, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 481, train_loss = 14.02005101274699, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 482, train_loss = 14.017719951458275, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 483, train_loss = 14.011676792986691, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 484, train_loss = 14.010985580272973, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 485, train_loss = 14.002939050085843, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 486, train_loss = 13.999204563908279, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 487, train_loss = 13.994629390537739, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 488, train_loss = 13.988012050278485, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 489, train_loss = 13.98624509293586, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 490, train_loss = 13.982618803624064, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 491, train_loss = 13.9790583178401, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 492, train_loss = 13.9761803150177, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 493, train_loss = 13.975608438253403, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 494, train_loss = 13.966161278542131, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 495, train_loss = 13.967247943393886, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 496, train_loss = 13.961934844497591, train_acc = 0.9697251979506288\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 497, train_loss = 13.95467864209786, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 498, train_loss = 13.950502755586058, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "23th- epoch: 499, train_loss = 13.946326024830341, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████▋                | 23/30 [3:28:10<1:03:15, 542.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "24th- epoch: 0, train_loss = 128.02437835931778, train_acc = 0.7661853749417792\n",
      "test Acc 0.8254189944134078:\n",
      "24th- epoch: 1, train_loss = 59.408789709210396, train_acc = 0.8792501164415464\n",
      "test Acc 0.8729050279329609:\n",
      "24th- epoch: 2, train_loss = 49.35571776330471, train_acc = 0.8970656730321379\n",
      "test Acc 0.8943202979515829:\n",
      "24th- epoch: 3, train_loss = 43.92164558172226, train_acc = 0.9089427107591989\n",
      "test Acc 0.9022346368715084:\n",
      "24th- epoch: 4, train_loss = 40.42357395589352, train_acc = 0.9136003726129484\n",
      "test Acc 0.9064245810055865:\n",
      "24th- epoch: 5, train_loss = 37.88589700311422, train_acc = 0.9194224499301351\n",
      "test Acc 0.9129422718808193:\n",
      "24th- epoch: 6, train_loss = 35.9979764521122, train_acc = 0.9229156963204471\n",
      "test Acc 0.9157355679702048:\n",
      "24th- epoch: 7, train_loss = 34.46786767989397, train_acc = 0.9274569166278528\n",
      "test Acc 0.9180633147113594:\n",
      "24th- epoch: 8, train_loss = 33.202607087790966, train_acc = 0.9297857475547275\n",
      "test Acc 0.9231843575418994:\n",
      "24th- epoch: 9, train_loss = 32.168914921581745, train_acc = 0.9315323707498836\n",
      "test Acc 0.9222532588454376:\n",
      "24th- epoch: 10, train_loss = 31.310658410191536, train_acc = 0.9329296693060084\n",
      "test Acc 0.9231843575418994:\n",
      "24th- epoch: 11, train_loss = 30.506296932697296, train_acc = 0.9343269678621332\n",
      "test Acc 0.9241154562383612:\n",
      "24th- epoch: 12, train_loss = 29.782710701227188, train_acc = 0.935724266418258\n",
      "test Acc 0.9241154562383612:\n",
      "24th- epoch: 13, train_loss = 29.133165799081326, train_acc = 0.9367722403353517\n",
      "test Acc 0.925512104283054:\n",
      "24th- epoch: 14, train_loss = 28.57164415717125, train_acc = 0.9377037727061015\n",
      "test Acc 0.9278398510242085:\n",
      "24th- epoch: 15, train_loss = 28.097792901098728, train_acc = 0.9386353050768514\n",
      "test Acc 0.9273743016759777:\n",
      "24th- epoch: 16, train_loss = 27.633933030068874, train_acc = 0.9394503959012576\n",
      "test Acc 0.9297020484171322:\n",
      "24th- epoch: 17, train_loss = 27.177275098860264, train_acc = 0.9404983698183512\n",
      "test Acc 0.9297020484171322:\n",
      "24th- epoch: 18, train_loss = 26.778466448187828, train_acc = 0.9415463437354448\n",
      "test Acc 0.9301675977653632:\n",
      "24th- epoch: 19, train_loss = 26.43004584312439, train_acc = 0.9427107591988821\n",
      "test Acc 0.930633147113594:\n",
      "24th- epoch: 20, train_loss = 26.09053548425436, train_acc = 0.9431765253842571\n",
      "test Acc 0.9301675977653632:\n",
      "24th- epoch: 21, train_loss = 25.776280485093594, train_acc = 0.9437587331159758\n",
      "test Acc 0.9301675977653632:\n",
      "24th- epoch: 22, train_loss = 25.467742301523685, train_acc = 0.945388914764788\n",
      "test Acc 0.931098696461825:\n",
      "24th- epoch: 23, train_loss = 25.199498265981674, train_acc = 0.9459711224965067\n",
      "test Acc 0.9315642458100558:\n",
      "24th- epoch: 24, train_loss = 24.927677035331726, train_acc = 0.9466697717745691\n",
      "test Acc 0.931098696461825:\n",
      "24th- epoch: 25, train_loss = 24.679515674710274, train_acc = 0.9474848625989754\n",
      "test Acc 0.9320297951582868:\n",
      "24th- epoch: 26, train_loss = 24.465017646551132, train_acc = 0.9476013041453191\n",
      "test Acc 0.9324953445065177:\n",
      "24th- epoch: 27, train_loss = 24.21843947470188, train_acc = 0.9482999534233815\n",
      "test Acc 0.9334264432029795:\n",
      "24th- epoch: 28, train_loss = 24.009791411459446, train_acc = 0.9485328365160689\n",
      "test Acc 0.9334264432029795:\n",
      "24th- epoch: 29, train_loss = 23.8174005150795, train_acc = 0.9487657196087564\n",
      "test Acc 0.9334264432029795:\n",
      "24th- epoch: 30, train_loss = 23.6219380274415, train_acc = 0.9491150442477876\n",
      "test Acc 0.9334264432029795:\n",
      "24th- epoch: 31, train_loss = 23.43631874769926, train_acc = 0.9492314857941313\n",
      "test Acc 0.9338919925512105:\n",
      "24th- epoch: 32, train_loss = 23.258049868047237, train_acc = 0.9495808104331626\n",
      "test Acc 0.9338919925512105:\n",
      "24th- epoch: 33, train_loss = 23.103111371397972, train_acc = 0.9500465766185375\n",
      "test Acc 0.9343575418994413:\n",
      "24th- epoch: 34, train_loss = 22.9229244440794, train_acc = 0.9501630181648812\n",
      "test Acc 0.9343575418994413:\n",
      "24th- epoch: 35, train_loss = 22.758129093796015, train_acc = 0.9503959012575687\n",
      "test Acc 0.9343575418994413:\n",
      "24th- epoch: 36, train_loss = 22.594302244484425, train_acc = 0.9508616674429436\n",
      "test Acc 0.9348230912476723:\n",
      "24th- epoch: 37, train_loss = 22.456816412508488, train_acc = 0.9508616674429436\n",
      "test Acc 0.9352886405959032:\n",
      "24th- epoch: 38, train_loss = 22.33320928737521, train_acc = 0.9508616674429436\n",
      "test Acc 0.9352886405959032:\n",
      "24th- epoch: 39, train_loss = 22.20296287536621, train_acc = 0.9510945505356311\n",
      "test Acc 0.936219739292365:\n",
      "24th- epoch: 40, train_loss = 22.06971113756299, train_acc = 0.9517931998136935\n",
      "test Acc 0.9371508379888268:\n",
      "24th- epoch: 41, train_loss = 21.940222170203924, train_acc = 0.952026082906381\n",
      "test Acc 0.9371508379888268:\n",
      "24th- epoch: 42, train_loss = 21.822169676423073, train_acc = 0.9522589659990685\n",
      "test Acc 0.9371508379888268:\n",
      "24th- epoch: 43, train_loss = 21.694916397333145, train_acc = 0.9526082906380997\n",
      "test Acc 0.9371508379888268:\n",
      "24th- epoch: 44, train_loss = 21.588684152811766, train_acc = 0.9528411737307871\n",
      "test Acc 0.9371508379888268:\n",
      "24th- epoch: 45, train_loss = 21.471397627145052, train_acc = 0.9531904983698184\n",
      "test Acc 0.9371508379888268:\n",
      "24th- epoch: 46, train_loss = 21.365823682397604, train_acc = 0.9533069399161621\n",
      "test Acc 0.9376163873370578:\n",
      "24th- epoch: 47, train_loss = 21.262937020510435, train_acc = 0.9535398230088495\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 48, train_loss = 21.152550525963306, train_acc = 0.9536562645551933\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 49, train_loss = 21.063062340021133, train_acc = 0.9541220307405682\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 50, train_loss = 20.96345504000783, train_acc = 0.9540055891942245\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 51, train_loss = 20.87610574066639, train_acc = 0.9545877969259432\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 52, train_loss = 20.780176155269146, train_acc = 0.9544713553795995\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 53, train_loss = 20.69672141596675, train_acc = 0.9547042384722869\n",
      "test Acc 0.9380819366852886:\n",
      "24th- epoch: 54, train_loss = 20.613344680517912, train_acc = 0.9548206800186306\n",
      "test Acc 0.9385474860335196:\n",
      "24th- epoch: 55, train_loss = 20.53642487898469, train_acc = 0.9550535631113182\n",
      "test Acc 0.9385474860335196:\n",
      "24th- epoch: 56, train_loss = 20.452688228338957, train_acc = 0.9549371215649743\n",
      "test Acc 0.9390130353817505:\n",
      "24th- epoch: 57, train_loss = 20.37644137814641, train_acc = 0.9554028877503493\n",
      "test Acc 0.9390130353817505:\n",
      "24th- epoch: 58, train_loss = 20.298396944999695, train_acc = 0.9550535631113182\n",
      "test Acc 0.9390130353817505:\n",
      "24th- epoch: 59, train_loss = 20.226585511118174, train_acc = 0.9557522123893806\n",
      "test Acc 0.9390130353817505:\n",
      "24th- epoch: 60, train_loss = 20.153770741075277, train_acc = 0.9561015370284117\n",
      "test Acc 0.9390130353817505:\n",
      "24th- epoch: 61, train_loss = 20.08048204705119, train_acc = 0.956450861667443\n",
      "test Acc 0.9385474860335196:\n",
      "24th- epoch: 62, train_loss = 20.01596974208951, train_acc = 0.9566837447601304\n",
      "test Acc 0.9390130353817505:\n",
      "24th- epoch: 63, train_loss = 19.936873879283667, train_acc = 0.9566837447601304\n",
      "test Acc 0.9385474860335196:\n",
      "24th- epoch: 64, train_loss = 19.88402097672224, train_acc = 0.9566837447601304\n",
      "test Acc 0.9385474860335196:\n",
      "24th- epoch: 65, train_loss = 19.80355866998434, train_acc = 0.9570330693991617\n",
      "test Acc 0.9385474860335196:\n",
      "24th- epoch: 66, train_loss = 19.735280144959688, train_acc = 0.9570330693991617\n",
      "test Acc 0.9390130353817505:\n",
      "24th- epoch: 67, train_loss = 19.674849443137646, train_acc = 0.9571495109455054\n",
      "test Acc 0.9390130353817505:\n",
      "24th- epoch: 68, train_loss = 19.61420490965247, train_acc = 0.9571495109455054\n",
      "test Acc 0.9399441340782123:\n",
      "24th- epoch: 69, train_loss = 19.554392535239458, train_acc = 0.9571495109455054\n",
      "test Acc 0.9399441340782123:\n",
      "24th- epoch: 70, train_loss = 19.49363010749221, train_acc = 0.9571495109455054\n",
      "test Acc 0.9399441340782123:\n",
      "24th- epoch: 71, train_loss = 19.439304318279028, train_acc = 0.9571495109455054\n",
      "test Acc 0.9399441340782123:\n",
      "24th- epoch: 72, train_loss = 19.389304969459772, train_acc = 0.9573823940381928\n",
      "test Acc 0.9404096834264432:\n",
      "24th- epoch: 73, train_loss = 19.339204397052526, train_acc = 0.9573823940381928\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 74, train_loss = 19.288087878376245, train_acc = 0.9572659524918491\n",
      "test Acc 0.9408752327746741:\n",
      "24th- epoch: 75, train_loss = 19.22206251695752, train_acc = 0.9578481602235678\n",
      "test Acc 0.9413407821229051:\n",
      "24th- epoch: 76, train_loss = 19.171392250806093, train_acc = 0.9578481602235678\n",
      "test Acc 0.9413407821229051:\n",
      "24th- epoch: 77, train_loss = 19.112197142094374, train_acc = 0.9574988355845365\n",
      "test Acc 0.9413407821229051:\n",
      "24th- epoch: 78, train_loss = 19.057117868214846, train_acc = 0.9577317186772241\n",
      "test Acc 0.9413407821229051:\n",
      "24th- epoch: 79, train_loss = 19.010091703385115, train_acc = 0.9578481602235678\n",
      "test Acc 0.9413407821229051:\n",
      "24th- epoch: 80, train_loss = 18.956311766058207, train_acc = 0.9581974848625989\n",
      "test Acc 0.9413407821229051:\n",
      "24th- epoch: 81, train_loss = 18.899872165173292, train_acc = 0.9580810433162552\n",
      "test Acc 0.9418063314711359:\n",
      "24th- epoch: 82, train_loss = 18.85752223432064, train_acc = 0.9580810433162552\n",
      "test Acc 0.9418063314711359:\n",
      "24th- epoch: 83, train_loss = 18.810943868011236, train_acc = 0.9584303679552865\n",
      "test Acc 0.9418063314711359:\n",
      "24th- epoch: 84, train_loss = 18.75911396369338, train_acc = 0.9586632510479739\n",
      "test Acc 0.9422718808193669:\n",
      "24th- epoch: 85, train_loss = 18.708143401890993, train_acc = 0.9591290172333489\n",
      "test Acc 0.9427374301675978:\n",
      "24th- epoch: 86, train_loss = 18.666157111525536, train_acc = 0.9592454587796926\n",
      "test Acc 0.9422718808193669:\n",
      "24th- epoch: 87, train_loss = 18.620572853833437, train_acc = 0.9592454587796926\n",
      "test Acc 0.9422718808193669:\n",
      "24th- epoch: 88, train_loss = 18.57254284247756, train_acc = 0.9593619003260363\n",
      "test Acc 0.9432029795158287:\n",
      "24th- epoch: 89, train_loss = 18.534626934677362, train_acc = 0.9595947834187238\n",
      "test Acc 0.9427374301675978:\n",
      "24th- epoch: 90, train_loss = 18.488020312041044, train_acc = 0.9593619003260363\n",
      "test Acc 0.9432029795158287:\n",
      "24th- epoch: 91, train_loss = 18.451937556266785, train_acc = 0.9598276665114113\n",
      "test Acc 0.9432029795158287:\n",
      "24th- epoch: 92, train_loss = 18.415056210011244, train_acc = 0.9597112249650676\n",
      "test Acc 0.9432029795158287:\n",
      "24th- epoch: 93, train_loss = 18.364794220775366, train_acc = 0.959944108057755\n",
      "test Acc 0.9436685288640596:\n",
      "24th- epoch: 94, train_loss = 18.33222309872508, train_acc = 0.9600605496040987\n",
      "test Acc 0.9432029795158287:\n",
      "24th- epoch: 95, train_loss = 18.294134963303804, train_acc = 0.9601769911504425\n",
      "test Acc 0.9436685288640596:\n",
      "24th- epoch: 96, train_loss = 18.259449262171984, train_acc = 0.96040987424313\n",
      "test Acc 0.9441340782122905:\n",
      "24th- epoch: 97, train_loss = 18.216474942862988, train_acc = 0.96040987424313\n",
      "test Acc 0.9436685288640596:\n",
      "24th- epoch: 98, train_loss = 18.177478432655334, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "24th- epoch: 99, train_loss = 18.14452563971281, train_acc = 0.9605263157894737\n",
      "test Acc 0.9441340782122905:\n",
      "24th- epoch: 100, train_loss = 18.09933043271303, train_acc = 0.9607591988821611\n",
      "test Acc 0.9441340782122905:\n",
      "24th- epoch: 101, train_loss = 18.071178872138262, train_acc = 0.9607591988821611\n",
      "test Acc 0.9441340782122905:\n",
      "24th- epoch: 102, train_loss = 18.030874010175467, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "24th- epoch: 103, train_loss = 17.99180492386222, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "24th- epoch: 104, train_loss = 17.9627301171422, train_acc = 0.9609920819748486\n",
      "test Acc 0.9441340782122905:\n",
      "24th- epoch: 105, train_loss = 17.924466092139482, train_acc = 0.9611085235211924\n",
      "test Acc 0.9441340782122905:\n",
      "24th- epoch: 106, train_loss = 17.89024106040597, train_acc = 0.9612249650675361\n",
      "test Acc 0.9441340782122905:\n",
      "24th- epoch: 107, train_loss = 17.853998940438032, train_acc = 0.9612249650675361\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 108, train_loss = 17.825624469667673, train_acc = 0.9614578481602236\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 109, train_loss = 17.792666863650084, train_acc = 0.9614578481602236\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 110, train_loss = 17.765061024576426, train_acc = 0.9615742897065673\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 111, train_loss = 17.73324293270707, train_acc = 0.9615742897065673\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 112, train_loss = 17.69558795168996, train_acc = 0.9615742897065673\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 113, train_loss = 17.664136663079262, train_acc = 0.961690731252911\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 114, train_loss = 17.634489607065916, train_acc = 0.961690731252911\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 115, train_loss = 17.607645083218813, train_acc = 0.961690731252911\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 116, train_loss = 17.569347511976957, train_acc = 0.9618071727992548\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 117, train_loss = 17.54599131643772, train_acc = 0.9619236143455985\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 118, train_loss = 17.510241927579045, train_acc = 0.9619236143455985\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 119, train_loss = 17.485353069379926, train_acc = 0.9622729389846297\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 120, train_loss = 17.459882093593478, train_acc = 0.9620400558919422\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 121, train_loss = 17.43281425535679, train_acc = 0.9623893805309734\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 122, train_loss = 17.39993724785745, train_acc = 0.9623893805309734\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 123, train_loss = 17.37224910967052, train_acc = 0.9620400558919422\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 124, train_loss = 17.353961616754532, train_acc = 0.9622729389846297\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 125, train_loss = 17.323252089321613, train_acc = 0.9622729389846297\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 126, train_loss = 17.289670882746577, train_acc = 0.9622729389846297\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 127, train_loss = 17.270938569679856, train_acc = 0.9622729389846297\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 128, train_loss = 17.235134499147534, train_acc = 0.9623893805309734\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 129, train_loss = 17.208804085850716, train_acc = 0.9625058220773172\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 130, train_loss = 17.188174521550536, train_acc = 0.9626222636236609\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 131, train_loss = 17.15990020520985, train_acc = 0.9623893805309734\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 132, train_loss = 17.13456337712705, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 133, train_loss = 17.115816516801715, train_acc = 0.9625058220773172\n",
      "test Acc 0.9445996275605214:\n",
      "24th- epoch: 134, train_loss = 17.091649547219276, train_acc = 0.9628551467163484\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 135, train_loss = 17.061610020697117, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 136, train_loss = 17.04841035604477, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 137, train_loss = 17.01731943525374, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 138, train_loss = 16.99816782772541, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 139, train_loss = 16.97614805214107, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 140, train_loss = 16.950220800936222, train_acc = 0.9627387051700047\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 141, train_loss = 16.93101060949266, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 142, train_loss = 16.91226502507925, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 143, train_loss = 16.88575013540685, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 144, train_loss = 16.85918264836073, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 145, train_loss = 16.840185947716236, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 146, train_loss = 16.827311657369137, train_acc = 0.9629715882626921\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 147, train_loss = 16.801592020317912, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 148, train_loss = 16.783351158723235, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 149, train_loss = 16.767168261110783, train_acc = 0.9633209129017233\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 150, train_loss = 16.736208545044065, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 151, train_loss = 16.71853848360479, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 152, train_loss = 16.699306443333626, train_acc = 0.9630880298090359\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 153, train_loss = 16.6802512165159, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 154, train_loss = 16.654616901651025, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 155, train_loss = 16.637767804786563, train_acc = 0.9635537959944108\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 156, train_loss = 16.617124758660793, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 157, train_loss = 16.589402427896857, train_acc = 0.9635537959944108\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 158, train_loss = 16.574380164965987, train_acc = 0.9636702375407545\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 159, train_loss = 16.556560032069683, train_acc = 0.9635537959944108\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 160, train_loss = 16.539530551061034, train_acc = 0.9635537959944108\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 161, train_loss = 16.5187117010355, train_acc = 0.963903120633442\n",
      "test Acc 0.9455307262569832:\n",
      "24th- epoch: 162, train_loss = 16.506217965856194, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 163, train_loss = 16.49205063842237, train_acc = 0.9637866790870983\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 164, train_loss = 16.461230278015137, train_acc = 0.963903120633442\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 165, train_loss = 16.44305574335158, train_acc = 0.963903120633442\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 166, train_loss = 16.4300767313689, train_acc = 0.963903120633442\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 167, train_loss = 16.40464830212295, train_acc = 0.9640195621797858\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 168, train_loss = 16.38537215255201, train_acc = 0.9640195621797858\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 169, train_loss = 16.372231394052505, train_acc = 0.9640195621797858\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 170, train_loss = 16.360512673854828, train_acc = 0.9642524452724732\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 171, train_loss = 16.32801309414208, train_acc = 0.9641360037261295\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 172, train_loss = 16.31761416979134, train_acc = 0.9642524452724732\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 173, train_loss = 16.303151505067945, train_acc = 0.9642524452724732\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 174, train_loss = 16.278086164966226, train_acc = 0.9641360037261295\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 175, train_loss = 16.26296323724091, train_acc = 0.9643688868188169\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 176, train_loss = 16.246561167761683, train_acc = 0.9648346530041919\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 177, train_loss = 16.23184358328581, train_acc = 0.9643688868188169\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 178, train_loss = 16.220237663015723, train_acc = 0.9641360037261295\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 179, train_loss = 16.20220410078764, train_acc = 0.9649510945505356\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 180, train_loss = 16.18994046933949, train_acc = 0.9642524452724732\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 181, train_loss = 16.166417649015784, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 182, train_loss = 16.149358285591006, train_acc = 0.9648346530041919\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 183, train_loss = 16.13378573395312, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 184, train_loss = 16.125662786886096, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 185, train_loss = 16.104490337893367, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 186, train_loss = 16.100283620879054, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 187, train_loss = 16.076520532369614, train_acc = 0.9651839776432231\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 188, train_loss = 16.065449168905616, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 189, train_loss = 16.053953289985657, train_acc = 0.9647182114578482\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 190, train_loss = 16.02805477939546, train_acc = 0.9651839776432231\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 191, train_loss = 16.022158375009894, train_acc = 0.9653004191895669\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 192, train_loss = 16.00159781984985, train_acc = 0.9653004191895669\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 193, train_loss = 15.98727248609066, train_acc = 0.9653004191895669\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 194, train_loss = 15.968792041763663, train_acc = 0.9654168607359106\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 195, train_loss = 15.962559318169951, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 196, train_loss = 15.94241270981729, train_acc = 0.965649743828598\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 197, train_loss = 15.92804461158812, train_acc = 0.9655333022822543\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 198, train_loss = 15.920273931697011, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 199, train_loss = 15.901446506381035, train_acc = 0.9658826269212856\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 200, train_loss = 15.89300218783319, train_acc = 0.9659990684676293\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 201, train_loss = 15.87640668451786, train_acc = 0.9655333022822543\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 202, train_loss = 15.860650857910514, train_acc = 0.9657661853749417\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 203, train_loss = 15.844431607052684, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 204, train_loss = 15.835184199735522, train_acc = 0.966115510013973\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 205, train_loss = 15.821406858041883, train_acc = 0.9658826269212856\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 206, train_loss = 15.803591584786773, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 207, train_loss = 15.792932337149978, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 208, train_loss = 15.780080869793892, train_acc = 0.9658826269212856\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 209, train_loss = 15.763814555481076, train_acc = 0.9658826269212856\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 210, train_loss = 15.754424013197422, train_acc = 0.9658826269212856\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 211, train_loss = 15.736586220562458, train_acc = 0.9662319515603167\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 212, train_loss = 15.72596757300198, train_acc = 0.9658826269212856\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 213, train_loss = 15.721409579738975, train_acc = 0.9659990684676293\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 214, train_loss = 15.70304704643786, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 215, train_loss = 15.693342866376042, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 216, train_loss = 15.67591824568808, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 217, train_loss = 15.66616533137858, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 218, train_loss = 15.654948698356748, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 219, train_loss = 15.645007649436593, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 220, train_loss = 15.632109098136425, train_acc = 0.966581276199348\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 221, train_loss = 15.623449126258492, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 222, train_loss = 15.608518356457353, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 223, train_loss = 15.5947620626539, train_acc = 0.966581276199348\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 224, train_loss = 15.587162867188454, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 225, train_loss = 15.574442794546485, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "24th- epoch: 226, train_loss = 15.563489040359855, train_acc = 0.966581276199348\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 227, train_loss = 15.552971260622144, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "24th- epoch: 228, train_loss = 15.546964382752776, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "24th- epoch: 229, train_loss = 15.528204903006554, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "24th- epoch: 230, train_loss = 15.509171733632684, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "24th- epoch: 231, train_loss = 15.501412840560079, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "24th- epoch: 232, train_loss = 15.49351217597723, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "24th- epoch: 233, train_loss = 15.480028802528977, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "24th- epoch: 234, train_loss = 15.466044083237648, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "24th- epoch: 235, train_loss = 15.448121340945363, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "24th- epoch: 236, train_loss = 15.441999308764935, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 237, train_loss = 15.423799535259604, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 238, train_loss = 15.43406324647367, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 239, train_loss = 15.41212691552937, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 240, train_loss = 15.398152293637395, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 241, train_loss = 15.390174843370914, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 242, train_loss = 15.375179944559932, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 243, train_loss = 15.371962500736117, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 244, train_loss = 15.35212142020464, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 245, train_loss = 15.350965894758701, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 246, train_loss = 15.336401170119643, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 247, train_loss = 15.334924526512623, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 248, train_loss = 15.319597346708179, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 249, train_loss = 15.301443239673972, train_acc = 0.9666977177456917\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 250, train_loss = 15.297466732561588, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 251, train_loss = 15.283574601635337, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 252, train_loss = 15.271752469241619, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 253, train_loss = 15.267293671146035, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 254, train_loss = 15.248282065615058, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 255, train_loss = 15.248863331973553, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 256, train_loss = 15.238463079556823, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 257, train_loss = 15.229073183611035, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 258, train_loss = 15.221298595890403, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 259, train_loss = 15.21322494931519, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 260, train_loss = 15.204485414549708, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 261, train_loss = 15.19338484108448, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 262, train_loss = 15.181523261591792, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 263, train_loss = 15.175690591335297, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 264, train_loss = 15.158479245379567, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 265, train_loss = 15.150077296420932, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 266, train_loss = 15.146326148882508, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 267, train_loss = 15.129766480997205, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 268, train_loss = 15.124416830018163, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 269, train_loss = 15.12071825005114, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 270, train_loss = 15.103739090263844, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 271, train_loss = 15.098848005756736, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 272, train_loss = 15.08303658105433, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 273, train_loss = 15.075281558558345, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 274, train_loss = 15.06346313469112, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 275, train_loss = 15.060727244243026, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 276, train_loss = 15.047443790361285, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 277, train_loss = 15.034684324637055, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 278, train_loss = 15.027936974540353, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 279, train_loss = 15.02556598931551, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 280, train_loss = 15.015717826783657, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 281, train_loss = 15.00627619959414, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 282, train_loss = 14.99527102522552, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 283, train_loss = 14.98608705215156, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 284, train_loss = 14.978620430454612, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 285, train_loss = 14.973392939195037, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 286, train_loss = 14.958386300131679, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 287, train_loss = 14.954040365293622, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 288, train_loss = 14.940581865608692, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 289, train_loss = 14.935880864039063, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 290, train_loss = 14.926403043791652, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 291, train_loss = 14.919785117730498, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 292, train_loss = 14.914081836119294, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 293, train_loss = 14.907324461266398, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 294, train_loss = 14.887744152918458, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 295, train_loss = 14.87933961302042, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 296, train_loss = 14.869434684515, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 297, train_loss = 14.863198338076472, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 298, train_loss = 14.85276923328638, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 299, train_loss = 14.844770120456815, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 300, train_loss = 14.836976021528244, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 301, train_loss = 14.828709969297051, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 302, train_loss = 14.820271082222462, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 303, train_loss = 14.813357537612319, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 304, train_loss = 14.801075115799904, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 305, train_loss = 14.797446699813008, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 306, train_loss = 14.784808605909348, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 307, train_loss = 14.781171372160316, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 308, train_loss = 14.77255766838789, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "24th- epoch: 309, train_loss = 14.763632072135806, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 310, train_loss = 14.7580856513232, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "24th- epoch: 311, train_loss = 14.747092118486762, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 312, train_loss = 14.742859670892358, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 313, train_loss = 14.737411141395569, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 314, train_loss = 14.725932182744145, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 315, train_loss = 14.719248265028, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 316, train_loss = 14.711812006309628, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "24th- epoch: 317, train_loss = 14.70567461848259, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 318, train_loss = 14.703565463423729, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 319, train_loss = 14.69069613236934, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 320, train_loss = 14.682668222114444, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 321, train_loss = 14.67599333357066, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 322, train_loss = 14.668635286390781, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 323, train_loss = 14.65896662324667, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 324, train_loss = 14.652225119061768, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 325, train_loss = 14.64364438969642, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 326, train_loss = 14.641652482561767, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 327, train_loss = 14.633542354218662, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 328, train_loss = 14.626603558659554, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 329, train_loss = 14.615928363986313, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "24th- epoch: 330, train_loss = 14.609928640536964, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 331, train_loss = 14.602617020718753, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 332, train_loss = 14.598595063202083, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 333, train_loss = 14.593334856443107, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 334, train_loss = 14.587279316969216, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "24th- epoch: 335, train_loss = 14.576689374633133, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 336, train_loss = 14.570443590171635, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 337, train_loss = 14.561869494616985, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 338, train_loss = 14.560814726166427, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 339, train_loss = 14.551318518817425, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "24th- epoch: 340, train_loss = 14.542658071033657, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 341, train_loss = 14.541666408069432, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 342, train_loss = 14.531116060912609, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 343, train_loss = 14.523277699947357, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "24th- epoch: 344, train_loss = 14.517959095537663, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 345, train_loss = 14.512016181834042, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 346, train_loss = 14.501889534294605, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 347, train_loss = 14.498852364718914, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 348, train_loss = 14.491170865483582, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 349, train_loss = 14.486501296050847, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 350, train_loss = 14.472705401480198, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 351, train_loss = 14.468968394212425, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 352, train_loss = 14.464685447514057, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "24th- epoch: 353, train_loss = 14.457459844648838, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "24th- epoch: 354, train_loss = 14.45430160779506, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 355, train_loss = 14.44447108078748, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 356, train_loss = 14.440283793024719, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 357, train_loss = 14.43264339864254, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 358, train_loss = 14.423051819205284, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 359, train_loss = 14.421295161359012, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 360, train_loss = 14.414906829595566, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 361, train_loss = 14.407569669187069, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 362, train_loss = 14.400852824561298, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 363, train_loss = 14.39711459260434, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 364, train_loss = 14.38853321224451, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 365, train_loss = 14.38365429919213, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 366, train_loss = 14.3792734593153, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 367, train_loss = 14.369841441512108, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 368, train_loss = 14.363010455854237, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 369, train_loss = 14.359297573566437, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 370, train_loss = 14.358195322565734, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 371, train_loss = 14.347283246926963, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 372, train_loss = 14.342778597958386, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 373, train_loss = 14.340527351014316, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 374, train_loss = 14.331474577076733, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 375, train_loss = 14.324125570245087, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 376, train_loss = 14.316103872843087, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 377, train_loss = 14.317521403543651, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 378, train_loss = 14.307623095810413, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 379, train_loss = 14.303732526488602, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 380, train_loss = 14.296312597580254, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 381, train_loss = 14.289302438497543, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 382, train_loss = 14.287577134557068, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 383, train_loss = 14.278177860192955, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 384, train_loss = 14.276332683861256, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 385, train_loss = 14.26594755332917, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 386, train_loss = 14.263262716121972, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 387, train_loss = 14.257828581146896, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 388, train_loss = 14.252493579871953, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 389, train_loss = 14.245406772010028, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 390, train_loss = 14.2432757364586, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 391, train_loss = 14.239702142775059, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 392, train_loss = 14.230551108717918, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 393, train_loss = 14.224606521427631, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 394, train_loss = 14.217222991399467, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 395, train_loss = 14.213991199620068, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 396, train_loss = 14.20837964117527, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 397, train_loss = 14.201923914253712, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 398, train_loss = 14.19371984153986, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 399, train_loss = 14.19137105345726, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 400, train_loss = 14.1902557015419, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 401, train_loss = 14.182949406094849, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 402, train_loss = 14.17415578942746, train_acc = 0.9691429902189101\n",
      "test Acc 0.9478584729981379:\n",
      "24th- epoch: 403, train_loss = 14.173315815627575, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 404, train_loss = 14.166612234897912, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 405, train_loss = 14.160398934967816, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 406, train_loss = 14.1550716413185, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 407, train_loss = 14.150417041964829, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 408, train_loss = 14.149450066499412, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 409, train_loss = 14.144134126603603, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 410, train_loss = 14.136885814368725, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 411, train_loss = 14.132824438624084, train_acc = 0.9692594317652539\n",
      "test Acc 0.9478584729981379:\n",
      "24th- epoch: 412, train_loss = 14.127013499848545, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 413, train_loss = 14.121620520949364, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 414, train_loss = 14.117705099284649, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 415, train_loss = 14.111219997517765, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 416, train_loss = 14.105040597729385, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 417, train_loss = 14.098256130702794, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 418, train_loss = 14.099310365505517, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 419, train_loss = 14.086752288043499, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 420, train_loss = 14.08638862799853, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 421, train_loss = 14.080301488749683, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 422, train_loss = 14.07727621216327, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 423, train_loss = 14.076725495047867, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 424, train_loss = 14.067968408577144, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 425, train_loss = 14.057420861907303, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 426, train_loss = 14.047972408123314, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "24th- epoch: 427, train_loss = 14.048358477652073, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 428, train_loss = 14.04298710823059, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 429, train_loss = 14.036229689605534, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 430, train_loss = 14.030569796450436, train_acc = 0.9693758733115976\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 431, train_loss = 14.028913480229676, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 432, train_loss = 14.022083709947765, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 433, train_loss = 14.025363911874592, train_acc = 0.969608756404285\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 434, train_loss = 14.015289542265236, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 435, train_loss = 14.00887740124017, train_acc = 0.9694923148579413\n",
      "test Acc 0.9478584729981379:\n",
      "24th- epoch: 436, train_loss = 14.002031018026173, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 437, train_loss = 13.997966055758297, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 438, train_loss = 13.993695470504463, train_acc = 0.9694923148579413\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 439, train_loss = 13.989771750755608, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 440, train_loss = 13.983991633169353, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 441, train_loss = 13.97901064902544, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 442, train_loss = 13.97669215966016, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 443, train_loss = 13.972521317191422, train_acc = 0.9697251979506288\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 444, train_loss = 13.965396839194, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 445, train_loss = 13.967703525908291, train_acc = 0.9697251979506288\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 446, train_loss = 13.956009536981583, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 447, train_loss = 13.951969929039478, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 448, train_loss = 13.95081910211593, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 449, train_loss = 13.949322931468487, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 450, train_loss = 13.936536406166852, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 451, train_loss = 13.930523629300296, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 452, train_loss = 13.931121218018234, train_acc = 0.9698416394969726\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 453, train_loss = 13.92613971233368, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 454, train_loss = 13.921320378780365, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 455, train_loss = 13.922703124582767, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 456, train_loss = 13.915363252162933, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 457, train_loss = 13.910068976692855, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 458, train_loss = 13.903778252191842, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 459, train_loss = 13.900880984961987, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 460, train_loss = 13.896525603719056, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 461, train_loss = 13.888881996273994, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 462, train_loss = 13.88893819320947, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 463, train_loss = 13.88428923022002, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 464, train_loss = 13.882091949693859, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 465, train_loss = 13.875970132648945, train_acc = 0.9697251979506288\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 466, train_loss = 13.871573681943119, train_acc = 0.9697251979506288\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 467, train_loss = 13.87414490710944, train_acc = 0.9697251979506288\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 468, train_loss = 13.86310838162899, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 469, train_loss = 13.860448335297406, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 470, train_loss = 13.85416625160724, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 471, train_loss = 13.855835609138012, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 472, train_loss = 13.847999083809555, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 473, train_loss = 13.843561199493706, train_acc = 0.9698416394969726\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 474, train_loss = 13.838127995841205, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 475, train_loss = 13.834755070507526, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 476, train_loss = 13.831873725168407, train_acc = 0.9697251979506288\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 477, train_loss = 13.825372290797532, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 478, train_loss = 13.82504865527153, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 479, train_loss = 13.820548181422055, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 480, train_loss = 13.814820197410882, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 481, train_loss = 13.812832993455231, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 482, train_loss = 13.8068309975788, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 483, train_loss = 13.800720892846584, train_acc = 0.9697251979506288\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 484, train_loss = 13.796892069280148, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 485, train_loss = 13.79639744758606, train_acc = 0.9698416394969726\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 486, train_loss = 13.791220867075026, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 487, train_loss = 13.785523280501366, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 488, train_loss = 13.780620983801782, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 489, train_loss = 13.77958160545677, train_acc = 0.97007452258966\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 490, train_loss = 13.776099455542862, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 491, train_loss = 13.771046769805253, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 492, train_loss = 13.765003862790763, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "24th- epoch: 493, train_loss = 13.760477292351425, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 494, train_loss = 13.755215075798333, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 495, train_loss = 13.755018923431635, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 496, train_loss = 13.748474695719779, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 497, train_loss = 13.747369372285903, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 498, train_loss = 13.742592413909733, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "24th- epoch: 499, train_loss = 13.738919115625322, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████▌              | 24/30 [3:37:14<54:16, 542.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "25th- epoch: 0, train_loss = 133.0015206038952, train_acc = 0.7414997671169073\n",
      "test Acc 0.7625698324022346:\n",
      "25th- epoch: 1, train_loss = 64.33412411808968, train_acc = 0.8678388448998603\n",
      "test Acc 0.8249534450651769:\n",
      "25th- epoch: 2, train_loss = 52.60006159543991, train_acc = 0.8883325570563577\n",
      "test Acc 0.8542830540037244:\n",
      "25th- epoch: 3, train_loss = 46.6560178399086, train_acc = 0.9041686073591058\n",
      "test Acc 0.8710428305400373:\n",
      "25th- epoch: 4, train_loss = 42.75709669291973, train_acc = 0.9104564508616675\n",
      "test Acc 0.883147113594041:\n",
      "25th- epoch: 5, train_loss = 39.96528621017933, train_acc = 0.9127852817885421\n",
      "test Acc 0.8896648044692738:\n",
      "25th- epoch: 6, train_loss = 37.83623240888119, train_acc = 0.9174429436422916\n",
      "test Acc 0.8971135940409684:\n",
      "25th- epoch: 7, train_loss = 36.146483704447746, train_acc = 0.9205868653935724\n",
      "test Acc 0.898975791433892:\n",
      "25th- epoch: 8, train_loss = 34.74758820980787, train_acc = 0.9230321378667908\n",
      "test Acc 0.9054934823091247:\n",
      "25th- epoch: 9, train_loss = 33.57794609665871, train_acc = 0.9244294364229158\n",
      "test Acc 0.9120111731843575:\n",
      "25th- epoch: 10, train_loss = 32.51855681836605, train_acc = 0.9269911504424779\n",
      "test Acc 0.9222532588454376:\n",
      "25th- epoch: 11, train_loss = 31.633331134915352, train_acc = 0.9297857475547275\n",
      "test Acc 0.9231843575418994:\n",
      "25th- epoch: 12, train_loss = 30.842531710863113, train_acc = 0.9312994876571961\n",
      "test Acc 0.9259776536312849:\n",
      "25th- epoch: 13, train_loss = 30.127060905098915, train_acc = 0.9337447601304145\n",
      "test Acc 0.9273743016759777:\n",
      "25th- epoch: 14, train_loss = 29.497387155890465, train_acc = 0.9353749417792269\n",
      "test Acc 0.9278398510242085:\n",
      "25th- epoch: 15, train_loss = 28.946724072098732, train_acc = 0.9359571495109456\n",
      "test Acc 0.931098696461825:\n",
      "25th- epoch: 16, train_loss = 28.439631082117558, train_acc = 0.9367722403353517\n",
      "test Acc 0.9315642458100558:\n",
      "25th- epoch: 17, train_loss = 27.954836510121822, train_acc = 0.9380530973451328\n",
      "test Acc 0.9324953445065177:\n",
      "25th- epoch: 18, train_loss = 27.527170203626156, train_acc = 0.9395668374476013\n",
      "test Acc 0.9334264432029795:\n",
      "25th- epoch: 19, train_loss = 27.126470934599638, train_acc = 0.9407312529110387\n",
      "test Acc 0.9329608938547486:\n",
      "25th- epoch: 20, train_loss = 26.767289873212576, train_acc = 0.9413134606427573\n",
      "test Acc 0.9338919925512105:\n",
      "25th- epoch: 21, train_loss = 26.448211196810007, train_acc = 0.9404983698183512\n",
      "test Acc 0.9338919925512105:\n",
      "25th- epoch: 22, train_loss = 26.11436216905713, train_acc = 0.9421285514671635\n",
      "test Acc 0.9348230912476723:\n",
      "25th- epoch: 23, train_loss = 25.807416018098593, train_acc = 0.9429436422915697\n",
      "test Acc 0.9338919925512105:\n",
      "25th- epoch: 24, train_loss = 25.537651553750038, train_acc = 0.9435258500232883\n",
      "test Acc 0.9343575418994413:\n",
      "25th- epoch: 25, train_loss = 25.27183371782303, train_acc = 0.9443409408476945\n",
      "test Acc 0.9348230912476723:\n",
      "25th- epoch: 26, train_loss = 25.01976403221488, train_acc = 0.9448067070330693\n",
      "test Acc 0.9348230912476723:\n",
      "25th- epoch: 27, train_loss = 24.79228227958083, train_acc = 0.9456217978574756\n",
      "test Acc 0.9348230912476723:\n",
      "25th- epoch: 28, train_loss = 24.581818018108606, train_acc = 0.946320447135538\n",
      "test Acc 0.9357541899441341:\n",
      "25th- epoch: 29, train_loss = 24.355305138975382, train_acc = 0.9465533302282254\n",
      "test Acc 0.9357541899441341:\n",
      "25th- epoch: 30, train_loss = 24.16108773648739, train_acc = 0.9470190964136004\n",
      "test Acc 0.9357541899441341:\n",
      "25th- epoch: 31, train_loss = 23.956529412418604, train_acc = 0.948067070330694\n",
      "test Acc 0.936219739292365:\n",
      "25th- epoch: 32, train_loss = 23.76939319819212, train_acc = 0.9481835118770378\n",
      "test Acc 0.9371508379888268:\n",
      "25th- epoch: 33, train_loss = 23.58950847387314, train_acc = 0.9482999534233815\n",
      "test Acc 0.9371508379888268:\n",
      "25th- epoch: 34, train_loss = 23.429603401571512, train_acc = 0.9484163949697252\n",
      "test Acc 0.9366852886405959:\n",
      "25th- epoch: 35, train_loss = 23.26831217482686, train_acc = 0.9489986027014439\n",
      "test Acc 0.9371508379888268:\n",
      "25th- epoch: 36, train_loss = 23.124136708676815, train_acc = 0.9492314857941313\n",
      "test Acc 0.9376163873370578:\n",
      "25th- epoch: 37, train_loss = 22.96400160714984, train_acc = 0.9499301350721937\n",
      "test Acc 0.9376163873370578:\n",
      "25th- epoch: 38, train_loss = 22.8137072250247, train_acc = 0.9501630181648812\n",
      "test Acc 0.9385474860335196:\n",
      "25th- epoch: 39, train_loss = 22.681336607784033, train_acc = 0.9507452258965999\n",
      "test Acc 0.9385474860335196:\n",
      "25th- epoch: 40, train_loss = 22.55794739536941, train_acc = 0.9509781089892874\n",
      "test Acc 0.9390130353817505:\n",
      "25th- epoch: 41, train_loss = 22.41641137190163, train_acc = 0.951560316721006\n",
      "test Acc 0.9390130353817505:\n",
      "25th- epoch: 42, train_loss = 22.285471372306347, train_acc = 0.9514438751746623\n",
      "test Acc 0.9390130353817505:\n",
      "25th- epoch: 43, train_loss = 22.17412810586393, train_acc = 0.9516767582673498\n",
      "test Acc 0.9390130353817505:\n",
      "25th- epoch: 44, train_loss = 22.060885643586516, train_acc = 0.952026082906381\n",
      "test Acc 0.9390130353817505:\n",
      "25th- epoch: 45, train_loss = 21.933203564956784, train_acc = 0.9523754075454122\n",
      "test Acc 0.9390130353817505:\n",
      "25th- epoch: 46, train_loss = 21.82766251079738, train_acc = 0.9527247321844434\n",
      "test Acc 0.9390130353817505:\n",
      "25th- epoch: 47, train_loss = 21.720032319426537, train_acc = 0.9527247321844434\n",
      "test Acc 0.9390130353817505:\n",
      "25th- epoch: 48, train_loss = 21.607185961678624, train_acc = 0.9528411737307871\n",
      "test Acc 0.9390130353817505:\n",
      "25th- epoch: 49, train_loss = 21.50877312757075, train_acc = 0.9528411737307871\n",
      "test Acc 0.9390130353817505:\n",
      "25th- epoch: 50, train_loss = 21.411630883812904, train_acc = 0.9529576152771309\n",
      "test Acc 0.9390130353817505:\n",
      "25th- epoch: 51, train_loss = 21.3245697170496, train_acc = 0.9531904983698184\n",
      "test Acc 0.9390130353817505:\n",
      "25th- epoch: 52, train_loss = 21.2219063565135, train_acc = 0.9530740568234746\n",
      "test Acc 0.9394785847299814:\n",
      "25th- epoch: 53, train_loss = 21.131531208753586, train_acc = 0.9533069399161621\n",
      "test Acc 0.9394785847299814:\n",
      "25th- epoch: 54, train_loss = 21.053379291668534, train_acc = 0.9533069399161621\n",
      "test Acc 0.9399441340782123:\n",
      "25th- epoch: 55, train_loss = 20.965290382504463, train_acc = 0.9534233814625058\n",
      "test Acc 0.9404096834264432:\n",
      "25th- epoch: 56, train_loss = 20.886895960196853, train_acc = 0.9536562645551933\n",
      "test Acc 0.9399441340782123:\n",
      "25th- epoch: 57, train_loss = 20.794339003041387, train_acc = 0.9542384722869119\n",
      "test Acc 0.9399441340782123:\n",
      "25th- epoch: 58, train_loss = 20.718276174739003, train_acc = 0.9542384722869119\n",
      "test Acc 0.9404096834264432:\n",
      "25th- epoch: 59, train_loss = 20.64316019974649, train_acc = 0.9542384722869119\n",
      "test Acc 0.9404096834264432:\n",
      "25th- epoch: 60, train_loss = 20.56178474985063, train_acc = 0.9545877969259432\n",
      "test Acc 0.9408752327746741:\n",
      "25th- epoch: 61, train_loss = 20.47095866687596, train_acc = 0.9549371215649743\n",
      "test Acc 0.9408752327746741:\n",
      "25th- epoch: 62, train_loss = 20.411445943638682, train_acc = 0.9554028877503493\n",
      "test Acc 0.9408752327746741:\n",
      "25th- epoch: 63, train_loss = 20.33419212140143, train_acc = 0.9554028877503493\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 64, train_loss = 20.259408697485924, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 65, train_loss = 20.191059097647667, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 66, train_loss = 20.13120379857719, train_acc = 0.9558686539357243\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 67, train_loss = 20.066937090829015, train_acc = 0.9558686539357243\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 68, train_loss = 19.99151086062193, train_acc = 0.9562179785747554\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 69, train_loss = 19.93245131522417, train_acc = 0.9562179785747554\n",
      "test Acc 0.9418063314711359:\n",
      "25th- epoch: 70, train_loss = 19.875344390049577, train_acc = 0.9563344201210993\n",
      "test Acc 0.9413407821229051:\n",
      "25th- epoch: 71, train_loss = 19.804465174674988, train_acc = 0.9566837447601304\n",
      "test Acc 0.9418063314711359:\n",
      "25th- epoch: 72, train_loss = 19.757845332846045, train_acc = 0.9566837447601304\n",
      "test Acc 0.9418063314711359:\n",
      "25th- epoch: 73, train_loss = 19.698237163946033, train_acc = 0.9570330693991617\n",
      "test Acc 0.9422718808193669:\n",
      "25th- epoch: 74, train_loss = 19.631996497511864, train_acc = 0.9569166278528178\n",
      "test Acc 0.9418063314711359:\n",
      "25th- epoch: 75, train_loss = 19.58967651426792, train_acc = 0.9570330693991617\n",
      "test Acc 0.9432029795158287:\n",
      "25th- epoch: 76, train_loss = 19.53026071935892, train_acc = 0.9572659524918491\n",
      "test Acc 0.9427374301675978:\n",
      "25th- epoch: 77, train_loss = 19.466146329417825, train_acc = 0.9571495109455054\n",
      "test Acc 0.9432029795158287:\n",
      "25th- epoch: 78, train_loss = 19.424660116434097, train_acc = 0.9574988355845365\n",
      "test Acc 0.9432029795158287:\n",
      "25th- epoch: 79, train_loss = 19.366241766139865, train_acc = 0.9573823940381928\n",
      "test Acc 0.9432029795158287:\n",
      "25th- epoch: 80, train_loss = 19.320175506174564, train_acc = 0.9574988355845365\n",
      "test Acc 0.9432029795158287:\n",
      "25th- epoch: 81, train_loss = 19.276245968416333, train_acc = 0.9580810433162552\n",
      "test Acc 0.9427374301675978:\n",
      "25th- epoch: 82, train_loss = 19.212968735024333, train_acc = 0.9579646017699115\n",
      "test Acc 0.9432029795158287:\n",
      "25th- epoch: 83, train_loss = 19.1650856602937, train_acc = 0.9583139264089428\n",
      "test Acc 0.9436685288640596:\n",
      "25th- epoch: 84, train_loss = 19.12070830911398, train_acc = 0.9581974848625989\n",
      "test Acc 0.9436685288640596:\n",
      "25th- epoch: 85, train_loss = 19.07713414542377, train_acc = 0.9581974848625989\n",
      "test Acc 0.9436685288640596:\n",
      "25th- epoch: 86, train_loss = 19.03120918571949, train_acc = 0.9583139264089428\n",
      "test Acc 0.9436685288640596:\n",
      "25th- epoch: 87, train_loss = 18.98916587792337, train_acc = 0.9584303679552865\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 88, train_loss = 18.943246066570282, train_acc = 0.9586632510479739\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 89, train_loss = 18.90690440684557, train_acc = 0.9584303679552865\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 90, train_loss = 18.86444879323244, train_acc = 0.9586632510479739\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 91, train_loss = 18.822862228378654, train_acc = 0.9588961341406614\n",
      "test Acc 0.9445996275605214:\n",
      "25th- epoch: 92, train_loss = 18.775341041386127, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 93, train_loss = 18.737738175317645, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 94, train_loss = 18.695014096796513, train_acc = 0.9588961341406614\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 95, train_loss = 18.649590700864792, train_acc = 0.9590125756870052\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 96, train_loss = 18.622532254084945, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 97, train_loss = 18.58085710555315, train_acc = 0.9592454587796926\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 98, train_loss = 18.53524104692042, train_acc = 0.95947834187238\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 99, train_loss = 18.498066755011678, train_acc = 0.95947834187238\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 100, train_loss = 18.461472421884537, train_acc = 0.9595947834187238\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 101, train_loss = 18.43257424980402, train_acc = 0.9597112249650676\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 102, train_loss = 18.395170042291284, train_acc = 0.9598276665114113\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 103, train_loss = 18.36425451375544, train_acc = 0.959944108057755\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 104, train_loss = 18.316982774063945, train_acc = 0.9602934326967862\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 105, train_loss = 18.291917691007257, train_acc = 0.96040987424313\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 106, train_loss = 18.259426133707166, train_acc = 0.96040987424313\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 107, train_loss = 18.226184787228703, train_acc = 0.9605263157894737\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 108, train_loss = 18.194792406633496, train_acc = 0.9602934326967862\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 109, train_loss = 18.159742021933198, train_acc = 0.9605263157894737\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 110, train_loss = 18.12616823427379, train_acc = 0.9605263157894737\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 111, train_loss = 18.096139699220657, train_acc = 0.9606427573358174\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 112, train_loss = 18.06920799612999, train_acc = 0.9607591988821611\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 113, train_loss = 18.0254890602082, train_acc = 0.9608756404285049\n",
      "test Acc 0.9445996275605214:\n",
      "25th- epoch: 114, train_loss = 17.993117274716496, train_acc = 0.9609920819748486\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 115, train_loss = 17.971707882359624, train_acc = 0.9611085235211924\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 116, train_loss = 17.928863944485784, train_acc = 0.9611085235211924\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 117, train_loss = 17.906129421666265, train_acc = 0.9612249650675361\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 118, train_loss = 17.869393849745393, train_acc = 0.9612249650675361\n",
      "test Acc 0.9445996275605214:\n",
      "25th- epoch: 119, train_loss = 17.8324412163347, train_acc = 0.9614578481602236\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 120, train_loss = 17.8232106808573, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 121, train_loss = 17.789513697847724, train_acc = 0.9614578481602236\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 122, train_loss = 17.76835745573044, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 123, train_loss = 17.740197487175465, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "25th- epoch: 124, train_loss = 17.69430739991367, train_acc = 0.961690731252911\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 125, train_loss = 17.683592246845365, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 126, train_loss = 17.644001515582204, train_acc = 0.9618071727992548\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 127, train_loss = 17.62238704971969, train_acc = 0.9615742897065673\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 128, train_loss = 17.587800033390522, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 129, train_loss = 17.56891993433237, train_acc = 0.9619236143455985\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 130, train_loss = 17.541837418451905, train_acc = 0.9619236143455985\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 131, train_loss = 17.51045305095613, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 132, train_loss = 17.490887677296996, train_acc = 0.9620400558919422\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 133, train_loss = 17.46436790935695, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 134, train_loss = 17.450206408277154, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 135, train_loss = 17.416341545060277, train_acc = 0.962156497438286\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 136, train_loss = 17.394971249625087, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 137, train_loss = 17.371071681380272, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "25th- epoch: 138, train_loss = 17.34777184575796, train_acc = 0.9622729389846297\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 139, train_loss = 17.315986590459943, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 140, train_loss = 17.28752792812884, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 141, train_loss = 17.260241724550724, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 142, train_loss = 17.246106823906302, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 143, train_loss = 17.21953295916319, train_acc = 0.9625058220773172\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 144, train_loss = 17.205828964710236, train_acc = 0.9623893805309734\n",
      "test Acc 0.9464618249534451:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 145, train_loss = 17.18105278722942, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 146, train_loss = 17.158523611724377, train_acc = 0.9623893805309734\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 147, train_loss = 17.13792504183948, train_acc = 0.9625058220773172\n",
      "test Acc 0.9464618249534451:\n",
      "25th- epoch: 148, train_loss = 17.1194132193923, train_acc = 0.9625058220773172\n",
      "test Acc 0.9464618249534451:\n",
      "25th- epoch: 149, train_loss = 17.094799457117915, train_acc = 0.9626222636236609\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 150, train_loss = 17.073767095804214, train_acc = 0.9628551467163484\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 151, train_loss = 17.051052272319794, train_acc = 0.9627387051700047\n",
      "test Acc 0.9464618249534451:\n",
      "25th- epoch: 152, train_loss = 17.030630519613624, train_acc = 0.9628551467163484\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 153, train_loss = 17.007687471807003, train_acc = 0.9626222636236609\n",
      "test Acc 0.9464618249534451:\n",
      "25th- epoch: 154, train_loss = 16.994171996600926, train_acc = 0.9627387051700047\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 155, train_loss = 16.96596840955317, train_acc = 0.9628551467163484\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 156, train_loss = 16.951083448715508, train_acc = 0.9629715882626921\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 157, train_loss = 16.93361651711166, train_acc = 0.9629715882626921\n",
      "test Acc 0.9464618249534451:\n",
      "25th- epoch: 158, train_loss = 16.918061202391982, train_acc = 0.9628551467163484\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 159, train_loss = 16.885105927474797, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 160, train_loss = 16.88540303427726, train_acc = 0.9629715882626921\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 161, train_loss = 16.844655752182007, train_acc = 0.9632044713553796\n",
      "test Acc 0.9464618249534451:\n",
      "25th- epoch: 162, train_loss = 16.83771138638258, train_acc = 0.9629715882626921\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 163, train_loss = 16.823494833894074, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 164, train_loss = 16.792719540186226, train_acc = 0.9633209129017233\n",
      "test Acc 0.9464618249534451:\n",
      "25th- epoch: 165, train_loss = 16.780756580643356, train_acc = 0.9632044713553796\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 166, train_loss = 16.759650607593358, train_acc = 0.9632044713553796\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 167, train_loss = 16.74005775153637, train_acc = 0.9633209129017233\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 168, train_loss = 16.72427195031196, train_acc = 0.9633209129017233\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 169, train_loss = 16.702446222305298, train_acc = 0.9634373544480671\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 170, train_loss = 16.6970560727641, train_acc = 0.9634373544480671\n",
      "test Acc 0.9464618249534451:\n",
      "25th- epoch: 171, train_loss = 16.665159319527447, train_acc = 0.9634373544480671\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 172, train_loss = 16.649839927442372, train_acc = 0.9634373544480671\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 173, train_loss = 16.62938262987882, train_acc = 0.9634373544480671\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 174, train_loss = 16.603633302263916, train_acc = 0.9634373544480671\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 175, train_loss = 16.588228623382747, train_acc = 0.9634373544480671\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 176, train_loss = 16.57339263241738, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 177, train_loss = 16.551646332256496, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 178, train_loss = 16.55253927130252, train_acc = 0.9635537959944108\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 179, train_loss = 16.525231736712158, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 180, train_loss = 16.50277082901448, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 181, train_loss = 16.4949662508443, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 182, train_loss = 16.470691420137882, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 183, train_loss = 16.456414555199444, train_acc = 0.9636702375407545\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 184, train_loss = 16.44582456815988, train_acc = 0.9635537959944108\n",
      "test Acc 0.946927374301676:\n",
      "25th- epoch: 185, train_loss = 16.423873673193157, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 186, train_loss = 16.415393821895123, train_acc = 0.9637866790870983\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 187, train_loss = 16.38988372962922, train_acc = 0.963903120633442\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 188, train_loss = 16.37857419718057, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 189, train_loss = 16.36483896803111, train_acc = 0.963903120633442\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 190, train_loss = 16.35092418640852, train_acc = 0.963903120633442\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 191, train_loss = 16.327391046099365, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 192, train_loss = 16.31346022337675, train_acc = 0.9642524452724732\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 193, train_loss = 16.30098074208945, train_acc = 0.963903120633442\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 194, train_loss = 16.28397376090288, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 195, train_loss = 16.272188815288246, train_acc = 0.9641360037261295\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 196, train_loss = 16.256657637655735, train_acc = 0.9641360037261295\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 197, train_loss = 16.239087025634944, train_acc = 0.9643688868188169\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 198, train_loss = 16.222829622216523, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 199, train_loss = 16.20866586547345, train_acc = 0.9643688868188169\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 200, train_loss = 16.197594958357513, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 201, train_loss = 16.176058555953205, train_acc = 0.9644853283651607\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 202, train_loss = 16.16934210062027, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 203, train_loss = 16.149568933062255, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 204, train_loss = 16.137821895070374, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 205, train_loss = 16.123335652053356, train_acc = 0.9646017699115044\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 206, train_loss = 16.11188370268792, train_acc = 0.9647182114578482\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 207, train_loss = 16.098942634649575, train_acc = 0.9647182114578482\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 208, train_loss = 16.08185072708875, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 209, train_loss = 16.066764037124813, train_acc = 0.9648346530041919\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 210, train_loss = 16.05573219805956, train_acc = 0.9649510945505356\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 211, train_loss = 16.042271140031517, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 212, train_loss = 16.02280220389366, train_acc = 0.9649510945505356\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 213, train_loss = 16.015820994973183, train_acc = 0.9650675360968793\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 214, train_loss = 16.00206026714295, train_acc = 0.9650675360968793\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 215, train_loss = 15.99754894245416, train_acc = 0.9650675360968793\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 216, train_loss = 15.9774438040331, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 217, train_loss = 15.962153810076416, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 218, train_loss = 15.952205213718116, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 219, train_loss = 15.938951127231121, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 220, train_loss = 15.92644879501313, train_acc = 0.9651839776432231\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 221, train_loss = 15.908834365196526, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 222, train_loss = 15.897978599183261, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 223, train_loss = 15.886545690707862, train_acc = 0.9653004191895669\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 224, train_loss = 15.879390726797283, train_acc = 0.9651839776432231\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 225, train_loss = 15.865068472921848, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 226, train_loss = 15.847120155580342, train_acc = 0.9654168607359106\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 227, train_loss = 15.847112287767231, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 228, train_loss = 15.835423749871552, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 229, train_loss = 15.821232728660107, train_acc = 0.9653004191895669\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 230, train_loss = 15.804035492241383, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 231, train_loss = 15.799370120279491, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 232, train_loss = 15.781331735663116, train_acc = 0.9654168607359106\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 233, train_loss = 15.764618292450905, train_acc = 0.9655333022822543\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 234, train_loss = 15.761167076416314, train_acc = 0.9654168607359106\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 235, train_loss = 15.753373146057129, train_acc = 0.9654168607359106\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 236, train_loss = 15.737026068381965, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 237, train_loss = 15.719905331730843, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 238, train_loss = 15.715491086244583, train_acc = 0.965649743828598\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 239, train_loss = 15.698323209770024, train_acc = 0.9655333022822543\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 240, train_loss = 15.686972732655704, train_acc = 0.965649743828598\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 241, train_loss = 15.680245933122933, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 242, train_loss = 15.668453830294311, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 243, train_loss = 15.651842040009797, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 244, train_loss = 15.64784213155508, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 245, train_loss = 15.628641282208264, train_acc = 0.965649743828598\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 246, train_loss = 15.623711593449116, train_acc = 0.9657661853749417\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 247, train_loss = 15.610112863592803, train_acc = 0.965649743828598\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 248, train_loss = 15.602567966096103, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 249, train_loss = 15.589753682725132, train_acc = 0.9658826269212856\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 250, train_loss = 15.5750681636855, train_acc = 0.9657661853749417\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 251, train_loss = 15.565601629205048, train_acc = 0.9658826269212856\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 252, train_loss = 15.564648854546249, train_acc = 0.9658826269212856\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 253, train_loss = 15.555317568592727, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 254, train_loss = 15.537091893143952, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 255, train_loss = 15.525093126110733, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 256, train_loss = 15.51745471637696, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 257, train_loss = 15.504625909030437, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 258, train_loss = 15.49987007677555, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 259, train_loss = 15.487738539464772, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 260, train_loss = 15.469962465576828, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 261, train_loss = 15.46279012132436, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 262, train_loss = 15.450690023601055, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 263, train_loss = 15.444522120058537, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 264, train_loss = 15.432647712528706, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 265, train_loss = 15.422617915086448, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 266, train_loss = 15.422307330183685, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 267, train_loss = 15.40514800697565, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "25th- epoch: 268, train_loss = 15.39447042811662, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 269, train_loss = 15.383880141191185, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 270, train_loss = 15.375451691448689, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 271, train_loss = 15.368398156948388, train_acc = 0.966115510013973\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 272, train_loss = 15.35322589147836, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 273, train_loss = 15.3469775095582, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 274, train_loss = 15.341650393791497, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 275, train_loss = 15.327757497318089, train_acc = 0.966115510013973\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 276, train_loss = 15.319450837559998, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 277, train_loss = 15.310791485011578, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 278, train_loss = 15.296929158270359, train_acc = 0.9663483931066604\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 279, train_loss = 15.287345279939473, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 280, train_loss = 15.276431214995682, train_acc = 0.9662319515603167\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 281, train_loss = 15.268634922802448, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 282, train_loss = 15.259108965285122, train_acc = 0.9664648346530041\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 283, train_loss = 15.253312580287457, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 284, train_loss = 15.247044528834522, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 285, train_loss = 15.232704363763332, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 286, train_loss = 15.22304788697511, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 287, train_loss = 15.219384387135506, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 288, train_loss = 15.209910380654037, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 289, train_loss = 15.202309909276664, train_acc = 0.966581276199348\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 290, train_loss = 15.195397727191448, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 291, train_loss = 15.179167062044144, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 292, train_loss = 15.173571732826531, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 293, train_loss = 15.163169905543327, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 294, train_loss = 15.15460395347327, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 295, train_loss = 15.153939967043698, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 296, train_loss = 15.147471457719803, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 297, train_loss = 15.132303687743843, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 298, train_loss = 15.121716792695224, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 299, train_loss = 15.116993722505867, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 300, train_loss = 15.112135755829513, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 301, train_loss = 15.094787794165313, train_acc = 0.9666977177456917\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 302, train_loss = 15.097250473685563, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 303, train_loss = 15.081236600875854, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 304, train_loss = 15.079598240554333, train_acc = 0.9666977177456917\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 305, train_loss = 15.065218634903431, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 306, train_loss = 15.05712524522096, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 307, train_loss = 15.058348953723907, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 308, train_loss = 15.03961040545255, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 309, train_loss = 15.030978314578533, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 310, train_loss = 15.031219601631165, train_acc = 0.9669306008383791\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 311, train_loss = 15.025259032845497, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 312, train_loss = 15.008822823874652, train_acc = 0.9668141592920354\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 313, train_loss = 14.99863854330033, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 314, train_loss = 14.98925660084933, train_acc = 0.9668141592920354\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 315, train_loss = 14.983702577650547, train_acc = 0.9670470423847228\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 316, train_loss = 14.976347493939102, train_acc = 0.9670470423847228\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 317, train_loss = 14.969496863894165, train_acc = 0.9670470423847228\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 318, train_loss = 14.957820184528828, train_acc = 0.9669306008383791\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 319, train_loss = 14.954252310097218, train_acc = 0.9670470423847228\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 320, train_loss = 14.941951759159565, train_acc = 0.9670470423847228\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 321, train_loss = 14.939248830080032, train_acc = 0.9671634839310667\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 322, train_loss = 14.93342615198344, train_acc = 0.9671634839310667\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 323, train_loss = 14.922657273709774, train_acc = 0.9671634839310667\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 324, train_loss = 14.917617621831596, train_acc = 0.9670470423847228\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 325, train_loss = 14.910090227611363, train_acc = 0.9670470423847228\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 326, train_loss = 14.909411233849823, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 327, train_loss = 14.894921864382923, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 328, train_loss = 14.88223430979997, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 329, train_loss = 14.876316219568253, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 330, train_loss = 14.870993887074292, train_acc = 0.9672799254774104\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 331, train_loss = 14.870181021280587, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 332, train_loss = 14.854760830290616, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 333, train_loss = 14.849678267724812, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 334, train_loss = 14.84258459508419, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 335, train_loss = 14.836849984712899, train_acc = 0.9675128085700978\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 336, train_loss = 14.82715505361557, train_acc = 0.9673963670237541\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 337, train_loss = 14.81915043015033, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 338, train_loss = 14.810951367020607, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 339, train_loss = 14.807658242993057, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 340, train_loss = 14.797229669988155, train_acc = 0.9676292501164415\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 341, train_loss = 14.793668821454048, train_acc = 0.9678621332091291\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 342, train_loss = 14.78252378385514, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 343, train_loss = 14.780058863572776, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 344, train_loss = 14.767919431440532, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 345, train_loss = 14.768231791444123, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 346, train_loss = 14.758503369987011, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 347, train_loss = 14.749762495048344, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 348, train_loss = 14.73951705545187, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 349, train_loss = 14.73812894243747, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 350, train_loss = 14.727633732371032, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 351, train_loss = 14.722237040288746, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 352, train_loss = 14.710714310407639, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 353, train_loss = 14.710760678164661, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 354, train_loss = 14.69938977342099, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 355, train_loss = 14.695864751935005, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 356, train_loss = 14.687657497823238, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 357, train_loss = 14.682597763836384, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 358, train_loss = 14.674837668426335, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 359, train_loss = 14.679209138266742, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 360, train_loss = 14.659067551605403, train_acc = 0.9680950163018165\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 361, train_loss = 14.655429127626121, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 362, train_loss = 14.646191214211285, train_acc = 0.9683278993945039\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 363, train_loss = 14.645387324504554, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 364, train_loss = 14.637719000689685, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 365, train_loss = 14.630541671998799, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 366, train_loss = 14.62019868195057, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 367, train_loss = 14.618435509502888, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 368, train_loss = 14.612343485467136, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 369, train_loss = 14.604467898607254, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 370, train_loss = 14.594756211154163, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 371, train_loss = 14.592277457006276, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 372, train_loss = 14.590994402766228, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 373, train_loss = 14.577557471580803, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 374, train_loss = 14.576295238919556, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 375, train_loss = 14.567618804983795, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 376, train_loss = 14.558697295375168, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 377, train_loss = 14.555628697387874, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 378, train_loss = 14.55034186411649, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 379, train_loss = 14.539325043559074, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 380, train_loss = 14.534098860807717, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 381, train_loss = 14.526480657048523, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 382, train_loss = 14.520004789344966, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 383, train_loss = 14.520058915019035, train_acc = 0.9683278993945039\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 384, train_loss = 14.511083747260273, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 385, train_loss = 14.512006799690425, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 386, train_loss = 14.496947932057083, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 387, train_loss = 14.494134140200913, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 388, train_loss = 14.489839784801006, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 389, train_loss = 14.487130863126367, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 390, train_loss = 14.478029052726924, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 391, train_loss = 14.469975280575454, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 392, train_loss = 14.459923948161304, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 393, train_loss = 14.459042593836784, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 394, train_loss = 14.450747263617814, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 395, train_loss = 14.449433609843254, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 396, train_loss = 14.438271529972553, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 397, train_loss = 14.430690221488476, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 398, train_loss = 14.426608677022159, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 399, train_loss = 14.428432030137628, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 400, train_loss = 14.415601489134133, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 401, train_loss = 14.410554367117584, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 402, train_loss = 14.406474302522838, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 403, train_loss = 14.401189977768809, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 404, train_loss = 14.394793515093625, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 405, train_loss = 14.392133491579443, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 406, train_loss = 14.381959023419768, train_acc = 0.9685607824871915\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 407, train_loss = 14.3775096363388, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 408, train_loss = 14.373383914120495, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 409, train_loss = 14.369642411824316, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "25th- epoch: 410, train_loss = 14.363289088010788, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 411, train_loss = 14.359218418598175, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 412, train_loss = 14.348893128335476, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 413, train_loss = 14.341689067427069, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 414, train_loss = 14.337156554218382, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 415, train_loss = 14.334522863384336, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 416, train_loss = 14.329581655561924, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 417, train_loss = 14.329237627331167, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 418, train_loss = 14.315392658114433, train_acc = 0.9686772240335352\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 419, train_loss = 14.314173465128988, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 420, train_loss = 14.30851567024365, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 421, train_loss = 14.30309628462419, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 422, train_loss = 14.296320843044668, train_acc = 0.9685607824871915\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 423, train_loss = 14.295432766433805, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 424, train_loss = 14.284779312554747, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 425, train_loss = 14.282637514173985, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 426, train_loss = 14.277150273323059, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 427, train_loss = 14.27300784504041, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 428, train_loss = 14.267727640923113, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 429, train_loss = 14.259463302791119, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 430, train_loss = 14.259359665215015, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 431, train_loss = 14.253491362091154, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 432, train_loss = 14.24751670891419, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 433, train_loss = 14.24047910189256, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 434, train_loss = 14.234325669705868, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 435, train_loss = 14.23441236699, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 436, train_loss = 14.227176492568105, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 437, train_loss = 14.223559687379748, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 438, train_loss = 14.219979504588991, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 439, train_loss = 14.212669295724481, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 440, train_loss = 14.202606238424778, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 441, train_loss = 14.203573738690466, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 442, train_loss = 14.19686105614528, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 443, train_loss = 14.191033825278282, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 444, train_loss = 14.186140152160078, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 445, train_loss = 14.184786958154291, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 446, train_loss = 14.180968304630369, train_acc = 0.9693758733115976\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 447, train_loss = 14.172769352793694, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 448, train_loss = 14.170453004539013, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 449, train_loss = 14.163238319102675, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 450, train_loss = 14.160223665181547, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 451, train_loss = 14.15397802228108, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 452, train_loss = 14.145733261946589, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 453, train_loss = 14.146982649806887, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 454, train_loss = 14.141714090947062, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 455, train_loss = 14.13472905009985, train_acc = 0.9694923148579413\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 456, train_loss = 14.129693910479546, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 457, train_loss = 14.12414695834741, train_acc = 0.9697251979506288\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 458, train_loss = 14.123129978775978, train_acc = 0.969608756404285\n",
      "test Acc 0.9497206703910615:\n",
      "25th- epoch: 459, train_loss = 14.119182646274567, train_acc = 0.9697251979506288\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 460, train_loss = 14.110207080841064, train_acc = 0.9697251979506288\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 461, train_loss = 14.104893811047077, train_acc = 0.9697251979506288\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 462, train_loss = 14.103871916886419, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 463, train_loss = 14.096954504493624, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 464, train_loss = 14.096797639969736, train_acc = 0.9697251979506288\n",
      "test Acc 0.9497206703910615:\n",
      "25th- epoch: 465, train_loss = 14.092856851872057, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 466, train_loss = 14.087899804115295, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "25th- epoch: 467, train_loss = 14.08055001264438, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 468, train_loss = 14.076294449623674, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 469, train_loss = 14.073047069367021, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 470, train_loss = 14.0720746666193, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 471, train_loss = 14.05891594523564, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 472, train_loss = 14.062190532684326, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 473, train_loss = 14.051428390201181, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 474, train_loss = 14.046978076454252, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 475, train_loss = 14.042963442858309, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 476, train_loss = 14.041054795030504, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 477, train_loss = 14.034496277570724, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 478, train_loss = 14.032561334315687, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 479, train_loss = 14.027495011687279, train_acc = 0.9701909641360037\n",
      "test Acc 0.9497206703910615:\n",
      "25th- epoch: 480, train_loss = 14.023913470562547, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 481, train_loss = 14.017768593970686, train_acc = 0.97007452258966\n",
      "test Acc 0.9501862197392924:\n",
      "25th- epoch: 482, train_loss = 14.018135545309633, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 483, train_loss = 14.010835900902748, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 484, train_loss = 14.005218552891165, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 485, train_loss = 14.001797256525606, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 486, train_loss = 13.999871119856834, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 487, train_loss = 13.994080446660519, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 488, train_loss = 13.986853202339262, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 489, train_loss = 13.983428006526083, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 490, train_loss = 13.977522812783718, train_acc = 0.9701909641360037\n",
      "test Acc 0.9501862197392924:\n",
      "25th- epoch: 491, train_loss = 13.982317738234997, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 492, train_loss = 13.973340138792992, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 493, train_loss = 13.9655857286416, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 494, train_loss = 13.962069660425186, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 495, train_loss = 13.95870049810037, train_acc = 0.9701909641360037\n",
      "test Acc 0.9497206703910615:\n",
      "25th- epoch: 496, train_loss = 13.95959830051288, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 497, train_loss = 13.953393312636763, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 498, train_loss = 13.945696940179914, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "25th- epoch: 499, train_loss = 13.938487534876913, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████            | 25/30 [3:46:18<45:15, 543.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "26th- epoch: 0, train_loss = 115.4410684555769, train_acc = 0.7814392175128085\n",
      "test Acc 0.8789571694599627:\n",
      "26th- epoch: 1, train_loss = 54.94027541577816, train_acc = 0.8835584536562645\n",
      "test Acc 0.9022346368715084:\n",
      "26th- epoch: 2, train_loss = 47.171870470047, train_acc = 0.8990451793199814\n",
      "test Acc 0.910148975791434:\n",
      "26th- epoch: 3, train_loss = 42.9403131082654, train_acc = 0.9078947368421053\n",
      "test Acc 0.914804469273743:\n",
      "26th- epoch: 4, train_loss = 39.9950849711895, train_acc = 0.9127852817885421\n",
      "test Acc 0.9189944134078212:\n",
      "26th- epoch: 5, train_loss = 37.688808768987656, train_acc = 0.9175593851886353\n",
      "test Acc 0.9217877094972067:\n",
      "26th- epoch: 6, train_loss = 35.833148919045925, train_acc = 0.9217512808570097\n",
      "test Acc 0.9231843575418994:\n",
      "26th- epoch: 7, train_loss = 34.34542567282915, train_acc = 0.9254774103400093\n",
      "test Acc 0.9241154562383612:\n",
      "26th- epoch: 8, train_loss = 33.17795496433973, train_acc = 0.9274569166278528\n",
      "test Acc 0.9278398510242085:\n",
      "26th- epoch: 9, train_loss = 32.164115995168686, train_acc = 0.9296693060083838\n",
      "test Acc 0.9283054003724395:\n",
      "26th- epoch: 10, train_loss = 31.289284132421017, train_acc = 0.9311830461108523\n",
      "test Acc 0.9292364990689013:\n",
      "26th- epoch: 11, train_loss = 30.47735921666026, train_acc = 0.9331625523986958\n",
      "test Acc 0.9287709497206704:\n",
      "26th- epoch: 12, train_loss = 29.755751948803663, train_acc = 0.9343269678621332\n",
      "test Acc 0.931098696461825:\n",
      "26th- epoch: 13, train_loss = 29.13371403887868, train_acc = 0.935258500232883\n",
      "test Acc 0.9324953445065177:\n",
      "26th- epoch: 14, train_loss = 28.559610083699226, train_acc = 0.936190032603633\n",
      "test Acc 0.9324953445065177:\n",
      "26th- epoch: 15, train_loss = 28.035705268383026, train_acc = 0.9375873311597578\n",
      "test Acc 0.9329608938547486:\n",
      "26th- epoch: 16, train_loss = 27.54803705587983, train_acc = 0.9391010712622264\n",
      "test Acc 0.9324953445065177:\n",
      "26th- epoch: 17, train_loss = 27.09583993628621, train_acc = 0.9404983698183512\n",
      "test Acc 0.9357541899441341:\n",
      "26th- epoch: 18, train_loss = 26.70413827523589, train_acc = 0.9409641360037261\n",
      "test Acc 0.936219739292365:\n",
      "26th- epoch: 19, train_loss = 26.308580428361893, train_acc = 0.9422449930135072\n",
      "test Acc 0.9371508379888268:\n",
      "26th- epoch: 20, train_loss = 25.975309014320374, train_acc = 0.9430600838379134\n",
      "test Acc 0.9376163873370578:\n",
      "26th- epoch: 21, train_loss = 25.632720705121756, train_acc = 0.9444573823940382\n",
      "test Acc 0.9394785847299814:\n",
      "26th- epoch: 22, train_loss = 25.33854464441538, train_acc = 0.9439916162086632\n",
      "test Acc 0.9390130353817505:\n",
      "26th- epoch: 23, train_loss = 25.07665526866913, train_acc = 0.9448067070330693\n",
      "test Acc 0.9399441340782123:\n",
      "26th- epoch: 24, train_loss = 24.803654965013266, train_acc = 0.945854680950163\n",
      "test Acc 0.9408752327746741:\n",
      "26th- epoch: 25, train_loss = 24.549724366515875, train_acc = 0.9460875640428504\n",
      "test Acc 0.9408752327746741:\n",
      "26th- epoch: 26, train_loss = 24.316271293908358, train_acc = 0.9477177456916628\n",
      "test Acc 0.9418063314711359:\n",
      "26th- epoch: 27, train_loss = 24.09420522674918, train_acc = 0.9482999534233815\n",
      "test Acc 0.9418063314711359:\n",
      "26th- epoch: 28, train_loss = 23.88044546544552, train_acc = 0.9486492780624126\n",
      "test Acc 0.9422718808193669:\n",
      "26th- epoch: 29, train_loss = 23.674958739429712, train_acc = 0.9491150442477876\n",
      "test Acc 0.9422718808193669:\n",
      "26th- epoch: 30, train_loss = 23.465176362544298, train_acc = 0.9494643688868188\n",
      "test Acc 0.9427374301675978:\n",
      "26th- epoch: 31, train_loss = 23.26514181867242, train_acc = 0.9496972519795063\n",
      "test Acc 0.9427374301675978:\n",
      "26th- epoch: 32, train_loss = 23.093783989548683, train_acc = 0.9500465766185375\n",
      "test Acc 0.9432029795158287:\n",
      "26th- epoch: 33, train_loss = 22.92564694583416, train_acc = 0.9503959012575687\n",
      "test Acc 0.9436685288640596:\n",
      "26th- epoch: 34, train_loss = 22.76415516063571, train_acc = 0.9508616674429436\n",
      "test Acc 0.9436685288640596:\n",
      "26th- epoch: 35, train_loss = 22.627008248120546, train_acc = 0.9509781089892874\n",
      "test Acc 0.9445996275605214:\n",
      "26th- epoch: 36, train_loss = 22.474243700504303, train_acc = 0.9514438751746623\n",
      "test Acc 0.9445996275605214:\n",
      "26th- epoch: 37, train_loss = 22.33580857515335, train_acc = 0.951560316721006\n",
      "test Acc 0.9445996275605214:\n",
      "26th- epoch: 38, train_loss = 22.19198637455702, train_acc = 0.9517931998136935\n",
      "test Acc 0.9445996275605214:\n",
      "26th- epoch: 39, train_loss = 22.059990167617798, train_acc = 0.9519096413600373\n",
      "test Acc 0.9445996275605214:\n",
      "26th- epoch: 40, train_loss = 21.945770230144262, train_acc = 0.9521425244527247\n",
      "test Acc 0.9445996275605214:\n",
      "26th- epoch: 41, train_loss = 21.811905283480883, train_acc = 0.9523754075454122\n",
      "test Acc 0.9445996275605214:\n",
      "26th- epoch: 42, train_loss = 21.71070720627904, train_acc = 0.952491849091756\n",
      "test Acc 0.9445996275605214:\n",
      "26th- epoch: 43, train_loss = 21.574065539985895, train_acc = 0.9529576152771309\n",
      "test Acc 0.9445996275605214:\n",
      "26th- epoch: 44, train_loss = 21.465522496029735, train_acc = 0.9530740568234746\n",
      "test Acc 0.9445996275605214:\n",
      "26th- epoch: 45, train_loss = 21.36791203916073, train_acc = 0.9531904983698184\n",
      "test Acc 0.9445996275605214:\n",
      "26th- epoch: 46, train_loss = 21.238653399050236, train_acc = 0.9535398230088495\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 47, train_loss = 21.14187853038311, train_acc = 0.9537727061015371\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 48, train_loss = 21.048952313140035, train_acc = 0.9538891476478808\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 49, train_loss = 20.95303512364626, train_acc = 0.9540055891942245\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 50, train_loss = 20.86849096417427, train_acc = 0.9541220307405682\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 51, train_loss = 20.760696060955524, train_acc = 0.9541220307405682\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 52, train_loss = 20.681943202391267, train_acc = 0.9543549138332557\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 53, train_loss = 20.610600985586643, train_acc = 0.9547042384722869\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 54, train_loss = 20.528737291693687, train_acc = 0.9545877969259432\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 55, train_loss = 20.433052018284798, train_acc = 0.9548206800186306\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 56, train_loss = 20.347235111519694, train_acc = 0.9550535631113182\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 57, train_loss = 20.269893184304237, train_acc = 0.9551700046576619\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 58, train_loss = 20.196265624836087, train_acc = 0.9551700046576619\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 59, train_loss = 20.142569363117218, train_acc = 0.9551700046576619\n",
      "test Acc 0.9441340782122905:\n",
      "26th- epoch: 60, train_loss = 20.061009692028165, train_acc = 0.9550535631113182\n",
      "test Acc 0.9450651769087524:\n",
      "26th- epoch: 61, train_loss = 19.989582331851125, train_acc = 0.9556357708430367\n",
      "test Acc 0.9450651769087524:\n",
      "26th- epoch: 62, train_loss = 19.913351418450475, train_acc = 0.9556357708430367\n",
      "test Acc 0.9450651769087524:\n",
      "26th- epoch: 63, train_loss = 19.850994244217873, train_acc = 0.9558686539357243\n",
      "test Acc 0.9450651769087524:\n",
      "26th- epoch: 64, train_loss = 19.778697898611426, train_acc = 0.9558686539357243\n",
      "test Acc 0.9450651769087524:\n",
      "26th- epoch: 65, train_loss = 19.72108406573534, train_acc = 0.9558686539357243\n",
      "test Acc 0.9450651769087524:\n",
      "26th- epoch: 66, train_loss = 19.65324673615396, train_acc = 0.955985095482068\n",
      "test Acc 0.9459962756052142:\n",
      "26th- epoch: 67, train_loss = 19.606233559548855, train_acc = 0.9561015370284117\n",
      "test Acc 0.9459962756052142:\n",
      "26th- epoch: 68, train_loss = 19.547286989167333, train_acc = 0.9562179785747554\n",
      "test Acc 0.9455307262569832:\n",
      "26th- epoch: 69, train_loss = 19.48297498933971, train_acc = 0.9562179785747554\n",
      "test Acc 0.9459962756052142:\n",
      "26th- epoch: 70, train_loss = 19.43074186705053, train_acc = 0.9565673032137867\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 71, train_loss = 19.35490014962852, train_acc = 0.9565673032137867\n",
      "test Acc 0.9459962756052142:\n",
      "26th- epoch: 72, train_loss = 19.303766107186675, train_acc = 0.9565673032137867\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 73, train_loss = 19.264458276331425, train_acc = 0.9566837447601304\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 74, train_loss = 19.20016822963953, train_acc = 0.9568001863064741\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 75, train_loss = 19.150445571169257, train_acc = 0.9572659524918491\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 76, train_loss = 19.084760097786784, train_acc = 0.9573823940381928\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 77, train_loss = 19.03600556589663, train_acc = 0.9573823940381928\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 78, train_loss = 18.984907990321517, train_acc = 0.9573823940381928\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 79, train_loss = 18.935510348528624, train_acc = 0.9573823940381928\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 80, train_loss = 18.90546120889485, train_acc = 0.9574988355845365\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 81, train_loss = 18.85260004363954, train_acc = 0.9574988355845365\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 82, train_loss = 18.78633303195238, train_acc = 0.9577317186772241\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 83, train_loss = 18.76028417982161, train_acc = 0.9578481602235678\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 84, train_loss = 18.70655215345323, train_acc = 0.9579646017699115\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 85, train_loss = 18.6635132599622, train_acc = 0.9580810433162552\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 86, train_loss = 18.639115318655968, train_acc = 0.9580810433162552\n",
      "test Acc 0.946927374301676:\n",
      "26th- epoch: 87, train_loss = 18.58544757589698, train_acc = 0.9580810433162552\n",
      "test Acc 0.9473929236499069:\n",
      "26th- epoch: 88, train_loss = 18.540552474558353, train_acc = 0.9581974848625989\n",
      "test Acc 0.9473929236499069:\n",
      "26th- epoch: 89, train_loss = 18.49669798836112, train_acc = 0.9580810433162552\n",
      "test Acc 0.9473929236499069:\n",
      "26th- epoch: 90, train_loss = 18.445666017010808, train_acc = 0.9581974848625989\n",
      "test Acc 0.9473929236499069:\n",
      "26th- epoch: 91, train_loss = 18.403215201571584, train_acc = 0.9581974848625989\n",
      "test Acc 0.9473929236499069:\n",
      "26th- epoch: 92, train_loss = 18.36760070733726, train_acc = 0.9583139264089428\n",
      "test Acc 0.9473929236499069:\n",
      "26th- epoch: 93, train_loss = 18.318373953923583, train_acc = 0.9581974848625989\n",
      "test Acc 0.9473929236499069:\n",
      "26th- epoch: 94, train_loss = 18.306879932060838, train_acc = 0.9583139264089428\n",
      "test Acc 0.9473929236499069:\n",
      "26th- epoch: 95, train_loss = 18.255633438006043, train_acc = 0.9583139264089428\n",
      "test Acc 0.9473929236499069:\n",
      "26th- epoch: 96, train_loss = 18.21291603706777, train_acc = 0.9586632510479739\n",
      "test Acc 0.9478584729981379:\n",
      "26th- epoch: 97, train_loss = 18.1868988070637, train_acc = 0.9588961341406614\n",
      "test Acc 0.9478584729981379:\n",
      "26th- epoch: 98, train_loss = 18.131753088906407, train_acc = 0.9588961341406614\n",
      "test Acc 0.9478584729981379:\n",
      "26th- epoch: 99, train_loss = 18.114587604999542, train_acc = 0.9591290172333489\n",
      "test Acc 0.9478584729981379:\n",
      "26th- epoch: 100, train_loss = 18.07759309373796, train_acc = 0.95947834187238\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 101, train_loss = 18.039085244759917, train_acc = 0.9595947834187238\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 102, train_loss = 18.000328248366714, train_acc = 0.9597112249650676\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 103, train_loss = 17.97023425064981, train_acc = 0.9598276665114113\n",
      "test Acc 0.9478584729981379:\n",
      "26th- epoch: 104, train_loss = 17.936378812417388, train_acc = 0.9597112249650676\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 105, train_loss = 17.89404997229576, train_acc = 0.9597112249650676\n",
      "test Acc 0.9478584729981379:\n",
      "26th- epoch: 106, train_loss = 17.869683489203453, train_acc = 0.959944108057755\n",
      "test Acc 0.9478584729981379:\n",
      "26th- epoch: 107, train_loss = 17.835645370185375, train_acc = 0.9601769911504425\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 108, train_loss = 17.801455879583955, train_acc = 0.959944108057755\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 109, train_loss = 17.76400643773377, train_acc = 0.9600605496040987\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 110, train_loss = 17.75793975777924, train_acc = 0.9601769911504425\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 111, train_loss = 17.699223218485713, train_acc = 0.9602934326967862\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 112, train_loss = 17.671913048252463, train_acc = 0.9602934326967862\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 113, train_loss = 17.647401809692383, train_acc = 0.96040987424313\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 114, train_loss = 17.624686194583774, train_acc = 0.9605263157894737\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 115, train_loss = 17.597309082746506, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 116, train_loss = 17.560244945809245, train_acc = 0.9607591988821611\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 117, train_loss = 17.539941174909472, train_acc = 0.9608756404285049\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 118, train_loss = 17.501651108264923, train_acc = 0.9611085235211924\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 119, train_loss = 17.47626969218254, train_acc = 0.9609920819748486\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 120, train_loss = 17.467958180233836, train_acc = 0.9611085235211924\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 121, train_loss = 17.415030170232058, train_acc = 0.9612249650675361\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 122, train_loss = 17.40275933034718, train_acc = 0.9612249650675361\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 123, train_loss = 17.36581841111183, train_acc = 0.9613414066138798\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 124, train_loss = 17.35582016967237, train_acc = 0.9615742897065673\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 125, train_loss = 17.320899268612266, train_acc = 0.961690731252911\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 126, train_loss = 17.28982133604586, train_acc = 0.961690731252911\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 127, train_loss = 17.274688409641385, train_acc = 0.9618071727992548\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 128, train_loss = 17.241310238838196, train_acc = 0.9620400558919422\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 129, train_loss = 17.201409675180912, train_acc = 0.9619236143455985\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 130, train_loss = 17.181626515462995, train_acc = 0.9620400558919422\n",
      "test Acc 0.9483240223463687:\n",
      "26th- epoch: 131, train_loss = 17.16369047947228, train_acc = 0.9619236143455985\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 132, train_loss = 17.132651403546333, train_acc = 0.9620400558919422\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 133, train_loss = 17.100510485470295, train_acc = 0.962156497438286\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 134, train_loss = 17.082728078588843, train_acc = 0.9620400558919422\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 135, train_loss = 17.062021175399423, train_acc = 0.962156497438286\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 136, train_loss = 17.030608354136348, train_acc = 0.962156497438286\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 137, train_loss = 17.02189932204783, train_acc = 0.962156497438286\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 138, train_loss = 16.977263456210494, train_acc = 0.962156497438286\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 139, train_loss = 16.952120641246438, train_acc = 0.9623893805309734\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 140, train_loss = 16.94495782069862, train_acc = 0.9625058220773172\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 141, train_loss = 16.923757219687104, train_acc = 0.9623893805309734\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 142, train_loss = 16.896884763613343, train_acc = 0.9625058220773172\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 143, train_loss = 16.87453693151474, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 144, train_loss = 16.84584636054933, train_acc = 0.9627387051700047\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 145, train_loss = 16.822729004547, train_acc = 0.9628551467163484\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 146, train_loss = 16.80719523690641, train_acc = 0.9628551467163484\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 147, train_loss = 16.779670594260097, train_acc = 0.9629715882626921\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 148, train_loss = 16.763100972399116, train_acc = 0.9629715882626921\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 149, train_loss = 16.73466813750565, train_acc = 0.9629715882626921\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 150, train_loss = 16.73246575333178, train_acc = 0.9629715882626921\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 151, train_loss = 16.690492833033204, train_acc = 0.9633209129017233\n",
      "test Acc 0.9492551210428305:\n",
      "26th- epoch: 152, train_loss = 16.671286139637232, train_acc = 0.9632044713553796\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 153, train_loss = 16.646076422184706, train_acc = 0.9632044713553796\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 154, train_loss = 16.639203688129783, train_acc = 0.9632044713553796\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 155, train_loss = 16.620852829888463, train_acc = 0.9630880298090359\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 156, train_loss = 16.597262604162097, train_acc = 0.9632044713553796\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 157, train_loss = 16.583234891295433, train_acc = 0.9634373544480671\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 158, train_loss = 16.559747010469437, train_acc = 0.9634373544480671\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 159, train_loss = 16.526139752939343, train_acc = 0.9633209129017233\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 160, train_loss = 16.51450734399259, train_acc = 0.9635537959944108\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 161, train_loss = 16.488955022767186, train_acc = 0.9634373544480671\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 162, train_loss = 16.4670223351568, train_acc = 0.9635537959944108\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 163, train_loss = 16.448734087869525, train_acc = 0.9635537959944108\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 164, train_loss = 16.43342338129878, train_acc = 0.9635537959944108\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 165, train_loss = 16.41453704237938, train_acc = 0.9637866790870983\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 166, train_loss = 16.391340892761946, train_acc = 0.963903120633442\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 167, train_loss = 16.388743171468377, train_acc = 0.9637866790870983\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 168, train_loss = 16.364292165264487, train_acc = 0.963903120633442\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 169, train_loss = 16.346404558047652, train_acc = 0.963903120633442\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 170, train_loss = 16.33907576650381, train_acc = 0.963903120633442\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 171, train_loss = 16.32516961544752, train_acc = 0.9640195621797858\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 172, train_loss = 16.309111751616, train_acc = 0.9640195621797858\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 173, train_loss = 16.27284980006516, train_acc = 0.9641360037261295\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 174, train_loss = 16.262762857601047, train_acc = 0.9642524452724732\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 175, train_loss = 16.24017951078713, train_acc = 0.9640195621797858\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 176, train_loss = 16.228312075138092, train_acc = 0.9642524452724732\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 177, train_loss = 16.209192404523492, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 178, train_loss = 16.192734135314822, train_acc = 0.9644853283651607\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 179, train_loss = 16.17474220134318, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 180, train_loss = 16.15962505340576, train_acc = 0.9644853283651607\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 181, train_loss = 16.146717853844166, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 182, train_loss = 16.131451779976487, train_acc = 0.9644853283651607\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 183, train_loss = 16.118424778804183, train_acc = 0.9644853283651607\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 184, train_loss = 16.100458063185215, train_acc = 0.9644853283651607\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 185, train_loss = 16.08441131748259, train_acc = 0.9644853283651607\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 186, train_loss = 16.076625486835837, train_acc = 0.9643688868188169\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 187, train_loss = 16.047013672068715, train_acc = 0.9646017699115044\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 188, train_loss = 16.03997858427465, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 189, train_loss = 16.0262318123132, train_acc = 0.9646017699115044\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 190, train_loss = 16.00685527175665, train_acc = 0.9646017699115044\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 191, train_loss = 15.992094179615378, train_acc = 0.9647182114578482\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 192, train_loss = 15.981181414797902, train_acc = 0.9646017699115044\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 193, train_loss = 15.957398663274944, train_acc = 0.9646017699115044\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 194, train_loss = 15.945460872724652, train_acc = 0.9648346530041919\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 195, train_loss = 15.93325441610068, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 196, train_loss = 15.919497668743134, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 197, train_loss = 15.913070862181485, train_acc = 0.9648346530041919\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 198, train_loss = 15.901833060197532, train_acc = 0.9647182114578482\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 199, train_loss = 15.871074862778187, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 200, train_loss = 15.862074725329876, train_acc = 0.9648346530041919\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 201, train_loss = 15.847352720797062, train_acc = 0.9649510945505356\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 202, train_loss = 15.83936928678304, train_acc = 0.9649510945505356\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 203, train_loss = 15.823385019786656, train_acc = 0.9650675360968793\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 204, train_loss = 15.809776077978313, train_acc = 0.9650675360968793\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 205, train_loss = 15.799644756130874, train_acc = 0.9649510945505356\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 206, train_loss = 15.784925390966237, train_acc = 0.9650675360968793\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 207, train_loss = 15.764138147234917, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 208, train_loss = 15.761395786888897, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 209, train_loss = 15.742258419282734, train_acc = 0.9649510945505356\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 210, train_loss = 15.727945926599205, train_acc = 0.9650675360968793\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 211, train_loss = 15.71803720574826, train_acc = 0.9650675360968793\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 212, train_loss = 15.705383710563183, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 213, train_loss = 15.686778713949025, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 214, train_loss = 15.680969494394958, train_acc = 0.9650675360968793\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 215, train_loss = 15.666485900990665, train_acc = 0.9651839776432231\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 216, train_loss = 15.664139029569924, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 217, train_loss = 15.645481194369495, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 218, train_loss = 15.632659241557121, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 219, train_loss = 15.624165090732276, train_acc = 0.9653004191895669\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 220, train_loss = 15.60952631663531, train_acc = 0.9654168607359106\n",
      "test Acc 0.9497206703910615:\n",
      "26th- epoch: 221, train_loss = 15.595118860714138, train_acc = 0.9654168607359106\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 222, train_loss = 15.585569982416928, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 223, train_loss = 15.574343058280647, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 224, train_loss = 15.565961867570877, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 225, train_loss = 15.543574037961662, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 226, train_loss = 15.537060014903545, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 227, train_loss = 15.526338499970734, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 228, train_loss = 15.520484979264438, train_acc = 0.9654168607359106\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 229, train_loss = 15.508443201892078, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 230, train_loss = 15.490874168463051, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 231, train_loss = 15.489473502151668, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 232, train_loss = 15.465602949261665, train_acc = 0.9654168607359106\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 233, train_loss = 15.474443380720913, train_acc = 0.9654168607359106\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 234, train_loss = 15.450756013393402, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 235, train_loss = 15.443495740182698, train_acc = 0.9654168607359106\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 236, train_loss = 15.428859445266426, train_acc = 0.9654168607359106\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 237, train_loss = 15.416887904517353, train_acc = 0.9654168607359106\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 238, train_loss = 15.420945398509502, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 239, train_loss = 15.390178414992988, train_acc = 0.9655333022822543\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 240, train_loss = 15.388424262404442, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 241, train_loss = 15.373385998420417, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 242, train_loss = 15.37507067155093, train_acc = 0.9655333022822543\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 243, train_loss = 15.358576622791588, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 244, train_loss = 15.35758288949728, train_acc = 0.9657661853749417\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 245, train_loss = 15.32363333273679, train_acc = 0.9657661853749417\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 246, train_loss = 15.318157933652401, train_acc = 0.9655333022822543\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 247, train_loss = 15.314117240719497, train_acc = 0.965649743828598\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 248, train_loss = 15.315761618316174, train_acc = 0.965649743828598\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 249, train_loss = 15.30753109883517, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 250, train_loss = 15.283174064941704, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 251, train_loss = 15.27178097795695, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 252, train_loss = 15.260918512940407, train_acc = 0.9658826269212856\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 253, train_loss = 15.2505526766181, train_acc = 0.9657661853749417\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 254, train_loss = 15.246613872237504, train_acc = 0.9659990684676293\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 255, train_loss = 15.244772019796073, train_acc = 0.9659990684676293\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 256, train_loss = 15.231133189983666, train_acc = 0.9659990684676293\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 257, train_loss = 15.21002206671983, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 258, train_loss = 15.21429376769811, train_acc = 0.966115510013973\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 259, train_loss = 15.19790066499263, train_acc = 0.9662319515603167\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 260, train_loss = 15.178366743028164, train_acc = 0.9663483931066604\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 261, train_loss = 15.173140418715775, train_acc = 0.9664648346530041\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 262, train_loss = 15.159903871826828, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 263, train_loss = 15.156104438006878, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 264, train_loss = 15.148723785765469, train_acc = 0.9664648346530041\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 265, train_loss = 15.156461802311242, train_acc = 0.9663483931066604\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 266, train_loss = 15.128313325345516, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 267, train_loss = 15.112731334753335, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 268, train_loss = 15.118355167098343, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 269, train_loss = 15.10056525003165, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 270, train_loss = 15.085968807339668, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 271, train_loss = 15.086214532144368, train_acc = 0.966581276199348\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 272, train_loss = 15.078515644185245, train_acc = 0.966581276199348\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 273, train_loss = 15.055588622577488, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 274, train_loss = 15.06646424997598, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 275, train_loss = 15.065717008896172, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 276, train_loss = 15.02872318495065, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 277, train_loss = 15.030438373796642, train_acc = 0.9671634839310667\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 278, train_loss = 15.025226240046322, train_acc = 0.9668141592920354\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 279, train_loss = 15.011538718827069, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 280, train_loss = 14.995880451984704, train_acc = 0.9666977177456917\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 281, train_loss = 14.989977936260402, train_acc = 0.9669306008383791\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 282, train_loss = 15.001824450679123, train_acc = 0.9670470423847228\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 283, train_loss = 14.981016539037228, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 284, train_loss = 14.96707705873996, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 285, train_loss = 14.953566245734692, train_acc = 0.9669306008383791\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 286, train_loss = 14.94829548895359, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 287, train_loss = 14.947998121380806, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 288, train_loss = 14.932476937770844, train_acc = 0.9670470423847228\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 289, train_loss = 14.917902693152428, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 290, train_loss = 14.921883287839592, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 291, train_loss = 14.904817064292729, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 292, train_loss = 14.899422739632428, train_acc = 0.9671634839310667\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 293, train_loss = 14.896527670323849, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 294, train_loss = 14.895020487718284, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 295, train_loss = 14.88216032832861, train_acc = 0.9673963670237541\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 296, train_loss = 14.871417619287968, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 297, train_loss = 14.86082647740841, train_acc = 0.9672799254774104\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 298, train_loss = 14.852716187946498, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 299, train_loss = 14.84841891657561, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 300, train_loss = 14.83248911332339, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 301, train_loss = 14.843819350004196, train_acc = 0.9673963670237541\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 302, train_loss = 14.824796100147069, train_acc = 0.9675128085700978\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 303, train_loss = 14.806703510694206, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 304, train_loss = 14.806711261160672, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 305, train_loss = 14.80875422526151, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 306, train_loss = 14.795926466584206, train_acc = 0.9678621332091291\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 307, train_loss = 14.795720274560153, train_acc = 0.9676292501164415\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 308, train_loss = 14.794679336249828, train_acc = 0.9677456916627852\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 309, train_loss = 14.782878008671105, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 310, train_loss = 14.784176111221313, train_acc = 0.9677456916627852\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 311, train_loss = 14.75352202821523, train_acc = 0.9679785747554728\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 312, train_loss = 14.743263758718967, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 313, train_loss = 14.734267503023148, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 314, train_loss = 14.73348181694746, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 315, train_loss = 14.719844102859497, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 316, train_loss = 14.719139781780541, train_acc = 0.9678621332091291\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 317, train_loss = 14.712674136273563, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 318, train_loss = 14.726000060327351, train_acc = 0.9679785747554728\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 319, train_loss = 14.709047761745751, train_acc = 0.9680950163018165\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 320, train_loss = 14.694548371247947, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 321, train_loss = 14.686605858616531, train_acc = 0.9680950163018165\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 322, train_loss = 14.68403148651123, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 323, train_loss = 14.686933398246765, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 324, train_loss = 14.666259936988354, train_acc = 0.9682114578481602\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 325, train_loss = 14.655930280685425, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 326, train_loss = 14.659026078879833, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 327, train_loss = 14.642214353196323, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 328, train_loss = 14.63426173478365, train_acc = 0.9680950163018165\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 329, train_loss = 14.638802513480186, train_acc = 0.9682114578481602\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 330, train_loss = 14.622256360948086, train_acc = 0.9683278993945039\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 331, train_loss = 14.620190468616784, train_acc = 0.9686772240335352\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 332, train_loss = 14.609109856188297, train_acc = 0.9686772240335352\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 333, train_loss = 14.594476453959942, train_acc = 0.9686772240335352\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 334, train_loss = 14.589509427547455, train_acc = 0.9687936655798789\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 335, train_loss = 14.592492744326591, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 336, train_loss = 14.57707795780152, train_acc = 0.9684443409408477\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 337, train_loss = 14.576496236026287, train_acc = 0.9687936655798789\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 338, train_loss = 14.571551282890141, train_acc = 0.9687936655798789\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 339, train_loss = 14.561239478178322, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 340, train_loss = 14.550879460759461, train_acc = 0.9687936655798789\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 341, train_loss = 14.555151748470962, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 342, train_loss = 14.545017808675766, train_acc = 0.9689101071262226\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 343, train_loss = 14.547792698256671, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 344, train_loss = 14.53238383680582, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 345, train_loss = 14.526121187023818, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 346, train_loss = 14.515684708952904, train_acc = 0.9689101071262226\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 347, train_loss = 14.522264492698014, train_acc = 0.9684443409408477\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 348, train_loss = 14.52169793099165, train_acc = 0.9684443409408477\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 349, train_loss = 14.520324078388512, train_acc = 0.9685607824871915\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 350, train_loss = 14.497879274189472, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 351, train_loss = 14.486989025957882, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 352, train_loss = 14.481288239359856, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 353, train_loss = 14.473722738213837, train_acc = 0.9690265486725663\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 354, train_loss = 14.471417208202183, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 355, train_loss = 14.46060222107917, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 356, train_loss = 14.454362590797246, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 357, train_loss = 14.448732140474021, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 358, train_loss = 14.449972818605602, train_acc = 0.9690265486725663\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 359, train_loss = 14.43966343998909, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 360, train_loss = 14.432648387737572, train_acc = 0.9690265486725663\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 361, train_loss = 14.429669593460858, train_acc = 0.9690265486725663\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 362, train_loss = 14.41785113234073, train_acc = 0.9690265486725663\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 363, train_loss = 14.417577805928886, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 364, train_loss = 14.412790070287883, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 365, train_loss = 14.402430067770183, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 366, train_loss = 14.398486171849072, train_acc = 0.9691429902189101\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 367, train_loss = 14.387088540010154, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 368, train_loss = 14.383783645927906, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 369, train_loss = 14.377381309866905, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 370, train_loss = 14.37890422064811, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 371, train_loss = 14.36970144789666, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 372, train_loss = 14.361706812866032, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 373, train_loss = 14.361467003822327, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 374, train_loss = 14.354123103432357, train_acc = 0.9691429902189101\n",
      "test Acc 0.9501862197392924:\n",
      "26th- epoch: 375, train_loss = 14.349484652280807, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 376, train_loss = 14.34658405650407, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 377, train_loss = 14.339716878719628, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 378, train_loss = 14.32844855915755, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 379, train_loss = 14.327308868058026, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 380, train_loss = 14.321331669576466, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 381, train_loss = 14.313262189738452, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 382, train_loss = 14.310654680244625, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 383, train_loss = 14.306127349846065, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 384, train_loss = 14.294570800848305, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 385, train_loss = 14.288822975941002, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 386, train_loss = 14.288014884106815, train_acc = 0.9691429902189101\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 387, train_loss = 14.274389709345996, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 388, train_loss = 14.27777361124754, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 389, train_loss = 14.26777021586895, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 390, train_loss = 14.265615299344063, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 391, train_loss = 14.256703262217343, train_acc = 0.9692594317652539\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 392, train_loss = 14.250394838862121, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 393, train_loss = 14.258755561895669, train_acc = 0.9692594317652539\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 394, train_loss = 14.241052262485027, train_acc = 0.9692594317652539\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 395, train_loss = 14.232807584106922, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 396, train_loss = 14.236799056641757, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 397, train_loss = 14.230201776139438, train_acc = 0.9691429902189101\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 398, train_loss = 14.236782955937088, train_acc = 0.9692594317652539\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 399, train_loss = 14.231244471855462, train_acc = 0.9691429902189101\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 400, train_loss = 14.211164641194046, train_acc = 0.9692594317652539\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 401, train_loss = 14.205170705914497, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 402, train_loss = 14.19745669234544, train_acc = 0.9692594317652539\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 403, train_loss = 14.197111423127353, train_acc = 0.9693758733115976\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 404, train_loss = 14.191367737948895, train_acc = 0.9693758733115976\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 405, train_loss = 14.184036779217422, train_acc = 0.9692594317652539\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 406, train_loss = 14.177432037889957, train_acc = 0.9692594317652539\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 407, train_loss = 14.17585212457925, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 408, train_loss = 14.177434098906815, train_acc = 0.9692594317652539\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 409, train_loss = 14.161062587983906, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 410, train_loss = 14.160984898917377, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 411, train_loss = 14.158022622577846, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 412, train_loss = 14.147410362958908, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 413, train_loss = 14.146233986131847, train_acc = 0.9692594317652539\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 414, train_loss = 14.144791725091636, train_acc = 0.9692594317652539\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 415, train_loss = 14.136084792204201, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 416, train_loss = 14.13551081251353, train_acc = 0.9693758733115976\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 417, train_loss = 14.129879313521087, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 418, train_loss = 14.120524716563523, train_acc = 0.9693758733115976\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 419, train_loss = 14.11349318176508, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 420, train_loss = 14.111540128476918, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 421, train_loss = 14.112780285067856, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 422, train_loss = 14.102219057735056, train_acc = 0.9692594317652539\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 423, train_loss = 14.094192509539425, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 424, train_loss = 14.09781114757061, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 425, train_loss = 14.089170917868614, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 426, train_loss = 14.080221106298268, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 427, train_loss = 14.087647559586912, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 428, train_loss = 14.081046879291534, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 429, train_loss = 14.072139965835959, train_acc = 0.9693758733115976\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 430, train_loss = 14.060599967837334, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 431, train_loss = 14.06066214805469, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 432, train_loss = 14.050231563393027, train_acc = 0.9692594317652539\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 433, train_loss = 14.049425115343183, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 434, train_loss = 14.054111381527036, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 435, train_loss = 14.043311429675668, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 436, train_loss = 14.03612308204174, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 437, train_loss = 14.034571195486933, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 438, train_loss = 14.028320290148258, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 439, train_loss = 14.032437334302813, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 440, train_loss = 14.017943538725376, train_acc = 0.9694923148579413\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 441, train_loss = 14.01161241531372, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 442, train_loss = 14.012006225530058, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 443, train_loss = 14.005559647921473, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 444, train_loss = 13.997819758951664, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 445, train_loss = 13.99246971309185, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 446, train_loss = 13.99465499818325, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 447, train_loss = 13.985188437160105, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 448, train_loss = 13.98418084019795, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 449, train_loss = 13.98412233358249, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 450, train_loss = 13.982289848383516, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 451, train_loss = 13.968223127070814, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 452, train_loss = 13.966271817684174, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 453, train_loss = 13.957819717470556, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 454, train_loss = 13.958630060311407, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 455, train_loss = 13.95254027331248, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 456, train_loss = 13.957280951086432, train_acc = 0.9694923148579413\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 457, train_loss = 13.955327840987593, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 458, train_loss = 13.949701356235892, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 459, train_loss = 13.937175413127989, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 460, train_loss = 13.929755275603384, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 461, train_loss = 13.933584032114595, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 462, train_loss = 13.923067490104586, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 463, train_loss = 13.920737174805254, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 464, train_loss = 13.911341970320791, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 465, train_loss = 13.907461538910866, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 466, train_loss = 13.90417688852176, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 467, train_loss = 13.892175525426865, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 468, train_loss = 13.892754072789103, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 469, train_loss = 13.891552612185478, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 470, train_loss = 13.893645269330591, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 471, train_loss = 13.878881183918566, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 472, train_loss = 13.875210858881474, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 473, train_loss = 13.877123892307281, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 474, train_loss = 13.871604750398546, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 475, train_loss = 13.86369132483378, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 476, train_loss = 13.859050867613405, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 477, train_loss = 13.854369414504617, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 478, train_loss = 13.852401609066874, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 479, train_loss = 13.850855705793947, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 480, train_loss = 13.846418544650078, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 481, train_loss = 13.84207801753655, train_acc = 0.9694923148579413\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 482, train_loss = 13.835719828959554, train_acc = 0.9693758733115976\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 483, train_loss = 13.834604484494776, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 484, train_loss = 13.828641918953508, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 485, train_loss = 13.826424643397331, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 486, train_loss = 13.825714697595686, train_acc = 0.9693758733115976\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 487, train_loss = 13.81671009445563, train_acc = 0.9693758733115976\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 488, train_loss = 13.817446547094733, train_acc = 0.9694923148579413\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 489, train_loss = 13.810860149562359, train_acc = 0.9693758733115976\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 490, train_loss = 13.806638787034899, train_acc = 0.9693758733115976\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 491, train_loss = 13.801893087569624, train_acc = 0.9693758733115976\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 492, train_loss = 13.797180866356939, train_acc = 0.9694923148579413\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 493, train_loss = 13.790616671089083, train_acc = 0.9693758733115976\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 494, train_loss = 13.789208933711052, train_acc = 0.9694923148579413\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 495, train_loss = 13.789022229611874, train_acc = 0.9693758733115976\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 496, train_loss = 13.779997842852026, train_acc = 0.9693758733115976\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 497, train_loss = 13.787309604231268, train_acc = 0.9694923148579413\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 498, train_loss = 13.775807097554207, train_acc = 0.969608756404285\n",
      "test Acc 0.9511173184357542:\n",
      "26th- epoch: 499, train_loss = 13.7775710769929, train_acc = 0.9694923148579413\n",
      "test Acc 0.9515828677839852:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|██████████████████████████████████████████████████████████████▍         | 26/30 [3:55:22<36:13, 543.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "27th- epoch: 0, train_loss = 123.56497845053673, train_acc = 0.7475547275267815\n",
      "test Acc 0.8305400372439479:\n",
      "27th- epoch: 1, train_loss = 58.693184807896614, train_acc = 0.8735444806707033\n",
      "test Acc 0.8743016759776536:\n",
      "27th- epoch: 2, train_loss = 49.101226672530174, train_acc = 0.897880763856544\n",
      "test Acc 0.888268156424581:\n",
      "27th- epoch: 3, train_loss = 44.08827379345894, train_acc = 0.9048672566371682\n",
      "test Acc 0.9008379888268156:\n",
      "27th- epoch: 4, train_loss = 40.821395710110664, train_acc = 0.9104564508616675\n",
      "test Acc 0.9078212290502793:\n",
      "27th- epoch: 5, train_loss = 38.2874239385128, train_acc = 0.9170936190032604\n",
      "test Acc 0.9157355679702048:\n",
      "27th- epoch: 6, train_loss = 36.278288535773754, train_acc = 0.9191895668374476\n",
      "test Acc 0.9171322160148976:\n",
      "27th- epoch: 7, train_loss = 34.66441382467747, train_acc = 0.9238472286911971\n",
      "test Acc 0.9213221601489758:\n",
      "27th- epoch: 8, train_loss = 33.32652672380209, train_acc = 0.9267582673497904\n",
      "test Acc 0.9236499068901304:\n",
      "27th- epoch: 9, train_loss = 32.222946748137474, train_acc = 0.9287377736376339\n",
      "test Acc 0.9269087523277467:\n",
      "27th- epoch: 10, train_loss = 31.3058033362031, train_acc = 0.9306008383791337\n",
      "test Acc 0.9287709497206704:\n",
      "27th- epoch: 11, train_loss = 30.479453541338444, train_acc = 0.932231020027946\n",
      "test Acc 0.9297020484171322:\n",
      "27th- epoch: 12, train_loss = 29.784265957772732, train_acc = 0.9340940847694458\n",
      "test Acc 0.930633147113594:\n",
      "27th- epoch: 13, train_loss = 29.163729675114155, train_acc = 0.935724266418258\n",
      "test Acc 0.930633147113594:\n",
      "27th- epoch: 14, train_loss = 28.587428487837315, train_acc = 0.9367722403353517\n",
      "test Acc 0.930633147113594:\n",
      "27th- epoch: 15, train_loss = 28.06912675499916, train_acc = 0.9384024219841639\n",
      "test Acc 0.931098696461825:\n",
      "27th- epoch: 16, train_loss = 27.604607798159122, train_acc = 0.9393339543549138\n",
      "test Acc 0.9329608938547486:\n",
      "27th- epoch: 17, train_loss = 27.181812271475792, train_acc = 0.9404983698183512\n",
      "test Acc 0.9334264432029795:\n",
      "27th- epoch: 18, train_loss = 26.79220039397478, train_acc = 0.9407312529110387\n",
      "test Acc 0.9334264432029795:\n",
      "27th- epoch: 19, train_loss = 26.416732128709555, train_acc = 0.9413134606427573\n",
      "test Acc 0.9343575418994413:\n",
      "27th- epoch: 20, train_loss = 26.08221348002553, train_acc = 0.942361434559851\n",
      "test Acc 0.9343575418994413:\n",
      "27th- epoch: 21, train_loss = 25.773540902882814, train_acc = 0.9428272007452259\n",
      "test Acc 0.9348230912476723:\n",
      "27th- epoch: 22, train_loss = 25.477350171655416, train_acc = 0.9434094084769445\n",
      "test Acc 0.9352886405959032:\n",
      "27th- epoch: 23, train_loss = 25.206959888339043, train_acc = 0.9442244993013508\n",
      "test Acc 0.936219739292365:\n",
      "27th- epoch: 24, train_loss = 24.952411491423845, train_acc = 0.9446902654867256\n",
      "test Acc 0.936219739292365:\n",
      "27th- epoch: 25, train_loss = 24.710050255060196, train_acc = 0.945388914764788\n",
      "test Acc 0.936219739292365:\n",
      "27th- epoch: 26, train_loss = 24.477472364902496, train_acc = 0.9457382394038193\n",
      "test Acc 0.936219739292365:\n",
      "27th- epoch: 27, train_loss = 24.25535762682557, train_acc = 0.9459711224965067\n",
      "test Acc 0.9352886405959032:\n",
      "27th- epoch: 28, train_loss = 24.05124529823661, train_acc = 0.9466697717745691\n",
      "test Acc 0.9352886405959032:\n",
      "27th- epoch: 29, train_loss = 23.860246997326612, train_acc = 0.9471355379599441\n",
      "test Acc 0.9352886405959032:\n",
      "27th- epoch: 30, train_loss = 23.6617963463068, train_acc = 0.9485328365160689\n",
      "test Acc 0.9357541899441341:\n",
      "27th- epoch: 31, train_loss = 23.471187323331833, train_acc = 0.9478341872380065\n",
      "test Acc 0.936219739292365:\n",
      "27th- epoch: 32, train_loss = 23.308328170329332, train_acc = 0.9493479273404751\n",
      "test Acc 0.9366852886405959:\n",
      "27th- epoch: 33, train_loss = 23.146737150847912, train_acc = 0.9499301350721937\n",
      "test Acc 0.936219739292365:\n",
      "27th- epoch: 34, train_loss = 22.987755052745342, train_acc = 0.9505123428039124\n",
      "test Acc 0.936219739292365:\n",
      "27th- epoch: 35, train_loss = 22.836987737566233, train_acc = 0.9507452258965999\n",
      "test Acc 0.9352886405959032:\n",
      "27th- epoch: 36, train_loss = 22.677160680294037, train_acc = 0.9509781089892874\n",
      "test Acc 0.936219739292365:\n",
      "27th- epoch: 37, train_loss = 22.52808541432023, train_acc = 0.9508616674429436\n",
      "test Acc 0.936219739292365:\n",
      "27th- epoch: 38, train_loss = 22.390203040093184, train_acc = 0.9512109920819748\n",
      "test Acc 0.936219739292365:\n",
      "27th- epoch: 39, train_loss = 22.265333373099566, train_acc = 0.9517931998136935\n",
      "test Acc 0.936219739292365:\n",
      "27th- epoch: 40, train_loss = 22.138589918613434, train_acc = 0.9522589659990685\n",
      "test Acc 0.936219739292365:\n",
      "27th- epoch: 41, train_loss = 22.024221535772085, train_acc = 0.9521425244527247\n",
      "test Acc 0.9366852886405959:\n",
      "27th- epoch: 42, train_loss = 21.904706370085478, train_acc = 0.9522589659990685\n",
      "test Acc 0.9371508379888268:\n",
      "27th- epoch: 43, train_loss = 21.794381499290466, train_acc = 0.9522589659990685\n",
      "test Acc 0.9380819366852886:\n",
      "27th- epoch: 44, train_loss = 21.68561191856861, train_acc = 0.9530740568234746\n",
      "test Acc 0.9385474860335196:\n",
      "27th- epoch: 45, train_loss = 21.573900694027543, train_acc = 0.9531904983698184\n",
      "test Acc 0.9394785847299814:\n",
      "27th- epoch: 46, train_loss = 21.477093398571014, train_acc = 0.9534233814625058\n",
      "test Acc 0.9390130353817505:\n",
      "27th- epoch: 47, train_loss = 21.382389215752482, train_acc = 0.9536562645551933\n",
      "test Acc 0.9394785847299814:\n",
      "27th- epoch: 48, train_loss = 21.275736955925822, train_acc = 0.9535398230088495\n",
      "test Acc 0.9390130353817505:\n",
      "27th- epoch: 49, train_loss = 21.188966378569603, train_acc = 0.9536562645551933\n",
      "test Acc 0.9399441340782123:\n",
      "27th- epoch: 50, train_loss = 21.09226681292057, train_acc = 0.9540055891942245\n",
      "test Acc 0.9390130353817505:\n",
      "27th- epoch: 51, train_loss = 21.014741353690624, train_acc = 0.9540055891942245\n",
      "test Acc 0.9399441340782123:\n",
      "27th- epoch: 52, train_loss = 20.941765466704965, train_acc = 0.9544713553795995\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 53, train_loss = 20.85198396258056, train_acc = 0.9543549138332557\n",
      "test Acc 0.9399441340782123:\n",
      "27th- epoch: 54, train_loss = 20.75853686966002, train_acc = 0.9545877969259432\n",
      "test Acc 0.9394785847299814:\n",
      "27th- epoch: 55, train_loss = 20.677378280088305, train_acc = 0.9548206800186306\n",
      "test Acc 0.9399441340782123:\n",
      "27th- epoch: 56, train_loss = 20.605134841054678, train_acc = 0.9550535631113182\n",
      "test Acc 0.9394785847299814:\n",
      "27th- epoch: 57, train_loss = 20.525033267214894, train_acc = 0.9550535631113182\n",
      "test Acc 0.9394785847299814:\n",
      "27th- epoch: 58, train_loss = 20.451429847627878, train_acc = 0.9551700046576619\n",
      "test Acc 0.9394785847299814:\n",
      "27th- epoch: 59, train_loss = 20.393556367605925, train_acc = 0.9556357708430367\n",
      "test Acc 0.9399441340782123:\n",
      "27th- epoch: 60, train_loss = 20.322180777788162, train_acc = 0.955519329296693\n",
      "test Acc 0.9394785847299814:\n",
      "27th- epoch: 61, train_loss = 20.24458123371005, train_acc = 0.955985095482068\n",
      "test Acc 0.9399441340782123:\n",
      "27th- epoch: 62, train_loss = 20.176894430071115, train_acc = 0.9561015370284117\n",
      "test Acc 0.9399441340782123:\n",
      "27th- epoch: 63, train_loss = 20.10631050169468, train_acc = 0.9562179785747554\n",
      "test Acc 0.9394785847299814:\n",
      "27th- epoch: 64, train_loss = 20.04612085223198, train_acc = 0.956450861667443\n",
      "test Acc 0.9394785847299814:\n",
      "27th- epoch: 65, train_loss = 19.982163321226835, train_acc = 0.956450861667443\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 66, train_loss = 19.912145134061575, train_acc = 0.9565673032137867\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 67, train_loss = 19.865443201735616, train_acc = 0.9565673032137867\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 68, train_loss = 19.791061157360673, train_acc = 0.9565673032137867\n",
      "test Acc 0.9408752327746741:\n",
      "27th- epoch: 69, train_loss = 19.73699652031064, train_acc = 0.9566837447601304\n",
      "test Acc 0.9408752327746741:\n",
      "27th- epoch: 70, train_loss = 19.67544151097536, train_acc = 0.9569166278528178\n",
      "test Acc 0.9408752327746741:\n",
      "27th- epoch: 71, train_loss = 19.62544904462993, train_acc = 0.9568001863064741\n",
      "test Acc 0.9413407821229051:\n",
      "27th- epoch: 72, train_loss = 19.58814956061542, train_acc = 0.9570330693991617\n",
      "test Acc 0.9408752327746741:\n",
      "27th- epoch: 73, train_loss = 19.516527101397514, train_acc = 0.9571495109455054\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 74, train_loss = 19.471231112256646, train_acc = 0.9572659524918491\n",
      "test Acc 0.9413407821229051:\n",
      "27th- epoch: 75, train_loss = 19.410440983250737, train_acc = 0.9572659524918491\n",
      "test Acc 0.9413407821229051:\n",
      "27th- epoch: 76, train_loss = 19.362756710499525, train_acc = 0.9572659524918491\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 77, train_loss = 19.318759597837925, train_acc = 0.9573823940381928\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 78, train_loss = 19.262903345748782, train_acc = 0.9576152771308803\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 79, train_loss = 19.216831278055906, train_acc = 0.9576152771308803\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 80, train_loss = 19.15994635038078, train_acc = 0.9578481602235678\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 81, train_loss = 19.117021983489394, train_acc = 0.9579646017699115\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 82, train_loss = 19.070165995508432, train_acc = 0.9579646017699115\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 83, train_loss = 19.026607383042574, train_acc = 0.9578481602235678\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 84, train_loss = 18.963292302563787, train_acc = 0.9581974848625989\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 85, train_loss = 18.93468519486487, train_acc = 0.9583139264089428\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 86, train_loss = 18.885428501293063, train_acc = 0.9583139264089428\n",
      "test Acc 0.9413407821229051:\n",
      "27th- epoch: 87, train_loss = 18.84531144797802, train_acc = 0.9584303679552865\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 88, train_loss = 18.802851563319564, train_acc = 0.9584303679552865\n",
      "test Acc 0.9413407821229051:\n",
      "27th- epoch: 89, train_loss = 18.74915680848062, train_acc = 0.9585468095016302\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 90, train_loss = 18.71753761358559, train_acc = 0.9585468095016302\n",
      "test Acc 0.9418063314711359:\n",
      "27th- epoch: 91, train_loss = 18.662551993504167, train_acc = 0.9587796925943176\n",
      "test Acc 0.9422718808193669:\n",
      "27th- epoch: 92, train_loss = 18.62960677035153, train_acc = 0.9590125756870052\n",
      "test Acc 0.9422718808193669:\n",
      "27th- epoch: 93, train_loss = 18.582888616248965, train_acc = 0.9588961341406614\n",
      "test Acc 0.9422718808193669:\n",
      "27th- epoch: 94, train_loss = 18.548765977844596, train_acc = 0.9592454587796926\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 95, train_loss = 18.51369990222156, train_acc = 0.9590125756870052\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 96, train_loss = 18.4671592079103, train_acc = 0.9591290172333489\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 97, train_loss = 18.44308117777109, train_acc = 0.9591290172333489\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 98, train_loss = 18.40551038272679, train_acc = 0.9592454587796926\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 99, train_loss = 18.345931934192777, train_acc = 0.9592454587796926\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 100, train_loss = 18.333782022818923, train_acc = 0.9595947834187238\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 101, train_loss = 18.287943435832858, train_acc = 0.9597112249650676\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 102, train_loss = 18.25596909597516, train_acc = 0.9595947834187238\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 103, train_loss = 18.20364436134696, train_acc = 0.9597112249650676\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 104, train_loss = 18.171113695949316, train_acc = 0.9598276665114113\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 105, train_loss = 18.137499567121267, train_acc = 0.959944108057755\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 106, train_loss = 18.106687994673848, train_acc = 0.9598276665114113\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 107, train_loss = 18.081221787258983, train_acc = 0.959944108057755\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 108, train_loss = 18.034723395481706, train_acc = 0.9601769911504425\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 109, train_loss = 18.014226123690605, train_acc = 0.9601769911504425\n",
      "test Acc 0.9427374301675978:\n",
      "27th- epoch: 110, train_loss = 17.977736307308078, train_acc = 0.9601769911504425\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 111, train_loss = 17.940369900316, train_acc = 0.9602934326967862\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 112, train_loss = 17.918987961485982, train_acc = 0.9602934326967862\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 113, train_loss = 17.877873372286558, train_acc = 0.9602934326967862\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 114, train_loss = 17.845277778804302, train_acc = 0.96040987424313\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 115, train_loss = 17.80927966348827, train_acc = 0.9605263157894737\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 116, train_loss = 17.78368879854679, train_acc = 0.9605263157894737\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 117, train_loss = 17.746967004612088, train_acc = 0.9606427573358174\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 118, train_loss = 17.72858053073287, train_acc = 0.9605263157894737\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 119, train_loss = 17.68217712827027, train_acc = 0.9608756404285049\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 120, train_loss = 17.662759819999337, train_acc = 0.9609920819748486\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 121, train_loss = 17.63096099719405, train_acc = 0.9611085235211924\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 122, train_loss = 17.602840380743146, train_acc = 0.9614578481602236\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 123, train_loss = 17.57060251571238, train_acc = 0.9613414066138798\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 124, train_loss = 17.54527069069445, train_acc = 0.9613414066138798\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 125, train_loss = 17.51533962227404, train_acc = 0.9618071727992548\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 126, train_loss = 17.493295785039663, train_acc = 0.9618071727992548\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 127, train_loss = 17.45993988774717, train_acc = 0.9618071727992548\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 128, train_loss = 17.446392372250557, train_acc = 0.9619236143455985\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 129, train_loss = 17.408983385190368, train_acc = 0.9619236143455985\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 130, train_loss = 17.38498387299478, train_acc = 0.9619236143455985\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 131, train_loss = 17.36014856211841, train_acc = 0.9622729389846297\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 132, train_loss = 17.34462462924421, train_acc = 0.9623893805309734\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 133, train_loss = 17.318245397880673, train_acc = 0.9625058220773172\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 134, train_loss = 17.298666229471564, train_acc = 0.9623893805309734\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 135, train_loss = 17.261858616024256, train_acc = 0.9625058220773172\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 136, train_loss = 17.234231136739254, train_acc = 0.9623893805309734\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 137, train_loss = 17.21774125099182, train_acc = 0.9627387051700047\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 138, train_loss = 17.200729651376605, train_acc = 0.9629715882626921\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 139, train_loss = 17.170287223532796, train_acc = 0.9629715882626921\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 140, train_loss = 17.143840085715055, train_acc = 0.9629715882626921\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 141, train_loss = 17.125146839767694, train_acc = 0.9630880298090359\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 142, train_loss = 17.103217281401157, train_acc = 0.9630880298090359\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 143, train_loss = 17.08138426207006, train_acc = 0.9630880298090359\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 144, train_loss = 17.05649023503065, train_acc = 0.9630880298090359\n",
      "test Acc 0.9441340782122905:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 145, train_loss = 17.03664749674499, train_acc = 0.9632044713553796\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 146, train_loss = 17.008239900693297, train_acc = 0.9633209129017233\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 147, train_loss = 16.989847287535667, train_acc = 0.9632044713553796\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 148, train_loss = 16.967597771435976, train_acc = 0.9632044713553796\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 149, train_loss = 16.950621152296662, train_acc = 0.9632044713553796\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 150, train_loss = 16.92517763748765, train_acc = 0.9633209129017233\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 151, train_loss = 16.907730270177126, train_acc = 0.9635537959944108\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 152, train_loss = 16.885187827050686, train_acc = 0.9634373544480671\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 153, train_loss = 16.86699436791241, train_acc = 0.9636702375407545\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 154, train_loss = 16.846838859841228, train_acc = 0.9635537959944108\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 155, train_loss = 16.827433401718736, train_acc = 0.9635537959944108\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 156, train_loss = 16.808488693088293, train_acc = 0.9634373544480671\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 157, train_loss = 16.78767696581781, train_acc = 0.9635537959944108\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 158, train_loss = 16.76724506728351, train_acc = 0.9636702375407545\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 159, train_loss = 16.7470856141299, train_acc = 0.9637866790870983\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 160, train_loss = 16.715794621035457, train_acc = 0.9637866790870983\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 161, train_loss = 16.706354897469282, train_acc = 0.9637866790870983\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 162, train_loss = 16.69444416463375, train_acc = 0.9637866790870983\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 163, train_loss = 16.668023778125644, train_acc = 0.9637866790870983\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 164, train_loss = 16.65018499083817, train_acc = 0.9637866790870983\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 165, train_loss = 16.630121724680066, train_acc = 0.9637866790870983\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 166, train_loss = 16.614511078223586, train_acc = 0.9637866790870983\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 167, train_loss = 16.59933751821518, train_acc = 0.9637866790870983\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 168, train_loss = 16.585430009290576, train_acc = 0.9637866790870983\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 169, train_loss = 16.573258286342025, train_acc = 0.9637866790870983\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 170, train_loss = 16.545929780229926, train_acc = 0.9637866790870983\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 171, train_loss = 16.531506972387433, train_acc = 0.9637866790870983\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 172, train_loss = 16.50914724357426, train_acc = 0.9637866790870983\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 173, train_loss = 16.489127311855555, train_acc = 0.9637866790870983\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 174, train_loss = 16.477205833420157, train_acc = 0.9637866790870983\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 175, train_loss = 16.455863209441304, train_acc = 0.9637866790870983\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 176, train_loss = 16.44150755368173, train_acc = 0.9640195621797858\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 177, train_loss = 16.43105691857636, train_acc = 0.963903120633442\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 178, train_loss = 16.412834057584405, train_acc = 0.963903120633442\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 179, train_loss = 16.39927794598043, train_acc = 0.963903120633442\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 180, train_loss = 16.37526655383408, train_acc = 0.963903120633442\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 181, train_loss = 16.361896634101868, train_acc = 0.9640195621797858\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 182, train_loss = 16.347001664340496, train_acc = 0.9641360037261295\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 183, train_loss = 16.33018465526402, train_acc = 0.9640195621797858\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 184, train_loss = 16.320416808128357, train_acc = 0.9641360037261295\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 185, train_loss = 16.29402343183756, train_acc = 0.9640195621797858\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 186, train_loss = 16.286928702145815, train_acc = 0.9641360037261295\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 187, train_loss = 16.270677668973804, train_acc = 0.9642524452724732\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 188, train_loss = 16.248662933707237, train_acc = 0.9642524452724732\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 189, train_loss = 16.240471256896853, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 190, train_loss = 16.22405030205846, train_acc = 0.9641360037261295\n",
      "test Acc 0.9441340782122905:\n",
      "27th- epoch: 191, train_loss = 16.20744605921209, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 192, train_loss = 16.194145457819104, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 193, train_loss = 16.17360652051866, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 194, train_loss = 16.164261771366, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 195, train_loss = 16.145236175507307, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 196, train_loss = 16.133408756926656, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 197, train_loss = 16.114519825205207, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 198, train_loss = 16.1087660882622, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 199, train_loss = 16.090462006628513, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 200, train_loss = 16.07888118736446, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 201, train_loss = 16.060397945344448, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 202, train_loss = 16.04772925004363, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 203, train_loss = 16.03549494035542, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 204, train_loss = 16.018645917996764, train_acc = 0.9641360037261295\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 205, train_loss = 16.005902640521526, train_acc = 0.9642524452724732\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 206, train_loss = 15.991421155631542, train_acc = 0.9642524452724732\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 207, train_loss = 15.978617480024695, train_acc = 0.9642524452724732\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 208, train_loss = 15.965872656553984, train_acc = 0.9642524452724732\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 209, train_loss = 15.950064525008202, train_acc = 0.9644853283651607\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 210, train_loss = 15.93994844891131, train_acc = 0.9643688868188169\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 211, train_loss = 15.927475739270449, train_acc = 0.9644853283651607\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 212, train_loss = 15.915356494486332, train_acc = 0.9646017699115044\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 213, train_loss = 15.899919969961047, train_acc = 0.9646017699115044\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 214, train_loss = 15.892029590904713, train_acc = 0.9646017699115044\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 215, train_loss = 15.876475505530834, train_acc = 0.9646017699115044\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 216, train_loss = 15.866155413910747, train_acc = 0.9646017699115044\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 217, train_loss = 15.851786645129323, train_acc = 0.9647182114578482\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 218, train_loss = 15.842966016381979, train_acc = 0.9647182114578482\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 219, train_loss = 15.827946994453669, train_acc = 0.9648346530041919\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 220, train_loss = 15.81407164875418, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 221, train_loss = 15.80519034806639, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 222, train_loss = 15.791341427713633, train_acc = 0.9650675360968793\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 223, train_loss = 15.779008732177317, train_acc = 0.9650675360968793\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 224, train_loss = 15.765301942825317, train_acc = 0.9651839776432231\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 225, train_loss = 15.757916473783553, train_acc = 0.9651839776432231\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 226, train_loss = 15.743496564216912, train_acc = 0.9651839776432231\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 227, train_loss = 15.738752816803753, train_acc = 0.9651839776432231\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 228, train_loss = 15.723294198513031, train_acc = 0.9650675360968793\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 229, train_loss = 15.711579550988972, train_acc = 0.9651839776432231\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 230, train_loss = 15.70110821351409, train_acc = 0.9651839776432231\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 231, train_loss = 15.692287494428456, train_acc = 0.9651839776432231\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 232, train_loss = 15.67999928444624, train_acc = 0.9651839776432231\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 233, train_loss = 15.670563437975943, train_acc = 0.9651839776432231\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 234, train_loss = 15.65666043292731, train_acc = 0.9651839776432231\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 235, train_loss = 15.642534003593028, train_acc = 0.9651839776432231\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 236, train_loss = 15.635463901795447, train_acc = 0.9651839776432231\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 237, train_loss = 15.625597897917032, train_acc = 0.9651839776432231\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 238, train_loss = 15.615063435398042, train_acc = 0.9653004191895669\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 239, train_loss = 15.591976978816092, train_acc = 0.965649743828598\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 240, train_loss = 15.590282128192484, train_acc = 0.9657661853749417\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 241, train_loss = 15.579770509153605, train_acc = 0.9651839776432231\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 242, train_loss = 15.564360569231212, train_acc = 0.9657661853749417\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 243, train_loss = 15.556328107602894, train_acc = 0.965649743828598\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 244, train_loss = 15.546296700835228, train_acc = 0.9657661853749417\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 245, train_loss = 15.540504462085664, train_acc = 0.9655333022822543\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 246, train_loss = 15.531458084471524, train_acc = 0.9657661853749417\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 247, train_loss = 15.517183455638587, train_acc = 0.9655333022822543\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 248, train_loss = 15.505813335068524, train_acc = 0.965649743828598\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 249, train_loss = 15.497781459242105, train_acc = 0.9657661853749417\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 250, train_loss = 15.485320958308876, train_acc = 0.9657661853749417\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 251, train_loss = 15.47466932144016, train_acc = 0.9657661853749417\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 252, train_loss = 15.465756438672543, train_acc = 0.9657661853749417\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 253, train_loss = 15.455928555689752, train_acc = 0.965649743828598\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 254, train_loss = 15.445834734477103, train_acc = 0.9657661853749417\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 255, train_loss = 15.432787113822997, train_acc = 0.9657661853749417\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 256, train_loss = 15.422600575722754, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 257, train_loss = 15.413901310414076, train_acc = 0.9657661853749417\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 258, train_loss = 15.406783808022738, train_acc = 0.9657661853749417\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 259, train_loss = 15.39815651718527, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 260, train_loss = 15.394407494924963, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 261, train_loss = 15.381573356688023, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 262, train_loss = 15.368472389876842, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 263, train_loss = 15.360077277757227, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 264, train_loss = 15.353432881645858, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 265, train_loss = 15.336141963489354, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 266, train_loss = 15.334537919610739, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 267, train_loss = 15.319389674812555, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 268, train_loss = 15.307338052429259, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 269, train_loss = 15.299368467181921, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 270, train_loss = 15.28783958684653, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 271, train_loss = 15.278956863097847, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 272, train_loss = 15.266158916987479, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 273, train_loss = 15.262166619300842, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 274, train_loss = 15.247626695781946, train_acc = 0.9659990684676293\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 275, train_loss = 15.243866949342191, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 276, train_loss = 15.235016085207462, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 277, train_loss = 15.224294126033783, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 278, train_loss = 15.213942741043866, train_acc = 0.9658826269212856\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 279, train_loss = 15.207361898384988, train_acc = 0.9659990684676293\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 280, train_loss = 15.195458783768117, train_acc = 0.9659990684676293\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 281, train_loss = 15.186489242129028, train_acc = 0.9659990684676293\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 282, train_loss = 15.179595804773271, train_acc = 0.966115510013973\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 283, train_loss = 15.171467307023704, train_acc = 0.9659990684676293\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 284, train_loss = 15.16137985792011, train_acc = 0.966115510013973\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 285, train_loss = 15.152480896562338, train_acc = 0.966115510013973\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 286, train_loss = 15.139485344290733, train_acc = 0.9662319515603167\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 287, train_loss = 15.13515930622816, train_acc = 0.9662319515603167\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 288, train_loss = 15.124893167056143, train_acc = 0.966115510013973\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 289, train_loss = 15.120635230094194, train_acc = 0.966115510013973\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 290, train_loss = 15.110586966387928, train_acc = 0.9662319515603167\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 291, train_loss = 15.102237065322697, train_acc = 0.9662319515603167\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 292, train_loss = 15.090210441499949, train_acc = 0.9662319515603167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 293, train_loss = 15.0870312852785, train_acc = 0.9662319515603167\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 294, train_loss = 15.074506032280624, train_acc = 0.9662319515603167\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 295, train_loss = 15.067554224282503, train_acc = 0.9662319515603167\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 296, train_loss = 15.05779939237982, train_acc = 0.9663483931066604\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 297, train_loss = 15.0545722739771, train_acc = 0.9663483931066604\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 298, train_loss = 15.043615826405585, train_acc = 0.9663483931066604\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 299, train_loss = 15.038124143145978, train_acc = 0.9662319515603167\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 300, train_loss = 15.030191303230822, train_acc = 0.9662319515603167\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 301, train_loss = 15.025732238776982, train_acc = 0.9663483931066604\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 302, train_loss = 15.010883994400501, train_acc = 0.9663483931066604\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 303, train_loss = 14.998096226714551, train_acc = 0.9663483931066604\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 304, train_loss = 14.996035374701023, train_acc = 0.9662319515603167\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 305, train_loss = 14.98952371161431, train_acc = 0.9663483931066604\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 306, train_loss = 14.984255260787904, train_acc = 0.9663483931066604\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 307, train_loss = 14.971742923371494, train_acc = 0.9664648346530041\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 308, train_loss = 14.963031768798828, train_acc = 0.9664648346530041\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 309, train_loss = 14.954278782941401, train_acc = 0.966581276199348\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 310, train_loss = 14.95232733618468, train_acc = 0.9666977177456917\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 311, train_loss = 14.940881356596947, train_acc = 0.9666977177456917\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 312, train_loss = 14.935187763534486, train_acc = 0.9666977177456917\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 313, train_loss = 14.931398372165859, train_acc = 0.9666977177456917\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 314, train_loss = 14.918664102442563, train_acc = 0.9668141592920354\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 315, train_loss = 14.914806975983083, train_acc = 0.9668141592920354\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 316, train_loss = 14.905355271883309, train_acc = 0.9668141592920354\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 317, train_loss = 14.900924415327609, train_acc = 0.9666977177456917\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 318, train_loss = 14.888969046063721, train_acc = 0.966581276199348\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 319, train_loss = 14.88407113775611, train_acc = 0.9669306008383791\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 320, train_loss = 14.87798411026597, train_acc = 0.9669306008383791\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 321, train_loss = 14.870262492448092, train_acc = 0.9669306008383791\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 322, train_loss = 14.866517384536564, train_acc = 0.9670470423847228\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 323, train_loss = 14.854606320150197, train_acc = 0.9670470423847228\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 324, train_loss = 14.848837145604193, train_acc = 0.9670470423847228\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 325, train_loss = 14.840349607169628, train_acc = 0.9670470423847228\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 326, train_loss = 14.833154599182308, train_acc = 0.9669306008383791\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 327, train_loss = 14.825262145139277, train_acc = 0.9669306008383791\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 328, train_loss = 14.820300043560565, train_acc = 0.9670470423847228\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 329, train_loss = 14.811813089996576, train_acc = 0.9670470423847228\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 330, train_loss = 14.803372948430479, train_acc = 0.9670470423847228\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 331, train_loss = 14.800167304463685, train_acc = 0.9670470423847228\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 332, train_loss = 14.791051130741835, train_acc = 0.9670470423847228\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 333, train_loss = 14.787150277756155, train_acc = 0.9670470423847228\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 334, train_loss = 14.77640147227794, train_acc = 0.9670470423847228\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 335, train_loss = 14.770190152339637, train_acc = 0.9670470423847228\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 336, train_loss = 14.767458875663579, train_acc = 0.9671634839310667\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 337, train_loss = 14.756101098842919, train_acc = 0.9670470423847228\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 338, train_loss = 14.749315922148526, train_acc = 0.9671634839310667\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 339, train_loss = 14.743237129412591, train_acc = 0.9671634839310667\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 340, train_loss = 14.739050370641053, train_acc = 0.9671634839310667\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 341, train_loss = 14.735505021177232, train_acc = 0.9671634839310667\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 342, train_loss = 14.721321697346866, train_acc = 0.9672799254774104\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 343, train_loss = 14.717963725328445, train_acc = 0.9671634839310667\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 344, train_loss = 14.713547919876873, train_acc = 0.9672799254774104\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 345, train_loss = 14.704098925925791, train_acc = 0.9672799254774104\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 346, train_loss = 14.695477806963027, train_acc = 0.9672799254774104\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 347, train_loss = 14.68812404293567, train_acc = 0.9673963670237541\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 348, train_loss = 14.688800894655287, train_acc = 0.9672799254774104\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 349, train_loss = 14.677034630440176, train_acc = 0.9672799254774104\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 350, train_loss = 14.669723936356604, train_acc = 0.9676292501164415\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 351, train_loss = 14.661930025555193, train_acc = 0.9675128085700978\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 352, train_loss = 14.658288248814642, train_acc = 0.9673963670237541\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 353, train_loss = 14.647847652435303, train_acc = 0.9673963670237541\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 354, train_loss = 14.64556108880788, train_acc = 0.9677456916627852\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 355, train_loss = 14.641959242522717, train_acc = 0.9675128085700978\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 356, train_loss = 14.634248856455088, train_acc = 0.9677456916627852\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 357, train_loss = 14.626763932406902, train_acc = 0.9677456916627852\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 358, train_loss = 14.61977590341121, train_acc = 0.9677456916627852\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 359, train_loss = 14.612623269669712, train_acc = 0.9678621332091291\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 360, train_loss = 14.612218052148819, train_acc = 0.9676292501164415\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 361, train_loss = 14.604074318893254, train_acc = 0.9677456916627852\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 362, train_loss = 14.594200762920082, train_acc = 0.9678621332091291\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 363, train_loss = 14.590739184059203, train_acc = 0.9677456916627852\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 364, train_loss = 14.583549156785011, train_acc = 0.9678621332091291\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 365, train_loss = 14.575579963624477, train_acc = 0.9680950163018165\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 366, train_loss = 14.576436585746706, train_acc = 0.9679785747554728\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 367, train_loss = 14.561494030058384, train_acc = 0.9679785747554728\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 368, train_loss = 14.556300246156752, train_acc = 0.9680950163018165\n",
      "test Acc 0.9450651769087524:\n",
      "27th- epoch: 369, train_loss = 14.554492072202265, train_acc = 0.9679785747554728\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 370, train_loss = 14.547418599016964, train_acc = 0.9682114578481602\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 371, train_loss = 14.537766941823065, train_acc = 0.9682114578481602\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 372, train_loss = 14.529519730247557, train_acc = 0.9682114578481602\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 373, train_loss = 14.529700401239097, train_acc = 0.9682114578481602\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 374, train_loss = 14.52394135762006, train_acc = 0.9680950163018165\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 375, train_loss = 14.518111131154, train_acc = 0.9682114578481602\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 376, train_loss = 14.51615475025028, train_acc = 0.9680950163018165\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 377, train_loss = 14.499988350085914, train_acc = 0.9682114578481602\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 378, train_loss = 14.495682469569147, train_acc = 0.9682114578481602\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 379, train_loss = 14.490877020172775, train_acc = 0.9682114578481602\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 380, train_loss = 14.495350883342326, train_acc = 0.9682114578481602\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 381, train_loss = 14.485981076955795, train_acc = 0.9682114578481602\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 382, train_loss = 14.4724563350901, train_acc = 0.9683278993945039\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 383, train_loss = 14.472364076413214, train_acc = 0.9682114578481602\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 384, train_loss = 14.465450665913522, train_acc = 0.9682114578481602\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 385, train_loss = 14.461357007734478, train_acc = 0.9682114578481602\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 386, train_loss = 14.456350957043469, train_acc = 0.9682114578481602\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 387, train_loss = 14.4493526564911, train_acc = 0.9682114578481602\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 388, train_loss = 14.446899902075529, train_acc = 0.9682114578481602\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 389, train_loss = 14.433740266598761, train_acc = 0.9682114578481602\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 390, train_loss = 14.433750891126692, train_acc = 0.9683278993945039\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 391, train_loss = 14.427067226730287, train_acc = 0.9683278993945039\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 392, train_loss = 14.41870608087629, train_acc = 0.9683278993945039\n",
      "test Acc 0.9459962756052142:\n",
      "27th- epoch: 393, train_loss = 14.410951093770564, train_acc = 0.9683278993945039\n",
      "test Acc 0.9455307262569832:\n",
      "27th- epoch: 394, train_loss = 14.411454495042562, train_acc = 0.9683278993945039\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 395, train_loss = 14.40776852145791, train_acc = 0.9682114578481602\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 396, train_loss = 14.395244598388672, train_acc = 0.9683278993945039\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 397, train_loss = 14.396920309402049, train_acc = 0.9683278993945039\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 398, train_loss = 14.38954244274646, train_acc = 0.9683278993945039\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 399, train_loss = 14.387454490177333, train_acc = 0.9685607824871915\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 400, train_loss = 14.37540649343282, train_acc = 0.9683278993945039\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 401, train_loss = 14.374087642878294, train_acc = 0.9685607824871915\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 402, train_loss = 14.369111177511513, train_acc = 0.9683278993945039\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 403, train_loss = 14.36472115200013, train_acc = 0.9683278993945039\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 404, train_loss = 14.355130827985704, train_acc = 0.9683278993945039\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 405, train_loss = 14.355361166410148, train_acc = 0.9685607824871915\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 406, train_loss = 14.342745794914663, train_acc = 0.9685607824871915\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 407, train_loss = 14.336726850830019, train_acc = 0.9685607824871915\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 408, train_loss = 14.335620880126953, train_acc = 0.9685607824871915\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 409, train_loss = 14.33658368140459, train_acc = 0.9685607824871915\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 410, train_loss = 14.330631520599127, train_acc = 0.9685607824871915\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 411, train_loss = 14.318157818168402, train_acc = 0.9685607824871915\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 412, train_loss = 14.31676633656025, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 413, train_loss = 14.314125881530344, train_acc = 0.9685607824871915\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 414, train_loss = 14.310494117438793, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 415, train_loss = 14.306717584840953, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 416, train_loss = 14.294407059438527, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 417, train_loss = 14.290552254766226, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 418, train_loss = 14.2875523455441, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 419, train_loss = 14.283918432891369, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 420, train_loss = 14.277111732400954, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 421, train_loss = 14.26617355644703, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 422, train_loss = 14.264333885163069, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 423, train_loss = 14.263048313558102, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 424, train_loss = 14.257133296690881, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 425, train_loss = 14.247599800117314, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 426, train_loss = 14.248975303024054, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 427, train_loss = 14.244293830357492, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 428, train_loss = 14.234804935753345, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 429, train_loss = 14.234317109920084, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 430, train_loss = 14.222769990563393, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 431, train_loss = 14.217240411788225, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 432, train_loss = 14.215108477510512, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 433, train_loss = 14.206376437097788, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 434, train_loss = 14.211157468147576, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 435, train_loss = 14.201602284796536, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 436, train_loss = 14.195904675871134, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 437, train_loss = 14.18929650541395, train_acc = 0.9687936655798789\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 438, train_loss = 14.184338049031794, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 439, train_loss = 14.18913998361677, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 440, train_loss = 14.176395886577666, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 441, train_loss = 14.172168161720037, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 442, train_loss = 14.167292202822864, train_acc = 0.9689101071262226\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 443, train_loss = 14.168141234666109, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 444, train_loss = 14.15663702134043, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 445, train_loss = 14.150806464254856, train_acc = 0.9687936655798789\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 446, train_loss = 14.15534661244601, train_acc = 0.9686772240335352\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 447, train_loss = 14.147148515097797, train_acc = 0.9689101071262226\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 448, train_loss = 14.138056814670563, train_acc = 0.9687936655798789\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 449, train_loss = 14.136040355078876, train_acc = 0.9687936655798789\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 450, train_loss = 14.129253131337464, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 451, train_loss = 14.127244457602501, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 452, train_loss = 14.127588295377791, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 453, train_loss = 14.116035738028586, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 454, train_loss = 14.117856901139021, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 455, train_loss = 14.10929849371314, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 456, train_loss = 14.10344725009054, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 457, train_loss = 14.102648411877453, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 458, train_loss = 14.095740315504372, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 459, train_loss = 14.095545899122953, train_acc = 0.9689101071262226\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 460, train_loss = 14.08326496835798, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 461, train_loss = 14.084666489623487, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 462, train_loss = 14.083381429314613, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 463, train_loss = 14.073490069247782, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 464, train_loss = 14.06535507272929, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 465, train_loss = 14.063318989239633, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 466, train_loss = 14.05836705584079, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 467, train_loss = 14.057029812596738, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 468, train_loss = 14.052823513746262, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 469, train_loss = 14.04887839127332, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 470, train_loss = 14.042972072027624, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 471, train_loss = 14.036154116503894, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 472, train_loss = 14.035222667269409, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 473, train_loss = 14.037586870603263, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 474, train_loss = 14.027122560888529, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 475, train_loss = 14.02071729209274, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 476, train_loss = 14.016703151166439, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 477, train_loss = 14.019486694596708, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 478, train_loss = 14.011684791184962, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 479, train_loss = 14.006042727269232, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 480, train_loss = 14.002676188014448, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 481, train_loss = 13.999281612224877, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 482, train_loss = 13.993485562503338, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 483, train_loss = 13.992160264402628, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 484, train_loss = 13.986635248176754, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 485, train_loss = 13.982174286153167, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 486, train_loss = 13.97984826285392, train_acc = 0.9690265486725663\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 487, train_loss = 13.972152757458389, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 488, train_loss = 13.97175091970712, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 489, train_loss = 13.966585424728692, train_acc = 0.9691429902189101\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 490, train_loss = 13.96075881505385, train_acc = 0.9692594317652539\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 491, train_loss = 13.960868024267256, train_acc = 0.9692594317652539\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 492, train_loss = 13.952067564241588, train_acc = 0.9693758733115976\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 493, train_loss = 13.952262870967388, train_acc = 0.9692594317652539\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 494, train_loss = 13.944147596601397, train_acc = 0.9694923148579413\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 495, train_loss = 13.944179942365736, train_acc = 0.9693758733115976\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 496, train_loss = 13.93760808929801, train_acc = 0.9693758733115976\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 497, train_loss = 13.936759238597006, train_acc = 0.9693758733115976\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 498, train_loss = 13.933534977491945, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "27th- epoch: 499, train_loss = 13.926976711954921, train_acc = 0.9694923148579413\n",
      "test Acc 0.946927374301676:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████▊       | 27/30 [4:04:26<27:10, 543.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "28th- epoch: 0, train_loss = 124.78025555610657, train_acc = 0.7459245458779693\n",
      "test Acc 0.7579143389199255:\n",
      "28th- epoch: 1, train_loss = 60.91704769432545, train_acc = 0.8687703772706101\n",
      "test Acc 0.8226256983240223:\n",
      "28th- epoch: 2, train_loss = 50.662580251693726, train_acc = 0.8914764788076386\n",
      "test Acc 0.8524208566108007:\n",
      "28th- epoch: 3, train_loss = 45.74715481698513, train_acc = 0.9025384257102934\n",
      "test Acc 0.86731843575419:\n",
      "28th- epoch: 4, train_loss = 42.39347532391548, train_acc = 0.9085933861201677\n",
      "test Acc 0.8766294227188082:\n",
      "28th- epoch: 5, train_loss = 39.87271158397198, train_acc = 0.9151141127154169\n",
      "test Acc 0.8901303538175046:\n",
      "28th- epoch: 6, train_loss = 37.886837132275105, train_acc = 0.9197717745691663\n",
      "test Acc 0.9022346368715084:\n",
      "28th- epoch: 7, train_loss = 36.222929291427135, train_acc = 0.9232650209594784\n",
      "test Acc 0.9082867783985102:\n",
      "28th- epoch: 8, train_loss = 34.87239596247673, train_acc = 0.9259431765253843\n",
      "test Acc 0.9162011173184358:\n",
      "28th- epoch: 9, train_loss = 33.70762783288956, train_acc = 0.928272007452259\n",
      "test Acc 0.9194599627560521:\n",
      "28th- epoch: 10, train_loss = 32.733515322208405, train_acc = 0.9303679552864462\n",
      "test Acc 0.9203910614525139:\n",
      "28th- epoch: 11, train_loss = 31.812377229332924, train_acc = 0.932231020027946\n",
      "test Acc 0.9236499068901304:\n",
      "28th- epoch: 12, train_loss = 31.025471560657024, train_acc = 0.9337447601304145\n",
      "test Acc 0.9245810055865922:\n",
      "28th- epoch: 13, train_loss = 30.351035438477993, train_acc = 0.9343269678621332\n",
      "test Acc 0.925512104283054:\n",
      "28th- epoch: 14, train_loss = 29.702663354575634, train_acc = 0.9360735910572893\n",
      "test Acc 0.9273743016759777:\n",
      "28th- epoch: 15, train_loss = 29.137325510382652, train_acc = 0.9360735910572893\n",
      "test Acc 0.9278398510242085:\n",
      "28th- epoch: 16, train_loss = 28.625955678522587, train_acc = 0.9367722403353517\n",
      "test Acc 0.9278398510242085:\n",
      "28th- epoch: 17, train_loss = 28.122429363429546, train_acc = 0.9377037727061015\n",
      "test Acc 0.9269087523277467:\n",
      "28th- epoch: 18, train_loss = 27.676662653684616, train_acc = 0.9386353050768514\n",
      "test Acc 0.9269087523277467:\n",
      "28th- epoch: 19, train_loss = 27.26967480778694, train_acc = 0.939683278993945\n",
      "test Acc 0.9273743016759777:\n",
      "28th- epoch: 20, train_loss = 26.895373687148094, train_acc = 0.9413134606427573\n",
      "test Acc 0.9278398510242085:\n",
      "28th- epoch: 21, train_loss = 26.536816887557507, train_acc = 0.941429902189101\n",
      "test Acc 0.9283054003724395:\n",
      "28th- epoch: 22, train_loss = 26.21263511106372, train_acc = 0.9428272007452259\n",
      "test Acc 0.9278398510242085:\n",
      "28th- epoch: 23, train_loss = 25.88006890192628, train_acc = 0.9430600838379134\n",
      "test Acc 0.9283054003724395:\n",
      "28th- epoch: 24, train_loss = 25.59111511707306, train_acc = 0.9434094084769445\n",
      "test Acc 0.9292364990689013:\n",
      "28th- epoch: 25, train_loss = 25.31833950802684, train_acc = 0.944108057755007\n",
      "test Acc 0.9297020484171322:\n",
      "28th- epoch: 26, train_loss = 25.032176453620195, train_acc = 0.9450395901257569\n",
      "test Acc 0.9301675977653632:\n",
      "28th- epoch: 27, train_loss = 24.788595508784056, train_acc = 0.9455053563111319\n",
      "test Acc 0.930633147113594:\n",
      "28th- epoch: 28, train_loss = 24.54044357687235, train_acc = 0.9456217978574756\n",
      "test Acc 0.9324953445065177:\n",
      "28th- epoch: 29, train_loss = 24.303080402314663, train_acc = 0.9466697717745691\n",
      "test Acc 0.9324953445065177:\n",
      "28th- epoch: 30, train_loss = 24.115363832563162, train_acc = 0.9472519795062878\n",
      "test Acc 0.9324953445065177:\n",
      "28th- epoch: 31, train_loss = 23.884848799556494, train_acc = 0.9478341872380065\n",
      "test Acc 0.9329608938547486:\n",
      "28th- epoch: 32, train_loss = 23.70000644773245, train_acc = 0.9481835118770378\n",
      "test Acc 0.9334264432029795:\n",
      "28th- epoch: 33, train_loss = 23.508202381432056, train_acc = 0.9487657196087564\n",
      "test Acc 0.9334264432029795:\n",
      "28th- epoch: 34, train_loss = 23.330640602856874, train_acc = 0.9494643688868188\n",
      "test Acc 0.9334264432029795:\n",
      "28th- epoch: 35, train_loss = 23.14705080166459, train_acc = 0.94981369352585\n",
      "test Acc 0.9343575418994413:\n",
      "28th- epoch: 36, train_loss = 22.957449037581682, train_acc = 0.9500465766185375\n",
      "test Acc 0.9348230912476723:\n",
      "28th- epoch: 37, train_loss = 22.795889034867287, train_acc = 0.9506287843502562\n",
      "test Acc 0.9348230912476723:\n",
      "28th- epoch: 38, train_loss = 22.649369481951, train_acc = 0.9507452258965999\n",
      "test Acc 0.9357541899441341:\n",
      "28th- epoch: 39, train_loss = 22.49807821214199, train_acc = 0.9508616674429436\n",
      "test Acc 0.9357541899441341:\n",
      "28th- epoch: 40, train_loss = 22.36198779195547, train_acc = 0.9513274336283186\n",
      "test Acc 0.936219739292365:\n",
      "28th- epoch: 41, train_loss = 22.24706956371665, train_acc = 0.9517931998136935\n",
      "test Acc 0.9357541899441341:\n",
      "28th- epoch: 42, train_loss = 22.0756898522377, train_acc = 0.9519096413600373\n",
      "test Acc 0.936219739292365:\n",
      "28th- epoch: 43, train_loss = 21.943523466587067, train_acc = 0.9521425244527247\n",
      "test Acc 0.936219739292365:\n",
      "28th- epoch: 44, train_loss = 21.82479940354824, train_acc = 0.9523754075454122\n",
      "test Acc 0.9366852886405959:\n",
      "28th- epoch: 45, train_loss = 21.714100390672684, train_acc = 0.9523754075454122\n",
      "test Acc 0.936219739292365:\n",
      "28th- epoch: 46, train_loss = 21.587285172194242, train_acc = 0.9528411737307871\n",
      "test Acc 0.9366852886405959:\n",
      "28th- epoch: 47, train_loss = 21.4679438136518, train_acc = 0.9533069399161621\n",
      "test Acc 0.9366852886405959:\n",
      "28th- epoch: 48, train_loss = 21.372466448694468, train_acc = 0.9536562645551933\n",
      "test Acc 0.9366852886405959:\n",
      "28th- epoch: 49, train_loss = 21.27241751179099, train_acc = 0.9537727061015371\n",
      "test Acc 0.9366852886405959:\n",
      "28th- epoch: 50, train_loss = 21.16628087311983, train_acc = 0.9536562645551933\n",
      "test Acc 0.9366852886405959:\n",
      "28th- epoch: 51, train_loss = 21.056776583194733, train_acc = 0.9538891476478808\n",
      "test Acc 0.9366852886405959:\n",
      "28th- epoch: 52, train_loss = 20.97524745389819, train_acc = 0.9541220307405682\n",
      "test Acc 0.9366852886405959:\n",
      "28th- epoch: 53, train_loss = 20.853105396032333, train_acc = 0.9543549138332557\n",
      "test Acc 0.9366852886405959:\n",
      "28th- epoch: 54, train_loss = 20.775490626692772, train_acc = 0.9544713553795995\n",
      "test Acc 0.9371508379888268:\n",
      "28th- epoch: 55, train_loss = 20.686987031251192, train_acc = 0.9544713553795995\n",
      "test Acc 0.9380819366852886:\n",
      "28th- epoch: 56, train_loss = 20.57848361134529, train_acc = 0.9544713553795995\n",
      "test Acc 0.9385474860335196:\n",
      "28th- epoch: 57, train_loss = 20.499542593955994, train_acc = 0.9545877969259432\n",
      "test Acc 0.9380819366852886:\n",
      "28th- epoch: 58, train_loss = 20.42411169037223, train_acc = 0.9550535631113182\n",
      "test Acc 0.9385474860335196:\n",
      "28th- epoch: 59, train_loss = 20.336839985102415, train_acc = 0.9550535631113182\n",
      "test Acc 0.9385474860335196:\n",
      "28th- epoch: 60, train_loss = 20.26151581481099, train_acc = 0.9552864462040056\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 61, train_loss = 20.189106795936823, train_acc = 0.955519329296693\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 62, train_loss = 20.118608325719833, train_acc = 0.955519329296693\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 63, train_loss = 20.025508780032396, train_acc = 0.9556357708430367\n",
      "test Acc 0.9385474860335196:\n",
      "28th- epoch: 64, train_loss = 19.9498258382082, train_acc = 0.9558686539357243\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 65, train_loss = 19.89300112426281, train_acc = 0.9562179785747554\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 66, train_loss = 19.807810734957457, train_acc = 0.9561015370284117\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 67, train_loss = 19.75079720467329, train_acc = 0.9562179785747554\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 68, train_loss = 19.68309983611107, train_acc = 0.9566837447601304\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 69, train_loss = 19.609547067433596, train_acc = 0.9569166278528178\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 70, train_loss = 19.548328954726458, train_acc = 0.9570330693991617\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 71, train_loss = 19.481782875955105, train_acc = 0.9570330693991617\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 72, train_loss = 19.420510549098253, train_acc = 0.9571495109455054\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 73, train_loss = 19.374883860349655, train_acc = 0.9573823940381928\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 74, train_loss = 19.30726645514369, train_acc = 0.9572659524918491\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 75, train_loss = 19.244959603995085, train_acc = 0.9572659524918491\n",
      "test Acc 0.9390130353817505:\n",
      "28th- epoch: 76, train_loss = 19.201248064637184, train_acc = 0.9577317186772241\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 77, train_loss = 19.146487791091204, train_acc = 0.9578481602235678\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 78, train_loss = 19.100752592086792, train_acc = 0.9580810433162552\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 79, train_loss = 19.040587209165096, train_acc = 0.9583139264089428\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 80, train_loss = 18.987062372267246, train_acc = 0.9581974848625989\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 81, train_loss = 18.92958154901862, train_acc = 0.9583139264089428\n",
      "test Acc 0.9399441340782123:\n",
      "28th- epoch: 82, train_loss = 18.891296412795782, train_acc = 0.9581974848625989\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 83, train_loss = 18.83819179981947, train_acc = 0.9584303679552865\n",
      "test Acc 0.9399441340782123:\n",
      "28th- epoch: 84, train_loss = 18.79669577255845, train_acc = 0.9581974848625989\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 85, train_loss = 18.740904793143272, train_acc = 0.9584303679552865\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 86, train_loss = 18.69901804625988, train_acc = 0.9585468095016302\n",
      "test Acc 0.9394785847299814:\n",
      "28th- epoch: 87, train_loss = 18.642275350168347, train_acc = 0.9585468095016302\n",
      "test Acc 0.9399441340782123:\n",
      "28th- epoch: 88, train_loss = 18.593324901536107, train_acc = 0.9586632510479739\n",
      "test Acc 0.9399441340782123:\n",
      "28th- epoch: 89, train_loss = 18.5610413774848, train_acc = 0.9586632510479739\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 90, train_loss = 18.50782404281199, train_acc = 0.9585468095016302\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 91, train_loss = 18.462970335036516, train_acc = 0.9592454587796926\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 92, train_loss = 18.43387732282281, train_acc = 0.9592454587796926\n",
      "test Acc 0.9413407821229051:\n",
      "28th- epoch: 93, train_loss = 18.383625263348222, train_acc = 0.9593619003260363\n",
      "test Acc 0.9418063314711359:\n",
      "28th- epoch: 94, train_loss = 18.35395330004394, train_acc = 0.9592454587796926\n",
      "test Acc 0.9418063314711359:\n",
      "28th- epoch: 95, train_loss = 18.307292403653264, train_acc = 0.9592454587796926\n",
      "test Acc 0.9418063314711359:\n",
      "28th- epoch: 96, train_loss = 18.25866481103003, train_acc = 0.9597112249650676\n",
      "test Acc 0.9418063314711359:\n",
      "28th- epoch: 97, train_loss = 18.22811192460358, train_acc = 0.9595947834187238\n",
      "test Acc 0.9418063314711359:\n",
      "28th- epoch: 98, train_loss = 18.19638871960342, train_acc = 0.95947834187238\n",
      "test Acc 0.9418063314711359:\n",
      "28th- epoch: 99, train_loss = 18.15453820489347, train_acc = 0.9598276665114113\n",
      "test Acc 0.9418063314711359:\n",
      "28th- epoch: 100, train_loss = 18.119217758998275, train_acc = 0.959944108057755\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 101, train_loss = 18.06495274603367, train_acc = 0.9598276665114113\n",
      "test Acc 0.9418063314711359:\n",
      "28th- epoch: 102, train_loss = 18.0430348534137, train_acc = 0.9600605496040987\n",
      "test Acc 0.9418063314711359:\n",
      "28th- epoch: 103, train_loss = 17.9938613306731, train_acc = 0.9602934326967862\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 104, train_loss = 17.95843637548387, train_acc = 0.9600605496040987\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 105, train_loss = 17.940777806565166, train_acc = 0.96040987424313\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 106, train_loss = 17.902472043409944, train_acc = 0.96040987424313\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 107, train_loss = 17.879571862518787, train_acc = 0.9602934326967862\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 108, train_loss = 17.83394836820662, train_acc = 0.9601769911504425\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 109, train_loss = 17.790865175426006, train_acc = 0.9605263157894737\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 110, train_loss = 17.781470032408834, train_acc = 0.9606427573358174\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 111, train_loss = 17.74245304428041, train_acc = 0.9607591988821611\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 112, train_loss = 17.696861296892166, train_acc = 0.9607591988821611\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 113, train_loss = 17.6686671692878, train_acc = 0.9607591988821611\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 114, train_loss = 17.638024711981416, train_acc = 0.9607591988821611\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 115, train_loss = 17.606982378289104, train_acc = 0.9607591988821611\n",
      "test Acc 0.9422718808193669:\n",
      "28th- epoch: 116, train_loss = 17.57014816440642, train_acc = 0.9606427573358174\n",
      "test Acc 0.9432029795158287:\n",
      "28th- epoch: 117, train_loss = 17.550994073972106, train_acc = 0.9606427573358174\n",
      "test Acc 0.9432029795158287:\n",
      "28th- epoch: 118, train_loss = 17.52413791976869, train_acc = 0.9609920819748486\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 119, train_loss = 17.49585997313261, train_acc = 0.9608756404285049\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 120, train_loss = 17.470784805715084, train_acc = 0.9609920819748486\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 121, train_loss = 17.45870520733297, train_acc = 0.9609920819748486\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 122, train_loss = 17.400476520881057, train_acc = 0.9611085235211924\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 123, train_loss = 17.373886413872242, train_acc = 0.9612249650675361\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 124, train_loss = 17.360780326649547, train_acc = 0.9614578481602236\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 125, train_loss = 17.327995302155614, train_acc = 0.9613414066138798\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 126, train_loss = 17.296492779627442, train_acc = 0.9613414066138798\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 127, train_loss = 17.27145916968584, train_acc = 0.9612249650675361\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 128, train_loss = 17.246804621070623, train_acc = 0.9614578481602236\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 129, train_loss = 17.225556038320065, train_acc = 0.9615742897065673\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 130, train_loss = 17.195098396390676, train_acc = 0.961690731252911\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 131, train_loss = 17.17270927503705, train_acc = 0.9620400558919422\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 132, train_loss = 17.14697190374136, train_acc = 0.9618071727992548\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 133, train_loss = 17.12754938751459, train_acc = 0.9619236143455985\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 134, train_loss = 17.099474992603064, train_acc = 0.962156497438286\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 135, train_loss = 17.071795793250203, train_acc = 0.9620400558919422\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 136, train_loss = 17.05382706038654, train_acc = 0.9623893805309734\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 137, train_loss = 17.021800873801112, train_acc = 0.9626222636236609\n",
      "test Acc 0.9445996275605214:\n",
      "28th- epoch: 138, train_loss = 17.01197368837893, train_acc = 0.9625058220773172\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 139, train_loss = 16.970008932054043, train_acc = 0.9623893805309734\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 140, train_loss = 16.937250638380647, train_acc = 0.9626222636236609\n",
      "test Acc 0.9445996275605214:\n",
      "28th- epoch: 141, train_loss = 16.92230357788503, train_acc = 0.9628551467163484\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 142, train_loss = 16.894441636279225, train_acc = 0.9628551467163484\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 143, train_loss = 16.888593031093478, train_acc = 0.9628551467163484\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 144, train_loss = 16.862754395231605, train_acc = 0.9629715882626921\n",
      "test Acc 0.9441340782122905:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 145, train_loss = 16.838190527632833, train_acc = 0.9633209129017233\n",
      "test Acc 0.9445996275605214:\n",
      "28th- epoch: 146, train_loss = 16.808526983484626, train_acc = 0.9633209129017233\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 147, train_loss = 16.78184320218861, train_acc = 0.9629715882626921\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 148, train_loss = 16.763340020552278, train_acc = 0.9634373544480671\n",
      "test Acc 0.9436685288640596:\n",
      "28th- epoch: 149, train_loss = 16.751368021592498, train_acc = 0.9633209129017233\n",
      "test Acc 0.9445996275605214:\n",
      "28th- epoch: 150, train_loss = 16.7221265938133, train_acc = 0.9633209129017233\n",
      "test Acc 0.9445996275605214:\n",
      "28th- epoch: 151, train_loss = 16.695878328755498, train_acc = 0.9633209129017233\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 152, train_loss = 16.663654200732708, train_acc = 0.9633209129017233\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 153, train_loss = 16.672554487362504, train_acc = 0.9635537959944108\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 154, train_loss = 16.64398148469627, train_acc = 0.9635537959944108\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 155, train_loss = 16.62117383815348, train_acc = 0.9636702375407545\n",
      "test Acc 0.9445996275605214:\n",
      "28th- epoch: 156, train_loss = 16.606648663058877, train_acc = 0.9636702375407545\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 157, train_loss = 16.59322463721037, train_acc = 0.9642524452724732\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 158, train_loss = 16.552093183621764, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 159, train_loss = 16.539547393098474, train_acc = 0.9641360037261295\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 160, train_loss = 16.526294333860278, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 161, train_loss = 16.509424397721887, train_acc = 0.9640195621797858\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 162, train_loss = 16.49762385711074, train_acc = 0.963903120633442\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 163, train_loss = 16.476386891677976, train_acc = 0.9642524452724732\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 164, train_loss = 16.457117034122348, train_acc = 0.9641360037261295\n",
      "test Acc 0.9455307262569832:\n",
      "28th- epoch: 165, train_loss = 16.43833858333528, train_acc = 0.9643688868188169\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 166, train_loss = 16.406617200002074, train_acc = 0.9641360037261295\n",
      "test Acc 0.9455307262569832:\n",
      "28th- epoch: 167, train_loss = 16.394339261576533, train_acc = 0.9642524452724732\n",
      "test Acc 0.9450651769087524:\n",
      "28th- epoch: 168, train_loss = 16.38523043692112, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 169, train_loss = 16.37284496612847, train_acc = 0.9641360037261295\n",
      "test Acc 0.9459962756052142:\n",
      "28th- epoch: 170, train_loss = 16.33858229778707, train_acc = 0.9641360037261295\n",
      "test Acc 0.9459962756052142:\n",
      "28th- epoch: 171, train_loss = 16.324185393750668, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 172, train_loss = 16.30316793732345, train_acc = 0.9642524452724732\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 173, train_loss = 16.29830503091216, train_acc = 0.9646017699115044\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 174, train_loss = 16.276456708088517, train_acc = 0.9647182114578482\n",
      "test Acc 0.9459962756052142:\n",
      "28th- epoch: 175, train_loss = 16.254789516329765, train_acc = 0.9643688868188169\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 176, train_loss = 16.239639470353723, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "28th- epoch: 177, train_loss = 16.229142505675554, train_acc = 0.9644853283651607\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 178, train_loss = 16.222009362652898, train_acc = 0.9646017699115044\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 179, train_loss = 16.189370330423117, train_acc = 0.9643688868188169\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 180, train_loss = 16.17751829698682, train_acc = 0.9648346530041919\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 181, train_loss = 16.16811910457909, train_acc = 0.9649510945505356\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 182, train_loss = 16.140634829178452, train_acc = 0.9653004191895669\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 183, train_loss = 16.12612601555884, train_acc = 0.9653004191895669\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 184, train_loss = 16.11487850174308, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 185, train_loss = 16.09808894060552, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 186, train_loss = 16.07551489956677, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 187, train_loss = 16.077851805835962, train_acc = 0.9654168607359106\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 188, train_loss = 16.053878350183368, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "28th- epoch: 189, train_loss = 16.03431079350412, train_acc = 0.9650675360968793\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 190, train_loss = 16.022996405139565, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 191, train_loss = 15.998314728960395, train_acc = 0.9653004191895669\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 192, train_loss = 15.984964912757277, train_acc = 0.9654168607359106\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 193, train_loss = 15.973927034065127, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 194, train_loss = 15.968594655394554, train_acc = 0.9651839776432231\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 195, train_loss = 15.952425494790077, train_acc = 0.9654168607359106\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 196, train_loss = 15.94318076968193, train_acc = 0.9651839776432231\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 197, train_loss = 15.9187375549227, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 198, train_loss = 15.90475576557219, train_acc = 0.965649743828598\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 199, train_loss = 15.890230664983392, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 200, train_loss = 15.875626409426332, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 201, train_loss = 15.868942068889737, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 202, train_loss = 15.84666227735579, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 203, train_loss = 15.832178825512528, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 204, train_loss = 15.808134457096457, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 205, train_loss = 15.810158899053931, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 206, train_loss = 15.784704651683569, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 207, train_loss = 15.785550037398934, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 208, train_loss = 15.776179464533925, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 209, train_loss = 15.761061577126384, train_acc = 0.9654168607359106\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 210, train_loss = 15.739573834463954, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 211, train_loss = 15.725389309227467, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 212, train_loss = 15.709494037553668, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 213, train_loss = 15.707128943875432, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 214, train_loss = 15.690154002979398, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 215, train_loss = 15.66676047258079, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 216, train_loss = 15.658085633069277, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 217, train_loss = 15.642098659649491, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 218, train_loss = 15.637395054101944, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 219, train_loss = 15.622176809236407, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 220, train_loss = 15.605112049728632, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 221, train_loss = 15.603059750050306, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 222, train_loss = 15.584483852609992, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 223, train_loss = 15.574405858293176, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 224, train_loss = 15.560486258938909, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 225, train_loss = 15.54352311231196, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 226, train_loss = 15.53722090087831, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 227, train_loss = 15.535625357180834, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 228, train_loss = 15.512164707295597, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 229, train_loss = 15.507204849272966, train_acc = 0.9668141592920354\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 230, train_loss = 15.499168784357607, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 231, train_loss = 15.474820821546018, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 232, train_loss = 15.466824390925467, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 233, train_loss = 15.458031120710075, train_acc = 0.9668141592920354\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 234, train_loss = 15.44268246460706, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 235, train_loss = 15.43132875021547, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 236, train_loss = 15.425970415584743, train_acc = 0.9668141592920354\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 237, train_loss = 15.413984715007246, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 238, train_loss = 15.398657185025513, train_acc = 0.9668141592920354\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 239, train_loss = 15.394430651329458, train_acc = 0.9668141592920354\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 240, train_loss = 15.385682889260352, train_acc = 0.9668141592920354\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 241, train_loss = 15.37659636233002, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 242, train_loss = 15.363056321628392, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 243, train_loss = 15.345900549553335, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 244, train_loss = 15.336775224655867, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 245, train_loss = 15.333081182092428, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 246, train_loss = 15.315474928356707, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 247, train_loss = 15.300618310458958, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 248, train_loss = 15.294425471685827, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 249, train_loss = 15.287512221373618, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 250, train_loss = 15.278802583925426, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 251, train_loss = 15.261765212751925, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 252, train_loss = 15.256690715439618, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 253, train_loss = 15.244190335273743, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 254, train_loss = 15.233254290185869, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 255, train_loss = 15.228816793300211, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 256, train_loss = 15.206596747040749, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 257, train_loss = 15.200819227844477, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 258, train_loss = 15.19892321061343, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 259, train_loss = 15.18318822979927, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 260, train_loss = 15.18411976005882, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 261, train_loss = 15.1610815403983, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 262, train_loss = 15.158327676355839, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 263, train_loss = 15.144862413406372, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 264, train_loss = 15.140485815703869, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 265, train_loss = 15.123999088071287, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 266, train_loss = 15.115388739854097, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 267, train_loss = 15.108565150760114, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 268, train_loss = 15.104867982678115, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 269, train_loss = 15.086481232196093, train_acc = 0.9671634839310667\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 270, train_loss = 15.074352502822876, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 271, train_loss = 15.075167966075242, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 272, train_loss = 15.061075772158802, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 273, train_loss = 15.049547751434147, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 274, train_loss = 15.039002454839647, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 275, train_loss = 15.03765953052789, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 276, train_loss = 15.020342322997749, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 277, train_loss = 15.013469774276018, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 278, train_loss = 15.001119534485042, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 279, train_loss = 14.99949820432812, train_acc = 0.9673963670237541\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 280, train_loss = 14.992504116147757, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 281, train_loss = 14.97115911450237, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 282, train_loss = 14.97181526850909, train_acc = 0.9675128085700978\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 283, train_loss = 14.960078594274819, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 284, train_loss = 14.951349675655365, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 285, train_loss = 14.943032945506275, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 286, train_loss = 14.933770584873855, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 287, train_loss = 14.928705695085227, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 288, train_loss = 14.922884351573884, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 289, train_loss = 14.909370780922472, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 290, train_loss = 14.901147930882871, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 291, train_loss = 14.900086804293096, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 292, train_loss = 14.884714622050524, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 293, train_loss = 14.883060042746365, train_acc = 0.9676292501164415\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 294, train_loss = 14.86683342140168, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 295, train_loss = 14.859060823917389, train_acc = 0.9678621332091291\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 296, train_loss = 14.85334490146488, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "28th- epoch: 297, train_loss = 14.846858111210167, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 298, train_loss = 14.833897016942501, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 299, train_loss = 14.827268860302866, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 300, train_loss = 14.828383141197264, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 301, train_loss = 14.820336206816137, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 302, train_loss = 14.79934813734144, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 303, train_loss = 14.798164404928684, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 304, train_loss = 14.788668577559292, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 305, train_loss = 14.78463917132467, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 306, train_loss = 14.769131255336106, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 307, train_loss = 14.773018398322165, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 308, train_loss = 14.75981130450964, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 309, train_loss = 14.747713794000447, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 310, train_loss = 14.737093021161854, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 311, train_loss = 14.726853889413178, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 312, train_loss = 14.724107942543924, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 313, train_loss = 14.712624781765044, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 314, train_loss = 14.712834640406072, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 315, train_loss = 14.70739262085408, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 316, train_loss = 14.692713215947151, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 317, train_loss = 14.681624558754265, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 318, train_loss = 14.678624375723302, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 319, train_loss = 14.663776885718107, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 320, train_loss = 14.661004505120218, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 321, train_loss = 14.65305572282523, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 322, train_loss = 14.653136640787125, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 323, train_loss = 14.643204975873232, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 324, train_loss = 14.636001744307578, train_acc = 0.9679785747554728\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 325, train_loss = 14.629526627250016, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 326, train_loss = 14.618974093347788, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 327, train_loss = 14.615581348538399, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 328, train_loss = 14.6060282997787, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 329, train_loss = 14.595652255229652, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 330, train_loss = 14.600236609578133, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 331, train_loss = 14.577305735088885, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 332, train_loss = 14.579653692431748, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 333, train_loss = 14.571056480519474, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 334, train_loss = 14.565652533434331, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 335, train_loss = 14.549866374582052, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 336, train_loss = 14.549805864691734, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 337, train_loss = 14.53745202254504, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 338, train_loss = 14.532119981013238, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 339, train_loss = 14.528666775673628, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 340, train_loss = 14.518779086880386, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 341, train_loss = 14.512023254297674, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 342, train_loss = 14.508633095771074, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 343, train_loss = 14.493161800317466, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 344, train_loss = 14.488746768794954, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 345, train_loss = 14.48269285261631, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 346, train_loss = 14.472734884358943, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 347, train_loss = 14.470474398694932, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 348, train_loss = 14.471917420625687, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 349, train_loss = 14.455222654156387, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 350, train_loss = 14.451426848769188, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 351, train_loss = 14.440612304024398, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 352, train_loss = 14.434954187832773, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 353, train_loss = 14.437985848635435, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 354, train_loss = 14.431757665239275, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 355, train_loss = 14.419193814508617, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 356, train_loss = 14.419088055379689, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 357, train_loss = 14.403629233129323, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 358, train_loss = 14.408385223709047, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 359, train_loss = 14.401819620281458, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "28th- epoch: 360, train_loss = 14.39636267349124, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 361, train_loss = 14.377393949776888, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 362, train_loss = 14.372935748659074, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 363, train_loss = 14.370843943208456, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 364, train_loss = 14.35467120166868, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 365, train_loss = 14.35403153207153, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 366, train_loss = 14.350935290567577, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 367, train_loss = 14.34247774630785, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 368, train_loss = 14.333771672099829, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 369, train_loss = 14.332532974891365, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 370, train_loss = 14.316896557807922, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 371, train_loss = 14.323920767754316, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 372, train_loss = 14.315838896669447, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 373, train_loss = 14.301798718981445, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 374, train_loss = 14.296170108020306, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 375, train_loss = 14.295186095871031, train_acc = 0.9683278993945039\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 376, train_loss = 14.287031851708889, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 377, train_loss = 14.284116551280022, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 378, train_loss = 14.27785703446716, train_acc = 0.9683278993945039\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 379, train_loss = 14.27188939601183, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 380, train_loss = 14.268783368170261, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 381, train_loss = 14.25881055276841, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 382, train_loss = 14.253964554518461, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 383, train_loss = 14.244318041950464, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 384, train_loss = 14.249668806791306, train_acc = 0.9684443409408477\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 385, train_loss = 14.241971024312079, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 386, train_loss = 14.232659745961428, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 387, train_loss = 14.225166897289455, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 388, train_loss = 14.218247465789318, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 389, train_loss = 14.213412930257618, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 390, train_loss = 14.210513125173748, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 391, train_loss = 14.198349762707949, train_acc = 0.9685607824871915\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 392, train_loss = 14.188673569820821, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 393, train_loss = 14.19050641078502, train_acc = 0.9684443409408477\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 394, train_loss = 14.184262744151056, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 395, train_loss = 14.181470627896488, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 396, train_loss = 14.17972159665078, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 397, train_loss = 14.165046907961369, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 398, train_loss = 14.155216484330595, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 399, train_loss = 14.15216301009059, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 400, train_loss = 14.149783671833575, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 401, train_loss = 14.137731733731925, train_acc = 0.9690265486725663\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 402, train_loss = 14.140506143681705, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 403, train_loss = 14.130917057394981, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 404, train_loss = 14.120841710828245, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 405, train_loss = 14.128107228316367, train_acc = 0.9686772240335352\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 406, train_loss = 14.114463687874377, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 407, train_loss = 14.115724377334118, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 408, train_loss = 14.11161433905363, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 409, train_loss = 14.10753574874252, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 410, train_loss = 14.093189812265337, train_acc = 0.9687936655798789\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 411, train_loss = 14.093857917934656, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 412, train_loss = 14.079890622757375, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 413, train_loss = 14.086347824893892, train_acc = 0.9686772240335352\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 414, train_loss = 14.075156152248383, train_acc = 0.9689101071262226\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 415, train_loss = 14.067363276146352, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 416, train_loss = 14.063167087733746, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 417, train_loss = 14.059832885861397, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 418, train_loss = 14.052303726784885, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 419, train_loss = 14.048385333269835, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 420, train_loss = 14.049218109808862, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 421, train_loss = 14.041096842847764, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 422, train_loss = 14.030870319344103, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 423, train_loss = 14.02976540569216, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 424, train_loss = 14.025481927208602, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 425, train_loss = 14.019742419011891, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 426, train_loss = 14.018615999259055, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 427, train_loss = 14.00877433642745, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 428, train_loss = 14.001786741428077, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 429, train_loss = 14.001259318552911, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 430, train_loss = 13.996065651066601, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 431, train_loss = 13.991699342615902, train_acc = 0.9687936655798789\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 432, train_loss = 13.99447472859174, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 433, train_loss = 13.983715694397688, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 434, train_loss = 13.975168112665415, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 435, train_loss = 13.96887984406203, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 436, train_loss = 13.962980672717094, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 437, train_loss = 13.96335346531123, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 438, train_loss = 13.958570060320199, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 439, train_loss = 13.949069730937481, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 440, train_loss = 13.94974554469809, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 441, train_loss = 13.938643074594438, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 442, train_loss = 13.943784843198955, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 443, train_loss = 13.930114102549851, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 444, train_loss = 13.930719714611769, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 445, train_loss = 13.920766055583954, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 446, train_loss = 13.918188954237849, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 447, train_loss = 13.91109936311841, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 448, train_loss = 13.9107211320661, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 449, train_loss = 13.907116580754519, train_acc = 0.9689101071262226\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 450, train_loss = 13.895432434976101, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 451, train_loss = 13.895966401789337, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 452, train_loss = 13.883121522609144, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 453, train_loss = 13.888515127357095, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 454, train_loss = 13.88236745679751, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 455, train_loss = 13.875313388649374, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 456, train_loss = 13.870624104049057, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 457, train_loss = 13.865554603282362, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 458, train_loss = 13.8734316281043, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 459, train_loss = 13.859171664807945, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 460, train_loss = 13.85331067442894, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 461, train_loss = 13.85020700097084, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 462, train_loss = 13.852894507348537, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 463, train_loss = 13.84277157112956, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 464, train_loss = 13.835800718516111, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 465, train_loss = 13.826909732073545, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 466, train_loss = 13.82717614620924, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 467, train_loss = 13.826413723174483, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 468, train_loss = 13.81288659432903, train_acc = 0.9690265486725663\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 469, train_loss = 13.816561043262482, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 470, train_loss = 13.813251849263906, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 471, train_loss = 13.801461616996676, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 472, train_loss = 13.797870265785605, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 473, train_loss = 13.79782498627901, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 474, train_loss = 13.790407618042082, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 475, train_loss = 13.784633775707334, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 476, train_loss = 13.788668210152537, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 477, train_loss = 13.779020024929196, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 478, train_loss = 13.78502906113863, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 479, train_loss = 13.76971901440993, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 480, train_loss = 13.76938670873642, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 481, train_loss = 13.767998100724071, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 482, train_loss = 13.76357559626922, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 483, train_loss = 13.759410737548023, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 484, train_loss = 13.752460788935423, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 485, train_loss = 13.74814817076549, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 486, train_loss = 13.742533026728779, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 487, train_loss = 13.739540094975382, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 488, train_loss = 13.737727953586727, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 489, train_loss = 13.727146860212088, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 490, train_loss = 13.729869285132736, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 491, train_loss = 13.716682992875576, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 492, train_loss = 13.716848765965551, train_acc = 0.9691429902189101\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 493, train_loss = 13.709924125578254, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 494, train_loss = 13.70938898762688, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 495, train_loss = 13.705170145723969, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 496, train_loss = 13.69880990544334, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 497, train_loss = 13.691717191133648, train_acc = 0.9692594317652539\n",
      "test Acc 0.9483240223463687:\n",
      "28th- epoch: 498, train_loss = 13.692199096083641, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 499, train_loss = 13.693681716918945, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████▏    | 28/30 [4:13:30<18:07, 543.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "29th- epoch: 0, train_loss = 123.51335108280182, train_acc = 0.7425477410340009\n",
      "test Acc 0.8566108007448789:\n",
      "29th- epoch: 1, train_loss = 56.2576664686203, train_acc = 0.872380065207266\n",
      "test Acc 0.8817504655493482:\n",
      "29th- epoch: 2, train_loss = 46.97509351372719, train_acc = 0.8910107126222636\n",
      "test Acc 0.904562383612663:\n",
      "29th- epoch: 3, train_loss = 42.246245220303535, train_acc = 0.9030041918956684\n",
      "test Acc 0.9124767225325885:\n",
      "29th- epoch: 4, train_loss = 39.162872210145, train_acc = 0.9105728924080112\n",
      "test Acc 0.9171322160148976:\n",
      "29th- epoch: 5, train_loss = 36.93672014027834, train_acc = 0.9151141127154169\n",
      "test Acc 0.9222532588454376:\n",
      "29th- epoch: 6, train_loss = 35.21063154190779, train_acc = 0.9196553330228225\n",
      "test Acc 0.9231843575418994:\n",
      "29th- epoch: 7, train_loss = 33.830182299017906, train_acc = 0.9223334885887284\n",
      "test Acc 0.9264432029795159:\n",
      "29th- epoch: 8, train_loss = 32.64714143425226, train_acc = 0.9248952026082906\n",
      "test Acc 0.9278398510242085:\n",
      "29th- epoch: 9, train_loss = 31.655802749097347, train_acc = 0.9287377736376339\n",
      "test Acc 0.9292364990689013:\n",
      "29th- epoch: 10, train_loss = 30.80668842047453, train_acc = 0.9311830461108523\n",
      "test Acc 0.9297020484171322:\n",
      "29th- epoch: 11, train_loss = 30.058711491525173, train_acc = 0.9331625523986958\n",
      "test Acc 0.931098696461825:\n",
      "29th- epoch: 12, train_loss = 29.420332610607147, train_acc = 0.9349091755938519\n",
      "test Acc 0.931098696461825:\n",
      "29th- epoch: 13, train_loss = 28.84268380701542, train_acc = 0.9365393572426641\n",
      "test Acc 0.9315642458100558:\n",
      "29th- epoch: 14, train_loss = 28.331028051674366, train_acc = 0.9377037727061015\n",
      "test Acc 0.9315642458100558:\n",
      "29th- epoch: 15, train_loss = 27.862967859953642, train_acc = 0.9393339543549138\n",
      "test Acc 0.931098696461825:\n",
      "29th- epoch: 16, train_loss = 27.44806145131588, train_acc = 0.9395668374476013\n",
      "test Acc 0.931098696461825:\n",
      "29th- epoch: 17, train_loss = 27.038370735943317, train_acc = 0.9411970190964136\n",
      "test Acc 0.9315642458100558:\n",
      "29th- epoch: 18, train_loss = 26.66255457699299, train_acc = 0.9420121099208197\n",
      "test Acc 0.9320297951582868:\n",
      "29th- epoch: 19, train_loss = 26.302561096847057, train_acc = 0.9428272007452259\n",
      "test Acc 0.9324953445065177:\n",
      "29th- epoch: 20, train_loss = 26.01615058630705, train_acc = 0.9432929669306008\n",
      "test Acc 0.9329608938547486:\n",
      "29th- epoch: 21, train_loss = 25.7087434977293, train_acc = 0.9437587331159758\n",
      "test Acc 0.9348230912476723:\n",
      "29th- epoch: 22, train_loss = 25.40978556126356, train_acc = 0.9446902654867256\n",
      "test Acc 0.9352886405959032:\n",
      "29th- epoch: 23, train_loss = 25.14352374523878, train_acc = 0.9445738239403819\n",
      "test Acc 0.9357541899441341:\n",
      "29th- epoch: 24, train_loss = 24.885285146534443, train_acc = 0.9451560316721006\n",
      "test Acc 0.936219739292365:\n",
      "29th- epoch: 25, train_loss = 24.650281235575676, train_acc = 0.9460875640428504\n",
      "test Acc 0.9366852886405959:\n",
      "29th- epoch: 26, train_loss = 24.435680709779263, train_acc = 0.9466697717745691\n",
      "test Acc 0.9371508379888268:\n",
      "29th- epoch: 27, train_loss = 24.213901687413454, train_acc = 0.9472519795062878\n",
      "test Acc 0.9371508379888268:\n",
      "29th- epoch: 28, train_loss = 24.008800476789474, train_acc = 0.948067070330694\n",
      "test Acc 0.9376163873370578:\n",
      "29th- epoch: 29, train_loss = 23.79076310619712, train_acc = 0.9485328365160689\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 30, train_loss = 23.599437419325113, train_acc = 0.9492314857941313\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 31, train_loss = 23.42078698799014, train_acc = 0.9494643688868188\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 32, train_loss = 23.25959139317274, train_acc = 0.94981369352585\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 33, train_loss = 23.094343572854996, train_acc = 0.9503959012575687\n",
      "test Acc 0.9390130353817505:\n",
      "29th- epoch: 34, train_loss = 22.90627922862768, train_acc = 0.9508616674429436\n",
      "test Acc 0.9390130353817505:\n",
      "29th- epoch: 35, train_loss = 22.75802493467927, train_acc = 0.9510945505356311\n",
      "test Acc 0.9390130353817505:\n",
      "29th- epoch: 36, train_loss = 22.6283864043653, train_acc = 0.9512109920819748\n",
      "test Acc 0.9390130353817505:\n",
      "29th- epoch: 37, train_loss = 22.488568004220724, train_acc = 0.9513274336283186\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 38, train_loss = 22.341960202902555, train_acc = 0.9514438751746623\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 39, train_loss = 22.20228758826852, train_acc = 0.9516767582673498\n",
      "test Acc 0.9385474860335196:\n",
      "29th- epoch: 40, train_loss = 22.092414017766714, train_acc = 0.952026082906381\n",
      "test Acc 0.9394785847299814:\n",
      "29th- epoch: 41, train_loss = 21.94988152757287, train_acc = 0.9521425244527247\n",
      "test Acc 0.9394785847299814:\n",
      "29th- epoch: 42, train_loss = 21.815237503498793, train_acc = 0.9522589659990685\n",
      "test Acc 0.9394785847299814:\n",
      "29th- epoch: 43, train_loss = 21.710063327103853, train_acc = 0.9523754075454122\n",
      "test Acc 0.9394785847299814:\n",
      "29th- epoch: 44, train_loss = 21.58740695565939, train_acc = 0.9531904983698184\n",
      "test Acc 0.9394785847299814:\n",
      "29th- epoch: 45, train_loss = 21.477944679558277, train_acc = 0.9528411737307871\n",
      "test Acc 0.9394785847299814:\n",
      "29th- epoch: 46, train_loss = 21.383142810314894, train_acc = 0.9533069399161621\n",
      "test Acc 0.9394785847299814:\n",
      "29th- epoch: 47, train_loss = 21.306930113583803, train_acc = 0.9534233814625058\n",
      "test Acc 0.9399441340782123:\n",
      "29th- epoch: 48, train_loss = 21.19515046849847, train_acc = 0.9538891476478808\n",
      "test Acc 0.9408752327746741:\n",
      "29th- epoch: 49, train_loss = 21.10076356679201, train_acc = 0.9540055891942245\n",
      "test Acc 0.9408752327746741:\n",
      "29th- epoch: 50, train_loss = 21.002820182591677, train_acc = 0.9542384722869119\n",
      "test Acc 0.9408752327746741:\n",
      "29th- epoch: 51, train_loss = 20.917641885578632, train_acc = 0.9542384722869119\n",
      "test Acc 0.9408752327746741:\n",
      "29th- epoch: 52, train_loss = 20.811521638184786, train_acc = 0.9548206800186306\n",
      "test Acc 0.9404096834264432:\n",
      "29th- epoch: 53, train_loss = 20.72652107849717, train_acc = 0.9545877969259432\n",
      "test Acc 0.9404096834264432:\n",
      "29th- epoch: 54, train_loss = 20.634594421833754, train_acc = 0.9550535631113182\n",
      "test Acc 0.9404096834264432:\n",
      "29th- epoch: 55, train_loss = 20.551463592797518, train_acc = 0.9549371215649743\n",
      "test Acc 0.9404096834264432:\n",
      "29th- epoch: 56, train_loss = 20.472004000097513, train_acc = 0.9554028877503493\n",
      "test Acc 0.9404096834264432:\n",
      "29th- epoch: 57, train_loss = 20.393272034823895, train_acc = 0.9552864462040056\n",
      "test Acc 0.9408752327746741:\n",
      "29th- epoch: 58, train_loss = 20.305107075721025, train_acc = 0.955519329296693\n",
      "test Acc 0.9408752327746741:\n",
      "29th- epoch: 59, train_loss = 20.24463116750121, train_acc = 0.9556357708430367\n",
      "test Acc 0.9408752327746741:\n",
      "29th- epoch: 60, train_loss = 20.17191845551133, train_acc = 0.9551700046576619\n",
      "test Acc 0.9413407821229051:\n",
      "29th- epoch: 61, train_loss = 20.099046893417835, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "29th- epoch: 62, train_loss = 20.02072297781706, train_acc = 0.9561015370284117\n",
      "test Acc 0.9413407821229051:\n",
      "29th- epoch: 63, train_loss = 19.96242394670844, train_acc = 0.9561015370284117\n",
      "test Acc 0.9413407821229051:\n",
      "29th- epoch: 64, train_loss = 19.897690135985613, train_acc = 0.9557522123893806\n",
      "test Acc 0.9413407821229051:\n",
      "29th- epoch: 65, train_loss = 19.80765287950635, train_acc = 0.9562179785747554\n",
      "test Acc 0.9418063314711359:\n",
      "29th- epoch: 66, train_loss = 19.763290490955114, train_acc = 0.9563344201210993\n",
      "test Acc 0.9418063314711359:\n",
      "29th- epoch: 67, train_loss = 19.68467613682151, train_acc = 0.9562179785747554\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 68, train_loss = 19.62105230614543, train_acc = 0.9565673032137867\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 69, train_loss = 19.562087297439575, train_acc = 0.9566837447601304\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 70, train_loss = 19.509706627577543, train_acc = 0.9566837447601304\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 71, train_loss = 19.452639918774366, train_acc = 0.9569166278528178\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 72, train_loss = 19.397168956696987, train_acc = 0.9571495109455054\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 73, train_loss = 19.332684438675642, train_acc = 0.9573823940381928\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 74, train_loss = 19.287795398384333, train_acc = 0.9572659524918491\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 75, train_loss = 19.2339325286448, train_acc = 0.9573823940381928\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 76, train_loss = 19.168281514197588, train_acc = 0.9572659524918491\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 77, train_loss = 19.118237931281328, train_acc = 0.9572659524918491\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 78, train_loss = 19.066702745854855, train_acc = 0.9576152771308803\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 79, train_loss = 19.021966625005007, train_acc = 0.9577317186772241\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 80, train_loss = 18.97328946366906, train_acc = 0.9577317186772241\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 81, train_loss = 18.911487855017185, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 82, train_loss = 18.863706063479185, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 83, train_loss = 18.810584016144276, train_acc = 0.9578481602235678\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 84, train_loss = 18.77923045679927, train_acc = 0.9579646017699115\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 85, train_loss = 18.724576476961374, train_acc = 0.9580810433162552\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 86, train_loss = 18.6736872009933, train_acc = 0.9583139264089428\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 87, train_loss = 18.64430089108646, train_acc = 0.9585468095016302\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 88, train_loss = 18.590228037908673, train_acc = 0.9586632510479739\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 89, train_loss = 18.526788026094437, train_acc = 0.9587796925943176\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 90, train_loss = 18.498193679377437, train_acc = 0.9586632510479739\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 91, train_loss = 18.461016023531556, train_acc = 0.9588961341406614\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 92, train_loss = 18.407526798546314, train_acc = 0.9588961341406614\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 93, train_loss = 18.368407210335135, train_acc = 0.9587796925943176\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 94, train_loss = 18.334757409989834, train_acc = 0.9591290172333489\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 95, train_loss = 18.288246296346188, train_acc = 0.9592454587796926\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 96, train_loss = 18.254563419148326, train_acc = 0.9592454587796926\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 97, train_loss = 18.216833906248212, train_acc = 0.9595947834187238\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 98, train_loss = 18.185773568227887, train_acc = 0.9597112249650676\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 99, train_loss = 18.140460280701518, train_acc = 0.9598276665114113\n",
      "test Acc 0.9422718808193669:\n",
      "29th- epoch: 100, train_loss = 18.090412078425288, train_acc = 0.9598276665114113\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 101, train_loss = 18.079838240519166, train_acc = 0.9602934326967862\n",
      "test Acc 0.9422718808193669:\n",
      "29th- epoch: 102, train_loss = 18.037054143846035, train_acc = 0.9601769911504425\n",
      "test Acc 0.9422718808193669:\n",
      "29th- epoch: 103, train_loss = 18.00908870063722, train_acc = 0.9601769911504425\n",
      "test Acc 0.9422718808193669:\n",
      "29th- epoch: 104, train_loss = 17.964831866323948, train_acc = 0.96040987424313\n",
      "test Acc 0.9422718808193669:\n",
      "29th- epoch: 105, train_loss = 17.930704355239868, train_acc = 0.9606427573358174\n",
      "test Acc 0.9422718808193669:\n",
      "29th- epoch: 106, train_loss = 17.907609401270747, train_acc = 0.96040987424313\n",
      "test Acc 0.9422718808193669:\n",
      "29th- epoch: 107, train_loss = 17.862366994842887, train_acc = 0.9609920819748486\n",
      "test Acc 0.9422718808193669:\n",
      "29th- epoch: 108, train_loss = 17.827662965282798, train_acc = 0.9606427573358174\n",
      "test Acc 0.9422718808193669:\n",
      "29th- epoch: 109, train_loss = 17.777424229308963, train_acc = 0.9611085235211924\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 110, train_loss = 17.746760683134198, train_acc = 0.9609920819748486\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 111, train_loss = 17.733187368139625, train_acc = 0.9612249650675361\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 112, train_loss = 17.70453858561814, train_acc = 0.9609920819748486\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 113, train_loss = 17.657919505611062, train_acc = 0.9609920819748486\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 114, train_loss = 17.640703024342656, train_acc = 0.9609920819748486\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 115, train_loss = 17.614727983251214, train_acc = 0.9611085235211924\n",
      "test Acc 0.9427374301675978:\n",
      "29th- epoch: 116, train_loss = 17.575565034523606, train_acc = 0.9612249650675361\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 117, train_loss = 17.547211913391948, train_acc = 0.9612249650675361\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 118, train_loss = 17.51279672421515, train_acc = 0.9614578481602236\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 119, train_loss = 17.480111652985215, train_acc = 0.9612249650675361\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 120, train_loss = 17.44552076421678, train_acc = 0.9614578481602236\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 121, train_loss = 17.41744524985552, train_acc = 0.9614578481602236\n",
      "test Acc 0.9432029795158287:\n",
      "29th- epoch: 122, train_loss = 17.390397069975734, train_acc = 0.9614578481602236\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 123, train_loss = 17.37258349917829, train_acc = 0.9615742897065673\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 124, train_loss = 17.333650117740035, train_acc = 0.9615742897065673\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 125, train_loss = 17.30109960027039, train_acc = 0.9614578481602236\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 126, train_loss = 17.272890135645866, train_acc = 0.961690731252911\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 127, train_loss = 17.256072022020817, train_acc = 0.9614578481602236\n",
      "test Acc 0.9441340782122905:\n",
      "29th- epoch: 128, train_loss = 17.234658628702164, train_acc = 0.9618071727992548\n",
      "test Acc 0.9441340782122905:\n",
      "29th- epoch: 129, train_loss = 17.21423531882465, train_acc = 0.961690731252911\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 130, train_loss = 17.175815045833588, train_acc = 0.9618071727992548\n",
      "test Acc 0.9436685288640596:\n",
      "29th- epoch: 131, train_loss = 17.155594440177083, train_acc = 0.9619236143455985\n",
      "test Acc 0.9441340782122905:\n",
      "29th- epoch: 132, train_loss = 17.1313635725528, train_acc = 0.962156497438286\n",
      "test Acc 0.9441340782122905:\n",
      "29th- epoch: 133, train_loss = 17.114726880565286, train_acc = 0.9620400558919422\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 134, train_loss = 17.084756895899773, train_acc = 0.9622729389846297\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 135, train_loss = 17.056357994675636, train_acc = 0.9623893805309734\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 136, train_loss = 17.035334400832653, train_acc = 0.9626222636236609\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 137, train_loss = 17.008610298857093, train_acc = 0.9625058220773172\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 138, train_loss = 16.99207305908203, train_acc = 0.9626222636236609\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 139, train_loss = 16.978752313181758, train_acc = 0.9626222636236609\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 140, train_loss = 16.96594842709601, train_acc = 0.9626222636236609\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 141, train_loss = 16.929451243951917, train_acc = 0.9628551467163484\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 142, train_loss = 16.89934021793306, train_acc = 0.9627387051700047\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 143, train_loss = 16.8835619520396, train_acc = 0.9629715882626921\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 144, train_loss = 16.861911753192544, train_acc = 0.9629715882626921\n",
      "test Acc 0.9445996275605214:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 145, train_loss = 16.824213311076164, train_acc = 0.9627387051700047\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 146, train_loss = 16.814102517440915, train_acc = 0.9630880298090359\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 147, train_loss = 16.791318660601974, train_acc = 0.9628551467163484\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 148, train_loss = 16.77997314929962, train_acc = 0.9628551467163484\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 149, train_loss = 16.74793365597725, train_acc = 0.9632044713553796\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 150, train_loss = 16.724954694509506, train_acc = 0.9629715882626921\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 151, train_loss = 16.711886072531343, train_acc = 0.9632044713553796\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 152, train_loss = 16.69285367242992, train_acc = 0.9630880298090359\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 153, train_loss = 16.679615773260593, train_acc = 0.9632044713553796\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 154, train_loss = 16.64872549287975, train_acc = 0.9630880298090359\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 155, train_loss = 16.630832275375724, train_acc = 0.9633209129017233\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 156, train_loss = 16.613689059391618, train_acc = 0.9636702375407545\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 157, train_loss = 16.60092701204121, train_acc = 0.9636702375407545\n",
      "test Acc 0.9450651769087524:\n",
      "29th- epoch: 158, train_loss = 16.56741282902658, train_acc = 0.9637866790870983\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 159, train_loss = 16.56047223508358, train_acc = 0.963903120633442\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 160, train_loss = 16.54715348035097, train_acc = 0.9640195621797858\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 161, train_loss = 16.51901948451996, train_acc = 0.9641360037261295\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 162, train_loss = 16.495284229516983, train_acc = 0.9643688868188169\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 163, train_loss = 16.488273983821273, train_acc = 0.9642524452724732\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 164, train_loss = 16.45962212048471, train_acc = 0.9642524452724732\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 165, train_loss = 16.449641443789005, train_acc = 0.9641360037261295\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 166, train_loss = 16.42819671332836, train_acc = 0.9646017699115044\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 167, train_loss = 16.40968314744532, train_acc = 0.9641360037261295\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 168, train_loss = 16.392343709245324, train_acc = 0.9644853283651607\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 169, train_loss = 16.37765329889953, train_acc = 0.9643688868188169\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 170, train_loss = 16.359743217006326, train_acc = 0.9644853283651607\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 171, train_loss = 16.341538600623608, train_acc = 0.9646017699115044\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 172, train_loss = 16.321002846583724, train_acc = 0.9646017699115044\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 173, train_loss = 16.2952833250165, train_acc = 0.9647182114578482\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 174, train_loss = 16.293016390874982, train_acc = 0.9646017699115044\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 175, train_loss = 16.274772284552455, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 176, train_loss = 16.248638859018683, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 177, train_loss = 16.24232122115791, train_acc = 0.9647182114578482\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 178, train_loss = 16.223308980464935, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 179, train_loss = 16.21008841879666, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "29th- epoch: 180, train_loss = 16.198096066713333, train_acc = 0.9649510945505356\n",
      "test Acc 0.9459962756052142:\n",
      "29th- epoch: 181, train_loss = 16.167620562016964, train_acc = 0.9648346530041919\n",
      "test Acc 0.9459962756052142:\n",
      "29th- epoch: 182, train_loss = 16.16896336711943, train_acc = 0.9648346530041919\n",
      "test Acc 0.9459962756052142:\n",
      "29th- epoch: 183, train_loss = 16.1362112686038, train_acc = 0.9648346530041919\n",
      "test Acc 0.9459962756052142:\n",
      "29th- epoch: 184, train_loss = 16.122992334887385, train_acc = 0.9647182114578482\n",
      "test Acc 0.9459962756052142:\n",
      "29th- epoch: 185, train_loss = 16.1164882350713, train_acc = 0.9649510945505356\n",
      "test Acc 0.9459962756052142:\n",
      "29th- epoch: 186, train_loss = 16.090946028009057, train_acc = 0.9649510945505356\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 187, train_loss = 16.091992408037186, train_acc = 0.9651839776432231\n",
      "test Acc 0.9459962756052142:\n",
      "29th- epoch: 188, train_loss = 16.065257171168923, train_acc = 0.9649510945505356\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 189, train_loss = 16.044494641944766, train_acc = 0.9653004191895669\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 190, train_loss = 16.03736274689436, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 191, train_loss = 16.019462063908577, train_acc = 0.9653004191895669\n",
      "test Acc 0.9459962756052142:\n",
      "29th- epoch: 192, train_loss = 15.997798988595605, train_acc = 0.9653004191895669\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 193, train_loss = 15.984295232221484, train_acc = 0.9654168607359106\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 194, train_loss = 15.978651091456413, train_acc = 0.9654168607359106\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 195, train_loss = 15.964875245466828, train_acc = 0.9654168607359106\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 196, train_loss = 15.937883168458939, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 197, train_loss = 15.942674107849598, train_acc = 0.9654168607359106\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 198, train_loss = 15.926117056980729, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 199, train_loss = 15.912403782829642, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 200, train_loss = 15.895736379548907, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 201, train_loss = 15.889677673578262, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 202, train_loss = 15.85158228315413, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 203, train_loss = 15.854544065892696, train_acc = 0.9657661853749417\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 204, train_loss = 15.84032122604549, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 205, train_loss = 15.818077055737376, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 206, train_loss = 15.809056915342808, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 207, train_loss = 15.793670520186424, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 208, train_loss = 15.775434046983719, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 209, train_loss = 15.781533973291516, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 210, train_loss = 15.754664666950703, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 211, train_loss = 15.731220051646233, train_acc = 0.965649743828598\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 212, train_loss = 15.712483895942569, train_acc = 0.9658826269212856\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 213, train_loss = 15.719685865566134, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 214, train_loss = 15.70157271437347, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 215, train_loss = 15.69503303617239, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 216, train_loss = 15.676496567204595, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 217, train_loss = 15.671271553263068, train_acc = 0.9659990684676293\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 218, train_loss = 15.67102043889463, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 219, train_loss = 15.638415426015854, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 220, train_loss = 15.616362186148763, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 221, train_loss = 15.60924299620092, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 222, train_loss = 15.592762948945165, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 223, train_loss = 15.593288578093052, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 224, train_loss = 15.580967597663403, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 225, train_loss = 15.55732542835176, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 226, train_loss = 15.551302395761013, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 227, train_loss = 15.54135725647211, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 228, train_loss = 15.53693020902574, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 229, train_loss = 15.521252585574985, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 230, train_loss = 15.510948978364468, train_acc = 0.966115510013973\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 231, train_loss = 15.497875213623047, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 232, train_loss = 15.483800234273076, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 233, train_loss = 15.480628928169608, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 234, train_loss = 15.452154122292995, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 235, train_loss = 15.45112699456513, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 236, train_loss = 15.440298737958074, train_acc = 0.9662319515603167\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 237, train_loss = 15.433187192305923, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 238, train_loss = 15.418044665828347, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 239, train_loss = 15.395061051473022, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 240, train_loss = 15.38432533480227, train_acc = 0.9664648346530041\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 241, train_loss = 15.374896524474025, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 242, train_loss = 15.35855290479958, train_acc = 0.9663483931066604\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 243, train_loss = 15.358371177688241, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 244, train_loss = 15.3504568785429, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 245, train_loss = 15.337951089255512, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 246, train_loss = 15.324048710986972, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 247, train_loss = 15.308373761363328, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 248, train_loss = 15.306143268942833, train_acc = 0.9668141592920354\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 249, train_loss = 15.291607545688748, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 250, train_loss = 15.270511195063591, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 251, train_loss = 15.273686188273132, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 252, train_loss = 15.274006225168705, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 253, train_loss = 15.250282064080238, train_acc = 0.9668141592920354\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 254, train_loss = 15.229496151208878, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 255, train_loss = 15.227589604444802, train_acc = 0.9668141592920354\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 256, train_loss = 15.219970941543579, train_acc = 0.9668141592920354\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 257, train_loss = 15.203571423888206, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 258, train_loss = 15.19777987897396, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 259, train_loss = 15.20802891254425, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 260, train_loss = 15.188616116531193, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 261, train_loss = 15.18851774185896, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 262, train_loss = 15.167395454831421, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 263, train_loss = 15.144643060863018, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 264, train_loss = 15.155099406838417, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 265, train_loss = 15.147044320590794, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 266, train_loss = 15.135785306803882, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 267, train_loss = 15.125169336795807, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 268, train_loss = 15.104844783432782, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 269, train_loss = 15.108320993371308, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 270, train_loss = 15.085361580364406, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "29th- epoch: 271, train_loss = 15.083706304430962, train_acc = 0.9669306008383791\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 272, train_loss = 15.073574314825237, train_acc = 0.9670470423847228\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 273, train_loss = 15.071768246591091, train_acc = 0.9669306008383791\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 274, train_loss = 15.047915033996105, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 275, train_loss = 15.036844906397164, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 276, train_loss = 15.034945237450302, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 277, train_loss = 15.025628129951656, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 278, train_loss = 15.020047751255333, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 279, train_loss = 15.01244977582246, train_acc = 0.9671634839310667\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 280, train_loss = 14.99380764644593, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 281, train_loss = 14.997459252364933, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 282, train_loss = 14.985435266979039, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 283, train_loss = 14.977789476513863, train_acc = 0.9672799254774104\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 284, train_loss = 14.970440712757409, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 285, train_loss = 14.965166434645653, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 286, train_loss = 14.948440556414425, train_acc = 0.9672799254774104\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 287, train_loss = 14.931050069630146, train_acc = 0.9673963670237541\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 288, train_loss = 14.93218494206667, train_acc = 0.9673963670237541\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 289, train_loss = 14.926179252564907, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 290, train_loss = 14.908035951666534, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 291, train_loss = 14.895413306541741, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 292, train_loss = 14.888314358890057, train_acc = 0.9675128085700978\n",
      "test Acc 0.9478584729981379:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 293, train_loss = 14.887014160864055, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 294, train_loss = 14.877749130129814, train_acc = 0.9676292501164415\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 295, train_loss = 14.862331330776215, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 296, train_loss = 14.872662097215652, train_acc = 0.9675128085700978\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 297, train_loss = 14.869758442044258, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 298, train_loss = 14.85456594824791, train_acc = 0.9677456916627852\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 299, train_loss = 14.846158869564533, train_acc = 0.9676292501164415\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 300, train_loss = 14.842322933487594, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 301, train_loss = 14.831947204656899, train_acc = 0.9678621332091291\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 302, train_loss = 14.8371358262375, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 303, train_loss = 14.813600805588067, train_acc = 0.9678621332091291\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 304, train_loss = 14.807999342679977, train_acc = 0.9678621332091291\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 305, train_loss = 14.790689651854336, train_acc = 0.9677456916627852\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 306, train_loss = 14.776701386086643, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 307, train_loss = 14.76555810123682, train_acc = 0.9678621332091291\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 308, train_loss = 14.774963651783764, train_acc = 0.9678621332091291\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 309, train_loss = 14.757967886514962, train_acc = 0.9679785747554728\n",
      "test Acc 0.9478584729981379:\n",
      "29th- epoch: 310, train_loss = 14.75859374832362, train_acc = 0.9677456916627852\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 311, train_loss = 14.752988840453327, train_acc = 0.9678621332091291\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 312, train_loss = 14.74871542584151, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 313, train_loss = 14.738266264088452, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 314, train_loss = 14.719366498291492, train_acc = 0.9679785747554728\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 315, train_loss = 14.723936855793, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 316, train_loss = 14.7143236072734, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 317, train_loss = 14.69398547988385, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 318, train_loss = 14.687276323325932, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 319, train_loss = 14.70306431222707, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 320, train_loss = 14.683891507796943, train_acc = 0.9678621332091291\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 321, train_loss = 14.667669127695262, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 322, train_loss = 14.659674596972764, train_acc = 0.9679785747554728\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 323, train_loss = 14.665360788814723, train_acc = 0.9684443409408477\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 324, train_loss = 14.661803856492043, train_acc = 0.9679785747554728\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 325, train_loss = 14.63239059317857, train_acc = 0.9680950163018165\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 326, train_loss = 14.63530548941344, train_acc = 0.9682114578481602\n",
      "test Acc 0.9483240223463687:\n",
      "29th- epoch: 327, train_loss = 14.623541194014251, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 328, train_loss = 14.62354190647602, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 329, train_loss = 14.625146147795022, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 330, train_loss = 14.611827832646668, train_acc = 0.9680950163018165\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 331, train_loss = 14.610508278012276, train_acc = 0.9682114578481602\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 332, train_loss = 14.594456143677235, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 333, train_loss = 14.587312768213451, train_acc = 0.9687936655798789\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 334, train_loss = 14.580157111398876, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 335, train_loss = 14.581551509909332, train_acc = 0.9683278993945039\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 336, train_loss = 14.56922521442175, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 337, train_loss = 14.5764514580369, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 338, train_loss = 14.55964174401015, train_acc = 0.9683278993945039\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 339, train_loss = 14.55509967636317, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 340, train_loss = 14.54807207453996, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 341, train_loss = 14.544388676993549, train_acc = 0.9683278993945039\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 342, train_loss = 14.537551830522716, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 343, train_loss = 14.52160691935569, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 344, train_loss = 14.511552423238754, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 345, train_loss = 14.5127586228773, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 346, train_loss = 14.506783033721149, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 347, train_loss = 14.498478817753494, train_acc = 0.9682114578481602\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 348, train_loss = 14.48516868520528, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 349, train_loss = 14.479358253069222, train_acc = 0.9686772240335352\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 350, train_loss = 14.473966807126999, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 351, train_loss = 14.473578159697354, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 352, train_loss = 14.462778247892857, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 353, train_loss = 14.45068250130862, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 354, train_loss = 14.461156795732677, train_acc = 0.9684443409408477\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 355, train_loss = 14.458137820474803, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 356, train_loss = 14.44163088221103, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 357, train_loss = 14.43691910803318, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 358, train_loss = 14.419507940299809, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 359, train_loss = 14.423519715666771, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 360, train_loss = 14.409806911833584, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 361, train_loss = 14.404798802919686, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 362, train_loss = 14.400007285177708, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 363, train_loss = 14.400768123567104, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 364, train_loss = 14.405685909092426, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 365, train_loss = 14.401702123694122, train_acc = 0.9692594317652539\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 366, train_loss = 14.374653488397598, train_acc = 0.9689101071262226\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 367, train_loss = 14.36691312957555, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 368, train_loss = 14.364987242035568, train_acc = 0.9687936655798789\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 369, train_loss = 14.359851625747979, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 370, train_loss = 14.360454644076526, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 371, train_loss = 14.35796931385994, train_acc = 0.9690265486725663\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 372, train_loss = 14.341467429883778, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 373, train_loss = 14.334086333401501, train_acc = 0.9690265486725663\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 374, train_loss = 14.335415485315025, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 375, train_loss = 14.322002959437668, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 376, train_loss = 14.31074019242078, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 377, train_loss = 14.303435820154846, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 378, train_loss = 14.300398208200932, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 379, train_loss = 14.29607777763158, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 380, train_loss = 14.28339418489486, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 381, train_loss = 14.287147131748497, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 382, train_loss = 14.27681352943182, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 383, train_loss = 14.286585125140846, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 384, train_loss = 14.268959331326187, train_acc = 0.9691429902189101\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 385, train_loss = 14.279290090315044, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 386, train_loss = 14.273950415663421, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 387, train_loss = 14.250761304982007, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 388, train_loss = 14.247898335568607, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 389, train_loss = 14.240292037837207, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 390, train_loss = 14.235086791217327, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 391, train_loss = 14.239957727491856, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 392, train_loss = 14.23644394427538, train_acc = 0.9691429902189101\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 393, train_loss = 14.229196277447045, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 394, train_loss = 14.243648392148316, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 395, train_loss = 14.23375170212239, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 396, train_loss = 14.209375825710595, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 397, train_loss = 14.219932094216347, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 398, train_loss = 14.20119845867157, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 399, train_loss = 14.206637809984386, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 400, train_loss = 14.198183633387089, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 401, train_loss = 14.193414536304772, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 402, train_loss = 14.204227914102376, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 403, train_loss = 14.169364278204739, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 404, train_loss = 14.166963282041252, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 405, train_loss = 14.173706424422562, train_acc = 0.9692594317652539\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 406, train_loss = 14.170495577156544, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 407, train_loss = 14.145535844378173, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 408, train_loss = 14.142380212433636, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 409, train_loss = 14.134589925408363, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 410, train_loss = 14.1372599452734, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 411, train_loss = 14.133052113465965, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 412, train_loss = 14.125177179463208, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 413, train_loss = 14.118008012883365, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 414, train_loss = 14.106937430799007, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 415, train_loss = 14.11084512155503, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 416, train_loss = 14.108522154390812, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 417, train_loss = 14.095997783355415, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 418, train_loss = 14.104024316184223, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 419, train_loss = 14.089653286151588, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 420, train_loss = 14.084603021852672, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 421, train_loss = 14.092512533068657, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 422, train_loss = 14.076062957756221, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 423, train_loss = 14.068156328983605, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 424, train_loss = 14.065381507389247, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 425, train_loss = 14.059403412044048, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 426, train_loss = 14.057530936785042, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 427, train_loss = 14.049630299210548, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 428, train_loss = 14.045337088406086, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 429, train_loss = 14.048380735330284, train_acc = 0.9697251979506288\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 430, train_loss = 14.036735951900482, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 431, train_loss = 14.031358435750008, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 432, train_loss = 14.026165828108788, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 433, train_loss = 14.018863305449486, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 434, train_loss = 14.01956331729889, train_acc = 0.9693758733115976\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 435, train_loss = 14.021846096031368, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 436, train_loss = 14.00791842956096, train_acc = 0.9694923148579413\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 437, train_loss = 14.009986544959247, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 438, train_loss = 14.003694780170918, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 439, train_loss = 13.994902309961617, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 440, train_loss = 13.98164798039943, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 441, train_loss = 13.990956015884876, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 442, train_loss = 13.986311699263752, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 443, train_loss = 13.974659025669098, train_acc = 0.9699580810433163\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 444, train_loss = 13.969361998140812, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 445, train_loss = 13.96854053158313, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 446, train_loss = 13.960292977280915, train_acc = 0.969608756404285\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 447, train_loss = 13.958616730757058, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 448, train_loss = 13.958302569575608, train_acc = 0.969608756404285\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 449, train_loss = 13.949731692671776, train_acc = 0.9698416394969726\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 450, train_loss = 13.951051344163716, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 451, train_loss = 13.943253375589848, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 452, train_loss = 13.93359126150608, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 453, train_loss = 13.937721657566726, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 454, train_loss = 13.936361816711724, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 455, train_loss = 13.931146736256778, train_acc = 0.97007452258966\n",
      "test Acc 0.9497206703910615:\n",
      "29th- epoch: 456, train_loss = 13.926618357189, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 457, train_loss = 13.920919597148895, train_acc = 0.97007452258966\n",
      "test Acc 0.9497206703910615:\n",
      "29th- epoch: 458, train_loss = 13.915221224538982, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 459, train_loss = 13.911537108011544, train_acc = 0.9698416394969726\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 460, train_loss = 13.90321930218488, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 461, train_loss = 13.903225366957486, train_acc = 0.9701909641360037\n",
      "test Acc 0.9497206703910615:\n",
      "29th- epoch: 462, train_loss = 13.890426854602993, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 463, train_loss = 13.898460251279175, train_acc = 0.9701909641360037\n",
      "test Acc 0.9497206703910615:\n",
      "29th- epoch: 464, train_loss = 13.881665599532425, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 465, train_loss = 13.908441026695073, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 466, train_loss = 13.899394023232162, train_acc = 0.9698416394969726\n",
      "test Acc 0.9497206703910615:\n",
      "29th- epoch: 467, train_loss = 13.892345756292343, train_acc = 0.9699580810433163\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 468, train_loss = 13.875429864041507, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 469, train_loss = 13.88783498108387, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 470, train_loss = 13.865021464414895, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 471, train_loss = 13.857364890165627, train_acc = 0.9704238472286912\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 472, train_loss = 13.857205614447594, train_acc = 0.9703074056823474\n",
      "test Acc 0.9497206703910615:\n",
      "29th- epoch: 473, train_loss = 13.855614532716572, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 474, train_loss = 13.851650451309979, train_acc = 0.9701909641360037\n",
      "test Acc 0.9497206703910615:\n",
      "29th- epoch: 475, train_loss = 13.847617693245411, train_acc = 0.9701909641360037\n",
      "test Acc 0.9497206703910615:\n",
      "29th- epoch: 476, train_loss = 13.844349796883762, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 477, train_loss = 13.849903996102512, train_acc = 0.97007452258966\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 478, train_loss = 13.83294961322099, train_acc = 0.9701909641360037\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 479, train_loss = 13.83012994658202, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 480, train_loss = 13.823312086053193, train_acc = 0.9704238472286912\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 481, train_loss = 13.818287529051304, train_acc = 0.9703074056823474\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 482, train_loss = 13.811697538010776, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 483, train_loss = 13.818398599512875, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 484, train_loss = 13.808570208959281, train_acc = 0.9703074056823474\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 485, train_loss = 13.805874618701637, train_acc = 0.9701909641360037\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 486, train_loss = 13.797486786730587, train_acc = 0.970540288775035\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 487, train_loss = 13.804661613889039, train_acc = 0.9701909641360037\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 488, train_loss = 13.805782894603908, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 489, train_loss = 13.792860153131187, train_acc = 0.970540288775035\n",
      "test Acc 0.9497206703910615:\n",
      "29th- epoch: 490, train_loss = 13.783482308499515, train_acc = 0.9703074056823474\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 491, train_loss = 13.785923850722611, train_acc = 0.9704238472286912\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 492, train_loss = 13.774014949798584, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 493, train_loss = 13.777062816079706, train_acc = 0.9704238472286912\n",
      "test Acc 0.9492551210428305:\n",
      "29th- epoch: 494, train_loss = 13.776567660272121, train_acc = 0.9703074056823474\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 495, train_loss = 13.767730916384608, train_acc = 0.970540288775035\n",
      "test Acc 0.9497206703910615:\n",
      "29th- epoch: 496, train_loss = 13.765444725751877, train_acc = 0.970540288775035\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 497, train_loss = 13.765773308463395, train_acc = 0.970540288775035\n",
      "test Acc 0.9501862197392924:\n",
      "29th- epoch: 498, train_loss = 13.753418144769967, train_acc = 0.9704238472286912\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 499, train_loss = 13.754764944314957, train_acc = 0.9703074056823474\n",
      "test Acc 0.9492551210428305:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████▌  | 29/30 [4:22:32<09:03, 543.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method7_second(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (1): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "30th- epoch: 0, train_loss = 115.23131236433983, train_acc = 0.7553563111318118\n",
      "test Acc 0.8221601489757915:\n",
      "30th- epoch: 1, train_loss = 59.639636024832726, train_acc = 0.8734280391243596\n",
      "test Acc 0.8649906890130353:\n",
      "30th- epoch: 2, train_loss = 49.37126184999943, train_acc = 0.8969492314857941\n",
      "test Acc 0.8878026070763501:\n",
      "30th- epoch: 3, train_loss = 44.10238888859749, train_acc = 0.9084769445738239\n",
      "test Acc 0.904562383612663:\n",
      "30th- epoch: 4, train_loss = 40.790367498993874, train_acc = 0.9137168141592921\n",
      "test Acc 0.9078212290502793:\n",
      "30th- epoch: 5, train_loss = 38.368752144277096, train_acc = 0.9189566837447601\n",
      "test Acc 0.9143389199255121:\n",
      "30th- epoch: 6, train_loss = 36.4471145644784, train_acc = 0.9224499301350721\n",
      "test Acc 0.9171322160148976:\n",
      "30th- epoch: 7, train_loss = 34.940157532691956, train_acc = 0.9254774103400093\n",
      "test Acc 0.9199255121042831:\n",
      "30th- epoch: 8, train_loss = 33.70608463138342, train_acc = 0.9285048905449464\n",
      "test Acc 0.9222532588454376:\n",
      "30th- epoch: 9, train_loss = 32.66639029979706, train_acc = 0.9306008383791337\n",
      "test Acc 0.9259776536312849:\n",
      "30th- epoch: 10, train_loss = 31.755968630313873, train_acc = 0.9319981369352585\n",
      "test Acc 0.9259776536312849:\n",
      "30th- epoch: 11, train_loss = 30.967758662998676, train_acc = 0.9335118770377271\n",
      "test Acc 0.9264432029795159:\n",
      "30th- epoch: 12, train_loss = 30.268527537584305, train_acc = 0.9354913833255706\n",
      "test Acc 0.9269087523277467:\n",
      "30th- epoch: 13, train_loss = 29.633063405752182, train_acc = 0.9370051234280391\n",
      "test Acc 0.9269087523277467:\n",
      "30th- epoch: 14, train_loss = 29.051897771656513, train_acc = 0.9382859804378202\n",
      "test Acc 0.9269087523277467:\n",
      "30th- epoch: 15, train_loss = 28.53515524417162, train_acc = 0.9387517466231952\n",
      "test Acc 0.9283054003724395:\n",
      "30th- epoch: 16, train_loss = 28.05301621556282, train_acc = 0.9397997205402888\n",
      "test Acc 0.9287709497206704:\n",
      "30th- epoch: 17, train_loss = 27.608018081635237, train_acc = 0.94014904517932\n",
      "test Acc 0.930633147113594:\n",
      "30th- epoch: 18, train_loss = 27.19502167031169, train_acc = 0.9410805775500699\n",
      "test Acc 0.931098696461825:\n",
      "30th- epoch: 19, train_loss = 26.812553744763136, train_acc = 0.941895668374476\n",
      "test Acc 0.930633147113594:\n",
      "30th- epoch: 20, train_loss = 26.459776040166616, train_acc = 0.9434094084769445\n",
      "test Acc 0.9320297951582868:\n",
      "30th- epoch: 21, train_loss = 26.121968813240528, train_acc = 0.9442244993013508\n",
      "test Acc 0.9320297951582868:\n",
      "30th- epoch: 22, train_loss = 25.804260432720184, train_acc = 0.9448067070330693\n",
      "test Acc 0.9324953445065177:\n",
      "30th- epoch: 23, train_loss = 25.5176155641675, train_acc = 0.9455053563111319\n",
      "test Acc 0.9334264432029795:\n",
      "30th- epoch: 24, train_loss = 25.24974312633276, train_acc = 0.9459711224965067\n",
      "test Acc 0.9334264432029795:\n",
      "30th- epoch: 25, train_loss = 24.980509284883738, train_acc = 0.9464368886818817\n",
      "test Acc 0.9338919925512105:\n",
      "30th- epoch: 26, train_loss = 24.738214801996946, train_acc = 0.946786213320913\n",
      "test Acc 0.9348230912476723:\n",
      "30th- epoch: 27, train_loss = 24.493603359907866, train_acc = 0.9472519795062878\n",
      "test Acc 0.9343575418994413:\n",
      "30th- epoch: 28, train_loss = 24.263477969914675, train_acc = 0.9479506287843502\n",
      "test Acc 0.9352886405959032:\n",
      "30th- epoch: 29, train_loss = 24.05701796337962, train_acc = 0.9479506287843502\n",
      "test Acc 0.9352886405959032:\n",
      "30th- epoch: 30, train_loss = 23.863107811659575, train_acc = 0.9488821611551002\n",
      "test Acc 0.9352886405959032:\n",
      "30th- epoch: 31, train_loss = 23.66082351282239, train_acc = 0.9496972519795063\n",
      "test Acc 0.9357541899441341:\n",
      "30th- epoch: 32, train_loss = 23.47356228157878, train_acc = 0.9500465766185375\n",
      "test Acc 0.936219739292365:\n",
      "30th- epoch: 33, train_loss = 23.30156694725156, train_acc = 0.9503959012575687\n",
      "test Acc 0.936219739292365:\n",
      "30th- epoch: 34, train_loss = 23.13348364457488, train_acc = 0.9507452258965999\n",
      "test Acc 0.9366852886405959:\n",
      "30th- epoch: 35, train_loss = 22.964679066091776, train_acc = 0.9508616674429436\n",
      "test Acc 0.9366852886405959:\n",
      "30th- epoch: 36, train_loss = 22.807990308851004, train_acc = 0.9517931998136935\n",
      "test Acc 0.9371508379888268:\n",
      "30th- epoch: 37, train_loss = 22.647502824664116, train_acc = 0.9519096413600373\n",
      "test Acc 0.9371508379888268:\n",
      "30th- epoch: 38, train_loss = 22.49792717397213, train_acc = 0.952026082906381\n",
      "test Acc 0.9376163873370578:\n",
      "30th- epoch: 39, train_loss = 22.358563221991062, train_acc = 0.9522589659990685\n",
      "test Acc 0.9376163873370578:\n",
      "30th- epoch: 40, train_loss = 22.217364322394133, train_acc = 0.9527247321844434\n",
      "test Acc 0.9380819366852886:\n",
      "30th- epoch: 41, train_loss = 22.085438404232264, train_acc = 0.9527247321844434\n",
      "test Acc 0.9390130353817505:\n",
      "30th- epoch: 42, train_loss = 21.967427112162113, train_acc = 0.9528411737307871\n",
      "test Acc 0.9390130353817505:\n",
      "30th- epoch: 43, train_loss = 21.847339395433664, train_acc = 0.9530740568234746\n",
      "test Acc 0.9390130353817505:\n",
      "30th- epoch: 44, train_loss = 21.721028864383698, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n",
      "30th- epoch: 45, train_loss = 21.61535121873021, train_acc = 0.9531904983698184\n",
      "test Acc 0.9399441340782123:\n",
      "30th- epoch: 46, train_loss = 21.50005980581045, train_acc = 0.9533069399161621\n",
      "test Acc 0.9399441340782123:\n",
      "30th- epoch: 47, train_loss = 21.387193083763123, train_acc = 0.9537727061015371\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 48, train_loss = 21.279620576649904, train_acc = 0.9535398230088495\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 49, train_loss = 21.18383626267314, train_acc = 0.9537727061015371\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 50, train_loss = 21.084492459893227, train_acc = 0.9548206800186306\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 51, train_loss = 20.986886382102966, train_acc = 0.9541220307405682\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 52, train_loss = 20.88611176237464, train_acc = 0.9550535631113182\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 53, train_loss = 20.797009898349643, train_acc = 0.9549371215649743\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 54, train_loss = 20.71987253986299, train_acc = 0.9548206800186306\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 55, train_loss = 20.613893618807197, train_acc = 0.955519329296693\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 56, train_loss = 20.53028834052384, train_acc = 0.9554028877503493\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 57, train_loss = 20.45327883027494, train_acc = 0.9558686539357243\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 58, train_loss = 20.362420102581382, train_acc = 0.955985095482068\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 59, train_loss = 20.302029311656952, train_acc = 0.9556357708430367\n",
      "test Acc 0.9422718808193669:\n",
      "30th- epoch: 60, train_loss = 20.22409945167601, train_acc = 0.9563344201210993\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 61, train_loss = 20.149455258622766, train_acc = 0.9554028877503493\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 62, train_loss = 20.08798866532743, train_acc = 0.955519329296693\n",
      "test Acc 0.9418063314711359:\n",
      "30th- epoch: 63, train_loss = 20.008052537217736, train_acc = 0.9562179785747554\n",
      "test Acc 0.9422718808193669:\n",
      "30th- epoch: 64, train_loss = 19.945375038310885, train_acc = 0.955985095482068\n",
      "test Acc 0.9422718808193669:\n",
      "30th- epoch: 65, train_loss = 19.87957158870995, train_acc = 0.9561015370284117\n",
      "test Acc 0.9422718808193669:\n",
      "30th- epoch: 66, train_loss = 19.80692177079618, train_acc = 0.9565673032137867\n",
      "test Acc 0.9422718808193669:\n",
      "30th- epoch: 67, train_loss = 19.73659181781113, train_acc = 0.9563344201210993\n",
      "test Acc 0.9422718808193669:\n",
      "30th- epoch: 68, train_loss = 19.67402308434248, train_acc = 0.9569166278528178\n",
      "test Acc 0.9422718808193669:\n",
      "30th- epoch: 69, train_loss = 19.610950533300638, train_acc = 0.9569166278528178\n",
      "test Acc 0.9422718808193669:\n",
      "30th- epoch: 70, train_loss = 19.54981736280024, train_acc = 0.9572659524918491\n",
      "test Acc 0.9422718808193669:\n",
      "30th- epoch: 71, train_loss = 19.483675902709365, train_acc = 0.9571495109455054\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 72, train_loss = 19.43738767877221, train_acc = 0.9570330693991617\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 73, train_loss = 19.367339864373207, train_acc = 0.9571495109455054\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 74, train_loss = 19.31493556126952, train_acc = 0.9572659524918491\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 75, train_loss = 19.258238093927503, train_acc = 0.9572659524918491\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 76, train_loss = 19.203346190974116, train_acc = 0.9576152771308803\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 77, train_loss = 19.144721165299416, train_acc = 0.9579646017699115\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 78, train_loss = 19.09626940637827, train_acc = 0.9580810433162552\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 79, train_loss = 19.035796532407403, train_acc = 0.9577317186772241\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 80, train_loss = 18.978404821828008, train_acc = 0.9579646017699115\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 81, train_loss = 18.93323527276516, train_acc = 0.9581974848625989\n",
      "test Acc 0.9432029795158287:\n",
      "30th- epoch: 82, train_loss = 18.885465197265148, train_acc = 0.9583139264089428\n",
      "test Acc 0.9436685288640596:\n",
      "30th- epoch: 83, train_loss = 18.835188364610076, train_acc = 0.9581974848625989\n",
      "test Acc 0.9436685288640596:\n",
      "30th- epoch: 84, train_loss = 18.7767471075058, train_acc = 0.9585468095016302\n",
      "test Acc 0.9436685288640596:\n",
      "30th- epoch: 85, train_loss = 18.72792363166809, train_acc = 0.9587796925943176\n",
      "test Acc 0.9436685288640596:\n",
      "30th- epoch: 86, train_loss = 18.69382061250508, train_acc = 0.9585468095016302\n",
      "test Acc 0.9436685288640596:\n",
      "30th- epoch: 87, train_loss = 18.645990105345845, train_acc = 0.9590125756870052\n",
      "test Acc 0.9436685288640596:\n",
      "30th- epoch: 88, train_loss = 18.604018626734614, train_acc = 0.9591290172333489\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 89, train_loss = 18.563608415424824, train_acc = 0.9592454587796926\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 90, train_loss = 18.50659424997866, train_acc = 0.9593619003260363\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 91, train_loss = 18.465576769784093, train_acc = 0.9598276665114113\n",
      "test Acc 0.9441340782122905:\n",
      "30th- epoch: 92, train_loss = 18.421563839539886, train_acc = 0.9598276665114113\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 93, train_loss = 18.377335833385587, train_acc = 0.9601769911504425\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 94, train_loss = 18.34933276474476, train_acc = 0.9601769911504425\n",
      "test Acc 0.9441340782122905:\n",
      "30th- epoch: 95, train_loss = 18.309674425050616, train_acc = 0.9600605496040987\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 96, train_loss = 18.27900000847876, train_acc = 0.959944108057755\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 97, train_loss = 18.235580863431096, train_acc = 0.96040987424313\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 98, train_loss = 18.188929503783584, train_acc = 0.9601769911504425\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 99, train_loss = 18.15192875266075, train_acc = 0.9600605496040987\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 100, train_loss = 18.11371142230928, train_acc = 0.9607591988821611\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 101, train_loss = 18.0756611302495, train_acc = 0.96040987424313\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 102, train_loss = 18.055147111415863, train_acc = 0.9606427573358174\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 103, train_loss = 18.004526747390628, train_acc = 0.9607591988821611\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 104, train_loss = 17.968758039176464, train_acc = 0.9611085235211924\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 105, train_loss = 17.943573309108615, train_acc = 0.9609920819748486\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 106, train_loss = 17.897669011726975, train_acc = 0.9613414066138798\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 107, train_loss = 17.86465673148632, train_acc = 0.9611085235211924\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 108, train_loss = 17.838107960298657, train_acc = 0.9619236143455985\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 109, train_loss = 17.80547950230539, train_acc = 0.9612249650675361\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 110, train_loss = 17.77504980005324, train_acc = 0.9615742897065673\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 111, train_loss = 17.729096204042435, train_acc = 0.9619236143455985\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 112, train_loss = 17.70413630641997, train_acc = 0.961690731252911\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 113, train_loss = 17.666578114032745, train_acc = 0.962156497438286\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 114, train_loss = 17.63588990457356, train_acc = 0.9618071727992548\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 115, train_loss = 17.605605244636536, train_acc = 0.962156497438286\n",
      "test Acc 0.9445996275605214:\n",
      "30th- epoch: 116, train_loss = 17.580272486433387, train_acc = 0.9619236143455985\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 117, train_loss = 17.555427556857467, train_acc = 0.962156497438286\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 118, train_loss = 17.515600740909576, train_acc = 0.9625058220773172\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 119, train_loss = 17.489477476105094, train_acc = 0.962156497438286\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 120, train_loss = 17.475493049249053, train_acc = 0.9625058220773172\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 121, train_loss = 17.436827233061194, train_acc = 0.9626222636236609\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 122, train_loss = 17.3994236048311, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 123, train_loss = 17.382133670151234, train_acc = 0.9622729389846297\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 124, train_loss = 17.359453504905105, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 125, train_loss = 17.32350317388773, train_acc = 0.9627387051700047\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 126, train_loss = 17.29383404739201, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 127, train_loss = 17.271093415096402, train_acc = 0.962156497438286\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 128, train_loss = 17.242627492174506, train_acc = 0.9627387051700047\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 129, train_loss = 17.215901033952832, train_acc = 0.9628551467163484\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 130, train_loss = 17.186995297670364, train_acc = 0.9625058220773172\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 131, train_loss = 17.16292922757566, train_acc = 0.9628551467163484\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 132, train_loss = 17.143477357923985, train_acc = 0.9629715882626921\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 133, train_loss = 17.119789123535156, train_acc = 0.9628551467163484\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 134, train_loss = 17.091762909665704, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 135, train_loss = 17.063083035871387, train_acc = 0.9632044713553796\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 136, train_loss = 17.05792761594057, train_acc = 0.9635537959944108\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 137, train_loss = 17.013622211292386, train_acc = 0.9634373544480671\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 138, train_loss = 16.99521387927234, train_acc = 0.9634373544480671\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 139, train_loss = 16.97240909934044, train_acc = 0.9636702375407545\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 140, train_loss = 16.95594129525125, train_acc = 0.9637866790870983\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 141, train_loss = 16.924677789211273, train_acc = 0.9637866790870983\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 142, train_loss = 16.901795089244843, train_acc = 0.9640195621797858\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 143, train_loss = 16.880481192842126, train_acc = 0.9637866790870983\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 144, train_loss = 16.860965305939317, train_acc = 0.9636702375407545\n",
      "test Acc 0.9455307262569832:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 145, train_loss = 16.83628506027162, train_acc = 0.9640195621797858\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 146, train_loss = 16.820240246132016, train_acc = 0.9641360037261295\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 147, train_loss = 16.79452502168715, train_acc = 0.9644853283651607\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 148, train_loss = 16.776116451248527, train_acc = 0.9643688868188169\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 149, train_loss = 16.76062543131411, train_acc = 0.9646017699115044\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 150, train_loss = 16.744512287899852, train_acc = 0.9646017699115044\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 151, train_loss = 16.726976001635194, train_acc = 0.9647182114578482\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 152, train_loss = 16.70060585439205, train_acc = 0.9647182114578482\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 153, train_loss = 16.676826238632202, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 154, train_loss = 16.650235688313842, train_acc = 0.9648346530041919\n",
      "test Acc 0.9455307262569832:\n",
      "30th- epoch: 155, train_loss = 16.622511932626367, train_acc = 0.9651839776432231\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 156, train_loss = 16.617635145783424, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 157, train_loss = 16.59456823207438, train_acc = 0.9650675360968793\n",
      "test Acc 0.9459962756052142:\n",
      "30th- epoch: 158, train_loss = 16.58536428026855, train_acc = 0.9649510945505356\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 159, train_loss = 16.56606245972216, train_acc = 0.9648346530041919\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 160, train_loss = 16.55016639828682, train_acc = 0.9650675360968793\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 161, train_loss = 16.521136177703738, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 162, train_loss = 16.49779963493347, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 163, train_loss = 16.48285911232233, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 164, train_loss = 16.469606602564454, train_acc = 0.9653004191895669\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 165, train_loss = 16.443566041067243, train_acc = 0.9653004191895669\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 166, train_loss = 16.429151771590114, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 167, train_loss = 16.401312882080674, train_acc = 0.9655333022822543\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 168, train_loss = 16.389881493523717, train_acc = 0.9653004191895669\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 169, train_loss = 16.373750360682607, train_acc = 0.9653004191895669\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 170, train_loss = 16.36935125477612, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 171, train_loss = 16.340327320620418, train_acc = 0.9650675360968793\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 172, train_loss = 16.31992113031447, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 173, train_loss = 16.299741350114346, train_acc = 0.9653004191895669\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 174, train_loss = 16.2767172139138, train_acc = 0.9651839776432231\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 175, train_loss = 16.27756980061531, train_acc = 0.9650675360968793\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 176, train_loss = 16.2533390391618, train_acc = 0.9653004191895669\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 177, train_loss = 16.235308391042054, train_acc = 0.9653004191895669\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 178, train_loss = 16.22088804282248, train_acc = 0.9654168607359106\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 179, train_loss = 16.201775601133704, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 180, train_loss = 16.180015748366714, train_acc = 0.9654168607359106\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 181, train_loss = 16.165845887735486, train_acc = 0.9653004191895669\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 182, train_loss = 16.147600019350648, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 183, train_loss = 16.130522603169084, train_acc = 0.9654168607359106\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 184, train_loss = 16.11738469172269, train_acc = 0.965649743828598\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 185, train_loss = 16.097492940723896, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 186, train_loss = 16.090095221996307, train_acc = 0.9655333022822543\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 187, train_loss = 16.07383876852691, train_acc = 0.965649743828598\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 188, train_loss = 16.058374410495162, train_acc = 0.965649743828598\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 189, train_loss = 16.0429178327322, train_acc = 0.965649743828598\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 190, train_loss = 16.019337649457157, train_acc = 0.965649743828598\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 191, train_loss = 16.007323645055294, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 192, train_loss = 15.993272200226784, train_acc = 0.965649743828598\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 193, train_loss = 15.981193900108337, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 194, train_loss = 15.961213973350823, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 195, train_loss = 15.956100868992507, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 196, train_loss = 15.936203780584037, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 197, train_loss = 15.921611562371254, train_acc = 0.965649743828598\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 198, train_loss = 15.90563955437392, train_acc = 0.9657661853749417\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 199, train_loss = 15.898098009638488, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 200, train_loss = 15.881050932221115, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 201, train_loss = 15.859368897974491, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 202, train_loss = 15.847761705517769, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 203, train_loss = 15.839957475662231, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 204, train_loss = 15.829397452063859, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 205, train_loss = 15.812839520163834, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 206, train_loss = 15.790535469539464, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 207, train_loss = 15.775377854704857, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 208, train_loss = 15.77458231896162, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 209, train_loss = 15.755037563852966, train_acc = 0.9658826269212856\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 210, train_loss = 15.73808515816927, train_acc = 0.9659990684676293\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 211, train_loss = 15.729361484758556, train_acc = 0.9662319515603167\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 212, train_loss = 15.718282681889832, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 213, train_loss = 15.709075895138085, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 214, train_loss = 15.691978958435357, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 215, train_loss = 15.681921002455056, train_acc = 0.9658826269212856\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 216, train_loss = 15.666124448180199, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 217, train_loss = 15.654791315086186, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 218, train_loss = 15.648196223191917, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 219, train_loss = 15.626450437121093, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 220, train_loss = 15.622268217615783, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 221, train_loss = 15.60022259503603, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 222, train_loss = 15.594925005920231, train_acc = 0.9658826269212856\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 223, train_loss = 15.585009050555527, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 224, train_loss = 15.574850532226264, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 225, train_loss = 15.559604200534523, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 226, train_loss = 15.541968603618443, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 227, train_loss = 15.533811983652413, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 228, train_loss = 15.522635680623353, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 229, train_loss = 15.51540594547987, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 230, train_loss = 15.505266758613288, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 231, train_loss = 15.488992515020072, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 232, train_loss = 15.477641982026398, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 233, train_loss = 15.468269417993724, train_acc = 0.966115510013973\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 234, train_loss = 15.459960974752903, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 235, train_loss = 15.449604272842407, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 236, train_loss = 15.437909643165767, train_acc = 0.9659990684676293\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 237, train_loss = 15.422446933574975, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 238, train_loss = 15.416251711547375, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 239, train_loss = 15.405183836817741, train_acc = 0.9659990684676293\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 240, train_loss = 15.389648701064289, train_acc = 0.966115510013973\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 241, train_loss = 15.384545343928039, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 242, train_loss = 15.38406531792134, train_acc = 0.9663483931066604\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 243, train_loss = 15.360378238372505, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 244, train_loss = 15.350152348168194, train_acc = 0.966115510013973\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 245, train_loss = 15.337536702863872, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 246, train_loss = 15.32342567294836, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 247, train_loss = 15.322983796708286, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 248, train_loss = 15.307523312978446, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 249, train_loss = 15.297430480830371, train_acc = 0.966581276199348\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 250, train_loss = 15.293660141527653, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 251, train_loss = 15.28149966429919, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 252, train_loss = 15.266415948979557, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 253, train_loss = 15.260936471633613, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 254, train_loss = 15.245438640005887, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 255, train_loss = 15.237618531100452, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 256, train_loss = 15.224783092737198, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 257, train_loss = 15.2173535451293, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 258, train_loss = 15.205044115893543, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 259, train_loss = 15.198439590632915, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 260, train_loss = 15.189168363809586, train_acc = 0.9662319515603167\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 261, train_loss = 15.17882448900491, train_acc = 0.9663483931066604\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 262, train_loss = 15.170110608451068, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 263, train_loss = 15.159853771328926, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 264, train_loss = 15.149917962960899, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 265, train_loss = 15.13875852059573, train_acc = 0.9663483931066604\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 266, train_loss = 15.12171911727637, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 267, train_loss = 15.123796460218728, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 268, train_loss = 15.11135992128402, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 269, train_loss = 15.104941427707672, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 270, train_loss = 15.100791995413601, train_acc = 0.9664648346530041\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 271, train_loss = 15.085592600516975, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 272, train_loss = 15.073390510864556, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 273, train_loss = 15.066827848553658, train_acc = 0.9664648346530041\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 274, train_loss = 15.05311281979084, train_acc = 0.966581276199348\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 275, train_loss = 15.051864199340343, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 276, train_loss = 15.035139332525432, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 277, train_loss = 15.02537575084716, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 278, train_loss = 15.018811978399754, train_acc = 0.9668141592920354\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 279, train_loss = 15.011844317428768, train_acc = 0.9668141592920354\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 280, train_loss = 15.001713980920613, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 281, train_loss = 14.993544508703053, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 282, train_loss = 14.98472164850682, train_acc = 0.966581276199348\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 283, train_loss = 14.976575627923012, train_acc = 0.9668141592920354\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 284, train_loss = 14.965586096048355, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 285, train_loss = 14.956102500669658, train_acc = 0.966581276199348\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 286, train_loss = 14.946929760277271, train_acc = 0.9668141592920354\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 287, train_loss = 14.939003969542682, train_acc = 0.9666977177456917\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 288, train_loss = 14.919269487261772, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 289, train_loss = 14.922068203799427, train_acc = 0.966581276199348\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 290, train_loss = 14.912782371044159, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 291, train_loss = 14.90652062278241, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 292, train_loss = 14.901743021793664, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 293, train_loss = 14.89049682021141, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 294, train_loss = 14.885660770349205, train_acc = 0.9668141592920354\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 295, train_loss = 14.87382484972477, train_acc = 0.9666977177456917\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 296, train_loss = 14.86893568187952, train_acc = 0.9668141592920354\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 297, train_loss = 14.85727196931839, train_acc = 0.9668141592920354\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 298, train_loss = 14.850390654988587, train_acc = 0.9669306008383791\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 299, train_loss = 14.842486071400344, train_acc = 0.9669306008383791\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 300, train_loss = 14.835646852850914, train_acc = 0.9669306008383791\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 301, train_loss = 14.826421312987804, train_acc = 0.9671634839310667\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 302, train_loss = 14.820965456776321, train_acc = 0.9669306008383791\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 303, train_loss = 14.810150700621307, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 304, train_loss = 14.795515161938965, train_acc = 0.9671634839310667\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 305, train_loss = 14.79599176067859, train_acc = 0.9670470423847228\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 306, train_loss = 14.785347978584468, train_acc = 0.9669306008383791\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 307, train_loss = 14.781546804122627, train_acc = 0.9669306008383791\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 308, train_loss = 14.77086050529033, train_acc = 0.9670470423847228\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 309, train_loss = 14.764560085721314, train_acc = 0.9672799254774104\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 310, train_loss = 14.758642288856208, train_acc = 0.9670470423847228\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 311, train_loss = 14.753943311981857, train_acc = 0.9670470423847228\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 312, train_loss = 14.742598344571888, train_acc = 0.9672799254774104\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 313, train_loss = 14.729606647975743, train_acc = 0.9671634839310667\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 314, train_loss = 14.728803369216621, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 315, train_loss = 14.718324343673885, train_acc = 0.9671634839310667\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 316, train_loss = 14.711844940669835, train_acc = 0.9671634839310667\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 317, train_loss = 14.708258810453117, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 318, train_loss = 14.691302533261478, train_acc = 0.9672799254774104\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 319, train_loss = 14.69007499795407, train_acc = 0.9672799254774104\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 320, train_loss = 14.68366738408804, train_acc = 0.9673963670237541\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 321, train_loss = 14.678086238913238, train_acc = 0.9673963670237541\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 322, train_loss = 14.671749499626458, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 323, train_loss = 14.663663345389068, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 324, train_loss = 14.65746887307614, train_acc = 0.9675128085700978\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 325, train_loss = 14.64534854888916, train_acc = 0.9677456916627852\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 326, train_loss = 14.643737807869911, train_acc = 0.9673963670237541\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 327, train_loss = 14.6316918162629, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 328, train_loss = 14.628388586454093, train_acc = 0.9677456916627852\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 329, train_loss = 14.624699458479881, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 330, train_loss = 14.611414328217506, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 331, train_loss = 14.611254207789898, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 332, train_loss = 14.60489700268954, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 333, train_loss = 14.588525891304016, train_acc = 0.9677456916627852\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 334, train_loss = 14.58934984356165, train_acc = 0.9679785747554728\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 335, train_loss = 14.580337409861386, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 336, train_loss = 14.575742202810943, train_acc = 0.9676292501164415\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 337, train_loss = 14.567175768315792, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 338, train_loss = 14.563707855530083, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 339, train_loss = 14.552020224742591, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 340, train_loss = 14.545064203441143, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 341, train_loss = 14.542238336987793, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 342, train_loss = 14.536092097871006, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 343, train_loss = 14.531344669871032, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 344, train_loss = 14.52195802796632, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 345, train_loss = 14.519417643547058, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 346, train_loss = 14.512854516506195, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 347, train_loss = 14.5012944964692, train_acc = 0.9677456916627852\n",
      "test Acc 0.9464618249534451:\n",
      "30th- epoch: 348, train_loss = 14.494817917235196, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 349, train_loss = 14.48370174318552, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 350, train_loss = 14.482471463270485, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 351, train_loss = 14.474565036594868, train_acc = 0.9677456916627852\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 352, train_loss = 14.473634511232376, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 353, train_loss = 14.463656890206039, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 354, train_loss = 14.458149281330407, train_acc = 0.9677456916627852\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 355, train_loss = 14.446686081588268, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 356, train_loss = 14.451244537718594, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 357, train_loss = 14.443598208017647, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 358, train_loss = 14.436618912033737, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 359, train_loss = 14.432045402936637, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 360, train_loss = 14.420457382686436, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 361, train_loss = 14.408234025351703, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 362, train_loss = 14.408596138469875, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 363, train_loss = 14.406010881066322, train_acc = 0.9678621332091291\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 364, train_loss = 14.396597032435238, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 365, train_loss = 14.39420937281102, train_acc = 0.9679785747554728\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 366, train_loss = 14.383663202635944, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 367, train_loss = 14.381966094486415, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 368, train_loss = 14.37581101525575, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 369, train_loss = 14.368921761400998, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 370, train_loss = 14.3671335875988, train_acc = 0.9682114578481602\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 371, train_loss = 14.357460317201912, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 372, train_loss = 14.35251435637474, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 373, train_loss = 14.343433233909309, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 374, train_loss = 14.341408424079418, train_acc = 0.9680950163018165\n",
      "test Acc 0.946927374301676:\n",
      "30th- epoch: 375, train_loss = 14.330465366132557, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 376, train_loss = 14.328848972916603, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 377, train_loss = 14.315110117197037, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 378, train_loss = 14.314989626407623, train_acc = 0.9680950163018165\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 379, train_loss = 14.306532554328442, train_acc = 0.9682114578481602\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 380, train_loss = 14.303191974759102, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 381, train_loss = 14.296566061675549, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 382, train_loss = 14.290664474479854, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 383, train_loss = 14.28392372559756, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 384, train_loss = 14.28742189425975, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 385, train_loss = 14.277653445489705, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 386, train_loss = 14.271197798661888, train_acc = 0.9680950163018165\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 387, train_loss = 14.263033199124038, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 388, train_loss = 14.26073332130909, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 389, train_loss = 14.257650285959244, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 390, train_loss = 14.251734912395477, train_acc = 0.9682114578481602\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 391, train_loss = 14.236573119647801, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 392, train_loss = 14.235126721672714, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 393, train_loss = 14.229560278356075, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 394, train_loss = 14.227100799791515, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 395, train_loss = 14.226176704280078, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 396, train_loss = 14.207971987314522, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 397, train_loss = 14.211923000402749, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 398, train_loss = 14.203298005275428, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 399, train_loss = 14.195737016387284, train_acc = 0.9683278993945039\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 400, train_loss = 14.200597208924592, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 401, train_loss = 14.19116737972945, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 402, train_loss = 14.186990375630558, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 403, train_loss = 14.176412145607173, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 404, train_loss = 14.1721271276474, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 405, train_loss = 14.167028878815472, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 406, train_loss = 14.158725204877555, train_acc = 0.9684443409408477\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 407, train_loss = 14.156520381569862, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 408, train_loss = 14.147531027905643, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 409, train_loss = 14.154730443842709, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 410, train_loss = 14.147952280938625, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 411, train_loss = 14.140185887925327, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 412, train_loss = 14.132910150103271, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 413, train_loss = 14.13612962514162, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 414, train_loss = 14.123878587968647, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 415, train_loss = 14.120962764136493, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 416, train_loss = 14.113197423517704, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 417, train_loss = 14.104949067346752, train_acc = 0.9685607824871915\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 418, train_loss = 14.100429341197014, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 419, train_loss = 14.094466510228813, train_acc = 0.9686772240335352\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 420, train_loss = 14.094913731329143, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 421, train_loss = 14.09278954565525, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 422, train_loss = 14.078853306360543, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 423, train_loss = 14.076375934295356, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 424, train_loss = 14.072538753040135, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 425, train_loss = 14.069540035910904, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 426, train_loss = 14.063841563649476, train_acc = 0.9687936655798789\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 427, train_loss = 14.062736208550632, train_acc = 0.9689101071262226\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 428, train_loss = 14.05251734238118, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 429, train_loss = 14.052878650836647, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 430, train_loss = 14.041137645952404, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 431, train_loss = 14.04342479724437, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 432, train_loss = 14.033131271600723, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 433, train_loss = 14.03084438573569, train_acc = 0.9690265486725663\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 434, train_loss = 14.028078746981919, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 435, train_loss = 14.020708575844765, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 436, train_loss = 14.009969885461032, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 437, train_loss = 14.008997765369713, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 438, train_loss = 14.008143057115376, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 439, train_loss = 14.007748673669994, train_acc = 0.9691429902189101\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 440, train_loss = 14.003500074148178, train_acc = 0.9692594317652539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 441, train_loss = 13.999066174030304, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 442, train_loss = 13.993437108583748, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 443, train_loss = 13.983579084277153, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 444, train_loss = 13.978036649525166, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 445, train_loss = 13.968836682848632, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 446, train_loss = 13.971171016804874, train_acc = 0.9692594317652539\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 447, train_loss = 13.965251259505749, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 448, train_loss = 13.96749276900664, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 449, train_loss = 13.956205812748522, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 450, train_loss = 13.948110076598823, train_acc = 0.9693758733115976\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 451, train_loss = 13.953063353896141, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 452, train_loss = 13.945255676750094, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 453, train_loss = 13.936112639959902, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 454, train_loss = 13.937938747461885, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 455, train_loss = 13.935719666536897, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 456, train_loss = 13.921134814620018, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 457, train_loss = 13.922353240195662, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 458, train_loss = 13.913735270500183, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 459, train_loss = 13.915894456207752, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 460, train_loss = 13.906555265188217, train_acc = 0.9693758733115976\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 461, train_loss = 13.904263084288687, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 462, train_loss = 13.899371149484068, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 463, train_loss = 13.894061008933932, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 464, train_loss = 13.888176048640162, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 465, train_loss = 13.89386466378346, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 466, train_loss = 13.88216088199988, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 467, train_loss = 13.875875303987414, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 468, train_loss = 13.87378822779283, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 469, train_loss = 13.877946868538857, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 470, train_loss = 13.867514006793499, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 471, train_loss = 13.863270848989487, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 472, train_loss = 13.864529080688953, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 473, train_loss = 13.854409769177437, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 474, train_loss = 13.852087711449713, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 475, train_loss = 13.847602494060993, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 476, train_loss = 13.844850982073694, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 477, train_loss = 13.832969014998525, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 478, train_loss = 13.836811219807714, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 479, train_loss = 13.8355274326168, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 480, train_loss = 13.829744823276997, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 481, train_loss = 13.824990508612245, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 482, train_loss = 13.81988387554884, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 483, train_loss = 13.818804701324552, train_acc = 0.9694923148579413\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 484, train_loss = 13.81257639080286, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 485, train_loss = 13.811935529112816, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 486, train_loss = 13.807061503175646, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 487, train_loss = 13.803781738039106, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 488, train_loss = 13.793746700044721, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 489, train_loss = 13.794972968753427, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 490, train_loss = 13.79486931860447, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 491, train_loss = 13.787056503351778, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 492, train_loss = 13.780185788869858, train_acc = 0.969608756404285\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 493, train_loss = 13.7739626490511, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 494, train_loss = 13.775717084761709, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 495, train_loss = 13.770730999764055, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 496, train_loss = 13.765216281171888, train_acc = 0.9697251979506288\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 497, train_loss = 13.762237610761076, train_acc = 0.9698416394969726\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 498, train_loss = 13.755862392485142, train_acc = 0.9698416394969726\n",
      "test Acc 0.9473929236499069:\n",
      "30th- epoch: 499, train_loss = 13.755847004707903, train_acc = 0.9697251979506288\n",
      "test Acc 0.9478584729981379:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 30/30 [4:31:35<00:00, 543.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4h 31min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    read_path = 'D:virus/image/1gram_768/'\n",
    "    \n",
    "    temp = [[],[]]\n",
    "    \n",
    "    Loader = D.File_loader()\n",
    "    data_a, label_a = Loader.read_files(read_path, interp = False)\n",
    "    \n",
    "    idx = np.argsort(label_a)\n",
    "    \n",
    "    sorted_data = data_a[idx].reshape(10736, -1)\n",
    "    sorted_label = sorted(label_a)\n",
    "        \n",
    "    BATCH_SIZE = 64\n",
    "    TOTAL = 30\n",
    "    EPOCH =500\n",
    "    NUM_CLASS = 9\n",
    "    LR = 0.0001\n",
    "    SEED = [s for s in range(TOTAL)]\n",
    "    Num_Nodes = 768\n",
    "    \n",
    "    CUDA_N = 'cuda:0'\n",
    "    \n",
    "    # creating data indices for spliting\n",
    "    full_dataset = CustomDataset(sorted_data, sorted_label)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # spliting\n",
    "    torch.manual_seed(10)\n",
    "    train_dataset, test_dataset = data.random_split(full_dataset, [train_size, test_size])\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    loss_total = []\n",
    "    acc_total = []\n",
    "    pred_total = []\n",
    "    true_total = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(TOTAL)):\n",
    "        \n",
    "        \n",
    "        device = torch.device(CUDA_N if torch.cuda.is_available() else 'cpu')\n",
    "        torch.manual_seed(SEED[i])\n",
    "        net = Mcslt(Num_Nodes, NUM_CLASS)\n",
    "        net.to(device)\n",
    "        print(net)\n",
    "        \n",
    "        softmax = nn.Softmax()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=LR, momentum = 0.1)\n",
    "        \n",
    "        loss_list = []\n",
    "        train_acc_list = []\n",
    "        test_acc_list = []\n",
    "        \n",
    "        pred_temp = []\n",
    "        true_temp = []\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            net.train()\n",
    "            running_loss = 0\n",
    "            total = train_size\n",
    "            correct = 0 \n",
    "            \n",
    "            for step, images_labels in enumerate(train_loader):\n",
    "                inputs, labels = images_labels\n",
    "                inputs, labels = inputs.type(torch.FloatTensor).to(device), labels.type(torch.LongTensor).to(device)\n",
    "                \n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, pred = torch.max(outputs, dim=1)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            train_acc = correct/total\n",
    "            loss_list.append(running_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "            print('{}th- epoch: {}, train_loss = {}, train_acc = {}'.format(i+1, epoch, running_loss, train_acc))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                correct = 0\n",
    "                total = test_size\n",
    "                pt, tt = [], []\n",
    "                \n",
    "                for step_t, images_labels_t in enumerate(test_loader):\n",
    "                    inputs_t, labels_t = images_labels_t\n",
    "                    inputs_t, labels_t = inputs_t.type(torch.FloatTensor).to(device), labels_t.type(torch.LongTensor).to(device)\n",
    "                    \n",
    "                    outputs_t = net(inputs_t)\n",
    "                    outputs_t = softmax(outputs_t)\n",
    "                    \n",
    "                    # test accuracy\n",
    "                    _, pred_t = torch.max(outputs_t, dim = 1)\n",
    "                    \n",
    "                    pt.append(pred_t)\n",
    "                    tt.append(labels_t)\n",
    "                    \n",
    "                    correct += (pred_t == labels_t).sum().item()\n",
    "                    \n",
    "                pred_temp.append(torch.cat(pt))\n",
    "                true_temp.append(torch.cat(tt))\n",
    "                \n",
    "                test_acc = correct/total\n",
    "                test_acc_list.append(test_acc)\n",
    "                \n",
    "                print('test Acc {}:'.format(test_acc))\n",
    "                \n",
    "        best_result_index = np.argmax(np.array(test_acc_list))\n",
    "        loss_total.append(loss_list[best_result_index])\n",
    "        acc_total.append(test_acc_list[best_result_index])\n",
    "        pred_total.append(pred_temp[best_result_index].tolist())\n",
    "        true_total.append(true_temp[best_result_index].tolist())\n",
    "        \n",
    "    file_name = 'res/Mcslt_1gram'\n",
    "    torch.save(net.state_dict(), file_name +'.pth')\n",
    "    \n",
    "    loss_DF = pd.DataFrame(loss_total)\n",
    "    loss_DF.to_csv(file_name+\" loss.csv\")\n",
    "    \n",
    "    acc_DF = pd.DataFrame(acc_total)\n",
    "    acc_DF.to_csv(file_name +\" acc.csv\")\n",
    "    \n",
    "    pred_DF = pd.DataFrame(pred_total)\n",
    "    pred_DF.to_csv(file_name +\" pred.csv\")\n",
    "    \n",
    "    true_DF = pd.DataFrame(true_total)\n",
    "    true_DF.to_csv(file_name +\" true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
