{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import utility.Data_loader as D\n",
    "from utility.Model import MCSP\n",
    "from utility.Custom import CustomDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "1th- epoch: 0, train_loss = 271.38937175273895, train_acc = 0.4503959012575687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DTools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.48324022346368717:\n",
      "1th- epoch: 1, train_loss = 207.47728526592255, train_acc = 0.4884722869119702\n",
      "test Acc 0.49813780260707635:\n",
      "1th- epoch: 2, train_loss = 165.97566998004913, train_acc = 0.5207265952491849\n",
      "test Acc 0.6089385474860335:\n",
      "1th- epoch: 3, train_loss = 143.82368010282516, train_acc = 0.6398462971588262\n",
      "test Acc 0.6848230912476723:\n",
      "1th- epoch: 4, train_loss = 126.21329790353775, train_acc = 0.7073823940381928\n",
      "test Acc 0.7472067039106145:\n",
      "1th- epoch: 5, train_loss = 110.92769342660904, train_acc = 0.7525617140195622\n",
      "test Acc 0.7676908752327747:\n",
      "1th- epoch: 6, train_loss = 97.63866636157036, train_acc = 0.7727061015370285\n",
      "test Acc 0.7886405959031657:\n",
      "1th- epoch: 7, train_loss = 86.2754915356636, train_acc = 0.8022822543083372\n",
      "test Acc 0.819366852886406:\n",
      "1th- epoch: 8, train_loss = 76.49726039171219, train_acc = 0.832324173265021\n",
      "test Acc 0.8389199255121043:\n",
      "1th- epoch: 9, train_loss = 67.9921723306179, train_acc = 0.8553795994410806\n",
      "test Acc 0.8696461824953445:\n",
      "1th- epoch: 10, train_loss = 60.655634850263596, train_acc = 0.8841406613879832\n",
      "test Acc 0.8938547486033519:\n",
      "1th- epoch: 11, train_loss = 54.47432076931, train_acc = 0.9059152305542617\n",
      "test Acc 0.9110800744878957:\n",
      "1th- epoch: 12, train_loss = 49.35263608396053, train_acc = 0.9200046576618538\n",
      "test Acc 0.9199255121042831:\n",
      "1th- epoch: 13, train_loss = 45.13451072573662, train_acc = 0.9281555659059152\n",
      "test Acc 0.9245810055865922:\n",
      "1th- epoch: 14, train_loss = 41.647420570254326, train_acc = 0.9314159292035398\n",
      "test Acc 0.9269087523277467:\n",
      "1th- epoch: 15, train_loss = 38.74468772113323, train_acc = 0.9356078248719143\n",
      "test Acc 0.930633147113594:\n",
      "1th- epoch: 16, train_loss = 36.30449849367142, train_acc = 0.9392175128085701\n",
      "test Acc 0.9357541899441341:\n",
      "1th- epoch: 17, train_loss = 34.227534614503384, train_acc = 0.9422449930135072\n",
      "test Acc 0.9376163873370578:\n",
      "1th- epoch: 18, train_loss = 32.440085120499134, train_acc = 0.9450395901257569\n",
      "test Acc 0.9418063314711359:\n",
      "1th- epoch: 19, train_loss = 30.8851185888052, train_acc = 0.9474848625989754\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 20, train_loss = 29.520424850285053, train_acc = 0.9492314857941313\n",
      "test Acc 0.9459962756052142:\n",
      "1th- epoch: 21, train_loss = 28.318116396665573, train_acc = 0.9512109920819748\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 22, train_loss = 27.24940800666809, train_acc = 0.9526082906380997\n",
      "test Acc 0.9492551210428305:\n",
      "1th- epoch: 23, train_loss = 26.288981653749943, train_acc = 0.9538891476478808\n",
      "test Acc 0.9497206703910615:\n",
      "1th- epoch: 24, train_loss = 25.41829989850521, train_acc = 0.9554028877503493\n",
      "test Acc 0.9515828677839852:\n",
      "1th- epoch: 25, train_loss = 24.622934214770794, train_acc = 0.9561015370284117\n",
      "test Acc 0.952048417132216:\n",
      "1th- epoch: 26, train_loss = 23.89183770865202, train_acc = 0.9569166278528178\n",
      "test Acc 0.952513966480447:\n",
      "1th- epoch: 27, train_loss = 23.21959186717868, train_acc = 0.9577317186772241\n",
      "test Acc 0.9534450651769087:\n",
      "1th- epoch: 28, train_loss = 22.596767023205757, train_acc = 0.9586632510479739\n",
      "test Acc 0.9539106145251397:\n",
      "1th- epoch: 29, train_loss = 22.015388779342175, train_acc = 0.9601769911504425\n",
      "test Acc 0.9543761638733705:\n",
      "1th- epoch: 30, train_loss = 21.47073931246996, train_acc = 0.9609920819748486\n",
      "test Acc 0.9548417132216015:\n",
      "1th- epoch: 31, train_loss = 20.95849896967411, train_acc = 0.9622729389846297\n",
      "test Acc 0.9557728119180633:\n",
      "1th- epoch: 32, train_loss = 20.475488547235727, train_acc = 0.9627387051700047\n",
      "test Acc 0.9562383612662942:\n",
      "1th- epoch: 33, train_loss = 20.018247306346893, train_acc = 0.9633209129017233\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 34, train_loss = 19.58418022096157, train_acc = 0.963903120633442\n",
      "test Acc 0.9581005586592178:\n",
      "1th- epoch: 35, train_loss = 19.17110724002123, train_acc = 0.9642524452724732\n",
      "test Acc 0.9581005586592178:\n",
      "1th- epoch: 36, train_loss = 18.77678656578064, train_acc = 0.9644853283651607\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 37, train_loss = 18.4001377671957, train_acc = 0.9651839776432231\n",
      "test Acc 0.9599627560521415:\n",
      "1th- epoch: 38, train_loss = 18.039785005152225, train_acc = 0.9663483931066604\n",
      "test Acc 0.9604283054003724:\n",
      "1th- epoch: 39, train_loss = 17.69400465860963, train_acc = 0.966581276199348\n",
      "test Acc 0.9608938547486033:\n",
      "1th- epoch: 40, train_loss = 17.36171079799533, train_acc = 0.9668141592920354\n",
      "test Acc 0.9613594040968343:\n",
      "1th- epoch: 41, train_loss = 17.042418118566275, train_acc = 0.9672799254774104\n",
      "test Acc 0.9622905027932961:\n",
      "1th- epoch: 42, train_loss = 16.73606989532709, train_acc = 0.9676292501164415\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 43, train_loss = 16.441340655088425, train_acc = 0.9676292501164415\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 44, train_loss = 16.15755147114396, train_acc = 0.9682114578481602\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 45, train_loss = 15.884021308273077, train_acc = 0.9685607824871915\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 46, train_loss = 15.62016698345542, train_acc = 0.9694923148579413\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 47, train_loss = 15.365415874868631, train_acc = 0.97007452258966\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 48, train_loss = 15.11919903382659, train_acc = 0.9707731718677224\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 49, train_loss = 14.88107892498374, train_acc = 0.9712389380530974\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 50, train_loss = 14.650857906788588, train_acc = 0.9715882626921285\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 51, train_loss = 14.427879434078932, train_acc = 0.9720540288775035\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 52, train_loss = 14.211907912045717, train_acc = 0.9724033535165347\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 53, train_loss = 14.002588886767626, train_acc = 0.9727526781555659\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 54, train_loss = 13.79945469647646, train_acc = 0.9732184443409408\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 55, train_loss = 13.602259881794453, train_acc = 0.9735677689799721\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 56, train_loss = 13.410680815577507, train_acc = 0.974033535165347\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 57, train_loss = 13.22432448528707, train_acc = 0.9741499767116907\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 58, train_loss = 13.043205481022596, train_acc = 0.9743828598043782\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 59, train_loss = 12.866945980116725, train_acc = 0.9743828598043782\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 60, train_loss = 12.69517669826746, train_acc = 0.9744993013507219\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 61, train_loss = 12.527849230915308, train_acc = 0.9749650675360969\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 62, train_loss = 12.36484693735838, train_acc = 0.9750815090824406\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 63, train_loss = 12.205870416015387, train_acc = 0.9751979506287843\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 64, train_loss = 12.050956673920155, train_acc = 0.9756637168141593\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 65, train_loss = 11.899586111307144, train_acc = 0.9761294829995343\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 66, train_loss = 11.751604668796062, train_acc = 0.9764788076385654\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 67, train_loss = 11.607080839574337, train_acc = 0.9770610153702841\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 68, train_loss = 11.465891972184181, train_acc = 0.9774103400093154\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 69, train_loss = 11.328190956264734, train_acc = 0.9775267815556591\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 70, train_loss = 11.193608777597547, train_acc = 0.9776432231020028\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 71, train_loss = 11.061946803703904, train_acc = 0.9778761061946902\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 72, train_loss = 10.933181639760733, train_acc = 0.977992547741034\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 73, train_loss = 10.807266080752015, train_acc = 0.9781089892873778\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 74, train_loss = 10.684079648926854, train_acc = 0.9781089892873778\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 75, train_loss = 10.563381545245647, train_acc = 0.9782254308337215\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 76, train_loss = 10.44507384300232, train_acc = 0.9782254308337215\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 77, train_loss = 10.329077776521444, train_acc = 0.9784583139264089\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 78, train_loss = 10.215207625180483, train_acc = 0.9784583139264089\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 79, train_loss = 10.103763964027166, train_acc = 0.9788076385654402\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 80, train_loss = 9.994532998651266, train_acc = 0.9790405216581276\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 81, train_loss = 9.887148067355156, train_acc = 0.9790405216581276\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 82, train_loss = 9.781848464161158, train_acc = 0.9790405216581276\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 83, train_loss = 9.678256295621395, train_acc = 0.9792734047508151\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 84, train_loss = 9.576640598475933, train_acc = 0.9793898462971589\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 85, train_loss = 9.476798381656408, train_acc = 0.9793898462971589\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 86, train_loss = 9.378483928740025, train_acc = 0.9795062878435026\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 87, train_loss = 9.281980238854885, train_acc = 0.97973917093619\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 88, train_loss = 9.186773039400578, train_acc = 0.9798556124825337\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 89, train_loss = 9.093187918886542, train_acc = 0.9803213786679087\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 90, train_loss = 9.000979429110885, train_acc = 0.9803213786679087\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 91, train_loss = 8.910219667479396, train_acc = 0.9805542617605962\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 92, train_loss = 8.820673037320375, train_acc = 0.98067070330694\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 93, train_loss = 8.732630301266909, train_acc = 0.9809035863996274\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 94, train_loss = 8.645828088745475, train_acc = 0.9811364694923148\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 95, train_loss = 8.56043973006308, train_acc = 0.9816022356776898\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 96, train_loss = 8.476415179669857, train_acc = 0.9818351187703773\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 97, train_loss = 8.39343011379242, train_acc = 0.9824173265020959\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 98, train_loss = 8.311964262276888, train_acc = 0.9825337680484397\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 99, train_loss = 8.231543734669685, train_acc = 0.9828830926874709\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 100, train_loss = 8.152430158108473, train_acc = 0.9831159757801584\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 101, train_loss = 8.074239240959287, train_acc = 0.9833488588728458\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 102, train_loss = 7.997314274311066, train_acc = 0.9834653004191896\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 103, train_loss = 7.921337781473994, train_acc = 0.9838146250582208\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 104, train_loss = 7.846586495637894, train_acc = 0.9842803912435957\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 105, train_loss = 7.772704308852553, train_acc = 0.9842803912435957\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 106, train_loss = 7.699769148603082, train_acc = 0.9842803912435957\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 107, train_loss = 7.628171488642693, train_acc = 0.9845132743362832\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 108, train_loss = 7.557292941957712, train_acc = 0.9846297158826269\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 109, train_loss = 7.487539269030094, train_acc = 0.9846297158826269\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 110, train_loss = 7.4185761641711, train_acc = 0.9847461574289706\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 111, train_loss = 7.350746830925345, train_acc = 0.9848625989753144\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 112, train_loss = 7.283705977723002, train_acc = 0.9849790405216581\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 113, train_loss = 7.2175404112786055, train_acc = 0.9850954820680019\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 114, train_loss = 7.152260826900601, train_acc = 0.9850954820680019\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 115, train_loss = 7.087781090289354, train_acc = 0.9850954820680019\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 116, train_loss = 7.02417198009789, train_acc = 0.9852119236143456\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 117, train_loss = 6.961210526525974, train_acc = 0.985444806707033\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 118, train_loss = 6.89930472150445, train_acc = 0.985444806707033\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 119, train_loss = 6.837943095713854, train_acc = 0.9855612482533768\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 120, train_loss = 6.777527337893844, train_acc = 0.9861434559850955\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 121, train_loss = 6.717809094116092, train_acc = 0.9862598975314392\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 122, train_loss = 6.658826718106866, train_acc = 0.9862598975314392\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 123, train_loss = 6.600696364417672, train_acc = 0.986376339077783\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 124, train_loss = 6.54322374612093, train_acc = 0.9864927806241267\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 125, train_loss = 6.486608248203993, train_acc = 0.9866092221704704\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 126, train_loss = 6.430644826963544, train_acc = 0.9867256637168141\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 127, train_loss = 6.375469485297799, train_acc = 0.9867256637168141\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 128, train_loss = 6.3208855874836445, train_acc = 0.9867256637168141\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 129, train_loss = 6.266583126038313, train_acc = 0.9868421052631579\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 130, train_loss = 6.212933477014303, train_acc = 0.9870749883558454\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 131, train_loss = 6.1605358980596066, train_acc = 0.9873078714485328\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 132, train_loss = 6.108862031251192, train_acc = 0.9875407545412203\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 133, train_loss = 6.057893205434084, train_acc = 0.9877736376339078\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 134, train_loss = 6.007547711953521, train_acc = 0.9882394038192828\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 135, train_loss = 5.957949070259929, train_acc = 0.9884722869119702\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 136, train_loss = 5.908857690170407, train_acc = 0.9884722869119702\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 137, train_loss = 5.860641248524189, train_acc = 0.9887051700046576\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 138, train_loss = 5.812992045655847, train_acc = 0.9887051700046576\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 139, train_loss = 5.765747334808111, train_acc = 0.9888216115510013\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 140, train_loss = 5.719344884157181, train_acc = 0.9889380530973452\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 141, train_loss = 5.673293167725205, train_acc = 0.9889380530973452\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 142, train_loss = 5.628013895824552, train_acc = 0.9890544946436889\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 143, train_loss = 5.583363976329565, train_acc = 0.9890544946436889\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 144, train_loss = 5.539255412295461, train_acc = 0.9891709361900326\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 145, train_loss = 5.495696039870381, train_acc = 0.98940381928272\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 146, train_loss = 5.452707953751087, train_acc = 0.98940381928272\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 147, train_loss = 5.410259246826172, train_acc = 0.98940381928272\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 148, train_loss = 5.36838480271399, train_acc = 0.9895202608290639\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 149, train_loss = 5.327092191204429, train_acc = 0.9895202608290639\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 150, train_loss = 5.286214472725987, train_acc = 0.9896367023754076\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 151, train_loss = 5.245995607227087, train_acc = 0.9897531439217513\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 152, train_loss = 5.206059105694294, train_acc = 0.9897531439217513\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 153, train_loss = 5.166612651199102, train_acc = 0.9897531439217513\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 154, train_loss = 5.127678159624338, train_acc = 0.989869585468095\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 155, train_loss = 5.088789800181985, train_acc = 0.989869585468095\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 156, train_loss = 5.050742065533996, train_acc = 0.9899860270144387\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 157, train_loss = 5.012923263013363, train_acc = 0.9899860270144387\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 158, train_loss = 4.975944234058261, train_acc = 0.9901024685607824\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 159, train_loss = 4.939508017152548, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 160, train_loss = 4.903196644037962, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 161, train_loss = 4.867817034013569, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 162, train_loss = 4.83265701495111, train_acc = 0.9902189101071263\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 163, train_loss = 4.798008837737143, train_acc = 0.99033535165347\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 164, train_loss = 4.763910666108131, train_acc = 0.9904517931998137\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 165, train_loss = 4.730108295567334, train_acc = 0.9905682347461574\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 166, train_loss = 4.696701827459037, train_acc = 0.9905682347461574\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 167, train_loss = 4.663830784149468, train_acc = 0.9906846762925011\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 168, train_loss = 4.631354029290378, train_acc = 0.990801117838845\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 169, train_loss = 4.599267274141312, train_acc = 0.9909175593851887\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 170, train_loss = 4.567468926310539, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 171, train_loss = 4.536162722855806, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 172, train_loss = 4.505318350158632, train_acc = 0.9911504424778761\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 173, train_loss = 4.474930169992149, train_acc = 0.9912668840242198\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 174, train_loss = 4.444811590947211, train_acc = 0.9912668840242198\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 175, train_loss = 4.415007044561207, train_acc = 0.9912668840242198\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 176, train_loss = 4.385796478949487, train_acc = 0.9912668840242198\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 177, train_loss = 4.356783236376941, train_acc = 0.9912668840242198\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 178, train_loss = 4.328063599765301, train_acc = 0.9912668840242198\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 179, train_loss = 4.299658335745335, train_acc = 0.9912668840242198\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 180, train_loss = 4.271768391132355, train_acc = 0.9914997671169073\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 181, train_loss = 4.244055169634521, train_acc = 0.9916162086632511\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 182, train_loss = 4.216752569191158, train_acc = 0.9916162086632511\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 183, train_loss = 4.189767267554998, train_acc = 0.9916162086632511\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 184, train_loss = 4.163127839565277, train_acc = 0.9917326502095948\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 185, train_loss = 4.1368069583550096, train_acc = 0.9917326502095948\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 186, train_loss = 4.110743474215269, train_acc = 0.9918490917559385\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 187, train_loss = 4.085076991468668, train_acc = 0.9919655333022822\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 188, train_loss = 4.059647806920111, train_acc = 0.9919655333022822\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 189, train_loss = 4.034541349858046, train_acc = 0.9919655333022822\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 190, train_loss = 4.009659702889621, train_acc = 0.9919655333022822\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 191, train_loss = 3.985137169249356, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 192, train_loss = 3.9608712503686547, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 193, train_loss = 3.936908859759569, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 194, train_loss = 3.9132234612479806, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 195, train_loss = 3.8898090505972505, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 196, train_loss = 3.8667151080444455, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 197, train_loss = 3.8437997298315167, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 198, train_loss = 3.8212249847128987, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 199, train_loss = 3.7989563113078475, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 200, train_loss = 3.776718913577497, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 201, train_loss = 3.754982233978808, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 202, train_loss = 3.733408804051578, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 203, train_loss = 3.712007095105946, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 204, train_loss = 3.690850518643856, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 205, train_loss = 3.670032694004476, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 206, train_loss = 3.64937165658921, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 207, train_loss = 3.628920268267393, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 208, train_loss = 3.6086937598884106, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 209, train_loss = 3.5887309201061726, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 210, train_loss = 3.568869241513312, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 211, train_loss = 3.5492430739104748, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 212, train_loss = 3.529883299022913, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 213, train_loss = 3.510674614459276, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 214, train_loss = 3.491676493547857, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 215, train_loss = 3.4728501504287124, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 216, train_loss = 3.45414627995342, train_acc = 0.9930135072193759\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 217, train_loss = 3.4358217320404947, train_acc = 0.9931299487657196\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 218, train_loss = 3.417571257799864, train_acc = 0.9931299487657196\n",
      "test Acc 0.9799813780260708:\n",
      "1th- epoch: 219, train_loss = 3.3995656692422926, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 220, train_loss = 3.381701776292175, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 221, train_loss = 3.364019172731787, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 222, train_loss = 3.346384194213897, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 223, train_loss = 3.3291335813701153, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 224, train_loss = 3.311924699228257, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 225, train_loss = 3.2948491224087775, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 226, train_loss = 3.2781000193208456, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 227, train_loss = 3.261292237788439, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 228, train_loss = 3.2449464802630246, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 229, train_loss = 3.228454432915896, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 230, train_loss = 3.2122891559265554, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 231, train_loss = 3.1962351971305907, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 232, train_loss = 3.1804092680104077, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 233, train_loss = 3.164584911894053, train_acc = 0.9935957149510946\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 234, train_loss = 3.149161222856492, train_acc = 0.9935957149510946\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 235, train_loss = 3.1336280121468008, train_acc = 0.9935957149510946\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 236, train_loss = 3.1182497702538967, train_acc = 0.9935957149510946\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 237, train_loss = 3.1033405233174562, train_acc = 0.9937121564974383\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 238, train_loss = 3.0882093091495335, train_acc = 0.9937121564974383\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 239, train_loss = 3.0733622666448355, train_acc = 0.9937121564974383\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 240, train_loss = 3.0585111025720835, train_acc = 0.993828598043782\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 241, train_loss = 3.044149732682854, train_acc = 0.993828598043782\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 242, train_loss = 3.02953022159636, train_acc = 0.993828598043782\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 243, train_loss = 3.015246464405209, train_acc = 0.993828598043782\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 244, train_loss = 3.0009358036331832, train_acc = 0.993828598043782\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 245, train_loss = 2.9871791643090546, train_acc = 0.993828598043782\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 246, train_loss = 2.9729570248164237, train_acc = 0.993828598043782\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 247, train_loss = 2.959244016557932, train_acc = 0.9939450395901258\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 248, train_loss = 2.9455896974541247, train_acc = 0.9939450395901258\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 249, train_loss = 2.9319670163094997, train_acc = 0.9940614811364695\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 250, train_loss = 2.91845761006698, train_acc = 0.9940614811364695\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 251, train_loss = 2.9052894129417837, train_acc = 0.9940614811364695\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 252, train_loss = 2.8920826739631593, train_acc = 0.9940614811364695\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 253, train_loss = 2.8789468868635595, train_acc = 0.9940614811364695\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 254, train_loss = 2.8658933169208467, train_acc = 0.9940614811364695\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 255, train_loss = 2.8531613699160516, train_acc = 0.9940614811364695\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 256, train_loss = 2.8404477201402187, train_acc = 0.9940614811364695\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 257, train_loss = 2.8277598307467997, train_acc = 0.9940614811364695\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 258, train_loss = 2.815217105206102, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 259, train_loss = 2.8027597032487392, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 260, train_loss = 2.790336831007153, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 261, train_loss = 2.7782436325214803, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 262, train_loss = 2.7659076005220413, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 263, train_loss = 2.7540071196854115, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 264, train_loss = 2.741947310511023, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 265, train_loss = 2.7303431355394423, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 266, train_loss = 2.718727824743837, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 267, train_loss = 2.707106154412031, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 268, train_loss = 2.6957442709244788, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 269, train_loss = 2.68448174232617, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 270, train_loss = 2.673139199614525, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 271, train_loss = 2.662169523537159, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 272, train_loss = 2.6511335596442223, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 273, train_loss = 2.6401945538818836, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 274, train_loss = 2.629386991262436, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 275, train_loss = 2.6187058626674116, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 276, train_loss = 2.6081737973727286, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 277, train_loss = 2.597612599376589, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 278, train_loss = 2.5871918997727334, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 279, train_loss = 2.5771117992699146, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 280, train_loss = 2.5667231692932546, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 281, train_loss = 2.556737349834293, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 282, train_loss = 2.5466970899142325, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 283, train_loss = 2.5367894172668457, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 284, train_loss = 2.527027314994484, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 285, train_loss = 2.5173960463143885, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 286, train_loss = 2.507650753017515, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 287, train_loss = 2.498426413629204, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 288, train_loss = 2.4887264943681657, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 289, train_loss = 2.4794811927713454, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 290, train_loss = 2.470290368888527, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 291, train_loss = 2.461069330573082, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 292, train_loss = 2.452164802700281, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 293, train_loss = 2.4430489712394774, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 294, train_loss = 2.4341645813547075, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 295, train_loss = 2.425600404618308, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 296, train_loss = 2.416620085714385, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 297, train_loss = 2.4082076486665756, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 298, train_loss = 2.399602497695014, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 299, train_loss = 2.3911248955409974, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 300, train_loss = 2.382803512038663, train_acc = 0.9947601304145319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 301, train_loss = 2.3745010558050126, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 302, train_loss = 2.3661543901544064, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 303, train_loss = 2.3581451836507767, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 304, train_loss = 2.3501630909740925, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 305, train_loss = 2.342170676914975, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 306, train_loss = 2.3341685496270657, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 307, train_loss = 2.3264602310955524, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 308, train_loss = 2.318677627714351, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 309, train_loss = 2.310980648966506, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 310, train_loss = 2.3033302079420537, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 311, train_loss = 2.2959784269332886, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 312, train_loss = 2.2884420417249203, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 313, train_loss = 2.281002872856334, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 314, train_loss = 2.2736699853558093, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 315, train_loss = 2.266373573569581, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 316, train_loss = 2.259341300697997, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 317, train_loss = 2.2522077311296016, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 318, train_loss = 2.2450703207869083, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 319, train_loss = 2.238108354387805, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 320, train_loss = 2.231248064665124, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 321, train_loss = 2.2243091363925487, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 322, train_loss = 2.2175097689032555, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 323, train_loss = 2.2109453689772636, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 324, train_loss = 2.204025889514014, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 325, train_loss = 2.1974885154049844, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 326, train_loss = 2.190888774814084, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 327, train_loss = 2.184560362249613, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 328, train_loss = 2.178086453350261, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 329, train_loss = 2.1716774243395776, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 330, train_loss = 2.165401804028079, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 331, train_loss = 2.159236387582496, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 332, train_loss = 2.1529403887689114, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 333, train_loss = 2.146823617396876, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 334, train_loss = 2.140840869396925, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 335, train_loss = 2.134712066501379, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 336, train_loss = 2.128777789650485, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 337, train_loss = 2.122781214537099, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 338, train_loss = 2.116860055597499, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 339, train_loss = 2.1110893313307315, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 340, train_loss = 2.105265485821292, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 341, train_loss = 2.0996582594234496, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 342, train_loss = 2.0939092710614204, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 343, train_loss = 2.0884002037346363, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 344, train_loss = 2.0827262960374355, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 345, train_loss = 2.077286646934226, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 346, train_loss = 2.0717208471614867, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 347, train_loss = 2.0663175161462277, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 348, train_loss = 2.0610909275710583, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 349, train_loss = 2.0556043598335236, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 350, train_loss = 2.050319292815402, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 351, train_loss = 2.0451108317356557, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 352, train_loss = 2.0399538341443986, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 353, train_loss = 2.034788466989994, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 354, train_loss = 2.0297177981119603, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 355, train_loss = 2.024599938420579, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 356, train_loss = 2.0196698270738125, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 357, train_loss = 2.0146033342462033, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "1th- epoch: 358, train_loss = 2.009707247139886, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 359, train_loss = 2.0049490320961922, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 360, train_loss = 2.0000291515607387, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 361, train_loss = 1.9952696103136986, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 362, train_loss = 1.990373906912282, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 363, train_loss = 1.9857630655169487, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 364, train_loss = 1.9810435462277383, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 365, train_loss = 1.9763027604203671, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 366, train_loss = 1.971702725859359, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 367, train_loss = 1.9671875040512532, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 368, train_loss = 1.9625847835559398, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 369, train_loss = 1.958103732438758, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 370, train_loss = 1.9536173057276756, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 371, train_loss = 1.949240818619728, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 372, train_loss = 1.94476252165623, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 373, train_loss = 1.940562390955165, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 374, train_loss = 1.9360623669344932, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 375, train_loss = 1.931832604110241, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 376, train_loss = 1.927667363313958, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 377, train_loss = 1.923361487686634, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 378, train_loss = 1.9192074399907142, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 379, train_loss = 1.9150323010981083, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 380, train_loss = 1.9110031550517306, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 381, train_loss = 1.9069669743767008, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 382, train_loss = 1.9028899582335725, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 383, train_loss = 1.898888073861599, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 384, train_loss = 1.8949318727245554, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 385, train_loss = 1.8908790623536333, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 386, train_loss = 1.8871252685785294, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 387, train_loss = 1.8830502815544605, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 388, train_loss = 1.8792731737485155, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 389, train_loss = 1.875545690418221, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 390, train_loss = 1.8716642720391974, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 391, train_loss = 1.8678236653795466, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 392, train_loss = 1.8642588332295418, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 393, train_loss = 1.860486265271902, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 394, train_loss = 1.8568258149316534, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 395, train_loss = 1.853097077459097, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 396, train_loss = 1.8496477492153645, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 397, train_loss = 1.8458796726772562, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 398, train_loss = 1.8424565866589546, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 399, train_loss = 1.8388619931647554, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 400, train_loss = 1.8352805165341124, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 401, train_loss = 1.8319363495102152, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 402, train_loss = 1.8284168591490015, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 403, train_loss = 1.824930939823389, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 404, train_loss = 1.8215393895516172, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 405, train_loss = 1.8181082470109686, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 406, train_loss = 1.8148559977998957, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 407, train_loss = 1.8114944696426392, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 408, train_loss = 1.808055080473423, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 409, train_loss = 1.8047580743441358, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 410, train_loss = 1.8014951957156882, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 411, train_loss = 1.7983459135284647, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 412, train_loss = 1.7951490171253681, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 413, train_loss = 1.792038088082336, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 414, train_loss = 1.788909042836167, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 415, train_loss = 1.78567446640227, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 416, train_loss = 1.7826907137641683, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 417, train_loss = 1.7796392577001825, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 418, train_loss = 1.7762852683663368, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 419, train_loss = 1.7733843611786142, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 420, train_loss = 1.7704544514417648, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 421, train_loss = 1.7673703444888815, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 422, train_loss = 1.764391033560969, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 423, train_loss = 1.761437501758337, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 424, train_loss = 1.7585046725580469, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 425, train_loss = 1.755514457821846, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 426, train_loss = 1.7526639761636034, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 427, train_loss = 1.749821106554009, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 428, train_loss = 1.7470763077726588, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 429, train_loss = 1.7442255826899782, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 430, train_loss = 1.741410605609417, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 431, train_loss = 1.7384349765488878, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 432, train_loss = 1.7356652120361105, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 433, train_loss = 1.7329708138713613, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 434, train_loss = 1.7302172841737047, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 435, train_loss = 1.727459722547792, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 436, train_loss = 1.7247260572621599, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 437, train_loss = 1.7221915995469317, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 438, train_loss = 1.7194516137242317, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 439, train_loss = 1.7167362967738882, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 440, train_loss = 1.7141929107019678, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 441, train_loss = 1.711697030812502, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 442, train_loss = 1.7089559683809057, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 443, train_loss = 1.7064446993172169, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 444, train_loss = 1.7038543286034837, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 445, train_loss = 1.7014583982527256, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 446, train_loss = 1.6989578567445278, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 447, train_loss = 1.6964095955481753, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 448, train_loss = 1.6939827961614355, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 449, train_loss = 1.691343106329441, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 450, train_loss = 1.6889020092785358, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 451, train_loss = 1.6862695589661598, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 452, train_loss = 1.6841778345406055, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 453, train_loss = 1.6814898997545242, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 454, train_loss = 1.6791131173959002, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 455, train_loss = 1.6766952028265223, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 456, train_loss = 1.6743861573049799, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 457, train_loss = 1.6720523834228516, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 458, train_loss = 1.6695681922137737, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 459, train_loss = 1.667412074864842, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 460, train_loss = 1.6651004068553448, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 461, train_loss = 1.6627863930771127, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 462, train_loss = 1.6604784080991521, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 463, train_loss = 1.658402230590582, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 464, train_loss = 1.656111108721234, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 465, train_loss = 1.6540452154586092, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 466, train_loss = 1.6515996679663658, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 467, train_loss = 1.6495199439814314, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 468, train_loss = 1.6473818955710158, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 469, train_loss = 1.6451900812098756, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 470, train_loss = 1.6430496101966128, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 471, train_loss = 1.640931727946736, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 472, train_loss = 1.6388531675329432, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 473, train_loss = 1.6367019303143024, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 474, train_loss = 1.6346697570988908, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 475, train_loss = 1.6326000863919035, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 476, train_loss = 1.6305450076470152, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 477, train_loss = 1.628448067815043, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 478, train_loss = 1.6265331879258156, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 479, train_loss = 1.6244622096419334, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 480, train_loss = 1.6224640818545595, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 481, train_loss = 1.6205266130855307, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 482, train_loss = 1.6184522086987272, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 483, train_loss = 1.6165173588087782, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 484, train_loss = 1.6144239492714405, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 485, train_loss = 1.6126256262068637, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 486, train_loss = 1.6107144951820374, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 487, train_loss = 1.6086732770199887, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 488, train_loss = 1.606931161135435, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 489, train_loss = 1.6049538254737854, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 490, train_loss = 1.6031593469087966, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 491, train_loss = 1.6013970859348774, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 492, train_loss = 1.599303589493502, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 493, train_loss = 1.597558160603512, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 494, train_loss = 1.5957960871164687, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 495, train_loss = 1.5939476217026822, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 496, train_loss = 1.5920381285250187, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 497, train_loss = 1.5902792501146905, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 498, train_loss = 1.5884952396154404, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 499, train_loss = 1.5868588809971698, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                      | 1/30 [06:40<3:13:28, 400.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "2th- epoch: 0, train_loss = 277.7319105863571, train_acc = 0.4273404750815091\n",
      "test Acc 0.49394785847299816:\n",
      "2th- epoch: 1, train_loss = 214.39298450946808, train_acc = 0.49417792268281324\n",
      "test Acc 0.49767225325884545:\n",
      "2th- epoch: 2, train_loss = 167.55566143989563, train_acc = 0.5133907778295296\n",
      "test Acc 0.5642458100558659:\n",
      "2th- epoch: 3, train_loss = 144.06441926956177, train_acc = 0.6488122962272939\n",
      "test Acc 0.696927374301676:\n",
      "2th- epoch: 4, train_loss = 125.8207654953003, train_acc = 0.7092454587796926\n",
      "test Acc 0.7337057728119181:\n",
      "2th- epoch: 5, train_loss = 110.07025307416916, train_acc = 0.7466231951560317\n",
      "test Acc 0.7760707635009311:\n",
      "2th- epoch: 6, train_loss = 96.53007903695107, train_acc = 0.7923847228691197\n",
      "test Acc 0.797951582867784:\n",
      "2th- epoch: 7, train_loss = 85.09349539875984, train_acc = 0.8169538891476479\n",
      "test Acc 0.818901303538175:\n",
      "2th- epoch: 8, train_loss = 75.46391707658768, train_acc = 0.8395435491383325\n",
      "test Acc 0.8482309124767226:\n",
      "2th- epoch: 9, train_loss = 67.32802650332451, train_acc = 0.8628318584070797\n",
      "test Acc 0.8747672253258846:\n",
      "2th- epoch: 10, train_loss = 60.46202144026756, train_acc = 0.881578947368421\n",
      "test Acc 0.8873370577281192:\n",
      "2th- epoch: 11, train_loss = 54.702780202031136, train_acc = 0.8918258034466697\n",
      "test Acc 0.8938547486033519:\n",
      "2th- epoch: 12, train_loss = 49.89695304632187, train_acc = 0.9020726595249184\n",
      "test Acc 0.9031657355679702:\n",
      "2th- epoch: 13, train_loss = 45.87108229100704, train_acc = 0.9138332557056358\n",
      "test Acc 0.9175977653631285:\n",
      "2th- epoch: 14, train_loss = 42.47060050070286, train_acc = 0.9229156963204471\n",
      "test Acc 0.925512104283054:\n",
      "2th- epoch: 15, train_loss = 39.56708908081055, train_acc = 0.9302515137401025\n",
      "test Acc 0.9315642458100558:\n",
      "2th- epoch: 16, train_loss = 37.08309184014797, train_acc = 0.9345598509548206\n",
      "test Acc 0.936219739292365:\n",
      "2th- epoch: 17, train_loss = 34.94314085692167, train_acc = 0.9416627852817886\n",
      "test Acc 0.9408752327746741:\n",
      "2th- epoch: 18, train_loss = 33.08022250235081, train_acc = 0.9449231485794132\n",
      "test Acc 0.9413407821229051:\n",
      "2th- epoch: 19, train_loss = 31.4479012042284, train_acc = 0.9472519795062878\n",
      "test Acc 0.9427374301675978:\n",
      "2th- epoch: 20, train_loss = 30.013840220868587, train_acc = 0.9495808104331626\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 21, train_loss = 28.74297320097685, train_acc = 0.9513274336283186\n",
      "test Acc 0.9478584729981379:\n",
      "2th- epoch: 22, train_loss = 27.609929405152798, train_acc = 0.9528411737307871\n",
      "test Acc 0.9483240223463687:\n",
      "2th- epoch: 23, train_loss = 26.59339825063944, train_acc = 0.9548206800186306\n",
      "test Acc 0.9492551210428305:\n",
      "2th- epoch: 24, train_loss = 25.67828392237425, train_acc = 0.955519329296693\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 25, train_loss = 24.847661525011063, train_acc = 0.9563344201210993\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 26, train_loss = 24.089016750454903, train_acc = 0.9578481602235678\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 27, train_loss = 23.39204552769661, train_acc = 0.9590125756870052\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 28, train_loss = 22.748347714543343, train_acc = 0.9600605496040987\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 29, train_loss = 22.15119780227542, train_acc = 0.9606427573358174\n",
      "test Acc 0.9529795158286778:\n",
      "2th- epoch: 30, train_loss = 21.59401696920395, train_acc = 0.9608756404285049\n",
      "test Acc 0.9543761638733705:\n",
      "2th- epoch: 31, train_loss = 21.072107579559088, train_acc = 0.9609920819748486\n",
      "test Acc 0.9548417132216015:\n",
      "2th- epoch: 32, train_loss = 20.58129569888115, train_acc = 0.961690731252911\n",
      "test Acc 0.9557728119180633:\n",
      "2th- epoch: 33, train_loss = 20.117776282131672, train_acc = 0.962156497438286\n",
      "test Acc 0.9567039106145251:\n",
      "2th- epoch: 34, train_loss = 19.678098492324352, train_acc = 0.9628551467163484\n",
      "test Acc 0.957635009310987:\n",
      "2th- epoch: 35, train_loss = 19.260276172310114, train_acc = 0.9630880298090359\n",
      "test Acc 0.9581005586592178:\n",
      "2th- epoch: 36, train_loss = 18.86260637640953, train_acc = 0.9635537959944108\n",
      "test Acc 0.9581005586592178:\n",
      "2th- epoch: 37, train_loss = 18.483624912798405, train_acc = 0.9642524452724732\n",
      "test Acc 0.9581005586592178:\n",
      "2th- epoch: 38, train_loss = 18.121730137616396, train_acc = 0.9650675360968793\n",
      "test Acc 0.9585661080074488:\n",
      "2th- epoch: 39, train_loss = 17.77598424628377, train_acc = 0.9655333022822543\n",
      "test Acc 0.9585661080074488:\n",
      "2th- epoch: 40, train_loss = 17.4448319375515, train_acc = 0.9662319515603167\n",
      "test Acc 0.9594972067039106:\n",
      "2th- epoch: 41, train_loss = 17.1271614395082, train_acc = 0.9668141592920354\n",
      "test Acc 0.9594972067039106:\n",
      "2th- epoch: 42, train_loss = 16.821569845080376, train_acc = 0.9672799254774104\n",
      "test Acc 0.9599627560521415:\n",
      "2th- epoch: 43, train_loss = 16.527592584490776, train_acc = 0.9682114578481602\n",
      "test Acc 0.9613594040968343:\n",
      "2th- epoch: 44, train_loss = 16.244236394762993, train_acc = 0.9691429902189101\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 45, train_loss = 15.970905974507332, train_acc = 0.9697251979506288\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 46, train_loss = 15.706952851265669, train_acc = 0.9706567303213787\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 47, train_loss = 15.451937563717365, train_acc = 0.9717047042384723\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 48, train_loss = 15.205209489911795, train_acc = 0.9717047042384723\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 49, train_loss = 14.966863427311182, train_acc = 0.971821145784816\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 50, train_loss = 14.736105237156153, train_acc = 0.9724033535165347\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 51, train_loss = 14.512560471892357, train_acc = 0.9729855612482534\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 52, train_loss = 14.296110812574625, train_acc = 0.9736842105263158\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 53, train_loss = 14.085668329149485, train_acc = 0.974033535165347\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 54, train_loss = 13.881266690790653, train_acc = 0.9742664182580345\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 55, train_loss = 13.682419314980507, train_acc = 0.9746157428970657\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 56, train_loss = 13.489466086030006, train_acc = 0.9747321844434094\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 57, train_loss = 13.301551587879658, train_acc = 0.9748486259897532\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 58, train_loss = 13.118548963218927, train_acc = 0.9749650675360969\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 59, train_loss = 12.941355617716908, train_acc = 0.9750815090824406\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 60, train_loss = 12.76876337081194, train_acc = 0.975314392175128\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 61, train_loss = 12.600573010742664, train_acc = 0.9754308337214718\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 62, train_loss = 12.436332058161497, train_acc = 0.9754308337214718\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 63, train_loss = 12.276075664907694, train_acc = 0.9756637168141593\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 64, train_loss = 12.11941223219037, train_acc = 0.9758965999068467\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 65, train_loss = 11.966834615916014, train_acc = 0.9758965999068467\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 66, train_loss = 11.818107467144728, train_acc = 0.9760130414531905\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 67, train_loss = 11.67283932119608, train_acc = 0.9760130414531905\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 68, train_loss = 11.531029757112265, train_acc = 0.976245924545878\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 69, train_loss = 11.3923454079777, train_acc = 0.9764788076385654\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 70, train_loss = 11.256776839494705, train_acc = 0.9764788076385654\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 71, train_loss = 11.124156694859266, train_acc = 0.9764788076385654\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 72, train_loss = 10.994386782869697, train_acc = 0.9769445738239404\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 73, train_loss = 10.867511862888932, train_acc = 0.9770610153702841\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 74, train_loss = 10.743261801078916, train_acc = 0.9771774569166278\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 75, train_loss = 10.621288729831576, train_acc = 0.9777596646483465\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 76, train_loss = 10.501872669905424, train_acc = 0.977992547741034\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 77, train_loss = 10.38491240888834, train_acc = 0.9784583139264089\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 78, train_loss = 10.270044934004545, train_acc = 0.9786911970190965\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 79, train_loss = 10.15750065073371, train_acc = 0.9788076385654402\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 80, train_loss = 10.047026682645082, train_acc = 0.9789240801117839\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 81, train_loss = 9.938700810074806, train_acc = 0.9793898462971589\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 82, train_loss = 9.832269057631493, train_acc = 0.9796227293898463\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 83, train_loss = 9.727743480354548, train_acc = 0.9796227293898463\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 84, train_loss = 9.6249671690166, train_acc = 0.9798556124825337\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 85, train_loss = 9.523940164595842, train_acc = 0.9798556124825337\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 86, train_loss = 9.424447398632765, train_acc = 0.9798556124825337\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 87, train_loss = 9.32675315439701, train_acc = 0.9800884955752213\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 88, train_loss = 9.230759680271149, train_acc = 0.980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 89, train_loss = 9.136302523314953, train_acc = 0.9804378202142524\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 90, train_loss = 9.043475944548845, train_acc = 0.980204937121565\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 91, train_loss = 8.952145382761955, train_acc = 0.980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 92, train_loss = 8.862314559519291, train_acc = 0.9804378202142524\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 93, train_loss = 8.773903168737888, train_acc = 0.98067070330694\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 94, train_loss = 8.687020240351558, train_acc = 0.9810200279459711\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 95, train_loss = 8.601236937567592, train_acc = 0.9810200279459711\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 96, train_loss = 8.516665279865265, train_acc = 0.9810200279459711\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 97, train_loss = 8.433280615136027, train_acc = 0.9813693525850024\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 98, train_loss = 8.351160513237119, train_acc = 0.9816022356776898\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 99, train_loss = 8.270106360316277, train_acc = 0.9818351187703773\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 100, train_loss = 8.190214484930038, train_acc = 0.981951560316721\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 101, train_loss = 8.111562378704548, train_acc = 0.9825337680484397\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 102, train_loss = 8.033812399953604, train_acc = 0.9831159757801584\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 103, train_loss = 7.957385970279574, train_acc = 0.9832324173265021\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 104, train_loss = 7.881839437410235, train_acc = 0.9835817419655333\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 105, train_loss = 7.807499948889017, train_acc = 0.9838146250582208\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 106, train_loss = 7.734172947704792, train_acc = 0.984163949697252\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 107, train_loss = 7.661907257512212, train_acc = 0.9842803912435957\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 108, train_loss = 7.59071989543736, train_acc = 0.9847461574289706\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 109, train_loss = 7.52030536159873, train_acc = 0.9847461574289706\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 110, train_loss = 7.45098589733243, train_acc = 0.9848625989753144\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 111, train_loss = 7.382621994242072, train_acc = 0.9849790405216581\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 112, train_loss = 7.315275635570288, train_acc = 0.9849790405216581\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 113, train_loss = 7.248699804767966, train_acc = 0.9853283651606893\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 114, train_loss = 7.1830592062324286, train_acc = 0.9855612482533768\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 115, train_loss = 7.118217593058944, train_acc = 0.9856776897997206\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 116, train_loss = 7.0542573388665915, train_acc = 0.9856776897997206\n",
      "test Acc 0.9739292364990689:\n",
      "2th- epoch: 117, train_loss = 6.991095272824168, train_acc = 0.985910572892408\n",
      "test Acc 0.9739292364990689:\n",
      "2th- epoch: 118, train_loss = 6.928916959092021, train_acc = 0.985910572892408\n",
      "test Acc 0.9739292364990689:\n",
      "2th- epoch: 119, train_loss = 6.867686295881867, train_acc = 0.9857941313460643\n",
      "test Acc 0.9739292364990689:\n",
      "2th- epoch: 120, train_loss = 6.807256177067757, train_acc = 0.985910572892408\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 121, train_loss = 6.747668445110321, train_acc = 0.985910572892408\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 122, train_loss = 6.688990062102675, train_acc = 0.9861434559850955\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 123, train_loss = 6.630996642634273, train_acc = 0.9862598975314392\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 124, train_loss = 6.573813887313008, train_acc = 0.9864927806241267\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 125, train_loss = 6.517463134601712, train_acc = 0.9864927806241267\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 126, train_loss = 6.461748553439975, train_acc = 0.9864927806241267\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 127, train_loss = 6.406881902366877, train_acc = 0.9866092221704704\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 128, train_loss = 6.352761797606945, train_acc = 0.9868421052631579\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 129, train_loss = 6.299253648146987, train_acc = 0.9870749883558454\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 130, train_loss = 6.246456550434232, train_acc = 0.9871914299021891\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 131, train_loss = 6.194327142089605, train_acc = 0.9873078714485328\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 132, train_loss = 6.14298371784389, train_acc = 0.9874243129948765\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 133, train_loss = 6.092357052490115, train_acc = 0.9874243129948765\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 134, train_loss = 6.04249501414597, train_acc = 0.9875407545412203\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 135, train_loss = 5.9930614698678255, train_acc = 0.9875407545412203\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 136, train_loss = 5.944503553211689, train_acc = 0.9875407545412203\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 137, train_loss = 5.896503897383809, train_acc = 0.9876571960875641\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 138, train_loss = 5.849112482741475, train_acc = 0.9878900791802515\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 139, train_loss = 5.802349576726556, train_acc = 0.9880065207265952\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 140, train_loss = 5.756277088075876, train_acc = 0.9880065207265952\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 141, train_loss = 5.7107516545802355, train_acc = 0.9880065207265952\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 142, train_loss = 5.665774641558528, train_acc = 0.9880065207265952\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 143, train_loss = 5.621422935277224, train_acc = 0.9880065207265952\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 144, train_loss = 5.577824996784329, train_acc = 0.9881229622729389\n",
      "test Acc 0.9748603351955307:\n",
      "2th- epoch: 145, train_loss = 5.534453479573131, train_acc = 0.9883558453656265\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 146, train_loss = 5.4917442705482244, train_acc = 0.9884722869119702\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 147, train_loss = 5.449075372889638, train_acc = 0.9884722869119702\n",
      "test Acc 0.9767225325884544:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 148, train_loss = 5.4068159237504005, train_acc = 0.9887051700046576\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 149, train_loss = 5.365139111876488, train_acc = 0.9887051700046576\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 150, train_loss = 5.324439138174057, train_acc = 0.9888216115510013\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 151, train_loss = 5.284057607874274, train_acc = 0.9888216115510013\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 152, train_loss = 5.244347095489502, train_acc = 0.9889380530973452\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 153, train_loss = 5.205181242898107, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 154, train_loss = 5.166394868865609, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 155, train_loss = 5.128315770067275, train_acc = 0.9895202608290639\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 156, train_loss = 5.0905182575806975, train_acc = 0.9895202608290639\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 157, train_loss = 5.0534683233127, train_acc = 0.9895202608290639\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 158, train_loss = 5.016693640500307, train_acc = 0.9896367023754076\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 159, train_loss = 4.980557573959231, train_acc = 0.9896367023754076\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 160, train_loss = 4.94479179289192, train_acc = 0.9896367023754076\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 161, train_loss = 4.909554292447865, train_acc = 0.9897531439217513\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 162, train_loss = 4.874728516675532, train_acc = 0.9897531439217513\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 163, train_loss = 4.840298027731478, train_acc = 0.9899860270144387\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 164, train_loss = 4.806277073919773, train_acc = 0.99033535165347\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 165, train_loss = 4.772882987745106, train_acc = 0.99033535165347\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 166, train_loss = 4.739558351226151, train_acc = 0.99033535165347\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 167, train_loss = 4.7069541765376925, train_acc = 0.9906846762925011\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 168, train_loss = 4.674460529349744, train_acc = 0.9906846762925011\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 169, train_loss = 4.642645885236561, train_acc = 0.9909175593851887\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 170, train_loss = 4.611232104711235, train_acc = 0.9910340009315324\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 171, train_loss = 4.579940726980567, train_acc = 0.9911504424778761\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 172, train_loss = 4.549259587191045, train_acc = 0.9913833255705635\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 173, train_loss = 4.518891330808401, train_acc = 0.9914997671169073\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 174, train_loss = 4.489001601934433, train_acc = 0.9917326502095948\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 175, train_loss = 4.459237075410783, train_acc = 0.9917326502095948\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 176, train_loss = 4.430028942413628, train_acc = 0.9918490917559385\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 177, train_loss = 4.401137378066778, train_acc = 0.9918490917559385\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 178, train_loss = 4.372471988201141, train_acc = 0.9918490917559385\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 179, train_loss = 4.344370324164629, train_acc = 0.9918490917559385\n",
      "test Acc 0.9767225325884544:\n",
      "2th- epoch: 180, train_loss = 4.316392540931702, train_acc = 0.9918490917559385\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 181, train_loss = 4.2888987101614475, train_acc = 0.9918490917559385\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 182, train_loss = 4.261583344079554, train_acc = 0.9918490917559385\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 183, train_loss = 4.234768983907998, train_acc = 0.9918490917559385\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 184, train_loss = 4.208118832670152, train_acc = 0.9918490917559385\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 185, train_loss = 4.181697477586567, train_acc = 0.9919655333022822\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 186, train_loss = 4.155818373896182, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 187, train_loss = 4.130194374360144, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 188, train_loss = 4.10475252661854, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 189, train_loss = 4.079610966145992, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 190, train_loss = 4.054795780219138, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 191, train_loss = 4.030187916941941, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 192, train_loss = 4.006006978452206, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 193, train_loss = 3.981919235549867, train_acc = 0.9921984163949698\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 194, train_loss = 3.958139139227569, train_acc = 0.9921984163949698\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 195, train_loss = 3.934669946320355, train_acc = 0.9921984163949698\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 196, train_loss = 3.911582618020475, train_acc = 0.9921984163949698\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 197, train_loss = 3.8885733848437667, train_acc = 0.9921984163949698\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 198, train_loss = 3.8658931190147996, train_acc = 0.9921984163949698\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 199, train_loss = 3.8431491516530514, train_acc = 0.9921984163949698\n",
      "test Acc 0.979050279329609:\n",
      "2th- epoch: 200, train_loss = 3.8208647118881345, train_acc = 0.9921984163949698\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 201, train_loss = 3.7988222455605865, train_acc = 0.9921984163949698\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 202, train_loss = 3.777289398945868, train_acc = 0.9921984163949698\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 203, train_loss = 3.7554759634658694, train_acc = 0.9921984163949698\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 204, train_loss = 3.7341137705370784, train_acc = 0.9921984163949698\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 205, train_loss = 3.713054914958775, train_acc = 0.9921984163949698\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 206, train_loss = 3.6922662518918514, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 207, train_loss = 3.671513062901795, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 208, train_loss = 3.651205244474113, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 209, train_loss = 3.6311925211921334, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 210, train_loss = 3.6109946062788367, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 211, train_loss = 3.591045648790896, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 212, train_loss = 3.571731436997652, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 213, train_loss = 3.552276747766882, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 214, train_loss = 3.5330559336580336, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 215, train_loss = 3.5140526592731476, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 216, train_loss = 3.495153507683426, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 217, train_loss = 3.4767364761792123, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 218, train_loss = 3.458183068782091, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 219, train_loss = 3.4399351961910725, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 220, train_loss = 3.4219084293581545, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 221, train_loss = 3.403983735013753, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 222, train_loss = 3.3863460142165422, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 223, train_loss = 3.368836288806051, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 224, train_loss = 3.351623371709138, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 225, train_loss = 3.33431062893942, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 226, train_loss = 3.317321848589927, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 227, train_loss = 3.3004147657193244, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 228, train_loss = 3.2837501508183777, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 229, train_loss = 3.2674940419383347, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 230, train_loss = 3.2509274035692215, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 231, train_loss = 3.234818100463599, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 232, train_loss = 3.2188156228512526, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 233, train_loss = 3.2028535618446767, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 234, train_loss = 3.1871372810564935, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 235, train_loss = 3.1713767792098224, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 236, train_loss = 3.156280677765608, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 237, train_loss = 3.140801591798663, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 238, train_loss = 3.1257822602055967, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 239, train_loss = 3.1105872560292482, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 240, train_loss = 3.095877844840288, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 241, train_loss = 3.0810353867709637, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 242, train_loss = 3.0664582918398082, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 243, train_loss = 3.0520096346735954, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 244, train_loss = 3.0377276339568198, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 245, train_loss = 3.0234061130322516, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 246, train_loss = 3.0094728167168796, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 247, train_loss = 2.995437543373555, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 248, train_loss = 2.9816310424357653, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 249, train_loss = 2.9681385732255876, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 250, train_loss = 2.954407370183617, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 251, train_loss = 2.940974374767393, train_acc = 0.9940614811364695\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 252, train_loss = 2.9274348355829716, train_acc = 0.9940614811364695\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 253, train_loss = 2.9144157953560352, train_acc = 0.9941779226828132\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 254, train_loss = 2.9014206491410732, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 255, train_loss = 2.888207346200943, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 256, train_loss = 2.8755934895016253, train_acc = 0.994294364229157\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 257, train_loss = 2.862738522235304, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 258, train_loss = 2.8501607687212527, train_acc = 0.9944108057755007\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 259, train_loss = 2.837625788990408, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 260, train_loss = 2.82526833191514, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 261, train_loss = 2.8128884532488883, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 262, train_loss = 2.8007800825871527, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 263, train_loss = 2.788691509515047, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 264, train_loss = 2.7767134816385806, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 265, train_loss = 2.764900027308613, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 266, train_loss = 2.7531588091515005, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 267, train_loss = 2.7414365895092487, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 268, train_loss = 2.729818169027567, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 269, train_loss = 2.7185305864550173, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 270, train_loss = 2.7071815989911556, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 271, train_loss = 2.6959847882390022, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 272, train_loss = 2.684823675546795, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 273, train_loss = 2.6737086437642574, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 274, train_loss = 2.6628481559455395, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 275, train_loss = 2.65185726294294, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 276, train_loss = 2.641232492867857, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 277, train_loss = 2.6304882541298866, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 278, train_loss = 2.62023014575243, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 279, train_loss = 2.6096144667826593, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 280, train_loss = 2.5992762646637857, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 281, train_loss = 2.5888056033290923, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 282, train_loss = 2.5787095851264894, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 283, train_loss = 2.5685325860977173, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 284, train_loss = 2.5585137181915343, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 285, train_loss = 2.548615798354149, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 286, train_loss = 2.5387625680305064, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 287, train_loss = 2.5291413157247007, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 288, train_loss = 2.5194172624032944, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 289, train_loss = 2.509848166257143, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 290, train_loss = 2.500452322186902, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 291, train_loss = 2.4909590769093484, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 292, train_loss = 2.481668076245114, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 293, train_loss = 2.4726040300447494, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 294, train_loss = 2.463418607832864, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 295, train_loss = 2.4544696535449475, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 296, train_loss = 2.4454529136419296, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 297, train_loss = 2.4367125171702355, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 298, train_loss = 2.427917342633009, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 299, train_loss = 2.419240177841857, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 300, train_loss = 2.4106327469926327, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 301, train_loss = 2.4020742003340274, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 302, train_loss = 2.393806954147294, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 303, train_loss = 2.38539261627011, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 304, train_loss = 2.3771750207524747, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 305, train_loss = 2.368876627413556, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 306, train_loss = 2.360869291005656, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 307, train_loss = 2.3527142491657287, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 308, train_loss = 2.344778833212331, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 309, train_loss = 2.336929385783151, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 310, train_loss = 2.3291094824671745, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 311, train_loss = 2.3213034111540765, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 312, train_loss = 2.313662052154541, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 313, train_loss = 2.305989192100242, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 314, train_loss = 2.2984972782433033, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 315, train_loss = 2.2909445762634277, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 316, train_loss = 2.283647069009021, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 317, train_loss = 2.2762054230552167, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 318, train_loss = 2.269042248604819, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 319, train_loss = 2.2618195861577988, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 320, train_loss = 2.2544907208066434, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 321, train_loss = 2.2475158150773495, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 322, train_loss = 2.2404091507196426, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 323, train_loss = 2.2334831890184432, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 324, train_loss = 2.226586375385523, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 325, train_loss = 2.219756655395031, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 326, train_loss = 2.213144389213994, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 327, train_loss = 2.206322354497388, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 328, train_loss = 2.1997779917437583, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 329, train_loss = 2.1931074026506394, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 330, train_loss = 2.1866586569231004, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 331, train_loss = 2.1802417871076614, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 332, train_loss = 2.1737985324580222, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 333, train_loss = 2.1672725055832416, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 334, train_loss = 2.161123586120084, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 335, train_loss = 2.1547940969467163, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 336, train_loss = 2.148557511391118, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 337, train_loss = 2.142752930521965, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 338, train_loss = 2.1363496605772525, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 339, train_loss = 2.130466132191941, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 340, train_loss = 2.124432689277455, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 341, train_loss = 2.118626479059458, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 342, train_loss = 2.1127564683556557, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 343, train_loss = 2.1069885592442006, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 344, train_loss = 2.10113263502717, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 345, train_loss = 2.0955712497234344, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 346, train_loss = 2.0898312504868954, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 347, train_loss = 2.0843827947974205, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 348, train_loss = 2.0786829714197665, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 349, train_loss = 2.0731184482574463, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 350, train_loss = 2.067698113620281, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 351, train_loss = 2.062313850969076, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 352, train_loss = 2.057184091536328, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 353, train_loss = 2.0517425313591957, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 354, train_loss = 2.0464337680023164, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 355, train_loss = 2.0412586939055473, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 356, train_loss = 2.0360854256432503, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 357, train_loss = 2.0308941390831023, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 358, train_loss = 2.025836394401267, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 359, train_loss = 2.020857234718278, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 360, train_loss = 2.0158200536388904, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 361, train_loss = 2.010864470154047, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 362, train_loss = 2.0060640673618764, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 363, train_loss = 2.0012586265802383, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 364, train_loss = 1.9962908737361431, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 365, train_loss = 1.9913508568424731, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 366, train_loss = 1.9867999379057437, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 367, train_loss = 1.9819628198165447, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 368, train_loss = 1.9773075506091118, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 369, train_loss = 1.972858729539439, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 370, train_loss = 1.9680170565843582, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 371, train_loss = 1.9637674540281296, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 372, train_loss = 1.959010124206543, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 373, train_loss = 1.9547071059932932, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 374, train_loss = 1.9501413939287886, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 375, train_loss = 1.945790708065033, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 376, train_loss = 1.9413837132742628, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 377, train_loss = 1.9371785236289725, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 378, train_loss = 1.932716873823665, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 379, train_loss = 1.9286078922450542, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 380, train_loss = 1.9241856361040846, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 381, train_loss = 1.920146712451242, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 382, train_loss = 1.9160050848731771, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 383, train_loss = 1.9118646109709516, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 384, train_loss = 1.9076416293391958, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 385, train_loss = 1.9036849861731753, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 386, train_loss = 1.8994660651078448, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 387, train_loss = 1.895713878213428, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 388, train_loss = 1.8915732130408287, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 389, train_loss = 1.887733722687699, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 390, train_loss = 1.883689023554325, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 391, train_loss = 1.8797820433974266, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 392, train_loss = 1.8760746283223853, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 393, train_loss = 1.8722293203463778, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 394, train_loss = 1.86840319132898, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 395, train_loss = 1.8647777797887102, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 396, train_loss = 1.8609319515526295, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 397, train_loss = 1.8573721857974306, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 398, train_loss = 1.8535867830505595, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 399, train_loss = 1.8499586594989523, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 400, train_loss = 1.8464088899781927, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 401, train_loss = 1.8428757973015308, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 402, train_loss = 1.839312439202331, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 403, train_loss = 1.8356774175772443, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 404, train_loss = 1.8324700394878164, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 405, train_loss = 1.8287400690605864, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 406, train_loss = 1.825284369289875, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 407, train_loss = 1.8218803057679906, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 408, train_loss = 1.818588358699344, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 409, train_loss = 1.8151043578982353, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 410, train_loss = 1.8118473291397095, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 411, train_loss = 1.8084093580255285, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 412, train_loss = 1.8051275262841955, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 413, train_loss = 1.8020386310527101, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 414, train_loss = 1.7988581893732771, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 415, train_loss = 1.79545606917236, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 416, train_loss = 1.7925058206310496, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 417, train_loss = 1.7890172265470028, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 418, train_loss = 1.7860438512871042, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 419, train_loss = 1.7827636698493734, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 420, train_loss = 1.779653942794539, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 421, train_loss = 1.7766715151956305, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 422, train_loss = 1.7734956605127081, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 423, train_loss = 1.7705462673911825, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 424, train_loss = 1.7674735659966245, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 425, train_loss = 1.7647144520888105, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 426, train_loss = 1.7613022699952126, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 427, train_loss = 1.7589604085078463, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 428, train_loss = 1.7555113732814789, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 429, train_loss = 1.7527323700487614, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 430, train_loss = 1.749698786647059, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 431, train_loss = 1.7469843216240406, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 432, train_loss = 1.744330377667211, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 433, train_loss = 1.7411502972245216, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 434, train_loss = 1.738541316241026, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 435, train_loss = 1.735626820474863, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 436, train_loss = 1.7329507084796205, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 437, train_loss = 1.7300784786930308, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 438, train_loss = 1.727719514281489, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 439, train_loss = 1.7246410436928272, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 440, train_loss = 1.7220407774439082, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 441, train_loss = 1.7191808186471462, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 442, train_loss = 1.716972248046659, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 443, train_loss = 1.713956218212843, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 444, train_loss = 1.7114418037235737, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 445, train_loss = 1.708747842698358, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 446, train_loss = 1.7064954912057146, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 447, train_loss = 1.7035617319634184, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 448, train_loss = 1.7010178392520174, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 449, train_loss = 1.6988112839171663, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 450, train_loss = 1.6959799056639895, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 451, train_loss = 1.6936670491704717, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 452, train_loss = 1.690921870409511, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 453, train_loss = 1.6888605604181066, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 454, train_loss = 1.6860315004596487, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 455, train_loss = 1.6837351495632902, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 456, train_loss = 1.6814815601101145, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 457, train_loss = 1.6789194321027026, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 458, train_loss = 1.676420908421278, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 459, train_loss = 1.6741925390670076, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 460, train_loss = 1.6718403225531802, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 461, train_loss = 1.66944669932127, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 462, train_loss = 1.6671007983386517, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 463, train_loss = 1.6650879321387038, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 464, train_loss = 1.6623961528530344, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 465, train_loss = 1.6601390639552847, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 466, train_loss = 1.6581289445748553, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 467, train_loss = 1.6559317832579836, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 468, train_loss = 1.6534476863453165, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 469, train_loss = 1.6512647854397073, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 470, train_loss = 1.64929201209452, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 471, train_loss = 1.6468702914426103, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 472, train_loss = 1.6447982353856787, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 473, train_loss = 1.642646991997026, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 474, train_loss = 1.6405571214854717, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 475, train_loss = 1.6382307633757591, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 476, train_loss = 1.636481687426567, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 477, train_loss = 1.6341098994016647, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 478, train_loss = 1.6318966696271673, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 479, train_loss = 1.630154884129297, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 480, train_loss = 1.6278317831456661, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 481, train_loss = 1.626204231113661, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 482, train_loss = 1.6237023919820786, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 483, train_loss = 1.6216843376751058, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 484, train_loss = 1.6198395912651904, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 485, train_loss = 1.6175904509727843, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 486, train_loss = 1.61596405133605, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 487, train_loss = 1.6137404541368596, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 488, train_loss = 1.611845017701853, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 489, train_loss = 1.6099448092281818, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 490, train_loss = 1.6078865614836104, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 491, train_loss = 1.6061997177894227, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 492, train_loss = 1.6039918214082718, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 493, train_loss = 1.6021349753136747, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 494, train_loss = 1.600462508678902, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 495, train_loss = 1.5984238063101657, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 496, train_loss = 1.5966480895876884, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 497, train_loss = 1.5948656896944158, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 498, train_loss = 1.5929025051300414, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "2th- epoch: 499, train_loss = 1.5908657697145827, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████▊                                                                    | 2/30 [13:19<3:06:34, 399.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "3th- epoch: 0, train_loss = 272.1220977306366, train_acc = 0.4523754075454122\n",
      "test Acc 0.4851024208566108:\n",
      "3th- epoch: 1, train_loss = 206.7877835035324, train_acc = 0.4913833255705636\n",
      "test Acc 0.4967411545623836:\n",
      "3th- epoch: 2, train_loss = 167.7125415802002, train_acc = 0.5060549604098742\n",
      "test Acc 0.5782122905027933:\n",
      "3th- epoch: 3, train_loss = 146.70894372463226, train_acc = 0.6152771308802981\n",
      "test Acc 0.6685288640595903:\n",
      "3th- epoch: 4, train_loss = 129.83699929714203, train_acc = 0.6924778761061947\n",
      "test Acc 0.7248603351955307:\n",
      "3th- epoch: 5, train_loss = 114.83242350816727, train_acc = 0.7299720540288775\n",
      "test Acc 0.7523277467411545:\n",
      "3th- epoch: 6, train_loss = 101.40494072437286, train_acc = 0.7675826734979041\n",
      "test Acc 0.787243947858473:\n",
      "3th- epoch: 7, train_loss = 89.54669332504272, train_acc = 0.8006520726595249\n",
      "test Acc 0.8161080074487895:\n",
      "3th- epoch: 8, train_loss = 79.15358531475067, train_acc = 0.8325570563577084\n",
      "test Acc 0.8463687150837989:\n",
      "3th- epoch: 9, train_loss = 70.11399519443512, train_acc = 0.8586399627387051\n",
      "test Acc 0.8715083798882681:\n",
      "3th- epoch: 10, train_loss = 62.41373971104622, train_acc = 0.8734280391243596\n",
      "test Acc 0.883147113594041:\n",
      "3th- epoch: 11, train_loss = 56.012745797634125, train_acc = 0.8871681415929203\n",
      "test Acc 0.8924581005586593:\n",
      "3th- epoch: 12, train_loss = 50.7607194930315, train_acc = 0.8969492314857941\n",
      "test Acc 0.898975791433892:\n",
      "3th- epoch: 13, train_loss = 46.4537398070097, train_acc = 0.9090591523055426\n",
      "test Acc 0.9134078212290503:\n",
      "3th- epoch: 14, train_loss = 42.88188777863979, train_acc = 0.9211690731252911\n",
      "test Acc 0.925512104283054:\n",
      "3th- epoch: 15, train_loss = 39.87221950292587, train_acc = 0.9292035398230089\n",
      "test Acc 0.9334264432029795:\n",
      "3th- epoch: 16, train_loss = 37.31926453113556, train_acc = 0.9345598509548206\n",
      "test Acc 0.9366852886405959:\n",
      "3th- epoch: 17, train_loss = 35.133654430508614, train_acc = 0.9421285514671635\n",
      "test Acc 0.9404096834264432:\n",
      "3th- epoch: 18, train_loss = 33.2437454983592, train_acc = 0.9444573823940382\n",
      "test Acc 0.9427374301675978:\n",
      "3th- epoch: 19, train_loss = 31.59521272033453, train_acc = 0.9477177456916628\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 20, train_loss = 30.143835492432117, train_acc = 0.9488821611551002\n",
      "test Acc 0.9478584729981379:\n",
      "3th- epoch: 21, train_loss = 28.858984008431435, train_acc = 0.952026082906381\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 22, train_loss = 27.71281886100769, train_acc = 0.9529576152771309\n",
      "test Acc 0.9501862197392924:\n",
      "3th- epoch: 23, train_loss = 26.68265837430954, train_acc = 0.9545877969259432\n",
      "test Acc 0.9515828677839852:\n",
      "3th- epoch: 24, train_loss = 25.74995881319046, train_acc = 0.9552864462040056\n",
      "test Acc 0.9534450651769087:\n",
      "3th- epoch: 25, train_loss = 24.901239663362503, train_acc = 0.9566837447601304\n",
      "test Acc 0.9529795158286778:\n",
      "3th- epoch: 26, train_loss = 24.12302676588297, train_acc = 0.9576152771308803\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 27, train_loss = 23.406667962670326, train_acc = 0.9583139264089428\n",
      "test Acc 0.9543761638733705:\n",
      "3th- epoch: 28, train_loss = 22.74409907311201, train_acc = 0.9590125756870052\n",
      "test Acc 0.9548417132216015:\n",
      "3th- epoch: 29, train_loss = 22.12836929038167, train_acc = 0.959944108057755\n",
      "test Acc 0.9548417132216015:\n",
      "3th- epoch: 30, train_loss = 21.553358126431704, train_acc = 0.9606427573358174\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 31, train_loss = 21.014791749417782, train_acc = 0.9614578481602236\n",
      "test Acc 0.9562383612662942:\n",
      "3th- epoch: 32, train_loss = 20.507542233914137, train_acc = 0.961690731252911\n",
      "test Acc 0.957169459962756:\n",
      "3th- epoch: 33, train_loss = 20.028297666460276, train_acc = 0.9622729389846297\n",
      "test Acc 0.957169459962756:\n",
      "3th- epoch: 34, train_loss = 19.574402630329132, train_acc = 0.9629715882626921\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 35, train_loss = 19.14363392814994, train_acc = 0.9636702375407545\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 36, train_loss = 18.733579635620117, train_acc = 0.9643688868188169\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 37, train_loss = 18.343061193823814, train_acc = 0.9650675360968793\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 38, train_loss = 17.97019601240754, train_acc = 0.9651839776432231\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 39, train_loss = 17.612889137119055, train_acc = 0.9666977177456917\n",
      "test Acc 0.9622905027932961:\n",
      "3th- epoch: 40, train_loss = 17.270503744482994, train_acc = 0.9679785747554728\n",
      "test Acc 0.9622905027932961:\n",
      "3th- epoch: 41, train_loss = 16.94182527810335, train_acc = 0.9693758733115976\n",
      "test Acc 0.962756052141527:\n",
      "3th- epoch: 42, train_loss = 16.626198925077915, train_acc = 0.9699580810433163\n",
      "test Acc 0.9632216014897579:\n",
      "3th- epoch: 43, train_loss = 16.323107358068228, train_acc = 0.9699580810433163\n",
      "test Acc 0.9646182495344506:\n",
      "3th- epoch: 44, train_loss = 16.03137794882059, train_acc = 0.9703074056823474\n",
      "test Acc 0.9646182495344506:\n",
      "3th- epoch: 45, train_loss = 15.749952413141727, train_acc = 0.9708896134140661\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 46, train_loss = 15.478739015758038, train_acc = 0.9712389380530974\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 47, train_loss = 15.217017464339733, train_acc = 0.9715882626921285\n",
      "test Acc 0.9664804469273743:\n",
      "3th- epoch: 48, train_loss = 14.964401610195637, train_acc = 0.972286911970191\n",
      "test Acc 0.9664804469273743:\n",
      "3th- epoch: 49, train_loss = 14.72069039568305, train_acc = 0.9729855612482534\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 50, train_loss = 14.485143341124058, train_acc = 0.9731020027945971\n",
      "test Acc 0.9660148975791434:\n",
      "3th- epoch: 51, train_loss = 14.257550522685051, train_acc = 0.9732184443409408\n",
      "test Acc 0.9664804469273743:\n",
      "3th- epoch: 52, train_loss = 14.03756084293127, train_acc = 0.9736842105263158\n",
      "test Acc 0.9669459962756052:\n",
      "3th- epoch: 53, train_loss = 13.824395652860403, train_acc = 0.9736842105263158\n",
      "test Acc 0.9674115456238361:\n",
      "3th- epoch: 54, train_loss = 13.618046697229147, train_acc = 0.9738006520726595\n",
      "test Acc 0.9674115456238361:\n",
      "3th- epoch: 55, train_loss = 13.418294597417116, train_acc = 0.974033535165347\n",
      "test Acc 0.9674115456238361:\n",
      "3th- epoch: 56, train_loss = 13.224479826167226, train_acc = 0.9743828598043782\n",
      "test Acc 0.9674115456238361:\n",
      "3th- epoch: 57, train_loss = 13.035899128764868, train_acc = 0.9744993013507219\n",
      "test Acc 0.9674115456238361:\n",
      "3th- epoch: 58, train_loss = 12.852844551205635, train_acc = 0.9744993013507219\n",
      "test Acc 0.9674115456238361:\n",
      "3th- epoch: 59, train_loss = 12.675319992005825, train_acc = 0.9744993013507219\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 60, train_loss = 12.502345122396946, train_acc = 0.9749650675360969\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 61, train_loss = 12.334185101091862, train_acc = 0.9750815090824406\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 62, train_loss = 12.171145930886269, train_acc = 0.9751979506287843\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 63, train_loss = 12.012251395732164, train_acc = 0.9758965999068467\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 64, train_loss = 11.857823062688112, train_acc = 0.976245924545878\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 65, train_loss = 11.707155462354422, train_acc = 0.9767116907312529\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 66, train_loss = 11.560424119234085, train_acc = 0.9769445738239404\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 67, train_loss = 11.417129553854465, train_acc = 0.9770610153702841\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 68, train_loss = 11.277335118502378, train_acc = 0.9774103400093154\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 69, train_loss = 11.14069969765842, train_acc = 0.9776432231020028\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 70, train_loss = 11.007330471649766, train_acc = 0.9776432231020028\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 71, train_loss = 10.876998921856284, train_acc = 0.9777596646483465\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 72, train_loss = 10.749529652297497, train_acc = 0.9778761061946902\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 73, train_loss = 10.62493952922523, train_acc = 0.9778761061946902\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 74, train_loss = 10.502904485911131, train_acc = 0.977992547741034\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 75, train_loss = 10.383274672552943, train_acc = 0.9781089892873778\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 76, train_loss = 10.266115160658956, train_acc = 0.9781089892873778\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 77, train_loss = 10.15139950811863, train_acc = 0.9784583139264089\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 78, train_loss = 10.038860980421305, train_acc = 0.9786911970190965\n",
      "test Acc 0.9697392923649907:\n",
      "3th- epoch: 79, train_loss = 9.928688015788794, train_acc = 0.9786911970190965\n",
      "test Acc 0.9702048417132216:\n",
      "3th- epoch: 80, train_loss = 9.820585910230875, train_acc = 0.9786911970190965\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 81, train_loss = 9.714555103331804, train_acc = 0.9789240801117839\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 82, train_loss = 9.610568162053823, train_acc = 0.9791569632044713\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 83, train_loss = 9.508532866835594, train_acc = 0.9791569632044713\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 84, train_loss = 9.408607803285122, train_acc = 0.9792734047508151\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 85, train_loss = 9.310215469449759, train_acc = 0.9793898462971589\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 86, train_loss = 9.212945736944675, train_acc = 0.9795062878435026\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 87, train_loss = 9.116734586656094, train_acc = 0.97973917093619\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 88, train_loss = 9.02227682992816, train_acc = 0.9800884955752213\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 89, train_loss = 8.929941672831774, train_acc = 0.9803213786679087\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 90, train_loss = 8.839203782379627, train_acc = 0.9803213786679087\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 91, train_loss = 8.750103134661913, train_acc = 0.9804378202142524\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 92, train_loss = 8.662339832633734, train_acc = 0.9804378202142524\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 93, train_loss = 8.576245903968811, train_acc = 0.9805542617605962\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 94, train_loss = 8.491545595228672, train_acc = 0.9810200279459711\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 95, train_loss = 8.408270107582211, train_acc = 0.9816022356776898\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 96, train_loss = 8.326213542371988, train_acc = 0.9818351187703773\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 97, train_loss = 8.245403988286853, train_acc = 0.9820680018630648\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 98, train_loss = 8.165873212739825, train_acc = 0.9821844434094085\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 99, train_loss = 8.087494341656566, train_acc = 0.9825337680484397\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 100, train_loss = 8.010338576510549, train_acc = 0.9827666511411272\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 101, train_loss = 7.934061046689749, train_acc = 0.9829995342338146\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 102, train_loss = 7.859083347022533, train_acc = 0.9835817419655333\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 103, train_loss = 7.785094354301691, train_acc = 0.983698183511877\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 104, train_loss = 7.712149132043123, train_acc = 0.983698183511877\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 105, train_loss = 7.640004202723503, train_acc = 0.983698183511877\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 106, train_loss = 7.569188132882118, train_acc = 0.9839310666045645\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 107, train_loss = 7.4992077350616455, train_acc = 0.9842803912435957\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 108, train_loss = 7.430150533095002, train_acc = 0.9845132743362832\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 109, train_loss = 7.362131288275123, train_acc = 0.9845132743362832\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 110, train_loss = 7.295181531459093, train_acc = 0.9850954820680019\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 111, train_loss = 7.229003457352519, train_acc = 0.9852119236143456\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 112, train_loss = 7.163808602839708, train_acc = 0.9852119236143456\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 113, train_loss = 7.099561203271151, train_acc = 0.9853283651606893\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 114, train_loss = 7.036201635375619, train_acc = 0.9853283651606893\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 115, train_loss = 6.973686546087265, train_acc = 0.9855612482533768\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 116, train_loss = 6.911992741748691, train_acc = 0.9856776897997206\n",
      "test Acc 0.9743947858472998:\n",
      "3th- epoch: 117, train_loss = 6.8511857353150845, train_acc = 0.9856776897997206\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 118, train_loss = 6.791070455685258, train_acc = 0.985910572892408\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 119, train_loss = 6.731843218207359, train_acc = 0.985910572892408\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 120, train_loss = 6.6734490897506475, train_acc = 0.985910572892408\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 121, train_loss = 6.615660643205047, train_acc = 0.985910572892408\n",
      "test Acc 0.9753258845437617:\n",
      "3th- epoch: 122, train_loss = 6.558257140219212, train_acc = 0.9860270144387517\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 123, train_loss = 6.501656278967857, train_acc = 0.9860270144387517\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 124, train_loss = 6.446325704455376, train_acc = 0.9860270144387517\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 125, train_loss = 6.391490316018462, train_acc = 0.9862598975314392\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 126, train_loss = 6.337590107694268, train_acc = 0.9864927806241267\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 127, train_loss = 6.284445630386472, train_acc = 0.9866092221704704\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 128, train_loss = 6.232112070545554, train_acc = 0.9868421052631579\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 129, train_loss = 6.18036144413054, train_acc = 0.9869585468095017\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 130, train_loss = 6.129369014874101, train_acc = 0.9871914299021891\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 131, train_loss = 6.0790277775377035, train_acc = 0.9873078714485328\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 132, train_loss = 6.0293476767838, train_acc = 0.9875407545412203\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 133, train_loss = 5.980271006003022, train_acc = 0.9877736376339078\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 134, train_loss = 5.9320114608854055, train_acc = 0.9877736376339078\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 135, train_loss = 5.884206436574459, train_acc = 0.9878900791802515\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 136, train_loss = 5.837213926017284, train_acc = 0.9880065207265952\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 137, train_loss = 5.790888965129852, train_acc = 0.9884722869119702\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 138, train_loss = 5.745134608820081, train_acc = 0.9884722869119702\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 139, train_loss = 5.699827929958701, train_acc = 0.9884722869119702\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 140, train_loss = 5.655282720923424, train_acc = 0.9885887284583139\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 141, train_loss = 5.611201880499721, train_acc = 0.9887051700046576\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 142, train_loss = 5.567965814843774, train_acc = 0.9887051700046576\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 143, train_loss = 5.524913154542446, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 144, train_loss = 5.482769917696714, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 145, train_loss = 5.440893042832613, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 146, train_loss = 5.399664064869285, train_acc = 0.9889380530973452\n",
      "test Acc 0.9762569832402235:\n",
      "3th- epoch: 147, train_loss = 5.35901471413672, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 148, train_loss = 5.318878162652254, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 149, train_loss = 5.279283000156283, train_acc = 0.9892873777363763\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 150, train_loss = 5.240186063572764, train_acc = 0.9892873777363763\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 151, train_loss = 5.201518977060914, train_acc = 0.9892873777363763\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 152, train_loss = 5.1634146347641945, train_acc = 0.9896367023754076\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 153, train_loss = 5.1257713008672, train_acc = 0.9896367023754076\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 154, train_loss = 5.088527688756585, train_acc = 0.9896367023754076\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 155, train_loss = 5.051901025697589, train_acc = 0.9897531439217513\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 156, train_loss = 5.015654725953937, train_acc = 0.9901024685607824\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 157, train_loss = 4.979821051470935, train_acc = 0.9902189101071263\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 158, train_loss = 4.94455989357084, train_acc = 0.9902189101071263\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 159, train_loss = 4.909708387218416, train_acc = 0.9904517931998137\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 160, train_loss = 4.875317760743201, train_acc = 0.9905682347461574\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 161, train_loss = 4.841210910119116, train_acc = 0.9905682347461574\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 162, train_loss = 4.807570565491915, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 163, train_loss = 4.774345528334379, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 164, train_loss = 4.741305310279131, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 165, train_loss = 4.709124077111483, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 166, train_loss = 4.676737909205258, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 167, train_loss = 4.6449562208727, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 168, train_loss = 4.613726043142378, train_acc = 0.9909175593851887\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 169, train_loss = 4.582996987737715, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 170, train_loss = 4.552481242455542, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 171, train_loss = 4.522550445981324, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 172, train_loss = 4.492791005410254, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 173, train_loss = 4.463559146039188, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 174, train_loss = 4.43459106143564, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 175, train_loss = 4.405924621038139, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 176, train_loss = 4.3777316538617015, train_acc = 0.9911504424778761\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 177, train_loss = 4.349714647047222, train_acc = 0.9912668840242198\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 178, train_loss = 4.322207625955343, train_acc = 0.9912668840242198\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 179, train_loss = 4.294895465485752, train_acc = 0.9912668840242198\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 180, train_loss = 4.268000436015427, train_acc = 0.9912668840242198\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 181, train_loss = 4.241364344954491, train_acc = 0.9912668840242198\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 182, train_loss = 4.215011835098267, train_acc = 0.9912668840242198\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 183, train_loss = 4.1889853393659, train_acc = 0.9914997671169073\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 184, train_loss = 4.163331328891218, train_acc = 0.9916162086632511\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 185, train_loss = 4.137848881073296, train_acc = 0.9916162086632511\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 186, train_loss = 4.112751110456884, train_acc = 0.9917326502095948\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 187, train_loss = 4.0879921251907945, train_acc = 0.9917326502095948\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 188, train_loss = 4.063216718845069, train_acc = 0.9917326502095948\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 189, train_loss = 4.039023645222187, train_acc = 0.9917326502095948\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 190, train_loss = 4.014805124141276, train_acc = 0.9917326502095948\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 191, train_loss = 3.9911261508241296, train_acc = 0.9917326502095948\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 192, train_loss = 3.967530065216124, train_acc = 0.9918490917559385\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 193, train_loss = 3.944229196757078, train_acc = 0.9919655333022822\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 194, train_loss = 3.9212480997666717, train_acc = 0.9919655333022822\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 195, train_loss = 3.8984752548858523, train_acc = 0.9919655333022822\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 196, train_loss = 3.8759101293981075, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 197, train_loss = 3.853756684809923, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 198, train_loss = 3.8315787641331553, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 199, train_loss = 3.8099305173382163, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 200, train_loss = 3.7883541425690055, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 201, train_loss = 3.7669600462540984, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 202, train_loss = 3.745799877680838, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 203, train_loss = 3.7250947086140513, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 204, train_loss = 3.704281695187092, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 205, train_loss = 3.6840089643374085, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 206, train_loss = 3.663680703379214, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 207, train_loss = 3.6436843583360314, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 208, train_loss = 3.6238371161744, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 209, train_loss = 3.604295742698014, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 210, train_loss = 3.5848265876993537, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 211, train_loss = 3.565590844489634, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 212, train_loss = 3.5465883696451783, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 213, train_loss = 3.5277644554153085, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 214, train_loss = 3.5091441897675395, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 215, train_loss = 3.4906149143353105, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 216, train_loss = 3.4723248444497585, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 217, train_loss = 3.454169798642397, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 218, train_loss = 3.4362091468647122, train_acc = 0.9925477410340009\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 219, train_loss = 3.418359608389437, train_acc = 0.9927806241266884\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 220, train_loss = 3.40091057959944, train_acc = 0.9927806241266884\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 221, train_loss = 3.3833741461858153, train_acc = 0.9928970656730322\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 222, train_loss = 3.366106517612934, train_acc = 0.9928970656730322\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 223, train_loss = 3.348900912795216, train_acc = 0.9928970656730322\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 224, train_loss = 3.3321680924855173, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 225, train_loss = 3.3152382038533688, train_acc = 0.9930135072193759\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 226, train_loss = 3.2986488579772413, train_acc = 0.9930135072193759\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 227, train_loss = 3.282243321184069, train_acc = 0.9930135072193759\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 228, train_loss = 3.2658980577252805, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 229, train_loss = 3.2496797651983798, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 230, train_loss = 3.233675581868738, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 231, train_loss = 3.217889465391636, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 232, train_loss = 3.202078152447939, train_acc = 0.9931299487657196\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 233, train_loss = 3.1865323148667812, train_acc = 0.9931299487657196\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 234, train_loss = 3.171033544000238, train_acc = 0.9931299487657196\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 235, train_loss = 3.155807411763817, train_acc = 0.9932463903120633\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 236, train_loss = 3.1406011092476547, train_acc = 0.9932463903120633\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 237, train_loss = 3.125449249520898, train_acc = 0.9932463903120633\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 238, train_loss = 3.1105400193482637, train_acc = 0.9933628318584071\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 239, train_loss = 3.096035771071911, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 240, train_loss = 3.081267972011119, train_acc = 0.9937121564974383\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 241, train_loss = 3.0669083441607654, train_acc = 0.9937121564974383\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 242, train_loss = 3.0526833101175725, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 243, train_loss = 3.038303182926029, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 244, train_loss = 3.0244940710254014, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 245, train_loss = 3.0102918609045446, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 246, train_loss = 2.9967532102018595, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 247, train_loss = 2.982895886991173, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 248, train_loss = 2.969307483639568, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 249, train_loss = 2.9560288786888123, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 250, train_loss = 2.942491285968572, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 251, train_loss = 2.9294899608939886, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 252, train_loss = 2.9162694117985666, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 253, train_loss = 2.9033268857747316, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 254, train_loss = 2.890377812553197, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 255, train_loss = 2.877642694860697, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 256, train_loss = 2.86506663588807, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 257, train_loss = 2.8525075311772525, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 258, train_loss = 2.8399494104087353, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 259, train_loss = 2.827876705676317, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 260, train_loss = 2.815522938966751, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 261, train_loss = 2.8035061373375356, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 262, train_loss = 2.791521026287228, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 263, train_loss = 2.7795824795030057, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 264, train_loss = 2.7677777358330786, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 265, train_loss = 2.7562820739112794, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 266, train_loss = 2.7444230802357197, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 267, train_loss = 2.73315409431234, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 268, train_loss = 2.7217497788369656, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 269, train_loss = 2.710484318435192, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 270, train_loss = 2.6993726156651974, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 271, train_loss = 2.688201356679201, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 272, train_loss = 2.677257100585848, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 273, train_loss = 2.6663747974671423, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 274, train_loss = 2.6556490450166166, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 275, train_loss = 2.6449187719263136, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 276, train_loss = 2.634314600378275, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 277, train_loss = 2.623803660273552, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 278, train_loss = 2.6134970635175705, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 279, train_loss = 2.6030681184493005, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 280, train_loss = 2.5927919051609933, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 281, train_loss = 2.582662863191217, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 282, train_loss = 2.5727416039444506, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 283, train_loss = 2.562650957610458, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 284, train_loss = 2.552799567580223, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 285, train_loss = 2.5429544537328184, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 286, train_loss = 2.533213660120964, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 287, train_loss = 2.523711597081274, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 288, train_loss = 2.513937786221504, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 289, train_loss = 2.5046819858253, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 290, train_loss = 2.4951949268579483, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 291, train_loss = 2.485793481115252, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 292, train_loss = 2.476723099593073, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 293, train_loss = 2.4676728136837482, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 294, train_loss = 2.4585673944093287, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 295, train_loss = 2.449588405434042, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 296, train_loss = 2.4409003481268883, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 297, train_loss = 2.4320529885590076, train_acc = 0.9947601304145319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 298, train_loss = 2.4233957580290735, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 299, train_loss = 2.414787174668163, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 300, train_loss = 2.4062571763060987, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 301, train_loss = 2.3979153498075902, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 302, train_loss = 2.3895509294234216, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 303, train_loss = 2.381127232220024, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 304, train_loss = 2.3730688132345676, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 305, train_loss = 2.3648737906478345, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 306, train_loss = 2.356870652642101, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 307, train_loss = 2.3487768322229385, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 308, train_loss = 2.3410641860682517, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 309, train_loss = 2.333171270787716, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 310, train_loss = 2.3253516033291817, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 311, train_loss = 2.317770400317386, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 312, train_loss = 2.3101858694572, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 313, train_loss = 2.302562914788723, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 314, train_loss = 2.2952887553256005, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 315, train_loss = 2.287849050015211, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 316, train_loss = 2.2803983974736184, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 317, train_loss = 2.2732014420907944, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 318, train_loss = 2.2661029659211636, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 319, train_loss = 2.2590857099276036, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 320, train_loss = 2.2518038116395473, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 321, train_loss = 2.244966061087325, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 322, train_loss = 2.238155296770856, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 323, train_loss = 2.231136381626129, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 324, train_loss = 2.224317779066041, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 325, train_loss = 2.217746273847297, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 326, train_loss = 2.2110445101279765, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 327, train_loss = 2.2043484959285706, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 328, train_loss = 2.1978227954823524, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 329, train_loss = 2.1915472459513694, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 330, train_loss = 2.185055038658902, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 331, train_loss = 2.178492208244279, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 332, train_loss = 2.1723451626021415, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 333, train_loss = 2.166052558692172, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 334, train_loss = 2.1599201932549477, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 335, train_loss = 2.1535344410222024, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 336, train_loss = 2.147522371262312, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 337, train_loss = 2.1415571917314082, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 338, train_loss = 2.1353835698682815, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 339, train_loss = 2.1294557985384017, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 340, train_loss = 2.1236582447309047, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 341, train_loss = 2.117907169042155, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 342, train_loss = 2.111982484580949, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 343, train_loss = 2.1063964057248086, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 344, train_loss = 2.100609776796773, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 345, train_loss = 2.0950593177694827, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 346, train_loss = 2.0894895307719707, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 347, train_loss = 2.084028981626034, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 348, train_loss = 2.078496066154912, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 349, train_loss = 2.073115289211273, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 350, train_loss = 2.067621347727254, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 351, train_loss = 2.062432985752821, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 352, train_loss = 2.05715070781298, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 353, train_loss = 2.051897395402193, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 354, train_loss = 2.0467150050681084, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 355, train_loss = 2.0416632778942585, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 356, train_loss = 2.036429662257433, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 357, train_loss = 2.031389740528539, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 358, train_loss = 2.0264299761038274, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 359, train_loss = 2.0215537648182362, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 360, train_loss = 2.0164717722218484, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 361, train_loss = 2.0116395007353276, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 362, train_loss = 2.006809212267399, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 363, train_loss = 2.001960291294381, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 364, train_loss = 1.997165946988389, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 365, train_loss = 1.9923589553218335, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 366, train_loss = 1.9877444915473461, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 367, train_loss = 1.9830195817630738, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 368, train_loss = 1.9784554466605186, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 369, train_loss = 1.973889583023265, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 370, train_loss = 1.9693810876924545, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 371, train_loss = 1.9649251166265458, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 372, train_loss = 1.9603653599042445, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 373, train_loss = 1.956017355201766, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 374, train_loss = 1.9515482857823372, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 375, train_loss = 1.9472228151280433, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 376, train_loss = 1.942872269777581, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 377, train_loss = 1.9386496108490974, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 378, train_loss = 1.9343620613217354, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 379, train_loss = 1.9301068733911961, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 380, train_loss = 1.925919843139127, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 381, train_loss = 1.9217877946794033, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 382, train_loss = 1.9177240394055843, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 383, train_loss = 1.9135075074154884, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 384, train_loss = 1.9095896508079022, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 385, train_loss = 1.9055450421292335, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 386, train_loss = 1.9015666793566197, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 387, train_loss = 1.8974472645204514, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 388, train_loss = 1.8935945380944759, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 389, train_loss = 1.8897074374835938, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 390, train_loss = 1.885867953300476, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 391, train_loss = 1.8818937055766582, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 392, train_loss = 1.878124951152131, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 393, train_loss = 1.8745279673021287, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 394, train_loss = 1.8706613617250696, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 395, train_loss = 1.86684677132871, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 396, train_loss = 1.8631495783338323, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 397, train_loss = 1.8596069688210264, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 398, train_loss = 1.8558977333595976, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 399, train_loss = 1.8524094572057948, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 400, train_loss = 1.8487455634167418, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 401, train_loss = 1.8451167879393324, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 402, train_loss = 1.8415583334863186, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 403, train_loss = 1.8381722258636728, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 404, train_loss = 1.834643910289742, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 405, train_loss = 1.831220873980783, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 406, train_loss = 1.827639358700253, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 407, train_loss = 1.8245612730970606, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 408, train_loss = 1.8209544494748116, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 409, train_loss = 1.81763704365585, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 410, train_loss = 1.8143683274975047, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 411, train_loss = 1.8110075244912878, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 412, train_loss = 1.8078476985683665, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 413, train_loss = 1.8046027831733227, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 414, train_loss = 1.8011643961071968, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 415, train_loss = 1.7980296040186659, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 416, train_loss = 1.7950116085121408, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 417, train_loss = 1.791659756214358, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 418, train_loss = 1.7884866992244497, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 419, train_loss = 1.785701526910998, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 420, train_loss = 1.782436277717352, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 421, train_loss = 1.7792296459665522, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 422, train_loss = 1.7763453548541293, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 423, train_loss = 1.7732255334267393, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 424, train_loss = 1.7702618638286367, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 425, train_loss = 1.7674584625056013, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 426, train_loss = 1.7642906258115545, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 427, train_loss = 1.761348178028129, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 428, train_loss = 1.7585529051721096, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 429, train_loss = 1.7555369809269905, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 430, train_loss = 1.752639745711349, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 431, train_loss = 1.749808250577189, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 432, train_loss = 1.7470773285022005, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 433, train_loss = 1.7442362928995863, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 434, train_loss = 1.7413569142809138, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 435, train_loss = 1.738693626015447, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 436, train_loss = 1.7357479259371758, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 437, train_loss = 1.733289131312631, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 438, train_loss = 1.7304531360277906, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 439, train_loss = 1.7276769975433126, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 440, train_loss = 1.7252761622658, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 441, train_loss = 1.7224471593508497, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 442, train_loss = 1.7197232767939568, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 443, train_loss = 1.717357980669476, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 444, train_loss = 1.7145708365133032, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 445, train_loss = 1.7118829576065764, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 446, train_loss = 1.7096466844668612, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 447, train_loss = 1.706794155179523, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 448, train_loss = 1.7044320292770863, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 449, train_loss = 1.7019272707402706, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 450, train_loss = 1.6992625085404143, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 451, train_loss = 1.6968974681803957, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 452, train_loss = 1.6944488808512688, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 453, train_loss = 1.6920257644960657, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 454, train_loss = 1.6893695431062952, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 455, train_loss = 1.6871155723929405, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 456, train_loss = 1.6848017735173926, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 457, train_loss = 1.6821668049087748, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 458, train_loss = 1.680177646339871, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 459, train_loss = 1.6774047687649727, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 460, train_loss = 1.6752928519854322, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 461, train_loss = 1.6728707315633073, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 462, train_loss = 1.6705367788672447, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 463, train_loss = 1.6684783125529066, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 464, train_loss = 1.6658763798186556, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 465, train_loss = 1.6638481816044077, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 466, train_loss = 1.6614124216139317, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 467, train_loss = 1.6592271961271763, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 468, train_loss = 1.6571738794445992, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 469, train_loss = 1.654845637618564, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 470, train_loss = 1.6526326661696658, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 471, train_loss = 1.6505630140891299, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 472, train_loss = 1.6482661055633798, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 473, train_loss = 1.6461249081185088, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 474, train_loss = 1.6440450152149424, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 475, train_loss = 1.642010765732266, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 476, train_loss = 1.639758242876269, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 477, train_loss = 1.637839519768022, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 478, train_loss = 1.6357574661960825, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 479, train_loss = 1.6335996525594965, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 480, train_loss = 1.6315033385762945, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 481, train_loss = 1.6295691704144701, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 482, train_loss = 1.6274603182682768, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 483, train_loss = 1.6253377720713615, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 484, train_loss = 1.6234827935695648, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 485, train_loss = 1.621506705880165, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 486, train_loss = 1.6194233124842867, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 487, train_loss = 1.617489187628962, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 488, train_loss = 1.6155168315162882, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 489, train_loss = 1.6136616617441177, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 490, train_loss = 1.6116532422602177, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 491, train_loss = 1.609952300786972, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 492, train_loss = 1.6079623773694038, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 493, train_loss = 1.606109137297608, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 494, train_loss = 1.6041173512348905, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 495, train_loss = 1.602256859303452, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 496, train_loss = 1.6003647483885288, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 497, train_loss = 1.5986096238484606, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 498, train_loss = 1.5967443846166134, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "3th- epoch: 499, train_loss = 1.5949735554168, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▎                                                                 | 3/30 [19:56<2:59:36, 399.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "4th- epoch: 0, train_loss = 274.69185411930084, train_acc = 0.4469026548672566\n",
      "test Acc 0.49813780260707635:\n",
      "4th- epoch: 1, train_loss = 212.43466222286224, train_acc = 0.5001164415463437\n",
      "test Acc 0.5009310986964618:\n",
      "4th- epoch: 2, train_loss = 167.38458067178726, train_acc = 0.5209594783418724\n",
      "test Acc 0.5516759776536313:\n",
      "4th- epoch: 3, train_loss = 144.29640716314316, train_acc = 0.6448532836516069\n",
      "test Acc 0.6987895716945997:\n",
      "4th- epoch: 4, train_loss = 125.99053710699081, train_acc = 0.7136702375407545\n",
      "test Acc 0.7295158286778398:\n",
      "4th- epoch: 5, train_loss = 110.52159512042999, train_acc = 0.7360270144387517\n",
      "test Acc 0.7565176908752328:\n",
      "4th- epoch: 6, train_loss = 97.81631463766098, train_acc = 0.7616441546343735\n",
      "test Acc 0.7802607076350093:\n",
      "4th- epoch: 7, train_loss = 87.25956371426582, train_acc = 0.7913367489520261\n",
      "test Acc 0.8100558659217877:\n",
      "4th- epoch: 8, train_loss = 78.16298049688339, train_acc = 0.8247554727526781\n",
      "test Acc 0.8375232774674115:\n",
      "4th- epoch: 9, train_loss = 70.14166370034218, train_acc = 0.847694457382394\n",
      "test Acc 0.8608007448789572:\n",
      "4th- epoch: 10, train_loss = 63.09275883436203, train_acc = 0.8721471821145785\n",
      "test Acc 0.8794227188081937:\n",
      "4th- epoch: 11, train_loss = 57.033603087067604, train_acc = 0.8880996739636703\n",
      "test Acc 0.8896648044692738:\n",
      "4th- epoch: 12, train_loss = 51.92493835091591, train_acc = 0.8949697251979506\n",
      "test Acc 0.8980446927374302:\n",
      "4th- epoch: 13, train_loss = 47.653271555900574, train_acc = 0.9087098276665114\n",
      "test Acc 0.9143389199255121:\n",
      "4th- epoch: 14, train_loss = 44.066977098584175, train_acc = 0.9203539823008849\n",
      "test Acc 0.9269087523277467:\n",
      "4th- epoch: 15, train_loss = 41.02685798704624, train_acc = 0.9289706567303214\n",
      "test Acc 0.9324953445065177:\n",
      "4th- epoch: 16, train_loss = 38.41978305578232, train_acc = 0.9336283185840708\n",
      "test Acc 0.9366852886405959:\n",
      "4th- epoch: 17, train_loss = 36.175417765975, train_acc = 0.9374708896134141\n",
      "test Acc 0.9380819366852886:\n",
      "4th- epoch: 18, train_loss = 34.229601852595806, train_acc = 0.9406148113646949\n",
      "test Acc 0.9399441340782123:\n",
      "4th- epoch: 19, train_loss = 32.52373240143061, train_acc = 0.9431765253842571\n",
      "test Acc 0.9436685288640596:\n",
      "4th- epoch: 20, train_loss = 31.016445726156235, train_acc = 0.9493479273404751\n",
      "test Acc 0.9445996275605214:\n",
      "4th- epoch: 21, train_loss = 29.67595338076353, train_acc = 0.9507452258965999\n",
      "test Acc 0.9445996275605214:\n",
      "4th- epoch: 22, train_loss = 28.47538150846958, train_acc = 0.9516767582673498\n",
      "test Acc 0.9450651769087524:\n",
      "4th- epoch: 23, train_loss = 27.392776399850845, train_acc = 0.9526082906380997\n",
      "test Acc 0.946927374301676:\n",
      "4th- epoch: 24, train_loss = 26.409302547574043, train_acc = 0.9538891476478808\n",
      "test Acc 0.9473929236499069:\n",
      "4th- epoch: 25, train_loss = 25.512363649904728, train_acc = 0.9548206800186306\n",
      "test Acc 0.9492551210428305:\n",
      "4th- epoch: 26, train_loss = 24.690152935683727, train_acc = 0.955985095482068\n",
      "test Acc 0.9506517690875232:\n",
      "4th- epoch: 27, train_loss = 23.932939521968365, train_acc = 0.9573823940381928\n",
      "test Acc 0.9515828677839852:\n",
      "4th- epoch: 28, train_loss = 23.23249378427863, train_acc = 0.9579646017699115\n",
      "test Acc 0.9534450651769087:\n",
      "4th- epoch: 29, train_loss = 22.5820746794343, train_acc = 0.9590125756870052\n",
      "test Acc 0.9534450651769087:\n",
      "4th- epoch: 30, train_loss = 21.975734394043684, train_acc = 0.9595947834187238\n",
      "test Acc 0.9543761638733705:\n",
      "4th- epoch: 31, train_loss = 21.40863300487399, train_acc = 0.96040987424313\n",
      "test Acc 0.9543761638733705:\n",
      "4th- epoch: 32, train_loss = 20.876312043517828, train_acc = 0.9613414066138798\n",
      "test Acc 0.9557728119180633:\n",
      "4th- epoch: 33, train_loss = 20.37529433518648, train_acc = 0.9615742897065673\n",
      "test Acc 0.9557728119180633:\n",
      "4th- epoch: 34, train_loss = 19.90230468660593, train_acc = 0.9619236143455985\n",
      "test Acc 0.9562383612662942:\n",
      "4th- epoch: 35, train_loss = 19.453976321965456, train_acc = 0.9626222636236609\n",
      "test Acc 0.9567039106145251:\n",
      "4th- epoch: 36, train_loss = 19.02814321964979, train_acc = 0.9629715882626921\n",
      "test Acc 0.9567039106145251:\n",
      "4th- epoch: 37, train_loss = 18.623419113457203, train_acc = 0.9636702375407545\n",
      "test Acc 0.9581005586592178:\n",
      "4th- epoch: 38, train_loss = 18.23841806873679, train_acc = 0.9647182114578482\n",
      "test Acc 0.9590316573556797:\n",
      "4th- epoch: 39, train_loss = 17.871583856642246, train_acc = 0.9654168607359106\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 40, train_loss = 17.520709615200758, train_acc = 0.9662319515603167\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 41, train_loss = 17.185315396636724, train_acc = 0.9668141592920354\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 42, train_loss = 16.863788466900587, train_acc = 0.9676292501164415\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 43, train_loss = 16.555326025933027, train_acc = 0.9680950163018165\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 44, train_loss = 16.258998297154903, train_acc = 0.9690265486725663\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 45, train_loss = 15.97399989888072, train_acc = 0.9693758733115976\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 46, train_loss = 15.699577644467354, train_acc = 0.9697251979506288\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 47, train_loss = 15.435157433152199, train_acc = 0.9701909641360037\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 48, train_loss = 15.179643463343382, train_acc = 0.9704238472286912\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 49, train_loss = 14.932625152170658, train_acc = 0.9712389380530974\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 50, train_loss = 14.693658746778965, train_acc = 0.9715882626921285\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 51, train_loss = 14.46231421455741, train_acc = 0.9719375873311598\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 52, train_loss = 14.23792551457882, train_acc = 0.972286911970191\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 53, train_loss = 14.02055737376213, train_acc = 0.9729855612482534\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 54, train_loss = 13.809960849583149, train_acc = 0.9735677689799721\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 55, train_loss = 13.605777483433485, train_acc = 0.9739170936190032\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 56, train_loss = 13.407779518514872, train_acc = 0.9744993013507219\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 57, train_loss = 13.215806730091572, train_acc = 0.9744993013507219\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 58, train_loss = 13.029485832899809, train_acc = 0.9746157428970657\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 59, train_loss = 12.847977854311466, train_acc = 0.9748486259897532\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 60, train_loss = 12.671435832977295, train_acc = 0.9750815090824406\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 61, train_loss = 12.499657310545444, train_acc = 0.975314392175128\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 62, train_loss = 12.332574605941772, train_acc = 0.9756637168141593\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 63, train_loss = 12.169629581272602, train_acc = 0.9756637168141593\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 64, train_loss = 12.011158853769302, train_acc = 0.9758965999068467\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 65, train_loss = 11.856796588748693, train_acc = 0.976245924545878\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 66, train_loss = 11.706372981891036, train_acc = 0.9764788076385654\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 67, train_loss = 11.559460122138262, train_acc = 0.9774103400093154\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 68, train_loss = 11.41639830172062, train_acc = 0.9775267815556591\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 69, train_loss = 11.276645746082067, train_acc = 0.9778761061946902\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 70, train_loss = 11.14001141116023, train_acc = 0.977992547741034\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 71, train_loss = 11.006623096764088, train_acc = 0.9783418723800652\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 72, train_loss = 10.876284204423428, train_acc = 0.9783418723800652\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 73, train_loss = 10.749039754271507, train_acc = 0.9788076385654402\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 74, train_loss = 10.624196134507656, train_acc = 0.9788076385654402\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 75, train_loss = 10.502200577408075, train_acc = 0.9790405216581276\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 76, train_loss = 10.38284631446004, train_acc = 0.9791569632044713\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 77, train_loss = 10.265835974365473, train_acc = 0.9793898462971589\n",
      "test Acc 0.9702048417132216:\n",
      "4th- epoch: 78, train_loss = 10.151488408446312, train_acc = 0.9795062878435026\n",
      "test Acc 0.9702048417132216:\n",
      "4th- epoch: 79, train_loss = 10.039309352636337, train_acc = 0.97973917093619\n",
      "test Acc 0.9702048417132216:\n",
      "4th- epoch: 80, train_loss = 9.929338157176971, train_acc = 0.97973917093619\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 81, train_loss = 9.821563243865967, train_acc = 0.9800884955752213\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 82, train_loss = 9.71570249646902, train_acc = 0.9803213786679087\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 83, train_loss = 9.611579988151789, train_acc = 0.9804378202142524\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 84, train_loss = 9.509463921189308, train_acc = 0.9807871448532837\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 85, train_loss = 9.408957671374083, train_acc = 0.9810200279459711\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 86, train_loss = 9.310355205088854, train_acc = 0.9811364694923148\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 87, train_loss = 9.213298369199038, train_acc = 0.9813693525850024\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 88, train_loss = 9.117691680788994, train_acc = 0.9812529110386586\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 89, train_loss = 9.02357211522758, train_acc = 0.9816022356776898\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 90, train_loss = 8.930568523705006, train_acc = 0.9816022356776898\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 91, train_loss = 8.83860257267952, train_acc = 0.9816022356776898\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 92, train_loss = 8.747914351522923, train_acc = 0.9817186772240335\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 93, train_loss = 8.658990394324064, train_acc = 0.9817186772240335\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 94, train_loss = 8.571780070662498, train_acc = 0.9820680018630648\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 95, train_loss = 8.486106134951115, train_acc = 0.9821844434094085\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 96, train_loss = 8.40186314471066, train_acc = 0.9825337680484397\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 97, train_loss = 8.318818725645542, train_acc = 0.9827666511411272\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 98, train_loss = 8.236994436010718, train_acc = 0.9828830926874709\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 99, train_loss = 8.156173193827271, train_acc = 0.9832324173265021\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 100, train_loss = 8.076453320682049, train_acc = 0.9833488588728458\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 101, train_loss = 7.9979114681482315, train_acc = 0.9838146250582208\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 102, train_loss = 7.92085743136704, train_acc = 0.9838146250582208\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 103, train_loss = 7.844703646376729, train_acc = 0.9839310666045645\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 104, train_loss = 7.769867965951562, train_acc = 0.9840475081509082\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 105, train_loss = 7.695850729942322, train_acc = 0.9847461574289706\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 106, train_loss = 7.622796365991235, train_acc = 0.9847461574289706\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 107, train_loss = 7.550888504832983, train_acc = 0.9848625989753144\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 108, train_loss = 7.4798528999090195, train_acc = 0.9848625989753144\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 109, train_loss = 7.409988552331924, train_acc = 0.9848625989753144\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 110, train_loss = 7.340995525941253, train_acc = 0.9849790405216581\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 111, train_loss = 7.272905362769961, train_acc = 0.9849790405216581\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 112, train_loss = 7.205834439024329, train_acc = 0.9848625989753144\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 113, train_loss = 7.139643680304289, train_acc = 0.9850954820680019\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 114, train_loss = 7.0744824931025505, train_acc = 0.9850954820680019\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 115, train_loss = 7.010076805949211, train_acc = 0.9852119236143456\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 116, train_loss = 6.946644494310021, train_acc = 0.9853283651606893\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 117, train_loss = 6.884145321324468, train_acc = 0.985444806707033\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 118, train_loss = 6.82249641045928, train_acc = 0.985444806707033\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 119, train_loss = 6.761651793494821, train_acc = 0.9855612482533768\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 120, train_loss = 6.701767455786467, train_acc = 0.9855612482533768\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 121, train_loss = 6.642543900758028, train_acc = 0.9857941313460643\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 122, train_loss = 6.584160320460796, train_acc = 0.9860270144387517\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 123, train_loss = 6.526676682755351, train_acc = 0.9861434559850955\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 124, train_loss = 6.469751885160804, train_acc = 0.9866092221704704\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 125, train_loss = 6.413538169115782, train_acc = 0.9868421052631579\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 126, train_loss = 6.358111014589667, train_acc = 0.9870749883558454\n",
      "test Acc 0.9753258845437617:\n",
      "4th- epoch: 127, train_loss = 6.303561083972454, train_acc = 0.9873078714485328\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 128, train_loss = 6.249760689213872, train_acc = 0.9875407545412203\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 129, train_loss = 6.196705533191562, train_acc = 0.9875407545412203\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 130, train_loss = 6.144294956699014, train_acc = 0.9876571960875641\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 131, train_loss = 6.092555386945605, train_acc = 0.9876571960875641\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 132, train_loss = 6.041488306596875, train_acc = 0.9878900791802515\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 133, train_loss = 5.991136843338609, train_acc = 0.9881229622729389\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 134, train_loss = 5.941443465650082, train_acc = 0.9882394038192828\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 135, train_loss = 5.892468690872192, train_acc = 0.9882394038192828\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 136, train_loss = 5.844406079500914, train_acc = 0.9883558453656265\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 137, train_loss = 5.796731607988477, train_acc = 0.9884722869119702\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 138, train_loss = 5.749981787055731, train_acc = 0.9885887284583139\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 139, train_loss = 5.703637953847647, train_acc = 0.9885887284583139\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 140, train_loss = 5.657955143600702, train_acc = 0.9888216115510013\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 141, train_loss = 5.613070482388139, train_acc = 0.9889380530973452\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 142, train_loss = 5.5684382151812315, train_acc = 0.9889380530973452\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 143, train_loss = 5.524604139849544, train_acc = 0.9889380530973452\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 144, train_loss = 5.481250895187259, train_acc = 0.9889380530973452\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 145, train_loss = 5.4384756702929735, train_acc = 0.9890544946436889\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 146, train_loss = 5.396224105730653, train_acc = 0.9891709361900326\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 147, train_loss = 5.354665046557784, train_acc = 0.9891709361900326\n",
      "test Acc 0.9762569832402235:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 148, train_loss = 5.313551949337125, train_acc = 0.9892873777363763\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 149, train_loss = 5.2730876337736845, train_acc = 0.9895202608290639\n",
      "test Acc 0.9767225325884544:\n",
      "4th- epoch: 150, train_loss = 5.233186053112149, train_acc = 0.9896367023754076\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 151, train_loss = 5.193720448762178, train_acc = 0.9896367023754076\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 152, train_loss = 5.154971560463309, train_acc = 0.9897531439217513\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 153, train_loss = 5.1164545211941, train_acc = 0.989869585468095\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 154, train_loss = 5.0785632859915495, train_acc = 0.989869585468095\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 155, train_loss = 5.041061174124479, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 156, train_loss = 5.004031367599964, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 157, train_loss = 4.967413118109107, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 158, train_loss = 4.931323565542698, train_acc = 0.99033535165347\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 159, train_loss = 4.8956841845065355, train_acc = 0.99033535165347\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 160, train_loss = 4.860435822978616, train_acc = 0.99033535165347\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 161, train_loss = 4.8257130132988095, train_acc = 0.99033535165347\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 162, train_loss = 4.791436675004661, train_acc = 0.99033535165347\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 163, train_loss = 4.757611820474267, train_acc = 0.9904517931998137\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 164, train_loss = 4.724094660952687, train_acc = 0.9904517931998137\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 165, train_loss = 4.691055058501661, train_acc = 0.9904517931998137\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 166, train_loss = 4.658308525569737, train_acc = 0.990801117838845\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 167, train_loss = 4.626187028363347, train_acc = 0.990801117838845\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 168, train_loss = 4.594160836189985, train_acc = 0.990801117838845\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 169, train_loss = 4.562598128803074, train_acc = 0.990801117838845\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 170, train_loss = 4.5315438359975815, train_acc = 0.9909175593851887\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 171, train_loss = 4.500850250013173, train_acc = 0.9909175593851887\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 172, train_loss = 4.4707757933065295, train_acc = 0.9910340009315324\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 173, train_loss = 4.4408153193071485, train_acc = 0.9910340009315324\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 174, train_loss = 4.411410463042557, train_acc = 0.9912668840242198\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 175, train_loss = 4.382245014421642, train_acc = 0.9912668840242198\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 176, train_loss = 4.353387903422117, train_acc = 0.9914997671169073\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 177, train_loss = 4.325134520418942, train_acc = 0.9914997671169073\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 178, train_loss = 4.296886891126633, train_acc = 0.9914997671169073\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 179, train_loss = 4.269140048883855, train_acc = 0.9916162086632511\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 180, train_loss = 4.2417785711586475, train_acc = 0.9916162086632511\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 181, train_loss = 4.214577227830887, train_acc = 0.9916162086632511\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 182, train_loss = 4.187866206280887, train_acc = 0.9916162086632511\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 183, train_loss = 4.161475744098425, train_acc = 0.9916162086632511\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 184, train_loss = 4.135317903012037, train_acc = 0.9917326502095948\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 185, train_loss = 4.109449370764196, train_acc = 0.9917326502095948\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 186, train_loss = 4.083985161036253, train_acc = 0.9918490917559385\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 187, train_loss = 4.058729913085699, train_acc = 0.9918490917559385\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 188, train_loss = 4.033798422664404, train_acc = 0.9918490917559385\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 189, train_loss = 4.009083520621061, train_acc = 0.9919655333022822\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 190, train_loss = 3.9847113005816936, train_acc = 0.9919655333022822\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 191, train_loss = 3.9605846777558327, train_acc = 0.9919655333022822\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 192, train_loss = 3.936729251407087, train_acc = 0.992081974848626\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 193, train_loss = 3.913035210222006, train_acc = 0.992081974848626\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 194, train_loss = 3.889754698611796, train_acc = 0.992081974848626\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 195, train_loss = 3.866682172752917, train_acc = 0.992081974848626\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 196, train_loss = 3.843909396789968, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 197, train_loss = 3.8214083509519696, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 198, train_loss = 3.7992134829983115, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 199, train_loss = 3.7772072106599808, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 200, train_loss = 3.7554975347593427, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 201, train_loss = 3.734019418247044, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 202, train_loss = 3.7127700252458453, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 203, train_loss = 3.691688373684883, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 204, train_loss = 3.6708874432370067, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 205, train_loss = 3.650354719720781, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 206, train_loss = 3.629971363581717, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 207, train_loss = 3.6099901096895337, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 208, train_loss = 3.5900181299075484, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 209, train_loss = 3.5702851423993707, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 210, train_loss = 3.5508692106232047, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 211, train_loss = 3.5315653951838613, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 212, train_loss = 3.5124524738639593, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 213, train_loss = 3.4936118768528104, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 214, train_loss = 3.4749690303578973, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 215, train_loss = 3.456412248313427, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 216, train_loss = 3.438116194680333, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 217, train_loss = 3.4200796093791723, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 218, train_loss = 3.4021507571451366, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 219, train_loss = 3.3843660461716354, train_acc = 0.9927806241266884\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 220, train_loss = 3.3668227824382484, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 221, train_loss = 3.3493997962214053, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 222, train_loss = 3.332139438483864, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 223, train_loss = 3.315147712826729, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 224, train_loss = 3.2982469028793275, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 225, train_loss = 3.2815605639480054, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 226, train_loss = 3.2651738673448563, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 227, train_loss = 3.248709908220917, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 228, train_loss = 3.2326200045645237, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 229, train_loss = 3.2167371339164674, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 230, train_loss = 3.200758637394756, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 231, train_loss = 3.185079148504883, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 232, train_loss = 3.1695029833354056, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 233, train_loss = 3.154266268014908, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 234, train_loss = 3.1388870389200747, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 235, train_loss = 3.123794054146856, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 236, train_loss = 3.1089903651736677, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 237, train_loss = 3.0940529219806194, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 238, train_loss = 3.0794513137079775, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 239, train_loss = 3.064915625844151, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 240, train_loss = 3.050466315355152, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 241, train_loss = 3.0361153297126293, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "4th- epoch: 242, train_loss = 3.022098687943071, train_acc = 0.9935957149510946\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 243, train_loss = 3.0079420530237257, train_acc = 0.9935957149510946\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 244, train_loss = 2.994138341397047, train_acc = 0.9935957149510946\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 245, train_loss = 2.9804034852422774, train_acc = 0.9937121564974383\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 246, train_loss = 2.966651959810406, train_acc = 0.9937121564974383\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 247, train_loss = 2.953248185571283, train_acc = 0.9937121564974383\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 248, train_loss = 2.939856438431889, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 249, train_loss = 2.9265357689000666, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 250, train_loss = 2.9135646014474332, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 251, train_loss = 2.9004231370054185, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 252, train_loss = 2.8875794783234596, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 253, train_loss = 2.8747677258215845, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 254, train_loss = 2.8622018597088754, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 255, train_loss = 2.8496206984855235, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 256, train_loss = 2.837196899112314, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 257, train_loss = 2.8248699717223644, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 258, train_loss = 2.8126414604485035, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 259, train_loss = 2.8005316206254065, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 260, train_loss = 2.7886150791309774, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 261, train_loss = 2.776666787918657, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 262, train_loss = 2.7649908647872508, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 263, train_loss = 2.753170418087393, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 264, train_loss = 2.741733687464148, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 265, train_loss = 2.7301360182464123, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 266, train_loss = 2.718813233077526, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 267, train_loss = 2.7075779736042023, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 268, train_loss = 2.696289302315563, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 269, train_loss = 2.6853596628643572, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 270, train_loss = 2.674407252576202, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 271, train_loss = 2.663473346736282, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 272, train_loss = 2.6526498273015022, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 273, train_loss = 2.6420626118779182, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 274, train_loss = 2.631380718201399, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 275, train_loss = 2.6209272728301585, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 276, train_loss = 2.6105093606747687, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 277, train_loss = 2.6001790673471987, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 278, train_loss = 2.5899376296438277, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 279, train_loss = 2.5798234245739877, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 280, train_loss = 2.569739507045597, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 281, train_loss = 2.559800684452057, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 282, train_loss = 2.549928931053728, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 283, train_loss = 2.5401185913942754, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 284, train_loss = 2.530477533582598, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 285, train_loss = 2.5209261826239526, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 286, train_loss = 2.511346608400345, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 287, train_loss = 2.5017845008987933, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 288, train_loss = 2.4923865993041545, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 289, train_loss = 2.483243976952508, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 290, train_loss = 2.473885077983141, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 291, train_loss = 2.464829495875165, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 292, train_loss = 2.4558123585302383, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 293, train_loss = 2.4468253403902054, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 294, train_loss = 2.438017826527357, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 295, train_loss = 2.429123666137457, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 296, train_loss = 2.4203882354777306, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 297, train_loss = 2.4116624754387885, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 298, train_loss = 2.403259128332138, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 299, train_loss = 2.3946007303893566, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 300, train_loss = 2.3862509180326015, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 301, train_loss = 2.377796961693093, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 302, train_loss = 2.369724902091548, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 303, train_loss = 2.361310850828886, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 304, train_loss = 2.353240702301264, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 305, train_loss = 2.3451137009542435, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 306, train_loss = 2.3373620870988816, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 307, train_loss = 2.329524766653776, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 308, train_loss = 2.3216998043935746, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 309, train_loss = 2.31363008916378, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 310, train_loss = 2.3061365459579974, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 311, train_loss = 2.2986203096807003, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 312, train_loss = 2.2910129267256707, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 313, train_loss = 2.2837052531540394, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 314, train_loss = 2.2760150369722396, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 315, train_loss = 2.2686357994098216, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 316, train_loss = 2.2616299588698894, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 317, train_loss = 2.254552074940875, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 318, train_loss = 2.247104197740555, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 319, train_loss = 2.2400656926911324, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 320, train_loss = 2.2332221914548427, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 321, train_loss = 2.226247816113755, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 322, train_loss = 2.219357804628089, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 323, train_loss = 2.2125849425792694, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 324, train_loss = 2.205956785706803, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 325, train_loss = 2.1991871159989387, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 326, train_loss = 2.1927776758093387, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 327, train_loss = 2.186056025326252, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 328, train_loss = 2.1797091774642467, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 329, train_loss = 2.173219695687294, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 330, train_loss = 2.166806599823758, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 331, train_loss = 2.1606501042842865, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 332, train_loss = 2.1543038312811404, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 333, train_loss = 2.148368200985715, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 334, train_loss = 2.1420806560199708, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 335, train_loss = 2.1360274564940482, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 336, train_loss = 2.13001490640454, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 337, train_loss = 2.1241033636033535, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 338, train_loss = 2.1181532442569733, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 339, train_loss = 2.112395688891411, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 340, train_loss = 2.106593319447711, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 341, train_loss = 2.1008422027807683, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 342, train_loss = 2.0950521044433117, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 343, train_loss = 2.0894690081477165, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 344, train_loss = 2.083875051466748, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 345, train_loss = 2.0782719254493713, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 346, train_loss = 2.0728451274335384, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 347, train_loss = 2.0673198502045125, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 348, train_loss = 2.062014139024541, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 349, train_loss = 2.056662845192477, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 350, train_loss = 2.051435361383483, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 351, train_loss = 2.046166706830263, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 352, train_loss = 2.040909379720688, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 353, train_loss = 2.0357661433517933, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 354, train_loss = 2.0306235812604427, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 355, train_loss = 2.025483015924692, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 356, train_loss = 2.0205414418596774, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 357, train_loss = 2.015373730333522, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 358, train_loss = 2.0106334660667926, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 359, train_loss = 2.005646213889122, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 360, train_loss = 2.0008070420008153, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 361, train_loss = 1.9959562930744141, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 362, train_loss = 1.9913533504586667, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 363, train_loss = 1.9863855950534344, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 364, train_loss = 1.9816846277099103, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 365, train_loss = 1.9769760258495808, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 366, train_loss = 1.9724680322688073, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 367, train_loss = 1.967836185125634, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 368, train_loss = 1.9633871864061803, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 369, train_loss = 1.9588979296386242, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 370, train_loss = 1.954321899684146, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 371, train_loss = 1.949949987232685, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 372, train_loss = 1.9453840453643352, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 373, train_loss = 1.9410449627321213, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 374, train_loss = 1.9367992728948593, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 375, train_loss = 1.9323837099364027, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 376, train_loss = 1.9282271973788738, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 377, train_loss = 1.924080261378549, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 378, train_loss = 1.9198229064932093, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 379, train_loss = 1.9156748168170452, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 380, train_loss = 1.911571150063537, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 381, train_loss = 1.907477573840879, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 382, train_loss = 1.9033584544667974, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 383, train_loss = 1.8995157243916765, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 384, train_loss = 1.895765739143826, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 385, train_loss = 1.8914472026517615, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 386, train_loss = 1.887501166551374, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 387, train_loss = 1.8836247163126245, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 388, train_loss = 1.8797092214226723, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 389, train_loss = 1.8760699989506975, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 390, train_loss = 1.8722430454799905, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 391, train_loss = 1.8683234453201294, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 392, train_loss = 1.8645434565842152, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 393, train_loss = 1.860873706638813, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 394, train_loss = 1.857181773870252, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 395, train_loss = 1.853710263967514, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 396, train_loss = 1.8500382205238566, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 397, train_loss = 1.8462220802903175, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 398, train_loss = 1.8427194940159097, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 399, train_loss = 1.8393430648138747, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 400, train_loss = 1.8357940204441547, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 401, train_loss = 1.8321065232157707, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 402, train_loss = 1.828737779171206, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 403, train_loss = 1.8253225000808015, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 404, train_loss = 1.8218115282943472, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 405, train_loss = 1.818422375828959, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 406, train_loss = 1.8150564705720171, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 407, train_loss = 1.8117413831641898, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 408, train_loss = 1.8083645962178707, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 409, train_loss = 1.8051856035599485, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 410, train_loss = 1.8018840005388483, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 411, train_loss = 1.7985842289635912, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 412, train_loss = 1.7953543215990067, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 413, train_loss = 1.792167498380877, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 414, train_loss = 1.7890087267151102, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 415, train_loss = 1.785835824906826, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 416, train_loss = 1.7827775353798643, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 417, train_loss = 1.7796379266073927, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 418, train_loss = 1.776538535952568, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 419, train_loss = 1.7734604850411415, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 420, train_loss = 1.7705321200191975, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 421, train_loss = 1.7674216130981222, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 422, train_loss = 1.7645140489330515, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 423, train_loss = 1.7615274837007746, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 424, train_loss = 1.758612527162768, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 425, train_loss = 1.755561069934629, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 426, train_loss = 1.7526716403663158, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 427, train_loss = 1.7498653680086136, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 428, train_loss = 1.746973936795257, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 429, train_loss = 1.7441695258021355, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 430, train_loss = 1.7412754906108603, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 431, train_loss = 1.7384807603666559, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 432, train_loss = 1.735756584792398, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 433, train_loss = 1.7329603085527197, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 434, train_loss = 1.7301748618483543, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 435, train_loss = 1.727440799237229, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 436, train_loss = 1.7247405698290095, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 437, train_loss = 1.7220383422682062, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 438, train_loss = 1.7194565361132845, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 439, train_loss = 1.7166357450187206, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 440, train_loss = 1.7141917794942856, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 441, train_loss = 1.711501982063055, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 442, train_loss = 1.7088158950209618, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 443, train_loss = 1.7063842365751043, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 444, train_loss = 1.703719305456616, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 445, train_loss = 1.7011672531953081, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 446, train_loss = 1.6986540803918615, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 447, train_loss = 1.6961534233996645, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 448, train_loss = 1.6937525980174541, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 449, train_loss = 1.6910906471312046, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 450, train_loss = 1.68869376310613, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 451, train_loss = 1.6862397603690624, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 452, train_loss = 1.6838538845768198, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 453, train_loss = 1.6814872100949287, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 454, train_loss = 1.6790259629487991, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 455, train_loss = 1.6765843281755224, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 456, train_loss = 1.6743388610193506, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 457, train_loss = 1.6719541350612417, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 458, train_loss = 1.669598538428545, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 459, train_loss = 1.6672708926489577, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 460, train_loss = 1.6649573259055614, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 461, train_loss = 1.6626953879604116, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 462, train_loss = 1.660392357618548, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 463, train_loss = 1.6581798965344205, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 464, train_loss = 1.6560187129070982, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 465, train_loss = 1.6537341935327277, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 466, train_loss = 1.6515087013831362, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 467, train_loss = 1.6493123123655096, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 468, train_loss = 1.6470654333243147, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 469, train_loss = 1.644930592388846, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 470, train_loss = 1.6428083764621988, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 471, train_loss = 1.6405949791660532, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 472, train_loss = 1.6385961609194055, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 473, train_loss = 1.6364171305904165, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 474, train_loss = 1.634319489239715, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 475, train_loss = 1.6321603717515245, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 476, train_loss = 1.6301055612275377, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 477, train_loss = 1.628141121356748, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 478, train_loss = 1.6260778941214085, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 479, train_loss = 1.6240642530028708, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 480, train_loss = 1.6219248386914842, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 481, train_loss = 1.61995529133128, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 482, train_loss = 1.6179135479032993, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 483, train_loss = 1.6159968661959283, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 484, train_loss = 1.6140819117426872, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 485, train_loss = 1.6120620891451836, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 486, train_loss = 1.610084343701601, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 487, train_loss = 1.608182653784752, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 488, train_loss = 1.606260774016846, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 489, train_loss = 1.6043342376942746, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 490, train_loss = 1.602444530755747, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 491, train_loss = 1.6005706290598027, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 492, train_loss = 1.598610206216108, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 493, train_loss = 1.5968444583122618, train_acc = 0.9962738705170004\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 494, train_loss = 1.5950114068691619, train_acc = 0.9962738705170004\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 495, train_loss = 1.5930974185466766, train_acc = 0.9962738705170004\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 496, train_loss = 1.5912714923615567, train_acc = 0.9962738705170004\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 497, train_loss = 1.5895127169787884, train_acc = 0.9962738705170004\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 498, train_loss = 1.58771961677121, train_acc = 0.9962738705170004\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 499, train_loss = 1.5859391267294995, train_acc = 0.9962738705170004\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████▋                                                               | 4/30 [26:34<2:52:50, 398.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "5th- epoch: 0, train_loss = 276.5684641599655, train_acc = 0.41511411271541687\n",
      "test Acc 0.4823091247672253:\n",
      "5th- epoch: 1, train_loss = 212.2772514820099, train_acc = 0.48637633907778294\n",
      "test Acc 0.49813780260707635:\n",
      "5th- epoch: 2, train_loss = 169.7993375658989, train_acc = 0.5149045179319981\n",
      "test Acc 0.542830540037244:\n",
      "5th- epoch: 3, train_loss = 146.50556790828705, train_acc = 0.6144620400558919\n",
      "test Acc 0.7001862197392924:\n",
      "5th- epoch: 4, train_loss = 127.586789727211, train_acc = 0.7090125756870052\n",
      "test Acc 0.7313780260707635:\n",
      "5th- epoch: 5, train_loss = 111.07937282323837, train_acc = 0.7458081043316255\n",
      "test Acc 0.7690875232774674:\n",
      "5th- epoch: 6, train_loss = 97.08629325032234, train_acc = 0.784350256171402\n",
      "test Acc 0.7993482309124768:\n",
      "5th- epoch: 7, train_loss = 85.33087581396103, train_acc = 0.8190498369818351\n",
      "test Acc 0.8254189944134078:\n",
      "5th- epoch: 8, train_loss = 75.42305019497871, train_acc = 0.845947834187238\n",
      "test Acc 0.8584729981378026:\n",
      "5th- epoch: 9, train_loss = 67.11150124669075, train_acc = 0.8677224033535166\n",
      "test Acc 0.87243947858473:\n",
      "5th- epoch: 10, train_loss = 60.22658437490463, train_acc = 0.8757568700512343\n",
      "test Acc 0.87756052141527:\n",
      "5th- epoch: 11, train_loss = 54.57591436803341, train_acc = 0.883791336748952\n",
      "test Acc 0.8845437616387337:\n",
      "5th- epoch: 12, train_loss = 49.93299153447151, train_acc = 0.8968327899394504\n",
      "test Acc 0.8980446927374302:\n",
      "5th- epoch: 13, train_loss = 46.07952979207039, train_acc = 0.9089427107591989\n",
      "test Acc 0.9129422718808193:\n",
      "5th- epoch: 14, train_loss = 42.83413244783878, train_acc = 0.9201210992081975\n",
      "test Acc 0.9222532588454376:\n",
      "5th- epoch: 15, train_loss = 40.06560917198658, train_acc = 0.9280391243595715\n",
      "test Acc 0.930633147113594:\n",
      "5th- epoch: 16, train_loss = 37.67785534262657, train_acc = 0.9333954354913834\n",
      "test Acc 0.9320297951582868:\n",
      "5th- epoch: 17, train_loss = 35.59978887438774, train_acc = 0.9367722403353517\n",
      "test Acc 0.9366852886405959:\n",
      "5th- epoch: 18, train_loss = 33.77633165568113, train_acc = 0.9400326036329762\n",
      "test Acc 0.9390130353817505:\n",
      "5th- epoch: 19, train_loss = 32.165696792304516, train_acc = 0.9427107591988821\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 20, train_loss = 30.73357604444027, train_acc = 0.9476013041453191\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 21, train_loss = 29.452100224792957, train_acc = 0.9495808104331626\n",
      "test Acc 0.9450651769087524:\n",
      "5th- epoch: 22, train_loss = 28.298388987779617, train_acc = 0.9508616674429436\n",
      "test Acc 0.9464618249534451:\n",
      "5th- epoch: 23, train_loss = 27.25701630115509, train_acc = 0.9522589659990685\n",
      "test Acc 0.9478584729981379:\n",
      "5th- epoch: 24, train_loss = 26.31101878732443, train_acc = 0.9541220307405682\n",
      "test Acc 0.9492551210428305:\n",
      "5th- epoch: 25, train_loss = 25.445534698665142, train_acc = 0.9549371215649743\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 26, train_loss = 24.65083260089159, train_acc = 0.9562179785747554\n",
      "test Acc 0.9506517690875232:\n",
      "5th- epoch: 27, train_loss = 23.920435659587383, train_acc = 0.9573823940381928\n",
      "test Acc 0.9506517690875232:\n",
      "5th- epoch: 28, train_loss = 23.245881244540215, train_acc = 0.9588961341406614\n",
      "test Acc 0.9515828677839852:\n",
      "5th- epoch: 29, train_loss = 22.619294311851263, train_acc = 0.9593619003260363\n",
      "test Acc 0.952513966480447:\n",
      "5th- epoch: 30, train_loss = 22.03497066348791, train_acc = 0.9595947834187238\n",
      "test Acc 0.9539106145251397:\n",
      "5th- epoch: 31, train_loss = 21.48698988556862, train_acc = 0.96040987424313\n",
      "test Acc 0.9553072625698324:\n",
      "5th- epoch: 32, train_loss = 20.971599251031876, train_acc = 0.9609920819748486\n",
      "test Acc 0.9553072625698324:\n",
      "5th- epoch: 33, train_loss = 20.484345331788063, train_acc = 0.9618071727992548\n",
      "test Acc 0.9557728119180633:\n",
      "5th- epoch: 34, train_loss = 20.023923844099045, train_acc = 0.9623893805309734\n",
      "test Acc 0.9557728119180633:\n",
      "5th- epoch: 35, train_loss = 19.588763374835253, train_acc = 0.9630880298090359\n",
      "test Acc 0.9557728119180633:\n",
      "5th- epoch: 36, train_loss = 19.175286509096622, train_acc = 0.9632044713553796\n",
      "test Acc 0.9562383612662942:\n",
      "5th- epoch: 37, train_loss = 18.78094456717372, train_acc = 0.9637866790870983\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 38, train_loss = 18.404896918684244, train_acc = 0.9642524452724732\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 39, train_loss = 18.04484209790826, train_acc = 0.9648346530041919\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 40, train_loss = 17.699657130986452, train_acc = 0.9653004191895669\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 41, train_loss = 17.368714813143015, train_acc = 0.9659990684676293\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 42, train_loss = 17.051355458796024, train_acc = 0.9669306008383791\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 43, train_loss = 16.746657118201256, train_acc = 0.9682114578481602\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 44, train_loss = 16.453974820673466, train_acc = 0.9687936655798789\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 45, train_loss = 16.172192588448524, train_acc = 0.9693758733115976\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 46, train_loss = 15.900819703936577, train_acc = 0.9699580810433163\n",
      "test Acc 0.9618249534450651:\n",
      "5th- epoch: 47, train_loss = 15.639021717011929, train_acc = 0.9710060549604099\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 48, train_loss = 15.386571805924177, train_acc = 0.9714718211457848\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 49, train_loss = 15.142515283077955, train_acc = 0.9714718211457848\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 50, train_loss = 14.906708147376776, train_acc = 0.9720540288775035\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 51, train_loss = 14.678170874714851, train_acc = 0.9721704704238472\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 52, train_loss = 14.456622544676065, train_acc = 0.9725197950628784\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 53, train_loss = 14.24167300760746, train_acc = 0.9728691197019096\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 54, train_loss = 14.032787255942822, train_acc = 0.9738006520726595\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 55, train_loss = 13.829700192436576, train_acc = 0.9741499767116907\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 56, train_loss = 13.632537666708231, train_acc = 0.9746157428970657\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 57, train_loss = 13.44071315228939, train_acc = 0.9747321844434094\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 58, train_loss = 13.25394955277443, train_acc = 0.9748486259897532\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 59, train_loss = 13.072212774306536, train_acc = 0.9751979506287843\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 60, train_loss = 12.895438272505999, train_acc = 0.9751979506287843\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 61, train_loss = 12.72320020571351, train_acc = 0.9754308337214718\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 62, train_loss = 12.555159334093332, train_acc = 0.9755472752678156\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 63, train_loss = 12.391164902597666, train_acc = 0.9755472752678156\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 64, train_loss = 12.231181785464287, train_acc = 0.9756637168141593\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 65, train_loss = 12.074876464903355, train_acc = 0.975780158360503\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 66, train_loss = 11.922265063971281, train_acc = 0.9758965999068467\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 67, train_loss = 11.77351101860404, train_acc = 0.9763623660922217\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 68, train_loss = 11.628335628658533, train_acc = 0.9767116907312529\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 69, train_loss = 11.486569412052631, train_acc = 0.9768281322775967\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 70, train_loss = 11.348376251757145, train_acc = 0.9769445738239404\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 71, train_loss = 11.21293280273676, train_acc = 0.9772938984629715\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 72, train_loss = 11.080940838903189, train_acc = 0.9776432231020028\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 73, train_loss = 10.951660953462124, train_acc = 0.9778761061946902\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 74, train_loss = 10.825438870117068, train_acc = 0.9781089892873778\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 75, train_loss = 10.701348677277565, train_acc = 0.9782254308337215\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 76, train_loss = 10.57999773323536, train_acc = 0.9783418723800652\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 77, train_loss = 10.460726795718074, train_acc = 0.9783418723800652\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 78, train_loss = 10.344078613445163, train_acc = 0.9784583139264089\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 79, train_loss = 10.229843720793724, train_acc = 0.9786911970190965\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 80, train_loss = 10.117639154195786, train_acc = 0.9790405216581276\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 81, train_loss = 10.007430946454406, train_acc = 0.9791569632044713\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 82, train_loss = 9.89932619780302, train_acc = 0.9791569632044713\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 83, train_loss = 9.793201491236687, train_acc = 0.9792734047508151\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 84, train_loss = 9.688947066664696, train_acc = 0.9796227293898463\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 85, train_loss = 9.586544252932072, train_acc = 0.9796227293898463\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 86, train_loss = 9.485486548393965, train_acc = 0.97973917093619\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 87, train_loss = 9.386336943134665, train_acc = 0.9799720540288775\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 88, train_loss = 9.288912791758776, train_acc = 0.9799720540288775\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 89, train_loss = 9.193553745746613, train_acc = 0.9800884955752213\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 90, train_loss = 9.099624833092093, train_acc = 0.9803213786679087\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 91, train_loss = 9.007500557228923, train_acc = 0.9804378202142524\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 92, train_loss = 8.916813537478447, train_acc = 0.9805542617605962\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 93, train_loss = 8.827587934210896, train_acc = 0.9809035863996274\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 94, train_loss = 8.739980624988675, train_acc = 0.9810200279459711\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 95, train_loss = 8.653191227465868, train_acc = 0.9811364694923148\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 96, train_loss = 8.56827544234693, train_acc = 0.9812529110386586\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 97, train_loss = 8.484643505886197, train_acc = 0.9816022356776898\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 98, train_loss = 8.402154762297869, train_acc = 0.9817186772240335\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 99, train_loss = 8.321034966036677, train_acc = 0.981951560316721\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 100, train_loss = 8.241127118468285, train_acc = 0.9820680018630648\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 101, train_loss = 8.162170251831412, train_acc = 0.9824173265020959\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 102, train_loss = 8.084658527746797, train_acc = 0.9826502095947834\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 103, train_loss = 8.008120030164719, train_acc = 0.9829995342338146\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 104, train_loss = 7.932818936184049, train_acc = 0.9833488588728458\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 105, train_loss = 7.858545649796724, train_acc = 0.9834653004191896\n",
      "test Acc 0.972998137802607:\n",
      "5th- epoch: 106, train_loss = 7.7853642869740725, train_acc = 0.9835817419655333\n",
      "test Acc 0.973463687150838:\n",
      "5th- epoch: 107, train_loss = 7.713151153177023, train_acc = 0.983698183511877\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 108, train_loss = 7.641991954296827, train_acc = 0.9839310666045645\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 109, train_loss = 7.571835095062852, train_acc = 0.9842803912435957\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 110, train_loss = 7.5025470443069935, train_acc = 0.9845132743362832\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 111, train_loss = 7.434394724667072, train_acc = 0.9846297158826269\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 112, train_loss = 7.367103133350611, train_acc = 0.9848625989753144\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 113, train_loss = 7.300705052912235, train_acc = 0.9849790405216581\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 114, train_loss = 7.235135480761528, train_acc = 0.9852119236143456\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 115, train_loss = 7.170490372925997, train_acc = 0.985444806707033\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 116, train_loss = 7.1064697448164225, train_acc = 0.9855612482533768\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 117, train_loss = 7.0436432007700205, train_acc = 0.9856776897997206\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 118, train_loss = 6.981457009911537, train_acc = 0.9856776897997206\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 119, train_loss = 6.92015746049583, train_acc = 0.985910572892408\n",
      "test Acc 0.9748603351955307:\n",
      "5th- epoch: 120, train_loss = 6.859825246036053, train_acc = 0.9860270144387517\n",
      "test Acc 0.9748603351955307:\n",
      "5th- epoch: 121, train_loss = 6.800181783735752, train_acc = 0.9860270144387517\n",
      "test Acc 0.9748603351955307:\n",
      "5th- epoch: 122, train_loss = 6.741366958245635, train_acc = 0.9860270144387517\n",
      "test Acc 0.9748603351955307:\n",
      "5th- epoch: 123, train_loss = 6.683529956266284, train_acc = 0.9860270144387517\n",
      "test Acc 0.9748603351955307:\n",
      "5th- epoch: 124, train_loss = 6.626288399100304, train_acc = 0.986376339077783\n",
      "test Acc 0.9748603351955307:\n",
      "5th- epoch: 125, train_loss = 6.570060571655631, train_acc = 0.9864927806241267\n",
      "test Acc 0.9748603351955307:\n",
      "5th- epoch: 126, train_loss = 6.51430388726294, train_acc = 0.9867256637168141\n",
      "test Acc 0.9748603351955307:\n",
      "5th- epoch: 127, train_loss = 6.4594641700387, train_acc = 0.9867256637168141\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 128, train_loss = 6.405346238985658, train_acc = 0.9867256637168141\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 129, train_loss = 6.351815070956945, train_acc = 0.9867256637168141\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 130, train_loss = 6.299103427678347, train_acc = 0.9868421052631579\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 131, train_loss = 6.2470583319664, train_acc = 0.9869585468095017\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 132, train_loss = 6.19567522034049, train_acc = 0.9869585468095017\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 133, train_loss = 6.144782120361924, train_acc = 0.9870749883558454\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 134, train_loss = 6.094364641234279, train_acc = 0.9870749883558454\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 135, train_loss = 6.044686209410429, train_acc = 0.9871914299021891\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 136, train_loss = 5.995649129152298, train_acc = 0.9873078714485328\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 137, train_loss = 5.947482464835048, train_acc = 0.9874243129948765\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 138, train_loss = 5.899875272065401, train_acc = 0.9874243129948765\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 139, train_loss = 5.852981319651008, train_acc = 0.9875407545412203\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 140, train_loss = 5.806723976507783, train_acc = 0.9876571960875641\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 141, train_loss = 5.760890562087297, train_acc = 0.9877736376339078\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 142, train_loss = 5.715919291600585, train_acc = 0.9878900791802515\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 143, train_loss = 5.671460386365652, train_acc = 0.9882394038192828\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 144, train_loss = 5.627638870850205, train_acc = 0.9884722869119702\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 145, train_loss = 5.584371915087104, train_acc = 0.9885887284583139\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 146, train_loss = 5.541495367884636, train_acc = 0.9887051700046576\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 147, train_loss = 5.4990515280514956, train_acc = 0.9887051700046576\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 148, train_loss = 5.457190001383424, train_acc = 0.9888216115510013\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 149, train_loss = 5.415742127224803, train_acc = 0.9890544946436889\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 150, train_loss = 5.3749341033399105, train_acc = 0.9890544946436889\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 151, train_loss = 5.334612895734608, train_acc = 0.9891709361900326\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 152, train_loss = 5.294841225259006, train_acc = 0.98940381928272\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 153, train_loss = 5.25529860612005, train_acc = 0.98940381928272\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 154, train_loss = 5.216376205906272, train_acc = 0.9895202608290639\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 155, train_loss = 5.178043966181576, train_acc = 0.9895202608290639\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 156, train_loss = 5.140037924982607, train_acc = 0.9895202608290639\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 157, train_loss = 5.102728226222098, train_acc = 0.9896367023754076\n",
      "test Acc 0.9748603351955307:\n",
      "5th- epoch: 158, train_loss = 5.06582850124687, train_acc = 0.989869585468095\n",
      "test Acc 0.9748603351955307:\n",
      "5th- epoch: 159, train_loss = 5.0293738935142756, train_acc = 0.9901024685607824\n",
      "test Acc 0.9748603351955307:\n",
      "5th- epoch: 160, train_loss = 4.993547583930194, train_acc = 0.9901024685607824\n",
      "test Acc 0.9757914338919925:\n",
      "5th- epoch: 161, train_loss = 4.957872127182782, train_acc = 0.9899860270144387\n",
      "test Acc 0.9753258845437617:\n",
      "5th- epoch: 162, train_loss = 4.923020827583969, train_acc = 0.9902189101071263\n",
      "test Acc 0.9753258845437617:\n",
      "5th- epoch: 163, train_loss = 4.88833346683532, train_acc = 0.99033535165347\n",
      "test Acc 0.9757914338919925:\n",
      "5th- epoch: 164, train_loss = 4.854132737033069, train_acc = 0.9905682347461574\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 165, train_loss = 4.820493753999472, train_acc = 0.9906846762925011\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 166, train_loss = 4.787065580487251, train_acc = 0.990801117838845\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 167, train_loss = 4.754325690679252, train_acc = 0.9911504424778761\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 168, train_loss = 4.72181264963001, train_acc = 0.9911504424778761\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 169, train_loss = 4.689777192659676, train_acc = 0.9911504424778761\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 170, train_loss = 4.658064518123865, train_acc = 0.9911504424778761\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 171, train_loss = 4.626840355806053, train_acc = 0.9911504424778761\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 172, train_loss = 4.5958674950525165, train_acc = 0.9911504424778761\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 173, train_loss = 4.565316424705088, train_acc = 0.9911504424778761\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 174, train_loss = 4.535102837719023, train_acc = 0.9911504424778761\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 175, train_loss = 4.50531293079257, train_acc = 0.9911504424778761\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 176, train_loss = 4.475891097448766, train_acc = 0.9911504424778761\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 177, train_loss = 4.446654417552054, train_acc = 0.9912668840242198\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 178, train_loss = 4.417981140315533, train_acc = 0.9912668840242198\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 179, train_loss = 4.38954698946327, train_acc = 0.9912668840242198\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 180, train_loss = 4.361335560679436, train_acc = 0.9912668840242198\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 181, train_loss = 4.333538788370788, train_acc = 0.9914997671169073\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 182, train_loss = 4.306103725917637, train_acc = 0.9914997671169073\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 183, train_loss = 4.278674621134996, train_acc = 0.9914997671169073\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 184, train_loss = 4.251509682275355, train_acc = 0.9914997671169073\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 185, train_loss = 4.22502626106143, train_acc = 0.9914997671169073\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 186, train_loss = 4.1987889893352985, train_acc = 0.9914997671169073\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 187, train_loss = 4.172767878510058, train_acc = 0.9916162086632511\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 188, train_loss = 4.147183299064636, train_acc = 0.9916162086632511\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 189, train_loss = 4.121906449086964, train_acc = 0.9917326502095948\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 190, train_loss = 4.096803051419556, train_acc = 0.9918490917559385\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 191, train_loss = 4.0720482328906655, train_acc = 0.9918490917559385\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 192, train_loss = 4.047635055147111, train_acc = 0.992081974848626\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 193, train_loss = 4.023356859572232, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 194, train_loss = 3.999352832324803, train_acc = 0.9921984163949698\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 195, train_loss = 3.9756738478317857, train_acc = 0.9921984163949698\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 196, train_loss = 3.952258593402803, train_acc = 0.9921984163949698\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 197, train_loss = 3.9291940070688725, train_acc = 0.9923148579413135\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 198, train_loss = 3.906133148819208, train_acc = 0.9923148579413135\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 199, train_loss = 3.883585243485868, train_acc = 0.9923148579413135\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 200, train_loss = 3.861077652312815, train_acc = 0.9924312994876572\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 201, train_loss = 3.838883351534605, train_acc = 0.9924312994876572\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 202, train_loss = 3.816953431814909, train_acc = 0.9925477410340009\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 203, train_loss = 3.795245185494423, train_acc = 0.9925477410340009\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 204, train_loss = 3.773775496520102, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 205, train_loss = 3.7523838030174375, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 206, train_loss = 3.7313119312748313, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 207, train_loss = 3.710550744086504, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 208, train_loss = 3.689954702742398, train_acc = 0.9926641825803446\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 209, train_loss = 3.6696084635332227, train_acc = 0.9927806241266884\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 210, train_loss = 3.6492580911144614, train_acc = 0.9927806241266884\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 211, train_loss = 3.6294855093583465, train_acc = 0.9927806241266884\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 212, train_loss = 3.60971632367, train_acc = 0.9928970656730322\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 213, train_loss = 3.5901262662373483, train_acc = 0.9928970656730322\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 214, train_loss = 3.570862224791199, train_acc = 0.9928970656730322\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 215, train_loss = 3.5516977407969534, train_acc = 0.9928970656730322\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 216, train_loss = 3.5327514186501503, train_acc = 0.9928970656730322\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 217, train_loss = 3.5141110457479954, train_acc = 0.9928970656730322\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 218, train_loss = 3.4954852014780045, train_acc = 0.9928970656730322\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 219, train_loss = 3.4772978709079325, train_acc = 0.9928970656730322\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 220, train_loss = 3.4589386344887316, train_acc = 0.9928970656730322\n",
      "test Acc 0.9776536312849162:\n",
      "5th- epoch: 221, train_loss = 3.4411245533265173, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 222, train_loss = 3.4231636375188828, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 223, train_loss = 3.4055802547372878, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 224, train_loss = 3.3880941472016275, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 225, train_loss = 3.3708626604638994, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 226, train_loss = 3.353638620581478, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 227, train_loss = 3.3367691398598254, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 228, train_loss = 3.319783876184374, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 229, train_loss = 3.3034652485512197, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 230, train_loss = 3.2868246347643435, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 231, train_loss = 3.270606379956007, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 232, train_loss = 3.254346510861069, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 233, train_loss = 3.2384798279963434, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 234, train_loss = 3.2224813532084227, train_acc = 0.9934792734047508\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 235, train_loss = 3.207037468906492, train_acc = 0.9934792734047508\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 236, train_loss = 3.191313246730715, train_acc = 0.9934792734047508\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 237, train_loss = 3.1759259905666113, train_acc = 0.9934792734047508\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 238, train_loss = 3.160648225340992, train_acc = 0.9934792734047508\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 239, train_loss = 3.1457356507889926, train_acc = 0.9935957149510946\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 240, train_loss = 3.130663570482284, train_acc = 0.9935957149510946\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 241, train_loss = 3.1158449798822403, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 242, train_loss = 3.1010775133036077, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 243, train_loss = 3.086780531797558, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 244, train_loss = 3.072077362332493, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 245, train_loss = 3.0579820424318314, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 246, train_loss = 3.0437602754682302, train_acc = 0.9939450395901258\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 247, train_loss = 3.029850194696337, train_acc = 0.9939450395901258\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 248, train_loss = 3.0157466088421643, train_acc = 0.9940614811364695\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 249, train_loss = 3.002151247113943, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 250, train_loss = 2.988447828684002, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 251, train_loss = 2.974949261639267, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 252, train_loss = 2.9615217726677656, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 253, train_loss = 2.948328596074134, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 254, train_loss = 2.935200660955161, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 255, train_loss = 2.9219464915804565, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 256, train_loss = 2.909151101950556, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 257, train_loss = 2.8963291333056986, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 258, train_loss = 2.8835206576623023, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 259, train_loss = 2.870937454048544, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 260, train_loss = 2.8585154749453068, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 261, train_loss = 2.8459118083119392, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 262, train_loss = 2.8336256905458868, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 263, train_loss = 2.821326354984194, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 264, train_loss = 2.8093025176785886, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 265, train_loss = 2.7972700484097004, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 266, train_loss = 2.785077908542007, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 267, train_loss = 2.7733776993118227, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 268, train_loss = 2.761592611670494, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 269, train_loss = 2.749909430742264, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 270, train_loss = 2.738243229687214, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 271, train_loss = 2.726831140462309, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 272, train_loss = 2.7154828966595232, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 273, train_loss = 2.7041841759346426, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 274, train_loss = 2.6930481367744505, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 275, train_loss = 2.6819423199631274, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 276, train_loss = 2.6710062362253666, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 277, train_loss = 2.660080596804619, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 278, train_loss = 2.6493412205018103, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 279, train_loss = 2.6388712860643864, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 280, train_loss = 2.628289049025625, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 281, train_loss = 2.6177745438180864, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 282, train_loss = 2.607581524644047, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 283, train_loss = 2.5973325832746923, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 284, train_loss = 2.5871643074788153, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 285, train_loss = 2.5770944468677044, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 286, train_loss = 2.5672221505083144, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 287, train_loss = 2.557342392858118, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 288, train_loss = 2.547611908521503, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 289, train_loss = 2.5378810153342783, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 290, train_loss = 2.528421690221876, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 291, train_loss = 2.5189005937427282, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 292, train_loss = 2.509410224854946, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 293, train_loss = 2.500169275328517, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 294, train_loss = 2.490909738931805, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 295, train_loss = 2.481745819328353, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 296, train_loss = 2.4727384224534035, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 297, train_loss = 2.4636859025340527, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 298, train_loss = 2.454842110397294, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 299, train_loss = 2.4460169423837215, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 300, train_loss = 2.43724337592721, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 301, train_loss = 2.4286809500772506, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 302, train_loss = 2.420169249176979, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 303, train_loss = 2.411563662113622, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 304, train_loss = 2.4031969208735973, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 305, train_loss = 2.3947811212856323, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 306, train_loss = 2.386667385697365, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 307, train_loss = 2.3785125601571053, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 308, train_loss = 2.3703970685601234, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 309, train_loss = 2.362449127016589, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 310, train_loss = 2.354363450082019, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 311, train_loss = 2.3464977194089442, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 312, train_loss = 2.3388216719031334, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 313, train_loss = 2.331105198711157, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 314, train_loss = 2.3234803851228207, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 315, train_loss = 2.315877514658496, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 316, train_loss = 2.308313788147643, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 317, train_loss = 2.300881288945675, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 318, train_loss = 2.2935221057850868, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 319, train_loss = 2.286300542531535, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 320, train_loss = 2.279042727081105, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 321, train_loss = 2.271789935650304, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 322, train_loss = 2.264795324532315, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 323, train_loss = 2.2576827507000417, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 324, train_loss = 2.250698524294421, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 325, train_loss = 2.24381638946943, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 326, train_loss = 2.2369488775730133, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 327, train_loss = 2.2301779340486974, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 328, train_loss = 2.223439022898674, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 329, train_loss = 2.216799819143489, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 330, train_loss = 2.210292189149186, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 331, train_loss = 2.2036516543012112, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 332, train_loss = 2.1971390780527145, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 333, train_loss = 2.1908572751563042, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 334, train_loss = 2.1844896513503045, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 335, train_loss = 2.1782017934601754, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 336, train_loss = 2.171984949382022, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 337, train_loss = 2.165713644353673, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 338, train_loss = 2.159601677209139, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 339, train_loss = 2.153543735621497, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 340, train_loss = 2.1475711576640606, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 341, train_loss = 2.1415776622015983, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 342, train_loss = 2.135628727497533, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 343, train_loss = 2.129863630980253, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 344, train_loss = 2.1240088816266507, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 345, train_loss = 2.1182452004868537, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 346, train_loss = 2.1126793026924133, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 347, train_loss = 2.1069133654236794, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 348, train_loss = 2.1013281370978802, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 349, train_loss = 2.095923596294597, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 350, train_loss = 2.090315520763397, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 351, train_loss = 2.0848950173240155, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 352, train_loss = 2.079451597062871, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 353, train_loss = 2.07413445902057, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 354, train_loss = 2.068872458068654, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 355, train_loss = 2.0635534215252846, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 356, train_loss = 2.0583768871147186, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 357, train_loss = 2.0531262792646885, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 358, train_loss = 2.0480314430315048, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 359, train_loss = 2.042898989049718, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 360, train_loss = 2.0378373798448592, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 361, train_loss = 2.0329708245117217, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 362, train_loss = 2.0279092874843627, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 363, train_loss = 2.022932356921956, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 364, train_loss = 2.0181643899995834, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 365, train_loss = 2.01325448974967, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 366, train_loss = 2.0084636360406876, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 367, train_loss = 2.0038068022113293, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 368, train_loss = 1.9989700738806278, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 369, train_loss = 1.9942139151971787, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 370, train_loss = 1.989792589098215, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 371, train_loss = 1.985021171392873, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 372, train_loss = 1.980628567514941, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 373, train_loss = 1.9759422664064914, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 374, train_loss = 1.9715240139048547, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 375, train_loss = 1.966896279482171, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 376, train_loss = 1.9626759737730026, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 377, train_loss = 1.9581439543981105, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 378, train_loss = 1.9538731735665351, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 379, train_loss = 1.949469393817708, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 380, train_loss = 1.9452688209712505, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 381, train_loss = 1.9408534590620548, train_acc = 0.9953423381462506\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 382, train_loss = 1.9368312421720475, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 383, train_loss = 1.9325267523527145, train_acc = 0.9953423381462506\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 384, train_loss = 1.9285192266106606, train_acc = 0.9953423381462506\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 385, train_loss = 1.924213762045838, train_acc = 0.9953423381462506\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 386, train_loss = 1.9202724943170324, train_acc = 0.9953423381462506\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 387, train_loss = 1.9160681354114786, train_acc = 0.9953423381462506\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 388, train_loss = 1.9122836490860209, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 389, train_loss = 1.9080954740056768, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 390, train_loss = 1.9042667472967878, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 391, train_loss = 1.9003166606416926, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 392, train_loss = 1.8964009595802054, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 393, train_loss = 1.8924592360854149, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 394, train_loss = 1.8886006897082552, train_acc = 0.9954587796925943\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 395, train_loss = 1.8848878579447046, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 396, train_loss = 1.880992396385409, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 397, train_loss = 1.8773942788830027, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 398, train_loss = 1.8734892444917932, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 399, train_loss = 1.8699492575833574, train_acc = 0.995575221238938\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 400, train_loss = 1.866124921827577, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 401, train_loss = 1.8626648969948292, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 402, train_loss = 1.8589046025881544, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 403, train_loss = 1.8554745254805312, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 404, train_loss = 1.851798802614212, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 405, train_loss = 1.848321843892336, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 406, train_loss = 1.8445852709701285, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 407, train_loss = 1.8413784404983744, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 408, train_loss = 1.8377119129290804, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 409, train_loss = 1.83441696933005, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 410, train_loss = 1.8308203952619806, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 411, train_loss = 1.8275607438990846, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 412, train_loss = 1.8240542175481096, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 413, train_loss = 1.8208055309951305, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 414, train_loss = 1.8173777982592583, train_acc = 0.9956916627852818\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 415, train_loss = 1.8142474169144407, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 416, train_loss = 1.8108872411539778, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 417, train_loss = 1.8077293150126934, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 418, train_loss = 1.8045748745789751, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 419, train_loss = 1.8014366080751643, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 420, train_loss = 1.7982594346394762, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 421, train_loss = 1.7949372716248035, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 422, train_loss = 1.791974755586125, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 423, train_loss = 1.7887093561002985, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 424, train_loss = 1.785818892181851, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 425, train_loss = 1.7826192876091227, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 426, train_loss = 1.779707116424106, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "5th- epoch: 427, train_loss = 1.7765775868901983, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 428, train_loss = 1.7736183864763007, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 429, train_loss = 1.7707011153688654, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 430, train_loss = 1.7678053230047226, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 431, train_loss = 1.7647520154714584, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 432, train_loss = 1.7619809582829475, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 433, train_loss = 1.7591397041687742, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 434, train_loss = 1.7562772035598755, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 435, train_loss = 1.753390317200683, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 436, train_loss = 1.7505985671887174, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 437, train_loss = 1.7477440796792507, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 438, train_loss = 1.7448916708817706, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 439, train_loss = 1.7422672597458586, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 440, train_loss = 1.7394026033580303, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 441, train_loss = 1.7367412025341764, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 442, train_loss = 1.7339287661015987, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 443, train_loss = 1.7313310205936432, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 444, train_loss = 1.7285412115743384, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 445, train_loss = 1.726006180047989, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 446, train_loss = 1.7233252289006487, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 447, train_loss = 1.7207094120094553, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 448, train_loss = 1.7181276777992025, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 449, train_loss = 1.7155249454081059, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 450, train_loss = 1.7128365561366081, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 451, train_loss = 1.7103607828030363, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 452, train_loss = 1.7077901201555505, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 453, train_loss = 1.7052263418445364, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 454, train_loss = 1.7028697741916403, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 455, train_loss = 1.7004037810256705, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 456, train_loss = 1.6979263661196455, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 457, train_loss = 1.6953585296869278, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 458, train_loss = 1.693039070814848, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 459, train_loss = 1.690706274122931, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 460, train_loss = 1.6882536771008745, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 461, train_loss = 1.6858475456247106, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 462, train_loss = 1.6834367787232623, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 463, train_loss = 1.6811649253359064, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 464, train_loss = 1.6788297867169604, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 465, train_loss = 1.676500990986824, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 466, train_loss = 1.674194574356079, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 467, train_loss = 1.671956910402514, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 468, train_loss = 1.669596590101719, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 469, train_loss = 1.6674280738225207, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 470, train_loss = 1.6651352569460869, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 471, train_loss = 1.6629126766929403, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 472, train_loss = 1.6607119577238336, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 473, train_loss = 1.6584903238108382, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 474, train_loss = 1.6563562862575054, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 475, train_loss = 1.6541752318153158, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 476, train_loss = 1.6520246838917956, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 477, train_loss = 1.6499132489552721, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 478, train_loss = 1.6476156438002363, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 479, train_loss = 1.645607871352695, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 480, train_loss = 1.6434464665362611, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 481, train_loss = 1.641439168364741, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 482, train_loss = 1.6392142859986052, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 483, train_loss = 1.637230190099217, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 484, train_loss = 1.6351619908818975, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 485, train_loss = 1.6332012551138178, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 486, train_loss = 1.6310209656367078, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 487, train_loss = 1.6291095042834058, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 488, train_loss = 1.627089268178679, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 489, train_loss = 1.625019041239284, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 490, train_loss = 1.6231880908017047, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 491, train_loss = 1.6211627845768817, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 492, train_loss = 1.6191687732934952, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 493, train_loss = 1.6172780928318389, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 494, train_loss = 1.6152687395806424, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 495, train_loss = 1.6133054929669015, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 496, train_loss = 1.6115366120939143, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 497, train_loss = 1.6096150751109235, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 498, train_loss = 1.6077123706345446, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 499, train_loss = 1.6058172906632535, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████▏                                                            | 5/30 [33:13<2:46:10, 398.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "6th- epoch: 0, train_loss = 271.19496762752533, train_acc = 0.4462040055891942\n",
      "test Acc 0.4930167597765363:\n",
      "6th- epoch: 1, train_loss = 206.55976378917694, train_acc = 0.487657196087564\n",
      "test Acc 0.49441340782122906:\n",
      "6th- epoch: 2, train_loss = 167.03801029920578, train_acc = 0.5159524918490918\n",
      "test Acc 0.6066108007448789:\n",
      "6th- epoch: 3, train_loss = 144.95208549499512, train_acc = 0.6486958546809501\n",
      "test Acc 0.686219739292365:\n",
      "6th- epoch: 4, train_loss = 127.24343973398209, train_acc = 0.7027247321844434\n",
      "test Acc 0.723463687150838:\n",
      "6th- epoch: 5, train_loss = 111.88775289058685, train_acc = 0.7373078714485328\n",
      "test Acc 0.7527932960893855:\n",
      "6th- epoch: 6, train_loss = 98.71168440580368, train_acc = 0.7707265952491849\n",
      "test Acc 0.787243947858473:\n",
      "6th- epoch: 7, train_loss = 87.47929364442825, train_acc = 0.8014671634839311\n",
      "test Acc 0.8105214152700186:\n",
      "6th- epoch: 8, train_loss = 77.78971108794212, train_acc = 0.8262692128551468\n",
      "test Acc 0.8337988826815642:\n",
      "6th- epoch: 9, train_loss = 69.38762304186821, train_acc = 0.8547973917093619\n",
      "test Acc 0.8659217877094972:\n",
      "6th- epoch: 10, train_loss = 62.16142311692238, train_acc = 0.8757568700512343\n",
      "test Acc 0.8789571694599627:\n",
      "6th- epoch: 11, train_loss = 56.03275924921036, train_acc = 0.8867023754075454\n",
      "test Acc 0.8873370577281192:\n",
      "6th- epoch: 12, train_loss = 50.897919073700905, train_acc = 0.8989287377736377\n",
      "test Acc 0.9013035381750466:\n",
      "6th- epoch: 13, train_loss = 46.621171697974205, train_acc = 0.9113879832324173\n",
      "test Acc 0.9162011173184358:\n",
      "6th- epoch: 14, train_loss = 43.05395655333996, train_acc = 0.9238472286911971\n",
      "test Acc 0.9245810055865922:\n",
      "6th- epoch: 15, train_loss = 40.05572149157524, train_acc = 0.9326967862133209\n",
      "test Acc 0.9320297951582868:\n",
      "6th- epoch: 16, train_loss = 37.49768626689911, train_acc = 0.9377037727061015\n",
      "test Acc 0.9343575418994413:\n",
      "6th- epoch: 17, train_loss = 35.30325302481651, train_acc = 0.9415463437354448\n",
      "test Acc 0.9380819366852886:\n",
      "6th- epoch: 18, train_loss = 33.405871979892254, train_acc = 0.9445738239403819\n",
      "test Acc 0.9418063314711359:\n",
      "6th- epoch: 19, train_loss = 31.752214580774307, train_acc = 0.946786213320913\n",
      "test Acc 0.9422718808193669:\n",
      "6th- epoch: 20, train_loss = 30.29815349727869, train_acc = 0.948067070330694\n",
      "test Acc 0.9427374301675978:\n",
      "6th- epoch: 21, train_loss = 29.008321925997734, train_acc = 0.950279459711225\n",
      "test Acc 0.9459962756052142:\n",
      "6th- epoch: 22, train_loss = 27.855518393218517, train_acc = 0.9513274336283186\n",
      "test Acc 0.9487895716945997:\n",
      "6th- epoch: 23, train_loss = 26.818207152187824, train_acc = 0.952026082906381\n",
      "test Acc 0.9497206703910615:\n",
      "6th- epoch: 24, train_loss = 25.87864127010107, train_acc = 0.9530740568234746\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 25, train_loss = 25.02276236563921, train_acc = 0.9542384722869119\n",
      "test Acc 0.9515828677839852:\n",
      "6th- epoch: 26, train_loss = 24.239572659134865, train_acc = 0.9557522123893806\n",
      "test Acc 0.952048417132216:\n",
      "6th- epoch: 27, train_loss = 23.519387915730476, train_acc = 0.956450861667443\n",
      "test Acc 0.952513966480447:\n",
      "6th- epoch: 28, train_loss = 22.853919710963964, train_acc = 0.9580810433162552\n",
      "test Acc 0.9548417132216015:\n",
      "6th- epoch: 29, train_loss = 22.235855404287577, train_acc = 0.9586632510479739\n",
      "test Acc 0.9548417132216015:\n",
      "6th- epoch: 30, train_loss = 21.65865533426404, train_acc = 0.9592454587796926\n",
      "test Acc 0.9548417132216015:\n",
      "6th- epoch: 31, train_loss = 21.117444921284914, train_acc = 0.9597112249650676\n",
      "test Acc 0.9557728119180633:\n",
      "6th- epoch: 32, train_loss = 20.608452778309584, train_acc = 0.9598276665114113\n",
      "test Acc 0.9567039106145251:\n",
      "6th- epoch: 33, train_loss = 20.127426777034998, train_acc = 0.9607591988821611\n",
      "test Acc 0.9567039106145251:\n",
      "6th- epoch: 34, train_loss = 19.671112556010485, train_acc = 0.9618071727992548\n",
      "test Acc 0.957169459962756:\n",
      "6th- epoch: 35, train_loss = 19.23748528212309, train_acc = 0.9630880298090359\n",
      "test Acc 0.957635009310987:\n",
      "6th- epoch: 36, train_loss = 18.823925584554672, train_acc = 0.963903120633442\n",
      "test Acc 0.9581005586592178:\n",
      "6th- epoch: 37, train_loss = 18.428542517125607, train_acc = 0.9646017699115044\n",
      "test Acc 0.9585661080074488:\n",
      "6th- epoch: 38, train_loss = 18.05028637126088, train_acc = 0.9651839776432231\n",
      "test Acc 0.9590316573556797:\n",
      "6th- epoch: 39, train_loss = 17.689011603593826, train_acc = 0.9658826269212856\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 40, train_loss = 17.343137931078672, train_acc = 0.9668141592920354\n",
      "test Acc 0.9604283054003724:\n",
      "6th- epoch: 41, train_loss = 17.012047637254, train_acc = 0.9672799254774104\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 42, train_loss = 16.6944100856781, train_acc = 0.9677456916627852\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 43, train_loss = 16.389289632439613, train_acc = 0.9683278993945039\n",
      "test Acc 0.9613594040968343:\n",
      "6th- epoch: 44, train_loss = 16.096072625368834, train_acc = 0.9687936655798789\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 45, train_loss = 15.814082328230143, train_acc = 0.9691429902189101\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 46, train_loss = 15.54239233955741, train_acc = 0.9692594317652539\n",
      "test Acc 0.9646182495344506:\n",
      "6th- epoch: 47, train_loss = 15.280288018286228, train_acc = 0.97007452258966\n",
      "test Acc 0.9650837988826816:\n",
      "6th- epoch: 48, train_loss = 15.027231853455305, train_acc = 0.9711224965067536\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 49, train_loss = 14.782985532656312, train_acc = 0.9715882626921285\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 50, train_loss = 14.546984042972326, train_acc = 0.9720540288775035\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 51, train_loss = 14.31853935867548, train_acc = 0.9725197950628784\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 52, train_loss = 14.097684767097235, train_acc = 0.9731020027945971\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 53, train_loss = 13.883666630834341, train_acc = 0.9739170936190032\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 54, train_loss = 13.676314916461706, train_acc = 0.9743828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 55, train_loss = 13.475718304514885, train_acc = 0.9743828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 56, train_loss = 13.28114888817072, train_acc = 0.9749650675360969\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 57, train_loss = 13.091498628258705, train_acc = 0.975314392175128\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 58, train_loss = 12.907464791089296, train_acc = 0.975314392175128\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 59, train_loss = 12.729061238467693, train_acc = 0.9755472752678156\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 60, train_loss = 12.555645905435085, train_acc = 0.9756637168141593\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 61, train_loss = 12.38761531189084, train_acc = 0.9763623660922217\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 62, train_loss = 12.2243413887918, train_acc = 0.9765952491849091\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 63, train_loss = 12.065198242664337, train_acc = 0.9767116907312529\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 64, train_loss = 11.910267990082502, train_acc = 0.9770610153702841\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 65, train_loss = 11.759816721081734, train_acc = 0.9772938984629715\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 66, train_loss = 11.613194562494755, train_acc = 0.9777596646483465\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 67, train_loss = 11.470297932624817, train_acc = 0.9778761061946902\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 68, train_loss = 11.330657932907343, train_acc = 0.9778761061946902\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 69, train_loss = 11.194433618336916, train_acc = 0.9781089892873778\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 70, train_loss = 11.061318803578615, train_acc = 0.9783418723800652\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 71, train_loss = 10.931244678795338, train_acc = 0.9784583139264089\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 72, train_loss = 10.804149247705936, train_acc = 0.9784583139264089\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 73, train_loss = 10.67932161130011, train_acc = 0.9784583139264089\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 74, train_loss = 10.557636665180326, train_acc = 0.9788076385654402\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 75, train_loss = 10.438316736370325, train_acc = 0.9788076385654402\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 76, train_loss = 10.321508524939418, train_acc = 0.9788076385654402\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 77, train_loss = 10.20702956803143, train_acc = 0.9789240801117839\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 78, train_loss = 10.0948770288378, train_acc = 0.9789240801117839\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 79, train_loss = 9.984852455556393, train_acc = 0.9788076385654402\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 80, train_loss = 9.876759726554155, train_acc = 0.9790405216581276\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 81, train_loss = 9.770790176466107, train_acc = 0.9790405216581276\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 82, train_loss = 9.666760172694921, train_acc = 0.9795062878435026\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 83, train_loss = 9.564523162320256, train_acc = 0.9796227293898463\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 84, train_loss = 9.46440982632339, train_acc = 0.9796227293898463\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 85, train_loss = 9.365757994353771, train_acc = 0.9796227293898463\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 86, train_loss = 9.268422618508339, train_acc = 0.9799720540288775\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 87, train_loss = 9.17217362858355, train_acc = 0.9800884955752213\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 88, train_loss = 9.078117432072759, train_acc = 0.9800884955752213\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 89, train_loss = 8.985961211845279, train_acc = 0.9803213786679087\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 90, train_loss = 8.895251039415598, train_acc = 0.98067070330694\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 91, train_loss = 8.806123863905668, train_acc = 0.9807871448532837\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 92, train_loss = 8.718358367681503, train_acc = 0.9811364694923148\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 93, train_loss = 8.632131149992347, train_acc = 0.9811364694923148\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 94, train_loss = 8.547426925972104, train_acc = 0.9818351187703773\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 95, train_loss = 8.463948564603925, train_acc = 0.9818351187703773\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 96, train_loss = 8.381611041724682, train_acc = 0.9821844434094085\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 97, train_loss = 8.30053056590259, train_acc = 0.9824173265020959\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 98, train_loss = 8.220504069700837, train_acc = 0.9826502095947834\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 99, train_loss = 8.141890062019229, train_acc = 0.9827666511411272\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 100, train_loss = 8.064270548522472, train_acc = 0.9828830926874709\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 101, train_loss = 7.987935151904821, train_acc = 0.9832324173265021\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 102, train_loss = 7.912656027823687, train_acc = 0.9835817419655333\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 103, train_loss = 7.838530281558633, train_acc = 0.9838146250582208\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 104, train_loss = 7.765360347926617, train_acc = 0.9843968327899395\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 105, train_loss = 7.693343346938491, train_acc = 0.9843968327899395\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 106, train_loss = 7.622157592326403, train_acc = 0.9847461574289706\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 107, train_loss = 7.5521923918277025, train_acc = 0.9850954820680019\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 108, train_loss = 7.483106324449182, train_acc = 0.9852119236143456\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 109, train_loss = 7.414989717304707, train_acc = 0.9852119236143456\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 110, train_loss = 7.347859473899007, train_acc = 0.9852119236143456\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 111, train_loss = 7.281513527035713, train_acc = 0.9853283651606893\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 112, train_loss = 7.216170946136117, train_acc = 0.9853283651606893\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 113, train_loss = 7.151905136182904, train_acc = 0.985444806707033\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 114, train_loss = 7.088078536093235, train_acc = 0.9855612482533768\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 115, train_loss = 7.025370988994837, train_acc = 0.9856776897997206\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 116, train_loss = 6.96335532143712, train_acc = 0.9857941313460643\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 117, train_loss = 6.902074368670583, train_acc = 0.9857941313460643\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 118, train_loss = 6.841728962957859, train_acc = 0.9857941313460643\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 119, train_loss = 6.782310513779521, train_acc = 0.9860270144387517\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 120, train_loss = 6.723599521443248, train_acc = 0.9861434559850955\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 121, train_loss = 6.66546586714685, train_acc = 0.9861434559850955\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 122, train_loss = 6.608317967504263, train_acc = 0.9861434559850955\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 123, train_loss = 6.551773676648736, train_acc = 0.9864927806241267\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 124, train_loss = 6.49605181440711, train_acc = 0.9866092221704704\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 125, train_loss = 6.441103462129831, train_acc = 0.9866092221704704\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 126, train_loss = 6.38693929836154, train_acc = 0.9869585468095017\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 127, train_loss = 6.33344629406929, train_acc = 0.9871914299021891\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 128, train_loss = 6.280700780451298, train_acc = 0.9871914299021891\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 129, train_loss = 6.228604858741164, train_acc = 0.9871914299021891\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 130, train_loss = 6.177429687231779, train_acc = 0.9873078714485328\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 131, train_loss = 6.126767110079527, train_acc = 0.9873078714485328\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 132, train_loss = 6.076707514002919, train_acc = 0.9873078714485328\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 133, train_loss = 6.027418015524745, train_acc = 0.9874243129948765\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 134, train_loss = 5.978627827018499, train_acc = 0.9875407545412203\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 135, train_loss = 5.93051584251225, train_acc = 0.9876571960875641\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 136, train_loss = 5.883006077259779, train_acc = 0.9876571960875641\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 137, train_loss = 5.835982562974095, train_acc = 0.9876571960875641\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 138, train_loss = 5.789794275537133, train_acc = 0.9876571960875641\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 139, train_loss = 5.744105180725455, train_acc = 0.9876571960875641\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 140, train_loss = 5.698953531682491, train_acc = 0.9876571960875641\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 141, train_loss = 5.6544414311647415, train_acc = 0.9878900791802515\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 142, train_loss = 5.610543221235275, train_acc = 0.9878900791802515\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 143, train_loss = 5.567109217867255, train_acc = 0.9881229622729389\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 144, train_loss = 5.524347577244043, train_acc = 0.9882394038192828\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 145, train_loss = 5.4821965377777815, train_acc = 0.9882394038192828\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 146, train_loss = 5.440506158396602, train_acc = 0.9882394038192828\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 147, train_loss = 5.39929855056107, train_acc = 0.9883558453656265\n",
      "test Acc 0.9762569832402235:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 148, train_loss = 5.35886855609715, train_acc = 0.9883558453656265\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 149, train_loss = 5.318582084029913, train_acc = 0.9883558453656265\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 150, train_loss = 5.278920501470566, train_acc = 0.9883558453656265\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 151, train_loss = 5.239920947700739, train_acc = 0.9885887284583139\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 152, train_loss = 5.201204065233469, train_acc = 0.9889380530973452\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 153, train_loss = 5.1629528142511845, train_acc = 0.9891709361900326\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 154, train_loss = 5.1254207622259855, train_acc = 0.9891709361900326\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 155, train_loss = 5.088142750784755, train_acc = 0.98940381928272\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 156, train_loss = 5.05137325823307, train_acc = 0.9895202608290639\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 157, train_loss = 5.015040779486299, train_acc = 0.9896367023754076\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 158, train_loss = 4.978970285505056, train_acc = 0.9897531439217513\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 159, train_loss = 4.943089848384261, train_acc = 0.989869585468095\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 160, train_loss = 4.907754374668002, train_acc = 0.989869585468095\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 161, train_loss = 4.872757059521973, train_acc = 0.9901024685607824\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 162, train_loss = 4.8383676232770085, train_acc = 0.9901024685607824\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 163, train_loss = 4.804691405035555, train_acc = 0.9901024685607824\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 164, train_loss = 4.771353806369007, train_acc = 0.9899860270144387\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 165, train_loss = 4.738183230161667, train_acc = 0.9901024685607824\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 166, train_loss = 4.705799430608749, train_acc = 0.9901024685607824\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 167, train_loss = 4.673480115830898, train_acc = 0.9901024685607824\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 168, train_loss = 4.641710651107132, train_acc = 0.99033535165347\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 169, train_loss = 4.610281805507839, train_acc = 0.9905682347461574\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 170, train_loss = 4.579321322031319, train_acc = 0.9905682347461574\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 171, train_loss = 4.548663509078324, train_acc = 0.9906846762925011\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 172, train_loss = 4.518414373509586, train_acc = 0.9909175593851887\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 173, train_loss = 4.488498792052269, train_acc = 0.9909175593851887\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 174, train_loss = 4.459020278416574, train_acc = 0.9909175593851887\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 175, train_loss = 4.429768331348896, train_acc = 0.9910340009315324\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 176, train_loss = 4.400793871842325, train_acc = 0.9911504424778761\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 177, train_loss = 4.37236659694463, train_acc = 0.9911504424778761\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 178, train_loss = 4.344158076681197, train_acc = 0.9912668840242198\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 179, train_loss = 4.316490546800196, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 180, train_loss = 4.2889507710933685, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 181, train_loss = 4.261703121475875, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 182, train_loss = 4.234898372553289, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 183, train_loss = 4.208362837322056, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 184, train_loss = 4.182021693326533, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 185, train_loss = 4.155996214598417, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 186, train_loss = 4.130318664945662, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 187, train_loss = 4.104932728223503, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 188, train_loss = 4.079873215407133, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 189, train_loss = 4.054944039322436, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 190, train_loss = 4.030475896783173, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 191, train_loss = 4.006108148954809, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 192, train_loss = 3.9820706387981772, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 193, train_loss = 3.958324675448239, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 194, train_loss = 3.934859797358513, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 195, train_loss = 3.911702918820083, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 196, train_loss = 3.888538971543312, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 197, train_loss = 3.8658964121714234, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 198, train_loss = 3.8432452976703644, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 199, train_loss = 3.8210845990106463, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 200, train_loss = 3.798985564149916, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 201, train_loss = 3.777219316922128, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 202, train_loss = 3.755534652620554, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 203, train_loss = 3.73416983243078, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 204, train_loss = 3.7130045210942626, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 205, train_loss = 3.6922486210241914, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 206, train_loss = 3.671556676737964, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 207, train_loss = 3.6511897714808583, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 208, train_loss = 3.630955212749541, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 209, train_loss = 3.611008409410715, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 210, train_loss = 3.5912609845399857, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 211, train_loss = 3.571722977794707, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 212, train_loss = 3.5523800337687135, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 213, train_loss = 3.5330657744780183, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 214, train_loss = 3.514267253689468, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 215, train_loss = 3.495322414673865, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 216, train_loss = 3.476872338913381, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 217, train_loss = 3.458299438469112, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 218, train_loss = 3.440100245177746, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 219, train_loss = 3.4221779219806194, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 220, train_loss = 3.404228395782411, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 221, train_loss = 3.3865299709141254, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 222, train_loss = 3.3690208792686462, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 223, train_loss = 3.351541397627443, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 224, train_loss = 3.3346426845528185, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 225, train_loss = 3.317550963256508, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 226, train_loss = 3.3007302321493626, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 227, train_loss = 3.2838848256506026, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 228, train_loss = 3.267602277453989, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 229, train_loss = 3.251094028353691, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 230, train_loss = 3.23500324646011, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 231, train_loss = 3.218949428293854, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 232, train_loss = 3.2030738391913474, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 233, train_loss = 3.1872991174459457, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 234, train_loss = 3.171719750855118, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 235, train_loss = 3.1562220603227615, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 236, train_loss = 3.1408774442970753, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 237, train_loss = 3.1256026178598404, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 238, train_loss = 3.110746680293232, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 239, train_loss = 3.0957846282981336, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 240, train_loss = 3.081111038569361, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 241, train_loss = 3.0665559978224337, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 242, train_loss = 3.051928238477558, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 243, train_loss = 3.0376698547042906, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 244, train_loss = 3.0235624187625945, train_acc = 0.993828598043782\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 245, train_loss = 3.009453372564167, train_acc = 0.993828598043782\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 246, train_loss = 2.995637819170952, train_acc = 0.9939450395901258\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 247, train_loss = 2.981783772353083, train_acc = 0.9939450395901258\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 248, train_loss = 2.9681308404542506, train_acc = 0.9939450395901258\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 249, train_loss = 2.954647157341242, train_acc = 0.9939450395901258\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 250, train_loss = 2.941169350873679, train_acc = 0.9939450395901258\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 251, train_loss = 2.9279039818793535, train_acc = 0.9939450395901258\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 252, train_loss = 2.9146171775646508, train_acc = 0.9939450395901258\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 253, train_loss = 2.9016162012703717, train_acc = 0.9940614811364695\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 254, train_loss = 2.888698970898986, train_acc = 0.9941779226828132\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 255, train_loss = 2.8757892274297774, train_acc = 0.9944108057755007\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 256, train_loss = 2.8630641661584377, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 257, train_loss = 2.8504298459738493, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 258, train_loss = 2.8380230739712715, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 259, train_loss = 2.8257133178412914, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 260, train_loss = 2.8133200122974813, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 261, train_loss = 2.8012611302547157, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 262, train_loss = 2.789064310491085, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 263, train_loss = 2.7772586955688894, train_acc = 0.994294364229157\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 264, train_loss = 2.765440484508872, train_acc = 0.994294364229157\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 265, train_loss = 2.753715377766639, train_acc = 0.994294364229157\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 266, train_loss = 2.7422932614572346, train_acc = 0.994294364229157\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 267, train_loss = 2.730577392037958, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 268, train_loss = 2.7191594163887203, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 269, train_loss = 2.7080206386744976, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 270, train_loss = 2.696775995194912, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 271, train_loss = 2.685844069812447, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 272, train_loss = 2.674662610515952, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 273, train_loss = 2.663841189816594, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 274, train_loss = 2.6530037545599043, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 275, train_loss = 2.642405783291906, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "6th- epoch: 276, train_loss = 2.6317274272441864, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 277, train_loss = 2.621213622391224, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 278, train_loss = 2.6108314977027476, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 279, train_loss = 2.600609270390123, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 280, train_loss = 2.5902893193997443, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 281, train_loss = 2.5802785246632993, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 282, train_loss = 2.5703516975045204, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 283, train_loss = 2.560336837079376, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 284, train_loss = 2.550600545015186, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 285, train_loss = 2.540799807757139, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 286, train_loss = 2.531109295785427, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 287, train_loss = 2.521652569528669, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 288, train_loss = 2.512193273752928, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 289, train_loss = 2.5028410986997187, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 290, train_loss = 2.4936654954217374, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 291, train_loss = 2.4842761382460594, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 292, train_loss = 2.4753492758609354, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 293, train_loss = 2.4660219796933234, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 294, train_loss = 2.457230588886887, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 295, train_loss = 2.448300365358591, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 296, train_loss = 2.4395567439496517, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 297, train_loss = 2.4308418706059456, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 298, train_loss = 2.4222740419209003, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 299, train_loss = 2.413780316710472, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 300, train_loss = 2.405105049489066, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 301, train_loss = 2.39697453007102, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 302, train_loss = 2.388509842334315, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 303, train_loss = 2.380547344684601, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 304, train_loss = 2.372255727648735, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 305, train_loss = 2.364348139613867, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 306, train_loss = 2.3561724920291454, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 307, train_loss = 2.3483558769803494, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 308, train_loss = 2.340444441884756, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 309, train_loss = 2.33292664331384, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 310, train_loss = 2.3250519931316376, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 311, train_loss = 2.31751944986172, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 312, train_loss = 2.309840612113476, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 313, train_loss = 2.302628481062129, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 314, train_loss = 2.2949543099384755, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 315, train_loss = 2.2876788687426597, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 316, train_loss = 2.2803953636903316, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 317, train_loss = 2.2733541391789913, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 318, train_loss = 2.2661516901571304, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 319, train_loss = 2.2591689296532422, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 320, train_loss = 2.2520933479536325, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 321, train_loss = 2.245035145431757, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 322, train_loss = 2.2384276806842536, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "6th- epoch: 323, train_loss = 2.231363955885172, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 324, train_loss = 2.2248718447517604, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 325, train_loss = 2.218159230425954, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 326, train_loss = 2.2116009413730353, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 327, train_loss = 2.2050433072727174, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 328, train_loss = 2.198563805548474, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 329, train_loss = 2.1921445566695184, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 330, train_loss = 2.1857779000420123, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 331, train_loss = 2.1792727273423225, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 332, train_loss = 2.173109207302332, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 333, train_loss = 2.1669006173033267, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 334, train_loss = 2.1608519952278584, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 335, train_loss = 2.154630582779646, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 336, train_loss = 2.148745923070237, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 337, train_loss = 2.142655525356531, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 338, train_loss = 2.136748329969123, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 339, train_loss = 2.1309045776724815, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 340, train_loss = 2.12499263510108, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 341, train_loss = 2.119261833606288, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 342, train_loss = 2.113609171239659, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 343, train_loss = 2.1078013963997364, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 344, train_loss = 2.1022493715863675, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 345, train_loss = 2.096643612952903, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 346, train_loss = 2.0911624792497605, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 347, train_loss = 2.0856209720950574, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 348, train_loss = 2.0801493239123374, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 349, train_loss = 2.0746989760082215, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 350, train_loss = 2.0694947440642864, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 351, train_loss = 2.0642159308772534, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 352, train_loss = 2.0589993346948177, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 353, train_loss = 2.053754697320983, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 354, train_loss = 2.0484951101243496, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 355, train_loss = 2.043527563335374, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 356, train_loss = 2.03825818374753, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 357, train_loss = 2.033463229658082, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 358, train_loss = 2.0281749356072396, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 359, train_loss = 2.0234484001994133, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 360, train_loss = 2.018472097814083, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 361, train_loss = 2.0136292714159936, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 362, train_loss = 2.0087264243047684, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 363, train_loss = 2.0039119545836, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 364, train_loss = 1.9991943910717964, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 365, train_loss = 1.9944234676659107, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 366, train_loss = 1.989678356796503, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 367, train_loss = 1.9850883919280022, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 368, train_loss = 1.9804863047320396, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 369, train_loss = 1.975779302418232, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 370, train_loss = 1.9712675262708217, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 371, train_loss = 1.9668411575257778, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 372, train_loss = 1.9622053888160735, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 373, train_loss = 1.9577870916109532, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 374, train_loss = 1.9533070039469749, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 375, train_loss = 1.9490202728193253, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 376, train_loss = 1.9446578361093998, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 377, train_loss = 1.9402681589126587, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 378, train_loss = 1.936017279746011, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 379, train_loss = 1.9317186672706157, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 380, train_loss = 1.92750895768404, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 381, train_loss = 1.9231497645378113, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 382, train_loss = 1.9189859330654144, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 383, train_loss = 1.9150117635726929, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 384, train_loss = 1.9107723087072372, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 385, train_loss = 1.9066556667676196, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 386, train_loss = 1.9027011481812224, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 387, train_loss = 1.8985199196031317, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 388, train_loss = 1.8944281613221392, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 389, train_loss = 1.8905848301947117, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 390, train_loss = 1.886588522582315, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 391, train_loss = 1.8827829957008362, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 392, train_loss = 1.8788818530738354, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 393, train_loss = 1.8749977201223373, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 394, train_loss = 1.8714302219450474, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 395, train_loss = 1.8677137730410323, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 396, train_loss = 1.8637977056205273, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 397, train_loss = 1.8603576211025938, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 398, train_loss = 1.8568213569233194, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 399, train_loss = 1.852971794665791, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 400, train_loss = 1.849629228352569, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 401, train_loss = 1.845983099192381, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 402, train_loss = 1.842459037899971, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 403, train_loss = 1.8389918593456969, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 404, train_loss = 1.8356671370565891, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 405, train_loss = 1.8321223556995392, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 406, train_loss = 1.82875147217419, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 407, train_loss = 1.8252673061797395, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 408, train_loss = 1.8219586052000523, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 409, train_loss = 1.8185798277845606, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 410, train_loss = 1.8153643744299188, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 411, train_loss = 1.8120035156607628, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 412, train_loss = 1.8088434027740732, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 413, train_loss = 1.805563019006513, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 414, train_loss = 1.8024079451570287, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 415, train_loss = 1.7991181103279814, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 416, train_loss = 1.796068018884398, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 417, train_loss = 1.7928178571164608, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 418, train_loss = 1.7896902970969677, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 419, train_loss = 1.7866330990800634, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 420, train_loss = 1.783533200621605, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 421, train_loss = 1.7806178653845564, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 422, train_loss = 1.7774253351381049, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 423, train_loss = 1.7743615297367796, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 424, train_loss = 1.7715271251508966, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 425, train_loss = 1.768478679121472, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 426, train_loss = 1.765658374875784, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 427, train_loss = 1.7626201920211315, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 428, train_loss = 1.759519593208097, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 429, train_loss = 1.7567011615028605, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 430, train_loss = 1.7539409883320332, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 431, train_loss = 1.7509939633309841, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 432, train_loss = 1.7480736337602139, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 433, train_loss = 1.7453289130935445, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 434, train_loss = 1.7425694428384304, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 435, train_loss = 1.7398524271557108, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 436, train_loss = 1.7371819416293874, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 437, train_loss = 1.7343674935400486, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 438, train_loss = 1.7315981512656435, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 439, train_loss = 1.7288531934609637, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 440, train_loss = 1.7262673862278461, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 441, train_loss = 1.72351662942674, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 442, train_loss = 1.7209824150195345, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 443, train_loss = 1.7182886736700311, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 444, train_loss = 1.7155980815878138, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 445, train_loss = 1.7131337486207485, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 446, train_loss = 1.7104521356523037, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 447, train_loss = 1.7079967806348577, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 448, train_loss = 1.705535002052784, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 449, train_loss = 1.7031163634965196, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 450, train_loss = 1.7004581888904795, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 451, train_loss = 1.6979981722543016, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 452, train_loss = 1.6956727182259783, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 453, train_loss = 1.69312120473478, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 454, train_loss = 1.6905883984873071, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 455, train_loss = 1.6882357274880633, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 456, train_loss = 1.6858085443964228, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 457, train_loss = 1.683396446169354, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 458, train_loss = 1.6810138722648844, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 459, train_loss = 1.6785839386284351, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 460, train_loss = 1.67636414244771, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 461, train_loss = 1.6741714477539062, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 462, train_loss = 1.6718171735992655, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 463, train_loss = 1.6694904007017612, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 464, train_loss = 1.66722361498978, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 465, train_loss = 1.6650254180422053, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 466, train_loss = 1.6627207919955254, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 467, train_loss = 1.660555299371481, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 468, train_loss = 1.6583626804640517, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 469, train_loss = 1.6560426031937823, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 470, train_loss = 1.6538714977214113, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 471, train_loss = 1.651720091700554, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 472, train_loss = 1.6496314158430323, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 473, train_loss = 1.6473741456866264, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 474, train_loss = 1.645280814380385, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 475, train_loss = 1.6431168963899836, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 476, train_loss = 1.641096374602057, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 477, train_loss = 1.6388224884867668, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 478, train_loss = 1.636829324066639, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 479, train_loss = 1.6347654635319486, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 480, train_loss = 1.6326678631594405, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 481, train_loss = 1.6305758754024282, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 482, train_loss = 1.6286219669273123, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "6th- epoch: 483, train_loss = 1.6265247439732775, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 484, train_loss = 1.6247038567671552, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 485, train_loss = 1.6225809218594804, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 486, train_loss = 1.6206707209348679, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 487, train_loss = 1.6186264330754057, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 488, train_loss = 1.616673612385057, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 489, train_loss = 1.6146998790791258, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 490, train_loss = 1.6127124789054506, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 491, train_loss = 1.6108276757295243, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 492, train_loss = 1.6088080704212189, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 493, train_loss = 1.6070075407624245, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 494, train_loss = 1.6051031586830504, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 495, train_loss = 1.6032627274398692, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 496, train_loss = 1.6013011572067626, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 497, train_loss = 1.5996053330600262, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 498, train_loss = 1.5977173472638242, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 499, train_loss = 1.5958736563916318, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████▌                                                          | 6/30 [39:51<2:39:24, 398.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "7th- epoch: 0, train_loss = 271.22323656082153, train_acc = 0.45144387517466233\n",
      "test Acc 0.4934823091247672:\n",
      "7th- epoch: 1, train_loss = 207.68267226219177, train_acc = 0.49627387051700045\n",
      "test Acc 0.4995344506517691:\n",
      "7th- epoch: 2, train_loss = 167.9548476934433, train_acc = 0.5203772706101537\n",
      "test Acc 0.5516759776536313:\n",
      "7th- epoch: 3, train_loss = 146.55672812461853, train_acc = 0.6273870517000466\n",
      "test Acc 0.702048417132216:\n",
      "7th- epoch: 4, train_loss = 128.46742683649063, train_acc = 0.7136702375407545\n",
      "test Acc 0.7346368715083799:\n",
      "7th- epoch: 5, train_loss = 112.10292863845825, train_acc = 0.7366092221704704\n",
      "test Acc 0.7532588454376163:\n",
      "7th- epoch: 6, train_loss = 98.10619112849236, train_acc = 0.7639729855612483\n",
      "test Acc 0.787243947858473:\n",
      "7th- epoch: 7, train_loss = 86.52737864851952, train_acc = 0.8090358639962739\n",
      "test Acc 0.8198324022346368:\n",
      "7th- epoch: 8, train_loss = 76.78765150904655, train_acc = 0.843735444806707\n",
      "test Acc 0.8547486033519553:\n",
      "7th- epoch: 9, train_loss = 68.47053322196007, train_acc = 0.8667908709827666\n",
      "test Acc 0.87756052141527:\n",
      "7th- epoch: 10, train_loss = 61.43174850940704, train_acc = 0.8818118304611086\n",
      "test Acc 0.8905959031657356:\n",
      "7th- epoch: 11, train_loss = 55.53650073707104, train_acc = 0.8892640894271076\n",
      "test Acc 0.8952513966480447:\n",
      "7th- epoch: 12, train_loss = 50.6138274371624, train_acc = 0.8972985561248253\n",
      "test Acc 0.9027001862197392:\n",
      "7th- epoch: 13, train_loss = 46.47403594851494, train_acc = 0.911970190964136\n",
      "test Acc 0.9189944134078212:\n",
      "7th- epoch: 14, train_loss = 42.97006204724312, train_acc = 0.9252445272473219\n",
      "test Acc 0.9297020484171322:\n",
      "7th- epoch: 15, train_loss = 39.98820540308952, train_acc = 0.9328132277596647\n",
      "test Acc 0.9357541899441341:\n",
      "7th- epoch: 16, train_loss = 37.42249397933483, train_acc = 0.9381695388914765\n",
      "test Acc 0.9394785847299814:\n",
      "7th- epoch: 17, train_loss = 35.20419281721115, train_acc = 0.9413134606427573\n",
      "test Acc 0.9394785847299814:\n",
      "7th- epoch: 18, train_loss = 33.2736734226346, train_acc = 0.9434094084769445\n",
      "test Acc 0.9399441340782123:\n",
      "7th- epoch: 19, train_loss = 31.584700785577297, train_acc = 0.9486492780624126\n",
      "test Acc 0.9441340782122905:\n",
      "7th- epoch: 20, train_loss = 30.095749579370022, train_acc = 0.9514438751746623\n",
      "test Acc 0.9445996275605214:\n",
      "7th- epoch: 21, train_loss = 28.776199832558632, train_acc = 0.9528411737307871\n",
      "test Acc 0.9450651769087524:\n",
      "7th- epoch: 22, train_loss = 27.60100894421339, train_acc = 0.9530740568234746\n",
      "test Acc 0.9464618249534451:\n",
      "7th- epoch: 23, train_loss = 26.547996804118156, train_acc = 0.9545877969259432\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 24, train_loss = 25.59897757321596, train_acc = 0.955519329296693\n",
      "test Acc 0.9492551210428305:\n",
      "7th- epoch: 25, train_loss = 24.738059654831886, train_acc = 0.9561015370284117\n",
      "test Acc 0.9501862197392924:\n",
      "7th- epoch: 26, train_loss = 23.95352264493704, train_acc = 0.9570330693991617\n",
      "test Acc 0.952048417132216:\n",
      "7th- epoch: 27, train_loss = 23.233181413263083, train_acc = 0.9577317186772241\n",
      "test Acc 0.9534450651769087:\n",
      "7th- epoch: 28, train_loss = 22.568625535815954, train_acc = 0.9587796925943176\n",
      "test Acc 0.9539106145251397:\n",
      "7th- epoch: 29, train_loss = 21.953068524599075, train_acc = 0.9592454587796926\n",
      "test Acc 0.9548417132216015:\n",
      "7th- epoch: 30, train_loss = 21.380521323531866, train_acc = 0.9598276665114113\n",
      "test Acc 0.9548417132216015:\n",
      "7th- epoch: 31, train_loss = 20.845688614994287, train_acc = 0.9608756404285049\n",
      "test Acc 0.9557728119180633:\n",
      "7th- epoch: 32, train_loss = 20.34463907778263, train_acc = 0.9613414066138798\n",
      "test Acc 0.9562383612662942:\n",
      "7th- epoch: 33, train_loss = 19.872884586453438, train_acc = 0.962156497438286\n",
      "test Acc 0.957169459962756:\n",
      "7th- epoch: 34, train_loss = 19.42800735682249, train_acc = 0.9623893805309734\n",
      "test Acc 0.957635009310987:\n",
      "7th- epoch: 35, train_loss = 19.007219936698675, train_acc = 0.9630880298090359\n",
      "test Acc 0.957635009310987:\n",
      "7th- epoch: 36, train_loss = 18.608255211263895, train_acc = 0.9636702375407545\n",
      "test Acc 0.9585661080074488:\n",
      "7th- epoch: 37, train_loss = 18.229420635849237, train_acc = 0.9640195621797858\n",
      "test Acc 0.9585661080074488:\n",
      "7th- epoch: 38, train_loss = 17.868815384805202, train_acc = 0.9649510945505356\n",
      "test Acc 0.9585661080074488:\n",
      "7th- epoch: 39, train_loss = 17.525030553340912, train_acc = 0.9654168607359106\n",
      "test Acc 0.9590316573556797:\n",
      "7th- epoch: 40, train_loss = 17.19639977067709, train_acc = 0.9663483931066604\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 41, train_loss = 16.88177039846778, train_acc = 0.9668141592920354\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 42, train_loss = 16.580413416028023, train_acc = 0.9680950163018165\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 43, train_loss = 16.29148480296135, train_acc = 0.9697251979506288\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 44, train_loss = 16.014103919267654, train_acc = 0.970540288775035\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 45, train_loss = 15.747783325612545, train_acc = 0.9717047042384723\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 46, train_loss = 15.491287471726537, train_acc = 0.9720540288775035\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 47, train_loss = 15.243744254112244, train_acc = 0.9728691197019096\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 48, train_loss = 15.00492430664599, train_acc = 0.9733348858872846\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 49, train_loss = 14.774367541074753, train_acc = 0.9734513274336283\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 50, train_loss = 14.550606478005648, train_acc = 0.9738006520726595\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 51, train_loss = 14.334037888795137, train_acc = 0.9742664182580345\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 52, train_loss = 14.124145798385143, train_acc = 0.9743828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 53, train_loss = 13.920506663620472, train_acc = 0.9746157428970657\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 54, train_loss = 13.722641941159964, train_acc = 0.9748486259897532\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 55, train_loss = 13.530233401805162, train_acc = 0.9749650675360969\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 56, train_loss = 13.342950209975243, train_acc = 0.975314392175128\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 57, train_loss = 13.160541951656342, train_acc = 0.9756637168141593\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 58, train_loss = 12.982641946524382, train_acc = 0.9761294829995343\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 59, train_loss = 12.809345703572035, train_acc = 0.976245924545878\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 60, train_loss = 12.64041930064559, train_acc = 0.976245924545878\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 61, train_loss = 12.475748352706432, train_acc = 0.9763623660922217\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 62, train_loss = 12.31496712192893, train_acc = 0.9764788076385654\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 63, train_loss = 12.158314783126116, train_acc = 0.9765952491849091\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 64, train_loss = 12.005430992692709, train_acc = 0.9767116907312529\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 65, train_loss = 11.856058452278376, train_acc = 0.9769445738239404\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 66, train_loss = 11.710174687206745, train_acc = 0.9771774569166278\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 67, train_loss = 11.567702459171414, train_acc = 0.9771774569166278\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 68, train_loss = 11.428517390042543, train_acc = 0.9772938984629715\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 69, train_loss = 11.292681254446507, train_acc = 0.9772938984629715\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 70, train_loss = 11.159857030957937, train_acc = 0.9775267815556591\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 71, train_loss = 11.02970010228455, train_acc = 0.977992547741034\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 72, train_loss = 10.9021105337888, train_acc = 0.9781089892873778\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 73, train_loss = 10.777053290978074, train_acc = 0.9785747554727526\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 74, train_loss = 10.6546864900738, train_acc = 0.9786911970190965\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 75, train_loss = 10.535094099119306, train_acc = 0.9789240801117839\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 76, train_loss = 10.417701790109277, train_acc = 0.9790405216581276\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 77, train_loss = 10.302914021536708, train_acc = 0.9791569632044713\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 78, train_loss = 10.18994865193963, train_acc = 0.9792734047508151\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 79, train_loss = 10.07904233597219, train_acc = 0.9793898462971589\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 80, train_loss = 9.970694730058312, train_acc = 0.9793898462971589\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 81, train_loss = 9.864694021642208, train_acc = 0.9796227293898463\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 82, train_loss = 9.760662911459804, train_acc = 0.9796227293898463\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 83, train_loss = 9.658589949831367, train_acc = 0.9798556124825337\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 84, train_loss = 9.558260513469577, train_acc = 0.9800884955752213\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 85, train_loss = 9.45957543514669, train_acc = 0.980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 86, train_loss = 9.362686801701784, train_acc = 0.9805542617605962\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 87, train_loss = 9.267424087971449, train_acc = 0.9805542617605962\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 88, train_loss = 9.173514809459448, train_acc = 0.9807871448532837\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 89, train_loss = 9.081098560243845, train_acc = 0.98067070330694\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 90, train_loss = 8.990197863429785, train_acc = 0.9807871448532837\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 91, train_loss = 8.900596115738153, train_acc = 0.9807871448532837\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 92, train_loss = 8.812350146472454, train_acc = 0.9809035863996274\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 93, train_loss = 8.725341495126486, train_acc = 0.9810200279459711\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 94, train_loss = 8.639593802392483, train_acc = 0.9810200279459711\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 95, train_loss = 8.555045485496521, train_acc = 0.9811364694923148\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 96, train_loss = 8.47181093879044, train_acc = 0.9812529110386586\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 97, train_loss = 8.389856804162264, train_acc = 0.9814857941313461\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 98, train_loss = 8.309211546555161, train_acc = 0.9814857941313461\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 99, train_loss = 8.22960251569748, train_acc = 0.9818351187703773\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 100, train_loss = 8.151158878579736, train_acc = 0.9820680018630648\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 101, train_loss = 8.073688903823495, train_acc = 0.9825337680484397\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 102, train_loss = 7.9973530154675245, train_acc = 0.9827666511411272\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 103, train_loss = 7.922163167968392, train_acc = 0.9828830926874709\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 104, train_loss = 7.847783492878079, train_acc = 0.9831159757801584\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 105, train_loss = 7.774508638307452, train_acc = 0.9831159757801584\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 106, train_loss = 7.7022013030946255, train_acc = 0.9831159757801584\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 107, train_loss = 7.630685996264219, train_acc = 0.9831159757801584\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 108, train_loss = 7.560126392170787, train_acc = 0.9833488588728458\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 109, train_loss = 7.490473952144384, train_acc = 0.9835817419655333\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 110, train_loss = 7.421743096783757, train_acc = 0.9838146250582208\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 111, train_loss = 7.353729510679841, train_acc = 0.9838146250582208\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 112, train_loss = 7.286782722920179, train_acc = 0.9840475081509082\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 113, train_loss = 7.220384793356061, train_acc = 0.9842803912435957\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 114, train_loss = 7.15505001693964, train_acc = 0.9845132743362832\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 115, train_loss = 7.090597903355956, train_acc = 0.9846297158826269\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 116, train_loss = 7.027267577126622, train_acc = 0.9847461574289706\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 117, train_loss = 6.964688977226615, train_acc = 0.9848625989753144\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 118, train_loss = 6.902922106906772, train_acc = 0.9847461574289706\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 119, train_loss = 6.841775301843882, train_acc = 0.9850954820680019\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 120, train_loss = 6.781341254711151, train_acc = 0.9853283651606893\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 121, train_loss = 6.721912046894431, train_acc = 0.985444806707033\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 122, train_loss = 6.663057195022702, train_acc = 0.9857941313460643\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 123, train_loss = 6.604839378967881, train_acc = 0.985910572892408\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 124, train_loss = 6.5474146865308285, train_acc = 0.9860270144387517\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 125, train_loss = 6.490510897710919, train_acc = 0.9861434559850955\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 126, train_loss = 6.434424163773656, train_acc = 0.9861434559850955\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 127, train_loss = 6.379015114158392, train_acc = 0.986376339077783\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 128, train_loss = 6.324182199314237, train_acc = 0.9864927806241267\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 129, train_loss = 6.270139340311289, train_acc = 0.9867256637168141\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 130, train_loss = 6.2168302945792675, train_acc = 0.9868421052631579\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 131, train_loss = 6.164075758308172, train_acc = 0.9871914299021891\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 132, train_loss = 6.111950943246484, train_acc = 0.9873078714485328\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 133, train_loss = 6.0605832897126675, train_acc = 0.9876571960875641\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 134, train_loss = 6.009668979793787, train_acc = 0.9877736376339078\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 135, train_loss = 5.959454894065857, train_acc = 0.9877736376339078\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 136, train_loss = 5.909967707470059, train_acc = 0.9880065207265952\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 137, train_loss = 5.861068584024906, train_acc = 0.9881229622729389\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 138, train_loss = 5.812745777890086, train_acc = 0.9882394038192828\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 139, train_loss = 5.765135392546654, train_acc = 0.9883558453656265\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 140, train_loss = 5.718160603195429, train_acc = 0.9885887284583139\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 141, train_loss = 5.67179006151855, train_acc = 0.9887051700046576\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 142, train_loss = 5.626079523935914, train_acc = 0.9888216115510013\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 143, train_loss = 5.580830937251449, train_acc = 0.9888216115510013\n",
      "test Acc 0.9757914338919925:\n",
      "7th- epoch: 144, train_loss = 5.536280866712332, train_acc = 0.9890544946436889\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 145, train_loss = 5.492313217371702, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 146, train_loss = 5.448802683502436, train_acc = 0.9892873777363763\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 147, train_loss = 5.405892986804247, train_acc = 0.9892873777363763\n",
      "test Acc 0.9767225325884544:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 148, train_loss = 5.363553009927273, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 149, train_loss = 5.3217499032616615, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 150, train_loss = 5.280495960265398, train_acc = 0.9895202608290639\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 151, train_loss = 5.239608135074377, train_acc = 0.9895202608290639\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 152, train_loss = 5.19939099624753, train_acc = 0.9896367023754076\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 153, train_loss = 5.159762728027999, train_acc = 0.9896367023754076\n",
      "test Acc 0.9776536312849162:\n",
      "7th- epoch: 154, train_loss = 5.120587473735213, train_acc = 0.9896367023754076\n",
      "test Acc 0.9776536312849162:\n",
      "7th- epoch: 155, train_loss = 5.081824050284922, train_acc = 0.989869585468095\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 156, train_loss = 5.04369671177119, train_acc = 0.9899860270144387\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 157, train_loss = 5.00586973875761, train_acc = 0.9899860270144387\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 158, train_loss = 4.968766868114471, train_acc = 0.9899860270144387\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 159, train_loss = 4.931928711943328, train_acc = 0.9899860270144387\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 160, train_loss = 4.895763854496181, train_acc = 0.9899860270144387\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 161, train_loss = 4.859921571798623, train_acc = 0.9899860270144387\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 162, train_loss = 4.824487551115453, train_acc = 0.9899860270144387\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 163, train_loss = 4.789596647955477, train_acc = 0.9899860270144387\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 164, train_loss = 4.755004799924791, train_acc = 0.9899860270144387\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 165, train_loss = 4.721128067933023, train_acc = 0.9902189101071263\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 166, train_loss = 4.687541960738599, train_acc = 0.99033535165347\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 167, train_loss = 4.654407665133476, train_acc = 0.99033535165347\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 168, train_loss = 4.621863122098148, train_acc = 0.9904517931998137\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 169, train_loss = 4.589468642137945, train_acc = 0.9905682347461574\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 170, train_loss = 4.557631035335362, train_acc = 0.9906846762925011\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 171, train_loss = 4.526332151144743, train_acc = 0.9906846762925011\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 172, train_loss = 4.495183994062245, train_acc = 0.990801117838845\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 173, train_loss = 4.4646111922338605, train_acc = 0.990801117838845\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 174, train_loss = 4.4343647146597505, train_acc = 0.990801117838845\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 175, train_loss = 4.404384487308562, train_acc = 0.990801117838845\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 176, train_loss = 4.374959839507937, train_acc = 0.990801117838845\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 177, train_loss = 4.345852111466229, train_acc = 0.9909175593851887\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 178, train_loss = 4.3169530956074595, train_acc = 0.9909175593851887\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 179, train_loss = 4.288499028421938, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 180, train_loss = 4.260340346954763, train_acc = 0.9911504424778761\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 181, train_loss = 4.232481677085161, train_acc = 0.9911504424778761\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 182, train_loss = 4.205184911377728, train_acc = 0.9912668840242198\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 183, train_loss = 4.1780942706391215, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 184, train_loss = 4.151436655782163, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 185, train_loss = 4.124926814809442, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 186, train_loss = 4.098957567475736, train_acc = 0.9916162086632511\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 187, train_loss = 4.073281545192003, train_acc = 0.9916162086632511\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 188, train_loss = 4.047746262513101, train_acc = 0.9917326502095948\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 189, train_loss = 4.022693081758916, train_acc = 0.9918490917559385\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 190, train_loss = 3.997727788053453, train_acc = 0.9919655333022822\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 191, train_loss = 3.973267330788076, train_acc = 0.9919655333022822\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 192, train_loss = 3.9488499015569687, train_acc = 0.992081974848626\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 193, train_loss = 3.9250081907957792, train_acc = 0.992081974848626\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 194, train_loss = 3.9012916265055537, train_acc = 0.992081974848626\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 195, train_loss = 3.8778292182832956, train_acc = 0.992081974848626\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 196, train_loss = 3.8546995408833027, train_acc = 0.992081974848626\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 197, train_loss = 3.831821539439261, train_acc = 0.9921984163949698\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 198, train_loss = 3.8091778634116054, train_acc = 0.9921984163949698\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 199, train_loss = 3.786880603991449, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 200, train_loss = 3.764787696301937, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 201, train_loss = 3.742959886789322, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 202, train_loss = 3.721341355703771, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 203, train_loss = 3.7000446459278464, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 204, train_loss = 3.678882625885308, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 205, train_loss = 3.658041683025658, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 206, train_loss = 3.6373741924762726, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 207, train_loss = 3.616940542124212, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 208, train_loss = 3.5968754291534424, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 209, train_loss = 3.5767736919224262, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 210, train_loss = 3.5570506351068616, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 211, train_loss = 3.5375287691131234, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 212, train_loss = 3.5181088312529027, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 213, train_loss = 3.499060222413391, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 214, train_loss = 3.4800844700075686, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 215, train_loss = 3.4613958573900163, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 216, train_loss = 3.4429031908512115, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 217, train_loss = 3.4245463185943663, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 218, train_loss = 3.4063586010597646, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 219, train_loss = 3.3883917084895074, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 220, train_loss = 3.3705725646577775, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 221, train_loss = 3.353124705608934, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 222, train_loss = 3.33549045259133, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 223, train_loss = 3.3184045827947557, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 224, train_loss = 3.3012514249421656, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 225, train_loss = 3.284349671099335, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 226, train_loss = 3.26759215304628, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 227, train_loss = 3.2510687322355807, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 228, train_loss = 3.234482912812382, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 229, train_loss = 3.2182473042048514, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 230, train_loss = 3.202089275699109, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 231, train_loss = 3.1861059521324933, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 232, train_loss = 3.1702241650782526, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 233, train_loss = 3.1545290048234165, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 234, train_loss = 3.138972937595099, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 235, train_loss = 3.123618120793253, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 236, train_loss = 3.108363576233387, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 237, train_loss = 3.0932576153427362, train_acc = 0.9939450395901258\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 238, train_loss = 3.078359615057707, train_acc = 0.9939450395901258\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 239, train_loss = 3.0634610820561647, train_acc = 0.9940614811364695\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 240, train_loss = 3.048898930195719, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 241, train_loss = 3.0342836403287947, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 242, train_loss = 3.0199281596578658, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 243, train_loss = 3.005498757120222, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 244, train_loss = 2.9915365241467953, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 245, train_loss = 2.9775647525675595, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 246, train_loss = 2.963555246591568, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 247, train_loss = 2.9499088544398546, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 248, train_loss = 2.9362666090019047, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 249, train_loss = 2.922811208292842, train_acc = 0.9941779226828132\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 250, train_loss = 2.909316806588322, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 251, train_loss = 2.8961461926810443, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 252, train_loss = 2.883076574187726, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 253, train_loss = 2.8699801359325647, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 254, train_loss = 2.857240824494511, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 255, train_loss = 2.8444880228489637, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 256, train_loss = 2.8318951413966715, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 257, train_loss = 2.8193741063587368, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 258, train_loss = 2.807049337774515, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 259, train_loss = 2.794693840201944, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 260, train_loss = 2.7826315481215715, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 261, train_loss = 2.7705509695224464, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 262, train_loss = 2.758646283764392, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 263, train_loss = 2.7468190961517394, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 264, train_loss = 2.7352077439427376, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 265, train_loss = 2.723573236260563, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 266, train_loss = 2.7121467790566385, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 267, train_loss = 2.7007404663600028, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 268, train_loss = 2.689458731096238, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 269, train_loss = 2.6783766676671803, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 270, train_loss = 2.6672195997089148, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 271, train_loss = 2.6563655105419457, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 272, train_loss = 2.645463873166591, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 273, train_loss = 2.634756850078702, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 274, train_loss = 2.624076798558235, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 275, train_loss = 2.613458211068064, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 276, train_loss = 2.6030733971856534, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 277, train_loss = 2.592740414198488, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 278, train_loss = 2.582468920852989, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 279, train_loss = 2.5722919167019427, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 280, train_loss = 2.562289336230606, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 281, train_loss = 2.5522230020724237, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 282, train_loss = 2.542324762791395, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 283, train_loss = 2.532603081315756, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 284, train_loss = 2.5228300504386425, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 285, train_loss = 2.5132834003306925, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 286, train_loss = 2.503694554325193, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 287, train_loss = 2.4943278380669653, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 288, train_loss = 2.484997925814241, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 289, train_loss = 2.4757046387530863, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 290, train_loss = 2.466646804008633, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 291, train_loss = 2.457502496894449, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 292, train_loss = 2.448601128999144, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 293, train_loss = 2.439681441988796, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 294, train_loss = 2.4309180341660976, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 295, train_loss = 2.422167773125693, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 296, train_loss = 2.413540657609701, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 297, train_loss = 2.4050001588184386, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 298, train_loss = 2.3964729346334934, train_acc = 0.9947601304145319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 299, train_loss = 2.388145238161087, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 300, train_loss = 2.3797537696082145, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 301, train_loss = 2.3715690176468343, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 302, train_loss = 2.3633750441949815, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 303, train_loss = 2.355364788323641, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 304, train_loss = 2.3473428424913436, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 305, train_loss = 2.339309886097908, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 306, train_loss = 2.331557473866269, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 307, train_loss = 2.3236461095511913, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 308, train_loss = 2.315919329645112, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 309, train_loss = 2.308267742395401, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 310, train_loss = 2.3006603841204196, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 311, train_loss = 2.293182924389839, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 312, train_loss = 2.285746082663536, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 313, train_loss = 2.2783595819491893, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 314, train_loss = 2.271132566034794, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 315, train_loss = 2.263833073200658, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 316, train_loss = 2.256727936444804, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 317, train_loss = 2.249619147507474, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 318, train_loss = 2.242659818381071, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 319, train_loss = 2.235605721594766, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 320, train_loss = 2.2287931330502033, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 321, train_loss = 2.2220051176846027, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 322, train_loss = 2.215155627578497, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 323, train_loss = 2.2085343424696475, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 324, train_loss = 2.201830965699628, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 325, train_loss = 2.1953213165979832, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 326, train_loss = 2.1887815955560654, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 327, train_loss = 2.182390533387661, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 328, train_loss = 2.1759410586673766, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 329, train_loss = 2.169648338109255, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 330, train_loss = 2.163349526003003, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 331, train_loss = 2.1571806725114584, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 332, train_loss = 2.1510309621226043, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 333, train_loss = 2.144825315102935, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 334, train_loss = 2.138871454866603, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 335, train_loss = 2.1328552153427154, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 336, train_loss = 2.126901821466163, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 337, train_loss = 2.121071308851242, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 338, train_loss = 2.11515495297499, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 339, train_loss = 2.1094314977526665, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 340, train_loss = 2.1036359209101647, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 341, train_loss = 2.0980325501877815, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 342, train_loss = 2.092431463301182, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 343, train_loss = 2.0867551390547305, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 344, train_loss = 2.0812584161758423, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 345, train_loss = 2.0758070275187492, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 346, train_loss = 2.0702797297853976, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 347, train_loss = 2.064972944557667, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 348, train_loss = 2.0595828033983707, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 349, train_loss = 2.05427602189593, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 350, train_loss = 2.0489998708944768, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 351, train_loss = 2.043796554207802, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 352, train_loss = 2.0386982534546405, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 353, train_loss = 2.03356147184968, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 354, train_loss = 2.0284902192652225, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 355, train_loss = 2.0234378811437637, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 356, train_loss = 2.018527213484049, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 357, train_loss = 2.013518448919058, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 358, train_loss = 2.008648219285533, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 359, train_loss = 2.003822500584647, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 360, train_loss = 1.9989547294098884, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 361, train_loss = 1.994262918829918, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 362, train_loss = 1.9894655223470181, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 363, train_loss = 1.9847226291894913, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 364, train_loss = 1.9801620307844132, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 365, train_loss = 1.97550726425834, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 366, train_loss = 1.970956478267908, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 367, train_loss = 1.9663848963100463, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 368, train_loss = 1.9619409579318017, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 369, train_loss = 1.957369551062584, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 370, train_loss = 1.952991993399337, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 371, train_loss = 1.9485338802915066, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 372, train_loss = 1.9442116629797965, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 373, train_loss = 1.9399943065363914, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 374, train_loss = 1.9355579551775008, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 375, train_loss = 1.9313982662279159, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 376, train_loss = 1.9271941147744656, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 377, train_loss = 1.9229384895879775, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 378, train_loss = 1.918776459991932, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 379, train_loss = 1.9147354152519256, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 380, train_loss = 1.9106258861720562, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 381, train_loss = 1.906576406210661, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 382, train_loss = 1.9025288161356002, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 383, train_loss = 1.89850989356637, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 384, train_loss = 1.8945756778120995, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 385, train_loss = 1.8906494416296482, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 386, train_loss = 1.886738250614144, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 387, train_loss = 1.8829001486301422, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 388, train_loss = 1.879017279832624, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 389, train_loss = 1.8752626416971907, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 390, train_loss = 1.8714859063038602, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 391, train_loss = 1.8676871719071642, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 392, train_loss = 1.8640047957887873, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 393, train_loss = 1.860353995114565, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 394, train_loss = 1.856674887239933, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 395, train_loss = 1.8530197044601664, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 396, train_loss = 1.8495005071163177, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 397, train_loss = 1.8458462258568034, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 398, train_loss = 1.8423350179800764, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 399, train_loss = 1.83876473212149, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 400, train_loss = 1.8353121690452099, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 401, train_loss = 1.831832497031428, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 402, train_loss = 1.8284729234874249, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 403, train_loss = 1.8249587366590276, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 404, train_loss = 1.8215835405280814, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 405, train_loss = 1.8182607144117355, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 406, train_loss = 1.814908622414805, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 407, train_loss = 1.8115280643105507, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 408, train_loss = 1.8084041749825701, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 409, train_loss = 1.8050196705153212, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 410, train_loss = 1.8018284291028976, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 411, train_loss = 1.798585037351586, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 412, train_loss = 1.795381878851913, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 413, train_loss = 1.792297001928091, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 414, train_loss = 1.789108794182539, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 415, train_loss = 1.7860138987889513, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 416, train_loss = 1.7829108325531706, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 417, train_loss = 1.77982773759868, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 418, train_loss = 1.7767806723713875, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 419, train_loss = 1.7737205749144778, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 420, train_loss = 1.7707496645161882, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 421, train_loss = 1.7677784176776186, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 422, train_loss = 1.7648118771612644, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 423, train_loss = 1.7617786837508902, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 424, train_loss = 1.7589002400636673, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 425, train_loss = 1.756013190955855, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 426, train_loss = 1.7531189596047625, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 427, train_loss = 1.7502914853394032, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 428, train_loss = 1.7474409254500642, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 429, train_loss = 1.7446600683033466, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 430, train_loss = 1.7418635239591822, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 431, train_loss = 1.7390343075385317, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 432, train_loss = 1.7363601451506838, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 433, train_loss = 1.7335006421199068, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 434, train_loss = 1.730866494239308, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 435, train_loss = 1.7281333766877651, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 436, train_loss = 1.725448471843265, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 437, train_loss = 1.7227889908244833, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 438, train_loss = 1.7201706022024155, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 439, train_loss = 1.7175503795733675, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 440, train_loss = 1.7149035955080763, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 441, train_loss = 1.7123841382563114, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 442, train_loss = 1.7097023949027061, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 443, train_loss = 1.7072362812468782, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 444, train_loss = 1.704647367238067, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 445, train_loss = 1.702171914279461, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 446, train_loss = 1.6996305882930756, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 447, train_loss = 1.6971983859548345, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 448, train_loss = 1.6947091656038538, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 449, train_loss = 1.6922731287777424, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 450, train_loss = 1.6897987449774519, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 451, train_loss = 1.6874398899963126, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 452, train_loss = 1.6850013422081247, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 453, train_loss = 1.6826246082782745, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 454, train_loss = 1.680220084846951, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 455, train_loss = 1.6779198931762949, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 456, train_loss = 1.6755445575108752, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 457, train_loss = 1.6732842872152105, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 458, train_loss = 1.670907199382782, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 459, train_loss = 1.6686803176999092, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 460, train_loss = 1.6663719887146726, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 461, train_loss = 1.6641775257885456, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 462, train_loss = 1.6618407666683197, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 463, train_loss = 1.6596543391933665, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 464, train_loss = 1.6574243741342798, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 465, train_loss = 1.6552428914001212, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 466, train_loss = 1.6530804187059402, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 467, train_loss = 1.6508803702890873, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 468, train_loss = 1.6487059816718102, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 469, train_loss = 1.646609948365949, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 470, train_loss = 1.6444289287319407, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 471, train_loss = 1.6423296220600605, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 472, train_loss = 1.6402964642038569, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 473, train_loss = 1.6381283240625635, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 474, train_loss = 1.636075080721639, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 475, train_loss = 1.6340188706526533, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 476, train_loss = 1.6319966949522495, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 477, train_loss = 1.6298915868392214, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 478, train_loss = 1.6279283227631822, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 479, train_loss = 1.6259275687625632, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 480, train_loss = 1.6239245645701885, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 481, train_loss = 1.621946836472489, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 482, train_loss = 1.619980106712319, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 483, train_loss = 1.6180085130035877, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 484, train_loss = 1.6160684997448698, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 485, train_loss = 1.6141414865851402, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 486, train_loss = 1.6122305555036291, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 487, train_loss = 1.6103261845419183, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 488, train_loss = 1.6083664583275095, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 489, train_loss = 1.6065481764962897, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 490, train_loss = 1.604634191840887, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 491, train_loss = 1.602775003761053, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 492, train_loss = 1.600972498417832, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 493, train_loss = 1.5990985358366743, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 494, train_loss = 1.597263446659781, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 495, train_loss = 1.5954669924685732, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 496, train_loss = 1.5936554335057735, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 497, train_loss = 1.5918401591479778, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 498, train_loss = 1.5901228077709675, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 499, train_loss = 1.5882678081397898, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████████████                                                        | 7/30 [46:29<2:32:43, 398.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "8th- epoch: 0, train_loss = 271.66735875606537, train_acc = 0.47030740568234747\n",
      "test Acc 0.4888268156424581:\n",
      "8th- epoch: 1, train_loss = 208.1599452495575, train_acc = 0.492081974848626\n",
      "test Acc 0.4967411545623836:\n",
      "8th- epoch: 2, train_loss = 167.3416070342064, train_acc = 0.5052398695854681\n",
      "test Acc 0.5339851024208566:\n",
      "8th- epoch: 3, train_loss = 144.812107026577, train_acc = 0.6308802980903586\n",
      "test Acc 0.6899441340782123:\n",
      "8th- epoch: 4, train_loss = 127.06897246837616, train_acc = 0.7061015370284117\n",
      "test Acc 0.7318435754189944:\n",
      "8th- epoch: 5, train_loss = 111.6828778386116, train_acc = 0.7345132743362832\n",
      "test Acc 0.7518621973929237:\n",
      "8th- epoch: 6, train_loss = 98.39731174707413, train_acc = 0.7727061015370285\n",
      "test Acc 0.792364990689013:\n",
      "8th- epoch: 7, train_loss = 87.1136571764946, train_acc = 0.8136935258500233\n",
      "test Acc 0.8314711359404097:\n",
      "8th- epoch: 8, train_loss = 77.50570112466812, train_acc = 0.8468793665579879\n",
      "test Acc 0.8561452513966481:\n",
      "8th- epoch: 9, train_loss = 69.29864639043808, train_acc = 0.8652771308802981\n",
      "test Acc 0.8687150837988827:\n",
      "8th- epoch: 10, train_loss = 62.342293947935104, train_acc = 0.8733115975780158\n",
      "test Acc 0.8747672253258846:\n",
      "8th- epoch: 11, train_loss = 56.48009818792343, train_acc = 0.8816953889147647\n",
      "test Acc 0.8794227188081937:\n",
      "8th- epoch: 12, train_loss = 51.584760904312134, train_acc = 0.8896134140661388\n",
      "test Acc 0.8878026070763501:\n",
      "8th- epoch: 13, train_loss = 47.46971836686134, train_acc = 0.9030041918956684\n",
      "test Acc 0.904562383612663:\n",
      "8th- epoch: 14, train_loss = 44.00173771381378, train_acc = 0.9140661387983232\n",
      "test Acc 0.9175977653631285:\n",
      "8th- epoch: 15, train_loss = 41.0545778721571, train_acc = 0.9248952026082906\n",
      "test Acc 0.930633147113594:\n",
      "8th- epoch: 16, train_loss = 38.52063645422459, train_acc = 0.9321145784816023\n",
      "test Acc 0.9329608938547486:\n",
      "8th- epoch: 17, train_loss = 36.316306710243225, train_acc = 0.9395668374476013\n",
      "test Acc 0.9380819366852886:\n",
      "8th- epoch: 18, train_loss = 34.39106221497059, train_acc = 0.9436422915696321\n",
      "test Acc 0.9390130353817505:\n",
      "8th- epoch: 19, train_loss = 32.69793748855591, train_acc = 0.9455053563111319\n",
      "test Acc 0.9413407821229051:\n",
      "8th- epoch: 20, train_loss = 31.198857188224792, train_acc = 0.9472519795062878\n",
      "test Acc 0.9427374301675978:\n",
      "8th- epoch: 21, train_loss = 29.864373050630093, train_acc = 0.9488821611551002\n",
      "test Acc 0.9427374301675978:\n",
      "8th- epoch: 22, train_loss = 28.669317424297333, train_acc = 0.9503959012575687\n",
      "test Acc 0.9441340782122905:\n",
      "8th- epoch: 23, train_loss = 27.591853715479374, train_acc = 0.9513274336283186\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 24, train_loss = 26.6139697432518, train_acc = 0.951560316721006\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 25, train_loss = 25.721781857311726, train_acc = 0.9530740568234746\n",
      "test Acc 0.946927374301676:\n",
      "8th- epoch: 26, train_loss = 24.905357256531715, train_acc = 0.9544713553795995\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 27, train_loss = 24.154011145234108, train_acc = 0.9551700046576619\n",
      "test Acc 0.9487895716945997:\n",
      "8th- epoch: 28, train_loss = 23.459661100059748, train_acc = 0.955985095482068\n",
      "test Acc 0.9497206703910615:\n",
      "8th- epoch: 29, train_loss = 22.815517235547304, train_acc = 0.9570330693991617\n",
      "test Acc 0.9506517690875232:\n",
      "8th- epoch: 30, train_loss = 22.21401920169592, train_acc = 0.9583139264089428\n",
      "test Acc 0.952048417132216:\n",
      "8th- epoch: 31, train_loss = 21.649513471871614, train_acc = 0.9591290172333489\n",
      "test Acc 0.9529795158286778:\n",
      "8th- epoch: 32, train_loss = 21.118933271616697, train_acc = 0.9602934326967862\n",
      "test Acc 0.9534450651769087:\n",
      "8th- epoch: 33, train_loss = 20.619452353566885, train_acc = 0.9607591988821611\n",
      "test Acc 0.9534450651769087:\n",
      "8th- epoch: 34, train_loss = 20.14714164659381, train_acc = 0.9611085235211924\n",
      "test Acc 0.9539106145251397:\n",
      "8th- epoch: 35, train_loss = 19.701134242117405, train_acc = 0.961690731252911\n",
      "test Acc 0.9539106145251397:\n",
      "8th- epoch: 36, train_loss = 19.277819581329823, train_acc = 0.9625058220773172\n",
      "test Acc 0.9539106145251397:\n",
      "8th- epoch: 37, train_loss = 18.875985093414783, train_acc = 0.9629715882626921\n",
      "test Acc 0.9539106145251397:\n",
      "8th- epoch: 38, train_loss = 18.493527989834547, train_acc = 0.963903120633442\n",
      "test Acc 0.9543761638733705:\n",
      "8th- epoch: 39, train_loss = 18.128286506980658, train_acc = 0.9643688868188169\n",
      "test Acc 0.9548417132216015:\n",
      "8th- epoch: 40, train_loss = 17.77841180562973, train_acc = 0.9649510945505356\n",
      "test Acc 0.957169459962756:\n",
      "8th- epoch: 41, train_loss = 17.442676708102226, train_acc = 0.9653004191895669\n",
      "test Acc 0.957635009310987:\n",
      "8th- epoch: 42, train_loss = 17.120865892618895, train_acc = 0.9659990684676293\n",
      "test Acc 0.9590316573556797:\n",
      "8th- epoch: 43, train_loss = 16.811844613403082, train_acc = 0.9666977177456917\n",
      "test Acc 0.9599627560521415:\n",
      "8th- epoch: 44, train_loss = 16.51457104086876, train_acc = 0.9673963670237541\n",
      "test Acc 0.9599627560521415:\n",
      "8th- epoch: 45, train_loss = 16.22858439013362, train_acc = 0.9675128085700978\n",
      "test Acc 0.9604283054003724:\n",
      "8th- epoch: 46, train_loss = 15.952826719731092, train_acc = 0.9686772240335352\n",
      "test Acc 0.9613594040968343:\n",
      "8th- epoch: 47, train_loss = 15.686070710420609, train_acc = 0.9692594317652539\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 48, train_loss = 15.42921756580472, train_acc = 0.969608756404285\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 49, train_loss = 15.181632094085217, train_acc = 0.97007452258966\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 50, train_loss = 14.942098792642355, train_acc = 0.9710060549604099\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 51, train_loss = 14.710219897329807, train_acc = 0.9717047042384723\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 52, train_loss = 14.485510095953941, train_acc = 0.9717047042384723\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 53, train_loss = 14.267426285892725, train_acc = 0.9720540288775035\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 54, train_loss = 14.05584385432303, train_acc = 0.9725197950628784\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 55, train_loss = 13.850437322631478, train_acc = 0.9729855612482534\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 56, train_loss = 13.65115387365222, train_acc = 0.9729855612482534\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 57, train_loss = 13.457652907818556, train_acc = 0.9734513274336283\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 58, train_loss = 13.269606176763773, train_acc = 0.9736842105263158\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 59, train_loss = 13.086765240877867, train_acc = 0.9738006520726595\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 60, train_loss = 12.90870015323162, train_acc = 0.974033535165347\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 61, train_loss = 12.73551195859909, train_acc = 0.9744993013507219\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 62, train_loss = 12.56662030145526, train_acc = 0.9750815090824406\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 63, train_loss = 12.402275074273348, train_acc = 0.9751979506287843\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 64, train_loss = 12.242489702999592, train_acc = 0.9751979506287843\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 65, train_loss = 12.086835067719221, train_acc = 0.9751979506287843\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 66, train_loss = 11.934958416968584, train_acc = 0.9755472752678156\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 67, train_loss = 11.7871463149786, train_acc = 0.9758965999068467\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 68, train_loss = 11.6429962515831, train_acc = 0.9760130414531905\n",
      "test Acc 0.9669459962756052:\n",
      "8th- epoch: 69, train_loss = 11.502332583069801, train_acc = 0.9768281322775967\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 70, train_loss = 11.364976417273283, train_acc = 0.9769445738239404\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 71, train_loss = 11.230777330696583, train_acc = 0.9772938984629715\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 72, train_loss = 11.099644921720028, train_acc = 0.9772938984629715\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 73, train_loss = 10.971277110278606, train_acc = 0.9774103400093154\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 74, train_loss = 10.845596903935075, train_acc = 0.9776432231020028\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 75, train_loss = 10.722537998110056, train_acc = 0.9778761061946902\n",
      "test Acc 0.9688081936685289:\n",
      "8th- epoch: 76, train_loss = 10.602264888584614, train_acc = 0.977992547741034\n",
      "test Acc 0.9692737430167597:\n",
      "8th- epoch: 77, train_loss = 10.48434559814632, train_acc = 0.977992547741034\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 78, train_loss = 10.368777930736542, train_acc = 0.9783418723800652\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 79, train_loss = 10.25569561496377, train_acc = 0.9785747554727526\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 80, train_loss = 10.144792471081018, train_acc = 0.9789240801117839\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 81, train_loss = 10.035700095817447, train_acc = 0.9789240801117839\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 82, train_loss = 9.928617818281054, train_acc = 0.9791569632044713\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 83, train_loss = 9.823233848437667, train_acc = 0.9791569632044713\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 84, train_loss = 9.71994655393064, train_acc = 0.9793898462971589\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 85, train_loss = 9.618385098874569, train_acc = 0.9796227293898463\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 86, train_loss = 9.518639456480742, train_acc = 0.97973917093619\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 87, train_loss = 9.420541767030954, train_acc = 0.9796227293898463\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 88, train_loss = 9.32412963360548, train_acc = 0.9798556124825337\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 89, train_loss = 9.229272106662393, train_acc = 0.9799720540288775\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 90, train_loss = 9.135812284424901, train_acc = 0.980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 91, train_loss = 9.043680751696229, train_acc = 0.9803213786679087\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 92, train_loss = 8.953567117452621, train_acc = 0.9805542617605962\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 93, train_loss = 8.865108132362366, train_acc = 0.98067070330694\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 94, train_loss = 8.777890032157302, train_acc = 0.9809035863996274\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 95, train_loss = 8.691656256094575, train_acc = 0.9812529110386586\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 96, train_loss = 8.606799257919192, train_acc = 0.9813693525850024\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 97, train_loss = 8.522830797359347, train_acc = 0.9814857941313461\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 98, train_loss = 8.440509654581547, train_acc = 0.9816022356776898\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 99, train_loss = 8.359715010970831, train_acc = 0.981951560316721\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 100, train_loss = 8.279798096045852, train_acc = 0.9820680018630648\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 101, train_loss = 8.201288402080536, train_acc = 0.9823008849557522\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 102, train_loss = 8.123854514211416, train_acc = 0.9823008849557522\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 103, train_loss = 8.047673100605607, train_acc = 0.9826502095947834\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 104, train_loss = 7.972352499142289, train_acc = 0.9829995342338146\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 105, train_loss = 7.898325562477112, train_acc = 0.9831159757801584\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 106, train_loss = 7.8251217901706696, train_acc = 0.9831159757801584\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 107, train_loss = 7.753160942345858, train_acc = 0.9832324173265021\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 108, train_loss = 7.682116178795695, train_acc = 0.983698183511877\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 109, train_loss = 7.6118166744709015, train_acc = 0.9839310666045645\n",
      "test Acc 0.9725325884543762:\n",
      "8th- epoch: 110, train_loss = 7.5426025968045, train_acc = 0.984163949697252\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 111, train_loss = 7.474395336583257, train_acc = 0.9842803912435957\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 112, train_loss = 7.407235283404589, train_acc = 0.9843968327899395\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 113, train_loss = 7.340899495407939, train_acc = 0.9843968327899395\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 114, train_loss = 7.275419682264328, train_acc = 0.9842803912435957\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 115, train_loss = 7.2109341360628605, train_acc = 0.9848625989753144\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 116, train_loss = 7.147291637957096, train_acc = 0.9850954820680019\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 117, train_loss = 7.084795704111457, train_acc = 0.9852119236143456\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 118, train_loss = 7.022771891206503, train_acc = 0.9853283651606893\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 119, train_loss = 6.961528575047851, train_acc = 0.9853283651606893\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 120, train_loss = 6.900743367150426, train_acc = 0.985444806707033\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 121, train_loss = 6.840233078226447, train_acc = 0.9857941313460643\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 122, train_loss = 6.780688084661961, train_acc = 0.9860270144387517\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 123, train_loss = 6.722260067239404, train_acc = 0.9860270144387517\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 124, train_loss = 6.664482768625021, train_acc = 0.9861434559850955\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 125, train_loss = 6.607682701200247, train_acc = 0.9861434559850955\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 126, train_loss = 6.551412984728813, train_acc = 0.9861434559850955\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 127, train_loss = 6.4959671553224325, train_acc = 0.9862598975314392\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 128, train_loss = 6.44126184284687, train_acc = 0.986376339077783\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 129, train_loss = 6.3874093648046255, train_acc = 0.986376339077783\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 130, train_loss = 6.33412741497159, train_acc = 0.9864927806241267\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 131, train_loss = 6.281530065461993, train_acc = 0.9864927806241267\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 132, train_loss = 6.229633262380958, train_acc = 0.9869585468095017\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 133, train_loss = 6.178728371858597, train_acc = 0.9869585468095017\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 134, train_loss = 6.128323428332806, train_acc = 0.9869585468095017\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 135, train_loss = 6.078621691092849, train_acc = 0.9873078714485328\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 136, train_loss = 6.029584165662527, train_acc = 0.9873078714485328\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 137, train_loss = 5.981152074411511, train_acc = 0.9873078714485328\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 138, train_loss = 5.9332027062773705, train_acc = 0.9875407545412203\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 139, train_loss = 5.886120013892651, train_acc = 0.9876571960875641\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 140, train_loss = 5.839571323245764, train_acc = 0.9880065207265952\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 141, train_loss = 5.793658351525664, train_acc = 0.9880065207265952\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 142, train_loss = 5.748131135478616, train_acc = 0.9881229622729389\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 143, train_loss = 5.703499997034669, train_acc = 0.9882394038192828\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 144, train_loss = 5.659191582351923, train_acc = 0.9890544946436889\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 145, train_loss = 5.615650061517954, train_acc = 0.9891709361900326\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 146, train_loss = 5.572583913803101, train_acc = 0.9891709361900326\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 147, train_loss = 5.529942674562335, train_acc = 0.9891709361900326\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 148, train_loss = 5.487946607172489, train_acc = 0.9891709361900326\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 149, train_loss = 5.446426721289754, train_acc = 0.9891709361900326\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 150, train_loss = 5.405341204255819, train_acc = 0.9891709361900326\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 151, train_loss = 5.36484822910279, train_acc = 0.9892873777363763\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 152, train_loss = 5.324767376296222, train_acc = 0.98940381928272\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 153, train_loss = 5.285516859963536, train_acc = 0.98940381928272\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 154, train_loss = 5.246409006416798, train_acc = 0.98940381928272\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 155, train_loss = 5.208005824126303, train_acc = 0.98940381928272\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 156, train_loss = 5.169991608709097, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 157, train_loss = 5.132459898479283, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 158, train_loss = 5.095390602946281, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 159, train_loss = 5.058850233443081, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 160, train_loss = 5.02253279555589, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 161, train_loss = 4.986969526857138, train_acc = 0.9895202608290639\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 162, train_loss = 4.951536119915545, train_acc = 0.9895202608290639\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 163, train_loss = 4.916650027036667, train_acc = 0.9897531439217513\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 164, train_loss = 4.882176253944635, train_acc = 0.99033535165347\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 165, train_loss = 4.848044634796679, train_acc = 0.99033535165347\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 166, train_loss = 4.814381167292595, train_acc = 0.9905682347461574\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 167, train_loss = 4.781097658909857, train_acc = 0.990801117838845\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 168, train_loss = 4.748098122887313, train_acc = 0.990801117838845\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 169, train_loss = 4.715588265098631, train_acc = 0.9909175593851887\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 170, train_loss = 4.683506314642727, train_acc = 0.9909175593851887\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 171, train_loss = 4.651802220381796, train_acc = 0.9910340009315324\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 172, train_loss = 4.620298974215984, train_acc = 0.9911504424778761\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 173, train_loss = 4.589205359108746, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 174, train_loss = 4.558509540744126, train_acc = 0.9913833255705635\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 175, train_loss = 4.527953485958278, train_acc = 0.9914997671169073\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 176, train_loss = 4.497791088186204, train_acc = 0.9914997671169073\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 177, train_loss = 4.4677538787946105, train_acc = 0.9916162086632511\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 178, train_loss = 4.438406985253096, train_acc = 0.9916162086632511\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 179, train_loss = 4.409252014942467, train_acc = 0.9916162086632511\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 180, train_loss = 4.380381714552641, train_acc = 0.9916162086632511\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 181, train_loss = 4.351846870966256, train_acc = 0.9916162086632511\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 182, train_loss = 4.323707177303731, train_acc = 0.9917326502095948\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 183, train_loss = 4.29606953356415, train_acc = 0.9918490917559385\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 184, train_loss = 4.268613354302943, train_acc = 0.9918490917559385\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 185, train_loss = 4.241443042643368, train_acc = 0.9918490917559385\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 186, train_loss = 4.214505887590349, train_acc = 0.9919655333022822\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 187, train_loss = 4.188114543445408, train_acc = 0.9919655333022822\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 188, train_loss = 4.162004999816418, train_acc = 0.9919655333022822\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 189, train_loss = 4.136032042093575, train_acc = 0.9919655333022822\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 190, train_loss = 4.1105735851451755, train_acc = 0.9919655333022822\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 191, train_loss = 4.085347220301628, train_acc = 0.9919655333022822\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 192, train_loss = 4.060267820954323, train_acc = 0.9919655333022822\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 193, train_loss = 4.035583637654781, train_acc = 0.9919655333022822\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 194, train_loss = 4.011223106645048, train_acc = 0.9919655333022822\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 195, train_loss = 3.9870952256023884, train_acc = 0.9919655333022822\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 196, train_loss = 3.9632034422829747, train_acc = 0.9919655333022822\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 197, train_loss = 3.9396169977262616, train_acc = 0.9919655333022822\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 198, train_loss = 3.916402946226299, train_acc = 0.9919655333022822\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 199, train_loss = 3.8933140700682998, train_acc = 0.992081974848626\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 200, train_loss = 3.870351809076965, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 201, train_loss = 3.847823212854564, train_acc = 0.9923148579413135\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 202, train_loss = 3.8254717839881778, train_acc = 0.9923148579413135\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 203, train_loss = 3.8034745901823044, train_acc = 0.9923148579413135\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 204, train_loss = 3.7816573716700077, train_acc = 0.9923148579413135\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 205, train_loss = 3.760022439993918, train_acc = 0.9924312994876572\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 206, train_loss = 3.7386925145983696, train_acc = 0.9925477410340009\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 207, train_loss = 3.7176352627575397, train_acc = 0.9925477410340009\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 208, train_loss = 3.6965843169018626, train_acc = 0.9925477410340009\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 209, train_loss = 3.675850059837103, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 210, train_loss = 3.65541463624686, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 211, train_loss = 3.6351703950203955, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 212, train_loss = 3.6150882481597364, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 213, train_loss = 3.5951169156469405, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 214, train_loss = 3.57545717805624, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 215, train_loss = 3.5559524917043746, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 216, train_loss = 3.536855537444353, train_acc = 0.9926641825803446\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 217, train_loss = 3.517634589225054, train_acc = 0.9927806241266884\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 218, train_loss = 3.4988765618763864, train_acc = 0.9927806241266884\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 219, train_loss = 3.480054667685181, train_acc = 0.9927806241266884\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 220, train_loss = 3.4617605381645262, train_acc = 0.9927806241266884\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 221, train_loss = 3.443448261823505, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 222, train_loss = 3.425361702684313, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 223, train_loss = 3.407333849463612, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 224, train_loss = 3.3896128311753273, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 225, train_loss = 3.371970161795616, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 226, train_loss = 3.3546941154636443, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 227, train_loss = 3.3374517909251153, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 228, train_loss = 3.320431863423437, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 229, train_loss = 3.3034966117702425, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 230, train_loss = 3.286788852419704, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 231, train_loss = 3.270259438548237, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 232, train_loss = 3.253961072769016, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 233, train_loss = 3.2376772686839104, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 234, train_loss = 3.2216345057822764, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 235, train_loss = 3.205684440676123, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 236, train_loss = 3.1899320227093995, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 237, train_loss = 3.1742738685570657, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 238, train_loss = 3.15872785449028, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 239, train_loss = 3.1433463767170906, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 240, train_loss = 3.128238717559725, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 241, train_loss = 3.1132080764509737, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 242, train_loss = 3.098150521982461, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 243, train_loss = 3.083505167160183, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 244, train_loss = 3.0686428234912455, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 245, train_loss = 3.0540612675249577, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 246, train_loss = 3.0394923998974264, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 247, train_loss = 3.025157378986478, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 248, train_loss = 3.0110785835422575, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 249, train_loss = 2.9969546664506197, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 250, train_loss = 2.982972225639969, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 251, train_loss = 2.969117768574506, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 252, train_loss = 2.955425771418959, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 253, train_loss = 2.941825142595917, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 254, train_loss = 2.9284245781600475, train_acc = 0.993828598043782\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 255, train_loss = 2.9150575124658644, train_acc = 0.993828598043782\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 256, train_loss = 2.9021643004380167, train_acc = 0.993828598043782\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 257, train_loss = 2.8890662156045437, train_acc = 0.9939450395901258\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 258, train_loss = 2.8763692169450223, train_acc = 0.9939450395901258\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 259, train_loss = 2.8635754720307887, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 260, train_loss = 2.851006268057972, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 261, train_loss = 2.8386447676457465, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 262, train_loss = 2.826171552296728, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 263, train_loss = 2.814037088304758, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 264, train_loss = 2.8019085959531367, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 265, train_loss = 2.789842040743679, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 266, train_loss = 2.7780970274470747, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 267, train_loss = 2.7661074101924896, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 268, train_loss = 2.75444612884894, train_acc = 0.9944108057755007\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 269, train_loss = 2.74285102263093, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 270, train_loss = 2.7314142785035074, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 271, train_loss = 2.7200929820537567, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 272, train_loss = 2.7087540715001523, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 273, train_loss = 2.6976451673544943, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 274, train_loss = 2.686459614429623, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 275, train_loss = 2.6756825135089457, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 276, train_loss = 2.664598221424967, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 277, train_loss = 2.654058861080557, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 278, train_loss = 2.6432345150969923, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 279, train_loss = 2.6327827773056924, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 280, train_loss = 2.62225012620911, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 281, train_loss = 2.6119077154435217, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 282, train_loss = 2.6017065471969545, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 283, train_loss = 2.5915583930909634, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 284, train_loss = 2.5813240609131753, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 285, train_loss = 2.571379786822945, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 286, train_loss = 2.5614695153199136, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 287, train_loss = 2.5516330651007593, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 288, train_loss = 2.54198906943202, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 289, train_loss = 2.532344486564398, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 290, train_loss = 2.522640820592642, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 291, train_loss = 2.513385647442192, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 292, train_loss = 2.5039927079342306, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 293, train_loss = 2.4946672320365906, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 294, train_loss = 2.4854364942293614, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 295, train_loss = 2.476616930216551, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 296, train_loss = 2.467472283868119, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 297, train_loss = 2.4584517229814082, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 298, train_loss = 2.4497293818276376, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 299, train_loss = 2.4410494938492775, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 300, train_loss = 2.432165451347828, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 301, train_loss = 2.4237209532875568, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 302, train_loss = 2.4151322667021304, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 303, train_loss = 2.4067997459787875, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 304, train_loss = 2.398628994822502, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 305, train_loss = 2.390038341283798, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 306, train_loss = 2.3820380456745625, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 307, train_loss = 2.373883708147332, train_acc = 0.9947601304145319\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 308, train_loss = 2.3658602237701416, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 309, train_loss = 2.3578442186117172, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 310, train_loss = 2.3500570517499, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 311, train_loss = 2.342095397412777, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 312, train_loss = 2.334367923438549, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 313, train_loss = 2.3266043551266193, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 314, train_loss = 2.319014273583889, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 315, train_loss = 2.3115007430315018, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 316, train_loss = 2.3040365141350776, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 317, train_loss = 2.2968283854424953, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 318, train_loss = 2.2893935416359454, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 319, train_loss = 2.282005712389946, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 320, train_loss = 2.2748753938358277, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 321, train_loss = 2.267651055008173, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 322, train_loss = 2.2605745207984, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 323, train_loss = 2.2535767282824963, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 324, train_loss = 2.246786531060934, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 325, train_loss = 2.2398776572663337, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 326, train_loss = 2.2330632645171136, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 327, train_loss = 2.226404447108507, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 328, train_loss = 2.219544369727373, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 329, train_loss = 2.2132175292354077, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 330, train_loss = 2.2065177385229617, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 331, train_loss = 2.200031142681837, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 332, train_loss = 2.193433762760833, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 333, train_loss = 2.1872667148709297, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 334, train_loss = 2.180863607674837, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 335, train_loss = 2.1746107216458768, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 336, train_loss = 2.168418363900855, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 337, train_loss = 2.16229618457146, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 338, train_loss = 2.1561626333277673, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 339, train_loss = 2.1500685040373355, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 340, train_loss = 2.144190451828763, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 341, train_loss = 2.138235069811344, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 342, train_loss = 2.1322150453925133, train_acc = 0.9948765719608756\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 343, train_loss = 2.126647957833484, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 344, train_loss = 2.1206391130108386, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 345, train_loss = 2.1149369191844016, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 346, train_loss = 2.10931812110357, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 347, train_loss = 2.1037202428560704, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 348, train_loss = 2.0981727924663574, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 349, train_loss = 2.092496581375599, train_acc = 0.9949930135072194\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 350, train_loss = 2.08726188656874, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 351, train_loss = 2.081696971086785, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 352, train_loss = 2.0762775491457433, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 353, train_loss = 2.070986847160384, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 354, train_loss = 2.065743215382099, train_acc = 0.9949930135072194\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 355, train_loss = 2.0603549543302506, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 356, train_loss = 2.055367103544995, train_acc = 0.9951094550535631\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 357, train_loss = 2.0501157592516392, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 358, train_loss = 2.0449945852160454, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 359, train_loss = 2.0398943487089127, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 360, train_loss = 2.0348875175695866, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 361, train_loss = 2.029755864292383, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 362, train_loss = 2.0249359372537583, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 363, train_loss = 2.0201496582012624, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 364, train_loss = 2.0151020400226116, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 365, train_loss = 2.010350278345868, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 366, train_loss = 2.005673723993823, train_acc = 0.9952258965999069\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 367, train_loss = 2.0007682170253247, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 368, train_loss = 1.9962287929374725, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 369, train_loss = 1.9914080612361431, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 370, train_loss = 1.986908059567213, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 371, train_loss = 1.9823212448973209, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 372, train_loss = 1.9776930946391076, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 373, train_loss = 1.9734091509599239, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 374, train_loss = 1.968477462651208, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 375, train_loss = 1.9644219491165131, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 376, train_loss = 1.9598718397319317, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 377, train_loss = 1.9555806692223996, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 378, train_loss = 1.9512336899060756, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 379, train_loss = 1.9467654649633914, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 380, train_loss = 1.942684255540371, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 381, train_loss = 1.9383298445027322, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 382, train_loss = 1.9341235917527229, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 383, train_loss = 1.9300499483942986, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 384, train_loss = 1.925855441717431, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 385, train_loss = 1.921698484569788, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 386, train_loss = 1.9177170135080814, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 387, train_loss = 1.9136199777713045, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 388, train_loss = 1.9095996730029583, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 389, train_loss = 1.9055659821024165, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 390, train_loss = 1.9016915945103392, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 391, train_loss = 1.897645477205515, train_acc = 0.9953423381462506\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 392, train_loss = 1.8938422849169, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 393, train_loss = 1.8897907609352842, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 394, train_loss = 1.8860539806773886, train_acc = 0.9954587796925943\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 395, train_loss = 1.8823425570735708, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 396, train_loss = 1.8784617433557287, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 397, train_loss = 1.8747243086108938, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 398, train_loss = 1.8709348427364603, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 399, train_loss = 1.867309458553791, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 400, train_loss = 1.8636533096432686, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 401, train_loss = 1.8598007187247276, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 402, train_loss = 1.8563387977192178, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 403, train_loss = 1.852688922197558, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 404, train_loss = 1.8491315046558157, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 405, train_loss = 1.845643421052955, train_acc = 0.995575221238938\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 406, train_loss = 1.8422516336431727, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 407, train_loss = 1.8385313848266378, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 408, train_loss = 1.835228239535354, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 409, train_loss = 1.8316900929203257, train_acc = 0.9956916627852818\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 410, train_loss = 1.8285235837101936, train_acc = 0.9958081043316255\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 411, train_loss = 1.8249800875782967, train_acc = 0.9958081043316255\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 412, train_loss = 1.8217466287314892, train_acc = 0.9958081043316255\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 413, train_loss = 1.8180984271457419, train_acc = 0.9958081043316255\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 414, train_loss = 1.8150816535344347, train_acc = 0.9958081043316255\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 415, train_loss = 1.8116278983652592, train_acc = 0.9958081043316255\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 416, train_loss = 1.8084519108524546, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 417, train_loss = 1.8049775114050135, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 418, train_loss = 1.8021434036782011, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 419, train_loss = 1.7986909883329645, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 420, train_loss = 1.795775314210914, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 421, train_loss = 1.7925837449729443, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 422, train_loss = 1.789608852355741, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 423, train_loss = 1.7861516935518011, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 424, train_loss = 1.7833008667221293, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 425, train_loss = 1.779974590986967, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 426, train_loss = 1.7774116086075082, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 427, train_loss = 1.7739830911159515, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 428, train_loss = 1.7712813466787338, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 429, train_loss = 1.7680863924324512, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 430, train_loss = 1.7655005095293745, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 431, train_loss = 1.7623064815998077, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 432, train_loss = 1.759568803012371, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 433, train_loss = 1.7564054342219606, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 434, train_loss = 1.753732342272997, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 435, train_loss = 1.7508512983331457, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 436, train_loss = 1.74808646121528, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 437, train_loss = 1.7449876802274957, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 438, train_loss = 1.7425124334404245, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 439, train_loss = 1.7395411556353793, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 440, train_loss = 1.736911740154028, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 441, train_loss = 1.7340344960102811, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 442, train_loss = 1.731419569463469, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 443, train_loss = 1.7286311946809292, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 444, train_loss = 1.7260304279625416, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 445, train_loss = 1.7233571434626356, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 446, train_loss = 1.7208979278802872, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 447, train_loss = 1.718044592649676, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 448, train_loss = 1.7154579249909148, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 449, train_loss = 1.712865283130668, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 450, train_loss = 1.7104385843267664, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 451, train_loss = 1.7077170349657536, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 452, train_loss = 1.7053002727916464, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 453, train_loss = 1.702823450206779, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 454, train_loss = 1.7003064639866352, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 455, train_loss = 1.697748632519506, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 456, train_loss = 1.6954052621731535, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 457, train_loss = 1.692794106900692, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 458, train_loss = 1.6903925376245752, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 459, train_loss = 1.6882408944657072, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 460, train_loss = 1.6853495761752129, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 461, train_loss = 1.6834425131091848, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 462, train_loss = 1.6807825131108984, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 463, train_loss = 1.6782368259737268, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 464, train_loss = 1.676333180279471, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 465, train_loss = 1.6736029399326071, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 466, train_loss = 1.6715164333581924, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 467, train_loss = 1.669178906828165, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 468, train_loss = 1.6668652122607455, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 469, train_loss = 1.6646067388355732, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 470, train_loss = 1.66230708360672, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 471, train_loss = 1.6601741848280653, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 472, train_loss = 1.6576728833606467, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 473, train_loss = 1.6557394601404667, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 474, train_loss = 1.6535610059509054, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 475, train_loss = 1.6513544991612434, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 476, train_loss = 1.6490961028030142, train_acc = 0.9958081043316255\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 477, train_loss = 1.6471905434736982, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 478, train_loss = 1.6447176411747932, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 479, train_loss = 1.6429295875132084, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 480, train_loss = 1.6404225131263956, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 481, train_loss = 1.6385976312449202, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 482, train_loss = 1.6363425528397784, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 483, train_loss = 1.6346212526550516, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 484, train_loss = 1.6321807379135862, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 485, train_loss = 1.6303201703121886, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 486, train_loss = 1.628165852278471, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 487, train_loss = 1.6262569514801726, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 488, train_loss = 1.624154455959797, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 489, train_loss = 1.6222454173257574, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 490, train_loss = 1.6204044161131606, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 491, train_loss = 1.6181794429430738, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 492, train_loss = 1.6161115715513006, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 493, train_loss = 1.614474467933178, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 494, train_loss = 1.6121658571064472, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 495, train_loss = 1.6106355810770765, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 496, train_loss = 1.6083909533917904, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 497, train_loss = 1.606693806766998, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 498, train_loss = 1.604787778109312, train_acc = 0.9959245458779693\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 499, train_loss = 1.6026971265673637, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|███████████████████▍                                                     | 8/30 [53:08<2:26:06, 398.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "9th- epoch: 0, train_loss = 272.4683874845505, train_acc = 0.4340940847694457\n",
      "test Acc 0.48696461824953446:\n",
      "9th- epoch: 1, train_loss = 207.87402307987213, train_acc = 0.49161620866325106\n",
      "test Acc 0.4972067039106145:\n",
      "9th- epoch: 2, train_loss = 168.27843153476715, train_acc = 0.5137401024685608\n",
      "test Acc 0.5418994413407822:\n",
      "9th- epoch: 3, train_loss = 146.05036747455597, train_acc = 0.6252911038658593\n",
      "test Acc 0.702048417132216:\n",
      "9th- epoch: 4, train_loss = 127.77926301956177, train_acc = 0.7141360037261295\n",
      "test Acc 0.7383612662942272:\n",
      "9th- epoch: 5, train_loss = 111.53311491012573, train_acc = 0.7519795062878435\n",
      "test Acc 0.7700186219739292:\n",
      "9th- epoch: 6, train_loss = 97.72281515598297, train_acc = 0.7887750349324639\n",
      "test Acc 0.7984171322160148:\n",
      "9th- epoch: 7, train_loss = 86.2993874847889, train_acc = 0.8192827200745226\n",
      "test Acc 0.8268156424581006:\n",
      "9th- epoch: 8, train_loss = 76.77130621671677, train_acc = 0.8423381462505822\n",
      "test Acc 0.8486964618249534:\n",
      "9th- epoch: 9, train_loss = 68.7605839073658, train_acc = 0.8643455985095482\n",
      "test Acc 0.87243947858473:\n",
      "9th- epoch: 10, train_loss = 62.02166637778282, train_acc = 0.8751746623195156\n",
      "test Acc 0.8780260707635009:\n",
      "9th- epoch: 11, train_loss = 56.37017369270325, train_acc = 0.8832091290172334\n",
      "test Acc 0.88268156424581:\n",
      "9th- epoch: 12, train_loss = 51.64653964340687, train_acc = 0.8918258034466697\n",
      "test Acc 0.8947858472998138:\n",
      "9th- epoch: 13, train_loss = 47.68805778026581, train_acc = 0.9019562179785747\n",
      "test Acc 0.9050279329608939:\n",
      "9th- epoch: 14, train_loss = 44.35267925262451, train_acc = 0.9147647880763856\n",
      "test Acc 0.9208566108007449:\n",
      "9th- epoch: 15, train_loss = 41.51099716126919, train_acc = 0.926525384257103\n",
      "test Acc 0.9301675977653632:\n",
      "9th- epoch: 16, train_loss = 39.05986751616001, train_acc = 0.9324639031206334\n",
      "test Acc 0.9329608938547486:\n",
      "9th- epoch: 17, train_loss = 36.919226348400116, train_acc = 0.9360735910572893\n",
      "test Acc 0.9376163873370578:\n",
      "9th- epoch: 18, train_loss = 35.03218360245228, train_acc = 0.9384024219841639\n",
      "test Acc 0.9390130353817505:\n",
      "9th- epoch: 19, train_loss = 33.357537396252155, train_acc = 0.9409641360037261\n",
      "test Acc 0.9404096834264432:\n",
      "9th- epoch: 20, train_loss = 31.860553808510303, train_acc = 0.9428272007452259\n",
      "test Acc 0.9422718808193669:\n",
      "9th- epoch: 21, train_loss = 30.51204715669155, train_acc = 0.9451560316721006\n",
      "test Acc 0.9455307262569832:\n",
      "9th- epoch: 22, train_loss = 29.293603464961052, train_acc = 0.9510945505356311\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 23, train_loss = 28.18625608831644, train_acc = 0.9526082906380997\n",
      "test Acc 0.9497206703910615:\n",
      "9th- epoch: 24, train_loss = 27.17465579509735, train_acc = 0.9540055891942245\n",
      "test Acc 0.9515828677839852:\n",
      "9th- epoch: 25, train_loss = 26.25042399019003, train_acc = 0.955519329296693\n",
      "test Acc 0.9529795158286778:\n",
      "9th- epoch: 26, train_loss = 25.401632227003574, train_acc = 0.9561015370284117\n",
      "test Acc 0.9539106145251397:\n",
      "9th- epoch: 27, train_loss = 24.617784962058067, train_acc = 0.9568001863064741\n",
      "test Acc 0.9543761638733705:\n",
      "9th- epoch: 28, train_loss = 23.891520250588655, train_acc = 0.9578481602235678\n",
      "test Acc 0.9548417132216015:\n",
      "9th- epoch: 29, train_loss = 23.21600281447172, train_acc = 0.9585468095016302\n",
      "test Acc 0.9548417132216015:\n",
      "9th- epoch: 30, train_loss = 22.585448782891035, train_acc = 0.9592454587796926\n",
      "test Acc 0.9543761638733705:\n",
      "9th- epoch: 31, train_loss = 21.994171794503927, train_acc = 0.9598276665114113\n",
      "test Acc 0.9543761638733705:\n",
      "9th- epoch: 32, train_loss = 21.439648061990738, train_acc = 0.9600605496040987\n",
      "test Acc 0.9543761638733705:\n",
      "9th- epoch: 33, train_loss = 20.916757371276617, train_acc = 0.9606427573358174\n",
      "test Acc 0.9553072625698324:\n",
      "9th- epoch: 34, train_loss = 20.42264636233449, train_acc = 0.9611085235211924\n",
      "test Acc 0.9557728119180633:\n",
      "9th- epoch: 35, train_loss = 19.95405748486519, train_acc = 0.9623893805309734\n",
      "test Acc 0.957169459962756:\n",
      "9th- epoch: 36, train_loss = 19.509386654943228, train_acc = 0.9628551467163484\n",
      "test Acc 0.9581005586592178:\n",
      "9th- epoch: 37, train_loss = 19.087093327194452, train_acc = 0.9633209129017233\n",
      "test Acc 0.9585661080074488:\n",
      "9th- epoch: 38, train_loss = 18.685361452400684, train_acc = 0.9636702375407545\n",
      "test Acc 0.9585661080074488:\n",
      "9th- epoch: 39, train_loss = 18.30232483521104, train_acc = 0.9644853283651607\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 40, train_loss = 17.93645578622818, train_acc = 0.9651839776432231\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 41, train_loss = 17.58622881397605, train_acc = 0.966115510013973\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 42, train_loss = 17.251206815242767, train_acc = 0.9666977177456917\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 43, train_loss = 16.929822828620672, train_acc = 0.9676292501164415\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 44, train_loss = 16.62059924006462, train_acc = 0.9683278993945039\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 45, train_loss = 16.323217764496803, train_acc = 0.9693758733115976\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 46, train_loss = 16.036642264574766, train_acc = 0.97007452258966\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 47, train_loss = 15.761260151863098, train_acc = 0.9707731718677224\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 48, train_loss = 15.49660162627697, train_acc = 0.9713553795994411\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 49, train_loss = 15.241757553070784, train_acc = 0.9715882626921285\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 50, train_loss = 14.996296685189009, train_acc = 0.972286911970191\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 51, train_loss = 14.75917512923479, train_acc = 0.972286911970191\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 52, train_loss = 14.530062031000853, train_acc = 0.9724033535165347\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 53, train_loss = 14.308579094707966, train_acc = 0.9727526781555659\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 54, train_loss = 14.094114862382412, train_acc = 0.9733348858872846\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 55, train_loss = 13.88598034158349, train_acc = 0.9734513274336283\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 56, train_loss = 13.684107253327966, train_acc = 0.9736842105263158\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 57, train_loss = 13.488365657627583, train_acc = 0.9743828598043782\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 58, train_loss = 13.298292938619852, train_acc = 0.9747321844434094\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 59, train_loss = 13.113667471334338, train_acc = 0.9748486259897532\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 60, train_loss = 12.934286925941706, train_acc = 0.9748486259897532\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 61, train_loss = 12.75994342751801, train_acc = 0.9748486259897532\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 62, train_loss = 12.590245125815272, train_acc = 0.9751979506287843\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 63, train_loss = 12.425415236502886, train_acc = 0.9754308337214718\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 64, train_loss = 12.265067832544446, train_acc = 0.9755472752678156\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 65, train_loss = 12.108872815966606, train_acc = 0.9758965999068467\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 66, train_loss = 11.956429447978735, train_acc = 0.9760130414531905\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 67, train_loss = 11.807557918131351, train_acc = 0.976245924545878\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 68, train_loss = 11.662307120859623, train_acc = 0.9765952491849091\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 69, train_loss = 11.520737797021866, train_acc = 0.9770610153702841\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 70, train_loss = 11.382353886961937, train_acc = 0.9774103400093154\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 71, train_loss = 11.24732081592083, train_acc = 0.9775267815556591\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 72, train_loss = 11.115484274923801, train_acc = 0.9776432231020028\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 73, train_loss = 10.986576296389103, train_acc = 0.9777596646483465\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 74, train_loss = 10.86048848927021, train_acc = 0.9778761061946902\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 75, train_loss = 10.737239178270102, train_acc = 0.9781089892873778\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 76, train_loss = 10.616432126611471, train_acc = 0.9781089892873778\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 77, train_loss = 10.4977175462991, train_acc = 0.9784583139264089\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 78, train_loss = 10.381345992907882, train_acc = 0.9788076385654402\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 79, train_loss = 10.267500007525086, train_acc = 0.9789240801117839\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 80, train_loss = 10.155659230425954, train_acc = 0.9790405216581276\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 81, train_loss = 10.046211114153266, train_acc = 0.9791569632044713\n",
      "test Acc 0.9702048417132216:\n",
      "9th- epoch: 82, train_loss = 9.938612431287766, train_acc = 0.9791569632044713\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 83, train_loss = 9.832906384021044, train_acc = 0.9792734047508151\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 84, train_loss = 9.729230949655175, train_acc = 0.9793898462971589\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 85, train_loss = 9.627391569316387, train_acc = 0.9793898462971589\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 86, train_loss = 9.527468437328935, train_acc = 0.9795062878435026\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 87, train_loss = 9.429380232468247, train_acc = 0.9796227293898463\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 88, train_loss = 9.33285360224545, train_acc = 0.9796227293898463\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 89, train_loss = 9.237958347424865, train_acc = 0.97973917093619\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 90, train_loss = 9.144550397992134, train_acc = 0.9798556124825337\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 91, train_loss = 9.052701430395246, train_acc = 0.9799720540288775\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 92, train_loss = 8.962569648399949, train_acc = 0.9799720540288775\n",
      "test Acc 0.9711359404096834:\n",
      "9th- epoch: 93, train_loss = 8.873986704275012, train_acc = 0.9800884955752213\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 94, train_loss = 8.786874536424875, train_acc = 0.9803213786679087\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 95, train_loss = 8.70101160928607, train_acc = 0.9804378202142524\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 96, train_loss = 8.616689141839743, train_acc = 0.9804378202142524\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 97, train_loss = 8.533475272357464, train_acc = 0.98067070330694\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 98, train_loss = 8.451557351276278, train_acc = 0.9810200279459711\n",
      "test Acc 0.9720670391061452:\n",
      "9th- epoch: 99, train_loss = 8.37081179395318, train_acc = 0.9812529110386586\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 100, train_loss = 8.291265500709414, train_acc = 0.9814857941313461\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 101, train_loss = 8.212817907333374, train_acc = 0.9817186772240335\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 102, train_loss = 8.135575549677014, train_acc = 0.9818351187703773\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 103, train_loss = 8.059122703969479, train_acc = 0.981951560316721\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 104, train_loss = 7.983956053853035, train_acc = 0.9821844434094085\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 105, train_loss = 7.909614913165569, train_acc = 0.9821844434094085\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 106, train_loss = 7.836365120485425, train_acc = 0.9823008849557522\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 107, train_loss = 7.763995254412293, train_acc = 0.9824173265020959\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 108, train_loss = 7.692699957638979, train_acc = 0.9824173265020959\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 109, train_loss = 7.622793721035123, train_acc = 0.9825337680484397\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 110, train_loss = 7.553798511624336, train_acc = 0.9826502095947834\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 111, train_loss = 7.485735485330224, train_acc = 0.9827666511411272\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 112, train_loss = 7.418537329882383, train_acc = 0.9827666511411272\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 113, train_loss = 7.352603113278747, train_acc = 0.9827666511411272\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 114, train_loss = 7.287471793591976, train_acc = 0.9829995342338146\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 115, train_loss = 7.223187202587724, train_acc = 0.9832324173265021\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 116, train_loss = 7.159759879112244, train_acc = 0.9835817419655333\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 117, train_loss = 7.0972082037478685, train_acc = 0.9838146250582208\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 118, train_loss = 7.035489769652486, train_acc = 0.9840475081509082\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 119, train_loss = 6.974473770707846, train_acc = 0.9840475081509082\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 120, train_loss = 6.914477271959186, train_acc = 0.9840475081509082\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 121, train_loss = 6.855158220976591, train_acc = 0.984163949697252\n",
      "test Acc 0.972998137802607:\n",
      "9th- epoch: 122, train_loss = 6.796661250293255, train_acc = 0.9846297158826269\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 123, train_loss = 6.738897563889623, train_acc = 0.9848625989753144\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 124, train_loss = 6.681992208585143, train_acc = 0.9849790405216581\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 125, train_loss = 6.6257889829576015, train_acc = 0.985444806707033\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 126, train_loss = 6.570346686989069, train_acc = 0.9856776897997206\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 127, train_loss = 6.515483308583498, train_acc = 0.985910572892408\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 128, train_loss = 6.461419008672237, train_acc = 0.9862598975314392\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 129, train_loss = 6.407994361594319, train_acc = 0.9861434559850955\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 130, train_loss = 6.355301724746823, train_acc = 0.9862598975314392\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 131, train_loss = 6.303189858794212, train_acc = 0.9866092221704704\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 132, train_loss = 6.25172601826489, train_acc = 0.9868421052631579\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 133, train_loss = 6.200865060091019, train_acc = 0.9869585468095017\n",
      "test Acc 0.973463687150838:\n",
      "9th- epoch: 134, train_loss = 6.150542134419084, train_acc = 0.9870749883558454\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 135, train_loss = 6.100883638486266, train_acc = 0.9870749883558454\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 136, train_loss = 6.051461903378367, train_acc = 0.9873078714485328\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 137, train_loss = 6.002951890230179, train_acc = 0.9873078714485328\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 138, train_loss = 5.954917449504137, train_acc = 0.9873078714485328\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 139, train_loss = 5.9075039476156235, train_acc = 0.9873078714485328\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 140, train_loss = 5.860662909224629, train_acc = 0.9875407545412203\n",
      "test Acc 0.9748603351955307:\n",
      "9th- epoch: 141, train_loss = 5.814317744225264, train_acc = 0.9877736376339078\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 142, train_loss = 5.768525147810578, train_acc = 0.9880065207265952\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 143, train_loss = 5.723214631900191, train_acc = 0.9880065207265952\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 144, train_loss = 5.6784651428461075, train_acc = 0.9881229622729389\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 145, train_loss = 5.634127063676715, train_acc = 0.9884722869119702\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 146, train_loss = 5.590303556993604, train_acc = 0.9884722869119702\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 147, train_loss = 5.547022243961692, train_acc = 0.9887051700046576\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 148, train_loss = 5.504272099584341, train_acc = 0.9888216115510013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 149, train_loss = 5.462021039798856, train_acc = 0.9888216115510013\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 150, train_loss = 5.420273458585143, train_acc = 0.9888216115510013\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 151, train_loss = 5.379086554981768, train_acc = 0.9888216115510013\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 152, train_loss = 5.338267751969397, train_acc = 0.9891709361900326\n",
      "test Acc 0.9757914338919925:\n",
      "9th- epoch: 153, train_loss = 5.298181206919253, train_acc = 0.9891709361900326\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 154, train_loss = 5.2582732597365975, train_acc = 0.9891709361900326\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 155, train_loss = 5.218831363134086, train_acc = 0.9891709361900326\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 156, train_loss = 5.180064293555915, train_acc = 0.9891709361900326\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 157, train_loss = 5.14153484813869, train_acc = 0.9892873777363763\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 158, train_loss = 5.103437568992376, train_acc = 0.9895202608290639\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 159, train_loss = 5.065889145247638, train_acc = 0.9897531439217513\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 160, train_loss = 5.028958931565285, train_acc = 0.9897531439217513\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 161, train_loss = 4.992025849409401, train_acc = 0.989869585468095\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 162, train_loss = 4.955932240001857, train_acc = 0.9899860270144387\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 163, train_loss = 4.920060978271067, train_acc = 0.9899860270144387\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 164, train_loss = 4.884552166797221, train_acc = 0.9899860270144387\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 165, train_loss = 4.8494993932545185, train_acc = 0.9899860270144387\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 166, train_loss = 4.814930183812976, train_acc = 0.9901024685607824\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 167, train_loss = 4.780752764083445, train_acc = 0.9902189101071263\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 168, train_loss = 4.746851221658289, train_acc = 0.9902189101071263\n",
      "test Acc 0.9771880819366853:\n",
      "9th- epoch: 169, train_loss = 4.713503149338067, train_acc = 0.99033535165347\n",
      "test Acc 0.9771880819366853:\n",
      "9th- epoch: 170, train_loss = 4.6804370898753405, train_acc = 0.9904517931998137\n",
      "test Acc 0.9771880819366853:\n",
      "9th- epoch: 171, train_loss = 4.647645234130323, train_acc = 0.9906846762925011\n",
      "test Acc 0.9771880819366853:\n",
      "9th- epoch: 172, train_loss = 4.615336460061371, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 173, train_loss = 4.583335151895881, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 174, train_loss = 4.551657985895872, train_acc = 0.9910340009315324\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 175, train_loss = 4.5204418590292335, train_acc = 0.9912668840242198\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 176, train_loss = 4.489529226906598, train_acc = 0.9913833255705635\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 177, train_loss = 4.4590257946401834, train_acc = 0.9913833255705635\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 178, train_loss = 4.4288679445162416, train_acc = 0.9914997671169073\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 179, train_loss = 4.399193226359785, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 180, train_loss = 4.36967724468559, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 181, train_loss = 4.340649572201073, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 182, train_loss = 4.311786630190909, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 183, train_loss = 4.283253741450608, train_acc = 0.9916162086632511\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 184, train_loss = 4.255315878428519, train_acc = 0.9917326502095948\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 185, train_loss = 4.227290961891413, train_acc = 0.9917326502095948\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 186, train_loss = 4.199878942221403, train_acc = 0.9918490917559385\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 187, train_loss = 4.172537584789097, train_acc = 0.9918490917559385\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 188, train_loss = 4.1456710724160075, train_acc = 0.9918490917559385\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 189, train_loss = 4.118860664777458, train_acc = 0.9918490917559385\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 190, train_loss = 4.092585778795183, train_acc = 0.9918490917559385\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 191, train_loss = 4.0663533033803105, train_acc = 0.9918490917559385\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 192, train_loss = 4.040516992099583, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 193, train_loss = 4.014930319972336, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 194, train_loss = 3.9897930277511477, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 195, train_loss = 3.964731660671532, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 196, train_loss = 3.940230959095061, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 197, train_loss = 3.9158277167007327, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 198, train_loss = 3.891769714653492, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 199, train_loss = 3.8680059844627976, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 200, train_loss = 3.8443906465545297, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 201, train_loss = 3.821218798868358, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 202, train_loss = 3.7979732528328896, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 203, train_loss = 3.7753633335232735, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 204, train_loss = 3.752741198055446, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 205, train_loss = 3.7305034743621945, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 206, train_loss = 3.708549533970654, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 207, train_loss = 3.6866823649033904, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 208, train_loss = 3.6651816330850124, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 209, train_loss = 3.6439858549274504, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 210, train_loss = 3.6227403269149363, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 211, train_loss = 3.602004534099251, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 212, train_loss = 3.581457208842039, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 213, train_loss = 3.5608541681431234, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 214, train_loss = 3.540735901799053, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 215, train_loss = 3.520782647188753, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 216, train_loss = 3.501015634741634, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 217, train_loss = 3.481452959123999, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 218, train_loss = 3.462200111243874, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 219, train_loss = 3.4430740126408637, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 220, train_loss = 3.4241332300007343, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 221, train_loss = 3.405527701135725, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 222, train_loss = 3.386908067855984, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 223, train_loss = 3.368593320250511, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 224, train_loss = 3.3504169564694166, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 225, train_loss = 3.332590103149414, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 226, train_loss = 3.3146893135271966, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 227, train_loss = 3.2971370755694807, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 228, train_loss = 3.279797735158354, train_acc = 0.9930135072193759\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 229, train_loss = 3.262416968587786, train_acc = 0.9931299487657196\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 230, train_loss = 3.245389025658369, train_acc = 0.9931299487657196\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 231, train_loss = 3.228495475370437, train_acc = 0.9931299487657196\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 232, train_loss = 3.211771124973893, train_acc = 0.9931299487657196\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 233, train_loss = 3.195181373041123, train_acc = 0.9932463903120633\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 234, train_loss = 3.1788176503032446, train_acc = 0.9932463903120633\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 235, train_loss = 3.162569289561361, train_acc = 0.9932463903120633\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 236, train_loss = 3.1464276015758514, train_acc = 0.9932463903120633\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 237, train_loss = 3.1306549324654043, train_acc = 0.9932463903120633\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 238, train_loss = 3.1148274578154087, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 239, train_loss = 3.0992008433677256, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 240, train_loss = 3.083779370877892, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 241, train_loss = 3.068480356130749, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 242, train_loss = 3.053336327429861, train_acc = 0.9935957149510946\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 243, train_loss = 3.0384776280261576, train_acc = 0.9935957149510946\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 244, train_loss = 3.0235124207101762, train_acc = 0.993828598043782\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 245, train_loss = 3.0089699043892324, train_acc = 0.993828598043782\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 246, train_loss = 2.9943894669413567, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 247, train_loss = 2.9799766638316214, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 248, train_loss = 2.965746761765331, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 249, train_loss = 2.9516950151883066, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 250, train_loss = 2.9377685957588255, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 251, train_loss = 2.92400354007259, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 252, train_loss = 2.910240878816694, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 253, train_loss = 2.896736392285675, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 254, train_loss = 2.8833765648305416, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 255, train_loss = 2.8700860240496695, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 256, train_loss = 2.8568397886119783, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 257, train_loss = 2.84385584294796, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 258, train_loss = 2.83086197078228, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 259, train_loss = 2.818146204110235, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 260, train_loss = 2.805485801305622, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 261, train_loss = 2.7929209135472775, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 262, train_loss = 2.780533855315298, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 263, train_loss = 2.7681759507395327, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 264, train_loss = 2.7560211904346943, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 265, train_loss = 2.7440496422350407, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 266, train_loss = 2.732062338385731, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 267, train_loss = 2.7202373296022415, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 268, train_loss = 2.708611457142979, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 269, train_loss = 2.6969938538968563, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 270, train_loss = 2.685387037694454, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 271, train_loss = 2.67414957517758, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 272, train_loss = 2.6628060191869736, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 273, train_loss = 2.6517090597189963, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 274, train_loss = 2.640747781842947, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 275, train_loss = 2.629770651459694, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 276, train_loss = 2.618888469878584, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 277, train_loss = 2.6083090766333044, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 278, train_loss = 2.5977068170905113, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 279, train_loss = 2.5873090899549425, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 280, train_loss = 2.5768169723451138, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 281, train_loss = 2.5664886771701276, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 282, train_loss = 2.556418299674988, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 283, train_loss = 2.5462107248604298, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 284, train_loss = 2.5364473164081573, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 285, train_loss = 2.52649371069856, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 286, train_loss = 2.516609586775303, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 287, train_loss = 2.5070931527297944, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 288, train_loss = 2.497345770476386, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 289, train_loss = 2.4879472355823964, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 290, train_loss = 2.4785517405252904, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 291, train_loss = 2.4691670301835984, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 292, train_loss = 2.460094127804041, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 293, train_loss = 2.4508273031096905, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 294, train_loss = 2.4418499146122485, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 295, train_loss = 2.4329361591953784, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 296, train_loss = 2.4239648182410747, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 297, train_loss = 2.4152078952174634, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 298, train_loss = 2.406521737575531, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 299, train_loss = 2.3978537146467716, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 300, train_loss = 2.389350560726598, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 301, train_loss = 2.3808739718515426, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 302, train_loss = 2.372467079432681, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 303, train_loss = 2.3643397092819214, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 304, train_loss = 2.3559895269572735, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 305, train_loss = 2.3478595700580627, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 306, train_loss = 2.3398444813210517, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 307, train_loss = 2.331790566444397, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 308, train_loss = 2.324025269597769, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 309, train_loss = 2.3161007289309055, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 310, train_loss = 2.308414865285158, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 311, train_loss = 2.300643963040784, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 312, train_loss = 2.293097486020997, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 313, train_loss = 2.285540385870263, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 314, train_loss = 2.277969726594165, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 315, train_loss = 2.2706651899497956, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 316, train_loss = 2.2633076831698418, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 317, train_loss = 2.256003388436511, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 318, train_loss = 2.2488144289236516, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 319, train_loss = 2.24169584736228, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 320, train_loss = 2.234691321849823, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 321, train_loss = 2.227664368925616, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 322, train_loss = 2.22080144030042, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 323, train_loss = 2.2140315894503146, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 324, train_loss = 2.207197144627571, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 325, train_loss = 2.2005002025980502, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 326, train_loss = 2.1938321355264634, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 327, train_loss = 2.1872711293399334, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 328, train_loss = 2.1805895778816193, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 329, train_loss = 2.1742151516955346, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 330, train_loss = 2.167705782921985, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 331, train_loss = 2.1613653015810996, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 332, train_loss = 2.1550555017311126, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 333, train_loss = 2.1488189350347966, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 334, train_loss = 2.142668217420578, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 335, train_loss = 2.1365821708459407, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 336, train_loss = 2.1304827481508255, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 337, train_loss = 2.1245377759914845, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 338, train_loss = 2.118428148329258, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 339, train_loss = 2.112643553642556, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 340, train_loss = 2.106762720970437, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 341, train_loss = 2.100941987009719, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 342, train_loss = 2.0952477157115936, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 343, train_loss = 2.089605414541438, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 344, train_loss = 2.0840495575685054, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 345, train_loss = 2.078356732847169, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 346, train_loss = 2.0727387170773, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 347, train_loss = 2.067302132723853, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 348, train_loss = 2.061965762404725, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 349, train_loss = 2.0566197484731674, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 350, train_loss = 2.051247264025733, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 351, train_loss = 2.045890698907897, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 352, train_loss = 2.0406590949278325, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 353, train_loss = 2.0354528452735394, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 354, train_loss = 2.030278575839475, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 355, train_loss = 2.025128311244771, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 356, train_loss = 2.020209514768794, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 357, train_loss = 2.015119644580409, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 358, train_loss = 2.010087476344779, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 359, train_loss = 2.0052504267077893, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 360, train_loss = 2.000283218920231, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 361, train_loss = 1.9955064181704074, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 362, train_loss = 1.9906462840735912, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 363, train_loss = 1.9858246892690659, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 364, train_loss = 1.9812162269372493, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 365, train_loss = 1.9764352701604366, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 366, train_loss = 1.9718989990651608, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 367, train_loss = 1.967207794310525, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 368, train_loss = 1.962663944810629, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 369, train_loss = 1.9581976905465126, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 370, train_loss = 1.9536511835176498, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 371, train_loss = 1.9491886496543884, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 372, train_loss = 1.944779445650056, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 373, train_loss = 1.9403082740027457, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 374, train_loss = 1.9360124232480302, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 375, train_loss = 1.9317164160311222, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 376, train_loss = 1.9275145754218102, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 377, train_loss = 1.9230992533266544, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 378, train_loss = 1.9189116893103346, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 379, train_loss = 1.9147574478993192, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 380, train_loss = 1.9106301540741697, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 381, train_loss = 1.9066180227091536, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 382, train_loss = 1.9023369401693344, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 383, train_loss = 1.8985452627530321, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 384, train_loss = 1.8944379227468744, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 385, train_loss = 1.890507709234953, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 386, train_loss = 1.8865494802594185, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 387, train_loss = 1.882678896188736, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 388, train_loss = 1.8787032639374956, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 389, train_loss = 1.8749560577562079, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 390, train_loss = 1.8710504621267319, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 391, train_loss = 1.8672111704945564, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 392, train_loss = 1.86361361539457, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 393, train_loss = 1.8597136698663235, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 394, train_loss = 1.856196790933609, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 395, train_loss = 1.8523977088043466, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 396, train_loss = 1.8487233631312847, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 397, train_loss = 1.8452178575098515, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 398, train_loss = 1.8415799600770697, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 399, train_loss = 1.8379642268409953, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 400, train_loss = 1.834577288478613, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 401, train_loss = 1.8309760255506262, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 402, train_loss = 1.8275343949208036, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 403, train_loss = 1.824115558178164, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 404, train_loss = 1.8206915967166424, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 405, train_loss = 1.8172428844263777, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 406, train_loss = 1.8139188326895237, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 407, train_loss = 1.8106062188744545, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 408, train_loss = 1.8071454825112596, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 409, train_loss = 1.8039256893098354, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 410, train_loss = 1.8006868636002764, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 411, train_loss = 1.7974595973500982, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 412, train_loss = 1.7941966640064493, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 413, train_loss = 1.791020238189958, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 414, train_loss = 1.7877941876649857, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 415, train_loss = 1.784749979735352, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 416, train_loss = 1.7815092926612124, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 417, train_loss = 1.7785407602787018, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 418, train_loss = 1.775478201569058, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 419, train_loss = 1.7722869701683521, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 420, train_loss = 1.7693248005816713, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 421, train_loss = 1.7663999820360914, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 422, train_loss = 1.7632287442684174, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 423, train_loss = 1.7603452503681183, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 424, train_loss = 1.7573310931911692, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 425, train_loss = 1.7545394686749205, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 426, train_loss = 1.7514555169036612, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 427, train_loss = 1.7485845176270232, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 428, train_loss = 1.7457616478204727, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 429, train_loss = 1.742944567115046, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 430, train_loss = 1.7401164347538725, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 431, train_loss = 1.737200835137628, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 432, train_loss = 1.7344792386284098, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 433, train_loss = 1.7318933457136154, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 434, train_loss = 1.729075726121664, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 435, train_loss = 1.7263072095811367, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 436, train_loss = 1.7235394455492496, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 437, train_loss = 1.7208820196101442, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 438, train_loss = 1.718187695951201, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 439, train_loss = 1.7156780660152435, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 440, train_loss = 1.7129279287764803, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 441, train_loss = 1.7103429412236437, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 442, train_loss = 1.7078084846725687, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 443, train_loss = 1.7052639672765508, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 444, train_loss = 1.702659102738835, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 445, train_loss = 1.7001082561910152, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 446, train_loss = 1.6977173214545473, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 447, train_loss = 1.695187402307056, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 448, train_loss = 1.692674701451324, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 449, train_loss = 1.690128892660141, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 450, train_loss = 1.6877219937741756, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 451, train_loss = 1.6852056992938742, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 452, train_loss = 1.6828531324863434, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 453, train_loss = 1.6804806416621432, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 454, train_loss = 1.6780507614603266, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 455, train_loss = 1.6755509786307812, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 456, train_loss = 1.6732274988899007, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 457, train_loss = 1.671101943938993, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 458, train_loss = 1.6686767427017912, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 459, train_loss = 1.6662442026427016, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 460, train_loss = 1.6640756403794512, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 461, train_loss = 1.661728416918777, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 462, train_loss = 1.659443543641828, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 463, train_loss = 1.6572854170808569, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 464, train_loss = 1.6550452908268198, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 465, train_loss = 1.6527126170694828, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 466, train_loss = 1.6506186289479956, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 467, train_loss = 1.648492851643823, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 468, train_loss = 1.646216363995336, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 469, train_loss = 1.6439732076833025, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 470, train_loss = 1.641949225217104, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 471, train_loss = 1.639874522923492, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 472, train_loss = 1.637705878703855, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 473, train_loss = 1.6355134546756744, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 474, train_loss = 1.6333764443406835, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 475, train_loss = 1.6312759829452261, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 476, train_loss = 1.629362533451058, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 477, train_loss = 1.6272996390471235, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 478, train_loss = 1.6251295084366575, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 479, train_loss = 1.6230852777371183, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 480, train_loss = 1.6211123937973753, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 481, train_loss = 1.6191727767582051, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 482, train_loss = 1.6173367289011367, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 483, train_loss = 1.6151958468253724, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 484, train_loss = 1.6132495502824895, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 485, train_loss = 1.611240444064606, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 486, train_loss = 1.6093075374956243, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 487, train_loss = 1.6074557441170327, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 488, train_loss = 1.6056591980159283, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 489, train_loss = 1.6036367167835124, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 490, train_loss = 1.6016069414908998, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 491, train_loss = 1.5999375854735263, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 492, train_loss = 1.5979302425985225, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 493, train_loss = 1.5960027165710926, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 494, train_loss = 1.5943214384024031, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 495, train_loss = 1.5925663262605667, train_acc = 0.9962738705170004\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 496, train_loss = 1.5906510427594185, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 497, train_loss = 1.5887920657987706, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 498, train_loss = 1.5870066111092456, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 499, train_loss = 1.5851347632706165, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████████████▉                                                   | 9/30 [59:45<2:19:22, 398.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "10th- epoch: 0, train_loss = 273.93307292461395, train_acc = 0.40905915230554263\n",
      "test Acc 0.4860335195530726:\n",
      "10th- epoch: 1, train_loss = 210.47129464149475, train_acc = 0.492081974848626\n",
      "test Acc 0.5:\n",
      "10th- epoch: 2, train_loss = 169.83437263965607, train_acc = 0.513623660922217\n",
      "test Acc 0.5484171322160148:\n",
      "10th- epoch: 3, train_loss = 146.50781744718552, train_acc = 0.6256404285048905\n",
      "test Acc 0.7094972067039106:\n",
      "10th- epoch: 4, train_loss = 127.88984823226929, train_acc = 0.7144853283651607\n",
      "test Acc 0.7313780260707635:\n",
      "10th- epoch: 5, train_loss = 111.67385399341583, train_acc = 0.7357941313460643\n",
      "test Acc 0.7546554934823091:\n",
      "10th- epoch: 6, train_loss = 98.22985827922821, train_acc = 0.7735211923614346\n",
      "test Acc 0.7895716945996276:\n",
      "10th- epoch: 7, train_loss = 87.20177626609802, train_acc = 0.8040288775034933\n",
      "test Acc 0.8109869646182495:\n",
      "10th- epoch: 8, train_loss = 77.91338434815407, train_acc = 0.8260363297624592\n",
      "test Acc 0.8319366852886406:\n",
      "10th- epoch: 9, train_loss = 69.95947909355164, train_acc = 0.853865859338612\n",
      "test Acc 0.8663873370577281:\n",
      "10th- epoch: 10, train_loss = 63.1435372531414, train_acc = 0.8735444806707033\n",
      "test Acc 0.8780260707635009:\n",
      "10th- epoch: 11, train_loss = 57.33103212714195, train_acc = 0.8830926874708896\n",
      "test Acc 0.8845437616387337:\n",
      "10th- epoch: 12, train_loss = 52.40229678153992, train_acc = 0.8927573358174197\n",
      "test Acc 0.8896648044692738:\n",
      "10th- epoch: 13, train_loss = 48.22389070689678, train_acc = 0.8996273870517001\n",
      "test Acc 0.898975791433892:\n",
      "10th- epoch: 14, train_loss = 44.66306583583355, train_acc = 0.9098742431299488\n",
      "test Acc 0.9110800744878957:\n",
      "10th- epoch: 15, train_loss = 41.632129684090614, train_acc = 0.9229156963204471\n",
      "test Acc 0.9259776536312849:\n",
      "10th- epoch: 16, train_loss = 39.01261629164219, train_acc = 0.9353749417792269\n",
      "test Acc 0.9343575418994413:\n",
      "10th- epoch: 17, train_loss = 36.72967641055584, train_acc = 0.94014904517932\n",
      "test Acc 0.9376163873370578:\n",
      "10th- epoch: 18, train_loss = 34.724728509783745, train_acc = 0.9429436422915697\n",
      "test Acc 0.9385474860335196:\n",
      "10th- epoch: 19, train_loss = 32.955776661634445, train_acc = 0.9450395901257569\n",
      "test Acc 0.9418063314711359:\n",
      "10th- epoch: 20, train_loss = 31.390122160315514, train_acc = 0.9477177456916628\n",
      "test Acc 0.9441340782122905:\n",
      "10th- epoch: 21, train_loss = 29.997084729373455, train_acc = 0.9492314857941313\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 22, train_loss = 28.75119400769472, train_acc = 0.9506287843502562\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 23, train_loss = 27.63099867105484, train_acc = 0.9513274336283186\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 24, train_loss = 26.61993768811226, train_acc = 0.952491849091756\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 25, train_loss = 25.701277188956738, train_acc = 0.9542384722869119\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 26, train_loss = 24.862979374825954, train_acc = 0.9554028877503493\n",
      "test Acc 0.9497206703910615:\n",
      "10th- epoch: 27, train_loss = 24.09415727108717, train_acc = 0.9556357708430367\n",
      "test Acc 0.9506517690875232:\n",
      "10th- epoch: 28, train_loss = 23.384799525141716, train_acc = 0.9566837447601304\n",
      "test Acc 0.9515828677839852:\n",
      "10th- epoch: 29, train_loss = 22.727101493626833, train_acc = 0.9576152771308803\n",
      "test Acc 0.952513966480447:\n",
      "10th- epoch: 30, train_loss = 22.114470593631268, train_acc = 0.9583139264089428\n",
      "test Acc 0.952513966480447:\n",
      "10th- epoch: 31, train_loss = 21.5419484898448, train_acc = 0.9592454587796926\n",
      "test Acc 0.9529795158286778:\n",
      "10th- epoch: 32, train_loss = 21.00558650866151, train_acc = 0.9601769911504425\n",
      "test Acc 0.9539106145251397:\n",
      "10th- epoch: 33, train_loss = 20.50198758020997, train_acc = 0.9607591988821611\n",
      "test Acc 0.9539106145251397:\n",
      "10th- epoch: 34, train_loss = 20.02790417894721, train_acc = 0.961690731252911\n",
      "test Acc 0.9543761638733705:\n",
      "10th- epoch: 35, train_loss = 19.5790330208838, train_acc = 0.9620400558919422\n",
      "test Acc 0.9548417132216015:\n",
      "10th- epoch: 36, train_loss = 19.154398553073406, train_acc = 0.9622729389846297\n",
      "test Acc 0.9548417132216015:\n",
      "10th- epoch: 37, train_loss = 18.751838203519583, train_acc = 0.9633209129017233\n",
      "test Acc 0.9562383612662942:\n",
      "10th- epoch: 38, train_loss = 18.36904586851597, train_acc = 0.9646017699115044\n",
      "test Acc 0.957169459962756:\n",
      "10th- epoch: 39, train_loss = 18.004775889217854, train_acc = 0.9648346530041919\n",
      "test Acc 0.9581005586592178:\n",
      "10th- epoch: 40, train_loss = 17.65734063833952, train_acc = 0.9658826269212856\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 41, train_loss = 17.325257439166307, train_acc = 0.9664648346530041\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 42, train_loss = 17.007479704916477, train_acc = 0.9679785747554728\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 43, train_loss = 16.702747024595737, train_acc = 0.9689101071262226\n",
      "test Acc 0.9608938547486033:\n",
      "10th- epoch: 44, train_loss = 16.409959129989147, train_acc = 0.9698416394969726\n",
      "test Acc 0.9608938547486033:\n",
      "10th- epoch: 45, train_loss = 16.128096964210272, train_acc = 0.9701909641360037\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 46, train_loss = 15.856941390782595, train_acc = 0.9701909641360037\n",
      "test Acc 0.9618249534450651:\n",
      "10th- epoch: 47, train_loss = 15.59544886648655, train_acc = 0.9704238472286912\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 48, train_loss = 15.343081813305616, train_acc = 0.9713553795994411\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 49, train_loss = 15.098760362714529, train_acc = 0.9719375873311598\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 50, train_loss = 14.86232067272067, train_acc = 0.9721704704238472\n",
      "test Acc 0.9641527001862198:\n",
      "10th- epoch: 51, train_loss = 14.633359517902136, train_acc = 0.9725197950628784\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 52, train_loss = 14.411685027182102, train_acc = 0.9729855612482534\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 53, train_loss = 14.19689617305994, train_acc = 0.9732184443409408\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 54, train_loss = 13.98867879062891, train_acc = 0.9735677689799721\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 55, train_loss = 13.786705795675516, train_acc = 0.9739170936190032\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 56, train_loss = 13.589900076389313, train_acc = 0.9741499767116907\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 57, train_loss = 13.39870971441269, train_acc = 0.9744993013507219\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 58, train_loss = 13.213063832372427, train_acc = 0.9744993013507219\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 59, train_loss = 13.0318343937397, train_acc = 0.9746157428970657\n",
      "test Acc 0.9655493482309124:\n",
      "10th- epoch: 60, train_loss = 12.85494651272893, train_acc = 0.9747321844434094\n",
      "test Acc 0.9664804469273743:\n",
      "10th- epoch: 61, train_loss = 12.682134691625834, train_acc = 0.9751979506287843\n",
      "test Acc 0.9664804469273743:\n",
      "10th- epoch: 62, train_loss = 12.512868955731392, train_acc = 0.9756637168141593\n",
      "test Acc 0.9669459962756052:\n",
      "10th- epoch: 63, train_loss = 12.346521381288767, train_acc = 0.975780158360503\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 64, train_loss = 12.185131561011076, train_acc = 0.9758965999068467\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 65, train_loss = 12.02814955636859, train_acc = 0.9758965999068467\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 66, train_loss = 11.875699248164892, train_acc = 0.9760130414531905\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 67, train_loss = 11.727290190756321, train_acc = 0.976245924545878\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 68, train_loss = 11.582436017692089, train_acc = 0.9764788076385654\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 69, train_loss = 11.44059020653367, train_acc = 0.9767116907312529\n",
      "test Acc 0.9688081936685289:\n",
      "10th- epoch: 70, train_loss = 11.301846861839294, train_acc = 0.9772938984629715\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 71, train_loss = 11.166047072038054, train_acc = 0.9776432231020028\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 72, train_loss = 11.033020434901118, train_acc = 0.9777596646483465\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 73, train_loss = 10.90288557112217, train_acc = 0.977992547741034\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 74, train_loss = 10.775560630485415, train_acc = 0.9781089892873778\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 75, train_loss = 10.651141801849008, train_acc = 0.9784583139264089\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 76, train_loss = 10.529429193586111, train_acc = 0.9785747554727526\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 77, train_loss = 10.410225650295615, train_acc = 0.9786911970190965\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 78, train_loss = 10.293664935976267, train_acc = 0.9788076385654402\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 79, train_loss = 10.17917793057859, train_acc = 0.9789240801117839\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 80, train_loss = 10.066757433116436, train_acc = 0.9789240801117839\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 81, train_loss = 9.956557773053646, train_acc = 0.9790405216581276\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 82, train_loss = 9.848120609298348, train_acc = 0.9790405216581276\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 83, train_loss = 9.741737447679043, train_acc = 0.9792734047508151\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 84, train_loss = 9.63751546293497, train_acc = 0.9793898462971589\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 85, train_loss = 9.535178311169147, train_acc = 0.9793898462971589\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 86, train_loss = 9.434619884938002, train_acc = 0.9793898462971589\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 87, train_loss = 9.335688419640064, train_acc = 0.9796227293898463\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 88, train_loss = 9.238275039941072, train_acc = 0.97973917093619\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 89, train_loss = 9.142476484179497, train_acc = 0.9799720540288775\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 90, train_loss = 9.04816960170865, train_acc = 0.9800884955752213\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 91, train_loss = 8.955865800380707, train_acc = 0.980204937121565\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 92, train_loss = 8.86529279872775, train_acc = 0.9803213786679087\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 93, train_loss = 8.776207976043224, train_acc = 0.9803213786679087\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 94, train_loss = 8.688553135842085, train_acc = 0.98067070330694\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 95, train_loss = 8.602257296442986, train_acc = 0.9809035863996274\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 96, train_loss = 8.517355227842927, train_acc = 0.9813693525850024\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 97, train_loss = 8.433601438999176, train_acc = 0.9814857941313461\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 98, train_loss = 8.351139146834612, train_acc = 0.9817186772240335\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 99, train_loss = 8.269601946696639, train_acc = 0.981951560316721\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 100, train_loss = 8.189589198678732, train_acc = 0.9820680018630648\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 101, train_loss = 8.110977137461305, train_acc = 0.9821844434094085\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 102, train_loss = 8.033501233905554, train_acc = 0.9824173265020959\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 103, train_loss = 7.957147318869829, train_acc = 0.9827666511411272\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 104, train_loss = 7.8819811549037695, train_acc = 0.9828830926874709\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 105, train_loss = 7.807865280658007, train_acc = 0.9832324173265021\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 106, train_loss = 7.734552748501301, train_acc = 0.9835817419655333\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 107, train_loss = 7.662420028820634, train_acc = 0.9839310666045645\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 108, train_loss = 7.591352097690105, train_acc = 0.9840475081509082\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 109, train_loss = 7.521178334951401, train_acc = 0.9842803912435957\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 110, train_loss = 7.45200097002089, train_acc = 0.9843968327899395\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 111, train_loss = 7.383794840425253, train_acc = 0.9849790405216581\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 112, train_loss = 7.316411484032869, train_acc = 0.9853283651606893\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 113, train_loss = 7.25003663264215, train_acc = 0.9853283651606893\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 114, train_loss = 7.184494704008102, train_acc = 0.985444806707033\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 115, train_loss = 7.119741678237915, train_acc = 0.9855612482533768\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 116, train_loss = 7.055941643193364, train_acc = 0.9855612482533768\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 117, train_loss = 6.9930955693125725, train_acc = 0.9855612482533768\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 118, train_loss = 6.9311763402074575, train_acc = 0.9856776897997206\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 119, train_loss = 6.869847897440195, train_acc = 0.9856776897997206\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 120, train_loss = 6.809464618563652, train_acc = 0.9857941313460643\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 121, train_loss = 6.749898388981819, train_acc = 0.9857941313460643\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 122, train_loss = 6.691217515617609, train_acc = 0.9861434559850955\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 123, train_loss = 6.63327744603157, train_acc = 0.9862598975314392\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 124, train_loss = 6.576158430427313, train_acc = 0.986376339077783\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 125, train_loss = 6.519727893173695, train_acc = 0.9866092221704704\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 126, train_loss = 6.464243648573756, train_acc = 0.9868421052631579\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 127, train_loss = 6.409282419830561, train_acc = 0.9871914299021891\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 128, train_loss = 6.355226514860988, train_acc = 0.9871914299021891\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 129, train_loss = 6.30175144597888, train_acc = 0.9873078714485328\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 130, train_loss = 6.249040452763438, train_acc = 0.9875407545412203\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 131, train_loss = 6.197080774232745, train_acc = 0.9876571960875641\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 132, train_loss = 6.145660754293203, train_acc = 0.9876571960875641\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 133, train_loss = 6.094996882602572, train_acc = 0.9880065207265952\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 134, train_loss = 6.044959533959627, train_acc = 0.9878900791802515\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 135, train_loss = 5.995549818500876, train_acc = 0.9878900791802515\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 136, train_loss = 5.946766518056393, train_acc = 0.9882394038192828\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 137, train_loss = 5.898658860474825, train_acc = 0.9885887284583139\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 138, train_loss = 5.851094007492065, train_acc = 0.9885887284583139\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 139, train_loss = 5.8043256141245365, train_acc = 0.9888216115510013\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 140, train_loss = 5.758088668808341, train_acc = 0.9888216115510013\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 141, train_loss = 5.7124541867524385, train_acc = 0.9888216115510013\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 142, train_loss = 5.667353512719274, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 143, train_loss = 5.622909074649215, train_acc = 0.9890544946436889\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 144, train_loss = 5.578906610608101, train_acc = 0.9890544946436889\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 145, train_loss = 5.535557409748435, train_acc = 0.9890544946436889\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 146, train_loss = 5.492547085508704, train_acc = 0.9890544946436889\n",
      "test Acc 0.9762569832402235:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 147, train_loss = 5.450225744396448, train_acc = 0.9890544946436889\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 148, train_loss = 5.408434312790632, train_acc = 0.9891709361900326\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 149, train_loss = 5.3668098747730255, train_acc = 0.9891709361900326\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 150, train_loss = 5.3259055353701115, train_acc = 0.9891709361900326\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 151, train_loss = 5.285195667296648, train_acc = 0.9891709361900326\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 152, train_loss = 5.245607288554311, train_acc = 0.9892873777363763\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 153, train_loss = 5.206211283802986, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 154, train_loss = 5.16759891435504, train_acc = 0.9896367023754076\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 155, train_loss = 5.129278790205717, train_acc = 0.989869585468095\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 156, train_loss = 5.091708278283477, train_acc = 0.9899860270144387\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 157, train_loss = 5.054352464154363, train_acc = 0.9899860270144387\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 158, train_loss = 5.017766922712326, train_acc = 0.9899860270144387\n",
      "test Acc 0.9762569832402235:\n",
      "10th- epoch: 159, train_loss = 4.981461636722088, train_acc = 0.9901024685607824\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 160, train_loss = 4.945743769407272, train_acc = 0.9901024685607824\n",
      "test Acc 0.9771880819366853:\n",
      "10th- epoch: 161, train_loss = 4.910547262057662, train_acc = 0.99033535165347\n",
      "test Acc 0.9771880819366853:\n",
      "10th- epoch: 162, train_loss = 4.875788528472185, train_acc = 0.99033535165347\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 163, train_loss = 4.841353939846158, train_acc = 0.9904517931998137\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 164, train_loss = 4.807455511763692, train_acc = 0.9904517931998137\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 165, train_loss = 4.773918490856886, train_acc = 0.9905682347461574\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 166, train_loss = 4.740803677588701, train_acc = 0.9905682347461574\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 167, train_loss = 4.708194957114756, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 168, train_loss = 4.67589358985424, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 169, train_loss = 4.6441445937380195, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 170, train_loss = 4.612643181346357, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 171, train_loss = 4.581810140050948, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 172, train_loss = 4.551230209879577, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 173, train_loss = 4.520919069647789, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 174, train_loss = 4.491052519530058, train_acc = 0.9910340009315324\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 175, train_loss = 4.46168112475425, train_acc = 0.9911504424778761\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 176, train_loss = 4.432524344883859, train_acc = 0.9911504424778761\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 177, train_loss = 4.40375807043165, train_acc = 0.9911504424778761\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 178, train_loss = 4.375389933586121, train_acc = 0.9911504424778761\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 179, train_loss = 4.347347986884415, train_acc = 0.9911504424778761\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 180, train_loss = 4.319633445702493, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 181, train_loss = 4.2923210533335805, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 182, train_loss = 4.265161816030741, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 183, train_loss = 4.238580889068544, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 184, train_loss = 4.212091042660177, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 185, train_loss = 4.186037155799568, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 186, train_loss = 4.16019759234041, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 187, train_loss = 4.134732522070408, train_acc = 0.9914997671169073\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 188, train_loss = 4.109536021016538, train_acc = 0.9916162086632511\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 189, train_loss = 4.084595845080912, train_acc = 0.9917326502095948\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 190, train_loss = 4.060013356618583, train_acc = 0.9917326502095948\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 191, train_loss = 4.035661775618792, train_acc = 0.9917326502095948\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 192, train_loss = 4.0113796927034855, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 193, train_loss = 3.9876840943470597, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 194, train_loss = 3.963801850564778, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 195, train_loss = 3.9406672408804297, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 196, train_loss = 3.91749744489789, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 197, train_loss = 3.894854418002069, train_acc = 0.9921984163949698\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 198, train_loss = 3.8721556840464473, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 199, train_loss = 3.8499641371890903, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 200, train_loss = 3.827982787042856, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 201, train_loss = 3.806024773977697, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 202, train_loss = 3.7844792306423187, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 203, train_loss = 3.763118172995746, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 204, train_loss = 3.741978974081576, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 205, train_loss = 3.721102745272219, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 206, train_loss = 3.7004245333373547, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 207, train_loss = 3.6799285812303424, train_acc = 0.9926641825803446\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 208, train_loss = 3.6595729598775506, train_acc = 0.9927806241266884\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 209, train_loss = 3.639426545239985, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 210, train_loss = 3.6193024665117264, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 211, train_loss = 3.599300974048674, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 212, train_loss = 3.5796075174584985, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 213, train_loss = 3.559563889168203, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 214, train_loss = 3.5394521271809936, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 215, train_loss = 3.5199598828330636, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 216, train_loss = 3.501043912023306, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 217, train_loss = 3.4825052618980408, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 218, train_loss = 3.464257773011923, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 219, train_loss = 3.4460493018850684, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 220, train_loss = 3.428246406838298, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 221, train_loss = 3.410439569503069, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 222, train_loss = 3.3929264629259706, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 223, train_loss = 3.375519054941833, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 224, train_loss = 3.3582801427692175, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 225, train_loss = 3.3411274245008826, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 226, train_loss = 3.324377187527716, train_acc = 0.9931299487657196\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 227, train_loss = 3.307412709109485, train_acc = 0.9931299487657196\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 228, train_loss = 3.291055184789002, train_acc = 0.9931299487657196\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 229, train_loss = 3.274608223233372, train_acc = 0.9931299487657196\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 230, train_loss = 3.258414274081588, train_acc = 0.9932463903120633\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 231, train_loss = 3.2422370216809213, train_acc = 0.9932463903120633\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 232, train_loss = 3.226392462849617, train_acc = 0.9932463903120633\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 233, train_loss = 3.2105452404357493, train_acc = 0.9933628318584071\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 234, train_loss = 3.1951097869314253, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 235, train_loss = 3.17944429628551, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 236, train_loss = 3.1640895674936473, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 237, train_loss = 3.1488771308213472, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 238, train_loss = 3.133827534969896, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 239, train_loss = 3.1189130102284253, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 240, train_loss = 3.104053332004696, train_acc = 0.9935957149510946\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 241, train_loss = 3.0894320141524076, train_acc = 0.9937121564974383\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 242, train_loss = 3.074925860390067, train_acc = 0.993828598043782\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 243, train_loss = 3.060544281732291, train_acc = 0.993828598043782\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 244, train_loss = 3.0462568406946957, train_acc = 0.993828598043782\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 245, train_loss = 3.0321741201914847, train_acc = 0.993828598043782\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 246, train_loss = 3.0181074268184602, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 247, train_loss = 3.0043468959629536, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 248, train_loss = 2.9905067211948335, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 249, train_loss = 2.9768088832497597, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 250, train_loss = 2.963263066019863, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 251, train_loss = 2.950016933027655, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 252, train_loss = 2.936615643557161, train_acc = 0.9940614811364695\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 253, train_loss = 2.9235442210920155, train_acc = 0.9940614811364695\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 254, train_loss = 2.910363625269383, train_acc = 0.9940614811364695\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 255, train_loss = 2.8974943975917995, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 256, train_loss = 2.884679952636361, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 257, train_loss = 2.871939937118441, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 258, train_loss = 2.8592733242549, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 259, train_loss = 2.846871630754322, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 260, train_loss = 2.8343148441053927, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 261, train_loss = 2.8221623487770557, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 262, train_loss = 2.809937824960798, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 263, train_loss = 2.797905683517456, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 264, train_loss = 2.785840901080519, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 265, train_loss = 2.774119336158037, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 266, train_loss = 2.7623394317924976, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 267, train_loss = 2.75061209872365, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 268, train_loss = 2.739186321850866, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 269, train_loss = 2.7276002690196037, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 270, train_loss = 2.716559515800327, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 271, train_loss = 2.7050866298377514, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 272, train_loss = 2.6941416361369193, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 273, train_loss = 2.6829719780944288, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 274, train_loss = 2.6722178435884416, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 275, train_loss = 2.661258748266846, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 276, train_loss = 2.6506008147262037, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 277, train_loss = 2.639841376338154, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 278, train_loss = 2.6293346397578716, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 279, train_loss = 2.6188316554762423, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 280, train_loss = 2.608533824328333, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 281, train_loss = 2.598220158368349, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 282, train_loss = 2.5879932143725455, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 283, train_loss = 2.5780841819941998, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 284, train_loss = 2.567806627601385, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 285, train_loss = 2.5580999976955354, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 286, train_loss = 2.548174226190895, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 287, train_loss = 2.538515228778124, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 288, train_loss = 2.5287902490235865, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 289, train_loss = 2.5192879936657846, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 290, train_loss = 2.5097306333482265, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 291, train_loss = 2.5002299919724464, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 292, train_loss = 2.4911073981784284, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 293, train_loss = 2.48174544936046, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 294, train_loss = 2.4725978509522974, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 295, train_loss = 2.4635488875210285, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 296, train_loss = 2.4545037038624287, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 297, train_loss = 2.4455593056045473, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 298, train_loss = 2.4368224567733705, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 299, train_loss = 2.4280524253845215, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 300, train_loss = 2.4193753115832806, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 301, train_loss = 2.410838135983795, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 302, train_loss = 2.4022721350193024, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 303, train_loss = 2.3937580287456512, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 304, train_loss = 2.385526901576668, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 305, train_loss = 2.3770828605629504, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 306, train_loss = 2.368942901492119, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 307, train_loss = 2.360698094125837, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 308, train_loss = 2.352818224579096, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 309, train_loss = 2.344744788017124, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 310, train_loss = 2.3368795341812074, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 311, train_loss = 2.328971782233566, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 312, train_loss = 2.3212767303921282, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 313, train_loss = 2.313543074997142, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 314, train_loss = 2.3058921832125634, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 315, train_loss = 2.2983164936304092, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 316, train_loss = 2.2910081062000245, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 317, train_loss = 2.283415611833334, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 318, train_loss = 2.2760640308260918, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 319, train_loss = 2.2688509474974126, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 320, train_loss = 2.261608912376687, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 321, train_loss = 2.2545332226436585, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 322, train_loss = 2.2474551387131214, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 323, train_loss = 2.2404175500851125, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 324, train_loss = 2.2333983592689037, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 325, train_loss = 2.2265689335763454, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 326, train_loss = 2.2198026329278946, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 327, train_loss = 2.2128807604312897, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 328, train_loss = 2.206387835321948, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 329, train_loss = 2.1997141130268574, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 330, train_loss = 2.1930910150986165, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 331, train_loss = 2.1865636110305786, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 332, train_loss = 2.1801631425041705, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 333, train_loss = 2.1739105843007565, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 334, train_loss = 2.167533300817013, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 335, train_loss = 2.161237781168893, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 336, train_loss = 2.1551089708227664, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 337, train_loss = 2.1489504985511303, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 338, train_loss = 2.142779378918931, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 339, train_loss = 2.1367035608273, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 340, train_loss = 2.130702458322048, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 341, train_loss = 2.1248849481344223, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 342, train_loss = 2.1190203230362386, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 343, train_loss = 2.1131536464672536, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 344, train_loss = 2.107393228681758, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 345, train_loss = 2.1016257405281067, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 346, train_loss = 2.0959640368819237, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 347, train_loss = 2.0905046202242374, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 348, train_loss = 2.084820018382743, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 349, train_loss = 2.079317793250084, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 350, train_loss = 2.0738201786298305, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 351, train_loss = 2.068455919623375, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 352, train_loss = 2.063180745812133, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 353, train_loss = 2.057794767199084, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 354, train_loss = 2.052591811865568, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 355, train_loss = 2.0472169630229473, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 356, train_loss = 2.04213597625494, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 357, train_loss = 2.0369810573756695, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 358, train_loss = 2.0318799540400505, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 359, train_loss = 2.026838521240279, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 360, train_loss = 2.021941654384136, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 361, train_loss = 2.016824883641675, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 362, train_loss = 2.011952082393691, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 363, train_loss = 2.0070630486588925, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 364, train_loss = 2.0022402789909393, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 365, train_loss = 1.9974320903420448, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 366, train_loss = 1.9926721304655075, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 367, train_loss = 1.9879357740283012, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 368, train_loss = 1.9833216902334243, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 369, train_loss = 1.978658750653267, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 370, train_loss = 1.9740900807082653, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 371, train_loss = 1.9695161182899028, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 372, train_loss = 1.964991670101881, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 373, train_loss = 1.960445010336116, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 374, train_loss = 1.9561435591895133, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 375, train_loss = 1.9516661874949932, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 376, train_loss = 1.947352558374405, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 377, train_loss = 1.9428301739972085, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 378, train_loss = 1.9386724929790944, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 379, train_loss = 1.9343231755774468, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 380, train_loss = 1.9301320563536137, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 381, train_loss = 1.9259238962549716, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 382, train_loss = 1.9218783352989703, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 383, train_loss = 1.9175527691841125, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 384, train_loss = 1.913560350658372, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 385, train_loss = 1.909502724884078, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 386, train_loss = 1.9053953848779202, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 387, train_loss = 1.9014025938231498, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 388, train_loss = 1.8975252497475594, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 389, train_loss = 1.893550845561549, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 390, train_loss = 1.8895524193067104, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 391, train_loss = 1.8856654204428196, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 392, train_loss = 1.8819522212725133, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 393, train_loss = 1.878068619640544, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 394, train_loss = 1.8742743011098355, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 395, train_loss = 1.870450445683673, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 396, train_loss = 1.866769403219223, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 397, train_loss = 1.8630677226465195, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 398, train_loss = 1.85928771388717, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 399, train_loss = 1.8557775542140007, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 400, train_loss = 1.8521172230830416, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 401, train_loss = 1.8486004509031773, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 402, train_loss = 1.8449150696396828, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 403, train_loss = 1.8414866166422144, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 404, train_loss = 1.8379861749708652, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 405, train_loss = 1.834475395618938, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 406, train_loss = 1.831079070805572, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 407, train_loss = 1.8275870978832245, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 408, train_loss = 1.824274798273109, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 409, train_loss = 1.8208580004284158, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 410, train_loss = 1.8174194917082787, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 411, train_loss = 1.8140998122980818, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 412, train_loss = 1.8108082687249407, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 413, train_loss = 1.8074770210077986, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 414, train_loss = 1.8042975092539564, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 415, train_loss = 1.801043144077994, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 416, train_loss = 1.7977759713539854, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 417, train_loss = 1.7945567654678598, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 418, train_loss = 1.7915319725871086, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 419, train_loss = 1.788352556526661, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 420, train_loss = 1.7852770388126373, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 421, train_loss = 1.7821351228049025, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 422, train_loss = 1.779120466322638, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 423, train_loss = 1.7759775394806638, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 424, train_loss = 1.7729833262274042, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 425, train_loss = 1.770056334673427, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 426, train_loss = 1.7670323997735977, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 427, train_loss = 1.7641259096562862, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 428, train_loss = 1.7611651830375195, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 429, train_loss = 1.7582654046127573, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 430, train_loss = 1.7554019453236833, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 431, train_loss = 1.7524699481436983, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 432, train_loss = 1.7496734770247713, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 433, train_loss = 1.746735637425445, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 434, train_loss = 1.7440889937570319, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 435, train_loss = 1.7412115061888471, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 436, train_loss = 1.7383707562694326, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 437, train_loss = 1.7356753895292059, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 438, train_loss = 1.7329143857350573, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 439, train_loss = 1.7301132418215275, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 440, train_loss = 1.7274578859796748, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 441, train_loss = 1.7248061386635527, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 442, train_loss = 1.7222088500857353, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 443, train_loss = 1.7195103032281622, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 444, train_loss = 1.7168439204106107, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 445, train_loss = 1.7142538217594847, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 446, train_loss = 1.7116514258086681, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 447, train_loss = 1.709054316044785, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 448, train_loss = 1.7065293131163344, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 449, train_loss = 1.7040706215193495, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 450, train_loss = 1.7014272511005402, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 451, train_loss = 1.6990212015807629, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 452, train_loss = 1.696517358184792, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 453, train_loss = 1.6940208798041567, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 454, train_loss = 1.6916549056768417, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 455, train_loss = 1.6891346412012354, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 456, train_loss = 1.6867579830577597, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 457, train_loss = 1.68436634412501, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 458, train_loss = 1.682009618729353, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 459, train_loss = 1.6796287409961224, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 460, train_loss = 1.677276081056334, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 461, train_loss = 1.675031932652928, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 462, train_loss = 1.6727146519115195, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 463, train_loss = 1.670299501507543, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 464, train_loss = 1.6680519754299894, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 465, train_loss = 1.6658532209694386, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 466, train_loss = 1.6636032151291147, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 467, train_loss = 1.6613504191627726, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 468, train_loss = 1.6590837948024273, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 469, train_loss = 1.6568518230924383, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 470, train_loss = 1.654544303775765, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 471, train_loss = 1.652428968460299, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 472, train_loss = 1.6501098411390558, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 473, train_loss = 1.6480540422489867, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 474, train_loss = 1.6458067558705807, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 475, train_loss = 1.643650251091458, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 476, train_loss = 1.6415706189582124, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 477, train_loss = 1.6394323445856571, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 478, train_loss = 1.637268178164959, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 479, train_loss = 1.6351991532137617, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 480, train_loss = 1.6332418596139178, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 481, train_loss = 1.631075600744225, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 482, train_loss = 1.6291570836910978, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 483, train_loss = 1.6270680775633082, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 484, train_loss = 1.6251008386025205, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 485, train_loss = 1.6231421629199758, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 486, train_loss = 1.6211424432694912, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 487, train_loss = 1.6192141635110602, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 488, train_loss = 1.617272766889073, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 489, train_loss = 1.615289133042097, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 490, train_loss = 1.6132803397485986, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 491, train_loss = 1.611383881419897, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 492, train_loss = 1.609532809467055, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 493, train_loss = 1.6076451042899862, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 494, train_loss = 1.6058909198036417, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 495, train_loss = 1.603927948861383, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 496, train_loss = 1.601997954188846, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 497, train_loss = 1.6002258969238028, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 498, train_loss = 1.598338125855662, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 499, train_loss = 1.5965849111089483, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████▎                                              | 10/30 [1:06:26<2:12:59, 398.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "11th- epoch: 0, train_loss = 276.43687188625336, train_acc = 0.4012575687005123\n",
      "test Acc 0.4776536312849162:\n",
      "11th- epoch: 1, train_loss = 214.68630850315094, train_acc = 0.48474615742897065\n",
      "test Acc 0.49068901303538176:\n",
      "11th- epoch: 2, train_loss = 172.2737140059471, train_acc = 0.4995342338146251\n",
      "test Acc 0.5107076350093109:\n",
      "11th- epoch: 3, train_loss = 148.94223803281784, train_acc = 0.595947834187238\n",
      "test Acc 0.6657355679702048:\n",
      "11th- epoch: 4, train_loss = 130.67741000652313, train_acc = 0.6913134606427573\n",
      "test Acc 0.7257914338919925:\n",
      "11th- epoch: 5, train_loss = 114.44150817394257, train_acc = 0.7452258965999069\n",
      "test Acc 0.7728119180633147:\n",
      "11th- epoch: 6, train_loss = 100.1523267030716, train_acc = 0.7899394503959013\n",
      "test Acc 0.797951582867784:\n",
      "11th- epoch: 7, train_loss = 87.83013820648193, train_acc = 0.8089194224499301\n",
      "test Acc 0.8161080074487895:\n",
      "11th- epoch: 8, train_loss = 77.36931836605072, train_acc = 0.8308104331625524\n",
      "test Acc 0.845437616387337:\n",
      "11th- epoch: 9, train_loss = 68.5897775888443, train_acc = 0.8595714951094551\n",
      "test Acc 0.8677839851024208:\n",
      "11th- epoch: 10, train_loss = 61.29387429356575, train_acc = 0.8797158826269212\n",
      "test Acc 0.8854748603351955:\n",
      "11th- epoch: 11, train_loss = 55.258409202098846, train_acc = 0.8913600372612949\n",
      "test Acc 0.8933891992551211:\n",
      "11th- epoch: 12, train_loss = 50.2583200186491, train_acc = 0.8982300884955752\n",
      "test Acc 0.8999068901303539:\n",
      "11th- epoch: 13, train_loss = 46.09443341195583, train_acc = 0.9078947368421053\n",
      "test Acc 0.9087523277467412:\n",
      "11th- epoch: 14, train_loss = 42.59335748851299, train_acc = 0.9162785281788542\n",
      "test Acc 0.9175977653631285:\n",
      "11th- epoch: 15, train_loss = 39.623356118798256, train_acc = 0.9244294364229158\n",
      "test Acc 0.9236499068901304:\n",
      "11th- epoch: 16, train_loss = 37.081449285149574, train_acc = 0.9325803446669771\n",
      "test Acc 0.9343575418994413:\n",
      "11th- epoch: 17, train_loss = 34.8882058262825, train_acc = 0.9406148113646949\n",
      "test Acc 0.9399441340782123:\n",
      "11th- epoch: 18, train_loss = 32.98162852227688, train_acc = 0.9444573823940382\n",
      "test Acc 0.9427374301675978:\n",
      "11th- epoch: 19, train_loss = 31.312046088278294, train_acc = 0.9469026548672567\n",
      "test Acc 0.9455307262569832:\n",
      "11th- epoch: 20, train_loss = 29.841849572956562, train_acc = 0.9499301350721937\n",
      "test Acc 0.9487895716945997:\n",
      "11th- epoch: 21, train_loss = 28.54091676324606, train_acc = 0.952026082906381\n",
      "test Acc 0.9492551210428305:\n",
      "11th- epoch: 22, train_loss = 27.379427202045918, train_acc = 0.9541220307405682\n",
      "test Acc 0.9501862197392924:\n",
      "11th- epoch: 23, train_loss = 26.34386720508337, train_acc = 0.9554028877503493\n",
      "test Acc 0.952513966480447:\n",
      "11th- epoch: 24, train_loss = 25.412685438990593, train_acc = 0.9565673032137867\n",
      "test Acc 0.9529795158286778:\n",
      "11th- epoch: 25, train_loss = 24.568447969853878, train_acc = 0.9574988355845365\n",
      "test Acc 0.9529795158286778:\n",
      "11th- epoch: 26, train_loss = 23.798683516681194, train_acc = 0.9590125756870052\n",
      "test Acc 0.9534450651769087:\n",
      "11th- epoch: 27, train_loss = 23.093350026756525, train_acc = 0.9595947834187238\n",
      "test Acc 0.9543761638733705:\n",
      "11th- epoch: 28, train_loss = 22.443658135831356, train_acc = 0.9602934326967862\n",
      "test Acc 0.9553072625698324:\n",
      "11th- epoch: 29, train_loss = 21.842332515865564, train_acc = 0.9607591988821611\n",
      "test Acc 0.9557728119180633:\n",
      "11th- epoch: 30, train_loss = 21.28230796381831, train_acc = 0.9613414066138798\n",
      "test Acc 0.9567039106145251:\n",
      "11th- epoch: 31, train_loss = 20.757931780070066, train_acc = 0.9622729389846297\n",
      "test Acc 0.957169459962756:\n",
      "11th- epoch: 32, train_loss = 20.265136931091547, train_acc = 0.9627387051700047\n",
      "test Acc 0.957635009310987:\n",
      "11th- epoch: 33, train_loss = 19.800516594201326, train_acc = 0.9636702375407545\n",
      "test Acc 0.9585661080074488:\n",
      "11th- epoch: 34, train_loss = 19.360158134251833, train_acc = 0.9646017699115044\n",
      "test Acc 0.9585661080074488:\n",
      "11th- epoch: 35, train_loss = 18.9417423941195, train_acc = 0.9650675360968793\n",
      "test Acc 0.9590316573556797:\n",
      "11th- epoch: 36, train_loss = 18.54377030953765, train_acc = 0.9655333022822543\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 37, train_loss = 18.164600647985935, train_acc = 0.9657661853749417\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 38, train_loss = 17.802138455212116, train_acc = 0.966581276199348\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 39, train_loss = 17.456131659448147, train_acc = 0.9671634839310667\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 40, train_loss = 17.124996107071638, train_acc = 0.9683278993945039\n",
      "test Acc 0.962756052141527:\n",
      "11th- epoch: 41, train_loss = 16.807814568281174, train_acc = 0.9690265486725663\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 42, train_loss = 16.50377471372485, train_acc = 0.9693758733115976\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 43, train_loss = 16.2119104526937, train_acc = 0.9698416394969726\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 44, train_loss = 15.930902030318975, train_acc = 0.97007452258966\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 45, train_loss = 15.659754909574986, train_acc = 0.9711224965067536\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 46, train_loss = 15.398163847625256, train_acc = 0.971821145784816\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 47, train_loss = 15.145805973559618, train_acc = 0.9720540288775035\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 48, train_loss = 14.902225036174059, train_acc = 0.9728691197019096\n",
      "test Acc 0.9641527001862198:\n",
      "11th- epoch: 49, train_loss = 14.666940353810787, train_acc = 0.9729855612482534\n",
      "test Acc 0.9646182495344506:\n",
      "11th- epoch: 50, train_loss = 14.439363546669483, train_acc = 0.9732184443409408\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 51, train_loss = 14.218986650928855, train_acc = 0.9735677689799721\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 52, train_loss = 14.005722457543015, train_acc = 0.9738006520726595\n",
      "test Acc 0.9650837988826816:\n",
      "11th- epoch: 53, train_loss = 13.799101991578937, train_acc = 0.9739170936190032\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 54, train_loss = 13.598642943426967, train_acc = 0.9741499767116907\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 55, train_loss = 13.403859879821539, train_acc = 0.9744993013507219\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 56, train_loss = 13.21458674967289, train_acc = 0.9749650675360969\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 57, train_loss = 13.030704692006111, train_acc = 0.9749650675360969\n",
      "test Acc 0.9674115456238361:\n",
      "11th- epoch: 58, train_loss = 12.85127105563879, train_acc = 0.9749650675360969\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 59, train_loss = 12.675519466400146, train_acc = 0.9750815090824406\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 60, train_loss = 12.50503645464778, train_acc = 0.9750815090824406\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 61, train_loss = 12.3394316136837, train_acc = 0.9751979506287843\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 62, train_loss = 12.178584177047014, train_acc = 0.9756637168141593\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 63, train_loss = 12.021958492696285, train_acc = 0.9760130414531905\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 64, train_loss = 11.869428128004074, train_acc = 0.9761294829995343\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 65, train_loss = 11.720876634120941, train_acc = 0.9767116907312529\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 66, train_loss = 11.57607338577509, train_acc = 0.9769445738239404\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 67, train_loss = 11.434706017374992, train_acc = 0.9775267815556591\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 68, train_loss = 11.296697195619345, train_acc = 0.977992547741034\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 69, train_loss = 11.161829140037298, train_acc = 0.977992547741034\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 70, train_loss = 11.030149426311255, train_acc = 0.9781089892873778\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 71, train_loss = 10.901106726378202, train_acc = 0.9781089892873778\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 72, train_loss = 10.774847153574228, train_acc = 0.9783418723800652\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 73, train_loss = 10.651419911533594, train_acc = 0.9784583139264089\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 74, train_loss = 10.530490528792143, train_acc = 0.9784583139264089\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 75, train_loss = 10.41206319257617, train_acc = 0.9783418723800652\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 76, train_loss = 10.296030476689339, train_acc = 0.9784583139264089\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 77, train_loss = 10.182257525622845, train_acc = 0.9785747554727526\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 78, train_loss = 10.070599660277367, train_acc = 0.9786911970190965\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 79, train_loss = 9.961120013147593, train_acc = 0.9789240801117839\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 80, train_loss = 9.853395499289036, train_acc = 0.9789240801117839\n",
      "test Acc 0.9688081936685289:\n",
      "11th- epoch: 81, train_loss = 9.747559800744057, train_acc = 0.9790405216581276\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 82, train_loss = 9.643947336822748, train_acc = 0.9795062878435026\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 83, train_loss = 9.5420574657619, train_acc = 0.97973917093619\n",
      "test Acc 0.9697392923649907:\n",
      "11th- epoch: 84, train_loss = 9.44175387173891, train_acc = 0.9798556124825337\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 85, train_loss = 9.343540336936712, train_acc = 0.9799720540288775\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 86, train_loss = 9.246907696127892, train_acc = 0.9800884955752213\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 87, train_loss = 9.152084842324257, train_acc = 0.9803213786679087\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 88, train_loss = 9.05865877866745, train_acc = 0.9804378202142524\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 89, train_loss = 8.96691845357418, train_acc = 0.9809035863996274\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 90, train_loss = 8.87664176337421, train_acc = 0.9810200279459711\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 91, train_loss = 8.787684498354793, train_acc = 0.9813693525850024\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 92, train_loss = 8.700335355475545, train_acc = 0.9814857941313461\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 93, train_loss = 8.614314433187246, train_acc = 0.9818351187703773\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 94, train_loss = 8.52954407967627, train_acc = 0.9821844434094085\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 95, train_loss = 8.44609547406435, train_acc = 0.9824173265020959\n",
      "test Acc 0.9716014897579144:\n",
      "11th- epoch: 96, train_loss = 8.363836836069822, train_acc = 0.9824173265020959\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 97, train_loss = 8.28276459313929, train_acc = 0.9824173265020959\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 98, train_loss = 8.202813697978854, train_acc = 0.9831159757801584\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 99, train_loss = 8.124182537198067, train_acc = 0.9834653004191896\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 100, train_loss = 8.046735815703869, train_acc = 0.9835817419655333\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 101, train_loss = 7.970497559756041, train_acc = 0.983698183511877\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 102, train_loss = 7.895309392362833, train_acc = 0.9840475081509082\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 103, train_loss = 7.8212494272738695, train_acc = 0.9842803912435957\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 104, train_loss = 7.748305164277554, train_acc = 0.9843968327899395\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 105, train_loss = 7.6762913800776005, train_acc = 0.9846297158826269\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 106, train_loss = 7.60547037050128, train_acc = 0.9849790405216581\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 107, train_loss = 7.535610273480415, train_acc = 0.9848625989753144\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 108, train_loss = 7.466845752671361, train_acc = 0.9849790405216581\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 109, train_loss = 7.398887649178505, train_acc = 0.9852119236143456\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 110, train_loss = 7.331827646121383, train_acc = 0.9853283651606893\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 111, train_loss = 7.265582064166665, train_acc = 0.9853283651606893\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 112, train_loss = 7.199973402544856, train_acc = 0.985444806707033\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 113, train_loss = 7.135185241699219, train_acc = 0.9856776897997206\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 114, train_loss = 7.071374060586095, train_acc = 0.985910572892408\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 115, train_loss = 7.008665611967444, train_acc = 0.9860270144387517\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 116, train_loss = 6.946729585528374, train_acc = 0.9860270144387517\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 117, train_loss = 6.8857024274766445, train_acc = 0.9861434559850955\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 118, train_loss = 6.825189268216491, train_acc = 0.9861434559850955\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 119, train_loss = 6.765611506998539, train_acc = 0.9862598975314392\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 120, train_loss = 6.706923428922892, train_acc = 0.9862598975314392\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 121, train_loss = 6.648997189477086, train_acc = 0.9864927806241267\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 122, train_loss = 6.591869290918112, train_acc = 0.9866092221704704\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 123, train_loss = 6.535240659490228, train_acc = 0.9866092221704704\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 124, train_loss = 6.478514144197106, train_acc = 0.9867256637168141\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 125, train_loss = 6.422995809465647, train_acc = 0.9867256637168141\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 126, train_loss = 6.368543101474643, train_acc = 0.9868421052631579\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 127, train_loss = 6.314924374222755, train_acc = 0.9868421052631579\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 128, train_loss = 6.261996187269688, train_acc = 0.9869585468095017\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 129, train_loss = 6.209974739700556, train_acc = 0.9870749883558454\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 130, train_loss = 6.158622143790126, train_acc = 0.9870749883558454\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 131, train_loss = 6.108067100867629, train_acc = 0.9873078714485328\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 132, train_loss = 6.058106845244765, train_acc = 0.9877736376339078\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 133, train_loss = 6.008987216278911, train_acc = 0.9877736376339078\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 134, train_loss = 5.960398260504007, train_acc = 0.9877736376339078\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 135, train_loss = 5.912534222006798, train_acc = 0.9877736376339078\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 136, train_loss = 5.865358870476484, train_acc = 0.9877736376339078\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 137, train_loss = 5.818660529330373, train_acc = 0.9881229622729389\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 138, train_loss = 5.77257713675499, train_acc = 0.9882394038192828\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 139, train_loss = 5.727206241339445, train_acc = 0.9883558453656265\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 140, train_loss = 5.682133728638291, train_acc = 0.9883558453656265\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 141, train_loss = 5.637887151911855, train_acc = 0.9883558453656265\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 142, train_loss = 5.594071116298437, train_acc = 0.9884722869119702\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 143, train_loss = 5.55089795589447, train_acc = 0.9884722869119702\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 144, train_loss = 5.508240995928645, train_acc = 0.9884722869119702\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 145, train_loss = 5.4662925116717815, train_acc = 0.9884722869119702\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 146, train_loss = 5.4248594883829355, train_acc = 0.9884722869119702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 147, train_loss = 5.383862781338394, train_acc = 0.9884722869119702\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 148, train_loss = 5.343644511885941, train_acc = 0.9887051700046576\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 149, train_loss = 5.303723017685115, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 150, train_loss = 5.264465055428445, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 151, train_loss = 5.2256445568054914, train_acc = 0.9887051700046576\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 152, train_loss = 5.187379642389715, train_acc = 0.9888216115510013\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 153, train_loss = 5.149519206024706, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 154, train_loss = 5.112299353815615, train_acc = 0.9895202608290639\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 155, train_loss = 5.0754009848460555, train_acc = 0.9895202608290639\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 156, train_loss = 5.039023638702929, train_acc = 0.9895202608290639\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 157, train_loss = 5.00305833760649, train_acc = 0.9897531439217513\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 158, train_loss = 4.967523969709873, train_acc = 0.9897531439217513\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 159, train_loss = 4.9323822585865855, train_acc = 0.9897531439217513\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 160, train_loss = 4.89718824531883, train_acc = 0.989869585468095\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 161, train_loss = 4.863047901540995, train_acc = 0.989869585468095\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 162, train_loss = 4.829075181856751, train_acc = 0.989869585468095\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 163, train_loss = 4.795909316278994, train_acc = 0.989869585468095\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 164, train_loss = 4.762953046709299, train_acc = 0.9899860270144387\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 165, train_loss = 4.730478192679584, train_acc = 0.9899860270144387\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 166, train_loss = 4.698468598537147, train_acc = 0.9899860270144387\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 167, train_loss = 4.666812508367002, train_acc = 0.9902189101071263\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 168, train_loss = 4.635504747740924, train_acc = 0.9902189101071263\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 169, train_loss = 4.60467532556504, train_acc = 0.99033535165347\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 170, train_loss = 4.574024255387485, train_acc = 0.99033535165347\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 171, train_loss = 4.543891917914152, train_acc = 0.99033535165347\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 172, train_loss = 4.514062794856727, train_acc = 0.9904517931998137\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 173, train_loss = 4.484594310633838, train_acc = 0.9904517931998137\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 174, train_loss = 4.455434501171112, train_acc = 0.9904517931998137\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 175, train_loss = 4.4267019191756845, train_acc = 0.9905682347461574\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 176, train_loss = 4.3982591181993484, train_acc = 0.9905682347461574\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 177, train_loss = 4.370092992670834, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 178, train_loss = 4.342217780649662, train_acc = 0.9910340009315324\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 179, train_loss = 4.314732886850834, train_acc = 0.9911504424778761\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 180, train_loss = 4.287515208125114, train_acc = 0.9912668840242198\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 181, train_loss = 4.260618536733091, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 182, train_loss = 4.2339792447164655, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 183, train_loss = 4.207797414623201, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 184, train_loss = 4.181966796517372, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 185, train_loss = 4.156300861388445, train_acc = 0.9918490917559385\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 186, train_loss = 4.130939965136349, train_acc = 0.9918490917559385\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 187, train_loss = 4.10598087310791, train_acc = 0.9918490917559385\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 188, train_loss = 4.081172759644687, train_acc = 0.9918490917559385\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 189, train_loss = 4.056705509312451, train_acc = 0.9918490917559385\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 190, train_loss = 4.0324694802984595, train_acc = 0.9918490917559385\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 191, train_loss = 4.008589464239776, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 192, train_loss = 3.9848342379555106, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 193, train_loss = 3.961483663879335, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 194, train_loss = 3.938133758492768, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 195, train_loss = 3.915428228676319, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 196, train_loss = 3.8926668921485543, train_acc = 0.9921984163949698\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 197, train_loss = 3.8703070441260934, train_acc = 0.9921984163949698\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 198, train_loss = 3.8480522828176618, train_acc = 0.9921984163949698\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 199, train_loss = 3.826250482350588, train_acc = 0.9921984163949698\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 200, train_loss = 3.8046113764867187, train_acc = 0.9921984163949698\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 201, train_loss = 3.7830676175653934, train_acc = 0.9921984163949698\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 202, train_loss = 3.7619413202628493, train_acc = 0.9921984163949698\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 203, train_loss = 3.7409385852515697, train_acc = 0.9921984163949698\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 204, train_loss = 3.7202606052160263, train_acc = 0.9923148579413135\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 205, train_loss = 3.6995857805013657, train_acc = 0.9923148579413135\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 206, train_loss = 3.679293350316584, train_acc = 0.9923148579413135\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 207, train_loss = 3.659043195657432, train_acc = 0.9923148579413135\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 208, train_loss = 3.63908710796386, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 209, train_loss = 3.6192939365282655, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 210, train_loss = 3.5998484902083874, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 211, train_loss = 3.5804638960398734, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 212, train_loss = 3.5614471682347357, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 213, train_loss = 3.5424174168147147, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 214, train_loss = 3.5237301625311375, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 215, train_loss = 3.505108029115945, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 216, train_loss = 3.48686912516132, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 217, train_loss = 3.4686511433683336, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 218, train_loss = 3.4506067926995456, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 219, train_loss = 3.4328938047401607, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 220, train_loss = 3.4152337429113686, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 221, train_loss = 3.397941395174712, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 222, train_loss = 3.3806428746320307, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 223, train_loss = 3.363497842568904, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 224, train_loss = 3.346506168600172, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 225, train_loss = 3.3296235208399594, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 226, train_loss = 3.312885583844036, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 227, train_loss = 3.296387769281864, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 228, train_loss = 3.280184611212462, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 229, train_loss = 3.263933947775513, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 230, train_loss = 3.247998232487589, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 231, train_loss = 3.232124115806073, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 232, train_loss = 3.2164174378849566, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 233, train_loss = 3.201011956203729, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 234, train_loss = 3.1855058376677334, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 235, train_loss = 3.1702298149466515, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 236, train_loss = 3.155177269130945, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 237, train_loss = 3.1402202118188143, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 238, train_loss = 3.125338676851243, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 239, train_loss = 3.110701927449554, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 240, train_loss = 3.096147661563009, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 241, train_loss = 3.0818575262092054, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 242, train_loss = 3.0673485076986253, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 243, train_loss = 3.0533094885759056, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 244, train_loss = 3.0391769823618233, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 245, train_loss = 3.0253969370387495, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 246, train_loss = 3.0114591754972935, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 247, train_loss = 2.9978472031652927, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 248, train_loss = 2.984234509523958, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 249, train_loss = 2.970623647328466, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 250, train_loss = 2.9574132836423814, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 251, train_loss = 2.9441764377988875, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 252, train_loss = 2.9309913679026067, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 253, train_loss = 2.9180420748889446, train_acc = 0.9937121564974383\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 254, train_loss = 2.9051461392082274, train_acc = 0.9937121564974383\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 255, train_loss = 2.8923813700675964, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 256, train_loss = 2.879800701048225, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 257, train_loss = 2.867164039518684, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 258, train_loss = 2.854818391148001, train_acc = 0.9939450395901258\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 259, train_loss = 2.842369692865759, train_acc = 0.9939450395901258\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 260, train_loss = 2.8301779688335955, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 261, train_loss = 2.8181212418712676, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 262, train_loss = 2.8059466183185577, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 263, train_loss = 2.7940544285811484, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 264, train_loss = 2.7822031141258776, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 265, train_loss = 2.770461985375732, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 266, train_loss = 2.758825935423374, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 267, train_loss = 2.747354125138372, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 268, train_loss = 2.735849326942116, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 269, train_loss = 2.7245171018876135, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 270, train_loss = 2.7131876051425934, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 271, train_loss = 2.7020742148160934, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 272, train_loss = 2.6908102543093264, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 273, train_loss = 2.679894518107176, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 274, train_loss = 2.6688813068903983, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 275, train_loss = 2.6580393873155117, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 276, train_loss = 2.647308722138405, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 277, train_loss = 2.636584577616304, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 278, train_loss = 2.626080274581909, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 279, train_loss = 2.6155377528630197, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 280, train_loss = 2.6051865369081497, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 281, train_loss = 2.5949159427545965, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 282, train_loss = 2.584723675157875, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 283, train_loss = 2.5746785565279424, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 284, train_loss = 2.5645214491523802, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 285, train_loss = 2.5547541356645525, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 286, train_loss = 2.544970579445362, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 287, train_loss = 2.535201943013817, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 288, train_loss = 2.5255836942233145, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 289, train_loss = 2.515918450895697, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 290, train_loss = 2.5064176260493696, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 291, train_loss = 2.497131639625877, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 292, train_loss = 2.487865363713354, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 293, train_loss = 2.4786447226069868, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 294, train_loss = 2.4695576862432063, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 295, train_loss = 2.4603874646127224, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 296, train_loss = 2.451465582009405, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 297, train_loss = 2.4426269233226776, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 298, train_loss = 2.433702008333057, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 299, train_loss = 2.4249918162822723, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 300, train_loss = 2.4164656191132963, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 301, train_loss = 2.4078166619874537, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 302, train_loss = 2.3993401501793414, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 303, train_loss = 2.3910010282415897, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 304, train_loss = 2.382604679791257, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 305, train_loss = 2.3744925260543823, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 306, train_loss = 2.366243902593851, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 307, train_loss = 2.358221818925813, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 308, train_loss = 2.350180321605876, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 309, train_loss = 2.3421676866710186, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 310, train_loss = 2.334401636151597, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 311, train_loss = 2.3267163012642413, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 312, train_loss = 2.3188306901138276, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 313, train_loss = 2.3111670203506947, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 314, train_loss = 2.3037425850052387, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 315, train_loss = 2.2961180408019572, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 316, train_loss = 2.2887371070683002, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 317, train_loss = 2.2812638480681926, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 318, train_loss = 2.274150315672159, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 319, train_loss = 2.266822673380375, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 320, train_loss = 2.2595583486836404, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 321, train_loss = 2.2525543831288815, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 322, train_loss = 2.2456177684944123, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 323, train_loss = 2.238551375688985, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 324, train_loss = 2.2316149063408375, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 325, train_loss = 2.224705030443147, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 326, train_loss = 2.2181071403902024, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 327, train_loss = 2.2112513408064842, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 328, train_loss = 2.2047378309071064, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 329, train_loss = 2.197972481371835, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 330, train_loss = 2.19144319742918, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 331, train_loss = 2.185254406183958, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 332, train_loss = 2.1787018105387688, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 333, train_loss = 2.1722256131470203, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 334, train_loss = 2.1659940865356475, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 335, train_loss = 2.1597162410616875, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 336, train_loss = 2.1535884726326913, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 337, train_loss = 2.147579209180549, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 338, train_loss = 2.1414234179537743, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 339, train_loss = 2.135367900133133, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 340, train_loss = 2.129488792270422, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 341, train_loss = 2.1234269391279668, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 342, train_loss = 2.117814092664048, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 343, train_loss = 2.1117800001520663, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 344, train_loss = 2.1061349373776466, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 345, train_loss = 2.1003257285337895, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 346, train_loss = 2.0946841202676296, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 347, train_loss = 2.0891035746317357, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 348, train_loss = 2.08356882003136, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 349, train_loss = 2.077959140064195, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 350, train_loss = 2.072558082640171, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 351, train_loss = 2.0670829091686755, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 352, train_loss = 2.0617427304387093, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 353, train_loss = 2.0563701651990414, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 354, train_loss = 2.0511644706130028, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 355, train_loss = 2.0460721019189805, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 356, train_loss = 2.040751551510766, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 357, train_loss = 2.035698536783457, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 358, train_loss = 2.030483393697068, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 359, train_loss = 2.025570159079507, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 360, train_loss = 2.0204613606911153, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 361, train_loss = 2.0155154913663864, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 362, train_loss = 2.010540198534727, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 363, train_loss = 2.005756765604019, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 364, train_loss = 2.0009814624208957, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 365, train_loss = 1.9961657524108887, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 366, train_loss = 1.9912806849461049, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 367, train_loss = 1.9867245219647884, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 368, train_loss = 1.9820173445623368, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 369, train_loss = 1.977464858442545, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 370, train_loss = 1.9726268500089645, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 371, train_loss = 1.9681571919936687, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 372, train_loss = 1.96360332518816, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 373, train_loss = 1.9591284121852368, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 374, train_loss = 1.9546378094237298, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 375, train_loss = 1.9504001091700047, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 376, train_loss = 1.9458074506837875, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 377, train_loss = 1.9415039792656898, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 378, train_loss = 1.9371777896303684, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 379, train_loss = 1.9329004399478436, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 380, train_loss = 1.9286735381465405, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 381, train_loss = 1.9245239670854062, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 382, train_loss = 1.9201489861588925, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 383, train_loss = 1.9161688163876534, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 384, train_loss = 1.9118877165019512, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 385, train_loss = 1.9078534916043282, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 386, train_loss = 1.9038104999344796, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 387, train_loss = 1.8997120324056596, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 388, train_loss = 1.8959291155915707, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 389, train_loss = 1.8918496582191437, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 390, train_loss = 1.8878561481833458, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 391, train_loss = 1.8840246822219342, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 392, train_loss = 1.880138996988535, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 393, train_loss = 1.876354054780677, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 394, train_loss = 1.8725604030769318, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 395, train_loss = 1.8687156203668565, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 396, train_loss = 1.8650196405360475, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 397, train_loss = 1.8613221161067486, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 398, train_loss = 1.8576436750590801, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 399, train_loss = 1.8539697279920802, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 400, train_loss = 1.8503701040754095, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 401, train_loss = 1.8467859998345375, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 402, train_loss = 1.843120968551375, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 403, train_loss = 1.8396020866930485, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 404, train_loss = 1.8361548694083467, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 405, train_loss = 1.8326284512877464, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 406, train_loss = 1.8291482651839033, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 407, train_loss = 1.8258005207171664, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 408, train_loss = 1.8223145864903927, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 409, train_loss = 1.8189200857887045, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 410, train_loss = 1.8156687567243353, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 411, train_loss = 1.8122180377831683, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "11th- epoch: 412, train_loss = 1.808967687189579, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 413, train_loss = 1.805749130784534, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 414, train_loss = 1.8024047216167673, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 415, train_loss = 1.7992048921296373, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 416, train_loss = 1.7960018863668665, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 417, train_loss = 1.792831583530642, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 418, train_loss = 1.7897457120707259, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 419, train_loss = 1.786544058471918, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 420, train_loss = 1.7834013166138902, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 421, train_loss = 1.7802083095302805, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 422, train_loss = 1.7773478167364374, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 423, train_loss = 1.7741170339286327, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 424, train_loss = 1.771204655407928, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 425, train_loss = 1.768186368048191, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 426, train_loss = 1.765188274323009, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 427, train_loss = 1.7621261304011568, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 428, train_loss = 1.7593894911697134, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 429, train_loss = 1.7563693585107103, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 430, train_loss = 1.7534319795668125, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 431, train_loss = 1.7507981397211552, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 432, train_loss = 1.7478013597428799, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 433, train_loss = 1.744886918575503, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 434, train_loss = 1.742151511250995, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 435, train_loss = 1.7393589913845062, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 436, train_loss = 1.7365213222801685, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 437, train_loss = 1.733663129271008, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 438, train_loss = 1.7311422638595104, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 439, train_loss = 1.7282370390603319, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 440, train_loss = 1.725742682814598, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 441, train_loss = 1.723029320477508, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 442, train_loss = 1.7203735572984442, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 443, train_loss = 1.7175897136330605, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 444, train_loss = 1.71504709625151, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 445, train_loss = 1.7123576737940311, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 446, train_loss = 1.7098664343357086, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 447, train_loss = 1.7073150724172592, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 448, train_loss = 1.7047169394791126, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 449, train_loss = 1.7022484267363325, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 450, train_loss = 1.6996592743089423, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 451, train_loss = 1.6971823833882809, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 452, train_loss = 1.6947493106126785, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 453, train_loss = 1.6921583140501752, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 454, train_loss = 1.6898343985667452, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 455, train_loss = 1.6873726857593283, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 456, train_loss = 1.684932168573141, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 457, train_loss = 1.6825458022067323, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 458, train_loss = 1.6802435865392908, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 459, train_loss = 1.6777225682744756, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 460, train_loss = 1.6755971858510748, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 461, train_loss = 1.6730905087897554, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 462, train_loss = 1.6707747392356396, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 463, train_loss = 1.6684737814357504, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 464, train_loss = 1.6662740968167782, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 465, train_loss = 1.6640147119760513, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 466, train_loss = 1.6615731865167618, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 467, train_loss = 1.6594592332839966, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 468, train_loss = 1.6572607544949278, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 469, train_loss = 1.6550253182649612, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 470, train_loss = 1.652770597487688, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 471, train_loss = 1.6506284611532465, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 472, train_loss = 1.648362056701444, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 473, train_loss = 1.6462687278399244, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 474, train_loss = 1.64405359828379, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 475, train_loss = 1.6419182928511873, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 476, train_loss = 1.6398499757051468, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 477, train_loss = 1.6376184150576591, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 478, train_loss = 1.635708224028349, train_acc = 0.996040987424313\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 479, train_loss = 1.6334696946432814, train_acc = 0.996040987424313\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 480, train_loss = 1.6314475113758817, train_acc = 0.996040987424313\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 481, train_loss = 1.6295245116343722, train_acc = 0.996040987424313\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 482, train_loss = 1.6275712860515341, train_acc = 0.996040987424313\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 483, train_loss = 1.6254471614956856, train_acc = 0.996040987424313\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 484, train_loss = 1.623307199566625, train_acc = 0.996040987424313\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 485, train_loss = 1.6213535206625238, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 486, train_loss = 1.619549885392189, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 487, train_loss = 1.6174202164402232, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 488, train_loss = 1.615523780346848, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 489, train_loss = 1.6135656473925337, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 490, train_loss = 1.6116295544197783, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 491, train_loss = 1.6097406906774268, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 492, train_loss = 1.6079165613045916, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 493, train_loss = 1.6058314181864262, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 494, train_loss = 1.6040846966207027, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 495, train_loss = 1.6021216387161985, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 496, train_loss = 1.600255873054266, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 497, train_loss = 1.5983741556992754, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 498, train_loss = 1.5966667061438784, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "11th- epoch: 499, train_loss = 1.5947283307323232, train_acc = 0.9962738705170004\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████▋                                            | 11/30 [1:13:05<2:06:21, 399.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "12th- epoch: 0, train_loss = 275.19305634498596, train_acc = 0.44993013507219376\n",
      "test Acc 0.4925512104283054:\n",
      "12th- epoch: 1, train_loss = 212.12537503242493, train_acc = 0.49499301350721936\n",
      "test Acc 0.49767225325884545:\n",
      "12th- epoch: 2, train_loss = 167.6011598110199, train_acc = 0.5078015836050302\n",
      "test Acc 0.547951582867784:\n",
      "12th- epoch: 3, train_loss = 144.35126692056656, train_acc = 0.6442710759198882\n",
      "test Acc 0.6918063314711359:\n",
      "12th- epoch: 4, train_loss = 126.06156104803085, train_acc = 0.7074988355845365\n",
      "test Acc 0.728584729981378:\n",
      "12th- epoch: 5, train_loss = 110.45528665184975, train_acc = 0.7410340009315324\n",
      "test Acc 0.7686219739292365:\n",
      "12th- epoch: 6, train_loss = 97.10198417305946, train_acc = 0.7829529576152772\n",
      "test Acc 0.7946927374301676:\n",
      "12th- epoch: 7, train_loss = 85.65045496821404, train_acc = 0.810316721006055\n",
      "test Acc 0.8161080074487895:\n",
      "12th- epoch: 8, train_loss = 75.80023857951164, train_acc = 0.8366325104797392\n",
      "test Acc 0.8463687150837989:\n",
      "12th- epoch: 9, train_loss = 67.35483422875404, train_acc = 0.8637633907778295\n",
      "test Acc 0.8752327746741154:\n",
      "12th- epoch: 10, train_loss = 60.21135224401951, train_acc = 0.8823940381928272\n",
      "test Acc 0.8873370577281192:\n",
      "12th- epoch: 11, train_loss = 54.247819513082504, train_acc = 0.893921751280857\n",
      "test Acc 0.8952513966480447:\n",
      "12th- epoch: 12, train_loss = 49.30187977850437, train_acc = 0.906264555193293\n",
      "test Acc 0.9087523277467412:\n",
      "12th- epoch: 13, train_loss = 45.19218574464321, train_acc = 0.9166278528178854\n",
      "test Acc 0.9175977653631285:\n",
      "12th- epoch: 14, train_loss = 41.74849820137024, train_acc = 0.9290870982766651\n",
      "test Acc 0.9297020484171322:\n",
      "12th- epoch: 15, train_loss = 38.831152737140656, train_acc = 0.9371215649743828\n",
      "test Acc 0.9357541899441341:\n",
      "12th- epoch: 16, train_loss = 36.34192694723606, train_acc = 0.941895668374476\n",
      "test Acc 0.9385474860335196:\n",
      "12th- epoch: 17, train_loss = 34.20294051617384, train_acc = 0.9451560316721006\n",
      "test Acc 0.9408752327746741:\n",
      "12th- epoch: 18, train_loss = 32.34885589778423, train_acc = 0.9473684210526315\n",
      "test Acc 0.9441340782122905:\n",
      "12th- epoch: 19, train_loss = 30.73238842189312, train_acc = 0.9487657196087564\n",
      "test Acc 0.9464618249534451:\n",
      "12th- epoch: 20, train_loss = 29.314886271953583, train_acc = 0.9501630181648812\n",
      "test Acc 0.9478584729981379:\n",
      "12th- epoch: 21, train_loss = 28.062073685228825, train_acc = 0.9517931998136935\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 22, train_loss = 26.944984547793865, train_acc = 0.9536562645551933\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 23, train_loss = 25.941731676459312, train_acc = 0.9550535631113182\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 24, train_loss = 25.039002023637295, train_acc = 0.956450861667443\n",
      "test Acc 0.9506517690875232:\n",
      "12th- epoch: 25, train_loss = 24.221598222851753, train_acc = 0.9571495109455054\n",
      "test Acc 0.9511173184357542:\n",
      "12th- epoch: 26, train_loss = 23.47617869451642, train_acc = 0.9584303679552865\n",
      "test Acc 0.9515828677839852:\n",
      "12th- epoch: 27, train_loss = 22.791547380387783, train_acc = 0.95947834187238\n",
      "test Acc 0.952513966480447:\n",
      "12th- epoch: 28, train_loss = 22.160493105649948, train_acc = 0.9607591988821611\n",
      "test Acc 0.9539106145251397:\n",
      "12th- epoch: 29, train_loss = 21.5754459425807, train_acc = 0.9614578481602236\n",
      "test Acc 0.9548417132216015:\n",
      "12th- epoch: 30, train_loss = 21.03055226430297, train_acc = 0.9622729389846297\n",
      "test Acc 0.9548417132216015:\n",
      "12th- epoch: 31, train_loss = 20.520096614956856, train_acc = 0.9630880298090359\n",
      "test Acc 0.9548417132216015:\n",
      "12th- epoch: 32, train_loss = 20.04067748039961, train_acc = 0.9635537959944108\n",
      "test Acc 0.9548417132216015:\n",
      "12th- epoch: 33, train_loss = 19.588928133249283, train_acc = 0.9637866790870983\n",
      "test Acc 0.9557728119180633:\n",
      "12th- epoch: 34, train_loss = 19.162306506186724, train_acc = 0.9642524452724732\n",
      "test Acc 0.9557728119180633:\n",
      "12th- epoch: 35, train_loss = 18.758595030754805, train_acc = 0.9648346530041919\n",
      "test Acc 0.9567039106145251:\n",
      "12th- epoch: 36, train_loss = 18.375072214752436, train_acc = 0.9653004191895669\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 37, train_loss = 18.009785290807486, train_acc = 0.9658826269212856\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 38, train_loss = 17.66118211299181, train_acc = 0.9664648346530041\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 39, train_loss = 17.32740431278944, train_acc = 0.9669306008383791\n",
      "test Acc 0.9585661080074488:\n",
      "12th- epoch: 40, train_loss = 17.007049702107906, train_acc = 0.9678621332091291\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 41, train_loss = 16.699405774474144, train_acc = 0.9684443409408477\n",
      "test Acc 0.9608938547486033:\n",
      "12th- epoch: 42, train_loss = 16.404155164957047, train_acc = 0.9686772240335352\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 43, train_loss = 16.120350893586874, train_acc = 0.9692594317652539\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 44, train_loss = 15.846914313733578, train_acc = 0.97007452258966\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 45, train_loss = 15.58329439535737, train_acc = 0.9707731718677224\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 46, train_loss = 15.328683190047741, train_acc = 0.9712389380530974\n",
      "test Acc 0.962756052141527:\n",
      "12th- epoch: 47, train_loss = 15.082569357007742, train_acc = 0.9717047042384723\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 48, train_loss = 14.844466619193554, train_acc = 0.9721704704238472\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 49, train_loss = 14.614091221243143, train_acc = 0.972286911970191\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 50, train_loss = 14.391138277947903, train_acc = 0.9725197950628784\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 51, train_loss = 14.175269588828087, train_acc = 0.9731020027945971\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 52, train_loss = 13.965907311066985, train_acc = 0.9732184443409408\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 53, train_loss = 13.762885311618447, train_acc = 0.9733348858872846\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 54, train_loss = 13.565747184678912, train_acc = 0.9734513274336283\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 55, train_loss = 13.374238731339574, train_acc = 0.9736842105263158\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 56, train_loss = 13.18808495439589, train_acc = 0.9738006520726595\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 57, train_loss = 13.006959296762943, train_acc = 0.9738006520726595\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 58, train_loss = 12.831068431958556, train_acc = 0.9742664182580345\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 59, train_loss = 12.660046473145485, train_acc = 0.9744993013507219\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 60, train_loss = 12.493604592978954, train_acc = 0.9748486259897532\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 61, train_loss = 12.331540744751692, train_acc = 0.9750815090824406\n",
      "test Acc 0.9674115456238361:\n",
      "12th- epoch: 62, train_loss = 12.173603244125843, train_acc = 0.9755472752678156\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 63, train_loss = 12.018792070448399, train_acc = 0.9760130414531905\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 64, train_loss = 11.867706473916769, train_acc = 0.976245924545878\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 65, train_loss = 11.720627341419458, train_acc = 0.9764788076385654\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 66, train_loss = 11.577420573681593, train_acc = 0.9764788076385654\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 67, train_loss = 11.437822248786688, train_acc = 0.9767116907312529\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 68, train_loss = 11.301439490169287, train_acc = 0.9769445738239404\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 69, train_loss = 11.168185826390982, train_acc = 0.9772938984629715\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 70, train_loss = 11.037970092147589, train_acc = 0.9774103400093154\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 71, train_loss = 10.910671941936016, train_acc = 0.9777596646483465\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 72, train_loss = 10.786004807800055, train_acc = 0.977992547741034\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 73, train_loss = 10.663862392306328, train_acc = 0.9781089892873778\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 74, train_loss = 10.544210705906153, train_acc = 0.9782254308337215\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 75, train_loss = 10.426963742822409, train_acc = 0.9784583139264089\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 76, train_loss = 10.311869949102402, train_acc = 0.9784583139264089\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 77, train_loss = 10.198931500315666, train_acc = 0.9784583139264089\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 78, train_loss = 10.088102726265788, train_acc = 0.9785747554727526\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 79, train_loss = 9.979314498603344, train_acc = 0.9790405216581276\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 80, train_loss = 9.872452706098557, train_acc = 0.9791569632044713\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 81, train_loss = 9.766954200342298, train_acc = 0.9791569632044713\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 82, train_loss = 9.663207694888115, train_acc = 0.9793898462971589\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 83, train_loss = 9.561358895152807, train_acc = 0.9795062878435026\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 84, train_loss = 9.461297990754247, train_acc = 0.9795062878435026\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 85, train_loss = 9.362891741096973, train_acc = 0.9796227293898463\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 86, train_loss = 9.266281329095364, train_acc = 0.9796227293898463\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 87, train_loss = 9.171068096533418, train_acc = 0.9800884955752213\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 88, train_loss = 9.07746284455061, train_acc = 0.980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 89, train_loss = 8.985286565497518, train_acc = 0.9804378202142524\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 90, train_loss = 8.894890699535608, train_acc = 0.9805542617605962\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 91, train_loss = 8.80583400465548, train_acc = 0.9805542617605962\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 92, train_loss = 8.71825796365738, train_acc = 0.9807871448532837\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 93, train_loss = 8.631958359852433, train_acc = 0.9810200279459711\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 94, train_loss = 8.547074306756258, train_acc = 0.9813693525850024\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 95, train_loss = 8.463475164026022, train_acc = 0.9814857941313461\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 96, train_loss = 8.381267074495554, train_acc = 0.9816022356776898\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 97, train_loss = 8.300093987956643, train_acc = 0.9817186772240335\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 98, train_loss = 8.220412688329816, train_acc = 0.981951560316721\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 99, train_loss = 8.141720900312066, train_acc = 0.9821844434094085\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 100, train_loss = 8.064289957284927, train_acc = 0.9823008849557522\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 101, train_loss = 7.988030541688204, train_acc = 0.9824173265020959\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 102, train_loss = 7.912586929276586, train_acc = 0.9826502095947834\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 103, train_loss = 7.838366391137242, train_acc = 0.9826502095947834\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 104, train_loss = 7.765203606337309, train_acc = 0.9826502095947834\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 105, train_loss = 7.693052215501666, train_acc = 0.9827666511411272\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 106, train_loss = 7.621945695951581, train_acc = 0.9828830926874709\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 107, train_loss = 7.5518980994820595, train_acc = 0.9831159757801584\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 108, train_loss = 7.48275538906455, train_acc = 0.9831159757801584\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 109, train_loss = 7.4147418066859245, train_acc = 0.9834653004191896\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 110, train_loss = 7.347639847546816, train_acc = 0.9835817419655333\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 111, train_loss = 7.281443852931261, train_acc = 0.984163949697252\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 112, train_loss = 7.216259676963091, train_acc = 0.9843968327899395\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 113, train_loss = 7.151779215782881, train_acc = 0.9846297158826269\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 114, train_loss = 7.0882894564419985, train_acc = 0.9847461574289706\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 115, train_loss = 7.025679789483547, train_acc = 0.9846297158826269\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 116, train_loss = 6.963897418230772, train_acc = 0.9848625989753144\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 117, train_loss = 6.902963412925601, train_acc = 0.9853283651606893\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 118, train_loss = 6.8428358770906925, train_acc = 0.985444806707033\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 119, train_loss = 6.783484015613794, train_acc = 0.9855612482533768\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 120, train_loss = 6.724944790825248, train_acc = 0.9856776897997206\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 121, train_loss = 6.667077217251062, train_acc = 0.9860270144387517\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 122, train_loss = 6.6101662684232, train_acc = 0.9862598975314392\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 123, train_loss = 6.5538496021181345, train_acc = 0.9862598975314392\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 124, train_loss = 6.498337276279926, train_acc = 0.986376339077783\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 125, train_loss = 6.4435808546841145, train_acc = 0.9866092221704704\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 126, train_loss = 6.389590732753277, train_acc = 0.9867256637168141\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 127, train_loss = 6.336257077753544, train_acc = 0.9871914299021891\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 128, train_loss = 6.283584248274565, train_acc = 0.9874243129948765\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 129, train_loss = 6.231818841770291, train_acc = 0.9874243129948765\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 130, train_loss = 6.180454785004258, train_acc = 0.9875407545412203\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 131, train_loss = 6.129969032481313, train_acc = 0.9875407545412203\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 132, train_loss = 6.0799509808421135, train_acc = 0.9876571960875641\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 133, train_loss = 6.030853001400828, train_acc = 0.9880065207265952\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 134, train_loss = 5.982102504000068, train_acc = 0.9880065207265952\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 135, train_loss = 5.934091918170452, train_acc = 0.9882394038192828\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 136, train_loss = 5.886581689119339, train_acc = 0.9882394038192828\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 137, train_loss = 5.839874247089028, train_acc = 0.9882394038192828\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 138, train_loss = 5.7936368100345135, train_acc = 0.9883558453656265\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 139, train_loss = 5.748036090284586, train_acc = 0.9883558453656265\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 140, train_loss = 5.703003650531173, train_acc = 0.9883558453656265\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 141, train_loss = 5.658611292019486, train_acc = 0.9885887284583139\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 142, train_loss = 5.614684784784913, train_acc = 0.9885887284583139\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 143, train_loss = 5.571279045194387, train_acc = 0.9885887284583139\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 144, train_loss = 5.528450099751353, train_acc = 0.9885887284583139\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 145, train_loss = 5.486114716157317, train_acc = 0.9887051700046576\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 146, train_loss = 5.444366855546832, train_acc = 0.9888216115510013\n",
      "test Acc 0.973463687150838:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 147, train_loss = 5.40314707159996, train_acc = 0.9889380530973452\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 148, train_loss = 5.362378327175975, train_acc = 0.9889380530973452\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 149, train_loss = 5.3222350757569075, train_acc = 0.9890544946436889\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 150, train_loss = 5.282610982656479, train_acc = 0.9890544946436889\n",
      "test Acc 0.9743947858472998:\n",
      "12th- epoch: 151, train_loss = 5.24352197535336, train_acc = 0.9892873777363763\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 152, train_loss = 5.20490512996912, train_acc = 0.9892873777363763\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 153, train_loss = 5.166759762912989, train_acc = 0.9892873777363763\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 154, train_loss = 5.129234688356519, train_acc = 0.9895202608290639\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 155, train_loss = 5.09203902259469, train_acc = 0.9896367023754076\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 156, train_loss = 5.055278953164816, train_acc = 0.9897531439217513\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 157, train_loss = 5.018931729719043, train_acc = 0.9897531439217513\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 158, train_loss = 4.9830394219607115, train_acc = 0.9897531439217513\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 159, train_loss = 4.947677304968238, train_acc = 0.9899860270144387\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 160, train_loss = 4.912567559629679, train_acc = 0.9899860270144387\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 161, train_loss = 4.878072088584304, train_acc = 0.9902189101071263\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 162, train_loss = 4.844052861444652, train_acc = 0.9902189101071263\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 163, train_loss = 4.810334496200085, train_acc = 0.99033535165347\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 164, train_loss = 4.777066805399954, train_acc = 0.99033535165347\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 165, train_loss = 4.744172065518796, train_acc = 0.9904517931998137\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 166, train_loss = 4.711557934992015, train_acc = 0.9905682347461574\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 167, train_loss = 4.679291364736855, train_acc = 0.9905682347461574\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 168, train_loss = 4.647620039060712, train_acc = 0.9906846762925011\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 169, train_loss = 4.616248550824821, train_acc = 0.990801117838845\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 170, train_loss = 4.585182089358568, train_acc = 0.9909175593851887\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 171, train_loss = 4.554509318433702, train_acc = 0.9909175593851887\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 172, train_loss = 4.524512228555977, train_acc = 0.9909175593851887\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 173, train_loss = 4.4945122031494975, train_acc = 0.9909175593851887\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 174, train_loss = 4.465093363076448, train_acc = 0.9910340009315324\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 175, train_loss = 4.43605347815901, train_acc = 0.9912668840242198\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 176, train_loss = 4.407140449620783, train_acc = 0.9912668840242198\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 177, train_loss = 4.378761371597648, train_acc = 0.9912668840242198\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 178, train_loss = 4.350595588795841, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 179, train_loss = 4.322785873897374, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 180, train_loss = 4.295429694466293, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 181, train_loss = 4.268488527275622, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 182, train_loss = 4.2416469706222415, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 183, train_loss = 4.215131802484393, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 184, train_loss = 4.189071640372276, train_acc = 0.9913833255705635\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 185, train_loss = 4.163279391825199, train_acc = 0.9914997671169073\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 186, train_loss = 4.137719373218715, train_acc = 0.9917326502095948\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 187, train_loss = 4.112516865134239, train_acc = 0.9917326502095948\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 188, train_loss = 4.087515681050718, train_acc = 0.9917326502095948\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 189, train_loss = 4.062854043208063, train_acc = 0.9917326502095948\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 190, train_loss = 4.038446425460279, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 191, train_loss = 4.014041676186025, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 192, train_loss = 3.9900713711977005, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 193, train_loss = 3.9662893461063504, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 194, train_loss = 3.942704437300563, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 195, train_loss = 3.9194886460900307, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 196, train_loss = 3.896323112770915, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 197, train_loss = 3.873517139814794, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 198, train_loss = 3.850784027017653, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 199, train_loss = 3.8282734090462327, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 200, train_loss = 3.8059289632365108, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 201, train_loss = 3.784161640331149, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 202, train_loss = 3.7627532994374633, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 203, train_loss = 3.7415183493867517, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 204, train_loss = 3.7205783501267433, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 205, train_loss = 3.6997891291975975, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 206, train_loss = 3.679264258593321, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 207, train_loss = 3.6589239798486233, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 208, train_loss = 3.6388308303430676, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 209, train_loss = 3.618912217207253, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 210, train_loss = 3.5992855271324515, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 211, train_loss = 3.579615142196417, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 212, train_loss = 3.560405650176108, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 213, train_loss = 3.5412800312042236, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 214, train_loss = 3.52230529114604, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 215, train_loss = 3.5033738911151886, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 216, train_loss = 3.4848109306767583, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 217, train_loss = 3.4664321122691035, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 218, train_loss = 3.448285627178848, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 219, train_loss = 3.430205383338034, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 220, train_loss = 3.412374979816377, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 221, train_loss = 3.394717011600733, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 222, train_loss = 3.3772096461616457, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 223, train_loss = 3.359829338733107, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 224, train_loss = 3.342629483435303, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 225, train_loss = 3.325594605412334, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 226, train_loss = 3.30877003679052, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 227, train_loss = 3.2921198778785765, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 228, train_loss = 3.275496346410364, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 229, train_loss = 3.2590293078683317, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 230, train_loss = 3.2429433190263808, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 231, train_loss = 3.2266831286251545, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 232, train_loss = 3.2107985108159482, train_acc = 0.9935957149510946\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 233, train_loss = 3.1949061304330826, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 234, train_loss = 3.1791815981268883, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 235, train_loss = 3.163595533464104, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 236, train_loss = 3.1481223925948143, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 237, train_loss = 3.132871425244957, train_acc = 0.9937121564974383\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 238, train_loss = 3.1176418997347355, train_acc = 0.993828598043782\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 239, train_loss = 3.1026513502001762, train_acc = 0.993828598043782\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 240, train_loss = 3.08776897797361, train_acc = 0.993828598043782\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 241, train_loss = 3.072944627609104, train_acc = 0.993828598043782\n",
      "test Acc 0.978584729981378:\n",
      "12th- epoch: 242, train_loss = 3.0583590543828905, train_acc = 0.993828598043782\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 243, train_loss = 3.0437810770235956, train_acc = 0.993828598043782\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 244, train_loss = 3.0294432840310037, train_acc = 0.993828598043782\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 245, train_loss = 3.015172030776739, train_acc = 0.993828598043782\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 246, train_loss = 3.0012545324862003, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 247, train_loss = 2.9870349280536175, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 248, train_loss = 2.973115453030914, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 249, train_loss = 2.9590911925770342, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 250, train_loss = 2.94552860641852, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 251, train_loss = 2.9319502152502537, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 252, train_loss = 2.9186660535633564, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 253, train_loss = 2.905286824796349, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 254, train_loss = 2.892332124058157, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 255, train_loss = 2.878986220806837, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 256, train_loss = 2.8662969418801367, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 257, train_loss = 2.8531948388554156, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 258, train_loss = 2.840462210122496, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 259, train_loss = 2.828031599521637, train_acc = 0.9941779226828132\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 260, train_loss = 2.815324356313795, train_acc = 0.9941779226828132\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 261, train_loss = 2.802956494037062, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 262, train_loss = 2.7908187569119036, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 263, train_loss = 2.7784711620770395, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 264, train_loss = 2.766528653446585, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 265, train_loss = 2.7545770122669637, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 266, train_loss = 2.74273564806208, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 267, train_loss = 2.7308883308432996, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 268, train_loss = 2.7194613651372492, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 269, train_loss = 2.707625979091972, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 270, train_loss = 2.696301265154034, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 271, train_loss = 2.6850212872959673, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 272, train_loss = 2.673693740274757, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 273, train_loss = 2.66249710181728, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 274, train_loss = 2.6515339948236942, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 275, train_loss = 2.6405194723047316, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 276, train_loss = 2.6297376342117786, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 277, train_loss = 2.6188742867670953, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 278, train_loss = 2.608330340590328, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 279, train_loss = 2.5976724959909916, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 280, train_loss = 2.5873325332067907, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 281, train_loss = 2.57687875861302, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 282, train_loss = 2.5666018202900887, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 283, train_loss = 2.5563905746676028, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 284, train_loss = 2.5464752577245235, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 285, train_loss = 2.5361859016120434, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 286, train_loss = 2.5264774574898183, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 287, train_loss = 2.516707224305719, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 288, train_loss = 2.5068669891916215, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 289, train_loss = 2.4974775300361216, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 290, train_loss = 2.48779284209013, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 291, train_loss = 2.4784482517279685, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 292, train_loss = 2.469132874161005, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 293, train_loss = 2.459865603595972, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 294, train_loss = 2.4506844407878816, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 295, train_loss = 2.4416164248250425, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 296, train_loss = 2.432730948086828, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 297, train_loss = 2.4237310052849352, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 298, train_loss = 2.4147574664093554, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 299, train_loss = 2.4060840965248644, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 300, train_loss = 2.3974885679781437, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 301, train_loss = 2.3890280262567103, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 302, train_loss = 2.380380779504776, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 303, train_loss = 2.371967562707141, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 304, train_loss = 2.3637216724455357, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 305, train_loss = 2.3553466114681214, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 306, train_loss = 2.3472574029583484, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 307, train_loss = 2.3390998530667275, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 308, train_loss = 2.331088909180835, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 309, train_loss = 2.3232410438358784, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 310, train_loss = 2.3153618860524148, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 311, train_loss = 2.3076016928534955, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 312, train_loss = 2.2998914557974786, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 313, train_loss = 2.2923418395221233, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 314, train_loss = 2.2847132843453437, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 315, train_loss = 2.277281492948532, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 316, train_loss = 2.2699028365314007, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 317, train_loss = 2.262530531734228, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 318, train_loss = 2.2552903194446117, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 319, train_loss = 2.248118123738095, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 320, train_loss = 2.2408564500510693, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 321, train_loss = 2.2338205550331622, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 322, train_loss = 2.2268747638445348, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 323, train_loss = 2.2199433769565076, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 324, train_loss = 2.213081060675904, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 325, train_loss = 2.2064419996459037, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 326, train_loss = 2.1997604221105576, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 327, train_loss = 2.193030461668968, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 328, train_loss = 2.1864119071979076, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 329, train_loss = 2.1799456339795142, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 330, train_loss = 2.173429451882839, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 331, train_loss = 2.166997641324997, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 332, train_loss = 2.160855485824868, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 333, train_loss = 2.154655472608283, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 334, train_loss = 2.148240643320605, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 335, train_loss = 2.142121096374467, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 336, train_loss = 2.1360690009314567, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 337, train_loss = 2.130090134916827, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 338, train_loss = 2.123954351991415, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 339, train_loss = 2.118055611848831, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 340, train_loss = 2.112166826846078, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 341, train_loss = 2.1063049223739654, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 342, train_loss = 2.1006733018439263, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 343, train_loss = 2.094895977526903, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 344, train_loss = 2.089133760659024, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 345, train_loss = 2.0836104564368725, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 346, train_loss = 2.0780039702076465, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 347, train_loss = 2.07249528542161, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "12th- epoch: 348, train_loss = 2.0672692742664367, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 349, train_loss = 2.0616670474410057, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 350, train_loss = 2.0562885876279324, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 351, train_loss = 2.051310357870534, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 352, train_loss = 2.045738971559331, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 353, train_loss = 2.0405922532081604, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 354, train_loss = 2.035515819909051, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 355, train_loss = 2.0301900368649513, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 356, train_loss = 2.025270176352933, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 357, train_loss = 2.0201841990929097, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 358, train_loss = 2.015138603746891, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 359, train_loss = 2.0103499814867973, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 360, train_loss = 2.0052625313401222, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 361, train_loss = 2.0003811344504356, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 362, train_loss = 1.9957984138745815, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 363, train_loss = 1.9908656887710094, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 364, train_loss = 1.9862174328882247, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 365, train_loss = 1.981400741962716, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 366, train_loss = 1.9768310897052288, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 367, train_loss = 1.9721694972831756, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 368, train_loss = 1.9675109274685383, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 369, train_loss = 1.9633093103766441, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 370, train_loss = 1.9586058172862977, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 371, train_loss = 1.9540875505190343, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 372, train_loss = 1.9498659744858742, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 373, train_loss = 1.9452550895512104, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 374, train_loss = 1.9409359868150204, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 375, train_loss = 1.9367722447495908, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 376, train_loss = 1.9323733113706112, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 377, train_loss = 1.9281395028810948, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 378, train_loss = 1.9239996473770589, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 379, train_loss = 1.9196692791301757, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 380, train_loss = 1.9156015019398183, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 381, train_loss = 1.911473710089922, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 382, train_loss = 1.90743421879597, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 383, train_loss = 1.9032662026584148, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 384, train_loss = 1.8995069861412048, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 385, train_loss = 1.895360579015687, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 386, train_loss = 1.8914492118638009, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 387, train_loss = 1.8874487963039428, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 388, train_loss = 1.883554618805647, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 389, train_loss = 1.8796549327671528, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 390, train_loss = 1.8760032219579443, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 391, train_loss = 1.8721256417920813, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 392, train_loss = 1.8684860058128834, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 393, train_loss = 1.8645744113018736, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 394, train_loss = 1.8608926385641098, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 395, train_loss = 1.8573138788342476, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 396, train_loss = 1.8535675642779097, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 397, train_loss = 1.8500532222678885, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 398, train_loss = 1.8463453935692087, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 399, train_loss = 1.8427775390446186, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 400, train_loss = 1.8393680788576603, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 401, train_loss = 1.8357258414616808, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 402, train_loss = 1.832363922148943, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 403, train_loss = 1.8289819372585043, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 404, train_loss = 1.8253632547566667, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 405, train_loss = 1.8220364475855604, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 406, train_loss = 1.8187368623912334, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 407, train_loss = 1.8152105460176244, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 408, train_loss = 1.8121662586927414, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 409, train_loss = 1.808650309802033, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 410, train_loss = 1.8053444400429726, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 411, train_loss = 1.8023036271333694, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 412, train_loss = 1.7988367067882791, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 413, train_loss = 1.7959032891085371, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 414, train_loss = 1.792486454010941, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 415, train_loss = 1.7893304042518139, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 416, train_loss = 1.786337455152534, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 417, train_loss = 1.7831926184007898, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 418, train_loss = 1.7801633341005072, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 419, train_loss = 1.7768936617067084, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 420, train_loss = 1.7740252601215616, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 421, train_loss = 1.7707628508796915, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 422, train_loss = 1.767734450637363, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 423, train_loss = 1.764797680079937, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 424, train_loss = 1.7619692236185074, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 425, train_loss = 1.7592123709619045, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 426, train_loss = 1.7560041038086638, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 427, train_loss = 1.7534612888703123, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 428, train_loss = 1.7503007786581293, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 429, train_loss = 1.7477021490922198, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 430, train_loss = 1.744697039364837, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 431, train_loss = 1.742064987658523, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 432, train_loss = 1.7390528371324763, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 433, train_loss = 1.736557960510254, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 434, train_loss = 1.733600297360681, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 435, train_loss = 1.7308340519666672, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 436, train_loss = 1.7283934032311663, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 437, train_loss = 1.725329827517271, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 438, train_loss = 1.722910845070146, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 439, train_loss = 1.7201395742595196, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 440, train_loss = 1.717593147070147, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 441, train_loss = 1.7148210579762235, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 442, train_loss = 1.7124445425579324, train_acc = 0.9958081043316255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 443, train_loss = 1.7096896147122607, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 444, train_loss = 1.7072704223683104, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 445, train_loss = 1.7045663272729144, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 446, train_loss = 1.7022033309331164, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 447, train_loss = 1.699385785846971, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 448, train_loss = 1.6971701147267595, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 449, train_loss = 1.694541297852993, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 450, train_loss = 1.6922618759563193, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 451, train_loss = 1.689665012061596, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 452, train_loss = 1.6874122904846445, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 453, train_loss = 1.6848563874373212, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 454, train_loss = 1.6826543224742636, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 455, train_loss = 1.680038321763277, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 456, train_loss = 1.6777319485554472, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 457, train_loss = 1.6753163760295138, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 458, train_loss = 1.673079909174703, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 459, train_loss = 1.670761970221065, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 460, train_loss = 1.6685167414834723, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 461, train_loss = 1.6662634214153513, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 462, train_loss = 1.663816075772047, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 463, train_loss = 1.661759089678526, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 464, train_loss = 1.6593521945178509, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 465, train_loss = 1.657269818126224, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 466, train_loss = 1.6549224257469177, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 467, train_loss = 1.6528836376965046, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 468, train_loss = 1.650524759083055, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 469, train_loss = 1.6485485695302486, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 470, train_loss = 1.6462041214108467, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 471, train_loss = 1.6441724374890327, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 472, train_loss = 1.6418823475250974, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 473, train_loss = 1.639665258466266, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 474, train_loss = 1.6378959032008424, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 475, train_loss = 1.6356745647499338, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 476, train_loss = 1.6337770223617554, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 477, train_loss = 1.631555506377481, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 478, train_loss = 1.6295038163661957, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 479, train_loss = 1.6275085235247388, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 480, train_loss = 1.6255004964768887, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 481, train_loss = 1.6235297819366679, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 482, train_loss = 1.6214771257946268, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 483, train_loss = 1.6195172555744648, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 484, train_loss = 1.6175193414092064, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 485, train_loss = 1.6155866099288687, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 486, train_loss = 1.6136140873422846, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 487, train_loss = 1.6117290271213278, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 488, train_loss = 1.6097941560437903, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 489, train_loss = 1.6079062260687351, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 490, train_loss = 1.6059483723947778, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 491, train_loss = 1.6040995828807354, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 492, train_loss = 1.6022762283682823, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 493, train_loss = 1.6003589878091589, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 494, train_loss = 1.5984881296753883, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 495, train_loss = 1.5966772573301569, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 496, train_loss = 1.5947996191680431, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 497, train_loss = 1.5930322495987639, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 498, train_loss = 1.5912069206824526, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 499, train_loss = 1.5894371829926968, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████                                          | 12/30 [1:19:45<1:59:49, 399.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "13th- epoch: 0, train_loss = 274.25511491298676, train_acc = 0.40742897065673034\n",
      "test Acc 0.4864990689013035:\n",
      "13th- epoch: 1, train_loss = 208.6076296567917, train_acc = 0.49382859804378204\n",
      "test Acc 0.5009310986964618:\n",
      "13th- epoch: 2, train_loss = 166.506505548954, train_acc = 0.5243362831858407\n",
      "test Acc 0.5609869646182495:\n",
      "13th- epoch: 3, train_loss = 142.98115706443787, train_acc = 0.6577782952957615\n",
      "test Acc 0.7141527001862198:\n",
      "13th- epoch: 4, train_loss = 123.92756706476212, train_acc = 0.7234513274336283\n",
      "test Acc 0.7392923649906891:\n",
      "13th- epoch: 5, train_loss = 107.7894651889801, train_acc = 0.7588495575221239\n",
      "test Acc 0.7807262569832403:\n",
      "13th- epoch: 6, train_loss = 94.47909823060036, train_acc = 0.7987890079180252\n",
      "test Acc 0.8044692737430168:\n",
      "13th- epoch: 7, train_loss = 83.49101370573044, train_acc = 0.8173032137866791\n",
      "test Acc 0.8207635009310987:\n",
      "13th- epoch: 8, train_loss = 74.24078771471977, train_acc = 0.8418723800652073\n",
      "test Acc 0.8566108007448789:\n",
      "13th- epoch: 9, train_loss = 66.39622193574905, train_acc = 0.8692361434559851\n",
      "test Acc 0.8798882681564246:\n",
      "13th- epoch: 10, train_loss = 59.76474553346634, train_acc = 0.8851886353050769\n",
      "test Acc 0.888268156424581:\n",
      "13th- epoch: 11, train_loss = 54.17559386789799, train_acc = 0.8928737773637634\n",
      "test Acc 0.8994413407821229:\n",
      "13th- epoch: 12, train_loss = 49.477723717689514, train_acc = 0.902771308802981\n",
      "test Acc 0.909217877094972:\n",
      "13th- epoch: 13, train_loss = 45.528687819838524, train_acc = 0.9193060083837913\n",
      "test Acc 0.9273743016759777:\n",
      "13th- epoch: 14, train_loss = 42.19238333404064, train_acc = 0.9288542151839776\n",
      "test Acc 0.9334264432029795:\n",
      "13th- epoch: 15, train_loss = 39.35518969595432, train_acc = 0.9347927340475082\n",
      "test Acc 0.9376163873370578:\n",
      "13th- epoch: 16, train_loss = 36.92454996705055, train_acc = 0.9374708896134141\n",
      "test Acc 0.9413407821229051:\n",
      "13th- epoch: 17, train_loss = 34.821812972426414, train_acc = 0.9435258500232883\n",
      "test Acc 0.9418063314711359:\n",
      "13th- epoch: 18, train_loss = 32.99144995957613, train_acc = 0.9459711224965067\n",
      "test Acc 0.9427374301675978:\n",
      "13th- epoch: 19, train_loss = 31.38825224339962, train_acc = 0.9482999534233815\n",
      "test Acc 0.9459962756052142:\n",
      "13th- epoch: 20, train_loss = 29.97325147688389, train_acc = 0.9496972519795063\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 21, train_loss = 28.7151912227273, train_acc = 0.9506287843502562\n",
      "test Acc 0.9473929236499069:\n",
      "13th- epoch: 22, train_loss = 27.588389225304127, train_acc = 0.952026082906381\n",
      "test Acc 0.9492551210428305:\n",
      "13th- epoch: 23, train_loss = 26.572809666395187, train_acc = 0.9536562645551933\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 24, train_loss = 25.650744318962097, train_acc = 0.9547042384722869\n",
      "test Acc 0.9515828677839852:\n",
      "13th- epoch: 25, train_loss = 24.808523885905743, train_acc = 0.9562179785747554\n",
      "test Acc 0.9515828677839852:\n",
      "13th- epoch: 26, train_loss = 24.033732265233994, train_acc = 0.9573823940381928\n",
      "test Acc 0.952513966480447:\n",
      "13th- epoch: 27, train_loss = 23.316315542906523, train_acc = 0.9583139264089428\n",
      "test Acc 0.9534450651769087:\n",
      "13th- epoch: 28, train_loss = 22.6512181609869, train_acc = 0.9590125756870052\n",
      "test Acc 0.9553072625698324:\n",
      "13th- epoch: 29, train_loss = 22.03210173547268, train_acc = 0.959944108057755\n",
      "test Acc 0.9562383612662942:\n",
      "13th- epoch: 30, train_loss = 21.453690361231565, train_acc = 0.9605263157894737\n",
      "test Acc 0.9567039106145251:\n",
      "13th- epoch: 31, train_loss = 20.911050409078598, train_acc = 0.9608756404285049\n",
      "test Acc 0.9567039106145251:\n",
      "13th- epoch: 32, train_loss = 20.40036329254508, train_acc = 0.9609920819748486\n",
      "test Acc 0.957169459962756:\n",
      "13th- epoch: 33, train_loss = 19.918839916586876, train_acc = 0.961690731252911\n",
      "test Acc 0.957169459962756:\n",
      "13th- epoch: 34, train_loss = 19.463027473539114, train_acc = 0.9623893805309734\n",
      "test Acc 0.9581005586592178:\n",
      "13th- epoch: 35, train_loss = 19.029390949755907, train_acc = 0.9630880298090359\n",
      "test Acc 0.9581005586592178:\n",
      "13th- epoch: 36, train_loss = 18.616836458444595, train_acc = 0.963903120633442\n",
      "test Acc 0.9581005586592178:\n",
      "13th- epoch: 37, train_loss = 18.223779942840338, train_acc = 0.9642524452724732\n",
      "test Acc 0.9581005586592178:\n",
      "13th- epoch: 38, train_loss = 17.849383909255266, train_acc = 0.9648346530041919\n",
      "test Acc 0.9585661080074488:\n",
      "13th- epoch: 39, train_loss = 17.492556620389223, train_acc = 0.965649743828598\n",
      "test Acc 0.9599627560521415:\n",
      "13th- epoch: 40, train_loss = 17.151166822761297, train_acc = 0.9666977177456917\n",
      "test Acc 0.9608938547486033:\n",
      "13th- epoch: 41, train_loss = 16.824155505746603, train_acc = 0.9673963670237541\n",
      "test Acc 0.9613594040968343:\n",
      "13th- epoch: 42, train_loss = 16.51019936800003, train_acc = 0.9679785747554728\n",
      "test Acc 0.9613594040968343:\n",
      "13th- epoch: 43, train_loss = 16.208349242806435, train_acc = 0.9690265486725663\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 44, train_loss = 15.918312940746546, train_acc = 0.9699580810433163\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 45, train_loss = 15.63856441900134, train_acc = 0.9711224965067536\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 46, train_loss = 15.368633352220058, train_acc = 0.9715882626921285\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 47, train_loss = 15.108827967196703, train_acc = 0.9719375873311598\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 48, train_loss = 14.85865093022585, train_acc = 0.9724033535165347\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 49, train_loss = 14.617456920444965, train_acc = 0.9726362366092222\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 50, train_loss = 14.384778328239918, train_acc = 0.9727526781555659\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 51, train_loss = 14.160114336758852, train_acc = 0.9731020027945971\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 52, train_loss = 13.943048562854528, train_acc = 0.9736842105263158\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 53, train_loss = 13.733415450900793, train_acc = 0.974033535165347\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 54, train_loss = 13.530428566038609, train_acc = 0.9746157428970657\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 55, train_loss = 13.333568772301078, train_acc = 0.9748486259897532\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 56, train_loss = 13.14302553795278, train_acc = 0.9749650675360969\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 57, train_loss = 12.95832940749824, train_acc = 0.9754308337214718\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 58, train_loss = 12.77890826575458, train_acc = 0.975780158360503\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 59, train_loss = 12.604519311338663, train_acc = 0.9760130414531905\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 60, train_loss = 12.434994414448738, train_acc = 0.9768281322775967\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 61, train_loss = 12.270201731473207, train_acc = 0.9769445738239404\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 62, train_loss = 12.109890408813953, train_acc = 0.9770610153702841\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 63, train_loss = 11.954047240316868, train_acc = 0.9772938984629715\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 64, train_loss = 11.802246950566769, train_acc = 0.9778761061946902\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 65, train_loss = 11.654276898130774, train_acc = 0.9782254308337215\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 66, train_loss = 11.510096043348312, train_acc = 0.9784583139264089\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 67, train_loss = 11.369476405903697, train_acc = 0.9788076385654402\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 68, train_loss = 11.232237493619323, train_acc = 0.9789240801117839\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 69, train_loss = 11.098303120583296, train_acc = 0.9790405216581276\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 70, train_loss = 10.967541294172406, train_acc = 0.9791569632044713\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 71, train_loss = 10.839819805696607, train_acc = 0.9791569632044713\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 72, train_loss = 10.71519610285759, train_acc = 0.9791569632044713\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 73, train_loss = 10.593177428469062, train_acc = 0.9791569632044713\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 74, train_loss = 10.47370932996273, train_acc = 0.9792734047508151\n",
      "test Acc 0.9702048417132216:\n",
      "13th- epoch: 75, train_loss = 10.356725335121155, train_acc = 0.9792734047508151\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 76, train_loss = 10.24228111281991, train_acc = 0.9792734047508151\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 77, train_loss = 10.129943015053868, train_acc = 0.9795062878435026\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 78, train_loss = 10.019799422472715, train_acc = 0.9796227293898463\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 79, train_loss = 9.911722768098116, train_acc = 0.9798556124825337\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 80, train_loss = 9.805782202631235, train_acc = 0.9799720540288775\n",
      "test Acc 0.9716014897579144:\n",
      "13th- epoch: 81, train_loss = 9.70180668309331, train_acc = 0.9800884955752213\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 82, train_loss = 9.599862169474363, train_acc = 0.980204937121565\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 83, train_loss = 9.49985633790493, train_acc = 0.980204937121565\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 84, train_loss = 9.4015031196177, train_acc = 0.980204937121565\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 85, train_loss = 9.305017665028572, train_acc = 0.980204937121565\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 86, train_loss = 9.21013244241476, train_acc = 0.9803213786679087\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 87, train_loss = 9.11676137149334, train_acc = 0.9805542617605962\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 88, train_loss = 9.024950969964266, train_acc = 0.9805542617605962\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 89, train_loss = 8.93441616371274, train_acc = 0.9807871448532837\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 90, train_loss = 8.845546174794436, train_acc = 0.9809035863996274\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 91, train_loss = 8.757931604981422, train_acc = 0.9810200279459711\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 92, train_loss = 8.672035329043865, train_acc = 0.9811364694923148\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 93, train_loss = 8.58741313032806, train_acc = 0.9812529110386586\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 94, train_loss = 8.504061935469508, train_acc = 0.9816022356776898\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 95, train_loss = 8.42208145186305, train_acc = 0.9818351187703773\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 96, train_loss = 8.341236418113112, train_acc = 0.9820680018630648\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 97, train_loss = 8.261563809588552, train_acc = 0.9820680018630648\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 98, train_loss = 8.183014450594783, train_acc = 0.9821844434094085\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 99, train_loss = 8.10573117248714, train_acc = 0.9823008849557522\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 100, train_loss = 8.029400998726487, train_acc = 0.9826502095947834\n",
      "test Acc 0.9725325884543762:\n",
      "13th- epoch: 101, train_loss = 7.954291511327028, train_acc = 0.9829995342338146\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 102, train_loss = 7.879983438178897, train_acc = 0.9835817419655333\n",
      "test Acc 0.972998137802607:\n",
      "13th- epoch: 103, train_loss = 7.806334782391787, train_acc = 0.983698183511877\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 104, train_loss = 7.73395337536931, train_acc = 0.9840475081509082\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 105, train_loss = 7.662714168429375, train_acc = 0.9842803912435957\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 106, train_loss = 7.592305075377226, train_acc = 0.9843968327899395\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 107, train_loss = 7.522921768948436, train_acc = 0.9845132743362832\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 108, train_loss = 7.454491604119539, train_acc = 0.9846297158826269\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 109, train_loss = 7.387057166546583, train_acc = 0.9846297158826269\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 110, train_loss = 7.320356860756874, train_acc = 0.9846297158826269\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 111, train_loss = 7.254509681835771, train_acc = 0.9846297158826269\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 112, train_loss = 7.189779786393046, train_acc = 0.9848625989753144\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 113, train_loss = 7.1256485637277365, train_acc = 0.9853283651606893\n",
      "test Acc 0.9739292364990689:\n",
      "13th- epoch: 114, train_loss = 7.062605954706669, train_acc = 0.9855612482533768\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 115, train_loss = 7.000127989798784, train_acc = 0.9857941313460643\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 116, train_loss = 6.938713004812598, train_acc = 0.9857941313460643\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 117, train_loss = 6.8777125012129545, train_acc = 0.9857941313460643\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 118, train_loss = 6.817847665399313, train_acc = 0.9857941313460643\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 119, train_loss = 6.7587426863610744, train_acc = 0.9860270144387517\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 120, train_loss = 6.700347205623984, train_acc = 0.9860270144387517\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 121, train_loss = 6.642677096650004, train_acc = 0.9866092221704704\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 122, train_loss = 6.585802374407649, train_acc = 0.9867256637168141\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 123, train_loss = 6.5294646099209785, train_acc = 0.9867256637168141\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 124, train_loss = 6.4739041943103075, train_acc = 0.9868421052631579\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 125, train_loss = 6.419069292023778, train_acc = 0.9869585468095017\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 126, train_loss = 6.3647171054035425, train_acc = 0.9870749883558454\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 127, train_loss = 6.311085358262062, train_acc = 0.9871914299021891\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 128, train_loss = 6.258072512224317, train_acc = 0.9873078714485328\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 129, train_loss = 6.205785447731614, train_acc = 0.9873078714485328\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 130, train_loss = 6.154086168855429, train_acc = 0.9873078714485328\n",
      "test Acc 0.9762569832402235:\n",
      "13th- epoch: 131, train_loss = 6.103029737249017, train_acc = 0.9873078714485328\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 132, train_loss = 6.052380135282874, train_acc = 0.9875407545412203\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 133, train_loss = 6.0023793168365955, train_acc = 0.9876571960875641\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 134, train_loss = 5.95295206271112, train_acc = 0.9876571960875641\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 135, train_loss = 5.904224021360278, train_acc = 0.9877736376339078\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 136, train_loss = 5.856181347742677, train_acc = 0.9876571960875641\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 137, train_loss = 5.80896707996726, train_acc = 0.9877736376339078\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 138, train_loss = 5.762257108464837, train_acc = 0.9877736376339078\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 139, train_loss = 5.716114018112421, train_acc = 0.9877736376339078\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 140, train_loss = 5.670554891228676, train_acc = 0.9878900791802515\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 141, train_loss = 5.625540858134627, train_acc = 0.9880065207265952\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 142, train_loss = 5.581116983667016, train_acc = 0.9884722869119702\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 143, train_loss = 5.537149442359805, train_acc = 0.9884722869119702\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 144, train_loss = 5.493571499362588, train_acc = 0.9885887284583139\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 145, train_loss = 5.450463341549039, train_acc = 0.9887051700046576\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 146, train_loss = 5.40763664804399, train_acc = 0.9888216115510013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 147, train_loss = 5.3658339865505695, train_acc = 0.9890544946436889\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 148, train_loss = 5.324697356671095, train_acc = 0.9890544946436889\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 149, train_loss = 5.283803446218371, train_acc = 0.9892873777363763\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 150, train_loss = 5.243714269250631, train_acc = 0.9892873777363763\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 151, train_loss = 5.203974740579724, train_acc = 0.9892873777363763\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 152, train_loss = 5.164706774055958, train_acc = 0.9892873777363763\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 153, train_loss = 5.125829683616757, train_acc = 0.98940381928272\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 154, train_loss = 5.087547414936125, train_acc = 0.98940381928272\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 155, train_loss = 5.049722568131983, train_acc = 0.98940381928272\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 156, train_loss = 5.012382526881993, train_acc = 0.98940381928272\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 157, train_loss = 4.975317503325641, train_acc = 0.98940381928272\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 158, train_loss = 4.938836391083896, train_acc = 0.98940381928272\n",
      "test Acc 0.9781191806331471:\n",
      "13th- epoch: 159, train_loss = 4.902763837017119, train_acc = 0.98940381928272\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 160, train_loss = 4.867218472063541, train_acc = 0.9895202608290639\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 161, train_loss = 4.831983202137053, train_acc = 0.9896367023754076\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 162, train_loss = 4.797308809123933, train_acc = 0.9896367023754076\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 163, train_loss = 4.763101309537888, train_acc = 0.9896367023754076\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 164, train_loss = 4.729159099981189, train_acc = 0.9899860270144387\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 165, train_loss = 4.695831103250384, train_acc = 0.9899860270144387\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 166, train_loss = 4.662753086537123, train_acc = 0.9901024685607824\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 167, train_loss = 4.630074088461697, train_acc = 0.99033535165347\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 168, train_loss = 4.597878678701818, train_acc = 0.9905682347461574\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 169, train_loss = 4.565982575528324, train_acc = 0.990801117838845\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 170, train_loss = 4.534497320652008, train_acc = 0.9909175593851887\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 171, train_loss = 4.503441202454269, train_acc = 0.9912668840242198\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 172, train_loss = 4.472830777056515, train_acc = 0.9912668840242198\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 173, train_loss = 4.44256183411926, train_acc = 0.9912668840242198\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 174, train_loss = 4.412762084975839, train_acc = 0.9912668840242198\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 175, train_loss = 4.38307398557663, train_acc = 0.9912668840242198\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 176, train_loss = 4.353989966213703, train_acc = 0.9913833255705635\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 177, train_loss = 4.325064855627716, train_acc = 0.9914997671169073\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 178, train_loss = 4.29665004555136, train_acc = 0.9914997671169073\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 179, train_loss = 4.268387885764241, train_acc = 0.9914997671169073\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 180, train_loss = 4.24061809014529, train_acc = 0.9914997671169073\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 181, train_loss = 4.213105753995478, train_acc = 0.9914997671169073\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 182, train_loss = 4.185989605262876, train_acc = 0.9914997671169073\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 183, train_loss = 4.159101604484022, train_acc = 0.9914997671169073\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 184, train_loss = 4.132699990645051, train_acc = 0.9917326502095948\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 185, train_loss = 4.10651667881757, train_acc = 0.9917326502095948\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 186, train_loss = 4.080649652518332, train_acc = 0.9918490917559385\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 187, train_loss = 4.055326513014734, train_acc = 0.9918490917559385\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 188, train_loss = 4.029987855814397, train_acc = 0.9919655333022822\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 189, train_loss = 4.004935494624078, train_acc = 0.9919655333022822\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 190, train_loss = 3.979913675226271, train_acc = 0.9921984163949698\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 191, train_loss = 3.9554801862686872, train_acc = 0.9921984163949698\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 192, train_loss = 3.9313405714929104, train_acc = 0.9921984163949698\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 193, train_loss = 3.907540858723223, train_acc = 0.9923148579413135\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 194, train_loss = 3.883956187404692, train_acc = 0.9924312994876572\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 195, train_loss = 3.8607180593535304, train_acc = 0.9924312994876572\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 196, train_loss = 3.8376420363783836, train_acc = 0.9924312994876572\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 197, train_loss = 3.8149278527125716, train_acc = 0.9924312994876572\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 198, train_loss = 3.7923030452802777, train_acc = 0.9924312994876572\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 199, train_loss = 3.770050350576639, train_acc = 0.9924312994876572\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 200, train_loss = 3.748056431300938, train_acc = 0.9924312994876572\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 201, train_loss = 3.726453938521445, train_acc = 0.9924312994876572\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 202, train_loss = 3.70468373503536, train_acc = 0.9925477410340009\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 203, train_loss = 3.683547361753881, train_acc = 0.9925477410340009\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 204, train_loss = 3.6623418256640434, train_acc = 0.9925477410340009\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 205, train_loss = 3.6416550343856215, train_acc = 0.9925477410340009\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 206, train_loss = 3.6209527738392353, train_acc = 0.9926641825803446\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 207, train_loss = 3.6006669318303466, train_acc = 0.9926641825803446\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 208, train_loss = 3.5805862164124846, train_acc = 0.9926641825803446\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 209, train_loss = 3.5606938870623708, train_acc = 0.9926641825803446\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 210, train_loss = 3.5408764174208045, train_acc = 0.9926641825803446\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 211, train_loss = 3.5215287073515356, train_acc = 0.9926641825803446\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 212, train_loss = 3.502191985491663, train_acc = 0.9926641825803446\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 213, train_loss = 3.4830751665867865, train_acc = 0.9928970656730322\n",
      "test Acc 0.9804469273743017:\n",
      "13th- epoch: 214, train_loss = 3.4644102440215647, train_acc = 0.9928970656730322\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 215, train_loss = 3.445543246809393, train_acc = 0.9930135072193759\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 216, train_loss = 3.4271352887153625, train_acc = 0.9930135072193759\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 217, train_loss = 3.408883336931467, train_acc = 0.9931299487657196\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 218, train_loss = 3.390755148138851, train_acc = 0.9931299487657196\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 219, train_loss = 3.37286489084363, train_acc = 0.9932463903120633\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 220, train_loss = 3.355102505069226, train_acc = 0.9932463903120633\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 221, train_loss = 3.337622268591076, train_acc = 0.9932463903120633\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 222, train_loss = 3.3202889752574265, train_acc = 0.9932463903120633\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 223, train_loss = 3.30301457317546, train_acc = 0.9933628318584071\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 224, train_loss = 3.286147219594568, train_acc = 0.9933628318584071\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 225, train_loss = 3.2693108352832496, train_acc = 0.9933628318584071\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 226, train_loss = 3.2526290477253497, train_acc = 0.9933628318584071\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 227, train_loss = 3.2360231317579746, train_acc = 0.9933628318584071\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 228, train_loss = 3.2198064238764346, train_acc = 0.9933628318584071\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 229, train_loss = 3.2035244964063168, train_acc = 0.9933628318584071\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 230, train_loss = 3.187593907583505, train_acc = 0.9933628318584071\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 231, train_loss = 3.1716166310943663, train_acc = 0.9933628318584071\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 232, train_loss = 3.1559142828918993, train_acc = 0.9933628318584071\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 233, train_loss = 3.140219350811094, train_acc = 0.9933628318584071\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 234, train_loss = 3.1246688407845795, train_acc = 0.9933628318584071\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 235, train_loss = 3.1092630699276924, train_acc = 0.9933628318584071\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 236, train_loss = 3.0939889517612755, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 237, train_loss = 3.078851366881281, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 238, train_loss = 3.0640104333870113, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 239, train_loss = 3.0493263411335647, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 240, train_loss = 3.034727916121483, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 241, train_loss = 3.0201837066560984, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 242, train_loss = 3.0059112175367773, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 243, train_loss = 2.9916981873102486, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 244, train_loss = 2.977765623945743, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 245, train_loss = 2.9638643912039697, train_acc = 0.9939450395901258\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 246, train_loss = 2.950015168171376, train_acc = 0.9939450395901258\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 247, train_loss = 2.9364312780089676, train_acc = 0.9939450395901258\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 248, train_loss = 2.922913331538439, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 249, train_loss = 2.9096070756204426, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 250, train_loss = 2.8964224592782557, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 251, train_loss = 2.8831299520097673, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 252, train_loss = 2.870221244636923, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 253, train_loss = 2.857360005378723, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 254, train_loss = 2.844482241664082, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 255, train_loss = 2.8319337354041636, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 256, train_loss = 2.8194181472063065, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 257, train_loss = 2.8069272092543542, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 258, train_loss = 2.794622089713812, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 259, train_loss = 2.7824548692442477, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 260, train_loss = 2.7704228186048567, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 261, train_loss = 2.758352456148714, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 262, train_loss = 2.7465534918010235, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 263, train_loss = 2.7347667403519154, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 264, train_loss = 2.723173222038895, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 265, train_loss = 2.711686575319618, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 266, train_loss = 2.700187271926552, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 267, train_loss = 2.688827946782112, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 268, train_loss = 2.677668848540634, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 269, train_loss = 2.6666448190808296, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 270, train_loss = 2.6555646718479693, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 271, train_loss = 2.644651874899864, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 272, train_loss = 2.6338401921093464, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 273, train_loss = 2.6231362619437277, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 274, train_loss = 2.6125133843161166, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 275, train_loss = 2.602028930094093, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 276, train_loss = 2.5915898508392274, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 277, train_loss = 2.5812310450710356, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 278, train_loss = 2.5711132236756384, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 279, train_loss = 2.5609903908334672, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 280, train_loss = 2.5508878394030035, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 281, train_loss = 2.54095429321751, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 282, train_loss = 2.531124224420637, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 283, train_loss = 2.5214390009641647, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 284, train_loss = 2.5118401758372784, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 285, train_loss = 2.502216165419668, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 286, train_loss = 2.4926648498512805, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 287, train_loss = 2.4833666495978832, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 288, train_loss = 2.474001494469121, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 289, train_loss = 2.464917251141742, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 290, train_loss = 2.4557621777057648, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 291, train_loss = 2.4467268586158752, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 292, train_loss = 2.4378105711657554, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 293, train_loss = 2.428896479308605, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 294, train_loss = 2.4201635234057903, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 295, train_loss = 2.411475208820775, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 296, train_loss = 2.40282512572594, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 297, train_loss = 2.3942930065095425, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 298, train_loss = 2.385861746966839, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 299, train_loss = 2.377555827377364, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 300, train_loss = 2.36926406621933, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 301, train_loss = 2.3611130353529006, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 302, train_loss = 2.3529463224112988, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 303, train_loss = 2.344933455111459, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 304, train_loss = 2.336887877434492, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 305, train_loss = 2.328941435785964, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 306, train_loss = 2.3211626957636327, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 307, train_loss = 2.3134504680056125, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 308, train_loss = 2.3056789077818394, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 309, train_loss = 2.2981695581693202, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 310, train_loss = 2.2905647966545075, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 311, train_loss = 2.283132202923298, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 312, train_loss = 2.2757046532351524, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 313, train_loss = 2.268382078735158, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 314, train_loss = 2.261115995468572, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 315, train_loss = 2.2539581556338817, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 316, train_loss = 2.2468253497499973, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 317, train_loss = 2.239785688696429, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 318, train_loss = 2.2328236859757453, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 319, train_loss = 2.2259123001713306, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 320, train_loss = 2.2191338364500552, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 321, train_loss = 2.212346274405718, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 322, train_loss = 2.205616567283869, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 323, train_loss = 2.1988895907998085, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 324, train_loss = 2.1925222501158714, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 325, train_loss = 2.1858502936083823, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 326, train_loss = 2.179466142086312, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 327, train_loss = 2.1730829428415745, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 328, train_loss = 2.16665193811059, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 329, train_loss = 2.16045709582977, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 330, train_loss = 2.1541190706193447, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 331, train_loss = 2.1480502262711525, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 332, train_loss = 2.141945027979091, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 333, train_loss = 2.1358507114928216, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 334, train_loss = 2.129866724135354, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 335, train_loss = 2.124019179493189, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 336, train_loss = 2.1181470963638276, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 337, train_loss = 2.1122915495652705, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 338, train_loss = 2.106514549581334, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 339, train_loss = 2.100732861785218, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 340, train_loss = 2.095185751793906, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 341, train_loss = 2.089431985048577, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 342, train_loss = 2.083943930687383, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 343, train_loss = 2.0785129368305206, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 344, train_loss = 2.0729618270415813, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 345, train_loss = 2.067436557263136, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 346, train_loss = 2.0622121419291943, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 347, train_loss = 2.056860697688535, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 348, train_loss = 2.051530161174014, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 349, train_loss = 2.046434413641691, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 350, train_loss = 2.0411495168227702, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 351, train_loss = 2.036043794127181, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 352, train_loss = 2.030878348974511, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 353, train_loss = 2.0258999168872833, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 354, train_loss = 2.0209763247985393, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 355, train_loss = 2.01586580905132, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 356, train_loss = 2.0110076952259988, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 357, train_loss = 2.0061102535109967, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 358, train_loss = 2.0013325202744454, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 359, train_loss = 1.996417809277773, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 360, train_loss = 1.9917559314053506, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 361, train_loss = 1.987027607858181, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 362, train_loss = 1.982431658776477, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 363, train_loss = 1.977768700569868, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 364, train_loss = 1.9731268237810582, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 365, train_loss = 1.9685879722237587, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 366, train_loss = 1.9640526175498962, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 367, train_loss = 1.959587786346674, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 368, train_loss = 1.9550890040118247, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 369, train_loss = 1.9507426619529724, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 370, train_loss = 1.9464090913534164, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 371, train_loss = 1.9419905667891726, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 372, train_loss = 1.9377402974059805, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 373, train_loss = 1.9334149496862665, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 374, train_loss = 1.9292451130459085, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 375, train_loss = 1.9249497452983633, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 376, train_loss = 1.9207462035119534, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 377, train_loss = 1.9165642721345648, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 378, train_loss = 1.9125847505638376, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 379, train_loss = 1.9084501266479492, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 380, train_loss = 1.9045859103789553, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 381, train_loss = 1.9004944438347593, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 382, train_loss = 1.8964918268611655, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 383, train_loss = 1.892518642009236, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 384, train_loss = 1.8885279794922099, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 385, train_loss = 1.8846819238970056, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 386, train_loss = 1.880837938399054, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 387, train_loss = 1.8769596926867962, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 388, train_loss = 1.8730982840061188, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 389, train_loss = 1.8695369263878092, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 390, train_loss = 1.8657300099730492, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 391, train_loss = 1.8620761124184355, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 392, train_loss = 1.858409901498817, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 393, train_loss = 1.8547000462422147, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 394, train_loss = 1.851087637245655, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 395, train_loss = 1.8475786224007607, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 396, train_loss = 1.8440025883028284, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 397, train_loss = 1.8404370645293966, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 398, train_loss = 1.837001015781425, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 399, train_loss = 1.833380607306026, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 400, train_loss = 1.8301317592849955, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 401, train_loss = 1.8265931742498651, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 402, train_loss = 1.8231090530753136, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 403, train_loss = 1.8196970050921664, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 404, train_loss = 1.8166756021091715, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 405, train_loss = 1.813089955598116, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 406, train_loss = 1.8098956035682932, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 407, train_loss = 1.80659718811512, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 408, train_loss = 1.803322572261095, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 409, train_loss = 1.8000584481051192, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 410, train_loss = 1.7969001270830631, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 411, train_loss = 1.7937520953128114, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 412, train_loss = 1.7905398048460484, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 413, train_loss = 1.7874649850418791, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 414, train_loss = 1.7843331223120913, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 415, train_loss = 1.7811688581714407, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 416, train_loss = 1.7782011168310419, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 417, train_loss = 1.775088937371038, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 418, train_loss = 1.7722562229027972, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 419, train_loss = 1.7692177258431911, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 420, train_loss = 1.7660497886827216, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 421, train_loss = 1.7631732113659382, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 422, train_loss = 1.760263979434967, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 423, train_loss = 1.7571903677890077, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 424, train_loss = 1.7544525588164106, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 425, train_loss = 1.751467173337005, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 426, train_loss = 1.748753596097231, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 427, train_loss = 1.7459197366843, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 428, train_loss = 1.7429972352692857, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 429, train_loss = 1.7401973468950018, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 430, train_loss = 1.7375596674392, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 431, train_loss = 1.7348071100423113, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 432, train_loss = 1.7319937323918566, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 433, train_loss = 1.729150228202343, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 434, train_loss = 1.7266837345669046, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 435, train_loss = 1.7239845879375935, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 436, train_loss = 1.721269546658732, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 437, train_loss = 1.7186181856086478, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 438, train_loss = 1.7160313924541697, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 439, train_loss = 1.7134409671416506, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 440, train_loss = 1.7108131448039785, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 441, train_loss = 1.7082855080952868, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 442, train_loss = 1.7056275233626366, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 443, train_loss = 1.7032804848859087, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 444, train_loss = 1.7007011311361566, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 445, train_loss = 1.6982800289988518, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 446, train_loss = 1.6957113383105025, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 447, train_loss = 1.6931617259979248, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 448, train_loss = 1.6909029918024316, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 449, train_loss = 1.688338345498778, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 450, train_loss = 1.686015377403237, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 451, train_loss = 1.6835573489079252, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 452, train_loss = 1.6811975439777598, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 453, train_loss = 1.678785938769579, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 454, train_loss = 1.67633882293012, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 455, train_loss = 1.6741707684705034, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 456, train_loss = 1.6718272616853938, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 457, train_loss = 1.669541726470925, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 458, train_loss = 1.6672267453977838, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 459, train_loss = 1.6650376642355695, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 460, train_loss = 1.6627644015243277, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 461, train_loss = 1.6603714004158974, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 462, train_loss = 1.6582248011836782, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 463, train_loss = 1.6560775066027418, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 464, train_loss = 1.653816070407629, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 465, train_loss = 1.6515886237611994, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 466, train_loss = 1.6494602909078822, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 467, train_loss = 1.6472763220081106, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 468, train_loss = 1.6451599908759817, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 469, train_loss = 1.6429941145470366, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 470, train_loss = 1.6410183906555176, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 471, train_loss = 1.6388827500632033, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 472, train_loss = 1.6367582443053834, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 473, train_loss = 1.634735808998812, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 474, train_loss = 1.6324843553011306, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 475, train_loss = 1.6305384784936905, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 476, train_loss = 1.6285439531202428, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 477, train_loss = 1.626435165584553, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 478, train_loss = 1.6244782470166683, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 479, train_loss = 1.6226507338578813, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 480, train_loss = 1.6204908092622645, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 481, train_loss = 1.6186170540750027, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 482, train_loss = 1.6165944077074528, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 483, train_loss = 1.6147086794371717, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 484, train_loss = 1.61269835755229, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 485, train_loss = 1.6107599399983883, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 486, train_loss = 1.608776468783617, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 487, train_loss = 1.6068398554925807, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 488, train_loss = 1.6052051695878617, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 489, train_loss = 1.6032925347681157, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 490, train_loss = 1.6013687675003894, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 491, train_loss = 1.5994790283148177, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 492, train_loss = 1.597600159526337, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 493, train_loss = 1.5958150562946685, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 494, train_loss = 1.5941716830129735, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 495, train_loss = 1.5922475245897658, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 496, train_loss = 1.5902301619644277, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 497, train_loss = 1.588724544912111, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 498, train_loss = 1.5869714033906348, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 499, train_loss = 1.5851116577978246, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████▎                                       | 13/30 [1:26:25<1:53:08, 399.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "14th- epoch: 0, train_loss = 272.3718866109848, train_acc = 0.45423847228691194\n",
      "test Acc 0.4864990689013035:\n",
      "14th- epoch: 1, train_loss = 208.38652956485748, train_acc = 0.4918490917559385\n",
      "test Acc 0.49767225325884545:\n",
      "14th- epoch: 2, train_loss = 168.79164361953735, train_acc = 0.5065207265952492\n",
      "test Acc 0.5256052141527002:\n",
      "14th- epoch: 3, train_loss = 147.300761282444, train_acc = 0.5908244061481136\n",
      "test Acc 0.6638733705772812:\n",
      "14th- epoch: 4, train_loss = 129.69359135627747, train_acc = 0.695388914764788\n",
      "test Acc 0.7243947858472998:\n",
      "14th- epoch: 5, train_loss = 113.76893174648285, train_acc = 0.733698183511877\n",
      "test Acc 0.7583798882681564:\n",
      "14th- epoch: 6, train_loss = 99.50902315974236, train_acc = 0.7771308802980904\n",
      "test Acc 0.7970204841713222:\n",
      "14th- epoch: 7, train_loss = 87.12028551101685, train_acc = 0.8216115510013973\n",
      "test Acc 0.8375232774674115:\n",
      "14th- epoch: 8, train_loss = 76.56980499625206, train_acc = 0.8536329762459245\n",
      "test Acc 0.8654562383612663:\n",
      "14th- epoch: 9, train_loss = 67.70585253834724, train_acc = 0.8702841173730788\n",
      "test Acc 0.8794227188081937:\n",
      "14th- epoch: 10, train_loss = 60.36830139160156, train_acc = 0.8829762459245459\n",
      "test Acc 0.8910614525139665:\n",
      "14th- epoch: 11, train_loss = 54.369413167238235, train_acc = 0.8940381928272008\n",
      "test Acc 0.8952513966480447:\n",
      "14th- epoch: 12, train_loss = 49.46841338276863, train_acc = 0.9039357242664182\n",
      "test Acc 0.904096834264432:\n",
      "14th- epoch: 13, train_loss = 45.445822298526764, train_acc = 0.9146483465300419\n",
      "test Acc 0.9152700186219739:\n",
      "14th- epoch: 14, train_loss = 42.10871261358261, train_acc = 0.922100605496041\n",
      "test Acc 0.9208566108007449:\n",
      "14th- epoch: 15, train_loss = 39.30415494740009, train_acc = 0.928272007452259\n",
      "test Acc 0.9334264432029795:\n",
      "14th- epoch: 16, train_loss = 36.91514824330807, train_acc = 0.9368886818816954\n",
      "test Acc 0.9371508379888268:\n",
      "14th- epoch: 17, train_loss = 34.856574684381485, train_acc = 0.9406148113646949\n",
      "test Acc 0.9404096834264432:\n",
      "14th- epoch: 18, train_loss = 33.065511256456375, train_acc = 0.942361434559851\n",
      "test Acc 0.9418063314711359:\n",
      "14th- epoch: 19, train_loss = 31.493716798722744, train_acc = 0.9442244993013508\n",
      "test Acc 0.9413407821229051:\n",
      "14th- epoch: 20, train_loss = 30.098376370966434, train_acc = 0.946320447135538\n",
      "test Acc 0.9436685288640596:\n",
      "14th- epoch: 21, train_loss = 28.853004418313503, train_acc = 0.9489986027014439\n",
      "test Acc 0.9445996275605214:\n",
      "14th- epoch: 22, train_loss = 27.7355540022254, train_acc = 0.9500465766185375\n",
      "test Acc 0.9464618249534451:\n",
      "14th- epoch: 23, train_loss = 26.723260678350925, train_acc = 0.9510945505356311\n",
      "test Acc 0.9492551210428305:\n",
      "14th- epoch: 24, train_loss = 25.802334800362587, train_acc = 0.9526082906380997\n",
      "test Acc 0.9511173184357542:\n",
      "14th- epoch: 25, train_loss = 24.95983173698187, train_acc = 0.9545877969259432\n",
      "test Acc 0.952513966480447:\n",
      "14th- epoch: 26, train_loss = 24.18406630307436, train_acc = 0.9558686539357243\n",
      "test Acc 0.9534450651769087:\n",
      "14th- epoch: 27, train_loss = 23.464876383543015, train_acc = 0.9572659524918491\n",
      "test Acc 0.9539106145251397:\n",
      "14th- epoch: 28, train_loss = 22.7990113645792, train_acc = 0.9588961341406614\n",
      "test Acc 0.9543761638733705:\n",
      "14th- epoch: 29, train_loss = 22.179837856441736, train_acc = 0.95947834187238\n",
      "test Acc 0.9562383612662942:\n",
      "14th- epoch: 30, train_loss = 21.600873351097107, train_acc = 0.9602934326967862\n",
      "test Acc 0.9567039106145251:\n",
      "14th- epoch: 31, train_loss = 21.05776347965002, train_acc = 0.9606427573358174\n",
      "test Acc 0.9567039106145251:\n",
      "14th- epoch: 32, train_loss = 20.546395014971495, train_acc = 0.9612249650675361\n",
      "test Acc 0.9567039106145251:\n",
      "14th- epoch: 33, train_loss = 20.063216641545296, train_acc = 0.9618071727992548\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 34, train_loss = 19.60407394170761, train_acc = 0.9622729389846297\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 35, train_loss = 19.16972691938281, train_acc = 0.9625058220773172\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 36, train_loss = 18.757328771054745, train_acc = 0.9628551467163484\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 37, train_loss = 18.36481522768736, train_acc = 0.9637866790870983\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 38, train_loss = 17.990646917372942, train_acc = 0.9649510945505356\n",
      "test Acc 0.9590316573556797:\n",
      "14th- epoch: 39, train_loss = 17.63434511050582, train_acc = 0.9657661853749417\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 40, train_loss = 17.29358832165599, train_acc = 0.9669306008383791\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 41, train_loss = 16.967424884438515, train_acc = 0.9677456916627852\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 42, train_loss = 16.654917296022177, train_acc = 0.9685607824871915\n",
      "test Acc 0.9622905027932961:\n",
      "14th- epoch: 43, train_loss = 16.355333745479584, train_acc = 0.9690265486725663\n",
      "test Acc 0.9641527001862198:\n",
      "14th- epoch: 44, train_loss = 16.067656725645065, train_acc = 0.9692594317652539\n",
      "test Acc 0.9636871508379888:\n",
      "14th- epoch: 45, train_loss = 15.790900722146034, train_acc = 0.9703074056823474\n",
      "test Acc 0.9641527001862198:\n",
      "14th- epoch: 46, train_loss = 15.52459155768156, train_acc = 0.970540288775035\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 47, train_loss = 15.268013034015894, train_acc = 0.9706567303213787\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 48, train_loss = 15.020062785595655, train_acc = 0.9713553795994411\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 49, train_loss = 14.780738597735763, train_acc = 0.9717047042384723\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 50, train_loss = 14.55032903328538, train_acc = 0.9720540288775035\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 51, train_loss = 14.328053891658783, train_acc = 0.9727526781555659\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 52, train_loss = 14.112705133855343, train_acc = 0.9731020027945971\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 53, train_loss = 13.904234997928143, train_acc = 0.9735677689799721\n",
      "test Acc 0.9664804469273743:\n",
      "14th- epoch: 54, train_loss = 13.702360592782497, train_acc = 0.9739170936190032\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 55, train_loss = 13.506890587508678, train_acc = 0.9741499767116907\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 56, train_loss = 13.317052882164717, train_acc = 0.9746157428970657\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 57, train_loss = 13.133067827671766, train_acc = 0.9748486259897532\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 58, train_loss = 12.954348627477884, train_acc = 0.9750815090824406\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 59, train_loss = 12.780341617763042, train_acc = 0.9751979506287843\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 60, train_loss = 12.611301604658365, train_acc = 0.9755472752678156\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 61, train_loss = 12.44668186828494, train_acc = 0.975780158360503\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 62, train_loss = 12.286080587655306, train_acc = 0.9758965999068467\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 63, train_loss = 12.129922587424517, train_acc = 0.9765952491849091\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 64, train_loss = 11.977516874670982, train_acc = 0.9765952491849091\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 65, train_loss = 11.829144962131977, train_acc = 0.9769445738239404\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 66, train_loss = 11.684805311262608, train_acc = 0.9770610153702841\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 67, train_loss = 11.543730948120356, train_acc = 0.9771774569166278\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 68, train_loss = 11.406046327203512, train_acc = 0.9771774569166278\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 69, train_loss = 11.271406572312117, train_acc = 0.9774103400093154\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 70, train_loss = 11.139713542535901, train_acc = 0.9776432231020028\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 71, train_loss = 11.01082956418395, train_acc = 0.9776432231020028\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 72, train_loss = 10.884741950780153, train_acc = 0.9781089892873778\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 73, train_loss = 10.761204648762941, train_acc = 0.9781089892873778\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 74, train_loss = 10.6401960067451, train_acc = 0.9781089892873778\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 75, train_loss = 10.521562037989497, train_acc = 0.9781089892873778\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 76, train_loss = 10.405424198135734, train_acc = 0.9782254308337215\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 77, train_loss = 10.291450748220086, train_acc = 0.9783418723800652\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 78, train_loss = 10.179921206086874, train_acc = 0.9785747554727526\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 79, train_loss = 10.070190312340856, train_acc = 0.9786911970190965\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 80, train_loss = 9.962490638718009, train_acc = 0.9788076385654402\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 81, train_loss = 9.856708209961653, train_acc = 0.9788076385654402\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 82, train_loss = 9.752372168004513, train_acc = 0.9789240801117839\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 83, train_loss = 9.649759784340858, train_acc = 0.9791569632044713\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 84, train_loss = 9.54901709780097, train_acc = 0.9791569632044713\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 85, train_loss = 9.449877183884382, train_acc = 0.9791569632044713\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 86, train_loss = 9.352581195533276, train_acc = 0.9793898462971589\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 87, train_loss = 9.25687626376748, train_acc = 0.9793898462971589\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 88, train_loss = 9.162642549723387, train_acc = 0.97973917093619\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 89, train_loss = 9.069957587867975, train_acc = 0.9798556124825337\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 90, train_loss = 8.978764720261097, train_acc = 0.9800884955752213\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 91, train_loss = 8.888814117759466, train_acc = 0.9803213786679087\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 92, train_loss = 8.800229165703058, train_acc = 0.9804378202142524\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 93, train_loss = 8.713278155773878, train_acc = 0.9805542617605962\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 94, train_loss = 8.627320686355233, train_acc = 0.98067070330694\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 95, train_loss = 8.542896391823888, train_acc = 0.9811364694923148\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 96, train_loss = 8.459674596786499, train_acc = 0.9813693525850024\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 97, train_loss = 8.377593901008368, train_acc = 0.9816022356776898\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 98, train_loss = 8.296873619779944, train_acc = 0.9818351187703773\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 99, train_loss = 8.216957483440638, train_acc = 0.9818351187703773\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 100, train_loss = 8.138363005593419, train_acc = 0.981951560316721\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 101, train_loss = 8.061024634167552, train_acc = 0.9821844434094085\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 102, train_loss = 7.9842916782945395, train_acc = 0.9824173265020959\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 103, train_loss = 7.908890878781676, train_acc = 0.9827666511411272\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 104, train_loss = 7.834226511418819, train_acc = 0.9829995342338146\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 105, train_loss = 7.760892564430833, train_acc = 0.9833488588728458\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 106, train_loss = 7.68826743401587, train_acc = 0.9835817419655333\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 107, train_loss = 7.616710947826505, train_acc = 0.9835817419655333\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 108, train_loss = 7.545921768993139, train_acc = 0.9840475081509082\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 109, train_loss = 7.4762293212115765, train_acc = 0.984163949697252\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 110, train_loss = 7.407231805846095, train_acc = 0.9845132743362832\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 111, train_loss = 7.339453421533108, train_acc = 0.9847461574289706\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 112, train_loss = 7.2723890114575624, train_acc = 0.9848625989753144\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 113, train_loss = 7.20645309612155, train_acc = 0.9849790405216581\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 114, train_loss = 7.141354218125343, train_acc = 0.9849790405216581\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 115, train_loss = 7.076960118487477, train_acc = 0.9850954820680019\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 116, train_loss = 7.013675931841135, train_acc = 0.9850954820680019\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 117, train_loss = 6.951109994202852, train_acc = 0.9853283651606893\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 118, train_loss = 6.889442924410105, train_acc = 0.9852119236143456\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 119, train_loss = 6.828497683629394, train_acc = 0.9856776897997206\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 120, train_loss = 6.76836035400629, train_acc = 0.9862598975314392\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 121, train_loss = 6.709096577018499, train_acc = 0.9862598975314392\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 122, train_loss = 6.650636650621891, train_acc = 0.986376339077783\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 123, train_loss = 6.592904159799218, train_acc = 0.9866092221704704\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 124, train_loss = 6.535927334800363, train_acc = 0.9866092221704704\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 125, train_loss = 6.479645378887653, train_acc = 0.9867256637168141\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 126, train_loss = 6.424086760729551, train_acc = 0.9867256637168141\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 127, train_loss = 6.36916727758944, train_acc = 0.9867256637168141\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 128, train_loss = 6.3150363974273205, train_acc = 0.9870749883558454\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 129, train_loss = 6.261550504714251, train_acc = 0.9870749883558454\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 130, train_loss = 6.208740653470159, train_acc = 0.9870749883558454\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 131, train_loss = 6.156730566173792, train_acc = 0.9877736376339078\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 132, train_loss = 6.105485262349248, train_acc = 0.9880065207265952\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 133, train_loss = 6.054626325145364, train_acc = 0.9881229622729389\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 134, train_loss = 6.004656385630369, train_acc = 0.9881229622729389\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 135, train_loss = 5.9552079271525145, train_acc = 0.9884722869119702\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 136, train_loss = 5.906635971739888, train_acc = 0.9884722869119702\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 137, train_loss = 5.858560500666499, train_acc = 0.9884722869119702\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 138, train_loss = 5.81107453070581, train_acc = 0.9884722869119702\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 139, train_loss = 5.764272538945079, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 140, train_loss = 5.718020616099238, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 141, train_loss = 5.672502720728517, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 142, train_loss = 5.627446414902806, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 143, train_loss = 5.5830326192080975, train_acc = 0.9888216115510013\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 144, train_loss = 5.539290003478527, train_acc = 0.9888216115510013\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 145, train_loss = 5.495972687378526, train_acc = 0.9889380530973452\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 146, train_loss = 5.453269172459841, train_acc = 0.9889380530973452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 147, train_loss = 5.411229087039828, train_acc = 0.9889380530973452\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 148, train_loss = 5.369534865021706, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 149, train_loss = 5.328495752997696, train_acc = 0.9891709361900326\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 150, train_loss = 5.287976375781, train_acc = 0.9891709361900326\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 151, train_loss = 5.247888251207769, train_acc = 0.9891709361900326\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 152, train_loss = 5.208423435688019, train_acc = 0.9895202608290639\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 153, train_loss = 5.16944345459342, train_acc = 0.9895202608290639\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 154, train_loss = 5.131105796433985, train_acc = 0.9896367023754076\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 155, train_loss = 5.093027935363352, train_acc = 0.9899860270144387\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 156, train_loss = 5.055631789378822, train_acc = 0.9901024685607824\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 157, train_loss = 5.018699917010963, train_acc = 0.9902189101071263\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 158, train_loss = 4.982152012176812, train_acc = 0.9902189101071263\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 159, train_loss = 4.946163062006235, train_acc = 0.99033535165347\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 160, train_loss = 4.910622050054371, train_acc = 0.9905682347461574\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 161, train_loss = 4.875590316951275, train_acc = 0.9905682347461574\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 162, train_loss = 4.840893543325365, train_acc = 0.9905682347461574\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 163, train_loss = 4.80684791598469, train_acc = 0.9905682347461574\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 164, train_loss = 4.773078883998096, train_acc = 0.9906846762925011\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 165, train_loss = 4.7396923173218966, train_acc = 0.990801117838845\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 166, train_loss = 4.7067990601062775, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 167, train_loss = 4.674284555949271, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 168, train_loss = 4.642277452163398, train_acc = 0.9911504424778761\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 169, train_loss = 4.6106085777282715, train_acc = 0.9911504424778761\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 170, train_loss = 4.579367142170668, train_acc = 0.9911504424778761\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 171, train_loss = 4.54840974509716, train_acc = 0.9911504424778761\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 172, train_loss = 4.517975389957428, train_acc = 0.9912668840242198\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 173, train_loss = 4.4877813048660755, train_acc = 0.9912668840242198\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 174, train_loss = 4.458038952201605, train_acc = 0.9912668840242198\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 175, train_loss = 4.4286745404824615, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 176, train_loss = 4.39974167291075, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 177, train_loss = 4.370988129638135, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 178, train_loss = 4.342813679017127, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 179, train_loss = 4.314895189367235, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 180, train_loss = 4.28720672801137, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 181, train_loss = 4.259980722330511, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 182, train_loss = 4.2330174297094345, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 183, train_loss = 4.206368452869356, train_acc = 0.9916162086632511\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 184, train_loss = 4.1799133867025375, train_acc = 0.9916162086632511\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 185, train_loss = 4.153952185995877, train_acc = 0.9916162086632511\n",
      "test Acc 0.9799813780260708:\n",
      "14th- epoch: 186, train_loss = 4.128271506167948, train_acc = 0.9917326502095948\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 187, train_loss = 4.102890097536147, train_acc = 0.9918490917559385\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 188, train_loss = 4.077692628838122, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 189, train_loss = 4.052982105873525, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 190, train_loss = 4.028417404741049, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 191, train_loss = 4.0041974084451795, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 192, train_loss = 3.9803279852494597, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 193, train_loss = 3.956632033921778, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 194, train_loss = 3.9332814747467637, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 195, train_loss = 3.9101941362023354, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 196, train_loss = 3.887157247401774, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 197, train_loss = 3.8647192120552063, train_acc = 0.9926641825803446\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 198, train_loss = 3.8423460153862834, train_acc = 0.9926641825803446\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 199, train_loss = 3.8202230958268046, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 200, train_loss = 3.7984787421301007, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 201, train_loss = 3.7767959060147405, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 202, train_loss = 3.755448798649013, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 203, train_loss = 3.734396018087864, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 204, train_loss = 3.71342767868191, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 205, train_loss = 3.6929348269477487, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 206, train_loss = 3.6723634214140475, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 207, train_loss = 3.652273108717054, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 208, train_loss = 3.6322664618492126, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 209, train_loss = 3.6124345660209656, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 210, train_loss = 3.5928906477056444, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 211, train_loss = 3.573434431105852, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 212, train_loss = 3.554461547639221, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 213, train_loss = 3.5352749773301184, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 214, train_loss = 3.5164615735411644, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 215, train_loss = 3.4978478960692883, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 216, train_loss = 3.479367966298014, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 217, train_loss = 3.461200869176537, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 218, train_loss = 3.4431565986014903, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 219, train_loss = 3.425239452626556, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 220, train_loss = 3.407520614564419, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 221, train_loss = 3.3900724253617227, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 222, train_loss = 3.3727464168332517, train_acc = 0.9930135072193759\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 223, train_loss = 3.3555393926799297, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 224, train_loss = 3.338699954096228, train_acc = 0.9931299487657196\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 225, train_loss = 3.32165095442906, train_acc = 0.9931299487657196\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 226, train_loss = 3.3050319380126894, train_acc = 0.9932463903120633\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 227, train_loss = 3.2885811612941325, train_acc = 0.9933628318584071\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 228, train_loss = 3.2723800614476204, train_acc = 0.9933628318584071\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 229, train_loss = 3.256026895251125, train_acc = 0.9933628318584071\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 230, train_loss = 3.2400201372802258, train_acc = 0.9933628318584071\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 231, train_loss = 3.2242193310521543, train_acc = 0.9933628318584071\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 232, train_loss = 3.2084839032031596, train_acc = 0.9933628318584071\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 233, train_loss = 3.193070687353611, train_acc = 0.9933628318584071\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 234, train_loss = 3.177463880274445, train_acc = 0.9933628318584071\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 235, train_loss = 3.16221109777689, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 236, train_loss = 3.147146836388856, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 237, train_loss = 3.1321769994683564, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 238, train_loss = 3.11730443732813, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 239, train_loss = 3.1026072301901877, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 240, train_loss = 3.088056577835232, train_acc = 0.9937121564974383\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 241, train_loss = 3.0735538243316114, train_acc = 0.9937121564974383\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 242, train_loss = 3.0593879502266645, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 243, train_loss = 3.04510880401358, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 244, train_loss = 3.031085739377886, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 245, train_loss = 3.017166128847748, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 246, train_loss = 3.0034901998005807, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 247, train_loss = 2.9896251405589283, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 248, train_loss = 2.976204412523657, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 249, train_loss = 2.962810156401247, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 250, train_loss = 2.949403910432011, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 251, train_loss = 2.936410655733198, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 252, train_loss = 2.923244605306536, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 253, train_loss = 2.910355770494789, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 254, train_loss = 2.897482135798782, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 255, train_loss = 2.884758397936821, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 256, train_loss = 2.872143237385899, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 257, train_loss = 2.859677472617477, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 258, train_loss = 2.8472707928158343, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 259, train_loss = 2.8349274112842977, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 260, train_loss = 2.822738500777632, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 261, train_loss = 2.810779793653637, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 262, train_loss = 2.798750373069197, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 263, train_loss = 2.786977502051741, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 264, train_loss = 2.775126262102276, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 265, train_loss = 2.763504236936569, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 266, train_loss = 2.7518715248443186, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 267, train_loss = 2.7405409179627895, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 268, train_loss = 2.7291477755643427, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 269, train_loss = 2.7178802178241313, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 270, train_loss = 2.7067484818398952, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 271, train_loss = 2.695684514939785, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 272, train_loss = 2.6847452470101416, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 273, train_loss = 2.6737725720740855, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 274, train_loss = 2.6631032028235495, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 275, train_loss = 2.6523644500412047, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 276, train_loss = 2.6417582049034536, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 277, train_loss = 2.6312283165752888, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 278, train_loss = 2.6208552718162537, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 279, train_loss = 2.610511463135481, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 280, train_loss = 2.600227909628302, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 281, train_loss = 2.5898105851374567, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 282, train_loss = 2.579760076943785, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 283, train_loss = 2.569572139531374, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 284, train_loss = 2.559794332832098, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 285, train_loss = 2.549785617738962, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 286, train_loss = 2.5401475057005882, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 287, train_loss = 2.5304281003773212, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 288, train_loss = 2.5208662014920264, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 289, train_loss = 2.5113921016454697, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 290, train_loss = 2.502139963209629, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 291, train_loss = 2.492797411978245, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 292, train_loss = 2.483444066019729, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 293, train_loss = 2.474528269143775, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 294, train_loss = 2.465387587668374, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 295, train_loss = 2.4564433693885803, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 296, train_loss = 2.4475053574424237, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 297, train_loss = 2.4388368155341595, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 298, train_loss = 2.430078472942114, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 299, train_loss = 2.42150982725434, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 300, train_loss = 2.412849015323445, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 301, train_loss = 2.404391534626484, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 302, train_loss = 2.3960621159058064, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 303, train_loss = 2.38772676885128, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 304, train_loss = 2.379466204671189, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 305, train_loss = 2.371280585648492, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 306, train_loss = 2.3632455107290298, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 307, train_loss = 2.355137052712962, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 308, train_loss = 2.34731566417031, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 309, train_loss = 2.339417990297079, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 310, train_loss = 2.331588999601081, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 311, train_loss = 2.3238576489966363, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 312, train_loss = 2.3161718894261867, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 313, train_loss = 2.308498590020463, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 314, train_loss = 2.3011742644011974, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 315, train_loss = 2.293562240898609, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 316, train_loss = 2.286286598769948, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 317, train_loss = 2.278890187619254, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 318, train_loss = 2.2716205790638924, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 319, train_loss = 2.2643205609638244, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 320, train_loss = 2.25738712772727, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 321, train_loss = 2.250173382461071, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 322, train_loss = 2.2432032127398998, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 323, train_loss = 2.2362983997445554, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 324, train_loss = 2.2293542486149818, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 325, train_loss = 2.2226612258236855, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 326, train_loss = 2.2158329624217004, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 327, train_loss = 2.209143343148753, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 328, train_loss = 2.202564775943756, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 329, train_loss = 2.1959432412404567, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 330, train_loss = 2.1894377146381885, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 331, train_loss = 2.183048100443557, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 332, train_loss = 2.1765692953485996, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 333, train_loss = 2.1702488474547863, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 334, train_loss = 2.1638681900221854, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 335, train_loss = 2.1578089359682053, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 336, train_loss = 2.1515021447557956, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 337, train_loss = 2.145390462130308, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 338, train_loss = 2.139442953048274, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 339, train_loss = 2.13340762257576, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 340, train_loss = 2.1274117715656757, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 341, train_loss = 2.121549431234598, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 342, train_loss = 2.115703685907647, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 343, train_loss = 2.1099764455575496, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 344, train_loss = 2.104248857824132, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 345, train_loss = 2.0984677399974316, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 346, train_loss = 2.0928616151213646, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 347, train_loss = 2.0873591899871826, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 348, train_loss = 2.0817225612699986, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 349, train_loss = 2.0762407060246915, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 350, train_loss = 2.070713313994929, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 351, train_loss = 2.0655217121820897, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 352, train_loss = 2.0599240101873875, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 353, train_loss = 2.054697956889868, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 354, train_loss = 2.0494319174904376, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 355, train_loss = 2.0441168944817036, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 356, train_loss = 2.039170554606244, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 357, train_loss = 2.033954707207158, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 358, train_loss = 2.0289101388771087, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 359, train_loss = 2.0238419596571475, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 360, train_loss = 2.0189165212213993, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 361, train_loss = 2.0138789925258607, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 362, train_loss = 2.008949000388384, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 363, train_loss = 2.00409925612621, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 364, train_loss = 1.9992441881913692, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 365, train_loss = 1.9945971716661006, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 366, train_loss = 1.9896848883945495, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 367, train_loss = 1.9851773008704185, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 368, train_loss = 1.9803959937999025, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 369, train_loss = 1.9758991760900244, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 370, train_loss = 1.9711666827788576, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 371, train_loss = 1.966712612658739, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 372, train_loss = 1.9621473141014576, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 373, train_loss = 1.9577224949607626, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 374, train_loss = 1.953137643635273, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 375, train_loss = 1.9489256913075224, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 376, train_loss = 1.9443491460988298, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 377, train_loss = 1.9401409166166559, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 378, train_loss = 1.935771589516662, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 379, train_loss = 1.9315245784819126, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 380, train_loss = 1.9274416664848104, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 381, train_loss = 1.9230378133943304, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 382, train_loss = 1.9188986470689997, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 383, train_loss = 1.9148685882100835, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 384, train_loss = 1.9106717122485861, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 385, train_loss = 1.9066959284245968, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 386, train_loss = 1.9027077244827524, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 387, train_loss = 1.8985478518297896, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 388, train_loss = 1.8946908687939867, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 389, train_loss = 1.8908194774994627, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 390, train_loss = 1.8868786506354809, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 391, train_loss = 1.8830247782170773, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 392, train_loss = 1.8791039908537641, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 393, train_loss = 1.8752992786467075, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 394, train_loss = 1.871534434496425, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 395, train_loss = 1.8678500478854403, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 396, train_loss = 1.864040425629355, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 397, train_loss = 1.860450368374586, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 398, train_loss = 1.8566335191717371, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 399, train_loss = 1.8531269207596779, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 400, train_loss = 1.8493748480686918, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 401, train_loss = 1.8458265364170074, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 402, train_loss = 1.8423779556760564, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 403, train_loss = 1.838831483037211, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 404, train_loss = 1.8352271988987923, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 405, train_loss = 1.8317949684569612, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 406, train_loss = 1.828388649970293, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 407, train_loss = 1.8249271115055308, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 408, train_loss = 1.8215973948827013, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 409, train_loss = 1.8180428134510294, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 410, train_loss = 1.8148238895228133, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 411, train_loss = 1.81155089661479, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 412, train_loss = 1.8081596357515082, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 413, train_loss = 1.8049966469407082, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 414, train_loss = 1.8017217554152012, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 415, train_loss = 1.7984905689954758, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 416, train_loss = 1.7952817442128435, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 417, train_loss = 1.792063869535923, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 418, train_loss = 1.7891161193838343, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 419, train_loss = 1.7858183631906286, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 420, train_loss = 1.7827616246649995, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 421, train_loss = 1.7797276936471462, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 422, train_loss = 1.7766136849531904, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 423, train_loss = 1.7736057005822659, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 424, train_loss = 1.7706481913337484, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 425, train_loss = 1.767673003138043, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 426, train_loss = 1.7646007525036111, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 427, train_loss = 1.7618408153066412, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 428, train_loss = 1.7588909877231345, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 429, train_loss = 1.7558585194638, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 430, train_loss = 1.7531915766885504, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 431, train_loss = 1.7501841323683038, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 432, train_loss = 1.7472905641188845, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 433, train_loss = 1.7445478575536981, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 434, train_loss = 1.7417395686497912, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 435, train_loss = 1.7389817970106378, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 436, train_loss = 1.736258890479803, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 437, train_loss = 1.733404046506621, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 438, train_loss = 1.7307708226144314, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 439, train_loss = 1.727994967252016, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 440, train_loss = 1.7254144847393036, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 441, train_loss = 1.7227290446171537, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 442, train_loss = 1.720033330260776, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 443, train_loss = 1.7174117490649223, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 444, train_loss = 1.7148841308662668, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 445, train_loss = 1.7120850557694212, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 446, train_loss = 1.7096268087625504, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 447, train_loss = 1.7070354582974687, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 448, train_loss = 1.704536035656929, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 449, train_loss = 1.7020456964382902, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 450, train_loss = 1.6995071768760681, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 451, train_loss = 1.6969748934498057, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 452, train_loss = 1.6945401169359684, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 453, train_loss = 1.6921357996761799, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 454, train_loss = 1.6897045051446185, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 455, train_loss = 1.6872565001249313, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 456, train_loss = 1.6848539573838934, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 457, train_loss = 1.6823302768170834, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 458, train_loss = 1.6800130034098402, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 459, train_loss = 1.677666506380774, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 460, train_loss = 1.675323580740951, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 461, train_loss = 1.6729450350394472, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 462, train_loss = 1.670659139752388, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 463, train_loss = 1.6684298403561115, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 464, train_loss = 1.6661591505398974, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 465, train_loss = 1.6638134060194716, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 466, train_loss = 1.661521958769299, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 467, train_loss = 1.6594192522461526, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 468, train_loss = 1.6571765753324144, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 469, train_loss = 1.6550797845120542, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 470, train_loss = 1.652786432474386, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 471, train_loss = 1.6505759109859355, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 472, train_loss = 1.6484892678563483, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 473, train_loss = 1.6462961087818258, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 474, train_loss = 1.6441180780529976, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 475, train_loss = 1.6419612554018386, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 476, train_loss = 1.6399029679596424, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 477, train_loss = 1.637854266911745, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 478, train_loss = 1.6357564441859722, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 479, train_loss = 1.633697276294697, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 480, train_loss = 1.631567062169779, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 481, train_loss = 1.6296648047864437, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 482, train_loss = 1.6275218588416465, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 483, train_loss = 1.625581070780754, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 484, train_loss = 1.6234596756403334, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 485, train_loss = 1.6215916301007383, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 486, train_loss = 1.6195604366366751, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 487, train_loss = 1.6177017825539224, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 488, train_loss = 1.6156776969437487, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 489, train_loss = 1.6136371630127542, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 490, train_loss = 1.611787439615, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 491, train_loss = 1.6099003764684312, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 492, train_loss = 1.6080421134829521, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 493, train_loss = 1.606105551123619, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 494, train_loss = 1.6041907320613973, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 495, train_loss = 1.602312648028601, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 496, train_loss = 1.6004750803112984, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 497, train_loss = 1.5986280863289721, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 498, train_loss = 1.5967769299750216, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 499, train_loss = 1.5950531512498856, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████████████████████████▋                                     | 14/30 [1:33:03<1:46:25, 399.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "15th- epoch: 0, train_loss = 273.7729822397232, train_acc = 0.444108057755007\n",
      "test Acc 0.4855679702048417:\n",
      "15th- epoch: 1, train_loss = 213.23647928237915, train_acc = 0.49161620866325106\n",
      "test Acc 0.4962756052141527:\n",
      "15th- epoch: 2, train_loss = 170.13501352071762, train_acc = 0.5089659990684676\n",
      "test Acc 0.5316573556797021:\n",
      "15th- epoch: 3, train_loss = 146.2389493584633, train_acc = 0.6311131811830462\n",
      "test Acc 0.6992551210428305:\n",
      "15th- epoch: 4, train_loss = 127.6070921421051, train_acc = 0.7146017699115044\n",
      "test Acc 0.7392923649906891:\n",
      "15th- epoch: 5, train_loss = 111.56435960531235, train_acc = 0.7447601304145319\n",
      "test Acc 0.7662942271880819:\n",
      "15th- epoch: 6, train_loss = 98.02257466316223, train_acc = 0.7845831392640894\n",
      "test Acc 0.7942271880819367:\n",
      "15th- epoch: 7, train_loss = 86.73753413558006, train_acc = 0.8106660456450862\n",
      "test Acc 0.8133147113594041:\n",
      "15th- epoch: 8, train_loss = 77.19601851701736, train_acc = 0.8317419655333023\n",
      "test Acc 0.8384543761638734:\n",
      "15th- epoch: 9, train_loss = 69.01916724443436, train_acc = 0.8529343269678621\n",
      "test Acc 0.8663873370577281:\n",
      "15th- epoch: 10, train_loss = 62.032658487558365, train_acc = 0.8734280391243596\n",
      "test Acc 0.8780260707635009:\n",
      "15th- epoch: 11, train_loss = 56.11387091875076, train_acc = 0.8862366092221705\n",
      "test Acc 0.888733705772812:\n",
      "15th- epoch: 12, train_loss = 51.17169231176376, train_acc = 0.8967163483931067\n",
      "test Acc 0.8994413407821229:\n",
      "15th- epoch: 13, train_loss = 47.04567836225033, train_acc = 0.9069632044713554\n",
      "test Acc 0.9087523277467412:\n",
      "15th- epoch: 14, train_loss = 43.57532213628292, train_acc = 0.9175593851886353\n",
      "test Acc 0.9241154562383612:\n",
      "15th- epoch: 15, train_loss = 40.6340012550354, train_acc = 0.9258267349790406\n",
      "test Acc 0.9297020484171322:\n",
      "15th- epoch: 16, train_loss = 38.10976926982403, train_acc = 0.9312994876571961\n",
      "test Acc 0.9376163873370578:\n",
      "15th- epoch: 17, train_loss = 35.91880555450916, train_acc = 0.9400326036329762\n",
      "test Acc 0.9418063314711359:\n",
      "15th- epoch: 18, train_loss = 34.00059060007334, train_acc = 0.9437587331159758\n",
      "test Acc 0.9427374301675978:\n",
      "15th- epoch: 19, train_loss = 32.306734815239906, train_acc = 0.9456217978574756\n",
      "test Acc 0.9436685288640596:\n",
      "15th- epoch: 20, train_loss = 30.804851718246937, train_acc = 0.9474848625989754\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 21, train_loss = 29.465169303119183, train_acc = 0.9494643688868188\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 22, train_loss = 28.264105521142483, train_acc = 0.9509781089892874\n",
      "test Acc 0.946927374301676:\n",
      "15th- epoch: 23, train_loss = 27.18268760293722, train_acc = 0.9523754075454122\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 24, train_loss = 26.20323096215725, train_acc = 0.9538891476478808\n",
      "test Acc 0.9515828677839852:\n",
      "15th- epoch: 25, train_loss = 25.314313001930714, train_acc = 0.9551700046576619\n",
      "test Acc 0.9529795158286778:\n",
      "15th- epoch: 26, train_loss = 24.504309259355068, train_acc = 0.956450861667443\n",
      "test Acc 0.9543761638733705:\n",
      "15th- epoch: 27, train_loss = 23.762505747377872, train_acc = 0.9572659524918491\n",
      "test Acc 0.9553072625698324:\n",
      "15th- epoch: 28, train_loss = 23.07977968081832, train_acc = 0.9581974848625989\n",
      "test Acc 0.9557728119180633:\n",
      "15th- epoch: 29, train_loss = 22.448350980877876, train_acc = 0.95947834187238\n",
      "test Acc 0.9557728119180633:\n",
      "15th- epoch: 30, train_loss = 21.861175678670406, train_acc = 0.9600605496040987\n",
      "test Acc 0.9553072625698324:\n",
      "15th- epoch: 31, train_loss = 21.31332205608487, train_acc = 0.9611085235211924\n",
      "test Acc 0.9553072625698324:\n",
      "15th- epoch: 32, train_loss = 20.799734577536583, train_acc = 0.9611085235211924\n",
      "test Acc 0.9567039106145251:\n",
      "15th- epoch: 33, train_loss = 20.31667484343052, train_acc = 0.9611085235211924\n",
      "test Acc 0.957635009310987:\n",
      "15th- epoch: 34, train_loss = 19.861040983349085, train_acc = 0.9620400558919422\n",
      "test Acc 0.9581005586592178:\n",
      "15th- epoch: 35, train_loss = 19.42978062853217, train_acc = 0.9627387051700047\n",
      "test Acc 0.9585661080074488:\n",
      "15th- epoch: 36, train_loss = 19.020388308912516, train_acc = 0.9634373544480671\n",
      "test Acc 0.9585661080074488:\n",
      "15th- epoch: 37, train_loss = 18.63097159564495, train_acc = 0.9642524452724732\n",
      "test Acc 0.9590316573556797:\n",
      "15th- epoch: 38, train_loss = 18.259618647396564, train_acc = 0.9650675360968793\n",
      "test Acc 0.9594972067039106:\n",
      "15th- epoch: 39, train_loss = 17.904270213097334, train_acc = 0.9657661853749417\n",
      "test Acc 0.9594972067039106:\n",
      "15th- epoch: 40, train_loss = 17.562980514019728, train_acc = 0.9666977177456917\n",
      "test Acc 0.9604283054003724:\n",
      "15th- epoch: 41, train_loss = 17.23495190963149, train_acc = 0.9672799254774104\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 42, train_loss = 16.919843889772892, train_acc = 0.9680950163018165\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 43, train_loss = 16.61633136495948, train_acc = 0.9689101071262226\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 44, train_loss = 16.324121430516243, train_acc = 0.9694923148579413\n",
      "test Acc 0.962756052141527:\n",
      "15th- epoch: 45, train_loss = 16.043288309127092, train_acc = 0.9699580810433163\n",
      "test Acc 0.9632216014897579:\n",
      "15th- epoch: 46, train_loss = 15.77281640470028, train_acc = 0.970540288775035\n",
      "test Acc 0.9632216014897579:\n",
      "15th- epoch: 47, train_loss = 15.512316297739744, train_acc = 0.9710060549604099\n",
      "test Acc 0.9632216014897579:\n",
      "15th- epoch: 48, train_loss = 15.260910246521235, train_acc = 0.9715882626921285\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 49, train_loss = 15.017154388129711, train_acc = 0.9719375873311598\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 50, train_loss = 14.779165547341108, train_acc = 0.9724033535165347\n",
      "test Acc 0.9646182495344506:\n",
      "15th- epoch: 51, train_loss = 14.54840924218297, train_acc = 0.9733348858872846\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 52, train_loss = 14.327538825571537, train_acc = 0.9733348858872846\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 53, train_loss = 14.114729337394238, train_acc = 0.9734513274336283\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 54, train_loss = 13.908577725291252, train_acc = 0.9735677689799721\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 55, train_loss = 13.708904126659036, train_acc = 0.9738006520726595\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 56, train_loss = 13.514851469546556, train_acc = 0.974033535165347\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 57, train_loss = 13.326011346653104, train_acc = 0.9743828598043782\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 58, train_loss = 13.142516838386655, train_acc = 0.9748486259897532\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 59, train_loss = 12.964009875431657, train_acc = 0.9748486259897532\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 60, train_loss = 12.789957415312529, train_acc = 0.9749650675360969\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 61, train_loss = 12.620291106402874, train_acc = 0.9749650675360969\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 62, train_loss = 12.455325201153755, train_acc = 0.9751979506287843\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 63, train_loss = 12.294599495828152, train_acc = 0.975314392175128\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 64, train_loss = 12.138127382844687, train_acc = 0.9754308337214718\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 65, train_loss = 11.9853439591825, train_acc = 0.9761294829995343\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 66, train_loss = 11.836568484082818, train_acc = 0.9767116907312529\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 67, train_loss = 11.691513886675239, train_acc = 0.9769445738239404\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 68, train_loss = 11.550087057054043, train_acc = 0.9770610153702841\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 69, train_loss = 11.411819588392973, train_acc = 0.9775267815556591\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 70, train_loss = 11.276502504944801, train_acc = 0.9775267815556591\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 71, train_loss = 11.144380904734135, train_acc = 0.9776432231020028\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 72, train_loss = 11.015136860311031, train_acc = 0.9776432231020028\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 73, train_loss = 10.888759400695562, train_acc = 0.9778761061946902\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 74, train_loss = 10.7649951800704, train_acc = 0.9778761061946902\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 75, train_loss = 10.64394686743617, train_acc = 0.977992547741034\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 76, train_loss = 10.525355257093906, train_acc = 0.9782254308337215\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 77, train_loss = 10.409191310405731, train_acc = 0.9784583139264089\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 78, train_loss = 10.29535661637783, train_acc = 0.9788076385654402\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 79, train_loss = 10.18390765413642, train_acc = 0.9789240801117839\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 80, train_loss = 10.07409106940031, train_acc = 0.9791569632044713\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 81, train_loss = 9.966505460441113, train_acc = 0.9791569632044713\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 82, train_loss = 9.860965453088284, train_acc = 0.9792734047508151\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 83, train_loss = 9.757424738258123, train_acc = 0.9793898462971589\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 84, train_loss = 9.655776899307966, train_acc = 0.9795062878435026\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 85, train_loss = 9.555796395987272, train_acc = 0.9795062878435026\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 86, train_loss = 9.457290679216385, train_acc = 0.9796227293898463\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 87, train_loss = 9.36038551107049, train_acc = 0.9796227293898463\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 88, train_loss = 9.265184439718723, train_acc = 0.980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 89, train_loss = 9.171762712299824, train_acc = 0.98067070330694\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 90, train_loss = 9.079891527071595, train_acc = 0.98067070330694\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 91, train_loss = 8.989492850378156, train_acc = 0.9807871448532837\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 92, train_loss = 8.900640200823545, train_acc = 0.9809035863996274\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 93, train_loss = 8.813053395599127, train_acc = 0.9809035863996274\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 94, train_loss = 8.726885411888361, train_acc = 0.9811364694923148\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 95, train_loss = 8.642024891451001, train_acc = 0.9816022356776898\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 96, train_loss = 8.558305706828833, train_acc = 0.981951560316721\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 97, train_loss = 8.475677447393537, train_acc = 0.9823008849557522\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 98, train_loss = 8.394530734047294, train_acc = 0.9824173265020959\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 99, train_loss = 8.314351661130786, train_acc = 0.9824173265020959\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 100, train_loss = 8.235511623322964, train_acc = 0.9825337680484397\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 101, train_loss = 8.157741257920861, train_acc = 0.9825337680484397\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 102, train_loss = 8.081044318154454, train_acc = 0.9827666511411272\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 103, train_loss = 8.0054154060781, train_acc = 0.9828830926874709\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 104, train_loss = 7.9310138914734125, train_acc = 0.9828830926874709\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 105, train_loss = 7.857633462175727, train_acc = 0.9834653004191896\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 106, train_loss = 7.785138849169016, train_acc = 0.9834653004191896\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 107, train_loss = 7.713603131473064, train_acc = 0.9838146250582208\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 108, train_loss = 7.643286373466253, train_acc = 0.9838146250582208\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 109, train_loss = 7.573481369763613, train_acc = 0.9839310666045645\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 110, train_loss = 7.504732606932521, train_acc = 0.9839310666045645\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 111, train_loss = 7.436846291646361, train_acc = 0.9843968327899395\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 112, train_loss = 7.369858607649803, train_acc = 0.9843968327899395\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 113, train_loss = 7.303846837952733, train_acc = 0.9843968327899395\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 114, train_loss = 7.238524656742811, train_acc = 0.9846297158826269\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 115, train_loss = 7.173796080052853, train_acc = 0.9848625989753144\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 116, train_loss = 7.110148930922151, train_acc = 0.9849790405216581\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 117, train_loss = 7.046947527676821, train_acc = 0.9848625989753144\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 118, train_loss = 6.984149759635329, train_acc = 0.9850954820680019\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 119, train_loss = 6.922003669664264, train_acc = 0.9855612482533768\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 120, train_loss = 6.860876293852925, train_acc = 0.9855612482533768\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 121, train_loss = 6.801006730645895, train_acc = 0.9857941313460643\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 122, train_loss = 6.741880564019084, train_acc = 0.9857941313460643\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 123, train_loss = 6.683367131277919, train_acc = 0.9857941313460643\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 124, train_loss = 6.625618118792772, train_acc = 0.9857941313460643\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 125, train_loss = 6.568407179787755, train_acc = 0.9861434559850955\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 126, train_loss = 6.512215744704008, train_acc = 0.9860270144387517\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 127, train_loss = 6.456488760188222, train_acc = 0.9861434559850955\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 128, train_loss = 6.40160271152854, train_acc = 0.9864927806241267\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 129, train_loss = 6.34745510481298, train_acc = 0.9866092221704704\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 130, train_loss = 6.294098833575845, train_acc = 0.9866092221704704\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 131, train_loss = 6.241415187716484, train_acc = 0.9867256637168141\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 132, train_loss = 6.189259162172675, train_acc = 0.9870749883558454\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 133, train_loss = 6.137626349925995, train_acc = 0.9871914299021891\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 134, train_loss = 6.086974564939737, train_acc = 0.9873078714485328\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 135, train_loss = 6.036863353103399, train_acc = 0.9873078714485328\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 136, train_loss = 5.987039601430297, train_acc = 0.9876571960875641\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 137, train_loss = 5.93830606713891, train_acc = 0.9876571960875641\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 138, train_loss = 5.88982311822474, train_acc = 0.9877736376339078\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 139, train_loss = 5.841948410496116, train_acc = 0.9880065207265952\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 140, train_loss = 5.794953603297472, train_acc = 0.9882394038192828\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 141, train_loss = 5.74834561906755, train_acc = 0.9882394038192828\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 142, train_loss = 5.702411876991391, train_acc = 0.9882394038192828\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 143, train_loss = 5.656797019764781, train_acc = 0.9882394038192828\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 144, train_loss = 5.612095892429352, train_acc = 0.9883558453656265\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 145, train_loss = 5.5675549898296595, train_acc = 0.9885887284583139\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 146, train_loss = 5.523836452513933, train_acc = 0.9887051700046576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 147, train_loss = 5.480611378327012, train_acc = 0.9888216115510013\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 148, train_loss = 5.437821375206113, train_acc = 0.9890544946436889\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 149, train_loss = 5.395805060863495, train_acc = 0.9892873777363763\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 150, train_loss = 5.3541047889739275, train_acc = 0.9892873777363763\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 151, train_loss = 5.312984470278025, train_acc = 0.9892873777363763\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 152, train_loss = 5.272364743053913, train_acc = 0.98940381928272\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 153, train_loss = 5.232332319021225, train_acc = 0.98940381928272\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 154, train_loss = 5.19271064735949, train_acc = 0.9895202608290639\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 155, train_loss = 5.15374830365181, train_acc = 0.9895202608290639\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 156, train_loss = 5.115060169249773, train_acc = 0.9895202608290639\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 157, train_loss = 5.077247064560652, train_acc = 0.9895202608290639\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 158, train_loss = 5.0393085069954395, train_acc = 0.9896367023754076\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 159, train_loss = 5.0023447116836905, train_acc = 0.9897531439217513\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 160, train_loss = 4.965507254935801, train_acc = 0.989869585468095\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 161, train_loss = 4.9293208019807935, train_acc = 0.9899860270144387\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 162, train_loss = 4.893486616201699, train_acc = 0.9901024685607824\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 163, train_loss = 4.858152314089239, train_acc = 0.9901024685607824\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 164, train_loss = 4.823129591532052, train_acc = 0.9902189101071263\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 165, train_loss = 4.788744460791349, train_acc = 0.99033535165347\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 166, train_loss = 4.754541075788438, train_acc = 0.99033535165347\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 167, train_loss = 4.720988950692117, train_acc = 0.9905682347461574\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 168, train_loss = 4.6878142124041915, train_acc = 0.9905682347461574\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 169, train_loss = 4.654782572761178, train_acc = 0.9906846762925011\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 170, train_loss = 4.622437269426882, train_acc = 0.990801117838845\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 171, train_loss = 4.59039001353085, train_acc = 0.990801117838845\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 172, train_loss = 4.558419520966709, train_acc = 0.990801117838845\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 173, train_loss = 4.527410390786827, train_acc = 0.9909175593851887\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 174, train_loss = 4.496410825289786, train_acc = 0.9909175593851887\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 175, train_loss = 4.465706656686962, train_acc = 0.9909175593851887\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 176, train_loss = 4.435545760206878, train_acc = 0.9909175593851887\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 177, train_loss = 4.405715039931238, train_acc = 0.9909175593851887\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 178, train_loss = 4.376158253289759, train_acc = 0.9911504424778761\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 179, train_loss = 4.347368030808866, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 180, train_loss = 4.318418321199715, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 181, train_loss = 4.289954272098839, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 182, train_loss = 4.2618577927351, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 183, train_loss = 4.234265199862421, train_acc = 0.9912668840242198\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 184, train_loss = 4.206851056776941, train_acc = 0.9913833255705635\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 185, train_loss = 4.17968315910548, train_acc = 0.9914997671169073\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 186, train_loss = 4.152738909237087, train_acc = 0.9914997671169073\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 187, train_loss = 4.126689795404673, train_acc = 0.9914997671169073\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 188, train_loss = 4.100308886729181, train_acc = 0.9916162086632511\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 189, train_loss = 4.074389058165252, train_acc = 0.9917326502095948\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 190, train_loss = 4.0488886730745435, train_acc = 0.9917326502095948\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 191, train_loss = 4.023781675845385, train_acc = 0.9917326502095948\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 192, train_loss = 3.9988111359998584, train_acc = 0.9918490917559385\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 193, train_loss = 3.9741848744452, train_acc = 0.9918490917559385\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 194, train_loss = 3.9497262947261333, train_acc = 0.9919655333022822\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 195, train_loss = 3.9257588274776936, train_acc = 0.992081974848626\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 196, train_loss = 3.9022608175873756, train_acc = 0.9921984163949698\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 197, train_loss = 3.878439157269895, train_acc = 0.9921984163949698\n",
      "test Acc 0.978584729981378:\n",
      "15th- epoch: 198, train_loss = 3.855330533348024, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 199, train_loss = 3.8325701719149947, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 200, train_loss = 3.8097305856645107, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 201, train_loss = 3.787504975683987, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 202, train_loss = 3.765381045639515, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 203, train_loss = 3.7432035813108087, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 204, train_loss = 3.721675873734057, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 205, train_loss = 3.7000370966270566, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 206, train_loss = 3.6788250925019383, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 207, train_loss = 3.657887913286686, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 208, train_loss = 3.6370673403143883, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 209, train_loss = 3.6167784268036485, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 210, train_loss = 3.5963515555486083, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 211, train_loss = 3.5761206075549126, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 212, train_loss = 3.5565052768215537, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 213, train_loss = 3.536782526411116, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 214, train_loss = 3.517442706041038, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 215, train_loss = 3.497993408702314, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 216, train_loss = 3.4791266536340117, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 217, train_loss = 3.460285654757172, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 218, train_loss = 3.441766025032848, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 219, train_loss = 3.42325733974576, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 220, train_loss = 3.405076975002885, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 221, train_loss = 3.387025995180011, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 222, train_loss = 3.3689750558696687, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 223, train_loss = 3.35137421451509, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 224, train_loss = 3.3338246741332114, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 225, train_loss = 3.3164150160737336, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 226, train_loss = 3.299545664805919, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 227, train_loss = 3.282305179629475, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 228, train_loss = 3.2654473367147148, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 229, train_loss = 3.248938478063792, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 230, train_loss = 3.2322772312909365, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 231, train_loss = 3.2160145044326782, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 232, train_loss = 3.1997562758624554, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "15th- epoch: 233, train_loss = 3.1836279649287462, train_acc = 0.9931299487657196\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 234, train_loss = 3.1679394729435444, train_acc = 0.9932463903120633\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 235, train_loss = 3.1521093230694532, train_acc = 0.9932463903120633\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 236, train_loss = 3.136491733137518, train_acc = 0.9932463903120633\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 237, train_loss = 3.1213351767510176, train_acc = 0.9932463903120633\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 238, train_loss = 3.105849494691938, train_acc = 0.9933628318584071\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 239, train_loss = 3.090777738019824, train_acc = 0.9933628318584071\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 240, train_loss = 3.075981004629284, train_acc = 0.9933628318584071\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 241, train_loss = 3.060997324064374, train_acc = 0.9933628318584071\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 242, train_loss = 3.046242507174611, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 243, train_loss = 3.0317149446345866, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 244, train_loss = 3.0173347112722695, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 245, train_loss = 3.003029473591596, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 246, train_loss = 2.9888626988977194, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 247, train_loss = 2.9745702645741403, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 248, train_loss = 2.960832921322435, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 249, train_loss = 2.9471571817994118, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 250, train_loss = 2.933205687906593, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 251, train_loss = 2.919551284518093, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 252, train_loss = 2.9061109931208193, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 253, train_loss = 2.8927473188377917, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 254, train_loss = 2.879374024923891, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 255, train_loss = 2.866261077579111, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 256, train_loss = 2.8534326343797147, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 257, train_loss = 2.840858366340399, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 258, train_loss = 2.8278725943528116, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 259, train_loss = 2.8152308599092066, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 260, train_loss = 2.8031699494458735, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 261, train_loss = 2.7905471376143396, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 262, train_loss = 2.778501432389021, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 263, train_loss = 2.7662681923247874, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 264, train_loss = 2.7542352327145636, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 265, train_loss = 2.7421803562901914, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 266, train_loss = 2.7307343743741512, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 267, train_loss = 2.7187515795230865, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 268, train_loss = 2.707383181899786, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 269, train_loss = 2.6957971355877817, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 270, train_loss = 2.6847306662239134, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 271, train_loss = 2.673076359089464, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 272, train_loss = 2.662064669188112, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 273, train_loss = 2.651048619300127, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 274, train_loss = 2.639972576405853, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 275, train_loss = 2.6291804178617895, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 276, train_loss = 2.6183219351805747, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 277, train_loss = 2.607796309981495, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 278, train_loss = 2.5969954542815685, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 279, train_loss = 2.586685123387724, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 280, train_loss = 2.576057681348175, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 281, train_loss = 2.566103453282267, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 282, train_loss = 2.5556263574399054, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 283, train_loss = 2.545779387000948, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 284, train_loss = 2.5355429141782224, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 285, train_loss = 2.52594485366717, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 286, train_loss = 2.5158399217762053, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 287, train_loss = 2.5062877661548555, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 288, train_loss = 2.4966741926036775, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 289, train_loss = 2.486964506562799, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 290, train_loss = 2.4777057631872594, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 291, train_loss = 2.4681529575027525, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 292, train_loss = 2.459104793611914, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 293, train_loss = 2.449869251344353, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 294, train_loss = 2.4404907091520727, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 295, train_loss = 2.4316749894060194, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 296, train_loss = 2.4225809299387038, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 297, train_loss = 2.4137747422792017, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 298, train_loss = 2.4051486626267433, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 299, train_loss = 2.396324899047613, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 300, train_loss = 2.387812952278182, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 301, train_loss = 2.3793538983445615, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 302, train_loss = 2.370709465118125, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 303, train_loss = 2.3625079803168774, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 304, train_loss = 2.3542226813733578, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 305, train_loss = 2.346015977440402, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 306, train_loss = 2.3378908820450306, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 307, train_loss = 2.3297037531156093, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 308, train_loss = 2.3218740683514625, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 309, train_loss = 2.3140071618836373, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 310, train_loss = 2.3060447946190834, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 311, train_loss = 2.2983016073703766, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 312, train_loss = 2.29060743865557, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 313, train_loss = 2.283052398590371, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 314, train_loss = 2.275502488017082, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 315, train_loss = 2.268046410055831, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 316, train_loss = 2.2606645226478577, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 317, train_loss = 2.2533743728417903, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 318, train_loss = 2.245982297929004, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 319, train_loss = 2.238841063110158, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 320, train_loss = 2.2317259882111102, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 321, train_loss = 2.2246860687155277, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 322, train_loss = 2.217401298461482, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 323, train_loss = 2.2109657663386315, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 324, train_loss = 2.203776452690363, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 325, train_loss = 2.197004384128377, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 326, train_loss = 2.190305483760312, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 327, train_loss = 2.1835456539411098, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 328, train_loss = 2.1768456909339875, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 329, train_loss = 2.170431427657604, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 330, train_loss = 2.1638451765757054, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 331, train_loss = 2.157589104026556, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 332, train_loss = 2.1510990522801876, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 333, train_loss = 2.144803736358881, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 334, train_loss = 2.138574082404375, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 335, train_loss = 2.1322768181562424, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 336, train_loss = 2.126571671338752, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 337, train_loss = 2.1202218409162015, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 338, train_loss = 2.114201359450817, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 339, train_loss = 2.1083614639937878, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 340, train_loss = 2.1024219393730164, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 341, train_loss = 2.0964536282699555, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 342, train_loss = 2.0906001192051917, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 343, train_loss = 2.0851179845631123, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 344, train_loss = 2.079313716618344, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 345, train_loss = 2.0735657538753003, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 346, train_loss = 2.0680972014088184, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 347, train_loss = 2.062504105269909, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 348, train_loss = 2.057115100324154, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 349, train_loss = 2.05135007458739, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 350, train_loss = 2.046302506001666, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 351, train_loss = 2.040940987644717, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 352, train_loss = 2.035521459998563, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 353, train_loss = 2.030315784038976, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 354, train_loss = 2.025080333231017, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 355, train_loss = 2.0199196797329932, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 356, train_loss = 2.0150243528187275, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 357, train_loss = 2.009791601449251, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 358, train_loss = 2.0047449108678848, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 359, train_loss = 2.000057044206187, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 360, train_loss = 1.9948294460773468, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 361, train_loss = 1.990041798679158, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 362, train_loss = 1.9851776820141822, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 363, train_loss = 1.9802884075324982, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 364, train_loss = 1.9758556932210922, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 365, train_loss = 1.970728825777769, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 366, train_loss = 1.966412543086335, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 367, train_loss = 1.9617774423677474, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 368, train_loss = 1.9569256554823369, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 369, train_loss = 1.95269579696469, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 370, train_loss = 1.9479789298493415, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 371, train_loss = 1.943398341536522, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 372, train_loss = 1.9392837460618466, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 373, train_loss = 1.9345314751844853, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 374, train_loss = 1.9302937239408493, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 375, train_loss = 1.9261713027954102, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 376, train_loss = 1.9216284689027816, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 377, train_loss = 1.9173278238158673, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 378, train_loss = 1.9133252997417003, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 379, train_loss = 1.9089659613091499, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 380, train_loss = 1.9050417554099113, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 381, train_loss = 1.9007345896679908, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 382, train_loss = 1.8966870580334216, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 383, train_loss = 1.8925523224752396, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 384, train_loss = 1.8886348952073604, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 385, train_loss = 1.8845481289317831, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 386, train_loss = 1.8806455408921465, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 387, train_loss = 1.8765257621416822, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 388, train_loss = 1.8730223650345579, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 389, train_loss = 1.8691043332219124, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 390, train_loss = 1.8650847797980532, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 391, train_loss = 1.8613987503340468, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 392, train_loss = 1.8575724139809608, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 393, train_loss = 1.8538118749856949, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 394, train_loss = 1.8503066375851631, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 395, train_loss = 1.8465535702416673, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 396, train_loss = 1.8427903428673744, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 397, train_loss = 1.8392269387841225, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 398, train_loss = 1.835564119159244, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 399, train_loss = 1.8322854489088058, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 400, train_loss = 1.8285278119146824, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 401, train_loss = 1.8249426247784868, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 402, train_loss = 1.821650568395853, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 403, train_loss = 1.8180752483895048, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 404, train_loss = 1.8146885508904234, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 405, train_loss = 1.8112300969660282, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 406, train_loss = 1.8079756809165701, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 407, train_loss = 1.8046172248432413, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 408, train_loss = 1.801239002496004, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 409, train_loss = 1.7981554990401492, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 410, train_loss = 1.7947881259024143, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 411, train_loss = 1.7914227495202795, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 412, train_loss = 1.7882934486260638, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 413, train_loss = 1.7849791757762432, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 414, train_loss = 1.7819853922119364, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 415, train_loss = 1.7787595763802528, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 416, train_loss = 1.7756071649491787, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 417, train_loss = 1.7726904103765264, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 418, train_loss = 1.769375012605451, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 419, train_loss = 1.7663994766771793, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 420, train_loss = 1.7633790472755209, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 421, train_loss = 1.7605170210590586, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 422, train_loss = 1.7575197666883469, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 423, train_loss = 1.7544313358375803, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 424, train_loss = 1.751549149514176, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 425, train_loss = 1.748525304137729, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 426, train_loss = 1.7458015270531178, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 427, train_loss = 1.7429220154881477, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 428, train_loss = 1.739813962369226, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 429, train_loss = 1.737103515653871, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 430, train_loss = 1.7342286308994517, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 431, train_loss = 1.7316039776196703, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 432, train_loss = 1.728670528740622, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 433, train_loss = 1.7260678386082873, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 434, train_loss = 1.7231672642519698, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 435, train_loss = 1.7206666059792042, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 436, train_loss = 1.7179548753192648, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 437, train_loss = 1.7150534043321386, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 438, train_loss = 1.7124571105232462, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 439, train_loss = 1.7098576774587855, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 440, train_loss = 1.7073390173027292, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 441, train_loss = 1.7045622220030054, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 442, train_loss = 1.702113057137467, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 443, train_loss = 1.699348770081997, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 444, train_loss = 1.697138924151659, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 445, train_loss = 1.6942385273287073, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 446, train_loss = 1.6922339523443952, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 447, train_loss = 1.689549179165624, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 448, train_loss = 1.6869005908956751, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 449, train_loss = 1.6844839453697205, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 450, train_loss = 1.6821171505143866, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 451, train_loss = 1.679877987713553, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 452, train_loss = 1.677299858420156, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 453, train_loss = 1.6747240833938122, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 454, train_loss = 1.6728473231196404, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 455, train_loss = 1.6702411895385012, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 456, train_loss = 1.6676867777714506, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 457, train_loss = 1.6657406650483608, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 458, train_loss = 1.6633666008710861, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 459, train_loss = 1.6607866497943178, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 460, train_loss = 1.6589853701880202, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 461, train_loss = 1.6564116217195988, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 462, train_loss = 1.6540656300494447, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 463, train_loss = 1.6521901538362727, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 464, train_loss = 1.6499019414186478, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 465, train_loss = 1.6474981755018234, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 466, train_loss = 1.6453197387745604, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 467, train_loss = 1.6434762416174635, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 468, train_loss = 1.6410986197879538, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 469, train_loss = 1.639016697765328, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 470, train_loss = 1.6368646658957005, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 471, train_loss = 1.634655024856329, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 472, train_loss = 1.632669448852539, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 473, train_loss = 1.6305177671601996, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 474, train_loss = 1.6286045188317075, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 475, train_loss = 1.6264386475086212, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 476, train_loss = 1.6244693733751774, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 477, train_loss = 1.6223594918847084, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 478, train_loss = 1.6205759719014168, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 479, train_loss = 1.6182106347987428, train_acc = 0.9962738705170004\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 480, train_loss = 1.6167179917683825, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 481, train_loss = 1.614321667701006, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 482, train_loss = 1.6124848363688216, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 483, train_loss = 1.6104929596185684, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 484, train_loss = 1.6085943803191185, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 485, train_loss = 1.6066138980677351, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 486, train_loss = 1.6047803772380576, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 487, train_loss = 1.6029272800078616, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 488, train_loss = 1.6008037267019972, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 489, train_loss = 1.5993047133088112, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 490, train_loss = 1.597187756211497, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 491, train_loss = 1.5953200658550486, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 492, train_loss = 1.593706424057018, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 493, train_loss = 1.591655646741856, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 494, train_loss = 1.5899044374818914, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 495, train_loss = 1.588107907504309, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 496, train_loss = 1.586228284984827, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 497, train_loss = 1.5843859786982648, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 498, train_loss = 1.582991972565651, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 499, train_loss = 1.5807669584755786, train_acc = 0.9963903120633442\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████                                   | 15/30 [1:39:44<1:39:52, 399.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "16th- epoch: 0, train_loss = 277.34157264232635, train_acc = 0.4578481602235678\n",
      "test Acc 0.4995344506517691:\n",
      "16th- epoch: 1, train_loss = 214.76152455806732, train_acc = 0.5017466231951561\n",
      "test Acc 0.4995344506517691:\n",
      "16th- epoch: 2, train_loss = 167.95336771011353, train_acc = 0.5081509082440615\n",
      "test Acc 0.542364990689013:\n",
      "16th- epoch: 3, train_loss = 144.86065137386322, train_acc = 0.6375174662319516\n",
      "test Acc 0.6964618249534451:\n",
      "16th- epoch: 4, train_loss = 125.92755055427551, train_acc = 0.7122729389846297\n",
      "test Acc 0.7313780260707635:\n",
      "16th- epoch: 5, train_loss = 109.37568604946136, train_acc = 0.7526781555659059\n",
      "test Acc 0.7788640595903166:\n",
      "16th- epoch: 6, train_loss = 95.47743648290634, train_acc = 0.7916860735910572\n",
      "test Acc 0.8026070763500931:\n",
      "16th- epoch: 7, train_loss = 83.96045935153961, train_acc = 0.8204471355379599\n",
      "test Acc 0.8277467411545624:\n",
      "16th- epoch: 8, train_loss = 74.28586521744728, train_acc = 0.8448998602701444\n",
      "test Acc 0.8580074487895717:\n",
      "16th- epoch: 9, train_loss = 66.114237844944, train_acc = 0.8700512342803912\n",
      "test Acc 0.8794227188081937:\n",
      "16th- epoch: 10, train_loss = 59.27910640835762, train_acc = 0.8843735444806707\n",
      "test Acc 0.8859404096834265:\n",
      "16th- epoch: 11, train_loss = 53.61985644698143, train_acc = 0.8965999068467629\n",
      "test Acc 0.9027001862197392:\n",
      "16th- epoch: 12, train_loss = 48.938038393855095, train_acc = 0.9082440614811365\n",
      "test Acc 0.9129422718808193:\n",
      "16th- epoch: 13, train_loss = 45.02975104749203, train_acc = 0.9203539823008849\n",
      "test Acc 0.9259776536312849:\n",
      "16th- epoch: 14, train_loss = 41.7376219779253, train_acc = 0.930018630647415\n",
      "test Acc 0.9287709497206704:\n",
      "16th- epoch: 15, train_loss = 38.93871684372425, train_acc = 0.9343269678621332\n",
      "test Acc 0.9315642458100558:\n",
      "16th- epoch: 16, train_loss = 36.540314480662346, train_acc = 0.9400326036329762\n",
      "test Acc 0.9380819366852886:\n",
      "16th- epoch: 17, train_loss = 34.46594990044832, train_acc = 0.9443409408476945\n",
      "test Acc 0.9399441340782123:\n",
      "16th- epoch: 18, train_loss = 32.65837799757719, train_acc = 0.9472519795062878\n",
      "test Acc 0.9422718808193669:\n",
      "16th- epoch: 19, train_loss = 31.07449857890606, train_acc = 0.9487657196087564\n",
      "test Acc 0.9427374301675978:\n",
      "16th- epoch: 20, train_loss = 29.678175762295723, train_acc = 0.9505123428039124\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 21, train_loss = 28.43613838404417, train_acc = 0.9517931998136935\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 22, train_loss = 27.32310964912176, train_acc = 0.9529576152771309\n",
      "test Acc 0.9473929236499069:\n",
      "16th- epoch: 23, train_loss = 26.322445265948772, train_acc = 0.9542384722869119\n",
      "test Acc 0.9483240223463687:\n",
      "16th- epoch: 24, train_loss = 25.41925821453333, train_acc = 0.9550535631113182\n",
      "test Acc 0.9506517690875232:\n",
      "16th- epoch: 25, train_loss = 24.597862407565117, train_acc = 0.9557522123893806\n",
      "test Acc 0.9515828677839852:\n",
      "16th- epoch: 26, train_loss = 23.845905538648367, train_acc = 0.956450861667443\n",
      "test Acc 0.9529795158286778:\n",
      "16th- epoch: 27, train_loss = 23.153067614883184, train_acc = 0.9578481602235678\n",
      "test Acc 0.9539106145251397:\n",
      "16th- epoch: 28, train_loss = 22.51182620227337, train_acc = 0.9587796925943176\n",
      "test Acc 0.9543761638733705:\n",
      "16th- epoch: 29, train_loss = 21.915076948702335, train_acc = 0.959944108057755\n",
      "test Acc 0.9557728119180633:\n",
      "16th- epoch: 30, train_loss = 21.357073072344065, train_acc = 0.9609920819748486\n",
      "test Acc 0.9562383612662942:\n",
      "16th- epoch: 31, train_loss = 20.83333668857813, train_acc = 0.9619236143455985\n",
      "test Acc 0.9562383612662942:\n",
      "16th- epoch: 32, train_loss = 20.340287141501904, train_acc = 0.9623893805309734\n",
      "test Acc 0.957169459962756:\n",
      "16th- epoch: 33, train_loss = 19.874834276735783, train_acc = 0.9625058220773172\n",
      "test Acc 0.957635009310987:\n",
      "16th- epoch: 34, train_loss = 19.434095673263073, train_acc = 0.9635537959944108\n",
      "test Acc 0.957635009310987:\n",
      "16th- epoch: 35, train_loss = 19.015312492847443, train_acc = 0.9637866790870983\n",
      "test Acc 0.9581005586592178:\n",
      "16th- epoch: 36, train_loss = 18.61692625656724, train_acc = 0.9642524452724732\n",
      "test Acc 0.9594972067039106:\n",
      "16th- epoch: 37, train_loss = 18.235864613205194, train_acc = 0.9644853283651607\n",
      "test Acc 0.9594972067039106:\n",
      "16th- epoch: 38, train_loss = 17.870170075446367, train_acc = 0.9651839776432231\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 39, train_loss = 17.519985377788544, train_acc = 0.9664648346530041\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 40, train_loss = 17.184355057775974, train_acc = 0.9668141592920354\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 41, train_loss = 16.862394232302904, train_acc = 0.9671634839310667\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 42, train_loss = 16.55294419825077, train_acc = 0.9683278993945039\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 43, train_loss = 16.255525447428226, train_acc = 0.9693758733115976\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 44, train_loss = 15.969014722853899, train_acc = 0.9701909641360037\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 45, train_loss = 15.6921600215137, train_acc = 0.9707731718677224\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 46, train_loss = 15.424110155552626, train_acc = 0.9712389380530974\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 47, train_loss = 15.165219781920314, train_acc = 0.9713553795994411\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 48, train_loss = 14.914798520505428, train_acc = 0.9719375873311598\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 49, train_loss = 14.672133143991232, train_acc = 0.9721704704238472\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 50, train_loss = 14.43675422295928, train_acc = 0.9726362366092222\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 51, train_loss = 14.208680626004934, train_acc = 0.9728691197019096\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 52, train_loss = 13.987756695598364, train_acc = 0.9734513274336283\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 53, train_loss = 13.773554164916277, train_acc = 0.9734513274336283\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 54, train_loss = 13.565442342311144, train_acc = 0.9736842105263158\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 55, train_loss = 13.363388903439045, train_acc = 0.9741499767116907\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 56, train_loss = 13.166936956346035, train_acc = 0.9742664182580345\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 57, train_loss = 12.97614647820592, train_acc = 0.9746157428970657\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 58, train_loss = 12.79069272428751, train_acc = 0.9750815090824406\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 59, train_loss = 12.610384874045849, train_acc = 0.975314392175128\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 60, train_loss = 12.434827353805304, train_acc = 0.975314392175128\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 61, train_loss = 12.26430432125926, train_acc = 0.9754308337214718\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 62, train_loss = 12.098083196207881, train_acc = 0.9756637168141593\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 63, train_loss = 11.936293533071876, train_acc = 0.9760130414531905\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 64, train_loss = 11.7785465400666, train_acc = 0.9761294829995343\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 65, train_loss = 11.624867977574468, train_acc = 0.9764788076385654\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 66, train_loss = 11.475161995738745, train_acc = 0.9768281322775967\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 67, train_loss = 11.329139174893498, train_acc = 0.9772938984629715\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 68, train_loss = 11.1865522749722, train_acc = 0.9777596646483465\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 69, train_loss = 11.047410197556019, train_acc = 0.9778761061946902\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 70, train_loss = 10.911442786455154, train_acc = 0.9781089892873778\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 71, train_loss = 10.778815384954214, train_acc = 0.9783418723800652\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 72, train_loss = 10.648699145764112, train_acc = 0.9784583139264089\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 73, train_loss = 10.521338623017073, train_acc = 0.9784583139264089\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 74, train_loss = 10.39692022278905, train_acc = 0.9784583139264089\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 75, train_loss = 10.275184705853462, train_acc = 0.9785747554727526\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 76, train_loss = 10.156061194837093, train_acc = 0.9786911970190965\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 77, train_loss = 10.039320793002844, train_acc = 0.9790405216581276\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 78, train_loss = 9.924859531223774, train_acc = 0.9791569632044713\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 79, train_loss = 9.812833305448294, train_acc = 0.9791569632044713\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 80, train_loss = 9.703139152377844, train_acc = 0.9791569632044713\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 81, train_loss = 9.595366261899471, train_acc = 0.9795062878435026\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 82, train_loss = 9.489879973232746, train_acc = 0.9795062878435026\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 83, train_loss = 9.386150427162647, train_acc = 0.9798556124825337\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 84, train_loss = 9.284328948706388, train_acc = 0.980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 85, train_loss = 9.184159129858017, train_acc = 0.9805542617605962\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 86, train_loss = 9.085195913910866, train_acc = 0.9809035863996274\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 87, train_loss = 8.988540291786194, train_acc = 0.9809035863996274\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 88, train_loss = 8.893668930977583, train_acc = 0.9811364694923148\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 89, train_loss = 8.80040292441845, train_acc = 0.9813693525850024\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 90, train_loss = 8.708959471434355, train_acc = 0.9814857941313461\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 91, train_loss = 8.61880667321384, train_acc = 0.9816022356776898\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 92, train_loss = 8.530444458127022, train_acc = 0.9816022356776898\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 93, train_loss = 8.44363371282816, train_acc = 0.9817186772240335\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 94, train_loss = 8.358037320896983, train_acc = 0.9817186772240335\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 95, train_loss = 8.273421550169587, train_acc = 0.9820680018630648\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 96, train_loss = 8.190250584855676, train_acc = 0.9824173265020959\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 97, train_loss = 8.108576707541943, train_acc = 0.9825337680484397\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 98, train_loss = 8.02799767255783, train_acc = 0.9826502095947834\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 99, train_loss = 7.949013087898493, train_acc = 0.9826502095947834\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 100, train_loss = 7.870928945019841, train_acc = 0.9827666511411272\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 101, train_loss = 7.793776333332062, train_acc = 0.9828830926874709\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 102, train_loss = 7.7178784273564816, train_acc = 0.9832324173265021\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 103, train_loss = 7.643100168555975, train_acc = 0.9835817419655333\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 104, train_loss = 7.569584658369422, train_acc = 0.9838146250582208\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 105, train_loss = 7.497123332694173, train_acc = 0.9840475081509082\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 106, train_loss = 7.425897357985377, train_acc = 0.9842803912435957\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 107, train_loss = 7.355467362329364, train_acc = 0.9846297158826269\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 108, train_loss = 7.286429716274142, train_acc = 0.985444806707033\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 109, train_loss = 7.21818402223289, train_acc = 0.9856776897997206\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 110, train_loss = 7.151150580495596, train_acc = 0.9856776897997206\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 111, train_loss = 7.085001556202769, train_acc = 0.9857941313460643\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 112, train_loss = 7.019897552207112, train_acc = 0.9857941313460643\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 113, train_loss = 6.955589523538947, train_acc = 0.9860270144387517\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 114, train_loss = 6.892334196716547, train_acc = 0.9860270144387517\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 115, train_loss = 6.829970462247729, train_acc = 0.9862598975314392\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 116, train_loss = 6.768459441140294, train_acc = 0.986376339077783\n",
      "test Acc 0.9753258845437617:\n",
      "16th- epoch: 117, train_loss = 6.707875218242407, train_acc = 0.9864927806241267\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 118, train_loss = 6.648244949057698, train_acc = 0.9864927806241267\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 119, train_loss = 6.589324122294784, train_acc = 0.9866092221704704\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 120, train_loss = 6.53146711550653, train_acc = 0.9868421052631579\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 121, train_loss = 6.474284786731005, train_acc = 0.9868421052631579\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 122, train_loss = 6.417860504239798, train_acc = 0.9869585468095017\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 123, train_loss = 6.362457247450948, train_acc = 0.9873078714485328\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 124, train_loss = 6.307505149394274, train_acc = 0.9874243129948765\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 125, train_loss = 6.253674689680338, train_acc = 0.9874243129948765\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 126, train_loss = 6.200509255751967, train_acc = 0.9878900791802515\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 127, train_loss = 6.148142404854298, train_acc = 0.9877736376339078\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 128, train_loss = 6.096420135349035, train_acc = 0.9877736376339078\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 129, train_loss = 6.045469498261809, train_acc = 0.9878900791802515\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 130, train_loss = 5.99521872214973, train_acc = 0.9880065207265952\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 131, train_loss = 5.945768190547824, train_acc = 0.9883558453656265\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 132, train_loss = 5.896969789639115, train_acc = 0.9887051700046576\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 133, train_loss = 5.848770914599299, train_acc = 0.9887051700046576\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 134, train_loss = 5.801361382007599, train_acc = 0.9887051700046576\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 135, train_loss = 5.75439590215683, train_acc = 0.9891709361900326\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 136, train_loss = 5.708190916106105, train_acc = 0.98940381928272\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 137, train_loss = 5.662535874173045, train_acc = 0.98940381928272\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 138, train_loss = 5.617654440924525, train_acc = 0.98940381928272\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 139, train_loss = 5.5730989798903465, train_acc = 0.98940381928272\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 140, train_loss = 5.5294245053082705, train_acc = 0.98940381928272\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 141, train_loss = 5.486136352643371, train_acc = 0.9895202608290639\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 142, train_loss = 5.443561937659979, train_acc = 0.9897531439217513\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 143, train_loss = 5.401368519291282, train_acc = 0.989869585468095\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 144, train_loss = 5.359786154702306, train_acc = 0.9899860270144387\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 145, train_loss = 5.318826857954264, train_acc = 0.9899860270144387\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 146, train_loss = 5.278302539139986, train_acc = 0.9899860270144387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 147, train_loss = 5.238410571590066, train_acc = 0.9899860270144387\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 148, train_loss = 5.1991189029067755, train_acc = 0.9901024685607824\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 149, train_loss = 5.160265708342195, train_acc = 0.99033535165347\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 150, train_loss = 5.121873166412115, train_acc = 0.99033535165347\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 151, train_loss = 5.084132643416524, train_acc = 0.9904517931998137\n",
      "test Acc 0.9795158286778398:\n",
      "16th- epoch: 152, train_loss = 5.0468742195516825, train_acc = 0.9904517931998137\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 153, train_loss = 5.010049378499389, train_acc = 0.9904517931998137\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 154, train_loss = 4.973643386736512, train_acc = 0.9904517931998137\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 155, train_loss = 4.9377595242112875, train_acc = 0.9905682347461574\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 156, train_loss = 4.902482647448778, train_acc = 0.9905682347461574\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 157, train_loss = 4.867473944090307, train_acc = 0.9906846762925011\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 158, train_loss = 4.833058194257319, train_acc = 0.9906846762925011\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 159, train_loss = 4.799062322825193, train_acc = 0.990801117838845\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 160, train_loss = 4.765497085638344, train_acc = 0.990801117838845\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 161, train_loss = 4.732243481092155, train_acc = 0.990801117838845\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 162, train_loss = 4.6994478683918715, train_acc = 0.9909175593851887\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 163, train_loss = 4.6671708738431334, train_acc = 0.9909175593851887\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 164, train_loss = 4.635168532840908, train_acc = 0.9909175593851887\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 165, train_loss = 4.60371208190918, train_acc = 0.9909175593851887\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 166, train_loss = 4.5725341802462935, train_acc = 0.9909175593851887\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 167, train_loss = 4.541957779787481, train_acc = 0.9909175593851887\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 168, train_loss = 4.511368117295206, train_acc = 0.9909175593851887\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 169, train_loss = 4.481409603729844, train_acc = 0.9910340009315324\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 170, train_loss = 4.451802298426628, train_acc = 0.9911504424778761\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 171, train_loss = 4.422630405984819, train_acc = 0.9911504424778761\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 172, train_loss = 4.3935831459239125, train_acc = 0.9913833255705635\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 173, train_loss = 4.365002362988889, train_acc = 0.9914997671169073\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 174, train_loss = 4.336750980466604, train_acc = 0.9916162086632511\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 175, train_loss = 4.309048864990473, train_acc = 0.9916162086632511\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 176, train_loss = 4.281320041976869, train_acc = 0.9916162086632511\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 177, train_loss = 4.254188150167465, train_acc = 0.9916162086632511\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 178, train_loss = 4.227250341325998, train_acc = 0.9916162086632511\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 179, train_loss = 4.20067551266402, train_acc = 0.9916162086632511\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 180, train_loss = 4.174304571934044, train_acc = 0.9916162086632511\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 181, train_loss = 4.148390978574753, train_acc = 0.9916162086632511\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 182, train_loss = 4.122690704651177, train_acc = 0.9916162086632511\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 183, train_loss = 4.097093543969095, train_acc = 0.9917326502095948\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 184, train_loss = 4.0720462473109365, train_acc = 0.9917326502095948\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 185, train_loss = 4.047253766097128, train_acc = 0.9918490917559385\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 186, train_loss = 4.02271210309118, train_acc = 0.9918490917559385\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 187, train_loss = 3.998386156745255, train_acc = 0.9919655333022822\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 188, train_loss = 3.974450785666704, train_acc = 0.9919655333022822\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 189, train_loss = 3.9505640668794513, train_acc = 0.992081974848626\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 190, train_loss = 3.927151046693325, train_acc = 0.992081974848626\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 191, train_loss = 3.90395946521312, train_acc = 0.992081974848626\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 192, train_loss = 3.880897627212107, train_acc = 0.9921984163949698\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 193, train_loss = 3.8582659801468253, train_acc = 0.9923148579413135\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 194, train_loss = 3.835755447857082, train_acc = 0.9923148579413135\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 195, train_loss = 3.813464525155723, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 196, train_loss = 3.7915103072300553, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 197, train_loss = 3.7698846384882927, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 198, train_loss = 3.7483609253540635, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 199, train_loss = 3.7270950013771653, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 200, train_loss = 3.706132805906236, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 201, train_loss = 3.6853459142148495, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 202, train_loss = 3.6648364206776023, train_acc = 0.9923148579413135\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 203, train_loss = 3.644518601708114, train_acc = 0.9924312994876572\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 204, train_loss = 3.6244415640830994, train_acc = 0.9924312994876572\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 205, train_loss = 3.60482170060277, train_acc = 0.9925477410340009\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 206, train_loss = 3.585080542601645, train_acc = 0.9925477410340009\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 207, train_loss = 3.5656673833727837, train_acc = 0.9926641825803446\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 208, train_loss = 3.546431771479547, train_acc = 0.9926641825803446\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 209, train_loss = 3.5273735569790006, train_acc = 0.9927806241266884\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 210, train_loss = 3.50857562571764, train_acc = 0.9927806241266884\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 211, train_loss = 3.4898850843310356, train_acc = 0.9927806241266884\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 212, train_loss = 3.471542918123305, train_acc = 0.9927806241266884\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 213, train_loss = 3.4532956639304757, train_acc = 0.9927806241266884\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 214, train_loss = 3.4350923346355557, train_acc = 0.9928970656730322\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 215, train_loss = 3.4172810772433877, train_acc = 0.9928970656730322\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 216, train_loss = 3.3995252391323447, train_acc = 0.9928970656730322\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 217, train_loss = 3.382046055048704, train_acc = 0.9928970656730322\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 218, train_loss = 3.364726100116968, train_acc = 0.9928970656730322\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 219, train_loss = 3.347455596085638, train_acc = 0.9928970656730322\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 220, train_loss = 3.3305062502622604, train_acc = 0.9928970656730322\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 221, train_loss = 3.3137288093566895, train_acc = 0.9928970656730322\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 222, train_loss = 3.296968176495284, train_acc = 0.9928970656730322\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 223, train_loss = 3.2804779652506113, train_acc = 0.9930135072193759\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 224, train_loss = 3.264192952308804, train_acc = 0.9930135072193759\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 225, train_loss = 3.248035865370184, train_acc = 0.9930135072193759\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 226, train_loss = 3.231936778873205, train_acc = 0.9930135072193759\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 227, train_loss = 3.216029880568385, train_acc = 0.9930135072193759\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 228, train_loss = 3.200431602075696, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 229, train_loss = 3.1847529872320592, train_acc = 0.9932463903120633\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 230, train_loss = 3.1694054468534887, train_acc = 0.9932463903120633\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 231, train_loss = 3.1538949399255216, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 232, train_loss = 3.139056845102459, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 233, train_loss = 3.1239062193781137, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 234, train_loss = 3.10914956824854, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 235, train_loss = 3.0944653400219977, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 236, train_loss = 3.079967111814767, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 237, train_loss = 3.0654910658486187, train_acc = 0.9935957149510946\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 238, train_loss = 3.050734482239932, train_acc = 0.9937121564974383\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 239, train_loss = 3.036967545747757, train_acc = 0.9937121564974383\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 240, train_loss = 3.0229187924414873, train_acc = 0.993828598043782\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 241, train_loss = 3.0088892388157547, train_acc = 0.9939450395901258\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 242, train_loss = 2.995247996877879, train_acc = 0.9939450395901258\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 243, train_loss = 2.981442607473582, train_acc = 0.9939450395901258\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 244, train_loss = 2.9677946805022657, train_acc = 0.9939450395901258\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 245, train_loss = 2.9544320409186184, train_acc = 0.9939450395901258\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 246, train_loss = 2.9413013155572116, train_acc = 0.9939450395901258\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 247, train_loss = 2.928004944231361, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "16th- epoch: 248, train_loss = 2.915090325754136, train_acc = 0.9939450395901258\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 249, train_loss = 2.9020381928421557, train_acc = 0.9940614811364695\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 250, train_loss = 2.889239229261875, train_acc = 0.9940614811364695\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 251, train_loss = 2.8763311095535755, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 252, train_loss = 2.8639805540442467, train_acc = 0.9941779226828132\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 253, train_loss = 2.851400048006326, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 254, train_loss = 2.839188436511904, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 255, train_loss = 2.8268658095039427, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 256, train_loss = 2.8146887379698455, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 257, train_loss = 2.8026425247080624, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 258, train_loss = 2.7905517644248903, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 259, train_loss = 2.7789768972434103, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 260, train_loss = 2.7672793897800148, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 261, train_loss = 2.7558604306541383, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 262, train_loss = 2.744137773755938, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 263, train_loss = 2.732768088579178, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 264, train_loss = 2.7215204290114343, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 265, train_loss = 2.7104497239924967, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 266, train_loss = 2.6990127004683018, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 267, train_loss = 2.688263019081205, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 268, train_loss = 2.6774545833468437, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 269, train_loss = 2.666559223085642, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 270, train_loss = 2.6558897546492517, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 271, train_loss = 2.6453117318451405, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 272, train_loss = 2.634861209895462, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 273, train_loss = 2.6243846281431615, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 274, train_loss = 2.6138926595449448, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 275, train_loss = 2.603880662471056, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 276, train_loss = 2.593785036355257, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 277, train_loss = 2.5836342819966376, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 278, train_loss = 2.5737589769996703, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 279, train_loss = 2.563753052148968, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 280, train_loss = 2.554077126085758, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 281, train_loss = 2.544455525930971, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 282, train_loss = 2.534738326910883, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 283, train_loss = 2.5250802650116384, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 284, train_loss = 2.5158752375282347, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 285, train_loss = 2.5065201334655285, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 286, train_loss = 2.4972791536711156, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 287, train_loss = 2.4881097585894167, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 288, train_loss = 2.478961976710707, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 289, train_loss = 2.47000023862347, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 290, train_loss = 2.461114509496838, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 291, train_loss = 2.4520052359439433, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 292, train_loss = 2.4434478119947016, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 293, train_loss = 2.4348612152971327, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 294, train_loss = 2.426236668135971, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 295, train_loss = 2.4177029095590115, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 296, train_loss = 2.409316333476454, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 297, train_loss = 2.4010008312761784, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 298, train_loss = 2.3925626538693905, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 299, train_loss = 2.384402512339875, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 300, train_loss = 2.376288055209443, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 301, train_loss = 2.368237712653354, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 302, train_loss = 2.360011548968032, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 303, train_loss = 2.3522374231833965, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 304, train_loss = 2.3444908161181957, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 305, train_loss = 2.3366021749097854, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 306, train_loss = 2.3290385890286416, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 307, train_loss = 2.3214176148176193, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 308, train_loss = 2.313690286129713, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 309, train_loss = 2.306288144318387, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 310, train_loss = 2.298879212467, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 311, train_loss = 2.2914507638197392, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 312, train_loss = 2.2840306733269244, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 313, train_loss = 2.277048698393628, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 314, train_loss = 2.2698887560982257, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 315, train_loss = 2.2626085442025214, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 316, train_loss = 2.2556377451401204, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 317, train_loss = 2.2488399371504784, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 318, train_loss = 2.2417835879605263, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 319, train_loss = 2.234968627570197, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 320, train_loss = 2.2281626909971237, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 321, train_loss = 2.221383197931573, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 322, train_loss = 2.214728170307353, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 323, train_loss = 2.2081538029015064, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 324, train_loss = 2.201575580984354, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 325, train_loss = 2.195189281133935, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 326, train_loss = 2.1887574282009155, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 327, train_loss = 2.1823705546557903, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 328, train_loss = 2.1758590426761657, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 329, train_loss = 2.1697992112021893, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 330, train_loss = 2.1635928724426776, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 331, train_loss = 2.157499349443242, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 332, train_loss = 2.1513910617213696, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 333, train_loss = 2.1451942820567638, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 334, train_loss = 2.1393606464844197, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 335, train_loss = 2.1331956449430436, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 336, train_loss = 2.12734421598725, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 337, train_loss = 2.1215025212150067, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 338, train_loss = 2.115707689197734, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 339, train_loss = 2.109948656288907, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 340, train_loss = 2.104270577430725, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 341, train_loss = 2.0984648901503533, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 342, train_loss = 2.092725499300286, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 343, train_loss = 2.087355940369889, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 344, train_loss = 2.0818515196442604, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 345, train_loss = 2.0763804998714477, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 346, train_loss = 2.0708070434629917, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 347, train_loss = 2.0656200237572193, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 348, train_loss = 2.0602812506258488, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 349, train_loss = 2.0548425193410367, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 350, train_loss = 2.0497318021953106, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 351, train_loss = 2.0446150701027364, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 352, train_loss = 2.039510389091447, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 353, train_loss = 2.0344771419186145, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 354, train_loss = 2.029284297255799, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 355, train_loss = 2.0242051507811993, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 356, train_loss = 2.019346073269844, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 357, train_loss = 2.014528701780364, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 358, train_loss = 2.0097077265381813, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 359, train_loss = 2.0049448620993644, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 360, train_loss = 2.0001138038933277, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 361, train_loss = 1.9953682881314307, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 362, train_loss = 1.9903633184731007, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 363, train_loss = 1.9860586908180267, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 364, train_loss = 1.9813156959135085, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 365, train_loss = 1.97677140426822, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 366, train_loss = 1.9723041045945138, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 367, train_loss = 1.9676006957888603, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 368, train_loss = 1.9629676055628806, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 369, train_loss = 1.9588965959846973, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 370, train_loss = 1.9542696215212345, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 371, train_loss = 1.9499723266344517, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 372, train_loss = 1.9458725464064628, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 373, train_loss = 1.941255733370781, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 374, train_loss = 1.9371260430198163, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 375, train_loss = 1.932755823014304, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 376, train_loss = 1.9286978754680604, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 377, train_loss = 1.9245592628140002, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 378, train_loss = 1.9203498363494873, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 379, train_loss = 1.916319890646264, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 380, train_loss = 1.912186797708273, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 381, train_loss = 1.9081813308876008, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 382, train_loss = 1.9039185668807477, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 383, train_loss = 1.9001527117798105, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 384, train_loss = 1.896392609924078, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 385, train_loss = 1.892186259268783, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 386, train_loss = 1.8885300593683496, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 387, train_loss = 1.884595169336535, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 388, train_loss = 1.8808679195353761, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 389, train_loss = 1.8767107190797105, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 390, train_loss = 1.873258799314499, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 391, train_loss = 1.8694026531884447, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 392, train_loss = 1.8657897772500291, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 393, train_loss = 1.8620644906768575, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 394, train_loss = 1.858325203298591, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 395, train_loss = 1.8548673912882805, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 396, train_loss = 1.8509332252433524, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 397, train_loss = 1.8476865714183077, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 398, train_loss = 1.8440538545837626, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 399, train_loss = 1.840624695061706, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 400, train_loss = 1.8370039412984625, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 401, train_loss = 1.8336806843290105, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 402, train_loss = 1.8300627171993256, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 403, train_loss = 1.8266099753091112, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 404, train_loss = 1.8232641568174586, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 405, train_loss = 1.8200316528091207, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 406, train_loss = 1.8167593280086294, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 407, train_loss = 1.813336305320263, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 408, train_loss = 1.810216469108127, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 409, train_loss = 1.8066877288511023, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 410, train_loss = 1.8034560704836622, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 411, train_loss = 1.8003407940268517, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 412, train_loss = 1.7972036451101303, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 413, train_loss = 1.7940086796879768, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 414, train_loss = 1.790819967747666, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 415, train_loss = 1.7877110230037943, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 416, train_loss = 1.7846474113175645, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 417, train_loss = 1.781440518796444, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 418, train_loss = 1.7784438593080267, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 419, train_loss = 1.775492193759419, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 420, train_loss = 1.7725119678070769, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 421, train_loss = 1.769491115002893, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 422, train_loss = 1.7665799347450957, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 423, train_loss = 1.7636060366639867, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 424, train_loss = 1.7607158062746748, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 425, train_loss = 1.7577342787990347, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 426, train_loss = 1.7547370182583109, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 427, train_loss = 1.752071356982924, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 428, train_loss = 1.7491998933255672, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 429, train_loss = 1.7463517127325758, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 430, train_loss = 1.7436122260987759, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 431, train_loss = 1.7408376211533323, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 432, train_loss = 1.738022701232694, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 433, train_loss = 1.735294595360756, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 434, train_loss = 1.7323063438525423, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 435, train_loss = 1.729843740700744, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 436, train_loss = 1.727154759108089, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 437, train_loss = 1.7244528183946386, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 438, train_loss = 1.7218420058488846, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 439, train_loss = 1.7191718630492687, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 440, train_loss = 1.7165489383041859, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 441, train_loss = 1.7139164371183142, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 442, train_loss = 1.711343320668675, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 443, train_loss = 1.7085676392307505, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 444, train_loss = 1.7062841976294294, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 445, train_loss = 1.703657449572347, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 446, train_loss = 1.701235712855123, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 447, train_loss = 1.698687327443622, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 448, train_loss = 1.696143270819448, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 449, train_loss = 1.6937641203403473, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 450, train_loss = 1.6913381392369047, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 451, train_loss = 1.688632432371378, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 452, train_loss = 1.686512236832641, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 453, train_loss = 1.6840111104538664, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 454, train_loss = 1.6817354907980189, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 455, train_loss = 1.679339911788702, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 456, train_loss = 1.6769806705415249, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 457, train_loss = 1.6746587194502354, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 458, train_loss = 1.672317480086349, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 459, train_loss = 1.6700208833208308, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 460, train_loss = 1.667580763460137, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 461, train_loss = 1.6654679216444492, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 462, train_loss = 1.663261853158474, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 463, train_loss = 1.6608903718879446, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 464, train_loss = 1.6587663976242766, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 465, train_loss = 1.6565139131853357, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 466, train_loss = 1.6543289745459333, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 467, train_loss = 1.6521120568504557, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 468, train_loss = 1.6499073579907417, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 469, train_loss = 1.6475457040360197, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 470, train_loss = 1.6456231673946604, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 471, train_loss = 1.643500193953514, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 472, train_loss = 1.6415149172535166, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 473, train_loss = 1.639166890294291, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 474, train_loss = 1.6373302824795246, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 475, train_loss = 1.6351112835109234, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 476, train_loss = 1.6330826444318518, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 477, train_loss = 1.6309059398481622, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 478, train_loss = 1.6289854509523138, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 479, train_loss = 1.6269394904375076, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 480, train_loss = 1.6250908548245206, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 481, train_loss = 1.6228731833398342, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 482, train_loss = 1.6209718225290999, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 483, train_loss = 1.6190431440481916, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 484, train_loss = 1.6171254938235506, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 485, train_loss = 1.6149315884103999, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 486, train_loss = 1.6131578870117664, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 487, train_loss = 1.6113069566199556, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 488, train_loss = 1.6093010492622852, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 489, train_loss = 1.607471837371122, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 490, train_loss = 1.6054600775241852, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 491, train_loss = 1.6038818011875264, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 492, train_loss = 1.6018404327332973, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 493, train_loss = 1.5999822144513018, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 494, train_loss = 1.5980819401447661, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 495, train_loss = 1.5963477243785746, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 496, train_loss = 1.5945791875128634, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 497, train_loss = 1.5927433520555496, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 498, train_loss = 1.5909865100984462, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "16th- epoch: 499, train_loss = 1.5891023364965804, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████▎                                | 16/30 [1:46:21<1:33:03, 398.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "17th- epoch: 0, train_loss = 273.17268800735474, train_acc = 0.44981369352585004\n",
      "test Acc 0.4930167597765363:\n",
      "17th- epoch: 1, train_loss = 209.0211807489395, train_acc = 0.49592454587796925\n",
      "test Acc 0.5:\n",
      "17th- epoch: 2, train_loss = 166.90707796812057, train_acc = 0.5164182580344667\n",
      "test Acc 0.5581936685288641:\n",
      "17th- epoch: 3, train_loss = 143.2300357222557, train_acc = 0.6563809967396367\n",
      "test Acc 0.702048417132216:\n",
      "17th- epoch: 4, train_loss = 124.8905890583992, train_acc = 0.716115510013973\n",
      "test Acc 0.7411545623836127:\n",
      "17th- epoch: 5, train_loss = 109.16892570257187, train_acc = 0.7467396367023754\n",
      "test Acc 0.7695530726256983:\n",
      "17th- epoch: 6, train_loss = 95.66022878885269, train_acc = 0.7880763856544015\n",
      "test Acc 0.8105214152700186:\n",
      "17th- epoch: 7, train_loss = 84.15414655208588, train_acc = 0.8280158360503027\n",
      "test Acc 0.840782122905028:\n",
      "17th- epoch: 8, train_loss = 74.39424240589142, train_acc = 0.8542151839776432\n",
      "test Acc 0.8654562383612663:\n",
      "17th- epoch: 9, train_loss = 66.21315789222717, train_acc = 0.8708663251047974\n",
      "test Acc 0.8747672253258846:\n",
      "17th- epoch: 10, train_loss = 59.42667409777641, train_acc = 0.8826269212855147\n",
      "test Acc 0.8854748603351955:\n",
      "17th- epoch: 11, train_loss = 53.82553541660309, train_acc = 0.8924080111783884\n",
      "test Acc 0.8943202979515829:\n",
      "17th- epoch: 12, train_loss = 49.188045397400856, train_acc = 0.9012575687005123\n",
      "test Acc 0.9017690875232774:\n",
      "17th- epoch: 13, train_loss = 45.322201266884804, train_acc = 0.9110386585933862\n",
      "test Acc 0.9110800744878957:\n",
      "17th- epoch: 14, train_loss = 42.063392758369446, train_acc = 0.9212855146716349\n",
      "test Acc 0.9245810055865922:\n",
      "17th- epoch: 15, train_loss = 39.27991633117199, train_acc = 0.9301350721937587\n",
      "test Acc 0.9315642458100558:\n",
      "17th- epoch: 16, train_loss = 36.891066178679466, train_acc = 0.9346762925011645\n",
      "test Acc 0.9348230912476723:\n",
      "17th- epoch: 17, train_loss = 34.82535195350647, train_acc = 0.9385188635305077\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 18, train_loss = 33.02211224287748, train_acc = 0.9445738239403819\n",
      "test Acc 0.9436685288640596:\n",
      "17th- epoch: 19, train_loss = 31.43828822672367, train_acc = 0.9473684210526315\n",
      "test Acc 0.9459962756052142:\n",
      "17th- epoch: 20, train_loss = 30.039212502539158, train_acc = 0.9488821611551002\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 21, train_loss = 28.794006921350956, train_acc = 0.9509781089892874\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 22, train_loss = 27.67740622907877, train_acc = 0.9526082906380997\n",
      "test Acc 0.9487895716945997:\n",
      "17th- epoch: 23, train_loss = 26.66836566478014, train_acc = 0.9537727061015371\n",
      "test Acc 0.9501862197392924:\n",
      "17th- epoch: 24, train_loss = 25.75238098949194, train_acc = 0.9549371215649743\n",
      "test Acc 0.9501862197392924:\n",
      "17th- epoch: 25, train_loss = 24.91831886023283, train_acc = 0.955519329296693\n",
      "test Acc 0.952048417132216:\n",
      "17th- epoch: 26, train_loss = 24.153864830732346, train_acc = 0.9568001863064741\n",
      "test Acc 0.9534450651769087:\n",
      "17th- epoch: 27, train_loss = 23.450403660535812, train_acc = 0.9576152771308803\n",
      "test Acc 0.9529795158286778:\n",
      "17th- epoch: 28, train_loss = 22.800181068480015, train_acc = 0.9584303679552865\n",
      "test Acc 0.9539106145251397:\n",
      "17th- epoch: 29, train_loss = 22.196510713547468, train_acc = 0.9588961341406614\n",
      "test Acc 0.9548417132216015:\n",
      "17th- epoch: 30, train_loss = 21.635074947029352, train_acc = 0.9595947834187238\n",
      "test Acc 0.9557728119180633:\n",
      "17th- epoch: 31, train_loss = 21.110409047454596, train_acc = 0.9608756404285049\n",
      "test Acc 0.9562383612662942:\n",
      "17th- epoch: 32, train_loss = 20.617639791220427, train_acc = 0.9612249650675361\n",
      "test Acc 0.957169459962756:\n",
      "17th- epoch: 33, train_loss = 20.153081957250834, train_acc = 0.9619236143455985\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 34, train_loss = 19.713944133371115, train_acc = 0.9620400558919422\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 35, train_loss = 19.29777842387557, train_acc = 0.9622729389846297\n",
      "test Acc 0.9581005586592178:\n",
      "17th- epoch: 36, train_loss = 18.90257629007101, train_acc = 0.9627387051700047\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 37, train_loss = 18.526249431073666, train_acc = 0.9634373544480671\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 38, train_loss = 18.16656645387411, train_acc = 0.9640195621797858\n",
      "test Acc 0.9590316573556797:\n",
      "17th- epoch: 39, train_loss = 17.82177299633622, train_acc = 0.9653004191895669\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 40, train_loss = 17.491102542728186, train_acc = 0.9658826269212856\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 41, train_loss = 17.17452008649707, train_acc = 0.966581276199348\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 42, train_loss = 16.870854139328003, train_acc = 0.9671634839310667\n",
      "test Acc 0.9622905027932961:\n",
      "17th- epoch: 43, train_loss = 16.578063506633043, train_acc = 0.9678621332091291\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 44, train_loss = 16.295872375369072, train_acc = 0.9686772240335352\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 45, train_loss = 16.02368950843811, train_acc = 0.9694923148579413\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 46, train_loss = 15.760780714452267, train_acc = 0.9701909641360037\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 47, train_loss = 15.506513569504023, train_acc = 0.9706567303213787\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 48, train_loss = 15.25990043580532, train_acc = 0.9708896134140661\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 49, train_loss = 15.02084818482399, train_acc = 0.9715882626921285\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 50, train_loss = 14.788537986576557, train_acc = 0.9719375873311598\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 51, train_loss = 14.5630277171731, train_acc = 0.9720540288775035\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 52, train_loss = 14.344290753826499, train_acc = 0.9724033535165347\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 53, train_loss = 14.132251895964146, train_acc = 0.9727526781555659\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 54, train_loss = 13.926270483061671, train_acc = 0.9733348858872846\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 55, train_loss = 13.726040832698345, train_acc = 0.9738006520726595\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 56, train_loss = 13.531145883724093, train_acc = 0.974033535165347\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 57, train_loss = 13.340822538360953, train_acc = 0.9741499767116907\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 58, train_loss = 13.155216163024306, train_acc = 0.9741499767116907\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 59, train_loss = 12.9746103733778, train_acc = 0.9746157428970657\n",
      "test Acc 0.9664804469273743:\n",
      "17th- epoch: 60, train_loss = 12.79877095296979, train_acc = 0.9749650675360969\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 61, train_loss = 12.62707532569766, train_acc = 0.975314392175128\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 62, train_loss = 12.459704801440239, train_acc = 0.9754308337214718\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 63, train_loss = 12.296003814786673, train_acc = 0.9755472752678156\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 64, train_loss = 12.13636652007699, train_acc = 0.9756637168141593\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 65, train_loss = 11.980414398014545, train_acc = 0.9763623660922217\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 66, train_loss = 11.828098755329847, train_acc = 0.9767116907312529\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 67, train_loss = 11.679198045283556, train_acc = 0.9768281322775967\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 68, train_loss = 11.533637247979641, train_acc = 0.9768281322775967\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 69, train_loss = 11.391333501785994, train_acc = 0.9769445738239404\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 70, train_loss = 11.251943528652191, train_acc = 0.9769445738239404\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 71, train_loss = 11.115595363080502, train_acc = 0.9771774569166278\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 72, train_loss = 10.98173421062529, train_acc = 0.9772938984629715\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 73, train_loss = 10.85056764446199, train_acc = 0.9775267815556591\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 74, train_loss = 10.721948767080903, train_acc = 0.9776432231020028\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 75, train_loss = 10.59613043628633, train_acc = 0.9776432231020028\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 76, train_loss = 10.472743077203631, train_acc = 0.9781089892873778\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 77, train_loss = 10.351875012740493, train_acc = 0.9786911970190965\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 78, train_loss = 10.233349708840251, train_acc = 0.9790405216581276\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 79, train_loss = 10.117030872032046, train_acc = 0.9790405216581276\n",
      "test Acc 0.9697392923649907:\n",
      "17th- epoch: 80, train_loss = 10.003082511946559, train_acc = 0.9792734047508151\n",
      "test Acc 0.9697392923649907:\n",
      "17th- epoch: 81, train_loss = 9.89142383262515, train_acc = 0.9792734047508151\n",
      "test Acc 0.9702048417132216:\n",
      "17th- epoch: 82, train_loss = 9.781858352944255, train_acc = 0.9795062878435026\n",
      "test Acc 0.9702048417132216:\n",
      "17th- epoch: 83, train_loss = 9.674143785610795, train_acc = 0.97973917093619\n",
      "test Acc 0.9702048417132216:\n",
      "17th- epoch: 84, train_loss = 9.568143615499139, train_acc = 0.9798556124825337\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 85, train_loss = 9.46403301693499, train_acc = 0.9799720540288775\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 86, train_loss = 9.361491069197655, train_acc = 0.9800884955752213\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 87, train_loss = 9.260778428986669, train_acc = 0.9804378202142524\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 88, train_loss = 9.161919347941875, train_acc = 0.9804378202142524\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 89, train_loss = 9.064474374055862, train_acc = 0.9805542617605962\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 90, train_loss = 8.968843381851912, train_acc = 0.9805542617605962\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 91, train_loss = 8.87503069639206, train_acc = 0.98067070330694\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 92, train_loss = 8.782952077686787, train_acc = 0.98067070330694\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 93, train_loss = 8.69248665496707, train_acc = 0.9807871448532837\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 94, train_loss = 8.603314228355885, train_acc = 0.9809035863996274\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 95, train_loss = 8.515696734189987, train_acc = 0.9810200279459711\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 96, train_loss = 8.429196026176214, train_acc = 0.9811364694923148\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 97, train_loss = 8.344327438622713, train_acc = 0.9813693525850024\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 98, train_loss = 8.26048843562603, train_acc = 0.9814857941313461\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 99, train_loss = 8.1780453491956, train_acc = 0.9814857941313461\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 100, train_loss = 8.09668643027544, train_acc = 0.9820680018630648\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 101, train_loss = 8.016760481521487, train_acc = 0.9821844434094085\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 102, train_loss = 7.937838742509484, train_acc = 0.9823008849557522\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 103, train_loss = 7.860182462260127, train_acc = 0.9824173265020959\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 104, train_loss = 7.783829661086202, train_acc = 0.9829995342338146\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 105, train_loss = 7.708431119099259, train_acc = 0.9828830926874709\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 106, train_loss = 7.6341669745743275, train_acc = 0.9829995342338146\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 107, train_loss = 7.561030589044094, train_acc = 0.9834653004191896\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 108, train_loss = 7.488788325339556, train_acc = 0.9835817419655333\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 109, train_loss = 7.4176610969007015, train_acc = 0.9838146250582208\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 110, train_loss = 7.347576890140772, train_acc = 0.9840475081509082\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 111, train_loss = 7.277997268363833, train_acc = 0.9842803912435957\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 112, train_loss = 7.209475390613079, train_acc = 0.9843968327899395\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 113, train_loss = 7.142035450786352, train_acc = 0.9845132743362832\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 114, train_loss = 7.075475495308638, train_acc = 0.9847461574289706\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 115, train_loss = 7.009959552437067, train_acc = 0.9848625989753144\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 116, train_loss = 6.945366259664297, train_acc = 0.9852119236143456\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 117, train_loss = 6.881645001471043, train_acc = 0.9852119236143456\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 118, train_loss = 6.818913657218218, train_acc = 0.9852119236143456\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 119, train_loss = 6.7569627575576305, train_acc = 0.985444806707033\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 120, train_loss = 6.695776708424091, train_acc = 0.985444806707033\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 121, train_loss = 6.635387057438493, train_acc = 0.9857941313460643\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 122, train_loss = 6.575989505276084, train_acc = 0.985910572892408\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 123, train_loss = 6.517216047272086, train_acc = 0.9860270144387517\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 124, train_loss = 6.459104185923934, train_acc = 0.9861434559850955\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 125, train_loss = 6.401476668193936, train_acc = 0.9861434559850955\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 126, train_loss = 6.344664983451366, train_acc = 0.9862598975314392\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 127, train_loss = 6.288764549419284, train_acc = 0.986376339077783\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 128, train_loss = 6.233753651380539, train_acc = 0.9864927806241267\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 129, train_loss = 6.179308475926518, train_acc = 0.9867256637168141\n",
      "test Acc 0.9753258845437617:\n",
      "17th- epoch: 130, train_loss = 6.1257546581327915, train_acc = 0.9868421052631579\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 131, train_loss = 6.072874657809734, train_acc = 0.9869585468095017\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 132, train_loss = 6.0206257198005915, train_acc = 0.9873078714485328\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 133, train_loss = 5.969159493222833, train_acc = 0.9878900791802515\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 134, train_loss = 5.918186012655497, train_acc = 0.9878900791802515\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 135, train_loss = 5.8679546639323235, train_acc = 0.9881229622729389\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 136, train_loss = 5.818315129727125, train_acc = 0.9882394038192828\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 137, train_loss = 5.769247882068157, train_acc = 0.9882394038192828\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 138, train_loss = 5.720870232209563, train_acc = 0.9883558453656265\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 139, train_loss = 5.673333479091525, train_acc = 0.9885887284583139\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 140, train_loss = 5.626433638855815, train_acc = 0.9888216115510013\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 141, train_loss = 5.580355599522591, train_acc = 0.9888216115510013\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 142, train_loss = 5.534780004993081, train_acc = 0.9888216115510013\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 143, train_loss = 5.489880131557584, train_acc = 0.9889380530973452\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 144, train_loss = 5.445529880002141, train_acc = 0.9889380530973452\n",
      "test Acc 0.9762569832402235:\n",
      "17th- epoch: 145, train_loss = 5.40193959698081, train_acc = 0.9889380530973452\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 146, train_loss = 5.358724826946855, train_acc = 0.9889380530973452\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 147, train_loss = 5.316223543137312, train_acc = 0.9892873777363763\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 148, train_loss = 5.274250918999314, train_acc = 0.9892873777363763\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 149, train_loss = 5.23282521404326, train_acc = 0.9895202608290639\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 150, train_loss = 5.1918521579355, train_acc = 0.9896367023754076\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 151, train_loss = 5.15152190066874, train_acc = 0.9896367023754076\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 152, train_loss = 5.111582120880485, train_acc = 0.9896367023754076\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 153, train_loss = 5.0722605446353555, train_acc = 0.989869585468095\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 154, train_loss = 5.033429850824177, train_acc = 0.989869585468095\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 155, train_loss = 4.994963268749416, train_acc = 0.9899860270144387\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 156, train_loss = 4.95690490026027, train_acc = 0.9899860270144387\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 157, train_loss = 4.919417570345104, train_acc = 0.9899860270144387\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 158, train_loss = 4.8824601555243134, train_acc = 0.9899860270144387\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 159, train_loss = 4.845567378215492, train_acc = 0.9901024685607824\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 160, train_loss = 4.808948299847543, train_acc = 0.99033535165347\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 161, train_loss = 4.773452325724065, train_acc = 0.9904517931998137\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 162, train_loss = 4.738310050219297, train_acc = 0.9905682347461574\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 163, train_loss = 4.703693054616451, train_acc = 0.990801117838845\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 164, train_loss = 4.669555760920048, train_acc = 0.990801117838845\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 165, train_loss = 4.635749293491244, train_acc = 0.9909175593851887\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 166, train_loss = 4.6025121519342065, train_acc = 0.9909175593851887\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 167, train_loss = 4.56967952568084, train_acc = 0.9911504424778761\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 168, train_loss = 4.5373117830604315, train_acc = 0.9911504424778761\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 169, train_loss = 4.505280210636556, train_acc = 0.9911504424778761\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 170, train_loss = 4.473749667406082, train_acc = 0.9911504424778761\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 171, train_loss = 4.442542471922934, train_acc = 0.9911504424778761\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 172, train_loss = 4.411721314303577, train_acc = 0.9911504424778761\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 173, train_loss = 4.381257536821067, train_acc = 0.9912668840242198\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 174, train_loss = 4.351264428347349, train_acc = 0.9912668840242198\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 175, train_loss = 4.321593008004129, train_acc = 0.9912668840242198\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 176, train_loss = 4.29227777197957, train_acc = 0.9913833255705635\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 177, train_loss = 4.2633852399885654, train_acc = 0.9914997671169073\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 178, train_loss = 4.234925731085241, train_acc = 0.9914997671169073\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 179, train_loss = 4.20656206458807, train_acc = 0.9914997671169073\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 180, train_loss = 4.178687605075538, train_acc = 0.9914997671169073\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 181, train_loss = 4.151224895380437, train_acc = 0.9914997671169073\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 182, train_loss = 4.123951037414372, train_acc = 0.9916162086632511\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 183, train_loss = 4.097092544659972, train_acc = 0.9916162086632511\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 184, train_loss = 4.070604659616947, train_acc = 0.9917326502095948\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 185, train_loss = 4.044434417039156, train_acc = 0.9918490917559385\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 186, train_loss = 4.018460891209543, train_acc = 0.9918490917559385\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 187, train_loss = 3.9930078238248825, train_acc = 0.9918490917559385\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 188, train_loss = 3.9677845099940896, train_acc = 0.9918490917559385\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 189, train_loss = 3.942773848772049, train_acc = 0.992081974848626\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 190, train_loss = 3.9181685941293836, train_acc = 0.992081974848626\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 191, train_loss = 3.8937872238457203, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 192, train_loss = 3.869768044911325, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 193, train_loss = 3.845890674740076, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 194, train_loss = 3.822450607083738, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 195, train_loss = 3.7991570318117738, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 196, train_loss = 3.776183164678514, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 197, train_loss = 3.7533776508644223, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 198, train_loss = 3.731076723895967, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 199, train_loss = 3.7087317556142807, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 200, train_loss = 3.6869850317016244, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 201, train_loss = 3.665231150574982, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 202, train_loss = 3.643871746957302, train_acc = 0.9921984163949698\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 203, train_loss = 3.6226060949265957, train_acc = 0.9924312994876572\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 204, train_loss = 3.6017774241045117, train_acc = 0.9924312994876572\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 205, train_loss = 3.5809550061821938, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 206, train_loss = 3.5604555471800268, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 207, train_loss = 3.5401437752880156, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 208, train_loss = 3.520197482313961, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 209, train_loss = 3.500299407634884, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 210, train_loss = 3.480696661863476, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 211, train_loss = 3.461237197276205, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 212, train_loss = 3.4421212202869356, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 213, train_loss = 3.423097460065037, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 214, train_loss = 3.4043572866357863, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 215, train_loss = 3.385813916567713, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 216, train_loss = 3.367449939250946, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 217, train_loss = 3.349266504868865, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 218, train_loss = 3.331263324711472, train_acc = 0.9927806241266884\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 219, train_loss = 3.313525907229632, train_acc = 0.9927806241266884\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 220, train_loss = 3.2957518654875457, train_acc = 0.9927806241266884\n",
      "test Acc 0.9776536312849162:\n",
      "17th- epoch: 221, train_loss = 3.278430819977075, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 222, train_loss = 3.26124689495191, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 223, train_loss = 3.244073469657451, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 224, train_loss = 3.227339992299676, train_acc = 0.9931299487657196\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 225, train_loss = 3.2104817857034504, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 226, train_loss = 3.194022706244141, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 227, train_loss = 3.177616810426116, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 228, train_loss = 3.1615462261252105, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 229, train_loss = 3.1453926153481007, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 230, train_loss = 3.1295773037709296, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 231, train_loss = 3.1137918061576784, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 232, train_loss = 3.0982720465399325, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 233, train_loss = 3.0828802357427776, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 234, train_loss = 3.067684341687709, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 235, train_loss = 3.0525177964009345, train_acc = 0.9934792734047508\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 236, train_loss = 3.037694651633501, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 237, train_loss = 3.0228977953083813, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 238, train_loss = 3.0082909241318703, train_acc = 0.9935957149510946\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 239, train_loss = 2.9937796276062727, train_acc = 0.9939450395901258\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 240, train_loss = 2.9793946999125183, train_acc = 0.9939450395901258\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 241, train_loss = 2.9652088042348623, train_acc = 0.9939450395901258\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 242, train_loss = 2.9511472866870463, train_acc = 0.9939450395901258\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 243, train_loss = 2.9371652300469577, train_acc = 0.9939450395901258\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 244, train_loss = 2.9234019313007593, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 245, train_loss = 2.9097436405718327, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 246, train_loss = 2.8961669080890715, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 247, train_loss = 2.8828468662686646, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 248, train_loss = 2.869452403858304, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 249, train_loss = 2.856443156953901, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 250, train_loss = 2.843347060959786, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 251, train_loss = 2.8305557086132467, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 252, train_loss = 2.817723802756518, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 253, train_loss = 2.805231081787497, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 254, train_loss = 2.7926555704325438, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 255, train_loss = 2.780358273535967, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 256, train_loss = 2.7680205847136676, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 257, train_loss = 2.755965366959572, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 258, train_loss = 2.743963861372322, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 259, train_loss = 2.7320745922625065, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 260, train_loss = 2.720326617360115, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 261, train_loss = 2.708676724229008, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 262, train_loss = 2.6970795788802207, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 263, train_loss = 2.6857795156538486, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 264, train_loss = 2.6744168885052204, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 265, train_loss = 2.663217129651457, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 266, train_loss = 2.6521521410904825, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 267, train_loss = 2.641167914029211, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 268, train_loss = 2.6303636259399354, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 269, train_loss = 2.6195036694407463, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 270, train_loss = 2.6088785170577466, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 271, train_loss = 2.598219595849514, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 272, train_loss = 2.5877048685215414, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 273, train_loss = 2.5773634486831725, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 274, train_loss = 2.56696285167709, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 275, train_loss = 2.5569201447069645, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 276, train_loss = 2.546873388113454, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 277, train_loss = 2.536905474960804, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 278, train_loss = 2.5270093579310924, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 279, train_loss = 2.517371228663251, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 280, train_loss = 2.50766093400307, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 281, train_loss = 2.498128102393821, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 282, train_loss = 2.4887488943058997, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 283, train_loss = 2.479411395965144, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 284, train_loss = 2.4701572011690587, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 285, train_loss = 2.4610136908013374, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 286, train_loss = 2.4518757064361125, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 287, train_loss = 2.442873351275921, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 288, train_loss = 2.4339770190417767, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 289, train_loss = 2.4251981787383556, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 290, train_loss = 2.4164323892910033, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 291, train_loss = 2.4078255456406623, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 292, train_loss = 2.399272008566186, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 293, train_loss = 2.39071686565876, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 294, train_loss = 2.3824283704161644, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 295, train_loss = 2.3740319672506303, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 296, train_loss = 2.3658240127842873, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 297, train_loss = 2.3577089719474316, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 298, train_loss = 2.349584646522999, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 299, train_loss = 2.341603087959811, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 300, train_loss = 2.333688526181504, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 301, train_loss = 2.325813685776666, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 302, train_loss = 2.318182111950591, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 303, train_loss = 2.310373816639185, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 304, train_loss = 2.3028143246192485, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 305, train_loss = 2.2953088842332363, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 306, train_loss = 2.287775815697387, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 307, train_loss = 2.2804504830855876, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 308, train_loss = 2.2731141049880534, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 309, train_loss = 2.265858097700402, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 310, train_loss = 2.2586293295025826, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 311, train_loss = 2.251596203772351, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 312, train_loss = 2.2445088054519147, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 313, train_loss = 2.2375044636428356, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 314, train_loss = 2.2306713003199548, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 315, train_loss = 2.2237949408590794, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 316, train_loss = 2.217003509402275, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 317, train_loss = 2.2102824065368623, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 318, train_loss = 2.2036250308156013, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 319, train_loss = 2.1970249463338405, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 320, train_loss = 2.190507971914485, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 321, train_loss = 2.1839973616879433, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 322, train_loss = 2.1775904695969075, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 323, train_loss = 2.171310768695548, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 324, train_loss = 2.1649621464312077, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 325, train_loss = 2.1587353460490704, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 326, train_loss = 2.1525541592855006, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 327, train_loss = 2.1464938793797046, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 328, train_loss = 2.1403735764324665, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 329, train_loss = 2.134328792570159, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 330, train_loss = 2.1284052543342113, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 331, train_loss = 2.1224970284383744, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 332, train_loss = 2.116681133629754, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 333, train_loss = 2.1108316108584404, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 334, train_loss = 2.1051283527631313, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 335, train_loss = 2.0994413930457085, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 336, train_loss = 2.093757809372619, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 337, train_loss = 2.0882798954844475, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 338, train_loss = 2.0826106269378215, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 339, train_loss = 2.07722274097614, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 340, train_loss = 2.071776629658416, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 341, train_loss = 2.066359071759507, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 342, train_loss = 2.0610460799653083, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 343, train_loss = 2.055720857111737, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 344, train_loss = 2.0504979204852134, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 345, train_loss = 2.0453058804851025, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 346, train_loss = 2.0401331272441894, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 347, train_loss = 2.0350283719599247, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 348, train_loss = 2.0299085180740803, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 349, train_loss = 2.0249222740530968, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 350, train_loss = 2.0199268523138016, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 351, train_loss = 2.0149824221152812, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 352, train_loss = 2.0100575536489487, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 353, train_loss = 2.005269418237731, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 354, train_loss = 2.0003796678502113, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 355, train_loss = 1.9956277894088998, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 356, train_loss = 1.9908620616188273, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 357, train_loss = 1.9862183704972267, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 358, train_loss = 1.981510060490109, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 359, train_loss = 1.9769238978624344, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 360, train_loss = 1.9723391880979761, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 361, train_loss = 1.9678022315492854, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 362, train_loss = 1.9632113924017176, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 363, train_loss = 1.9587910895934328, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 364, train_loss = 1.954381818533875, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 365, train_loss = 1.949925878434442, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 366, train_loss = 1.9456193894147873, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 367, train_loss = 1.9412771513452753, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 368, train_loss = 1.9370101852109656, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 369, train_loss = 1.9327287586638704, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 370, train_loss = 1.928538010804914, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 371, train_loss = 1.9242807775735855, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 372, train_loss = 1.9201948469271883, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 373, train_loss = 1.9160499585559592, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 374, train_loss = 1.9119680920848623, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 375, train_loss = 1.907924616127275, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 376, train_loss = 1.9038594091543928, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 377, train_loss = 1.899906569509767, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 378, train_loss = 1.8958758190274239, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 379, train_loss = 1.8919870654353872, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 380, train_loss = 1.8880776999285445, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 381, train_loss = 1.8842317188391462, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 382, train_loss = 1.8803957005729899, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 383, train_loss = 1.8765667838742957, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 384, train_loss = 1.8727996982634068, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 385, train_loss = 1.8690361367771402, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 386, train_loss = 1.8653045272221789, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 387, train_loss = 1.8616623133420944, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 388, train_loss = 1.8579672587802634, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 389, train_loss = 1.8543641939759254, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 390, train_loss = 1.8507439655950293, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 391, train_loss = 1.8472069265553728, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 392, train_loss = 1.8435724936425686, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 393, train_loss = 1.8400961073348299, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 394, train_loss = 1.8365891227731481, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 395, train_loss = 1.833139674155973, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 396, train_loss = 1.8297030739486217, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 397, train_loss = 1.8262691957643256, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 398, train_loss = 1.8229101510951295, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 399, train_loss = 1.8195094602415338, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 400, train_loss = 1.8161893052747473, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "17th- epoch: 401, train_loss = 1.812828604131937, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 402, train_loss = 1.8095438046148047, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 403, train_loss = 1.806294952868484, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 404, train_loss = 1.8030764423310757, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 405, train_loss = 1.7997954785823822, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 406, train_loss = 1.7966132065048441, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 407, train_loss = 1.7934594614198431, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 408, train_loss = 1.790331439464353, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 409, train_loss = 1.7872042072704062, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 410, train_loss = 1.7840818477561697, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 411, train_loss = 1.7809899797430262, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 412, train_loss = 1.7779557419707999, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 413, train_loss = 1.7748732218751684, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 414, train_loss = 1.7718530049314722, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 415, train_loss = 1.7688627379247919, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 416, train_loss = 1.7658663988113403, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 417, train_loss = 1.7629201436648145, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 418, train_loss = 1.7600736878812313, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 419, train_loss = 1.7571400267770514, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 420, train_loss = 1.7542486861348152, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 421, train_loss = 1.7514000063529238, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 422, train_loss = 1.7485012151300907, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 423, train_loss = 1.7457081228494644, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 424, train_loss = 1.7428740611067042, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 425, train_loss = 1.7401275858283043, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 426, train_loss = 1.7373607084155083, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 427, train_loss = 1.7346179708838463, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 428, train_loss = 1.7319223135709763, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 429, train_loss = 1.7291834863135591, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 430, train_loss = 1.7264732035109773, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 431, train_loss = 1.7238258036086336, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 432, train_loss = 1.7211273784050718, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 433, train_loss = 1.7185272065689787, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 434, train_loss = 1.7159169092774391, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 435, train_loss = 1.713330569327809, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 436, train_loss = 1.7107631774852052, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 437, train_loss = 1.7081948319682851, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 438, train_loss = 1.7056989930570126, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 439, train_loss = 1.7031459944555536, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 440, train_loss = 1.7005850585410371, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 441, train_loss = 1.6981117315590382, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 442, train_loss = 1.6956802606582642, train_acc = 0.9958081043316255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 443, train_loss = 1.693158665089868, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 444, train_loss = 1.6907601319253445, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 445, train_loss = 1.6883280239999294, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 446, train_loss = 1.6859223060309887, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 447, train_loss = 1.6835352070629597, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 448, train_loss = 1.6811448546359316, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 449, train_loss = 1.678807683289051, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 450, train_loss = 1.6764094704994932, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 451, train_loss = 1.6741318901767954, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 452, train_loss = 1.6718708971748129, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 453, train_loss = 1.6695143257966265, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 454, train_loss = 1.667216052650474, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 455, train_loss = 1.6649416573345661, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 456, train_loss = 1.6627172554726712, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 457, train_loss = 1.660463725507725, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 458, train_loss = 1.6582184160943143, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 459, train_loss = 1.656000943214167, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 460, train_loss = 1.6537793626193888, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 461, train_loss = 1.651618501811754, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 462, train_loss = 1.6494748604600318, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 463, train_loss = 1.6472514781053178, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 464, train_loss = 1.6451242615585215, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 465, train_loss = 1.6430565429036506, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 466, train_loss = 1.6409096419811249, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 467, train_loss = 1.6388278752565384, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 468, train_loss = 1.6367166017298587, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 469, train_loss = 1.6346432280843146, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 470, train_loss = 1.6325839062337764, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 471, train_loss = 1.630512561649084, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 472, train_loss = 1.6284923776984215, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 473, train_loss = 1.626462082087528, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 474, train_loss = 1.624532449990511, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 475, train_loss = 1.6225180961191654, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 476, train_loss = 1.620493223250378, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 477, train_loss = 1.6185519297723658, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 478, train_loss = 1.6165803844924085, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 479, train_loss = 1.6146556213498116, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 480, train_loss = 1.61270447447896, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 481, train_loss = 1.6107698529958725, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 482, train_loss = 1.608867825299967, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 483, train_loss = 1.606982797384262, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 484, train_loss = 1.6051434787805192, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 485, train_loss = 1.6032158322632313, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 486, train_loss = 1.6013541991706006, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 487, train_loss = 1.5995182655751705, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 488, train_loss = 1.59762904047966, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 489, train_loss = 1.5958545704488643, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 490, train_loss = 1.5940972876851447, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 491, train_loss = 1.5922110813553445, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 492, train_loss = 1.590469076007139, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 493, train_loss = 1.588657519489061, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 494, train_loss = 1.586949173361063, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 495, train_loss = 1.5851287133991718, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 496, train_loss = 1.5833403604920022, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 497, train_loss = 1.581669456034433, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 498, train_loss = 1.5799482154543512, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "17th- epoch: 499, train_loss = 1.5781964709167369, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████▋                              | 17/30 [1:52:57<1:26:15, 398.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "18th- epoch: 0, train_loss = 274.7224613428116, train_acc = 0.43968327899394505\n",
      "test Acc 0.48696461824953446:\n",
      "18th- epoch: 1, train_loss = 210.77077901363373, train_acc = 0.4896367023754076\n",
      "test Acc 0.49534450651769085:\n",
      "18th- epoch: 2, train_loss = 169.3545904159546, train_acc = 0.5190964136003726\n",
      "test Acc 0.5516759776536313:\n",
      "18th- epoch: 3, train_loss = 145.42279851436615, train_acc = 0.6476478807638566\n",
      "test Acc 0.7006517690875232:\n",
      "18th- epoch: 4, train_loss = 126.38734424114227, train_acc = 0.7136702375407545\n",
      "test Acc 0.7402234636871509:\n",
      "18th- epoch: 5, train_loss = 110.13836577534676, train_acc = 0.7392873777363763\n",
      "test Acc 0.7588454376163873:\n",
      "18th- epoch: 6, train_loss = 96.5242147743702, train_acc = 0.7775966464834653\n",
      "test Acc 0.8035381750465549:\n",
      "18th- epoch: 7, train_loss = 85.17172473669052, train_acc = 0.8220773171867722\n",
      "test Acc 0.8337988826815642:\n",
      "18th- epoch: 8, train_loss = 75.55671966075897, train_acc = 0.8478108989287377\n",
      "test Acc 0.861731843575419:\n",
      "18th- epoch: 9, train_loss = 67.36774790287018, train_acc = 0.8685374941779227\n",
      "test Acc 0.8770949720670391:\n",
      "18th- epoch: 10, train_loss = 60.446025639772415, train_acc = 0.8802980903586399\n",
      "test Acc 0.8850093109869647:\n",
      "18th- epoch: 11, train_loss = 54.68411111831665, train_acc = 0.88996273870517\n",
      "test Acc 0.8929236499068901:\n",
      "18th- epoch: 12, train_loss = 49.925235733389854, train_acc = 0.8968327899394504\n",
      "test Acc 0.8985102420856611:\n",
      "18th- epoch: 13, train_loss = 45.97090841829777, train_acc = 0.9064974382859804\n",
      "test Acc 0.9124767225325885:\n",
      "18th- epoch: 14, train_loss = 42.648005336523056, train_acc = 0.9245458779692595\n",
      "test Acc 0.9292364990689013:\n",
      "18th- epoch: 15, train_loss = 39.834221348166466, train_acc = 0.9344434094084769\n",
      "test Acc 0.9348230912476723:\n",
      "18th- epoch: 16, train_loss = 37.422605380415916, train_acc = 0.9387517466231952\n",
      "test Acc 0.9380819366852886:\n",
      "18th- epoch: 17, train_loss = 35.33404994010925, train_acc = 0.9420121099208197\n",
      "test Acc 0.9394785847299814:\n",
      "18th- epoch: 18, train_loss = 33.51129621267319, train_acc = 0.9438751746623195\n",
      "test Acc 0.9394785847299814:\n",
      "18th- epoch: 19, train_loss = 31.90634696930647, train_acc = 0.9462040055891943\n",
      "test Acc 0.9418063314711359:\n",
      "18th- epoch: 20, train_loss = 30.48115959018469, train_acc = 0.9479506287843502\n",
      "test Acc 0.9441340782122905:\n",
      "18th- epoch: 21, train_loss = 29.207391008734703, train_acc = 0.9501630181648812\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 22, train_loss = 28.06043780595064, train_acc = 0.952026082906381\n",
      "test Acc 0.9464618249534451:\n",
      "18th- epoch: 23, train_loss = 27.024826668202877, train_acc = 0.9537727061015371\n",
      "test Acc 0.9473929236499069:\n",
      "18th- epoch: 24, train_loss = 26.085146382451057, train_acc = 0.9545877969259432\n",
      "test Acc 0.9501862197392924:\n",
      "18th- epoch: 25, train_loss = 25.229087308049202, train_acc = 0.9565673032137867\n",
      "test Acc 0.9515828677839852:\n",
      "18th- epoch: 26, train_loss = 24.445461712777615, train_acc = 0.9574988355845365\n",
      "test Acc 0.952048417132216:\n",
      "18th- epoch: 27, train_loss = 23.724490210413933, train_acc = 0.9585468095016302\n",
      "test Acc 0.9529795158286778:\n",
      "18th- epoch: 28, train_loss = 23.056803930550814, train_acc = 0.9595947834187238\n",
      "test Acc 0.9543761638733705:\n",
      "18th- epoch: 29, train_loss = 22.43702545762062, train_acc = 0.9602934326967862\n",
      "test Acc 0.9557728119180633:\n",
      "18th- epoch: 30, train_loss = 21.859190441668034, train_acc = 0.9602934326967862\n",
      "test Acc 0.9567039106145251:\n",
      "18th- epoch: 31, train_loss = 21.319356210529804, train_acc = 0.9609920819748486\n",
      "test Acc 0.9567039106145251:\n",
      "18th- epoch: 32, train_loss = 20.812831860035658, train_acc = 0.9609920819748486\n",
      "test Acc 0.957635009310987:\n",
      "18th- epoch: 33, train_loss = 20.33617064729333, train_acc = 0.9615742897065673\n",
      "test Acc 0.9581005586592178:\n",
      "18th- epoch: 34, train_loss = 19.885736256837845, train_acc = 0.9620400558919422\n",
      "test Acc 0.9585661080074488:\n",
      "18th- epoch: 35, train_loss = 19.45950111746788, train_acc = 0.9623893805309734\n",
      "test Acc 0.9590316573556797:\n",
      "18th- epoch: 36, train_loss = 19.05514057725668, train_acc = 0.9635537959944108\n",
      "test Acc 0.9599627560521415:\n",
      "18th- epoch: 37, train_loss = 18.670598194003105, train_acc = 0.9641360037261295\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 38, train_loss = 18.304445389658213, train_acc = 0.9648346530041919\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 39, train_loss = 17.95486993715167, train_acc = 0.9648346530041919\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 40, train_loss = 17.62064877524972, train_acc = 0.9657661853749417\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 41, train_loss = 17.30081244185567, train_acc = 0.9668141592920354\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 42, train_loss = 16.993614621460438, train_acc = 0.9673963670237541\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 43, train_loss = 16.69803672656417, train_acc = 0.9680950163018165\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 44, train_loss = 16.41363448649645, train_acc = 0.9690265486725663\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 45, train_loss = 16.140016242861748, train_acc = 0.9694923148579413\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 46, train_loss = 15.875895906239748, train_acc = 0.9697251979506288\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 47, train_loss = 15.621021799743176, train_acc = 0.9699580810433163\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 48, train_loss = 15.374984599649906, train_acc = 0.9703074056823474\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 49, train_loss = 15.137062687426805, train_acc = 0.970540288775035\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 50, train_loss = 14.906955227255821, train_acc = 0.9713553795994411\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 51, train_loss = 14.68433078378439, train_acc = 0.9720540288775035\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 52, train_loss = 14.468495689332485, train_acc = 0.972286911970191\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 53, train_loss = 14.25934960320592, train_acc = 0.972286911970191\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 54, train_loss = 14.05626281350851, train_acc = 0.9731020027945971\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 55, train_loss = 13.858986230567098, train_acc = 0.9731020027945971\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 56, train_loss = 13.667221209034324, train_acc = 0.9732184443409408\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 57, train_loss = 13.480503145605326, train_acc = 0.9735677689799721\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 58, train_loss = 13.298697980120778, train_acc = 0.9735677689799721\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 59, train_loss = 13.121896674856544, train_acc = 0.974033535165347\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 60, train_loss = 12.949923723936081, train_acc = 0.9742664182580345\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 61, train_loss = 12.78220946714282, train_acc = 0.9744993013507219\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 62, train_loss = 12.618886545300484, train_acc = 0.9749650675360969\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 63, train_loss = 12.459665194153786, train_acc = 0.9749650675360969\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 64, train_loss = 12.30399265885353, train_acc = 0.975314392175128\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 65, train_loss = 12.15114101395011, train_acc = 0.9755472752678156\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 66, train_loss = 12.002034611999989, train_acc = 0.9755472752678156\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 67, train_loss = 11.856775660067797, train_acc = 0.9761294829995343\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 68, train_loss = 11.714754279702902, train_acc = 0.9763623660922217\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 69, train_loss = 11.575889095664024, train_acc = 0.9768281322775967\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 70, train_loss = 11.440208107233047, train_acc = 0.9769445738239404\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 71, train_loss = 11.307421613484621, train_acc = 0.9772938984629715\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 72, train_loss = 11.177386496216059, train_acc = 0.9775267815556591\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 73, train_loss = 11.050295524299145, train_acc = 0.9777596646483465\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 74, train_loss = 10.925947681069374, train_acc = 0.977992547741034\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 75, train_loss = 10.804147526621819, train_acc = 0.9785747554727526\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 76, train_loss = 10.684577714651823, train_acc = 0.9785747554727526\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 77, train_loss = 10.56732388958335, train_acc = 0.9789240801117839\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 78, train_loss = 10.452298793941736, train_acc = 0.9790405216581276\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 79, train_loss = 10.33953238837421, train_acc = 0.9792734047508151\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 80, train_loss = 10.22905794903636, train_acc = 0.9792734047508151\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 81, train_loss = 10.120360219851136, train_acc = 0.9792734047508151\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 82, train_loss = 10.013824557885528, train_acc = 0.9795062878435026\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 83, train_loss = 9.908973421901464, train_acc = 0.9796227293898463\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 84, train_loss = 9.805936340242624, train_acc = 0.9796227293898463\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 85, train_loss = 9.704650660976768, train_acc = 0.9798556124825337\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 86, train_loss = 9.605171002447605, train_acc = 0.9799720540288775\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 87, train_loss = 9.507065914571285, train_acc = 0.980204937121565\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 88, train_loss = 9.410691849887371, train_acc = 0.9803213786679087\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 89, train_loss = 9.315755996853113, train_acc = 0.9804378202142524\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 90, train_loss = 9.222175922244787, train_acc = 0.9807871448532837\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 91, train_loss = 9.130135975778103, train_acc = 0.9807871448532837\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 92, train_loss = 9.039481859654188, train_acc = 0.9807871448532837\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 93, train_loss = 8.950208902359009, train_acc = 0.9810200279459711\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 94, train_loss = 8.862352132797241, train_acc = 0.9812529110386586\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 95, train_loss = 8.775595679879189, train_acc = 0.9816022356776898\n",
      "test Acc 0.9706703910614525:\n",
      "18th- epoch: 96, train_loss = 8.69020751491189, train_acc = 0.981951560316721\n",
      "test Acc 0.9706703910614525:\n",
      "18th- epoch: 97, train_loss = 8.606016732752323, train_acc = 0.9823008849557522\n",
      "test Acc 0.9706703910614525:\n",
      "18th- epoch: 98, train_loss = 8.523176770657301, train_acc = 0.9826502095947834\n",
      "test Acc 0.9706703910614525:\n",
      "18th- epoch: 99, train_loss = 8.441724963486195, train_acc = 0.9827666511411272\n",
      "test Acc 0.9706703910614525:\n",
      "18th- epoch: 100, train_loss = 8.361350206658244, train_acc = 0.9828830926874709\n",
      "test Acc 0.9706703910614525:\n",
      "18th- epoch: 101, train_loss = 8.282076867297292, train_acc = 0.9829995342338146\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 102, train_loss = 8.203767525032163, train_acc = 0.9829995342338146\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 103, train_loss = 8.126671036705375, train_acc = 0.9833488588728458\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 104, train_loss = 8.050214121118188, train_acc = 0.9839310666045645\n",
      "test Acc 0.9711359404096834:\n",
      "18th- epoch: 105, train_loss = 7.9749857522547245, train_acc = 0.9839310666045645\n",
      "test Acc 0.9716014897579144:\n",
      "18th- epoch: 106, train_loss = 7.900682063773274, train_acc = 0.984163949697252\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 107, train_loss = 7.827292328700423, train_acc = 0.984163949697252\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 108, train_loss = 7.7553614266216755, train_acc = 0.9842803912435957\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 109, train_loss = 7.6843355987221, train_acc = 0.9842803912435957\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 110, train_loss = 7.61442856118083, train_acc = 0.9843968327899395\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 111, train_loss = 7.5452982019633055, train_acc = 0.9843968327899395\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 112, train_loss = 7.477129492908716, train_acc = 0.9845132743362832\n",
      "test Acc 0.9725325884543762:\n",
      "18th- epoch: 113, train_loss = 7.40984820201993, train_acc = 0.9847461574289706\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 114, train_loss = 7.343135584145784, train_acc = 0.9848625989753144\n",
      "test Acc 0.972998137802607:\n",
      "18th- epoch: 115, train_loss = 7.277099562808871, train_acc = 0.9848625989753144\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 116, train_loss = 7.212354250252247, train_acc = 0.9849790405216581\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 117, train_loss = 7.148296970874071, train_acc = 0.9849790405216581\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 118, train_loss = 7.085225280374289, train_acc = 0.9850954820680019\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 119, train_loss = 7.02284119464457, train_acc = 0.9852119236143456\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 120, train_loss = 6.961439719423652, train_acc = 0.9853283651606893\n",
      "test Acc 0.9748603351955307:\n",
      "18th- epoch: 121, train_loss = 6.900882337242365, train_acc = 0.9855612482533768\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 122, train_loss = 6.8409726824611425, train_acc = 0.9856776897997206\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 123, train_loss = 6.78161358460784, train_acc = 0.985910572892408\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 124, train_loss = 6.72156447917223, train_acc = 0.9861434559850955\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 125, train_loss = 6.661726586520672, train_acc = 0.9862598975314392\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 126, train_loss = 6.603456972166896, train_acc = 0.986376339077783\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 127, train_loss = 6.546485176309943, train_acc = 0.9864927806241267\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 128, train_loss = 6.490259388461709, train_acc = 0.9868421052631579\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 129, train_loss = 6.435231203213334, train_acc = 0.9869585468095017\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 130, train_loss = 6.380962252616882, train_acc = 0.9870749883558454\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 131, train_loss = 6.327269254252315, train_acc = 0.9870749883558454\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 132, train_loss = 6.274352079257369, train_acc = 0.9873078714485328\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 133, train_loss = 6.222066346555948, train_acc = 0.9873078714485328\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 134, train_loss = 6.170544253662229, train_acc = 0.9874243129948765\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 135, train_loss = 6.119621727615595, train_acc = 0.9874243129948765\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 136, train_loss = 6.069428892806172, train_acc = 0.9874243129948765\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 137, train_loss = 6.019839962944388, train_acc = 0.9876571960875641\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 138, train_loss = 5.970955278724432, train_acc = 0.9876571960875641\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 139, train_loss = 5.922738226130605, train_acc = 0.9876571960875641\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 140, train_loss = 5.874949522316456, train_acc = 0.9877736376339078\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 141, train_loss = 5.827945793047547, train_acc = 0.9878900791802515\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 142, train_loss = 5.781328860670328, train_acc = 0.9878900791802515\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 143, train_loss = 5.735468477010727, train_acc = 0.9878900791802515\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 144, train_loss = 5.690041335299611, train_acc = 0.9878900791802515\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 145, train_loss = 5.645237436518073, train_acc = 0.9880065207265952\n",
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 146, train_loss = 5.601028369739652, train_acc = 0.9881229622729389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9753258845437617:\n",
      "18th- epoch: 147, train_loss = 5.557195609435439, train_acc = 0.9883558453656265\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 148, train_loss = 5.514023037627339, train_acc = 0.9884722869119702\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 149, train_loss = 5.471493383869529, train_acc = 0.9885887284583139\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 150, train_loss = 5.4295289143919945, train_acc = 0.9885887284583139\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 151, train_loss = 5.387852419167757, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 152, train_loss = 5.347009288147092, train_acc = 0.9889380530973452\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 153, train_loss = 5.306446546688676, train_acc = 0.9890544946436889\n",
      "test Acc 0.9762569832402235:\n",
      "18th- epoch: 154, train_loss = 5.266363924369216, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 155, train_loss = 5.227060528472066, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 156, train_loss = 5.187985362485051, train_acc = 0.9895202608290639\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 157, train_loss = 5.149445317685604, train_acc = 0.9896367023754076\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 158, train_loss = 5.111432816833258, train_acc = 0.9896367023754076\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 159, train_loss = 5.0739203710108995, train_acc = 0.989869585468095\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 160, train_loss = 5.036732982844114, train_acc = 0.989869585468095\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 161, train_loss = 5.000058518722653, train_acc = 0.989869585468095\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 162, train_loss = 4.963881444185972, train_acc = 0.9901024685607824\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 163, train_loss = 4.928251234814525, train_acc = 0.9901024685607824\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 164, train_loss = 4.892764305695891, train_acc = 0.9902189101071263\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 165, train_loss = 4.857829017564654, train_acc = 0.9902189101071263\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 166, train_loss = 4.8234399612993, train_acc = 0.9902189101071263\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 167, train_loss = 4.789282901212573, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 168, train_loss = 4.75573358591646, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 169, train_loss = 4.722588523291051, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 170, train_loss = 4.689790307544172, train_acc = 0.9904517931998137\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 171, train_loss = 4.65722137875855, train_acc = 0.9904517931998137\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 172, train_loss = 4.625356978736818, train_acc = 0.9904517931998137\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 173, train_loss = 4.593686560168862, train_acc = 0.9905682347461574\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 174, train_loss = 4.562470501288772, train_acc = 0.9905682347461574\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 175, train_loss = 4.53150789719075, train_acc = 0.990801117838845\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 176, train_loss = 4.501072070561349, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 177, train_loss = 4.470959804020822, train_acc = 0.9911504424778761\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 178, train_loss = 4.441211123950779, train_acc = 0.9912668840242198\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 179, train_loss = 4.4117752043530345, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 180, train_loss = 4.382682437077165, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 181, train_loss = 4.354004838503897, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 182, train_loss = 4.325533208437264, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 183, train_loss = 4.2974705854430795, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 184, train_loss = 4.269792430102825, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 185, train_loss = 4.242361469194293, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 186, train_loss = 4.2151593482121825, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 187, train_loss = 4.188464375212789, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 188, train_loss = 4.161904230713844, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 189, train_loss = 4.1356406677514315, train_acc = 0.9917326502095948\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 190, train_loss = 4.109819941222668, train_acc = 0.9918490917559385\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 191, train_loss = 4.084184348583221, train_acc = 0.9918490917559385\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 192, train_loss = 4.058862940408289, train_acc = 0.9918490917559385\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 193, train_loss = 4.0338486498221755, train_acc = 0.9918490917559385\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 194, train_loss = 4.0090887397527695, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 195, train_loss = 3.984638308174908, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 196, train_loss = 3.960481976158917, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 197, train_loss = 3.9365037782117724, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 198, train_loss = 3.912939477711916, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 199, train_loss = 3.889576549641788, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 200, train_loss = 3.866458215750754, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 201, train_loss = 3.843654458411038, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 202, train_loss = 3.820937362499535, train_acc = 0.9921984163949698\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 203, train_loss = 3.7986653288826346, train_acc = 0.9921984163949698\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 204, train_loss = 3.776608136482537, train_acc = 0.9921984163949698\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 205, train_loss = 3.754678479395807, train_acc = 0.9921984163949698\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 206, train_loss = 3.7331164265051484, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 207, train_loss = 3.7116877222433686, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 208, train_loss = 3.690563646145165, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 209, train_loss = 3.6695949314162135, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 210, train_loss = 3.64897873532027, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 211, train_loss = 3.628298551775515, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 212, train_loss = 3.608117406256497, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 213, train_loss = 3.5879785614088178, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 214, train_loss = 3.568130196072161, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 215, train_loss = 3.548449474386871, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 216, train_loss = 3.528918285854161, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 217, train_loss = 3.5096596693620086, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 218, train_loss = 3.4907188722863793, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 219, train_loss = 3.471734275110066, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 220, train_loss = 3.453110014088452, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 221, train_loss = 3.4345779893919826, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 222, train_loss = 3.4161903597414494, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 223, train_loss = 3.3981214528903365, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 224, train_loss = 3.3801653115078807, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 225, train_loss = 3.362499645911157, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 226, train_loss = 3.3448515506461263, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 227, train_loss = 3.3274807082489133, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 228, train_loss = 3.3102923491969705, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 229, train_loss = 3.2931907856836915, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 230, train_loss = 3.2762586614117026, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 231, train_loss = 3.259436182677746, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 232, train_loss = 3.2430382780730724, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 233, train_loss = 3.2265002341009676, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 234, train_loss = 3.2103191800415516, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 235, train_loss = 3.194276411086321, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 236, train_loss = 3.178353783208877, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 237, train_loss = 3.162395013961941, train_acc = 0.9935957149510946\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 238, train_loss = 3.1468654074706137, train_acc = 0.9935957149510946\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 239, train_loss = 3.131212228909135, train_acc = 0.9935957149510946\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 240, train_loss = 3.1160641009919345, train_acc = 0.9935957149510946\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 241, train_loss = 3.1006353441625834, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 242, train_loss = 3.0854725912213326, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 243, train_loss = 3.070460529997945, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 244, train_loss = 3.055569380056113, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 245, train_loss = 3.040848980192095, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 246, train_loss = 3.0262969047762454, train_acc = 0.9937121564974383\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 247, train_loss = 3.0117398663423955, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 248, train_loss = 2.997402195353061, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 249, train_loss = 2.9833573140203953, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 250, train_loss = 2.969171946402639, train_acc = 0.9940614811364695\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 251, train_loss = 2.9551554820500314, train_acc = 0.9940614811364695\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 252, train_loss = 2.9415770028717816, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 253, train_loss = 2.927708037663251, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 254, train_loss = 2.914213499519974, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 255, train_loss = 2.900689424946904, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 256, train_loss = 2.8873380511067808, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 257, train_loss = 2.873879214283079, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 258, train_loss = 2.86079860990867, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 259, train_loss = 2.847442079335451, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 260, train_loss = 2.834418943617493, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 261, train_loss = 2.8215967901051044, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 262, train_loss = 2.808588369283825, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 263, train_loss = 2.795942446682602, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 264, train_loss = 2.783698420971632, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 265, train_loss = 2.771351983305067, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 266, train_loss = 2.759359572082758, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 267, train_loss = 2.7473298273980618, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 268, train_loss = 2.7354586347937584, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 269, train_loss = 2.7235725335776806, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 270, train_loss = 2.7120821215212345, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 271, train_loss = 2.700487154070288, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 272, train_loss = 2.688965210225433, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 273, train_loss = 2.677775400225073, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 274, train_loss = 2.6664681434631348, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 275, train_loss = 2.6555422791279852, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 276, train_loss = 2.6443839743733406, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 277, train_loss = 2.633560416754335, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 278, train_loss = 2.622728577349335, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 279, train_loss = 2.6120813847519457, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 280, train_loss = 2.601516069378704, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 281, train_loss = 2.591008371207863, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 282, train_loss = 2.5806368067860603, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 283, train_loss = 2.570262175053358, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 284, train_loss = 2.560045026242733, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 285, train_loss = 2.549998583737761, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 286, train_loss = 2.5399040677584708, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 287, train_loss = 2.530078563839197, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 288, train_loss = 2.5201397351920605, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 289, train_loss = 2.510436651762575, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 290, train_loss = 2.5008751465938985, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 291, train_loss = 2.491251517087221, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 292, train_loss = 2.4818658432923257, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 293, train_loss = 2.472496835049242, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 294, train_loss = 2.4632220081984997, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 295, train_loss = 2.454030932392925, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 296, train_loss = 2.444949379656464, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 297, train_loss = 2.4358719303272665, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 298, train_loss = 2.4269958226941526, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 299, train_loss = 2.4180200323462486, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 300, train_loss = 2.409412033855915, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 301, train_loss = 2.400669611990452, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 302, train_loss = 2.392130243126303, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 303, train_loss = 2.3835797957144678, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 304, train_loss = 2.375206768512726, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 305, train_loss = 2.366817543748766, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 306, train_loss = 2.358655928168446, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 307, train_loss = 2.35042267665267, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 308, train_loss = 2.342317695263773, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 309, train_loss = 2.3343647681176662, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 310, train_loss = 2.3263464458286762, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 311, train_loss = 2.3186528333462775, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 312, train_loss = 2.310662927571684, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 313, train_loss = 2.3030766285955906, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 314, train_loss = 2.2954325589817017, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 315, train_loss = 2.2877627585548908, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 316, train_loss = 2.280352681875229, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 317, train_loss = 2.273022926179692, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 318, train_loss = 2.265546263428405, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 319, train_loss = 2.258417173055932, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 320, train_loss = 2.251151407836005, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 321, train_loss = 2.2440581396222115, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 322, train_loss = 2.2369480319321156, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 323, train_loss = 2.23001500335522, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 324, train_loss = 2.2231008533854038, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 325, train_loss = 2.2161303733009845, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 326, train_loss = 2.209459309699014, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 327, train_loss = 2.2026401225011796, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 328, train_loss = 2.1960588071960956, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 329, train_loss = 2.189363570185378, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 330, train_loss = 2.1829523246269673, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 331, train_loss = 2.176393035799265, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 332, train_loss = 2.1699740302283317, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 333, train_loss = 2.1636768355965614, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 334, train_loss = 2.157274680910632, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 335, train_loss = 2.1512272220570594, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 336, train_loss = 2.1449883717577904, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 337, train_loss = 2.1388246926944703, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 338, train_loss = 2.132840880425647, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 339, train_loss = 2.1267730456311256, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 340, train_loss = 2.1209140431601554, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 341, train_loss = 2.1149288702290505, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 342, train_loss = 2.1091136187314987, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 343, train_loss = 2.1033300545532256, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 344, train_loss = 2.0976478320080787, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 345, train_loss = 2.0919304105918854, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 346, train_loss = 2.0862954545300454, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 347, train_loss = 2.0807551878970116, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 348, train_loss = 2.0751975912135094, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 349, train_loss = 2.0696897010784596, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 350, train_loss = 2.06425624829717, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 351, train_loss = 2.058875598013401, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 352, train_loss = 2.053468309342861, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 353, train_loss = 2.0483146857004613, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 354, train_loss = 2.043008005945012, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 355, train_loss = 2.0378684115130454, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 356, train_loss = 2.0326867115218192, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 357, train_loss = 2.027517868904397, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 358, train_loss = 2.022538486868143, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 359, train_loss = 2.0174392114859074, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 360, train_loss = 2.0126158494967967, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 361, train_loss = 2.007542363135144, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 362, train_loss = 2.002842793939635, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 363, train_loss = 1.997813194990158, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 364, train_loss = 1.9930699567776173, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 365, train_loss = 1.9883250046987087, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 366, train_loss = 1.9836085785645992, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 367, train_loss = 1.9788501833099872, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 368, train_loss = 1.974336615530774, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 369, train_loss = 1.969707202166319, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 370, train_loss = 1.9651098574977368, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 371, train_loss = 1.9606217506807297, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 372, train_loss = 1.956170693039894, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 373, train_loss = 1.95168595504947, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 374, train_loss = 1.9473006974440068, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 375, train_loss = 1.9428729328792542, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 376, train_loss = 1.9386248986702412, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 377, train_loss = 1.9343085996806622, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 378, train_loss = 1.9300624046009034, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 379, train_loss = 1.9257947716396302, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 380, train_loss = 1.9217170129995793, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 381, train_loss = 1.917411345988512, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 382, train_loss = 1.9134504224639386, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 383, train_loss = 1.9088202368002385, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 384, train_loss = 1.90506183472462, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 385, train_loss = 1.9008332826197147, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 386, train_loss = 1.8967896401882172, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 387, train_loss = 1.8930298064369708, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 388, train_loss = 1.8888597451150417, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 389, train_loss = 1.884857039898634, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 390, train_loss = 1.8813044305425137, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 391, train_loss = 1.877221391769126, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 392, train_loss = 1.8734320066869259, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 393, train_loss = 1.8698068622034043, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 394, train_loss = 1.86596858385019, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 395, train_loss = 1.8623164519667625, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 396, train_loss = 1.8584396939259022, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 397, train_loss = 1.855046099750325, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 398, train_loss = 1.851116232573986, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 399, train_loss = 1.8476331557612866, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 400, train_loss = 1.8440399467945099, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 401, train_loss = 1.8406289120903239, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 402, train_loss = 1.8370483927428722, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 403, train_loss = 1.8334086822578683, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 404, train_loss = 1.8302336459746584, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 405, train_loss = 1.8265459189424291, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 406, train_loss = 1.823143720626831, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 407, train_loss = 1.8198025859892368, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 408, train_loss = 1.816555997938849, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 409, train_loss = 1.8130896389484406, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 410, train_loss = 1.8097936237463728, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 411, train_loss = 1.8064870089292526, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 412, train_loss = 1.8031298220157623, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 413, train_loss = 1.7995681104948744, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 414, train_loss = 1.7965061254799366, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 415, train_loss = 1.793524251668714, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 416, train_loss = 1.7902817825088277, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 417, train_loss = 1.7871792005607858, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 418, train_loss = 1.7840791791677475, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 419, train_loss = 1.7808990180492401, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 420, train_loss = 1.777820703922771, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 421, train_loss = 1.774524318636395, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 422, train_loss = 1.7713745733490214, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 423, train_loss = 1.7683969475328922, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 424, train_loss = 1.7653798945248127, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 425, train_loss = 1.7626398181309924, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 426, train_loss = 1.7595694934716448, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 427, train_loss = 1.7565125599503517, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 428, train_loss = 1.7538041360676289, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 429, train_loss = 1.7508118264377117, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 430, train_loss = 1.7479866681387648, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 431, train_loss = 1.7450478622922674, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 432, train_loss = 1.7423181422054768, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 433, train_loss = 1.739460002630949, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 434, train_loss = 1.7367168813943863, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 435, train_loss = 1.733845543116331, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 436, train_loss = 1.7311907795956358, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 437, train_loss = 1.7284846591064706, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 438, train_loss = 1.7257418036460876, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 439, train_loss = 1.7230596989393234, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 440, train_loss = 1.7203974860021845, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 441, train_loss = 1.717695165425539, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 442, train_loss = 1.7150957994163036, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 443, train_loss = 1.712434258311987, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 444, train_loss = 1.7099529864499345, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 445, train_loss = 1.7073837394127622, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 446, train_loss = 1.7046539932489395, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 447, train_loss = 1.7023165685823187, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 448, train_loss = 1.699809331446886, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 449, train_loss = 1.6971984120318666, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 450, train_loss = 1.6948241206118837, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 451, train_loss = 1.6923434709897265, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 452, train_loss = 1.6898359867045656, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 453, train_loss = 1.6874221190810204, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 454, train_loss = 1.6850054115056992, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 455, train_loss = 1.6825944209704176, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 456, train_loss = 1.6802330774953589, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 457, train_loss = 1.6780291931936517, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 458, train_loss = 1.67564197385218, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 459, train_loss = 1.6732820371398702, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 460, train_loss = 1.671006596297957, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "18th- epoch: 461, train_loss = 1.6684423958649859, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 462, train_loss = 1.6663707433035597, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 463, train_loss = 1.664103472023271, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 464, train_loss = 1.661723586381413, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 465, train_loss = 1.659378053038381, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 466, train_loss = 1.6572084265062585, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 467, train_loss = 1.6549984676530585, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "18th- epoch: 468, train_loss = 1.6527599655091763, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 469, train_loss = 1.650536714703776, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 470, train_loss = 1.6484475830802694, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 471, train_loss = 1.646265825838782, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 472, train_loss = 1.644038082449697, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 473, train_loss = 1.641974880010821, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 474, train_loss = 1.6397742629051208, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 475, train_loss = 1.637654323130846, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 476, train_loss = 1.635758010088466, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 477, train_loss = 1.6335285194218159, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 478, train_loss = 1.631517813890241, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 479, train_loss = 1.6294894529273733, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 480, train_loss = 1.6273753978312016, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 481, train_loss = 1.625326830893755, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 482, train_loss = 1.6234597960719839, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 483, train_loss = 1.6213288666913286, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 484, train_loss = 1.6193587146699429, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 485, train_loss = 1.6172632351517677, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 486, train_loss = 1.615481473505497, train_acc = 0.9959245458779693\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 487, train_loss = 1.613540137768723, train_acc = 0.996040987424313\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 488, train_loss = 1.6114676693687215, train_acc = 0.996040987424313\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 489, train_loss = 1.6095768114319071, train_acc = 0.996040987424313\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 490, train_loss = 1.6077229703078046, train_acc = 0.996040987424313\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 491, train_loss = 1.60576693713665, train_acc = 0.996040987424313\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 492, train_loss = 1.6039073839783669, train_acc = 0.996040987424313\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 493, train_loss = 1.6019993076333776, train_acc = 0.996040987424313\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 494, train_loss = 1.6001103483140469, train_acc = 0.996040987424313\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 495, train_loss = 1.5982728140661493, train_acc = 0.996040987424313\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 496, train_loss = 1.5964187296340242, train_acc = 0.996040987424313\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 497, train_loss = 1.5945949492743239, train_acc = 0.996040987424313\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 498, train_loss = 1.5928029902279377, train_acc = 0.996040987424313\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 499, train_loss = 1.5909518724074587, train_acc = 0.996040987424313\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████                            | 18/30 [1:59:35<1:19:37, 398.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "19th- epoch: 0, train_loss = 275.33688831329346, train_acc = 0.45517000465766183\n",
      "test Acc 0.48789571694599626:\n",
      "19th- epoch: 1, train_loss = 214.43318057060242, train_acc = 0.49126688402421986\n",
      "test Acc 0.4967411545623836:\n",
      "19th- epoch: 2, train_loss = 171.23444122076035, train_acc = 0.503493246390312\n",
      "test Acc 0.5181564245810056:\n",
      "19th- epoch: 3, train_loss = 148.7467451095581, train_acc = 0.6037494177922683\n",
      "test Acc 0.6852886405959032:\n",
      "19th- epoch: 4, train_loss = 131.03430265188217, train_acc = 0.6993479273404751\n",
      "test Acc 0.728584729981378:\n",
      "19th- epoch: 5, train_loss = 115.5030500292778, train_acc = 0.7324173265020959\n",
      "test Acc 0.755586592178771:\n",
      "19th- epoch: 6, train_loss = 101.9838194847107, train_acc = 0.7607126222636237\n",
      "test Acc 0.7825884543761639:\n",
      "19th- epoch: 7, train_loss = 90.43360128998756, train_acc = 0.7996040987424313\n",
      "test Acc 0.8128491620111732:\n",
      "19th- epoch: 8, train_loss = 80.50053736567497, train_acc = 0.8249883558453657\n",
      "test Acc 0.8342644320297952:\n",
      "19th- epoch: 9, train_loss = 71.83258146047592, train_acc = 0.8504890544946437\n",
      "test Acc 0.8635940409683427:\n",
      "19th- epoch: 10, train_loss = 64.29001650214195, train_acc = 0.8779692594317653\n",
      "test Acc 0.8868715083798883:\n",
      "19th- epoch: 11, train_loss = 57.845810890197754, train_acc = 0.8887983232417327\n",
      "test Acc 0.8924581005586593:\n",
      "19th- epoch: 12, train_loss = 52.44323217868805, train_acc = 0.8962505822077317\n",
      "test Acc 0.9008379888268156:\n",
      "19th- epoch: 13, train_loss = 47.950289875268936, train_acc = 0.9049836981835119\n",
      "test Acc 0.909683426443203:\n",
      "19th- epoch: 14, train_loss = 44.202524587512016, train_acc = 0.9179087098276665\n",
      "test Acc 0.9227188081936686:\n",
      "19th- epoch: 15, train_loss = 41.047322168946266, train_acc = 0.926525384257103\n",
      "test Acc 0.9278398510242085:\n",
      "19th- epoch: 16, train_loss = 38.366643249988556, train_acc = 0.935258500232883\n",
      "test Acc 0.9334264432029795:\n",
      "19th- epoch: 17, train_loss = 36.0701405107975, train_acc = 0.9391010712622264\n",
      "test Acc 0.9371508379888268:\n",
      "19th- epoch: 18, train_loss = 34.08712887018919, train_acc = 0.942361434559851\n",
      "test Acc 0.9408752327746741:\n",
      "19th- epoch: 19, train_loss = 32.360597386956215, train_acc = 0.9442244993013508\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 20, train_loss = 30.844277635216713, train_acc = 0.9469026548672567\n",
      "test Acc 0.9432029795158287:\n",
      "19th- epoch: 21, train_loss = 29.50195898860693, train_acc = 0.9489986027014439\n",
      "test Acc 0.9459962756052142:\n",
      "19th- epoch: 22, train_loss = 28.308246202766895, train_acc = 0.9501630181648812\n",
      "test Acc 0.9483240223463687:\n",
      "19th- epoch: 23, train_loss = 27.23761223256588, train_acc = 0.9519096413600373\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 24, train_loss = 26.268318451941013, train_acc = 0.9538891476478808\n",
      "test Acc 0.9534450651769087:\n",
      "19th- epoch: 25, train_loss = 25.383871220052242, train_acc = 0.9558686539357243\n",
      "test Acc 0.9548417132216015:\n",
      "19th- epoch: 26, train_loss = 24.57184675335884, train_acc = 0.9570330693991617\n",
      "test Acc 0.9553072625698324:\n",
      "19th- epoch: 27, train_loss = 23.82921366021037, train_acc = 0.9578481602235678\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 28, train_loss = 23.143716629594564, train_acc = 0.9587796925943176\n",
      "test Acc 0.9562383612662942:\n",
      "19th- epoch: 29, train_loss = 22.50771365687251, train_acc = 0.9593619003260363\n",
      "test Acc 0.9562383612662942:\n",
      "19th- epoch: 30, train_loss = 21.91533261165023, train_acc = 0.96040987424313\n",
      "test Acc 0.9567039106145251:\n",
      "19th- epoch: 31, train_loss = 21.360991694033146, train_acc = 0.9613414066138798\n",
      "test Acc 0.9567039106145251:\n",
      "19th- epoch: 32, train_loss = 20.840360589325428, train_acc = 0.9619236143455985\n",
      "test Acc 0.9567039106145251:\n",
      "19th- epoch: 33, train_loss = 20.349905665963888, train_acc = 0.9626222636236609\n",
      "test Acc 0.9567039106145251:\n",
      "19th- epoch: 34, train_loss = 19.886404380202293, train_acc = 0.9626222636236609\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 35, train_loss = 19.44672256335616, train_acc = 0.9632044713553796\n",
      "test Acc 0.957169459962756:\n",
      "19th- epoch: 36, train_loss = 19.028773572295904, train_acc = 0.9641360037261295\n",
      "test Acc 0.9581005586592178:\n",
      "19th- epoch: 37, train_loss = 18.630899004638195, train_acc = 0.9654168607359106\n",
      "test Acc 0.9585661080074488:\n",
      "19th- epoch: 38, train_loss = 18.251728009432554, train_acc = 0.966115510013973\n",
      "test Acc 0.9585661080074488:\n",
      "19th- epoch: 39, train_loss = 17.889583814889193, train_acc = 0.9666977177456917\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 40, train_loss = 17.542520195245743, train_acc = 0.9671634839310667\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 41, train_loss = 17.209994979202747, train_acc = 0.9678621332091291\n",
      "test Acc 0.9604283054003724:\n",
      "19th- epoch: 42, train_loss = 16.890929277986288, train_acc = 0.9682114578481602\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 43, train_loss = 16.58490614965558, train_acc = 0.9686772240335352\n",
      "test Acc 0.9622905027932961:\n",
      "19th- epoch: 44, train_loss = 16.29061795771122, train_acc = 0.9693758733115976\n",
      "test Acc 0.9622905027932961:\n",
      "19th- epoch: 45, train_loss = 16.007632203400135, train_acc = 0.9697251979506288\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 46, train_loss = 15.734565403312445, train_acc = 0.9699580810433163\n",
      "test Acc 0.9632216014897579:\n",
      "19th- epoch: 47, train_loss = 15.470710691064596, train_acc = 0.9704238472286912\n",
      "test Acc 0.9636871508379888:\n",
      "19th- epoch: 48, train_loss = 15.215414673089981, train_acc = 0.9706567303213787\n",
      "test Acc 0.9646182495344506:\n",
      "19th- epoch: 49, train_loss = 14.968484990298748, train_acc = 0.9714718211457848\n",
      "test Acc 0.9650837988826816:\n",
      "19th- epoch: 50, train_loss = 14.729849800467491, train_acc = 0.9719375873311598\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 51, train_loss = 14.498514054343104, train_acc = 0.9728691197019096\n",
      "test Acc 0.9664804469273743:\n",
      "19th- epoch: 52, train_loss = 14.274444894865155, train_acc = 0.9735677689799721\n",
      "test Acc 0.9669459962756052:\n",
      "19th- epoch: 53, train_loss = 14.05705826729536, train_acc = 0.9739170936190032\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 54, train_loss = 13.84618584997952, train_acc = 0.974033535165347\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 55, train_loss = 13.641092792153358, train_acc = 0.9741499767116907\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 56, train_loss = 13.441813215613365, train_acc = 0.9743828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 57, train_loss = 13.248392600566149, train_acc = 0.9743828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 58, train_loss = 13.06028888002038, train_acc = 0.9746157428970657\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 59, train_loss = 12.877298835664988, train_acc = 0.9748486259897532\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 60, train_loss = 12.698941588401794, train_acc = 0.9751979506287843\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 61, train_loss = 12.525165129452944, train_acc = 0.975314392175128\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 62, train_loss = 12.355929736047983, train_acc = 0.9756637168141593\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 63, train_loss = 12.19107885658741, train_acc = 0.9756637168141593\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 64, train_loss = 12.030483573675156, train_acc = 0.975780158360503\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 65, train_loss = 11.874033149331808, train_acc = 0.9758965999068467\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 66, train_loss = 11.721499674022198, train_acc = 0.9761294829995343\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 67, train_loss = 11.572683587670326, train_acc = 0.9767116907312529\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 68, train_loss = 11.427451387047768, train_acc = 0.9771774569166278\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 69, train_loss = 11.285521280020475, train_acc = 0.9771774569166278\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 70, train_loss = 11.14667758345604, train_acc = 0.9776432231020028\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 71, train_loss = 11.010840941220522, train_acc = 0.9778761061946902\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 72, train_loss = 10.87803789228201, train_acc = 0.977992547741034\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 73, train_loss = 10.748025845736265, train_acc = 0.9783418723800652\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 74, train_loss = 10.620709158480167, train_acc = 0.9785747554727526\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 75, train_loss = 10.495963603258133, train_acc = 0.9785747554727526\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 76, train_loss = 10.373779678717256, train_acc = 0.9785747554727526\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 77, train_loss = 10.254017613828182, train_acc = 0.9785747554727526\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 78, train_loss = 10.136771574616432, train_acc = 0.9788076385654402\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 79, train_loss = 10.021979067474604, train_acc = 0.9788076385654402\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 80, train_loss = 9.90927492082119, train_acc = 0.9790405216581276\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 81, train_loss = 9.798763187602162, train_acc = 0.9792734047508151\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 82, train_loss = 9.690592791885138, train_acc = 0.9793898462971589\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 83, train_loss = 9.584438070654869, train_acc = 0.9798556124825337\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 84, train_loss = 9.480349242687225, train_acc = 0.9799720540288775\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 85, train_loss = 9.378081921488047, train_acc = 0.9800884955752213\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 86, train_loss = 9.277761306613684, train_acc = 0.9803213786679087\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 87, train_loss = 9.179049670696259, train_acc = 0.9805542617605962\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 88, train_loss = 9.08212012052536, train_acc = 0.98067070330694\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 89, train_loss = 8.986885912716389, train_acc = 0.9807871448532837\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 90, train_loss = 8.893141686916351, train_acc = 0.9807871448532837\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 91, train_loss = 8.800938282161951, train_acc = 0.9811364694923148\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 92, train_loss = 8.710235599428415, train_acc = 0.9811364694923148\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 93, train_loss = 8.620871430262923, train_acc = 0.9812529110386586\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 94, train_loss = 8.532991172745824, train_acc = 0.9814857941313461\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 95, train_loss = 8.446339592337608, train_acc = 0.9816022356776898\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 96, train_loss = 8.361060785129666, train_acc = 0.9818351187703773\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 97, train_loss = 8.27696762420237, train_acc = 0.9818351187703773\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 98, train_loss = 8.19431895762682, train_acc = 0.9818351187703773\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 99, train_loss = 8.112986661493778, train_acc = 0.9821844434094085\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 100, train_loss = 8.032787535339594, train_acc = 0.9824173265020959\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 101, train_loss = 7.95353433303535, train_acc = 0.9825337680484397\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 102, train_loss = 7.875535454601049, train_acc = 0.9828830926874709\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 103, train_loss = 7.7988495752215385, train_acc = 0.9831159757801584\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 104, train_loss = 7.723246423527598, train_acc = 0.9832324173265021\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 105, train_loss = 7.648898713290691, train_acc = 0.9832324173265021\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 106, train_loss = 7.575366767123342, train_acc = 0.9838146250582208\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 107, train_loss = 7.502988759428263, train_acc = 0.984163949697252\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 108, train_loss = 7.431653181090951, train_acc = 0.9843968327899395\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 109, train_loss = 7.361226849257946, train_acc = 0.9843968327899395\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 110, train_loss = 7.2917909026145935, train_acc = 0.9845132743362832\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 111, train_loss = 7.223373532295227, train_acc = 0.9847461574289706\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 112, train_loss = 7.156061306595802, train_acc = 0.9850954820680019\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 113, train_loss = 7.089557910338044, train_acc = 0.9853283651606893\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 114, train_loss = 7.024200271815062, train_acc = 0.9853283651606893\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 115, train_loss = 6.959557561203837, train_acc = 0.985444806707033\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 116, train_loss = 6.895891623571515, train_acc = 0.9853283651606893\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 117, train_loss = 6.833090549334884, train_acc = 0.985444806707033\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 118, train_loss = 6.77114525437355, train_acc = 0.9855612482533768\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 119, train_loss = 6.710115130990744, train_acc = 0.9855612482533768\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 120, train_loss = 6.649756735190749, train_acc = 0.9856776897997206\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 121, train_loss = 6.590425232425332, train_acc = 0.9857941313460643\n",
      "test Acc 0.9743947858472998:\n",
      "19th- epoch: 122, train_loss = 6.531818741932511, train_acc = 0.9860270144387517\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 123, train_loss = 6.474076341837645, train_acc = 0.986376339077783\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 124, train_loss = 6.416849417611957, train_acc = 0.986376339077783\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 125, train_loss = 6.360715981572866, train_acc = 0.986376339077783\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 126, train_loss = 6.3051222413778305, train_acc = 0.986376339077783\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 127, train_loss = 6.250440679490566, train_acc = 0.9866092221704704\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 128, train_loss = 6.196569714695215, train_acc = 0.9869585468095017\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 129, train_loss = 6.143341939896345, train_acc = 0.9869585468095017\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 130, train_loss = 6.090818382799625, train_acc = 0.9876571960875641\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 131, train_loss = 6.039053147658706, train_acc = 0.9877736376339078\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 132, train_loss = 5.987944154068828, train_acc = 0.9881229622729389\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 133, train_loss = 5.937520639970899, train_acc = 0.9882394038192828\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 134, train_loss = 5.887850983068347, train_acc = 0.9883558453656265\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 135, train_loss = 5.8388063330203295, train_acc = 0.9885887284583139\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 136, train_loss = 5.790125861763954, train_acc = 0.9888216115510013\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 137, train_loss = 5.741917600855231, train_acc = 0.9889380530973452\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 138, train_loss = 5.694465525448322, train_acc = 0.9890544946436889\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 139, train_loss = 5.647734710946679, train_acc = 0.9891709361900326\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 140, train_loss = 5.602122873067856, train_acc = 0.9891709361900326\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 141, train_loss = 5.557066336274147, train_acc = 0.9892873777363763\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 142, train_loss = 5.512455536052585, train_acc = 0.98940381928272\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 143, train_loss = 5.468584068119526, train_acc = 0.9895202608290639\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 144, train_loss = 5.425324929878116, train_acc = 0.9896367023754076\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 145, train_loss = 5.382614394649863, train_acc = 0.9896367023754076\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 146, train_loss = 5.340439857915044, train_acc = 0.9896367023754076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 147, train_loss = 5.298764394596219, train_acc = 0.9897531439217513\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 148, train_loss = 5.2578258235007524, train_acc = 0.9897531439217513\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 149, train_loss = 5.21721881814301, train_acc = 0.9897531439217513\n",
      "test Acc 0.9762569832402235:\n",
      "19th- epoch: 150, train_loss = 5.177343787625432, train_acc = 0.989869585468095\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 151, train_loss = 5.137853255495429, train_acc = 0.989869585468095\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 152, train_loss = 5.098964259028435, train_acc = 0.989869585468095\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 153, train_loss = 5.0605642925947905, train_acc = 0.9899860270144387\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 154, train_loss = 5.022559160366654, train_acc = 0.9902189101071263\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 155, train_loss = 4.985288606956601, train_acc = 0.9902189101071263\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 156, train_loss = 4.948292624205351, train_acc = 0.9902189101071263\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 157, train_loss = 4.911670478992164, train_acc = 0.9902189101071263\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 158, train_loss = 4.875569523312151, train_acc = 0.99033535165347\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 159, train_loss = 4.840022278949618, train_acc = 0.9904517931998137\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 160, train_loss = 4.804749081842601, train_acc = 0.9904517931998137\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 161, train_loss = 4.769957565702498, train_acc = 0.9904517931998137\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 162, train_loss = 4.735551916062832, train_acc = 0.9905682347461574\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 163, train_loss = 4.701701758429408, train_acc = 0.990801117838845\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 164, train_loss = 4.668386561796069, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 165, train_loss = 4.635459675453603, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 166, train_loss = 4.603069211356342, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 167, train_loss = 4.5708526922389865, train_acc = 0.9909175593851887\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 168, train_loss = 4.539376941509545, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 169, train_loss = 4.508006688207388, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 170, train_loss = 4.47730674687773, train_acc = 0.9911504424778761\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 171, train_loss = 4.446789775043726, train_acc = 0.9911504424778761\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 172, train_loss = 4.416802109219134, train_acc = 0.9912668840242198\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 173, train_loss = 4.387090771459043, train_acc = 0.9912668840242198\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 174, train_loss = 4.357812830246985, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 175, train_loss = 4.32859958242625, train_acc = 0.9914997671169073\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 176, train_loss = 4.300283760763705, train_acc = 0.9914997671169073\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 177, train_loss = 4.271940709091723, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 178, train_loss = 4.244140991009772, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 179, train_loss = 4.216513401828706, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 180, train_loss = 4.189341292716563, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 181, train_loss = 4.162483051419258, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 182, train_loss = 4.135827104561031, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 183, train_loss = 4.109635680913925, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 184, train_loss = 4.0836214711889625, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 185, train_loss = 4.058057151734829, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 186, train_loss = 4.032743257470429, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 187, train_loss = 4.007714646868408, train_acc = 0.9918490917559385\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 188, train_loss = 3.9828345365822315, train_acc = 0.9918490917559385\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 189, train_loss = 3.958321730606258, train_acc = 0.9918490917559385\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 190, train_loss = 3.934075340628624, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 191, train_loss = 3.910091179423034, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 192, train_loss = 3.886491213925183, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 193, train_loss = 3.863265773281455, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 194, train_loss = 3.8401125045493245, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 195, train_loss = 3.8174989661201835, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 196, train_loss = 3.7949465001001954, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 197, train_loss = 3.772673647850752, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 198, train_loss = 3.7506523365154862, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 199, train_loss = 3.7288286043331027, train_acc = 0.9926641825803446\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 200, train_loss = 3.7073792703449726, train_acc = 0.9926641825803446\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 201, train_loss = 3.6857485892251134, train_acc = 0.9926641825803446\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 202, train_loss = 3.6648145699873567, train_acc = 0.9926641825803446\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 203, train_loss = 3.6437407694756985, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 204, train_loss = 3.623020675033331, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 205, train_loss = 3.602417907677591, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 206, train_loss = 3.5822066934779286, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 207, train_loss = 3.5621981443837285, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 208, train_loss = 3.542420598678291, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 209, train_loss = 3.522841122932732, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 210, train_loss = 3.5032980339601636, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 211, train_loss = 3.4840830406174064, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 212, train_loss = 3.4647496053949, train_acc = 0.9926641825803446\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 213, train_loss = 3.4457502840086818, train_acc = 0.9926641825803446\n",
      "test Acc 0.979050279329609:\n",
      "19th- epoch: 214, train_loss = 3.4268368864431977, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 215, train_loss = 3.4078431772068143, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 216, train_loss = 3.38915251288563, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 217, train_loss = 3.3707133969292045, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 218, train_loss = 3.352791008539498, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 219, train_loss = 3.3352534398436546, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 220, train_loss = 3.3178171231411397, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 221, train_loss = 3.3006686405278742, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 222, train_loss = 3.2836421779356897, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 223, train_loss = 3.266490498557687, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 224, train_loss = 3.250029235612601, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 225, train_loss = 3.2334454115480185, train_acc = 0.9932463903120633\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 226, train_loss = 3.217057954054326, train_acc = 0.9932463903120633\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 227, train_loss = 3.2008233293890953, train_acc = 0.9932463903120633\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 228, train_loss = 3.1848674439825118, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 229, train_loss = 3.1689340020529926, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 230, train_loss = 3.1533210780471563, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 231, train_loss = 3.1376598346978426, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 232, train_loss = 3.122388450894505, train_acc = 0.9935957149510946\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 233, train_loss = 3.107057326938957, train_acc = 0.9935957149510946\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 234, train_loss = 3.092041424009949, train_acc = 0.9937121564974383\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 235, train_loss = 3.07701321458444, train_acc = 0.9937121564974383\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 236, train_loss = 3.062330723274499, train_acc = 0.9937121564974383\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 237, train_loss = 3.0474977563135326, train_acc = 0.9937121564974383\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 238, train_loss = 3.0331346727907658, train_acc = 0.9937121564974383\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 239, train_loss = 3.0187376854009926, train_acc = 0.9937121564974383\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 240, train_loss = 3.004533940926194, train_acc = 0.9937121564974383\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 241, train_loss = 2.99030547356233, train_acc = 0.9937121564974383\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 242, train_loss = 2.9763671178370714, train_acc = 0.9937121564974383\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 243, train_loss = 2.9625670448876917, train_acc = 0.9937121564974383\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 244, train_loss = 2.9489133744500577, train_acc = 0.9937121564974383\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 245, train_loss = 2.9352463739924133, train_acc = 0.9937121564974383\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 246, train_loss = 2.9219379969872534, train_acc = 0.9937121564974383\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 247, train_loss = 2.908544765319675, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 248, train_loss = 2.8954279758036137, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 249, train_loss = 2.8822627724148333, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 250, train_loss = 2.8693284043110907, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 251, train_loss = 2.8565462888218462, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 252, train_loss = 2.8437454774975777, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 253, train_loss = 2.831244496162981, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 254, train_loss = 2.8186666420660913, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 255, train_loss = 2.806399670895189, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 256, train_loss = 2.794153640512377, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 257, train_loss = 2.78208285337314, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 258, train_loss = 2.770064403768629, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 259, train_loss = 2.7581954821944237, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 260, train_loss = 2.7464940645731986, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 261, train_loss = 2.7347080945037305, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 262, train_loss = 2.7231959626078606, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 263, train_loss = 2.7115570195019245, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 264, train_loss = 2.7000071206130087, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 265, train_loss = 2.688230202998966, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 266, train_loss = 2.6770967259071767, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 267, train_loss = 2.665938871446997, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 268, train_loss = 2.6551324813626707, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 269, train_loss = 2.644170572515577, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 270, train_loss = 2.6335912882350385, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 271, train_loss = 2.622807504143566, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 272, train_loss = 2.6123103513382375, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 273, train_loss = 2.6019031293690205, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 274, train_loss = 2.591549011413008, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 275, train_loss = 2.5812603957019746, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 276, train_loss = 2.571129432413727, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 277, train_loss = 2.5610231645405293, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 278, train_loss = 2.5510299168527126, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 279, train_loss = 2.5412023081444204, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 280, train_loss = 2.531439669430256, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 281, train_loss = 2.5216170586645603, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 282, train_loss = 2.512050291057676, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 283, train_loss = 2.502597885672003, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 284, train_loss = 2.4931495524942875, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 285, train_loss = 2.483766245190054, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 286, train_loss = 2.4746011667884886, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 287, train_loss = 2.4652739078737795, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 288, train_loss = 2.45633357623592, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 289, train_loss = 2.4473218671046197, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 290, train_loss = 2.4384931004606187, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 291, train_loss = 2.429657407104969, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 292, train_loss = 2.4209113814868033, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 293, train_loss = 2.4121343730948865, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 294, train_loss = 2.403662336524576, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 295, train_loss = 2.3951131131034344, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 296, train_loss = 2.386702752439305, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 297, train_loss = 2.378319673240185, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 298, train_loss = 2.37011793628335, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 299, train_loss = 2.3620151716750115, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 300, train_loss = 2.353729523718357, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 301, train_loss = 2.3457386705558747, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 302, train_loss = 2.337890512077138, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 303, train_loss = 2.330053360434249, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 304, train_loss = 2.322150271385908, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 305, train_loss = 2.3143484331667423, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 306, train_loss = 2.30676253256388, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 307, train_loss = 2.299266279907897, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 308, train_loss = 2.2917484517674893, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 309, train_loss = 2.284109602449462, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 310, train_loss = 2.2768141489941627, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 311, train_loss = 2.2693586472887546, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 312, train_loss = 2.262271908344701, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 313, train_loss = 2.2551171258091927, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 314, train_loss = 2.247922405600548, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 315, train_loss = 2.240891968132928, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 316, train_loss = 2.2338517494499683, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 317, train_loss = 2.227047110674903, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 318, train_loss = 2.2202405631542206, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 319, train_loss = 2.2135541774332523, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 320, train_loss = 2.206688327016309, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 321, train_loss = 2.1999836426693946, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 322, train_loss = 2.193590232403949, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 323, train_loss = 2.186951705487445, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 324, train_loss = 2.1805654007475823, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 325, train_loss = 2.174079177202657, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 326, train_loss = 2.1675923231523484, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 327, train_loss = 2.1615634597837925, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 328, train_loss = 2.155303171603009, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 329, train_loss = 2.1489800177514553, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 330, train_loss = 2.1429537758231163, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 331, train_loss = 2.136695485562086, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 332, train_loss = 2.1308645457029343, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 333, train_loss = 2.124956402927637, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 334, train_loss = 2.118981895269826, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 335, train_loss = 2.1131582979578525, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 336, train_loss = 2.1073170143645257, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 337, train_loss = 2.101527725579217, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 338, train_loss = 2.095999797107652, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 339, train_loss = 2.0902976281940937, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 340, train_loss = 2.0847109258174896, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 341, train_loss = 2.078975108684972, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 342, train_loss = 2.073691123398021, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 343, train_loss = 2.0682374860625714, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 344, train_loss = 2.062898598611355, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 345, train_loss = 2.057335637509823, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 346, train_loss = 2.0522642135620117, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 347, train_loss = 2.0467353996355087, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 348, train_loss = 2.0417465306818485, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 349, train_loss = 2.0365486417431384, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 350, train_loss = 2.0315535191912204, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 351, train_loss = 2.0262391269207, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 352, train_loss = 2.021213452098891, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 353, train_loss = 2.0162807628512383, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 354, train_loss = 2.0114667813759297, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 355, train_loss = 2.0063792131841183, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 356, train_loss = 2.0014391790609807, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 357, train_loss = 1.9967721712309867, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 358, train_loss = 1.9919976592063904, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 359, train_loss = 1.9871645730454475, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 360, train_loss = 1.9825398821849376, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 361, train_loss = 1.9776220109779388, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 362, train_loss = 1.9733000695705414, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 363, train_loss = 1.9686883080285043, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 364, train_loss = 1.9641523882746696, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 365, train_loss = 1.959455284057185, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 366, train_loss = 1.9551399510819465, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 367, train_loss = 1.950655170949176, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 368, train_loss = 1.946285743266344, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 369, train_loss = 1.9418751138728112, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 370, train_loss = 1.9374658204615116, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 371, train_loss = 1.933281111298129, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 372, train_loss = 1.929074577987194, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 373, train_loss = 1.9247330948710442, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 374, train_loss = 1.9204464901704341, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 375, train_loss = 1.9164408408105373, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 376, train_loss = 1.912351630628109, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 377, train_loss = 1.9082433767616749, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 378, train_loss = 1.904026760486886, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 379, train_loss = 1.9001340009272099, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 380, train_loss = 1.8961508659413084, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 381, train_loss = 1.8922281773993745, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 382, train_loss = 1.8883203566074371, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 383, train_loss = 1.8842260712990537, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 384, train_loss = 1.8806038001785055, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 385, train_loss = 1.8767192488303408, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 386, train_loss = 1.872873647720553, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 387, train_loss = 1.8689563547959551, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 388, train_loss = 1.865303690196015, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 389, train_loss = 1.8615782918641344, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 390, train_loss = 1.8580463044345379, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 391, train_loss = 1.8542453857371584, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 392, train_loss = 1.8504349117865786, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 393, train_loss = 1.8471608659019694, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 394, train_loss = 1.843369389534928, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 395, train_loss = 1.8398617146303877, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 396, train_loss = 1.8362730158260092, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 397, train_loss = 1.8328053019940853, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 398, train_loss = 1.8295467495918274, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 399, train_loss = 1.8259530924260616, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 400, train_loss = 1.8223846467444673, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 401, train_loss = 1.8191080205142498, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 402, train_loss = 1.815852022380568, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 403, train_loss = 1.8124905104050413, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 404, train_loss = 1.8091297881910577, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 405, train_loss = 1.8057330747833475, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 406, train_loss = 1.8027824958553538, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 407, train_loss = 1.7993826208403334, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 408, train_loss = 1.7960898590972647, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 409, train_loss = 1.7928066240856424, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 410, train_loss = 1.7898478396236897, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 411, train_loss = 1.7867715023458004, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 412, train_loss = 1.7834749221801758, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 413, train_loss = 1.780240194289945, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 414, train_loss = 1.7774190455675125, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 415, train_loss = 1.774356177658774, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 416, train_loss = 1.7713536396622658, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 417, train_loss = 1.7680727789411321, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 418, train_loss = 1.7653843326261267, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 419, train_loss = 1.7623536499449983, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 420, train_loss = 1.7593099536607042, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 421, train_loss = 1.756402307539247, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 422, train_loss = 1.7535419774940237, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 423, train_loss = 1.7506891986122355, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 424, train_loss = 1.747921915142797, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 425, train_loss = 1.7448349371552467, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 426, train_loss = 1.7421320900321007, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 427, train_loss = 1.7394102029502392, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 428, train_loss = 1.7366348678478971, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 429, train_loss = 1.733680296689272, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 430, train_loss = 1.731112264096737, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 431, train_loss = 1.7283850722014904, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 432, train_loss = 1.7255932824919, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "19th- epoch: 433, train_loss = 1.72284549230244, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 434, train_loss = 1.7203142506768927, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 435, train_loss = 1.717687433003448, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 436, train_loss = 1.7150834612548351, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 437, train_loss = 1.7123623540392146, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 438, train_loss = 1.7097362838685513, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 439, train_loss = 1.707354474812746, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 440, train_loss = 1.7047619620570913, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 441, train_loss = 1.7020601071417332, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 442, train_loss = 1.6997051412472501, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 443, train_loss = 1.6971227986505255, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 444, train_loss = 1.694471050053835, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 445, train_loss = 1.6921440871665254, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 446, train_loss = 1.6897230757167563, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 447, train_loss = 1.6873963586986065, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 448, train_loss = 1.6847092820098624, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 449, train_loss = 1.6824885035166517, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 450, train_loss = 1.6800380734493956, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 451, train_loss = 1.6775803404161707, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 452, train_loss = 1.6753872396657243, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 453, train_loss = 1.673000076203607, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 454, train_loss = 1.6706913436064497, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 455, train_loss = 1.6681813473114744, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 456, train_loss = 1.6661950262496248, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 457, train_loss = 1.663691652356647, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 458, train_loss = 1.6613165512681007, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 459, train_loss = 1.6592589020729065, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 460, train_loss = 1.6571222307393327, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 461, train_loss = 1.6548467265674844, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 462, train_loss = 1.6524591892957687, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 463, train_loss = 1.6503583788871765, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 464, train_loss = 1.648238239227794, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 465, train_loss = 1.6459652943303809, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 466, train_loss = 1.6440232148161158, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 467, train_loss = 1.6416785381734371, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 468, train_loss = 1.6395517414202914, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 469, train_loss = 1.637646852643229, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 470, train_loss = 1.6353705897927284, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 471, train_loss = 1.6332836635410786, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 472, train_loss = 1.631386307417415, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 473, train_loss = 1.6293204998364672, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 474, train_loss = 1.6271638659527525, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 475, train_loss = 1.6252413764595985, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 476, train_loss = 1.6231744749238715, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 477, train_loss = 1.6211404241621494, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 478, train_loss = 1.6192816669354215, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 479, train_loss = 1.6172645799815655, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 480, train_loss = 1.6152872865786776, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 481, train_loss = 1.6133962037274614, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 482, train_loss = 1.6114054707577452, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 483, train_loss = 1.6093916868558154, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 484, train_loss = 1.6075745560228825, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 485, train_loss = 1.6057392954826355, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 486, train_loss = 1.6036996680195443, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 487, train_loss = 1.6019804974202998, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 488, train_loss = 1.6000862121582031, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 489, train_loss = 1.5980139921302907, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 490, train_loss = 1.5963824366335757, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 491, train_loss = 1.5945422512595542, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 492, train_loss = 1.5925693474709988, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 493, train_loss = 1.5909324673120864, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 494, train_loss = 1.5891650232370012, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 495, train_loss = 1.587234377861023, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 496, train_loss = 1.5854084603488445, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 497, train_loss = 1.5838233443791978, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 498, train_loss = 1.5821101156179793, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 499, train_loss = 1.5803701616823673, train_acc = 0.9961574289706567\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|████████████████████████████████████████████▎                         | 19/30 [2:06:13<1:12:57, 397.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "20th- epoch: 0, train_loss = 269.3404802083969, train_acc = 0.4795062878435026\n",
      "test Acc 0.4883612662942272:\n",
      "20th- epoch: 1, train_loss = 204.38775324821472, train_acc = 0.4914997671169073\n",
      "test Acc 0.4972067039106145:\n",
      "20th- epoch: 2, train_loss = 166.20657587051392, train_acc = 0.5073358174196554\n",
      "test Acc 0.5563314711359404:\n",
      "20th- epoch: 3, train_loss = 144.91059482097626, train_acc = 0.6387983232417327\n",
      "test Acc 0.6908752327746741:\n",
      "20th- epoch: 4, train_loss = 127.19343703985214, train_acc = 0.7086632510479739\n",
      "test Acc 0.7327746741154563:\n",
      "20th- epoch: 5, train_loss = 111.2161141037941, train_acc = 0.746040987424313\n",
      "test Acc 0.7667597765363129:\n",
      "20th- epoch: 6, train_loss = 97.1123006939888, train_acc = 0.7835351653469959\n",
      "test Acc 0.797486033519553:\n",
      "20th- epoch: 7, train_loss = 85.03505551815033, train_acc = 0.821727992547741\n",
      "test Acc 0.8296089385474861:\n",
      "20th- epoch: 8, train_loss = 74.89560106396675, train_acc = 0.8488588728458314\n",
      "test Acc 0.8594040968342644:\n",
      "20th- epoch: 9, train_loss = 66.5044614970684, train_acc = 0.8686539357242664\n",
      "test Acc 0.8738361266294227:\n",
      "20th- epoch: 10, train_loss = 59.61740052700043, train_acc = 0.8770377270610153\n",
      "test Acc 0.8780260707635009:\n",
      "20th- epoch: 11, train_loss = 53.95893286168575, train_acc = 0.886003726129483\n",
      "test Acc 0.8840782122905028:\n",
      "20th- epoch: 12, train_loss = 49.28630295395851, train_acc = 0.8941546343735445\n",
      "test Acc 0.8933891992551211:\n",
      "20th- epoch: 13, train_loss = 45.407172113657, train_acc = 0.902771308802981\n",
      "test Acc 0.9050279329608939:\n",
      "20th- epoch: 14, train_loss = 42.144335225224495, train_acc = 0.9187238006520727\n",
      "test Acc 0.9208566108007449:\n",
      "20th- epoch: 15, train_loss = 39.36239369213581, train_acc = 0.9304843968327899\n",
      "test Acc 0.9357541899441341:\n",
      "20th- epoch: 16, train_loss = 36.96644468605518, train_acc = 0.9389846297158826\n",
      "test Acc 0.9399441340782123:\n",
      "20th- epoch: 17, train_loss = 34.88464669883251, train_acc = 0.9420121099208197\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 18, train_loss = 33.06275995075703, train_acc = 0.9450395901257569\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 19, train_loss = 31.456923201680183, train_acc = 0.9472519795062878\n",
      "test Acc 0.9455307262569832:\n",
      "20th- epoch: 20, train_loss = 30.030238196253777, train_acc = 0.9493479273404751\n",
      "test Acc 0.9483240223463687:\n",
      "20th- epoch: 21, train_loss = 28.753365069627762, train_acc = 0.9513274336283186\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 22, train_loss = 27.609495870769024, train_acc = 0.9526082906380997\n",
      "test Acc 0.9506517690875232:\n",
      "20th- epoch: 23, train_loss = 26.579185158014297, train_acc = 0.9542384722869119\n",
      "test Acc 0.9511173184357542:\n",
      "20th- epoch: 24, train_loss = 25.64530251175165, train_acc = 0.9554028877503493\n",
      "test Acc 0.9515828677839852:\n",
      "20th- epoch: 25, train_loss = 24.79570445418358, train_acc = 0.9561015370284117\n",
      "test Acc 0.952513966480447:\n",
      "20th- epoch: 26, train_loss = 24.01991481333971, train_acc = 0.9569166278528178\n",
      "test Acc 0.9534450651769087:\n",
      "20th- epoch: 27, train_loss = 23.308113269507885, train_acc = 0.9580810433162552\n",
      "test Acc 0.9548417132216015:\n",
      "20th- epoch: 28, train_loss = 22.65132522955537, train_acc = 0.9593619003260363\n",
      "test Acc 0.9562383612662942:\n",
      "20th- epoch: 29, train_loss = 22.04282433539629, train_acc = 0.9597112249650676\n",
      "test Acc 0.9562383612662942:\n",
      "20th- epoch: 30, train_loss = 21.475847702473402, train_acc = 0.9601769911504425\n",
      "test Acc 0.9562383612662942:\n",
      "20th- epoch: 31, train_loss = 20.94487462937832, train_acc = 0.9608756404285049\n",
      "test Acc 0.957635009310987:\n",
      "20th- epoch: 32, train_loss = 20.446072213351727, train_acc = 0.9607591988821611\n",
      "test Acc 0.9585661080074488:\n",
      "20th- epoch: 33, train_loss = 19.97584592178464, train_acc = 0.9612249650675361\n",
      "test Acc 0.9594972067039106:\n",
      "20th- epoch: 34, train_loss = 19.53127633407712, train_acc = 0.9614578481602236\n",
      "test Acc 0.9604283054003724:\n",
      "20th- epoch: 35, train_loss = 19.110743042081594, train_acc = 0.9626222636236609\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 36, train_loss = 18.712290812283754, train_acc = 0.9635537959944108\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 37, train_loss = 18.333263263106346, train_acc = 0.9642524452724732\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 38, train_loss = 17.972204227000475, train_acc = 0.9649510945505356\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 39, train_loss = 17.627928633242846, train_acc = 0.966115510013973\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 40, train_loss = 17.29876571893692, train_acc = 0.9668141592920354\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 41, train_loss = 16.983824122697115, train_acc = 0.9672799254774104\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 42, train_loss = 16.682036571204662, train_acc = 0.9689101071262226\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 43, train_loss = 16.39194130524993, train_acc = 0.9694923148579413\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 44, train_loss = 16.11250963807106, train_acc = 0.97007452258966\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 45, train_loss = 15.843512181192636, train_acc = 0.9704238472286912\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 46, train_loss = 15.583995521068573, train_acc = 0.9713553795994411\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 47, train_loss = 15.333363432437181, train_acc = 0.9720540288775035\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 48, train_loss = 15.091088097542524, train_acc = 0.9721704704238472\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 49, train_loss = 14.856775432825089, train_acc = 0.9725197950628784\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 50, train_loss = 14.629697151482105, train_acc = 0.9727526781555659\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 51, train_loss = 14.40944118052721, train_acc = 0.9728691197019096\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 52, train_loss = 14.195744093507528, train_acc = 0.9732184443409408\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 53, train_loss = 13.988338731229305, train_acc = 0.9735677689799721\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 54, train_loss = 13.786685179919004, train_acc = 0.9739170936190032\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 55, train_loss = 13.590154189616442, train_acc = 0.974033535165347\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 56, train_loss = 13.398829247802496, train_acc = 0.9742664182580345\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 57, train_loss = 13.213166996836662, train_acc = 0.9743828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 58, train_loss = 13.032832629978657, train_acc = 0.9748486259897532\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 59, train_loss = 12.857411127537489, train_acc = 0.975314392175128\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 60, train_loss = 12.686791867017746, train_acc = 0.975314392175128\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 61, train_loss = 12.520719185471535, train_acc = 0.9758965999068467\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 62, train_loss = 12.35900779813528, train_acc = 0.9760130414531905\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 63, train_loss = 12.201214261353016, train_acc = 0.976245924545878\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 64, train_loss = 12.047275740653276, train_acc = 0.9763623660922217\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 65, train_loss = 11.896750658750534, train_acc = 0.9764788076385654\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 66, train_loss = 11.749851815402508, train_acc = 0.9767116907312529\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 67, train_loss = 11.606441091746092, train_acc = 0.9768281322775967\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 68, train_loss = 11.466331288218498, train_acc = 0.9768281322775967\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 69, train_loss = 11.329266522079706, train_acc = 0.9768281322775967\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 70, train_loss = 11.195419535040855, train_acc = 0.9769445738239404\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 71, train_loss = 11.064794285222888, train_acc = 0.9770610153702841\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 72, train_loss = 10.93693151883781, train_acc = 0.9771774569166278\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 73, train_loss = 10.811850233003497, train_acc = 0.9776432231020028\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 74, train_loss = 10.689217485487461, train_acc = 0.977992547741034\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 75, train_loss = 10.569025252014399, train_acc = 0.9781089892873778\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 76, train_loss = 10.450640322640538, train_acc = 0.9781089892873778\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 77, train_loss = 10.334833601489663, train_acc = 0.9785747554727526\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 78, train_loss = 10.22169197909534, train_acc = 0.9785747554727526\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 79, train_loss = 10.110865185037255, train_acc = 0.9788076385654402\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 80, train_loss = 10.002030111849308, train_acc = 0.9790405216581276\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 81, train_loss = 9.895367411896586, train_acc = 0.9791569632044713\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 82, train_loss = 9.790377706289291, train_acc = 0.9791569632044713\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 83, train_loss = 9.687458291649818, train_acc = 0.9792734047508151\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 84, train_loss = 9.586180448532104, train_acc = 0.9792734047508151\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 85, train_loss = 9.486792743206024, train_acc = 0.9793898462971589\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 86, train_loss = 9.389196891337633, train_acc = 0.9796227293898463\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 87, train_loss = 9.293252691626549, train_acc = 0.9798556124825337\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 88, train_loss = 9.198915340006351, train_acc = 0.980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 89, train_loss = 9.106276728212833, train_acc = 0.9803213786679087\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 90, train_loss = 9.01522210240364, train_acc = 0.9804378202142524\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 91, train_loss = 8.925466060638428, train_acc = 0.9805542617605962\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 92, train_loss = 8.83715995401144, train_acc = 0.9805542617605962\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 93, train_loss = 8.750438768416643, train_acc = 0.9807871448532837\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 94, train_loss = 8.664903793483973, train_acc = 0.9812529110386586\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 95, train_loss = 8.58080342784524, train_acc = 0.9814857941313461\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 96, train_loss = 8.497930109500885, train_acc = 0.9818351187703773\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 97, train_loss = 8.41652455367148, train_acc = 0.981951560316721\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 98, train_loss = 8.336127266287804, train_acc = 0.9821844434094085\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 99, train_loss = 8.256857547909021, train_acc = 0.9825337680484397\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 100, train_loss = 8.178872723132372, train_acc = 0.9826502095947834\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 101, train_loss = 8.101971209049225, train_acc = 0.9829995342338146\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 102, train_loss = 8.026055062189698, train_acc = 0.9833488588728458\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 103, train_loss = 7.951183564960957, train_acc = 0.9834653004191896\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 104, train_loss = 7.877493996173143, train_acc = 0.9835817419655333\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 105, train_loss = 7.804719591513276, train_acc = 0.983698183511877\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 106, train_loss = 7.732960719615221, train_acc = 0.9839310666045645\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 107, train_loss = 7.662052042782307, train_acc = 0.9840475081509082\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 108, train_loss = 7.592184999957681, train_acc = 0.984163949697252\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 109, train_loss = 7.523216670379043, train_acc = 0.9843968327899395\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 110, train_loss = 7.455197997391224, train_acc = 0.9845132743362832\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 111, train_loss = 7.387986114248633, train_acc = 0.9845132743362832\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 112, train_loss = 7.3216766975820065, train_acc = 0.9845132743362832\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 113, train_loss = 7.25631283596158, train_acc = 0.9846297158826269\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 114, train_loss = 7.191698916256428, train_acc = 0.9849790405216581\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 115, train_loss = 7.127931689843535, train_acc = 0.9852119236143456\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 116, train_loss = 7.064858183264732, train_acc = 0.9852119236143456\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 117, train_loss = 7.002639036625624, train_acc = 0.9856776897997206\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 118, train_loss = 6.941322989761829, train_acc = 0.9861434559850955\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 119, train_loss = 6.880734339356422, train_acc = 0.9861434559850955\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 120, train_loss = 6.820961005985737, train_acc = 0.9862598975314392\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 121, train_loss = 6.761752422899008, train_acc = 0.9864927806241267\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 122, train_loss = 6.70246166177094, train_acc = 0.9866092221704704\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 123, train_loss = 6.644419025629759, train_acc = 0.9868421052631579\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 124, train_loss = 6.587260095402598, train_acc = 0.9867256637168141\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 125, train_loss = 6.531152728945017, train_acc = 0.9867256637168141\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 126, train_loss = 6.475440125912428, train_acc = 0.9869585468095017\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 127, train_loss = 6.42024558223784, train_acc = 0.9871914299021891\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 128, train_loss = 6.365768752992153, train_acc = 0.9873078714485328\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 129, train_loss = 6.312210664153099, train_acc = 0.9874243129948765\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 130, train_loss = 6.259154008701444, train_acc = 0.9875407545412203\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 131, train_loss = 6.206957705318928, train_acc = 0.9875407545412203\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 132, train_loss = 6.155373813584447, train_acc = 0.9876571960875641\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 133, train_loss = 6.1043182592839, train_acc = 0.9876571960875641\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 134, train_loss = 6.053913740441203, train_acc = 0.9878900791802515\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 135, train_loss = 6.004333766177297, train_acc = 0.9880065207265952\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 136, train_loss = 5.955108653753996, train_acc = 0.9880065207265952\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 137, train_loss = 5.906627496704459, train_acc = 0.9882394038192828\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 138, train_loss = 5.858707161620259, train_acc = 0.9882394038192828\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 139, train_loss = 5.811293635517359, train_acc = 0.9882394038192828\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 140, train_loss = 5.764732314273715, train_acc = 0.9883558453656265\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 141, train_loss = 5.7184914369136095, train_acc = 0.9887051700046576\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 142, train_loss = 5.67293643951416, train_acc = 0.9887051700046576\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 143, train_loss = 5.627739394083619, train_acc = 0.9887051700046576\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 144, train_loss = 5.583036677911878, train_acc = 0.9888216115510013\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 145, train_loss = 5.539035189896822, train_acc = 0.9889380530973452\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 146, train_loss = 5.495502719655633, train_acc = 0.9890544946436889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 147, train_loss = 5.452610153704882, train_acc = 0.9891709361900326\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 148, train_loss = 5.410106731578708, train_acc = 0.9891709361900326\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 149, train_loss = 5.368116229772568, train_acc = 0.98940381928272\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 150, train_loss = 5.326679049059749, train_acc = 0.9895202608290639\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 151, train_loss = 5.285763928666711, train_acc = 0.9895202608290639\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 152, train_loss = 5.245486969128251, train_acc = 0.9895202608290639\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 153, train_loss = 5.205567976459861, train_acc = 0.9895202608290639\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 154, train_loss = 5.166103754192591, train_acc = 0.9896367023754076\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 155, train_loss = 5.127054803073406, train_acc = 0.9897531439217513\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 156, train_loss = 5.088505099527538, train_acc = 0.9897531439217513\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 157, train_loss = 5.050497523508966, train_acc = 0.9897531439217513\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 158, train_loss = 5.0128487451002, train_acc = 0.989869585468095\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 159, train_loss = 4.975724003277719, train_acc = 0.989869585468095\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 160, train_loss = 4.9390525855124, train_acc = 0.989869585468095\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 161, train_loss = 4.9028166541829705, train_acc = 0.9901024685607824\n",
      "test Acc 0.9776536312849162:\n",
      "20th- epoch: 162, train_loss = 4.867162455804646, train_acc = 0.9901024685607824\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 163, train_loss = 4.831763591617346, train_acc = 0.9901024685607824\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 164, train_loss = 4.796810534782708, train_acc = 0.9902189101071263\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 165, train_loss = 4.76229742821306, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 166, train_loss = 4.728163789026439, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 167, train_loss = 4.694571782834828, train_acc = 0.9902189101071263\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 168, train_loss = 4.661269575357437, train_acc = 0.9902189101071263\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 169, train_loss = 4.628456869162619, train_acc = 0.9902189101071263\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 170, train_loss = 4.595924091525376, train_acc = 0.9904517931998137\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 171, train_loss = 4.563998921774328, train_acc = 0.990801117838845\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 172, train_loss = 4.532236668281257, train_acc = 0.990801117838845\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 173, train_loss = 4.501100659370422, train_acc = 0.9909175593851887\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 174, train_loss = 4.470170508138835, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 175, train_loss = 4.439703729003668, train_acc = 0.9911504424778761\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 176, train_loss = 4.409581775777042, train_acc = 0.9912668840242198\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 177, train_loss = 4.379946976900101, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 178, train_loss = 4.350501406937838, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 179, train_loss = 4.321519387885928, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 180, train_loss = 4.292857917025685, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 181, train_loss = 4.2645551627501845, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 182, train_loss = 4.236644531600177, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 183, train_loss = 4.208847775124013, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 184, train_loss = 4.181593879126012, train_acc = 0.9916162086632511\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 185, train_loss = 4.154487643390894, train_acc = 0.9917326502095948\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 186, train_loss = 4.127790044993162, train_acc = 0.9918490917559385\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 187, train_loss = 4.101275750435889, train_acc = 0.9918490917559385\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 188, train_loss = 4.07523241546005, train_acc = 0.9918490917559385\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 189, train_loss = 4.049500512890518, train_acc = 0.9918490917559385\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 190, train_loss = 4.023968920111656, train_acc = 0.9919655333022822\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 191, train_loss = 3.9988269777968526, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 192, train_loss = 3.973946106620133, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 193, train_loss = 3.9492943175137043, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 194, train_loss = 3.925030396319926, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 195, train_loss = 3.900912143290043, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 196, train_loss = 3.8771980330348015, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 197, train_loss = 3.853682198561728, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 198, train_loss = 3.8304386101663113, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 199, train_loss = 3.8074862333014607, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 200, train_loss = 3.7847440177574754, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 201, train_loss = 3.7621909799054265, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 202, train_loss = 3.739996526390314, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 203, train_loss = 3.718018800020218, train_acc = 0.9923148579413135\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 204, train_loss = 3.6962979892268777, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 205, train_loss = 3.6748023442924023, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 206, train_loss = 3.6534660821780562, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 207, train_loss = 3.632476852275431, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 208, train_loss = 3.611676901578903, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "20th- epoch: 209, train_loss = 3.5910682128742337, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 210, train_loss = 3.570723014883697, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 211, train_loss = 3.550626250449568, train_acc = 0.9926641825803446\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 212, train_loss = 3.5306730843149126, train_acc = 0.9926641825803446\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 213, train_loss = 3.510998362209648, train_acc = 0.9927806241266884\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 214, train_loss = 3.4916079714894295, train_acc = 0.9927806241266884\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 215, train_loss = 3.4722435348667204, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 216, train_loss = 3.4531472311355174, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 217, train_loss = 3.434318100567907, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 218, train_loss = 3.415529016405344, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 219, train_loss = 3.397210044786334, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 220, train_loss = 3.378817078191787, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 221, train_loss = 3.3607689272612333, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 222, train_loss = 3.3428803659044206, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 223, train_loss = 3.325089320540428, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 224, train_loss = 3.307576898019761, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 225, train_loss = 3.290299551561475, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 226, train_loss = 3.272984637413174, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 227, train_loss = 3.2560463142581284, train_acc = 0.9932463903120633\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 228, train_loss = 3.2391845248639584, train_acc = 0.9932463903120633\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 229, train_loss = 3.222550384234637, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 230, train_loss = 3.2059765397571027, train_acc = 0.9932463903120633\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 231, train_loss = 3.1897343448363245, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 232, train_loss = 3.173427034635097, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 233, train_loss = 3.1574692465364933, train_acc = 0.9933628318584071\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 234, train_loss = 3.1415407550521195, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 235, train_loss = 3.1258329660631716, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 236, train_loss = 3.110243273433298, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 237, train_loss = 3.0948152858763933, train_acc = 0.9935957149510946\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 238, train_loss = 3.0795418662019074, train_acc = 0.9935957149510946\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 239, train_loss = 3.064433058258146, train_acc = 0.9937121564974383\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 240, train_loss = 3.0495323915965855, train_acc = 0.9937121564974383\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 241, train_loss = 3.034668712411076, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 242, train_loss = 3.0200120992958546, train_acc = 0.9939450395901258\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 243, train_loss = 3.0055328644812107, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 244, train_loss = 2.9910554215312004, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 245, train_loss = 2.9768604766577482, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 246, train_loss = 2.9626348670572042, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 247, train_loss = 2.948760569561273, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 248, train_loss = 2.93493271805346, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 249, train_loss = 2.921215584501624, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 250, train_loss = 2.907632257323712, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 251, train_loss = 2.894162588287145, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 252, train_loss = 2.8808512296527624, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 253, train_loss = 2.867650545667857, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 254, train_loss = 2.854543214198202, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 255, train_loss = 2.8416843079030514, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 256, train_loss = 2.828899224754423, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 257, train_loss = 2.8161524175666273, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 258, train_loss = 2.8035359331406653, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 259, train_loss = 2.7910630865953863, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 260, train_loss = 2.778715018182993, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 261, train_loss = 2.766657216940075, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 262, train_loss = 2.7542761736549437, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 263, train_loss = 2.742505695670843, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 264, train_loss = 2.7305695875547826, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 265, train_loss = 2.718736289534718, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 266, train_loss = 2.7070974954403937, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 267, train_loss = 2.695499444846064, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 268, train_loss = 2.684105704072863, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 269, train_loss = 2.672746103256941, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 270, train_loss = 2.661487728357315, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 271, train_loss = 2.6504144654609263, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 272, train_loss = 2.639289937913418, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 273, train_loss = 2.628440776374191, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 274, train_loss = 2.6175987483002245, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 275, train_loss = 2.606972558889538, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 276, train_loss = 2.5962548316456378, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 277, train_loss = 2.585719096008688, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 278, train_loss = 2.5753796086646616, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 279, train_loss = 2.5650816806592047, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 280, train_loss = 2.554798072669655, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 281, train_loss = 2.5446942287962884, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 282, train_loss = 2.5347085136454552, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 283, train_loss = 2.5247197039425373, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 284, train_loss = 2.514986402122304, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 285, train_loss = 2.505119862733409, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 286, train_loss = 2.495534001616761, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 287, train_loss = 2.486018442781642, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 288, train_loss = 2.476552842883393, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 289, train_loss = 2.467155070276931, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 290, train_loss = 2.457879900932312, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 291, train_loss = 2.4487717982847244, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 292, train_loss = 2.439631911693141, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 293, train_loss = 2.4305530686397105, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 294, train_loss = 2.4217455238103867, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 295, train_loss = 2.412802714854479, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 296, train_loss = 2.404037893982604, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 297, train_loss = 2.3953188497107476, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 298, train_loss = 2.3867076199967414, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 299, train_loss = 2.378112281439826, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 300, train_loss = 2.369658637791872, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 301, train_loss = 2.361210049362853, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 302, train_loss = 2.353020381182432, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 303, train_loss = 2.3448809918481857, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 304, train_loss = 2.336703744949773, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 305, train_loss = 2.328714281320572, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 306, train_loss = 2.3207307073753327, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 307, train_loss = 2.312962503405288, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 308, train_loss = 2.3051720384974033, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 309, train_loss = 2.297451213002205, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 310, train_loss = 2.2898423683363944, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 311, train_loss = 2.28234217944555, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 312, train_loss = 2.274784956127405, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 313, train_loss = 2.2674861040432006, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 314, train_loss = 2.2601565942168236, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 315, train_loss = 2.2529035869520158, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 316, train_loss = 2.2457031819503754, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 317, train_loss = 2.2387117967009544, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 318, train_loss = 2.23163761314936, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 319, train_loss = 2.224711447954178, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 320, train_loss = 2.217754663201049, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 321, train_loss = 2.211086453171447, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 322, train_loss = 2.2042074762284756, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 323, train_loss = 2.1974988281726837, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 324, train_loss = 2.1908649678807706, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 325, train_loss = 2.1842636328656226, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 326, train_loss = 2.1776969607453793, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 327, train_loss = 2.1714653943199664, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 328, train_loss = 2.1649856057483703, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 329, train_loss = 2.1586303003132343, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 330, train_loss = 2.152468043146655, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 331, train_loss = 2.1462959323544055, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 332, train_loss = 2.1401719488203526, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 333, train_loss = 2.13396851089783, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 334, train_loss = 2.1280526455957443, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 335, train_loss = 2.122057141037658, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 336, train_loss = 2.116230135085061, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 337, train_loss = 2.110210261074826, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 338, train_loss = 2.1045375566463917, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 339, train_loss = 2.0988005970139056, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 340, train_loss = 2.092985524563119, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 341, train_loss = 2.0874578568618745, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 342, train_loss = 2.0818078306037933, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 343, train_loss = 2.0762266640085727, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 344, train_loss = 2.070699704112485, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 345, train_loss = 2.065405062166974, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 346, train_loss = 2.0598607163410634, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 347, train_loss = 2.0546810154337436, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 348, train_loss = 2.049192354083061, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 349, train_loss = 2.044097476871684, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 350, train_loss = 2.03890261054039, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 351, train_loss = 2.033600553870201, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 352, train_loss = 2.0285455982666463, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 353, train_loss = 2.0234745431225747, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 354, train_loss = 2.0185406890232116, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 355, train_loss = 2.0134152732789516, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 356, train_loss = 2.008544733049348, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 357, train_loss = 2.0036348204594105, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 358, train_loss = 1.9987831935286522, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 359, train_loss = 1.9940031704027206, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 360, train_loss = 1.9892607207875699, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 361, train_loss = 1.9844542283099145, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 362, train_loss = 1.9798451662063599, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 363, train_loss = 1.9751369605073705, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 364, train_loss = 1.9706378566334024, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 365, train_loss = 1.965948510915041, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 366, train_loss = 1.9614820828428492, train_acc = 0.9954587796925943\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 367, train_loss = 1.9568798802793026, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 368, train_loss = 1.9525178372859955, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 369, train_loss = 1.9480468208203092, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 370, train_loss = 1.9436580166220665, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 371, train_loss = 1.9393609376857057, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 372, train_loss = 1.9350172504782677, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 373, train_loss = 1.9307258278131485, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 374, train_loss = 1.926470002741553, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 375, train_loss = 1.9223087491700426, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 376, train_loss = 1.9181217662990093, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 377, train_loss = 1.9139874478569254, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 378, train_loss = 1.9098706977674738, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 379, train_loss = 1.9058179868152365, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 380, train_loss = 1.9018516180804, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 381, train_loss = 1.8977993117878214, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 382, train_loss = 1.8937414711108431, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 383, train_loss = 1.889901606948115, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 384, train_loss = 1.8859675886342302, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 385, train_loss = 1.8819983837893233, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 386, train_loss = 1.8781814003596082, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 387, train_loss = 1.8742943791439757, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 388, train_loss = 1.8705116981873289, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 389, train_loss = 1.8666689470410347, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 390, train_loss = 1.8627796781947836, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 391, train_loss = 1.8592588106403127, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 392, train_loss = 1.8555511956801638, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 393, train_loss = 1.8519861834356561, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 394, train_loss = 1.8482994958758354, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 395, train_loss = 1.8447322808206081, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 396, train_loss = 1.8411699905991554, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 397, train_loss = 1.837655983865261, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 398, train_loss = 1.8341781720519066, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 399, train_loss = 1.8307100521633402, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 400, train_loss = 1.8272946613142267, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 401, train_loss = 1.8237728303065524, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 402, train_loss = 1.8203989813337103, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 403, train_loss = 1.817110845237039, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 404, train_loss = 1.8137334436178207, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 405, train_loss = 1.8104338012635708, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 406, train_loss = 1.8071110075106844, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 407, train_loss = 1.8039219515630975, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 408, train_loss = 1.8006514323642477, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 409, train_loss = 1.7974848374724388, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 410, train_loss = 1.7942023910582066, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 411, train_loss = 1.791075593442656, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 412, train_loss = 1.7879300290951505, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 413, train_loss = 1.7848259719321504, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 414, train_loss = 1.7816470140824094, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 415, train_loss = 1.7785986065864563, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 416, train_loss = 1.7755481464555487, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 417, train_loss = 1.7726209834218025, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 418, train_loss = 1.7694793790578842, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 419, train_loss = 1.7665758481016383, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 420, train_loss = 1.763575198710896, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 421, train_loss = 1.7606998272240162, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 422, train_loss = 1.7575974141946062, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 423, train_loss = 1.7549270814051852, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 424, train_loss = 1.7519122883677483, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 425, train_loss = 1.7491097785532475, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 426, train_loss = 1.7461267547914758, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 427, train_loss = 1.7434893535682932, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 428, train_loss = 1.7405576506862417, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 429, train_loss = 1.7377943632891402, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 430, train_loss = 1.7350764349102974, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 431, train_loss = 1.732348763733171, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 432, train_loss = 1.7295488180825487, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 433, train_loss = 1.7270618254551664, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 434, train_loss = 1.72416153550148, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 435, train_loss = 1.721604453981854, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 436, train_loss = 1.7188925308873877, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 437, train_loss = 1.7164258571574464, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 438, train_loss = 1.7135818476090208, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 439, train_loss = 1.7111219664802775, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 440, train_loss = 1.7085223322501406, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 441, train_loss = 1.7060200708219782, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 442, train_loss = 1.7033892447361723, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 443, train_loss = 1.7008855106541887, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 444, train_loss = 1.6984265794744715, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 445, train_loss = 1.6957949163625017, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 446, train_loss = 1.6934111876180395, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 447, train_loss = 1.6909197084605694, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 448, train_loss = 1.6885681686690077, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 449, train_loss = 1.6861018998315558, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 450, train_loss = 1.6837804466485977, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "20th- epoch: 451, train_loss = 1.6812191853532568, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 452, train_loss = 1.6790845058858395, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 453, train_loss = 1.6765023184707388, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 454, train_loss = 1.674267521710135, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 455, train_loss = 1.6720145331928506, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 456, train_loss = 1.6696520125260577, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 457, train_loss = 1.6672792980680242, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 458, train_loss = 1.6650795402238145, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 459, train_loss = 1.6627385318279266, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 460, train_loss = 1.6605311942985281, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 461, train_loss = 1.6583249742398039, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 462, train_loss = 1.6560257226228714, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 463, train_loss = 1.6539200358092785, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 464, train_loss = 1.651763943315018, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 465, train_loss = 1.6494427261059172, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 466, train_loss = 1.6473403759300709, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 467, train_loss = 1.6452205926179886, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 468, train_loss = 1.6430537104606628, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 469, train_loss = 1.640871960669756, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 470, train_loss = 1.6387753908638842, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 471, train_loss = 1.6366766330902465, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 472, train_loss = 1.6346810298855416, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 473, train_loss = 1.6325667276978493, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 474, train_loss = 1.630545234947931, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 475, train_loss = 1.6284753319923766, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 476, train_loss = 1.6265133035485633, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 477, train_loss = 1.6244078266317956, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 478, train_loss = 1.622529860585928, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 479, train_loss = 1.6203679616446607, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 480, train_loss = 1.618584697425831, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 481, train_loss = 1.6164378772373311, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 482, train_loss = 1.6146057844161987, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 483, train_loss = 1.6125020161271095, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 484, train_loss = 1.6107031417195685, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 485, train_loss = 1.6088376852567308, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 486, train_loss = 1.6068899159436114, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 487, train_loss = 1.6049707743222825, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 488, train_loss = 1.6032397995586507, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 489, train_loss = 1.60115597397089, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 490, train_loss = 1.5993909475510009, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 491, train_loss = 1.5975830529932864, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 492, train_loss = 1.5957632337813266, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 493, train_loss = 1.593891681462992, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 494, train_loss = 1.5921397184138186, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 495, train_loss = 1.5903354187612422, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 496, train_loss = 1.5884583902661689, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 497, train_loss = 1.586722481995821, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 498, train_loss = 1.5849476220901124, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "20th- epoch: 499, train_loss = 1.583187943964731, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████▋                       | 20/30 [2:12:51<1:06:18, 397.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "21th- epoch: 0, train_loss = 268.9405608177185, train_acc = 0.43060083837913365\n",
      "test Acc 0.48417132216014896:\n",
      "21th- epoch: 1, train_loss = 206.42288517951965, train_acc = 0.4890544946436889\n",
      "test Acc 0.49767225325884545:\n",
      "21th- epoch: 2, train_loss = 168.6500025987625, train_acc = 0.5045412203074057\n",
      "test Acc 0.5242085661080075:\n",
      "21th- epoch: 3, train_loss = 148.33989715576172, train_acc = 0.6042151839776432\n",
      "test Acc 0.6745810055865922:\n",
      "21th- epoch: 4, train_loss = 131.84061205387115, train_acc = 0.6960875640428504\n",
      "test Acc 0.7248603351955307:\n",
      "21th- epoch: 5, train_loss = 116.71534651517868, train_acc = 0.73067070330694\n",
      "test Acc 0.7486033519553073:\n",
      "21th- epoch: 6, train_loss = 103.01619952917099, train_acc = 0.7586166744294365\n",
      "test Acc 0.7797951582867784:\n",
      "21th- epoch: 7, train_loss = 91.05052801966667, train_acc = 0.8025151374010246\n",
      "test Acc 0.8105214152700186:\n",
      "21th- epoch: 8, train_loss = 80.77907022833824, train_acc = 0.8220773171867722\n",
      "test Acc 0.8277467411545624:\n",
      "21th- epoch: 9, train_loss = 71.93159371614456, train_acc = 0.8400093153237075\n",
      "test Acc 0.8491620111731844:\n",
      "21th- epoch: 10, train_loss = 64.30145475268364, train_acc = 0.8645784816022357\n",
      "test Acc 0.8803538175046555:\n",
      "21th- epoch: 11, train_loss = 57.802043199539185, train_acc = 0.8932231020027946\n",
      "test Acc 0.8947858472998138:\n",
      "21th- epoch: 12, train_loss = 52.345119431614876, train_acc = 0.9083605030274802\n",
      "test Acc 0.909217877094972:\n",
      "21th- epoch: 13, train_loss = 47.7931984513998, train_acc = 0.917675826734979\n",
      "test Acc 0.9185288640595903:\n",
      "21th- epoch: 14, train_loss = 43.98875439167023, train_acc = 0.9252445272473219\n",
      "test Acc 0.925512104283054:\n",
      "21th- epoch: 15, train_loss = 40.79925511777401, train_acc = 0.9342105263157895\n",
      "test Acc 0.9329608938547486:\n",
      "21th- epoch: 16, train_loss = 38.10360096395016, train_acc = 0.9387517466231952\n",
      "test Acc 0.9394785847299814:\n",
      "21th- epoch: 17, train_loss = 35.80086353421211, train_acc = 0.9422449930135072\n",
      "test Acc 0.9404096834264432:\n",
      "21th- epoch: 18, train_loss = 33.81621968746185, train_acc = 0.9439916162086632\n",
      "test Acc 0.9413407821229051:\n",
      "21th- epoch: 19, train_loss = 32.09355400502682, train_acc = 0.945854680950163\n",
      "test Acc 0.9436685288640596:\n",
      "21th- epoch: 20, train_loss = 30.587762214243412, train_acc = 0.9472519795062878\n",
      "test Acc 0.9455307262569832:\n",
      "21th- epoch: 21, train_loss = 29.25996996462345, train_acc = 0.9491150442477876\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 22, train_loss = 28.081387490034103, train_acc = 0.950279459711225\n",
      "test Acc 0.9501862197392924:\n",
      "21th- epoch: 23, train_loss = 27.02610445767641, train_acc = 0.9517931998136935\n",
      "test Acc 0.9506517690875232:\n",
      "21th- epoch: 24, train_loss = 26.072224035859108, train_acc = 0.9540055891942245\n",
      "test Acc 0.952048417132216:\n",
      "21th- epoch: 25, train_loss = 25.204071931540966, train_acc = 0.9554028877503493\n",
      "test Acc 0.9515828677839852:\n",
      "21th- epoch: 26, train_loss = 24.40938351303339, train_acc = 0.9571495109455054\n",
      "test Acc 0.952513966480447:\n",
      "21th- epoch: 27, train_loss = 23.676541931927204, train_acc = 0.9583139264089428\n",
      "test Acc 0.9543761638733705:\n",
      "21th- epoch: 28, train_loss = 22.99770227447152, train_acc = 0.9591290172333489\n",
      "test Acc 0.9548417132216015:\n",
      "21th- epoch: 29, train_loss = 22.36705620214343, train_acc = 0.9598276665114113\n",
      "test Acc 0.9562383612662942:\n",
      "21th- epoch: 30, train_loss = 21.778917863965034, train_acc = 0.9601769911504425\n",
      "test Acc 0.957169459962756:\n",
      "21th- epoch: 31, train_loss = 21.2285344786942, train_acc = 0.96040987424313\n",
      "test Acc 0.957169459962756:\n",
      "21th- epoch: 32, train_loss = 20.711852706968784, train_acc = 0.9611085235211924\n",
      "test Acc 0.957635009310987:\n",
      "21th- epoch: 33, train_loss = 20.225881654769182, train_acc = 0.9623893805309734\n",
      "test Acc 0.9581005586592178:\n",
      "21th- epoch: 34, train_loss = 19.766937039792538, train_acc = 0.9628551467163484\n",
      "test Acc 0.9585661080074488:\n",
      "21th- epoch: 35, train_loss = 19.332460805773735, train_acc = 0.9633209129017233\n",
      "test Acc 0.9590316573556797:\n",
      "21th- epoch: 36, train_loss = 18.919306192547083, train_acc = 0.963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 37, train_loss = 18.525934990495443, train_acc = 0.9648346530041919\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 38, train_loss = 18.150940284132957, train_acc = 0.9651839776432231\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 39, train_loss = 17.792870853096247, train_acc = 0.9663483931066604\n",
      "test Acc 0.9599627560521415:\n",
      "21th- epoch: 40, train_loss = 17.450345251709223, train_acc = 0.9668141592920354\n",
      "test Acc 0.9608938547486033:\n",
      "21th- epoch: 41, train_loss = 17.121664196252823, train_acc = 0.9676292501164415\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 42, train_loss = 16.806111074984074, train_acc = 0.9686772240335352\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 43, train_loss = 16.502683870494366, train_acc = 0.9693758733115976\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 44, train_loss = 16.210494596511126, train_acc = 0.9701909641360037\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 45, train_loss = 15.928816817700863, train_acc = 0.9707731718677224\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 46, train_loss = 15.657099351286888, train_acc = 0.9712389380530974\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 47, train_loss = 15.394586347043514, train_acc = 0.9714718211457848\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 48, train_loss = 15.140374049544334, train_acc = 0.9719375873311598\n",
      "test Acc 0.9650837988826816:\n",
      "21th- epoch: 49, train_loss = 14.89441728964448, train_acc = 0.9721704704238472\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 50, train_loss = 14.656168531626463, train_acc = 0.9724033535165347\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 51, train_loss = 14.425376635044813, train_acc = 0.9727526781555659\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 52, train_loss = 14.201853439211845, train_acc = 0.9725197950628784\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 53, train_loss = 13.985312182456255, train_acc = 0.9729855612482534\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 54, train_loss = 13.775456175208092, train_acc = 0.9733348858872846\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 55, train_loss = 13.57177085801959, train_acc = 0.9736842105263158\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 56, train_loss = 13.374254563823342, train_acc = 0.974033535165347\n",
      "test Acc 0.9669459962756052:\n",
      "21th- epoch: 57, train_loss = 13.183425122871995, train_acc = 0.9741499767116907\n",
      "test Acc 0.9669459962756052:\n",
      "21th- epoch: 58, train_loss = 12.998577961698174, train_acc = 0.9742664182580345\n",
      "test Acc 0.9674115456238361:\n",
      "21th- epoch: 59, train_loss = 12.818899480625987, train_acc = 0.9743828598043782\n",
      "test Acc 0.9674115456238361:\n",
      "21th- epoch: 60, train_loss = 12.644151400774717, train_acc = 0.9744993013507219\n",
      "test Acc 0.9674115456238361:\n",
      "21th- epoch: 61, train_loss = 12.474082577973604, train_acc = 0.9750815090824406\n",
      "test Acc 0.9669459962756052:\n",
      "21th- epoch: 62, train_loss = 12.308882683515549, train_acc = 0.9751979506287843\n",
      "test Acc 0.9669459962756052:\n",
      "21th- epoch: 63, train_loss = 12.147891256958246, train_acc = 0.9760130414531905\n",
      "test Acc 0.9674115456238361:\n",
      "21th- epoch: 64, train_loss = 11.991104200482368, train_acc = 0.9764788076385654\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 65, train_loss = 11.838161654770374, train_acc = 0.9768281322775967\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 66, train_loss = 11.688839480280876, train_acc = 0.9768281322775967\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 67, train_loss = 11.543393321335316, train_acc = 0.9770610153702841\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 68, train_loss = 11.401933839544654, train_acc = 0.9774103400093154\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 69, train_loss = 11.264131713658571, train_acc = 0.9777596646483465\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 70, train_loss = 11.129560079425573, train_acc = 0.9778761061946902\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 71, train_loss = 10.998079622164369, train_acc = 0.977992547741034\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 72, train_loss = 10.869437105953693, train_acc = 0.977992547741034\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 73, train_loss = 10.74385198391974, train_acc = 0.9782254308337215\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 74, train_loss = 10.620902486145496, train_acc = 0.9785747554727526\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 75, train_loss = 10.500564884394407, train_acc = 0.9786911970190965\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 76, train_loss = 10.38269074819982, train_acc = 0.9785747554727526\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 77, train_loss = 10.267218183726072, train_acc = 0.9786911970190965\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 78, train_loss = 10.15409642830491, train_acc = 0.9786911970190965\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 79, train_loss = 10.043088391423225, train_acc = 0.9788076385654402\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 80, train_loss = 9.934185221791267, train_acc = 0.9789240801117839\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 81, train_loss = 9.827339071780443, train_acc = 0.9789240801117839\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 82, train_loss = 9.722470853477716, train_acc = 0.9789240801117839\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 83, train_loss = 9.6194275803864, train_acc = 0.9790405216581276\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 84, train_loss = 9.518074780702591, train_acc = 0.9792734047508151\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 85, train_loss = 9.418042853474617, train_acc = 0.9795062878435026\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 86, train_loss = 9.319831665605307, train_acc = 0.9796227293898463\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 87, train_loss = 9.223690751940012, train_acc = 0.97973917093619\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 88, train_loss = 9.129053924232721, train_acc = 0.97973917093619\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 89, train_loss = 9.036119930446148, train_acc = 0.9799720540288775\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 90, train_loss = 8.94455635547638, train_acc = 0.9799720540288775\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 91, train_loss = 8.854613415896893, train_acc = 0.980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 92, train_loss = 8.765865258872509, train_acc = 0.9803213786679087\n",
      "test Acc 0.9692737430167597:\n",
      "21th- epoch: 93, train_loss = 8.67860060557723, train_acc = 0.9805542617605962\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 94, train_loss = 8.592834781855345, train_acc = 0.9805542617605962\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 95, train_loss = 8.508341109380126, train_acc = 0.98067070330694\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 96, train_loss = 8.425226174294949, train_acc = 0.9809035863996274\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 97, train_loss = 8.343378592282534, train_acc = 0.9811364694923148\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 98, train_loss = 8.262712685391307, train_acc = 0.9816022356776898\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 99, train_loss = 8.181969683617353, train_acc = 0.981951560316721\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 100, train_loss = 8.102697424590588, train_acc = 0.9823008849557522\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 101, train_loss = 8.024327585473657, train_acc = 0.9827666511411272\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 102, train_loss = 7.947693265974522, train_acc = 0.9828830926874709\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 103, train_loss = 7.872410481795669, train_acc = 0.9831159757801584\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 104, train_loss = 7.798461375758052, train_acc = 0.9833488588728458\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 105, train_loss = 7.725412525236607, train_acc = 0.9834653004191896\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 106, train_loss = 7.653434701263905, train_acc = 0.9835817419655333\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 107, train_loss = 7.582724099978805, train_acc = 0.9835817419655333\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 108, train_loss = 7.51287885196507, train_acc = 0.9835817419655333\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 109, train_loss = 7.444327728822827, train_acc = 0.9840475081509082\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 110, train_loss = 7.376649962738156, train_acc = 0.9840475081509082\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 111, train_loss = 7.309958564117551, train_acc = 0.9842803912435957\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 112, train_loss = 7.243968419730663, train_acc = 0.9846297158826269\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 113, train_loss = 7.179055102169514, train_acc = 0.9847461574289706\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 114, train_loss = 7.114926226437092, train_acc = 0.9848625989753144\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 115, train_loss = 7.051533764228225, train_acc = 0.9848625989753144\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 116, train_loss = 6.98924009129405, train_acc = 0.9852119236143456\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 117, train_loss = 6.927891040220857, train_acc = 0.9853283651606893\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 118, train_loss = 6.867243390530348, train_acc = 0.985444806707033\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 119, train_loss = 6.807634595781565, train_acc = 0.9855612482533768\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 120, train_loss = 6.748940907418728, train_acc = 0.9857941313460643\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 121, train_loss = 6.691004939377308, train_acc = 0.9857941313460643\n",
      "test Acc 0.972998137802607:\n",
      "21th- epoch: 122, train_loss = 6.633982678875327, train_acc = 0.985910572892408\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 123, train_loss = 6.57759059779346, train_acc = 0.9860270144387517\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 124, train_loss = 6.522048128768802, train_acc = 0.9861434559850955\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 125, train_loss = 6.467230321839452, train_acc = 0.986376339077783\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 126, train_loss = 6.413007851690054, train_acc = 0.9867256637168141\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 127, train_loss = 6.3597799595445395, train_acc = 0.9866092221704704\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 128, train_loss = 6.306903213262558, train_acc = 0.9868421052631579\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 129, train_loss = 6.254612293094397, train_acc = 0.9869585468095017\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 130, train_loss = 6.203288404271007, train_acc = 0.9873078714485328\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 131, train_loss = 6.15251369215548, train_acc = 0.9873078714485328\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 132, train_loss = 6.1025000140070915, train_acc = 0.9875407545412203\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 133, train_loss = 6.0529690608382225, train_acc = 0.9876571960875641\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 134, train_loss = 6.0043048076331615, train_acc = 0.9877736376339078\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 135, train_loss = 5.956260712817311, train_acc = 0.9877736376339078\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 136, train_loss = 5.908835669979453, train_acc = 0.9878900791802515\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 137, train_loss = 5.862095749005675, train_acc = 0.9881229622729389\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 138, train_loss = 5.815777001902461, train_acc = 0.9881229622729389\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 139, train_loss = 5.770275920629501, train_acc = 0.9881229622729389\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 140, train_loss = 5.725253198295832, train_acc = 0.9882394038192828\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 141, train_loss = 5.680826332420111, train_acc = 0.9883558453656265\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 142, train_loss = 5.63687832839787, train_acc = 0.9888216115510013\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 143, train_loss = 5.593625031411648, train_acc = 0.9890544946436889\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 144, train_loss = 5.550829825922847, train_acc = 0.9891709361900326\n",
      "test Acc 0.9739292364990689:\n",
      "21th- epoch: 145, train_loss = 5.508487371727824, train_acc = 0.9895202608290639\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 146, train_loss = 5.466867620125413, train_acc = 0.9895202608290639\n",
      "test Acc 0.9743947858472998:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 147, train_loss = 5.425589187070727, train_acc = 0.9895202608290639\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 148, train_loss = 5.384985430166125, train_acc = 0.9896367023754076\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 149, train_loss = 5.3448163121938705, train_acc = 0.9896367023754076\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 150, train_loss = 5.305036624893546, train_acc = 0.9897531439217513\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 151, train_loss = 5.265855433419347, train_acc = 0.9897531439217513\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 152, train_loss = 5.2270667143166065, train_acc = 0.989869585468095\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 153, train_loss = 5.188845289871097, train_acc = 0.9901024685607824\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 154, train_loss = 5.150844976305962, train_acc = 0.9901024685607824\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 155, train_loss = 5.113533138297498, train_acc = 0.9901024685607824\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 156, train_loss = 5.076444740407169, train_acc = 0.9901024685607824\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 157, train_loss = 5.040038425475359, train_acc = 0.9901024685607824\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 158, train_loss = 5.004014145582914, train_acc = 0.9902189101071263\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 159, train_loss = 4.968410177156329, train_acc = 0.9902189101071263\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 160, train_loss = 4.933321583084762, train_acc = 0.9902189101071263\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 161, train_loss = 4.8985856072977185, train_acc = 0.9902189101071263\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 162, train_loss = 4.864408308640122, train_acc = 0.9902189101071263\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 163, train_loss = 4.8305556531995535, train_acc = 0.99033535165347\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 164, train_loss = 4.79706144053489, train_acc = 0.9905682347461574\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 165, train_loss = 4.764110853895545, train_acc = 0.9906846762925011\n",
      "test Acc 0.9767225325884544:\n",
      "21th- epoch: 166, train_loss = 4.731290242634714, train_acc = 0.9909175593851887\n",
      "test Acc 0.9767225325884544:\n",
      "21th- epoch: 167, train_loss = 4.699065663851798, train_acc = 0.9910340009315324\n",
      "test Acc 0.9767225325884544:\n",
      "21th- epoch: 168, train_loss = 4.667153801769018, train_acc = 0.9910340009315324\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 169, train_loss = 4.635611563920975, train_acc = 0.9911504424778761\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 170, train_loss = 4.604423143900931, train_acc = 0.9911504424778761\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 171, train_loss = 4.5736839435994625, train_acc = 0.9911504424778761\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 172, train_loss = 4.543244391679764, train_acc = 0.9911504424778761\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 173, train_loss = 4.513026591390371, train_acc = 0.9911504424778761\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 174, train_loss = 4.483403316698968, train_acc = 0.9912668840242198\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 175, train_loss = 4.4539389330893755, train_acc = 0.9912668840242198\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 176, train_loss = 4.424795754253864, train_acc = 0.9912668840242198\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 177, train_loss = 4.395929053425789, train_acc = 0.9912668840242198\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 178, train_loss = 4.367561612278223, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 179, train_loss = 4.3393720192834735, train_acc = 0.9914997671169073\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 180, train_loss = 4.311426798813045, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 181, train_loss = 4.283893213607371, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 182, train_loss = 4.256723298691213, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 183, train_loss = 4.229940827935934, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 184, train_loss = 4.203394670039415, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 185, train_loss = 4.177228130400181, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 186, train_loss = 4.151358917355537, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 187, train_loss = 4.12569038476795, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 188, train_loss = 4.100390394218266, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 189, train_loss = 4.075546494685113, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 190, train_loss = 4.050591113977134, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 191, train_loss = 4.026323079131544, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 192, train_loss = 4.002000835724175, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 193, train_loss = 3.977721410803497, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 194, train_loss = 3.9540447145700455, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 195, train_loss = 3.9299628688022494, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 196, train_loss = 3.9066227339208126, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 197, train_loss = 3.883578666485846, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 198, train_loss = 3.860862046480179, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 199, train_loss = 3.8383280215784907, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 200, train_loss = 3.8161773262545466, train_acc = 0.9921984163949698\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 201, train_loss = 3.7942582396790385, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 202, train_loss = 3.7724537858739495, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 203, train_loss = 3.751008439809084, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 204, train_loss = 3.7295051887631416, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 205, train_loss = 3.708515051752329, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 206, train_loss = 3.6878898376598954, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 207, train_loss = 3.6671624537557364, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 208, train_loss = 3.6468080012127757, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 209, train_loss = 3.6266915341839194, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 210, train_loss = 3.6067007882520556, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 211, train_loss = 3.5870060473680496, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 212, train_loss = 3.5672871973365545, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 213, train_loss = 3.548044443130493, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 214, train_loss = 3.528740213252604, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 215, train_loss = 3.509872741997242, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 216, train_loss = 3.4910545954480767, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 217, train_loss = 3.4725828655064106, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 218, train_loss = 3.454114932566881, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 219, train_loss = 3.4360207258723676, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 220, train_loss = 3.418021326418966, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 221, train_loss = 3.4001802117563784, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 222, train_loss = 3.382458216045052, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 223, train_loss = 3.3651296733878553, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 224, train_loss = 3.3477425165474415, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 225, train_loss = 3.3306160704232752, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 226, train_loss = 3.313474061433226, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 227, train_loss = 3.29670986905694, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 228, train_loss = 3.2798664732836187, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 229, train_loss = 3.2633605846203864, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 230, train_loss = 3.2468909844756126, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 231, train_loss = 3.230719735380262, train_acc = 0.9932463903120633\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 232, train_loss = 3.2145978077314794, train_acc = 0.9932463903120633\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 233, train_loss = 3.1986100114881992, train_acc = 0.9932463903120633\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 234, train_loss = 3.182782929390669, train_acc = 0.9932463903120633\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 235, train_loss = 3.1671579577960074, train_acc = 0.9933628318584071\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 236, train_loss = 3.1516144960187376, train_acc = 0.9933628318584071\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 237, train_loss = 3.1362741994671524, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 238, train_loss = 3.121085352730006, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 239, train_loss = 3.106034921016544, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 240, train_loss = 3.0910113509744406, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 241, train_loss = 3.0762995849363506, train_acc = 0.9935957149510946\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 242, train_loss = 3.0617163996212184, train_acc = 0.9935957149510946\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 243, train_loss = 3.0471908878535032, train_acc = 0.9935957149510946\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 244, train_loss = 3.0327315907925367, train_acc = 0.9935957149510946\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 245, train_loss = 3.018454173579812, train_acc = 0.9935957149510946\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 246, train_loss = 3.004435585346073, train_acc = 0.9935957149510946\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 247, train_loss = 2.990371785592288, train_acc = 0.9935957149510946\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 248, train_loss = 2.976466473657638, train_acc = 0.9935957149510946\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 249, train_loss = 2.9628258026205003, train_acc = 0.9935957149510946\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 250, train_loss = 2.9492568033747375, train_acc = 0.9935957149510946\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 251, train_loss = 2.9356860988773406, train_acc = 0.9935957149510946\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 252, train_loss = 2.9223091253079474, train_acc = 0.9937121564974383\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 253, train_loss = 2.909165345598012, train_acc = 0.993828598043782\n",
      "test Acc 0.9813780260707635:\n",
      "21th- epoch: 254, train_loss = 2.895925050135702, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 255, train_loss = 2.8830319582484663, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 256, train_loss = 2.8700248524546623, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 257, train_loss = 2.857236213516444, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 258, train_loss = 2.844676161184907, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 259, train_loss = 2.831965568009764, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 260, train_loss = 2.819577442482114, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 261, train_loss = 2.8072677380405366, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 262, train_loss = 2.7950504031032324, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 263, train_loss = 2.782903097104281, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 264, train_loss = 2.7709112502634525, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 265, train_loss = 2.75904243811965, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 266, train_loss = 2.747194994240999, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 267, train_loss = 2.73555289208889, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 268, train_loss = 2.7239905297756195, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 269, train_loss = 2.7125074230134487, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 270, train_loss = 2.7012415807694197, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 271, train_loss = 2.689974866807461, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 272, train_loss = 2.6787856123410165, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 273, train_loss = 2.6677170284092426, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 274, train_loss = 2.6568418205715716, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 275, train_loss = 2.645885015372187, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 276, train_loss = 2.6352115026675165, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 277, train_loss = 2.6245453120209277, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 278, train_loss = 2.613904702011496, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 279, train_loss = 2.6035262518562376, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 280, train_loss = 2.5930377482436597, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 281, train_loss = 2.582960297819227, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 282, train_loss = 2.5728066288866103, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 283, train_loss = 2.5626631206832826, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 284, train_loss = 2.552693173289299, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 285, train_loss = 2.5428724996745586, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 286, train_loss = 2.5330837867222726, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 287, train_loss = 2.523374622222036, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 288, train_loss = 2.51374918455258, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 289, train_loss = 2.504264841321856, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 290, train_loss = 2.494806727860123, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 291, train_loss = 2.4855654388666153, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 292, train_loss = 2.4762153238989413, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 293, train_loss = 2.4672123678028584, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 294, train_loss = 2.458209205418825, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 295, train_loss = 2.4491569972597063, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 296, train_loss = 2.440260535571724, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 297, train_loss = 2.43146875500679, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 298, train_loss = 2.422503975685686, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 299, train_loss = 2.4137152694165707, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 300, train_loss = 2.4052640188019723, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 301, train_loss = 2.3968555964529514, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 302, train_loss = 2.3884212386328727, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 303, train_loss = 2.3801226031500846, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 304, train_loss = 2.3716813114006072, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 305, train_loss = 2.363674111664295, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 306, train_loss = 2.3554669495206326, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 307, train_loss = 2.3474027428310364, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 308, train_loss = 2.339549886761233, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 309, train_loss = 2.331574668409303, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 310, train_loss = 2.3237584095913917, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 311, train_loss = 2.3159525357186794, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 312, train_loss = 2.308296162635088, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 313, train_loss = 2.3006734896916896, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 314, train_loss = 2.293334998190403, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 315, train_loss = 2.2857779327314347, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 316, train_loss = 2.2784273114521056, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 317, train_loss = 2.271289836615324, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 318, train_loss = 2.2639820724725723, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 319, train_loss = 2.2568631432950497, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 320, train_loss = 2.249806684674695, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 321, train_loss = 2.2427490253467113, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 322, train_loss = 2.2357685540337116, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 323, train_loss = 2.2290812220890075, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 324, train_loss = 2.222207070561126, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 325, train_loss = 2.215394428698346, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 326, train_loss = 2.208809118717909, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 327, train_loss = 2.202176046790555, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 328, train_loss = 2.195606851251796, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 329, train_loss = 2.1889922209084034, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 330, train_loss = 2.1824343155603856, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 331, train_loss = 2.17625692486763, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 332, train_loss = 2.1696861076634377, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 333, train_loss = 2.1637307319324464, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 334, train_loss = 2.1572579566854984, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 335, train_loss = 2.151456183521077, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 336, train_loss = 2.144960404606536, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 337, train_loss = 2.1393881142139435, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 338, train_loss = 2.13293232396245, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 339, train_loss = 2.1270752314012498, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 340, train_loss = 2.1212495279032737, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 341, train_loss = 2.115435903193429, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 342, train_loss = 2.109506845474243, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 343, train_loss = 2.103924446972087, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 344, train_loss = 2.0981767748016864, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 345, train_loss = 2.092638502595946, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 346, train_loss = 2.0869918304961175, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 347, train_loss = 2.081507608294487, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 348, train_loss = 2.0760912832338363, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 349, train_loss = 2.0706314917188138, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 350, train_loss = 2.065198415191844, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 351, train_loss = 2.0600496754050255, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 352, train_loss = 2.0546108062844723, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 353, train_loss = 2.0494356479030102, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 354, train_loss = 2.044237853260711, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 355, train_loss = 2.038984139682725, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 356, train_loss = 2.0339529551565647, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 357, train_loss = 2.0288948006927967, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 358, train_loss = 2.024036218645051, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 359, train_loss = 2.0189680580515414, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 360, train_loss = 2.0139729988295585, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 361, train_loss = 2.0090922999661416, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 362, train_loss = 2.004286739975214, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 363, train_loss = 1.9993421633262187, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 364, train_loss = 1.9946346108336002, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 365, train_loss = 1.9898953400552273, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 366, train_loss = 1.984967265278101, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "21th- epoch: 367, train_loss = 1.9805417694151402, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 368, train_loss = 1.975798949599266, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 369, train_loss = 1.9712759915273637, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 370, train_loss = 1.9667262223083526, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 371, train_loss = 1.9623038407880813, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 372, train_loss = 1.9576646585483104, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 373, train_loss = 1.9534287489950657, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 374, train_loss = 1.949059347389266, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 375, train_loss = 1.944570366293192, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 376, train_loss = 1.9403598494827747, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 377, train_loss = 1.9360008239746094, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 378, train_loss = 1.9318259481806308, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 379, train_loss = 1.9275787025690079, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 380, train_loss = 1.923390880227089, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 381, train_loss = 1.9193380165379494, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 382, train_loss = 1.9151492826640606, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 383, train_loss = 1.911076633958146, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 384, train_loss = 1.9071334017207846, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 385, train_loss = 1.903089770465158, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 386, train_loss = 1.899024219601415, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 387, train_loss = 1.8952234188327566, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 388, train_loss = 1.8911669241497293, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 389, train_loss = 1.8874220451107249, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 390, train_loss = 1.8834717100253329, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 391, train_loss = 1.8796121379127726, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 392, train_loss = 1.8758281556656584, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 393, train_loss = 1.8721913819899783, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 394, train_loss = 1.8682614242425188, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 395, train_loss = 1.8647318296134472, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 396, train_loss = 1.8610756509006023, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 397, train_loss = 1.8574025928974152, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 398, train_loss = 1.8537403555819765, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 399, train_loss = 1.8501217340817675, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 400, train_loss = 1.846542201936245, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 401, train_loss = 1.8430712843546644, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 402, train_loss = 1.8393158974358812, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 403, train_loss = 1.8360232649138197, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 404, train_loss = 1.8324432919034734, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 405, train_loss = 1.8290087295463309, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 406, train_loss = 1.8255837993929163, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 407, train_loss = 1.822299286723137, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 408, train_loss = 1.8188286559889093, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 409, train_loss = 1.8155760517111048, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 410, train_loss = 1.812212729244493, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 411, train_loss = 1.8089778100838885, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 412, train_loss = 1.8056540252873674, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 413, train_loss = 1.8024276321521029, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 414, train_loss = 1.7992222210159525, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 415, train_loss = 1.7959878233959898, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 416, train_loss = 1.7929039262235165, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 417, train_loss = 1.7895884389290586, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 418, train_loss = 1.7865044152131304, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 419, train_loss = 1.7833758480846882, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 420, train_loss = 1.780331720947288, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 421, train_loss = 1.7773433463880792, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 422, train_loss = 1.7741990126669407, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 423, train_loss = 1.771191742271185, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 424, train_loss = 1.7682328881928697, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 425, train_loss = 1.7651824405184016, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 426, train_loss = 1.7623501904308796, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 427, train_loss = 1.7593376301229, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 428, train_loss = 1.7564885889878497, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 429, train_loss = 1.7534609846770763, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 430, train_loss = 1.7507013095309958, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 431, train_loss = 1.7478432295611128, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 432, train_loss = 1.7450078005203977, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 433, train_loss = 1.7422289289534092, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 434, train_loss = 1.7394021153450012, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 435, train_loss = 1.7365981166949496, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 436, train_loss = 1.733946050168015, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 437, train_loss = 1.7311396958539262, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 438, train_loss = 1.7283379025757313, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 439, train_loss = 1.7256610617041588, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 440, train_loss = 1.7230333983898163, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 441, train_loss = 1.7203413223614916, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 442, train_loss = 1.717654669075273, train_acc = 0.9958081043316255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 443, train_loss = 1.7151585469255224, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 444, train_loss = 1.7124721457948908, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 445, train_loss = 1.7097844233503565, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 446, train_loss = 1.707357312203385, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 447, train_loss = 1.7048021107912064, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 448, train_loss = 1.7021674737334251, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 449, train_loss = 1.6998415552079678, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 450, train_loss = 1.6972484228899702, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 451, train_loss = 1.6946996884653345, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 452, train_loss = 1.6923659866442904, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 453, train_loss = 1.6899619562318549, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 454, train_loss = 1.687411135644652, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 455, train_loss = 1.6849760251352564, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 456, train_loss = 1.6826909705996513, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 457, train_loss = 1.6802764311432838, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 458, train_loss = 1.6778532800963148, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 459, train_loss = 1.6755486950278282, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 460, train_loss = 1.6732638789108023, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 461, train_loss = 1.6708347549429163, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 462, train_loss = 1.6685974349966273, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 463, train_loss = 1.6662323711207137, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 464, train_loss = 1.6640336042037234, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 465, train_loss = 1.6617513758828864, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 466, train_loss = 1.659527961164713, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 467, train_loss = 1.6573004747042432, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 468, train_loss = 1.6550998898455873, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 469, train_loss = 1.6529996345052496, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 470, train_loss = 1.6506824059179053, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 471, train_loss = 1.6484472242882475, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 472, train_loss = 1.6464382745325565, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 473, train_loss = 1.6443224983522668, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 474, train_loss = 1.642117578536272, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 475, train_loss = 1.6400521757313982, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 476, train_loss = 1.6380382986972108, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 477, train_loss = 1.6357914904365316, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 478, train_loss = 1.6337795940926298, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 479, train_loss = 1.6316877901554108, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 480, train_loss = 1.6296957557788119, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 481, train_loss = 1.627679742872715, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 482, train_loss = 1.6256065033376217, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 483, train_loss = 1.6236791698029265, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 484, train_loss = 1.621579165221192, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 485, train_loss = 1.6197487140307203, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 486, train_loss = 1.6176312640309334, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 487, train_loss = 1.6157045426080003, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 488, train_loss = 1.6138362474739552, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 489, train_loss = 1.6118149993708357, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 490, train_loss = 1.6099536741385236, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 491, train_loss = 1.6079372266540304, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 492, train_loss = 1.6062202341854572, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 493, train_loss = 1.6042745399172418, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 494, train_loss = 1.6024506377871148, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 495, train_loss = 1.6003949518199079, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 496, train_loss = 1.5987725593149662, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 497, train_loss = 1.5968439429998398, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 498, train_loss = 1.5951158851385117, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 499, train_loss = 1.5931486822664738, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████████████████████████████████████▍                     | 21/30 [2:19:28<59:39, 397.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "22th- epoch: 0, train_loss = 268.8612949848175, train_acc = 0.47391709361900325\n",
      "test Acc 0.48789571694599626:\n",
      "22th- epoch: 1, train_loss = 203.92638337612152, train_acc = 0.4991849091755938\n",
      "test Acc 0.5013966480446927:\n",
      "22th- epoch: 2, train_loss = 163.02246940135956, train_acc = 0.5214252445272474\n",
      "test Acc 0.5712290502793296:\n",
      "22th- epoch: 3, train_loss = 141.257222533226, train_acc = 0.6587098276665114\n",
      "test Acc 0.7062383612662942:\n",
      "22th- epoch: 4, train_loss = 123.43745529651642, train_acc = 0.7170470423847228\n",
      "test Acc 0.7411545623836127:\n",
      "22th- epoch: 5, train_loss = 108.06941977143288, train_acc = 0.749534233814625\n",
      "test Acc 0.7690875232774674:\n",
      "22th- epoch: 6, train_loss = 95.13798534870148, train_acc = 0.7908709827666511\n",
      "test Acc 0.8058659217877095:\n",
      "22th- epoch: 7, train_loss = 84.25601702928543, train_acc = 0.8164881229622729\n",
      "test Acc 0.8249534450651769:\n",
      "22th- epoch: 8, train_loss = 74.97627601027489, train_acc = 0.8379133674895203\n",
      "test Acc 0.8514897579143389:\n",
      "22th- epoch: 9, train_loss = 67.0496808886528, train_acc = 0.8644620400558919\n",
      "test Acc 0.8719739292364991:\n",
      "22th- epoch: 10, train_loss = 60.3356571495533, train_acc = 0.8797158826269212\n",
      "test Acc 0.88268156424581:\n",
      "22th- epoch: 11, train_loss = 54.68876051902771, train_acc = 0.8898462971588262\n",
      "test Acc 0.8891992551210428:\n",
      "22th- epoch: 12, train_loss = 49.95235253870487, train_acc = 0.9032370749883558\n",
      "test Acc 0.8999068901303539:\n",
      "22th- epoch: 13, train_loss = 45.961370170116425, train_acc = 0.9146483465300419\n",
      "test Acc 0.9143389199255121:\n",
      "22th- epoch: 14, train_loss = 42.58684268593788, train_acc = 0.9245458779692595\n",
      "test Acc 0.9245810055865922:\n",
      "22th- epoch: 15, train_loss = 39.713643088936806, train_acc = 0.9304843968327899\n",
      "test Acc 0.9301675977653632:\n",
      "22th- epoch: 16, train_loss = 37.25126360356808, train_acc = 0.9346762925011645\n",
      "test Acc 0.9329608938547486:\n",
      "22th- epoch: 17, train_loss = 35.11908484995365, train_acc = 0.9381695388914765\n",
      "test Acc 0.936219739292365:\n",
      "22th- epoch: 18, train_loss = 33.25452809780836, train_acc = 0.9430600838379134\n",
      "test Acc 0.9408752327746741:\n",
      "22th- epoch: 19, train_loss = 31.620584435760975, train_acc = 0.946320447135538\n",
      "test Acc 0.9418063314711359:\n",
      "22th- epoch: 20, train_loss = 30.176990494132042, train_acc = 0.9478341872380065\n",
      "test Acc 0.9441340782122905:\n",
      "22th- epoch: 21, train_loss = 28.892418183386326, train_acc = 0.94981369352585\n",
      "test Acc 0.9459962756052142:\n",
      "22th- epoch: 22, train_loss = 27.74507052451372, train_acc = 0.9519096413600373\n",
      "test Acc 0.9473929236499069:\n",
      "22th- epoch: 23, train_loss = 26.71747748553753, train_acc = 0.9533069399161621\n",
      "test Acc 0.9492551210428305:\n",
      "22th- epoch: 24, train_loss = 25.790936581790447, train_acc = 0.9545877969259432\n",
      "test Acc 0.952048417132216:\n",
      "22th- epoch: 25, train_loss = 24.949461191892624, train_acc = 0.9562179785747554\n",
      "test Acc 0.952513966480447:\n",
      "22th- epoch: 26, train_loss = 24.180125057697296, train_acc = 0.9573823940381928\n",
      "test Acc 0.9539106145251397:\n",
      "22th- epoch: 27, train_loss = 23.472130954265594, train_acc = 0.9583139264089428\n",
      "test Acc 0.9543761638733705:\n",
      "22th- epoch: 28, train_loss = 22.814216040074825, train_acc = 0.9590125756870052\n",
      "test Acc 0.9543761638733705:\n",
      "22th- epoch: 29, train_loss = 22.201625768095255, train_acc = 0.959944108057755\n",
      "test Acc 0.9553072625698324:\n",
      "22th- epoch: 30, train_loss = 21.631331365555525, train_acc = 0.9602934326967862\n",
      "test Acc 0.9553072625698324:\n",
      "22th- epoch: 31, train_loss = 21.096868742257357, train_acc = 0.9608756404285049\n",
      "test Acc 0.9553072625698324:\n",
      "22th- epoch: 32, train_loss = 20.593765933066607, train_acc = 0.9609920819748486\n",
      "test Acc 0.9557728119180633:\n",
      "22th- epoch: 33, train_loss = 20.117824338376522, train_acc = 0.9618071727992548\n",
      "test Acc 0.9562383612662942:\n",
      "22th- epoch: 34, train_loss = 19.667331021279097, train_acc = 0.9629715882626921\n",
      "test Acc 0.9557728119180633:\n",
      "22th- epoch: 35, train_loss = 19.23960357159376, train_acc = 0.9635537959944108\n",
      "test Acc 0.9562383612662942:\n",
      "22th- epoch: 36, train_loss = 18.83416087925434, train_acc = 0.9640195621797858\n",
      "test Acc 0.9562383612662942:\n",
      "22th- epoch: 37, train_loss = 18.44902741163969, train_acc = 0.9644853283651607\n",
      "test Acc 0.957169459962756:\n",
      "22th- epoch: 38, train_loss = 18.081386350095272, train_acc = 0.9651839776432231\n",
      "test Acc 0.9581005586592178:\n",
      "22th- epoch: 39, train_loss = 17.729982793331146, train_acc = 0.966115510013973\n",
      "test Acc 0.9585661080074488:\n",
      "22th- epoch: 40, train_loss = 17.39307901263237, train_acc = 0.9663483931066604\n",
      "test Acc 0.9585661080074488:\n",
      "22th- epoch: 41, train_loss = 17.069897588342428, train_acc = 0.966581276199348\n",
      "test Acc 0.9590316573556797:\n",
      "22th- epoch: 42, train_loss = 16.759004682302475, train_acc = 0.9675128085700978\n",
      "test Acc 0.9594972067039106:\n",
      "22th- epoch: 43, train_loss = 16.45994394272566, train_acc = 0.9680950163018165\n",
      "test Acc 0.9604283054003724:\n",
      "22th- epoch: 44, train_loss = 16.17233880609274, train_acc = 0.9687936655798789\n",
      "test Acc 0.9604283054003724:\n",
      "22th- epoch: 45, train_loss = 15.895926211029291, train_acc = 0.9698416394969726\n",
      "test Acc 0.9604283054003724:\n",
      "22th- epoch: 46, train_loss = 15.6293570920825, train_acc = 0.9706567303213787\n",
      "test Acc 0.9604283054003724:\n",
      "22th- epoch: 47, train_loss = 15.37220760062337, train_acc = 0.9710060549604099\n",
      "test Acc 0.9608938547486033:\n",
      "22th- epoch: 48, train_loss = 15.124071422964334, train_acc = 0.9713553795994411\n",
      "test Acc 0.9608938547486033:\n",
      "22th- epoch: 49, train_loss = 14.884406246244907, train_acc = 0.9717047042384723\n",
      "test Acc 0.9618249534450651:\n",
      "22th- epoch: 50, train_loss = 14.652834586799145, train_acc = 0.9719375873311598\n",
      "test Acc 0.9632216014897579:\n",
      "22th- epoch: 51, train_loss = 14.428960230201483, train_acc = 0.972286911970191\n",
      "test Acc 0.9636871508379888:\n",
      "22th- epoch: 52, train_loss = 14.21196248754859, train_acc = 0.9728691197019096\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 53, train_loss = 14.001534212380648, train_acc = 0.9738006520726595\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 54, train_loss = 13.79758975468576, train_acc = 0.9741499767116907\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 55, train_loss = 13.600127862766385, train_acc = 0.9746157428970657\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 56, train_loss = 13.40852721221745, train_acc = 0.9747321844434094\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 57, train_loss = 13.222317581996322, train_acc = 0.9748486259897532\n",
      "test Acc 0.9646182495344506:\n",
      "22th- epoch: 58, train_loss = 13.041521230712533, train_acc = 0.9748486259897532\n",
      "test Acc 0.9650837988826816:\n",
      "22th- epoch: 59, train_loss = 12.865769060328603, train_acc = 0.9749650675360969\n",
      "test Acc 0.9650837988826816:\n",
      "22th- epoch: 60, train_loss = 12.694605015218258, train_acc = 0.975314392175128\n",
      "test Acc 0.9655493482309124:\n",
      "22th- epoch: 61, train_loss = 12.528063077479601, train_acc = 0.9754308337214718\n",
      "test Acc 0.9664804469273743:\n",
      "22th- epoch: 62, train_loss = 12.365703508257866, train_acc = 0.9755472752678156\n",
      "test Acc 0.9664804469273743:\n",
      "22th- epoch: 63, train_loss = 12.207378394901752, train_acc = 0.975780158360503\n",
      "test Acc 0.9664804469273743:\n",
      "22th- epoch: 64, train_loss = 12.052934981882572, train_acc = 0.9760130414531905\n",
      "test Acc 0.9674115456238361:\n",
      "22th- epoch: 65, train_loss = 11.902312614023685, train_acc = 0.9764788076385654\n",
      "test Acc 0.9674115456238361:\n",
      "22th- epoch: 66, train_loss = 11.755051840096712, train_acc = 0.9771774569166278\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 67, train_loss = 11.611247513443232, train_acc = 0.9771774569166278\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 68, train_loss = 11.470791537314653, train_acc = 0.9775267815556591\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 69, train_loss = 11.332946076989174, train_acc = 0.9777596646483465\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 70, train_loss = 11.197939235717058, train_acc = 0.977992547741034\n",
      "test Acc 0.9683426443202979:\n",
      "22th- epoch: 71, train_loss = 11.066133264452219, train_acc = 0.9781089892873778\n",
      "test Acc 0.9683426443202979:\n",
      "22th- epoch: 72, train_loss = 10.937465853989124, train_acc = 0.9783418723800652\n",
      "test Acc 0.9683426443202979:\n",
      "22th- epoch: 73, train_loss = 10.811491146683693, train_acc = 0.9784583139264089\n",
      "test Acc 0.9688081936685289:\n",
      "22th- epoch: 74, train_loss = 10.688484452664852, train_acc = 0.9784583139264089\n",
      "test Acc 0.9692737430167597:\n",
      "22th- epoch: 75, train_loss = 10.568014569580555, train_acc = 0.9786911970190965\n",
      "test Acc 0.9688081936685289:\n",
      "22th- epoch: 76, train_loss = 10.449960457161069, train_acc = 0.9788076385654402\n",
      "test Acc 0.9692737430167597:\n",
      "22th- epoch: 77, train_loss = 10.334110690280795, train_acc = 0.9790405216581276\n",
      "test Acc 0.9702048417132216:\n",
      "22th- epoch: 78, train_loss = 10.220815114676952, train_acc = 0.9792734047508151\n",
      "test Acc 0.9702048417132216:\n",
      "22th- epoch: 79, train_loss = 10.10962824895978, train_acc = 0.9792734047508151\n",
      "test Acc 0.9706703910614525:\n",
      "22th- epoch: 80, train_loss = 10.000594139099121, train_acc = 0.9793898462971589\n",
      "test Acc 0.9706703910614525:\n",
      "22th- epoch: 81, train_loss = 9.893447376787663, train_acc = 0.9793898462971589\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 82, train_loss = 9.788070866838098, train_acc = 0.9793898462971589\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 83, train_loss = 9.684642311185598, train_acc = 0.9793898462971589\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 84, train_loss = 9.582901038229465, train_acc = 0.9793898462971589\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 85, train_loss = 9.482865644618869, train_acc = 0.9793898462971589\n",
      "test Acc 0.9716014897579144:\n",
      "22th- epoch: 86, train_loss = 9.384520664811134, train_acc = 0.9795062878435026\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 87, train_loss = 9.287963263690472, train_acc = 0.9795062878435026\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 88, train_loss = 9.192923173308372, train_acc = 0.9795062878435026\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 89, train_loss = 9.099309366196394, train_acc = 0.9795062878435026\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 90, train_loss = 9.007212117314339, train_acc = 0.97973917093619\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 91, train_loss = 8.916705090552568, train_acc = 0.9799720540288775\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 92, train_loss = 8.827520724385977, train_acc = 0.9798556124825337\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 93, train_loss = 8.73949433118105, train_acc = 0.9800884955752213\n",
      "test Acc 0.9720670391061452:\n",
      "22th- epoch: 94, train_loss = 8.65274952724576, train_acc = 0.9807871448532837\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 95, train_loss = 8.566918577998877, train_acc = 0.9812529110386586\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 96, train_loss = 8.482526905834675, train_acc = 0.9816022356776898\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 97, train_loss = 8.399053042754531, train_acc = 0.981951560316721\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 98, train_loss = 8.316900184378028, train_acc = 0.9825337680484397\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 99, train_loss = 8.235947983339429, train_acc = 0.9826502095947834\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 100, train_loss = 8.15621299482882, train_acc = 0.9826502095947834\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 101, train_loss = 8.077704520896077, train_acc = 0.9828830926874709\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 102, train_loss = 8.000291934236884, train_acc = 0.9831159757801584\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 103, train_loss = 7.923747202381492, train_acc = 0.9833488588728458\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 104, train_loss = 7.848671060055494, train_acc = 0.983698183511877\n",
      "test Acc 0.9739292364990689:\n",
      "22th- epoch: 105, train_loss = 7.774158963933587, train_acc = 0.983698183511877\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 106, train_loss = 7.700930682942271, train_acc = 0.9840475081509082\n",
      "test Acc 0.9743947858472998:\n",
      "22th- epoch: 107, train_loss = 7.628594033420086, train_acc = 0.9842803912435957\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 108, train_loss = 7.55740792863071, train_acc = 0.9843968327899395\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 109, train_loss = 7.487246738746762, train_acc = 0.9846297158826269\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 110, train_loss = 7.41784793138504, train_acc = 0.9847461574289706\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 111, train_loss = 7.349502796307206, train_acc = 0.9846297158826269\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 112, train_loss = 7.281860299408436, train_acc = 0.9846297158826269\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 113, train_loss = 7.2149294055998325, train_acc = 0.9850954820680019\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 114, train_loss = 7.149142088368535, train_acc = 0.9852119236143456\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 115, train_loss = 7.084622090682387, train_acc = 0.9853283651606893\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 116, train_loss = 7.020757963880897, train_acc = 0.9855612482533768\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 117, train_loss = 6.9578447211533785, train_acc = 0.9855612482533768\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 118, train_loss = 6.895751031115651, train_acc = 0.9856776897997206\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 119, train_loss = 6.834367446601391, train_acc = 0.9857941313460643\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 120, train_loss = 6.773831678554416, train_acc = 0.985910572892408\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 121, train_loss = 6.713512673974037, train_acc = 0.9860270144387517\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 122, train_loss = 6.653491396456957, train_acc = 0.986376339077783\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 123, train_loss = 6.5943013951182365, train_acc = 0.9864927806241267\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 124, train_loss = 6.536644594743848, train_acc = 0.9868421052631579\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 125, train_loss = 6.479847867041826, train_acc = 0.9869585468095017\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 126, train_loss = 6.423930274322629, train_acc = 0.9871914299021891\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 127, train_loss = 6.368817567825317, train_acc = 0.9874243129948765\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 128, train_loss = 6.314586296677589, train_acc = 0.9874243129948765\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 129, train_loss = 6.261038534343243, train_acc = 0.9874243129948765\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 130, train_loss = 6.208285415545106, train_acc = 0.9874243129948765\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 131, train_loss = 6.156087348237634, train_acc = 0.9877736376339078\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 132, train_loss = 6.1047460827976465, train_acc = 0.9881229622729389\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 133, train_loss = 6.053622167557478, train_acc = 0.9882394038192828\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 134, train_loss = 6.003261372447014, train_acc = 0.9883558453656265\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 135, train_loss = 5.953832931816578, train_acc = 0.9884722869119702\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 136, train_loss = 5.904982445761561, train_acc = 0.9885887284583139\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 137, train_loss = 5.856963230296969, train_acc = 0.9885887284583139\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 138, train_loss = 5.809596186503768, train_acc = 0.9885887284583139\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 139, train_loss = 5.762923248112202, train_acc = 0.9885887284583139\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 140, train_loss = 5.716826446354389, train_acc = 0.9885887284583139\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 141, train_loss = 5.671513199806213, train_acc = 0.9885887284583139\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 142, train_loss = 5.626665512099862, train_acc = 0.9885887284583139\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 143, train_loss = 5.582372514531016, train_acc = 0.9888216115510013\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 144, train_loss = 5.538773611187935, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 145, train_loss = 5.495666034519672, train_acc = 0.9889380530973452\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 146, train_loss = 5.453121962025762, train_acc = 0.9890544946436889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 147, train_loss = 5.411052513867617, train_acc = 0.9891709361900326\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 148, train_loss = 5.3696680180728436, train_acc = 0.9891709361900326\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 149, train_loss = 5.328789409250021, train_acc = 0.98940381928272\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 150, train_loss = 5.288376139476895, train_acc = 0.9896367023754076\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 151, train_loss = 5.248560829088092, train_acc = 0.9897531439217513\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 152, train_loss = 5.209082789719105, train_acc = 0.989869585468095\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 153, train_loss = 5.170347448438406, train_acc = 0.989869585468095\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 154, train_loss = 5.131905239075422, train_acc = 0.989869585468095\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 155, train_loss = 5.094027245417237, train_acc = 0.9901024685607824\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 156, train_loss = 5.0567330764606595, train_acc = 0.99033535165347\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 157, train_loss = 5.019920055754483, train_acc = 0.99033535165347\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 158, train_loss = 4.983512029051781, train_acc = 0.9904517931998137\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 159, train_loss = 4.947441899217665, train_acc = 0.9906846762925011\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 160, train_loss = 4.912054889835417, train_acc = 0.990801117838845\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 161, train_loss = 4.877022893168032, train_acc = 0.990801117838845\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 162, train_loss = 4.842465813271701, train_acc = 0.990801117838845\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 163, train_loss = 4.808332505635917, train_acc = 0.9909175593851887\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 164, train_loss = 4.774653009139001, train_acc = 0.9909175593851887\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 165, train_loss = 4.741311018355191, train_acc = 0.9909175593851887\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 166, train_loss = 4.708490502089262, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 167, train_loss = 4.6761406026780605, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 168, train_loss = 4.6440828973427415, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 169, train_loss = 4.612434067763388, train_acc = 0.9910340009315324\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 170, train_loss = 4.581169788725674, train_acc = 0.9911504424778761\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 171, train_loss = 4.5503510450944304, train_acc = 0.9911504424778761\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 172, train_loss = 4.519926526583731, train_acc = 0.9911504424778761\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 173, train_loss = 4.48978225607425, train_acc = 0.9912668840242198\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 174, train_loss = 4.460023361258209, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 175, train_loss = 4.4306254936382174, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 176, train_loss = 4.401636670343578, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 177, train_loss = 4.373000686056912, train_acc = 0.9917326502095948\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 178, train_loss = 4.344537301920354, train_acc = 0.9917326502095948\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 179, train_loss = 4.316575888544321, train_acc = 0.9918490917559385\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 180, train_loss = 4.289009955711663, train_acc = 0.9918490917559385\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 181, train_loss = 4.261663350276649, train_acc = 0.9919655333022822\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 182, train_loss = 4.2346060974523425, train_acc = 0.9919655333022822\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 183, train_loss = 4.207956810481846, train_acc = 0.9919655333022822\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 184, train_loss = 4.181578137911856, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 185, train_loss = 4.155570917762816, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 186, train_loss = 4.129751938395202, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 187, train_loss = 4.1043741488829255, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 188, train_loss = 4.079172061756253, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 189, train_loss = 4.054248634725809, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 190, train_loss = 4.029636763036251, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 191, train_loss = 4.005390954203904, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 192, train_loss = 3.981290706433356, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 193, train_loss = 3.9575129095464945, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 194, train_loss = 3.934031411074102, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "22th- epoch: 195, train_loss = 3.9107201658189297, train_acc = 0.9921984163949698\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 196, train_loss = 3.8877713633701205, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 197, train_loss = 3.8650017520412803, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 198, train_loss = 3.8425017716363072, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 199, train_loss = 3.820313003845513, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 200, train_loss = 3.798256751149893, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 201, train_loss = 3.7764917770400643, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 202, train_loss = 3.755076893605292, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 203, train_loss = 3.733664944767952, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 204, train_loss = 3.7125581493601203, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 205, train_loss = 3.6916414126753807, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 206, train_loss = 3.6709474651142955, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 207, train_loss = 3.6505698869004846, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 208, train_loss = 3.6303818179294467, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 209, train_loss = 3.6102911829948425, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 210, train_loss = 3.5906110629439354, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 211, train_loss = 3.571037736721337, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 212, train_loss = 3.55169028788805, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 213, train_loss = 3.532530923373997, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "22th- epoch: 214, train_loss = 3.5135552175343037, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 215, train_loss = 3.4948048242367804, train_acc = 0.9931299487657196\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 216, train_loss = 3.4761368818581104, train_acc = 0.9931299487657196\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 217, train_loss = 3.4578872211277485, train_acc = 0.9931299487657196\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 218, train_loss = 3.4396168342791498, train_acc = 0.9931299487657196\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 219, train_loss = 3.4216599091887474, train_acc = 0.9931299487657196\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 220, train_loss = 3.4037186703644693, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 221, train_loss = 3.3861455977894366, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 222, train_loss = 3.368671858217567, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 223, train_loss = 3.351335729006678, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 224, train_loss = 3.3341914541088045, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 225, train_loss = 3.317334526684135, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 226, train_loss = 3.3004904785193503, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 227, train_loss = 3.2839228264056146, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 228, train_loss = 3.267454031854868, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 229, train_loss = 3.251035159919411, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 230, train_loss = 3.235019812826067, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 231, train_loss = 3.21897841244936, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 232, train_loss = 3.2032330543734133, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 233, train_loss = 3.1875755391083658, train_acc = 0.9931299487657196\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 234, train_loss = 3.171983940061182, train_acc = 0.9932463903120633\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 235, train_loss = 3.1566353081725538, train_acc = 0.9933628318584071\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 236, train_loss = 3.1413582214154303, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 237, train_loss = 3.126303907483816, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 238, train_loss = 3.111384513322264, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 239, train_loss = 3.0966570139862597, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 240, train_loss = 3.081941047683358, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 241, train_loss = 3.0674158544279635, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 242, train_loss = 3.053059557918459, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 243, train_loss = 3.038795430213213, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 244, train_loss = 3.024663219228387, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 245, train_loss = 3.0106633380055428, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 246, train_loss = 2.9969014194794, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 247, train_loss = 2.9830990326590836, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 248, train_loss = 2.969570139888674, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 249, train_loss = 2.95599004579708, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 250, train_loss = 2.9426777944900095, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 251, train_loss = 2.9294386953115463, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 252, train_loss = 2.9161851736716926, train_acc = 0.9935957149510946\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 253, train_loss = 2.903098554816097, train_acc = 0.993828598043782\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 254, train_loss = 2.8901307191699743, train_acc = 0.9939450395901258\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 255, train_loss = 2.877322982996702, train_acc = 0.9939450395901258\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 256, train_loss = 2.864583671092987, train_acc = 0.9939450395901258\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 257, train_loss = 2.8519643140025437, train_acc = 0.9939450395901258\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 258, train_loss = 2.8394093718379736, train_acc = 0.9939450395901258\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 259, train_loss = 2.8270435947924852, train_acc = 0.9939450395901258\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 260, train_loss = 2.8146855160593987, train_acc = 0.9939450395901258\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 261, train_loss = 2.8024856708943844, train_acc = 0.9939450395901258\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 262, train_loss = 2.790377392899245, train_acc = 0.9940614811364695\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 263, train_loss = 2.778277361765504, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 264, train_loss = 2.766642936039716, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 265, train_loss = 2.7547626458108425, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 266, train_loss = 2.7431092322804034, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 267, train_loss = 2.7316299811936915, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 268, train_loss = 2.7203154847957194, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 269, train_loss = 2.7088423632085323, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 270, train_loss = 2.6975626051425934, train_acc = 0.9940614811364695\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 271, train_loss = 2.686479104682803, train_acc = 0.994294364229157\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 272, train_loss = 2.6755594606511295, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 273, train_loss = 2.664534145500511, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 274, train_loss = 2.653771936893463, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 275, train_loss = 2.6430482543073595, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 276, train_loss = 2.6323724896647036, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 277, train_loss = 2.6218315586447716, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 278, train_loss = 2.611425334122032, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 279, train_loss = 2.6010308526456356, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 280, train_loss = 2.5908124041743577, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 281, train_loss = 2.5805900492705405, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 282, train_loss = 2.570660287514329, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 283, train_loss = 2.560531944502145, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 284, train_loss = 2.550688316579908, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 285, train_loss = 2.54089572140947, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 286, train_loss = 2.53116666758433, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 287, train_loss = 2.5215631653554738, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 288, train_loss = 2.5119589138776064, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 289, train_loss = 2.502500888425857, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 290, train_loss = 2.493209033505991, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 291, train_loss = 2.4838210735470057, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 292, train_loss = 2.474585796473548, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 293, train_loss = 2.465510514797643, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 294, train_loss = 2.456441727699712, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 295, train_loss = 2.447475756285712, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 296, train_loss = 2.4385902397334576, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 297, train_loss = 2.429778116522357, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 298, train_loss = 2.4210209709126502, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 299, train_loss = 2.412357034860179, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 300, train_loss = 2.40374947222881, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 301, train_loss = 2.395265427650884, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 302, train_loss = 2.386873710900545, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 303, train_loss = 2.3785509888548404, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 304, train_loss = 2.370350816519931, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 305, train_loss = 2.3621355753857642, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 306, train_loss = 2.3540882132947445, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 307, train_loss = 2.3459713831543922, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 308, train_loss = 2.338053359417245, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 309, train_loss = 2.3302157185971737, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 310, train_loss = 2.322299335151911, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 311, train_loss = 2.314722366631031, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 312, train_loss = 2.307004527421668, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 313, train_loss = 2.299410830019042, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 314, train_loss = 2.2918750133831054, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 315, train_loss = 2.2844548274297267, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 316, train_loss = 2.276951301842928, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 317, train_loss = 2.2696288835722953, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 318, train_loss = 2.2624743666965514, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 319, train_loss = 2.2552618123590946, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 320, train_loss = 2.2480991929769516, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 321, train_loss = 2.241154571296647, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 322, train_loss = 2.2340964525938034, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 323, train_loss = 2.2271742559969425, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 324, train_loss = 2.2203200943768024, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 325, train_loss = 2.213551636785269, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 326, train_loss = 2.206814583390951, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 327, train_loss = 2.2001203161198646, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 328, train_loss = 2.193514183163643, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 329, train_loss = 2.1869850903749466, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 330, train_loss = 2.180577475577593, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 331, train_loss = 2.1741159968078136, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 332, train_loss = 2.167713050963357, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 333, train_loss = 2.161437512608245, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 334, train_loss = 2.1552026569843292, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 335, train_loss = 2.149019746808335, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 336, train_loss = 2.1428716604132205, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 337, train_loss = 2.1368312884587795, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 338, train_loss = 2.1307405654806644, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 339, train_loss = 2.1248613831121475, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 340, train_loss = 2.118870535166934, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 341, train_loss = 2.113105991156772, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 342, train_loss = 2.107255271403119, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 343, train_loss = 2.1015148472506553, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 344, train_loss = 2.0958163540344685, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 345, train_loss = 2.0901912413537502, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 346, train_loss = 2.084475538460538, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 347, train_loss = 2.0790450647473335, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 348, train_loss = 2.0734341230709106, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 349, train_loss = 2.068109270185232, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 350, train_loss = 2.0626901264768094, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 351, train_loss = 2.057256120024249, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 352, train_loss = 2.0519205033779144, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 353, train_loss = 2.0466604221146554, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 354, train_loss = 2.0414766296744347, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 355, train_loss = 2.0363190311472863, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 356, train_loss = 2.031178681878373, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 357, train_loss = 2.0261587214190513, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 358, train_loss = 2.0210446678102016, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 359, train_loss = 2.0161398116033524, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 360, train_loss = 2.0111485819797963, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 361, train_loss = 2.006208856822923, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 362, train_loss = 2.001384178875014, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 363, train_loss = 1.9965448651928455, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 364, train_loss = 1.9917612161953002, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 365, train_loss = 1.9870553687214851, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 366, train_loss = 1.9823263783473521, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 367, train_loss = 1.9777305498719215, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 368, train_loss = 1.9731508728582412, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 369, train_loss = 1.9685345378238708, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 370, train_loss = 1.9639459028840065, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 371, train_loss = 1.9595275211613625, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 372, train_loss = 1.954992889193818, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 373, train_loss = 1.9505611136555672, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 374, train_loss = 1.9461794210365042, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 375, train_loss = 1.9418100664624944, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 376, train_loss = 1.9374947076430544, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 377, train_loss = 1.9332269231090322, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 378, train_loss = 1.9289850505301729, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 379, train_loss = 1.924763741553761, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 380, train_loss = 1.9205199429998174, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 381, train_loss = 1.9164534583687782, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 382, train_loss = 1.9123054333031178, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 383, train_loss = 1.908143429667689, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 384, train_loss = 1.9041922079632059, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 385, train_loss = 1.9001454015960917, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 386, train_loss = 1.8961111592361704, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 387, train_loss = 1.8923061514506117, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 388, train_loss = 1.888249285519123, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 389, train_loss = 1.884430903941393, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 390, train_loss = 1.8805066756904125, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 391, train_loss = 1.8766523463418707, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 392, train_loss = 1.87296198180411, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 393, train_loss = 1.8691568499198183, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 394, train_loss = 1.8654294734587893, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 395, train_loss = 1.8617020534584299, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 396, train_loss = 1.8579183531692252, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 397, train_loss = 1.8543747998774052, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 398, train_loss = 1.8507046898594126, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 399, train_loss = 1.8470587009796873, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 400, train_loss = 1.8435499047627673, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 401, train_loss = 1.8400002183625475, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 402, train_loss = 1.8364631086587906, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 403, train_loss = 1.8330586962401867, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 404, train_loss = 1.8295119205722585, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 405, train_loss = 1.8261115750065073, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 406, train_loss = 1.822634145617485, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 407, train_loss = 1.8193505927920341, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 408, train_loss = 1.8159298760583624, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 409, train_loss = 1.812607180327177, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 410, train_loss = 1.8092258349061012, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 411, train_loss = 1.8059945391723886, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 412, train_loss = 1.8027524799108505, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 413, train_loss = 1.799456860870123, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 414, train_loss = 1.796249832957983, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 415, train_loss = 1.7930691639194265, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 416, train_loss = 1.789840346784331, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 417, train_loss = 1.7868487437954172, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 418, train_loss = 1.7836342429509386, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 419, train_loss = 1.7805903380503878, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 420, train_loss = 1.7774972344050184, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 421, train_loss = 1.774502720683813, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 422, train_loss = 1.7714050723006949, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 423, train_loss = 1.7684177731862292, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 424, train_loss = 1.7653889805078506, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 425, train_loss = 1.7625035891542211, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 426, train_loss = 1.7594994691899046, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 427, train_loss = 1.7566324596991763, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 428, train_loss = 1.7536887936294079, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 429, train_loss = 1.750822907895781, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 430, train_loss = 1.747887946665287, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 431, train_loss = 1.7451129779219627, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 432, train_loss = 1.7422412062296644, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 433, train_loss = 1.7394746268400922, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 434, train_loss = 1.7367326194653288, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 435, train_loss = 1.7339234637329355, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 436, train_loss = 1.7312525237211958, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 437, train_loss = 1.7284718677401543, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 438, train_loss = 1.7257636165013537, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 439, train_loss = 1.7230896018445492, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 440, train_loss = 1.720468501211144, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 441, train_loss = 1.717857556999661, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 442, train_loss = 1.715091542690061, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 443, train_loss = 1.7125546658644453, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 444, train_loss = 1.7099605178227648, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 445, train_loss = 1.7073790753493086, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 446, train_loss = 1.7048027366399765, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 447, train_loss = 1.7022758660605177, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 448, train_loss = 1.699761432944797, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 449, train_loss = 1.6973163360962644, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 450, train_loss = 1.6948479315033183, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 451, train_loss = 1.6923312619328499, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 452, train_loss = 1.6898543325951323, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 453, train_loss = 1.6874484891304746, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 454, train_loss = 1.6850609295070171, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 455, train_loss = 1.6826142681529745, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 456, train_loss = 1.6802811423549429, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 457, train_loss = 1.6779528768965974, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 458, train_loss = 1.6755309030413628, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 459, train_loss = 1.67324100935366, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 460, train_loss = 1.6708531193435192, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 461, train_loss = 1.6685732180485502, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 462, train_loss = 1.6663460632553324, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 463, train_loss = 1.66403543332126, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 464, train_loss = 1.6617917580297217, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 465, train_loss = 1.6595208396902308, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 466, train_loss = 1.6573229059576988, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 467, train_loss = 1.6550999855389819, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 468, train_loss = 1.6528696827590466, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 469, train_loss = 1.650696455151774, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 470, train_loss = 1.648549985140562, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 471, train_loss = 1.6463942440459505, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 472, train_loss = 1.6442697359016165, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 473, train_loss = 1.6421079660067335, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 474, train_loss = 1.6400381786515936, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 475, train_loss = 1.6379074404248968, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 476, train_loss = 1.6357992365956306, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 477, train_loss = 1.6337438635528088, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 478, train_loss = 1.6316378017072566, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 479, train_loss = 1.6296642708475702, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 480, train_loss = 1.6275907444651239, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 481, train_loss = 1.625609529495705, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 482, train_loss = 1.6235689409077168, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 483, train_loss = 1.6215175613760948, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 484, train_loss = 1.6196602334384806, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 485, train_loss = 1.6175713241100311, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 486, train_loss = 1.6156294097309, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 487, train_loss = 1.613730326294899, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 488, train_loss = 1.6117985000018962, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 489, train_loss = 1.609846590727102, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 490, train_loss = 1.607967899471987, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 491, train_loss = 1.6060386101598851, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 492, train_loss = 1.604133018583525, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 493, train_loss = 1.6023062716121785, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 494, train_loss = 1.6004537257249467, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 495, train_loss = 1.598599432676565, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 496, train_loss = 1.5967125172610395, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 497, train_loss = 1.594937960326206, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 498, train_loss = 1.593067790090572, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "22th- epoch: 499, train_loss = 1.591297638893593, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|████████████████████████████████████████████████████▊                   | 22/30 [2:26:11<53:13, 399.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "23th- epoch: 0, train_loss = 270.2150901556015, train_acc = 0.441895668374476\n",
      "test Acc 0.49115456238361266:\n",
      "23th- epoch: 1, train_loss = 206.75417470932007, train_acc = 0.4991849091755938\n",
      "test Acc 0.4995344506517691:\n",
      "23th- epoch: 2, train_loss = 165.39785075187683, train_acc = 0.51932929669306\n",
      "test Acc 0.6047486033519553:\n",
      "23th- epoch: 3, train_loss = 144.2771970629692, train_acc = 0.632510479739171\n",
      "test Acc 0.6824953445065177:\n",
      "23th- epoch: 4, train_loss = 126.72896891832352, train_acc = 0.7100605496040987\n",
      "test Acc 0.7383612662942272:\n",
      "23th- epoch: 5, train_loss = 110.9806552529335, train_acc = 0.7546576618537494\n",
      "test Acc 0.7802607076350093:\n",
      "23th- epoch: 6, train_loss = 97.07507884502411, train_acc = 0.8055426176059618\n",
      "test Acc 0.8175046554934823:\n",
      "23th- epoch: 7, train_loss = 85.15410232543945, train_acc = 0.8334885887284583\n",
      "test Acc 0.8431098696461825:\n",
      "23th- epoch: 8, train_loss = 75.06400948762894, train_acc = 0.8558453656264555\n",
      "test Acc 0.8682495344506518:\n",
      "23th- epoch: 9, train_loss = 66.62620708346367, train_acc = 0.8705170004657662\n",
      "test Acc 0.8743016759776536:\n",
      "23th- epoch: 10, train_loss = 59.653843224048615, train_acc = 0.8794829995342338\n",
      "test Acc 0.8812849162011173:\n",
      "23th- epoch: 11, train_loss = 53.93912519514561, train_acc = 0.8885654401490451\n",
      "test Acc 0.8878026070763501:\n",
      "23th- epoch: 12, train_loss = 49.25588893890381, train_acc = 0.8964834653004192\n",
      "test Acc 0.9017690875232774:\n",
      "23th- epoch: 13, train_loss = 45.38248424232006, train_acc = 0.9083605030274802\n",
      "test Acc 0.9175977653631285:\n",
      "23th- epoch: 14, train_loss = 42.13858325779438, train_acc = 0.9197717745691663\n",
      "test Acc 0.9227188081936686:\n",
      "23th- epoch: 15, train_loss = 39.38473303616047, train_acc = 0.9283884489986027\n",
      "test Acc 0.9315642458100558:\n",
      "23th- epoch: 16, train_loss = 37.01913347840309, train_acc = 0.9342105263157895\n",
      "test Acc 0.9385474860335196:\n",
      "23th- epoch: 17, train_loss = 34.965209029614925, train_acc = 0.9416627852817886\n",
      "test Acc 0.9408752327746741:\n",
      "23th- epoch: 18, train_loss = 33.163477160036564, train_acc = 0.9432929669306008\n",
      "test Acc 0.9445996275605214:\n",
      "23th- epoch: 19, train_loss = 31.57224480062723, train_acc = 0.9457382394038193\n",
      "test Acc 0.9450651769087524:\n",
      "23th- epoch: 20, train_loss = 30.16304562985897, train_acc = 0.9474848625989754\n",
      "test Acc 0.9464618249534451:\n",
      "23th- epoch: 21, train_loss = 28.905651092529297, train_acc = 0.9489986027014439\n",
      "test Acc 0.9483240223463687:\n",
      "23th- epoch: 22, train_loss = 27.77387449890375, train_acc = 0.9506287843502562\n",
      "test Acc 0.952048417132216:\n",
      "23th- epoch: 23, train_loss = 26.751060970127583, train_acc = 0.9527247321844434\n",
      "test Acc 0.9529795158286778:\n",
      "23th- epoch: 24, train_loss = 25.82150226086378, train_acc = 0.9538891476478808\n",
      "test Acc 0.9539106145251397:\n",
      "23th- epoch: 25, train_loss = 24.971077613532543, train_acc = 0.9551700046576619\n",
      "test Acc 0.9553072625698324:\n",
      "23th- epoch: 26, train_loss = 24.1891368329525, train_acc = 0.9565673032137867\n",
      "test Acc 0.9562383612662942:\n",
      "23th- epoch: 27, train_loss = 23.467801928520203, train_acc = 0.9569166278528178\n",
      "test Acc 0.9562383612662942:\n",
      "23th- epoch: 28, train_loss = 22.79920057952404, train_acc = 0.9579646017699115\n",
      "test Acc 0.957169459962756:\n",
      "23th- epoch: 29, train_loss = 22.176047649234533, train_acc = 0.9587796925943176\n",
      "test Acc 0.957169459962756:\n",
      "23th- epoch: 30, train_loss = 21.594140969216824, train_acc = 0.9597112249650676\n",
      "test Acc 0.957635009310987:\n",
      "23th- epoch: 31, train_loss = 21.049384277313948, train_acc = 0.9605263157894737\n",
      "test Acc 0.9581005586592178:\n",
      "23th- epoch: 32, train_loss = 20.537119038403034, train_acc = 0.9607591988821611\n",
      "test Acc 0.9585661080074488:\n",
      "23th- epoch: 33, train_loss = 20.05392077192664, train_acc = 0.9611085235211924\n",
      "test Acc 0.9585661080074488:\n",
      "23th- epoch: 34, train_loss = 19.596014633774757, train_acc = 0.9614578481602236\n",
      "test Acc 0.9585661080074488:\n",
      "23th- epoch: 35, train_loss = 19.16245048120618, train_acc = 0.9622729389846297\n",
      "test Acc 0.9585661080074488:\n",
      "23th- epoch: 36, train_loss = 18.751399233937263, train_acc = 0.9633209129017233\n",
      "test Acc 0.9594972067039106:\n",
      "23th- epoch: 37, train_loss = 18.359821137040854, train_acc = 0.9642524452724732\n",
      "test Acc 0.9594972067039106:\n",
      "23th- epoch: 38, train_loss = 17.986107904464006, train_acc = 0.9649510945505356\n",
      "test Acc 0.9599627560521415:\n",
      "23th- epoch: 39, train_loss = 17.62917637079954, train_acc = 0.9658826269212856\n",
      "test Acc 0.9613594040968343:\n",
      "23th- epoch: 40, train_loss = 17.285479549318552, train_acc = 0.9664648346530041\n",
      "test Acc 0.9632216014897579:\n",
      "23th- epoch: 41, train_loss = 16.957030966877937, train_acc = 0.9670470423847228\n",
      "test Acc 0.9632216014897579:\n",
      "23th- epoch: 42, train_loss = 16.642975002527237, train_acc = 0.9678621332091291\n",
      "test Acc 0.9636871508379888:\n",
      "23th- epoch: 43, train_loss = 16.34184906631708, train_acc = 0.9682114578481602\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 44, train_loss = 16.051976941525936, train_acc = 0.9691429902189101\n",
      "test Acc 0.9641527001862198:\n",
      "23th- epoch: 45, train_loss = 15.772843088954687, train_acc = 0.969608756404285\n",
      "test Acc 0.9646182495344506:\n",
      "23th- epoch: 46, train_loss = 15.503991596400738, train_acc = 0.970540288775035\n",
      "test Acc 0.9650837988826816:\n",
      "23th- epoch: 47, train_loss = 15.244820952415466, train_acc = 0.9706567303213787\n",
      "test Acc 0.9650837988826816:\n",
      "23th- epoch: 48, train_loss = 14.995120085775852, train_acc = 0.971821145784816\n",
      "test Acc 0.9646182495344506:\n",
      "23th- epoch: 49, train_loss = 14.754118356853724, train_acc = 0.9724033535165347\n",
      "test Acc 0.9646182495344506:\n",
      "23th- epoch: 50, train_loss = 14.521636959165335, train_acc = 0.9728691197019096\n",
      "test Acc 0.9650837988826816:\n",
      "23th- epoch: 51, train_loss = 14.29712562635541, train_acc = 0.9734513274336283\n",
      "test Acc 0.9655493482309124:\n",
      "23th- epoch: 52, train_loss = 14.080201234668493, train_acc = 0.9736842105263158\n",
      "test Acc 0.9660148975791434:\n",
      "23th- epoch: 53, train_loss = 13.870229385793209, train_acc = 0.9736842105263158\n",
      "test Acc 0.9664804469273743:\n",
      "23th- epoch: 54, train_loss = 13.666874393820763, train_acc = 0.974033535165347\n",
      "test Acc 0.9669459962756052:\n",
      "23th- epoch: 55, train_loss = 13.46973505243659, train_acc = 0.9742664182580345\n",
      "test Acc 0.9674115456238361:\n",
      "23th- epoch: 56, train_loss = 13.278475530445576, train_acc = 0.9741499767116907\n",
      "test Acc 0.9674115456238361:\n",
      "23th- epoch: 57, train_loss = 13.09286504983902, train_acc = 0.9742664182580345\n",
      "test Acc 0.9674115456238361:\n",
      "23th- epoch: 58, train_loss = 12.912681743502617, train_acc = 0.9743828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 59, train_loss = 12.737614255398512, train_acc = 0.9747321844434094\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 60, train_loss = 12.567609779536724, train_acc = 0.9751979506287843\n",
      "test Acc 0.9674115456238361:\n",
      "23th- epoch: 61, train_loss = 12.402115989476442, train_acc = 0.9751979506287843\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 62, train_loss = 12.241180211305618, train_acc = 0.9754308337214718\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 63, train_loss = 12.084467362612486, train_acc = 0.9755472752678156\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 64, train_loss = 11.931585103273392, train_acc = 0.976245924545878\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 65, train_loss = 11.782221157103777, train_acc = 0.9767116907312529\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 66, train_loss = 11.635685458779335, train_acc = 0.9769445738239404\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 67, train_loss = 11.492141529917717, train_acc = 0.9776432231020028\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 68, train_loss = 11.352620270103216, train_acc = 0.9777596646483465\n",
      "test Acc 0.9678770949720671:\n",
      "23th- epoch: 69, train_loss = 11.216982878744602, train_acc = 0.9778761061946902\n",
      "test Acc 0.9683426443202979:\n",
      "23th- epoch: 70, train_loss = 11.0847835727036, train_acc = 0.9782254308337215\n",
      "test Acc 0.9683426443202979:\n",
      "23th- epoch: 71, train_loss = 10.955522513017058, train_acc = 0.9783418723800652\n",
      "test Acc 0.9683426443202979:\n",
      "23th- epoch: 72, train_loss = 10.829366505146027, train_acc = 0.9784583139264089\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 73, train_loss = 10.706126842647791, train_acc = 0.9784583139264089\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 74, train_loss = 10.585681393742561, train_acc = 0.9786911970190965\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 75, train_loss = 10.467691011726856, train_acc = 0.9789240801117839\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 76, train_loss = 10.352171996608377, train_acc = 0.9790405216581276\n",
      "test Acc 0.9688081936685289:\n",
      "23th- epoch: 77, train_loss = 10.238684782758355, train_acc = 0.9795062878435026\n",
      "test Acc 0.9692737430167597:\n",
      "23th- epoch: 78, train_loss = 10.127605196088552, train_acc = 0.9795062878435026\n",
      "test Acc 0.9692737430167597:\n",
      "23th- epoch: 79, train_loss = 10.018625255674124, train_acc = 0.9795062878435026\n",
      "test Acc 0.9692737430167597:\n",
      "23th- epoch: 80, train_loss = 9.911841060966253, train_acc = 0.9795062878435026\n",
      "test Acc 0.9697392923649907:\n",
      "23th- epoch: 81, train_loss = 9.807089490815997, train_acc = 0.9795062878435026\n",
      "test Acc 0.9697392923649907:\n",
      "23th- epoch: 82, train_loss = 9.704206572845578, train_acc = 0.9795062878435026\n",
      "test Acc 0.9697392923649907:\n",
      "23th- epoch: 83, train_loss = 9.603270949795842, train_acc = 0.97973917093619\n",
      "test Acc 0.9702048417132216:\n",
      "23th- epoch: 84, train_loss = 9.504090832546353, train_acc = 0.97973917093619\n",
      "test Acc 0.9702048417132216:\n",
      "23th- epoch: 85, train_loss = 9.406742718070745, train_acc = 0.9800884955752213\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 86, train_loss = 9.310915747657418, train_acc = 0.9803213786679087\n",
      "test Acc 0.9716014897579144:\n",
      "23th- epoch: 87, train_loss = 9.216609450057149, train_acc = 0.9803213786679087\n",
      "test Acc 0.9716014897579144:\n",
      "23th- epoch: 88, train_loss = 9.124025722965598, train_acc = 0.9807871448532837\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 89, train_loss = 9.032772354781628, train_acc = 0.9807871448532837\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 90, train_loss = 8.942924708127975, train_acc = 0.9807871448532837\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 91, train_loss = 8.85451391339302, train_acc = 0.9811364694923148\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 92, train_loss = 8.767297323793173, train_acc = 0.9812529110386586\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 93, train_loss = 8.6814622618258, train_acc = 0.9814857941313461\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 94, train_loss = 8.597017409279943, train_acc = 0.9818351187703773\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 95, train_loss = 8.513577310368419, train_acc = 0.9824173265020959\n",
      "test Acc 0.9725325884543762:\n",
      "23th- epoch: 96, train_loss = 8.431389456614852, train_acc = 0.9826502095947834\n",
      "test Acc 0.9725325884543762:\n",
      "23th- epoch: 97, train_loss = 8.350375862792134, train_acc = 0.9827666511411272\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 98, train_loss = 8.270607609301805, train_acc = 0.9828830926874709\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 99, train_loss = 8.192022694274783, train_acc = 0.9828830926874709\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 100, train_loss = 8.114547407254577, train_acc = 0.9832324173265021\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 101, train_loss = 8.038206221535802, train_acc = 0.9832324173265021\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 102, train_loss = 7.962993487715721, train_acc = 0.9833488588728458\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 103, train_loss = 7.8889060486108065, train_acc = 0.9835817419655333\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 104, train_loss = 7.815740391612053, train_acc = 0.9835817419655333\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 105, train_loss = 7.7435867097228765, train_acc = 0.9839310666045645\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 106, train_loss = 7.672406401485205, train_acc = 0.9840475081509082\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 107, train_loss = 7.602096874266863, train_acc = 0.9842803912435957\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 108, train_loss = 7.532727692276239, train_acc = 0.9845132743362832\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 109, train_loss = 7.464362485334277, train_acc = 0.9846297158826269\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 110, train_loss = 7.396865293383598, train_acc = 0.9847461574289706\n",
      "test Acc 0.9743947858472998:\n",
      "23th- epoch: 111, train_loss = 7.330225711688399, train_acc = 0.9849790405216581\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 112, train_loss = 7.264594577252865, train_acc = 0.9849790405216581\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 113, train_loss = 7.199599476531148, train_acc = 0.9849790405216581\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 114, train_loss = 7.135732103139162, train_acc = 0.9849790405216581\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 115, train_loss = 7.072480391710997, train_acc = 0.9852119236143456\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 116, train_loss = 7.010150982066989, train_acc = 0.9856776897997206\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 117, train_loss = 6.948254473507404, train_acc = 0.9855612482533768\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 118, train_loss = 6.887114208191633, train_acc = 0.9856776897997206\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 119, train_loss = 6.826952390372753, train_acc = 0.9860270144387517\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 120, train_loss = 6.767453886568546, train_acc = 0.9861434559850955\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 121, train_loss = 6.708648752421141, train_acc = 0.9862598975314392\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 122, train_loss = 6.650726435706019, train_acc = 0.986376339077783\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 123, train_loss = 6.593602117151022, train_acc = 0.9866092221704704\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 124, train_loss = 6.5370572078973055, train_acc = 0.9866092221704704\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 125, train_loss = 6.481417058035731, train_acc = 0.9867256637168141\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 126, train_loss = 6.426213702186942, train_acc = 0.9869585468095017\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 127, train_loss = 6.371895890682936, train_acc = 0.9869585468095017\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 128, train_loss = 6.318125355988741, train_acc = 0.9870749883558454\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 129, train_loss = 6.265248626470566, train_acc = 0.9871914299021891\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 130, train_loss = 6.213095339015126, train_acc = 0.9871914299021891\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 131, train_loss = 6.16134318523109, train_acc = 0.9873078714485328\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 132, train_loss = 6.110338496044278, train_acc = 0.9873078714485328\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 133, train_loss = 6.059905493631959, train_acc = 0.9874243129948765\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 134, train_loss = 6.0101297199726105, train_acc = 0.9876571960875641\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 135, train_loss = 5.960948431864381, train_acc = 0.9876571960875641\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 136, train_loss = 5.912245571613312, train_acc = 0.9876571960875641\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 137, train_loss = 5.864247443154454, train_acc = 0.9877736376339078\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 138, train_loss = 5.816809156909585, train_acc = 0.9877736376339078\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 139, train_loss = 5.770085835829377, train_acc = 0.9878900791802515\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 140, train_loss = 5.723959477618337, train_acc = 0.9883558453656265\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 141, train_loss = 5.67832494340837, train_acc = 0.9883558453656265\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 142, train_loss = 5.633388748392463, train_acc = 0.9883558453656265\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 143, train_loss = 5.588861141353846, train_acc = 0.9883558453656265\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 144, train_loss = 5.5450989454984665, train_acc = 0.9885887284583139\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 145, train_loss = 5.501616088673472, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 146, train_loss = 5.45894917473197, train_acc = 0.9887051700046576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 147, train_loss = 5.416749306023121, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 148, train_loss = 5.374901939183474, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 149, train_loss = 5.3337002620100975, train_acc = 0.9888216115510013\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 150, train_loss = 5.293004227802157, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 151, train_loss = 5.252828258089721, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 152, train_loss = 5.213204404339194, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 153, train_loss = 5.1740130335092545, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 154, train_loss = 5.135303036309779, train_acc = 0.9892873777363763\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 155, train_loss = 5.097011353820562, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 156, train_loss = 5.05920057091862, train_acc = 0.9895202608290639\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 157, train_loss = 5.021873679943383, train_acc = 0.9895202608290639\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 158, train_loss = 4.984959244728088, train_acc = 0.9896367023754076\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 159, train_loss = 4.948475272394717, train_acc = 0.9897531439217513\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 160, train_loss = 4.912470309063792, train_acc = 0.989869585468095\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 161, train_loss = 4.8769005527719855, train_acc = 0.989869585468095\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 162, train_loss = 4.841833109036088, train_acc = 0.989869585468095\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 163, train_loss = 4.80708886962384, train_acc = 0.989869585468095\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 164, train_loss = 4.7728192219510674, train_acc = 0.9901024685607824\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 165, train_loss = 4.7389837466180325, train_acc = 0.9902189101071263\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 166, train_loss = 4.705524884164333, train_acc = 0.9902189101071263\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 167, train_loss = 4.672413575462997, train_acc = 0.9902189101071263\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 168, train_loss = 4.639943549409509, train_acc = 0.9904517931998137\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 169, train_loss = 4.607751104049385, train_acc = 0.9905682347461574\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 170, train_loss = 4.5758564760908484, train_acc = 0.9906846762925011\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 171, train_loss = 4.544409201480448, train_acc = 0.990801117838845\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 172, train_loss = 4.513356299139559, train_acc = 0.990801117838845\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 173, train_loss = 4.482731803320348, train_acc = 0.9910340009315324\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 174, train_loss = 4.452426922507584, train_acc = 0.9911504424778761\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 175, train_loss = 4.422412938438356, train_acc = 0.9911504424778761\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 176, train_loss = 4.392904635518789, train_acc = 0.9911504424778761\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 177, train_loss = 4.363723034970462, train_acc = 0.9911504424778761\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 178, train_loss = 4.334842306561768, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 179, train_loss = 4.3062208872288465, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 180, train_loss = 4.278021438978612, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 181, train_loss = 4.250026189722121, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 182, train_loss = 4.222699464298785, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 183, train_loss = 4.195303776301444, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 184, train_loss = 4.168438850902021, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 185, train_loss = 4.14196655806154, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 186, train_loss = 4.11552286054939, train_acc = 0.9913833255705635\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 187, train_loss = 4.089589680545032, train_acc = 0.9913833255705635\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 188, train_loss = 4.063938811421394, train_acc = 0.9914997671169073\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 189, train_loss = 4.038498078472912, train_acc = 0.9914997671169073\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 190, train_loss = 4.0134748900309205, train_acc = 0.9914997671169073\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 191, train_loss = 3.9886150928214192, train_acc = 0.9917326502095948\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 192, train_loss = 3.9641127036884427, train_acc = 0.9917326502095948\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 193, train_loss = 3.9398754686117172, train_acc = 0.9917326502095948\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 194, train_loss = 3.9159413129091263, train_acc = 0.9917326502095948\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 195, train_loss = 3.8922393629327416, train_acc = 0.9917326502095948\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 196, train_loss = 3.86875331774354, train_acc = 0.9918490917559385\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 197, train_loss = 3.8455566177144647, train_acc = 0.9918490917559385\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 198, train_loss = 3.82275730650872, train_acc = 0.992081974848626\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 199, train_loss = 3.800083122216165, train_acc = 0.9923148579413135\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 200, train_loss = 3.7776581458747387, train_acc = 0.9923148579413135\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 201, train_loss = 3.755542782135308, train_acc = 0.9925477410340009\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 202, train_loss = 3.7336181793361902, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 203, train_loss = 3.7120062364265323, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 204, train_loss = 3.690544215030968, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 205, train_loss = 3.6694160848855972, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 206, train_loss = 3.6484574964269996, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 207, train_loss = 3.6277590664103627, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 208, train_loss = 3.6071990812197328, train_acc = 0.9928970656730322\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 209, train_loss = 3.587078965269029, train_acc = 0.9928970656730322\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 210, train_loss = 3.566975043155253, train_acc = 0.9928970656730322\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 211, train_loss = 3.5472009824588895, train_acc = 0.9928970656730322\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 212, train_loss = 3.5274983383715153, train_acc = 0.9928970656730322\n",
      "test Acc 0.9776536312849162:\n",
      "23th- epoch: 213, train_loss = 3.5082036056555808, train_acc = 0.9930135072193759\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 214, train_loss = 3.4891002965159714, train_acc = 0.9930135072193759\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 215, train_loss = 3.470218227710575, train_acc = 0.9930135072193759\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 216, train_loss = 3.451410388108343, train_acc = 0.9930135072193759\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 217, train_loss = 3.4329577032476664, train_acc = 0.9930135072193759\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 218, train_loss = 3.4145856015384197, train_acc = 0.9931299487657196\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 219, train_loss = 3.3966070585884154, train_acc = 0.9931299487657196\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 220, train_loss = 3.37854095781222, train_acc = 0.9931299487657196\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 221, train_loss = 3.360839480534196, train_acc = 0.9931299487657196\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 222, train_loss = 3.343187843915075, train_acc = 0.9932463903120633\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 223, train_loss = 3.325874916743487, train_acc = 0.9932463903120633\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 224, train_loss = 3.308698071166873, train_acc = 0.9933628318584071\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 225, train_loss = 3.2916112672537565, train_acc = 0.9933628318584071\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 226, train_loss = 3.2747897640801966, train_acc = 0.9933628318584071\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 227, train_loss = 3.2580974283628166, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 228, train_loss = 3.2416490926407278, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 229, train_loss = 3.225223313551396, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 230, train_loss = 3.209077538456768, train_acc = 0.9937121564974383\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 231, train_loss = 3.193102835211903, train_acc = 0.9937121564974383\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 232, train_loss = 3.177217020187527, train_acc = 0.9937121564974383\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 233, train_loss = 3.1615172824822366, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 234, train_loss = 3.1460840911604464, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 235, train_loss = 3.1306197247467935, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 236, train_loss = 3.115384168922901, train_acc = 0.993828598043782\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 237, train_loss = 3.100429733749479, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 238, train_loss = 3.0854615471325815, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 239, train_loss = 3.070556789636612, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 240, train_loss = 3.056044439319521, train_acc = 0.9939450395901258\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 241, train_loss = 3.0414167367853224, train_acc = 0.9940614811364695\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 242, train_loss = 3.027113212738186, train_acc = 0.9940614811364695\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 243, train_loss = 3.012807463761419, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 244, train_loss = 2.99883117293939, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 245, train_loss = 2.9848967120051384, train_acc = 0.9941779226828132\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 246, train_loss = 2.9709538593888283, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 247, train_loss = 2.9574292614124715, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 248, train_loss = 2.9437790527008474, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 249, train_loss = 2.9303190484642982, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 250, train_loss = 2.917073199059814, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 251, train_loss = 2.903855661395937, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 252, train_loss = 2.8908291161060333, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 253, train_loss = 2.877883404493332, train_acc = 0.994294364229157\n",
      "test Acc 0.9781191806331471:\n",
      "23th- epoch: 254, train_loss = 2.8650805191136897, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 255, train_loss = 2.8524436354637146, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 256, train_loss = 2.839836427476257, train_acc = 0.9944108057755007\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 257, train_loss = 2.8274500630795956, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 258, train_loss = 2.8151059611700475, train_acc = 0.9945272473218444\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 259, train_loss = 2.803010819014162, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 260, train_loss = 2.790910939220339, train_acc = 0.9946436888681882\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 261, train_loss = 2.7787868604063988, train_acc = 0.9947601304145319\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 262, train_loss = 2.767066564410925, train_acc = 0.9947601304145319\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 263, train_loss = 2.75513281673193, train_acc = 0.9947601304145319\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 264, train_loss = 2.7435728372074664, train_acc = 0.9947601304145319\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 265, train_loss = 2.7320094108581543, train_acc = 0.9947601304145319\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 266, train_loss = 2.720615990459919, train_acc = 0.9947601304145319\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 267, train_loss = 2.709244234021753, train_acc = 0.9947601304145319\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 268, train_loss = 2.6979417577385902, train_acc = 0.9947601304145319\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 269, train_loss = 2.6868522106669843, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 270, train_loss = 2.675838539842516, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 271, train_loss = 2.664831259753555, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 272, train_loss = 2.6540240519680083, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 273, train_loss = 2.6432703523896635, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 274, train_loss = 2.632656226400286, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 275, train_loss = 2.622159784194082, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 276, train_loss = 2.6115695140324533, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 277, train_loss = 2.601397778838873, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 278, train_loss = 2.591126322746277, train_acc = 0.9945272473218444\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 279, train_loss = 2.5809491029940546, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 280, train_loss = 2.5709235058166087, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 281, train_loss = 2.5608778432942927, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 282, train_loss = 2.551035305019468, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 283, train_loss = 2.5412869839929044, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 284, train_loss = 2.531438624020666, train_acc = 0.9946436888681882\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 285, train_loss = 2.521853808313608, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 286, train_loss = 2.5123666836880147, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 287, train_loss = 2.502875918056816, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 288, train_loss = 2.4934068210422993, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 289, train_loss = 2.484235836658627, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 290, train_loss = 2.474995033349842, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 291, train_loss = 2.465861322823912, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 292, train_loss = 2.45677008992061, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 293, train_loss = 2.447812035679817, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 294, train_loss = 2.43890896695666, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 295, train_loss = 2.4301003739237785, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 296, train_loss = 2.42144616949372, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 297, train_loss = 2.4126834832131863, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 298, train_loss = 2.404066041111946, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 299, train_loss = 2.395548852859065, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 300, train_loss = 2.3872897427063435, train_acc = 0.9947601304145319\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 301, train_loss = 2.378872973145917, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 302, train_loss = 2.3705870620906353, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 303, train_loss = 2.362377253593877, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 304, train_loss = 2.3542765229940414, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 305, train_loss = 2.3462226565461606, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 306, train_loss = 2.338339125039056, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 307, train_loss = 2.3303813461679965, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 308, train_loss = 2.3226289339363575, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 309, train_loss = 2.314828806789592, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 310, train_loss = 2.307196381269023, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 311, train_loss = 2.299625125946477, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 312, train_loss = 2.292094149859622, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 313, train_loss = 2.284576551290229, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 314, train_loss = 2.2772582571487874, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 315, train_loss = 2.2698990057688206, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 316, train_loss = 2.2626296046655625, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 317, train_loss = 2.2554589596111327, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 318, train_loss = 2.248446963727474, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 319, train_loss = 2.241319624008611, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 320, train_loss = 2.234386229189113, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 321, train_loss = 2.2274194869678468, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 322, train_loss = 2.22064986708574, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 323, train_loss = 2.2137920036911964, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 324, train_loss = 2.2071951602119952, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 325, train_loss = 2.2005040161311626, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 326, train_loss = 2.1939202409703285, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 327, train_loss = 2.1873393543064594, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 328, train_loss = 2.180903884349391, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 329, train_loss = 2.1744628858286887, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 330, train_loss = 2.1681020830292255, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 331, train_loss = 2.161788222612813, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 332, train_loss = 2.1555845588445663, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 333, train_loss = 2.149343567667529, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 334, train_loss = 2.14319854718633, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 335, train_loss = 2.13708958029747, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 336, train_loss = 2.1310671295505017, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 337, train_loss = 2.1250042021274567, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 338, train_loss = 2.119188005803153, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 339, train_loss = 2.113274186849594, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 340, train_loss = 2.107475644676015, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 341, train_loss = 2.1017612777650356, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 342, train_loss = 2.096098964335397, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 343, train_loss = 2.090384694514796, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 344, train_loss = 2.0847023862879723, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 345, train_loss = 2.0792685474734753, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 346, train_loss = 2.073754048673436, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 347, train_loss = 2.068265788257122, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 348, train_loss = 2.062883858801797, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 349, train_loss = 2.057489151833579, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 350, train_loss = 2.052281953394413, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 351, train_loss = 2.0469569985289127, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 352, train_loss = 2.0416698765475303, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 353, train_loss = 2.0366076417267323, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 354, train_loss = 2.0315027546603233, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 355, train_loss = 2.026379143120721, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 356, train_loss = 2.021396492840722, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 357, train_loss = 2.016323869349435, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 358, train_loss = 2.0114328402560204, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 359, train_loss = 2.0064560920000076, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 360, train_loss = 2.0016560591757298, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 361, train_loss = 1.9968033954501152, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 362, train_loss = 1.9920991833787411, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 363, train_loss = 1.9873074814677238, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 364, train_loss = 1.9826452943962067, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 365, train_loss = 1.9778909359592944, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 366, train_loss = 1.9733791500329971, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 367, train_loss = 1.968828409910202, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 368, train_loss = 1.964213726343587, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 369, train_loss = 1.9596593726892024, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 370, train_loss = 1.9552966083865613, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 371, train_loss = 1.950804679421708, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 372, train_loss = 1.9464768506586552, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 373, train_loss = 1.9420361209195107, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 374, train_loss = 1.9377977289259434, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 375, train_loss = 1.9335866917390376, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 376, train_loss = 1.929251704365015, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 377, train_loss = 1.925074638100341, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 378, train_loss = 1.9208422924857587, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 379, train_loss = 1.9166791327297688, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 380, train_loss = 1.9126592848915607, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 381, train_loss = 1.9085614867508411, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 382, train_loss = 1.904493416310288, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 383, train_loss = 1.9004347436130047, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 384, train_loss = 1.8964824713766575, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 385, train_loss = 1.892652366310358, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 386, train_loss = 1.8886501068482175, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 387, train_loss = 1.884790894924663, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 388, train_loss = 1.8808773756027222, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 389, train_loss = 1.8771447936305776, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 390, train_loss = 1.8733011098811403, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 391, train_loss = 1.869578368961811, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 392, train_loss = 1.8658117862651125, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 393, train_loss = 1.862180732190609, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 394, train_loss = 1.8584613353013992, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 395, train_loss = 1.8548188457498327, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 396, train_loss = 1.8511515408754349, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 397, train_loss = 1.8476660860469565, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 398, train_loss = 1.8440143205225468, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 399, train_loss = 1.8405496428022161, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 400, train_loss = 1.837058295845054, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 401, train_loss = 1.8334556320914999, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 402, train_loss = 1.8301033502211794, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 403, train_loss = 1.8265978917479515, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 404, train_loss = 1.8232203846564516, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 405, train_loss = 1.8197549110045657, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 406, train_loss = 1.816343062906526, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 407, train_loss = 1.8132260715356097, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 408, train_loss = 1.8098632456967607, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 409, train_loss = 1.8065937981009483, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 410, train_loss = 1.803318127989769, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 411, train_loss = 1.8000844469061121, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 412, train_loss = 1.796709194779396, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 413, train_loss = 1.7937929444015026, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 414, train_loss = 1.7906189585337415, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 415, train_loss = 1.7874294929206371, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 416, train_loss = 1.7843238351633772, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 417, train_loss = 1.781330231577158, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 418, train_loss = 1.7781268520047888, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 419, train_loss = 1.7750900337705389, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 420, train_loss = 1.7720791846513748, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 421, train_loss = 1.7688953392207623, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 422, train_loss = 1.766206836909987, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 423, train_loss = 1.7629821473965421, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 424, train_loss = 1.760156560689211, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 425, train_loss = 1.7571927830576897, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 426, train_loss = 1.7542742105433717, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 427, train_loss = 1.7515226937830448, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 428, train_loss = 1.7486038667848334, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 429, train_loss = 1.745820021838881, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 430, train_loss = 1.7428948594024405, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 431, train_loss = 1.7401569783687592, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 432, train_loss = 1.7373627139022574, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 433, train_loss = 1.7346075723180547, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 434, train_loss = 1.7319137329468504, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 435, train_loss = 1.7291825488209724, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 436, train_loss = 1.7263613803079352, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 437, train_loss = 1.7239394187927246, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 438, train_loss = 1.721151871024631, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 439, train_loss = 1.71844582259655, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 440, train_loss = 1.7158756107091904, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 441, train_loss = 1.713244155049324, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 442, train_loss = 1.7107018418610096, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 443, train_loss = 1.7080965042114258, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 444, train_loss = 1.7056244785198942, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 445, train_loss = 1.7028966756770387, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 446, train_loss = 1.7006091127404943, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 447, train_loss = 1.6979514993727207, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 448, train_loss = 1.6955583418020979, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 449, train_loss = 1.6930475557455793, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 450, train_loss = 1.6905767234275118, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 451, train_loss = 1.6881118578603491, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 452, train_loss = 1.68585968518164, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 453, train_loss = 1.683279536664486, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 454, train_loss = 1.681057951063849, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 455, train_loss = 1.6785064823925495, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 456, train_loss = 1.6763197170803323, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 457, train_loss = 1.6739342088112608, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 458, train_loss = 1.6715922318398952, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 459, train_loss = 1.6693350920686498, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 460, train_loss = 1.666982946335338, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 461, train_loss = 1.6646583216497675, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 462, train_loss = 1.662660421221517, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 463, train_loss = 1.6601964061846957, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 464, train_loss = 1.6579585945000872, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 465, train_loss = 1.6557903625071049, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 466, train_loss = 1.6536531870951876, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 467, train_loss = 1.6513933589449152, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 468, train_loss = 1.649293765425682, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 469, train_loss = 1.647165215224959, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 470, train_loss = 1.6448776485631242, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 471, train_loss = 1.642788735567592, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 472, train_loss = 1.640608330606483, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 473, train_loss = 1.6386683384189382, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 474, train_loss = 1.63649955263827, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 475, train_loss = 1.6344425653805956, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 476, train_loss = 1.6323045330354944, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 477, train_loss = 1.6302359849214554, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 478, train_loss = 1.6282138576498255, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 479, train_loss = 1.6263638077070937, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 480, train_loss = 1.6242191108176485, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 481, train_loss = 1.6221668733051047, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 482, train_loss = 1.6202324082842097, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 483, train_loss = 1.6183613041648641, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 484, train_loss = 1.616261242539622, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 485, train_loss = 1.6144123785197735, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 486, train_loss = 1.6123663844773546, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 487, train_loss = 1.6103871451923624, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 488, train_loss = 1.6085526024689898, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 489, train_loss = 1.6067156629869714, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 490, train_loss = 1.6047629775712267, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 491, train_loss = 1.602994792163372, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 492, train_loss = 1.6010694144060835, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 493, train_loss = 1.5991321913897991, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 494, train_loss = 1.5973768209223635, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 495, train_loss = 1.5954064193065278, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 496, train_loss = 1.5937960458104499, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 497, train_loss = 1.5918776628677733, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 498, train_loss = 1.5900586222414859, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 499, train_loss = 1.5883797953720205, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████████████████████████████▏                | 23/30 [2:32:48<46:30, 398.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "24th- epoch: 0, train_loss = 274.23117780685425, train_acc = 0.35561248253376804\n",
      "test Acc 0.4725325884543762:\n",
      "24th- epoch: 1, train_loss = 214.2915049791336, train_acc = 0.48428039124359573\n",
      "test Acc 0.49534450651769085:\n",
      "24th- epoch: 2, train_loss = 170.3494439125061, train_acc = 0.5108290638099674\n",
      "test Acc 0.5563314711359404:\n",
      "24th- epoch: 3, train_loss = 146.10000455379486, train_acc = 0.6289007918025151\n",
      "test Acc 0.6838919925512105:\n",
      "24th- epoch: 4, train_loss = 127.93154442310333, train_acc = 0.7037727061015371\n",
      "test Acc 0.7327746741154563:\n",
      "24th- epoch: 5, train_loss = 112.41535812616348, train_acc = 0.7347461574289706\n",
      "test Acc 0.7523277467411545:\n",
      "24th- epoch: 6, train_loss = 99.21181130409241, train_acc = 0.7664182580344667\n",
      "test Acc 0.7877094972067039:\n",
      "24th- epoch: 7, train_loss = 88.07592797279358, train_acc = 0.7996040987424313\n",
      "test Acc 0.8081936685288641:\n",
      "24th- epoch: 8, train_loss = 78.5098606646061, train_acc = 0.8210293432696786\n",
      "test Acc 0.8337988826815642:\n",
      "24th- epoch: 9, train_loss = 70.17941308021545, train_acc = 0.8454820680018631\n",
      "test Acc 0.8584729981378026:\n",
      "24th- epoch: 10, train_loss = 62.97598737478256, train_acc = 0.8701676758267349\n",
      "test Acc 0.8780260707635009:\n",
      "24th- epoch: 11, train_loss = 56.85539001226425, train_acc = 0.8802980903586399\n",
      "test Acc 0.8840782122905028:\n",
      "24th- epoch: 12, train_loss = 51.71874204277992, train_acc = 0.8915929203539823\n",
      "test Acc 0.8957169459962756:\n",
      "24th- epoch: 13, train_loss = 47.43024618923664, train_acc = 0.9041686073591058\n",
      "test Acc 0.909217877094972:\n",
      "24th- epoch: 14, train_loss = 43.840193808078766, train_acc = 0.9179087098276665\n",
      "test Acc 0.9250465549348231:\n",
      "24th- epoch: 15, train_loss = 40.80653232336044, train_acc = 0.9306008383791337\n",
      "test Acc 0.931098696461825:\n",
      "24th- epoch: 16, train_loss = 38.215712293982506, train_acc = 0.935724266418258\n",
      "test Acc 0.9348230912476723:\n",
      "24th- epoch: 17, train_loss = 35.97674471139908, train_acc = 0.9410805775500699\n",
      "test Acc 0.9385474860335196:\n",
      "24th- epoch: 18, train_loss = 34.02925844490528, train_acc = 0.9439916162086632\n",
      "test Acc 0.9413407821229051:\n",
      "24th- epoch: 19, train_loss = 32.3233277797699, train_acc = 0.945854680950163\n",
      "test Acc 0.9432029795158287:\n",
      "24th- epoch: 20, train_loss = 30.819289535284042, train_acc = 0.9481835118770378\n",
      "test Acc 0.9450651769087524:\n",
      "24th- epoch: 21, train_loss = 29.48796723037958, train_acc = 0.9500465766185375\n",
      "test Acc 0.9459962756052142:\n",
      "24th- epoch: 22, train_loss = 28.30162613093853, train_acc = 0.9513274336283186\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 23, train_loss = 27.233457542955875, train_acc = 0.9527247321844434\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 24, train_loss = 26.266767479479313, train_acc = 0.9540055891942245\n",
      "test Acc 0.9515828677839852:\n",
      "24th- epoch: 25, train_loss = 25.388449102640152, train_acc = 0.9552864462040056\n",
      "test Acc 0.9515828677839852:\n",
      "24th- epoch: 26, train_loss = 24.58689060807228, train_acc = 0.955985095482068\n",
      "test Acc 0.9534450651769087:\n",
      "24th- epoch: 27, train_loss = 23.850396931171417, train_acc = 0.9563344201210993\n",
      "test Acc 0.9529795158286778:\n",
      "24th- epoch: 28, train_loss = 23.170854575932026, train_acc = 0.9573823940381928\n",
      "test Acc 0.9534450651769087:\n",
      "24th- epoch: 29, train_loss = 22.540931042283773, train_acc = 0.9585468095016302\n",
      "test Acc 0.9553072625698324:\n",
      "24th- epoch: 30, train_loss = 21.954330909997225, train_acc = 0.9593619003260363\n",
      "test Acc 0.9553072625698324:\n",
      "24th- epoch: 31, train_loss = 21.406315982341766, train_acc = 0.9602934326967862\n",
      "test Acc 0.9553072625698324:\n",
      "24th- epoch: 32, train_loss = 20.8922931663692, train_acc = 0.9612249650675361\n",
      "test Acc 0.9562383612662942:\n",
      "24th- epoch: 33, train_loss = 20.408107671886683, train_acc = 0.9620400558919422\n",
      "test Acc 0.9567039106145251:\n",
      "24th- epoch: 34, train_loss = 19.95073401927948, train_acc = 0.9623893805309734\n",
      "test Acc 0.957169459962756:\n",
      "24th- epoch: 35, train_loss = 19.51751796901226, train_acc = 0.9627387051700047\n",
      "test Acc 0.957635009310987:\n",
      "24th- epoch: 36, train_loss = 19.10597140714526, train_acc = 0.963903120633442\n",
      "test Acc 0.9585661080074488:\n",
      "24th- epoch: 37, train_loss = 18.71461236104369, train_acc = 0.9648346530041919\n",
      "test Acc 0.9590316573556797:\n",
      "24th- epoch: 38, train_loss = 18.34221450611949, train_acc = 0.965649743828598\n",
      "test Acc 0.9594972067039106:\n",
      "24th- epoch: 39, train_loss = 17.98623228445649, train_acc = 0.9663483931066604\n",
      "test Acc 0.9599627560521415:\n",
      "24th- epoch: 40, train_loss = 17.645522262901068, train_acc = 0.9669306008383791\n",
      "test Acc 0.9599627560521415:\n",
      "24th- epoch: 41, train_loss = 17.31895049661398, train_acc = 0.9673963670237541\n",
      "test Acc 0.9599627560521415:\n",
      "24th- epoch: 42, train_loss = 17.005528941750526, train_acc = 0.9675128085700978\n",
      "test Acc 0.9599627560521415:\n",
      "24th- epoch: 43, train_loss = 16.7043012753129, train_acc = 0.9683278993945039\n",
      "test Acc 0.9604283054003724:\n",
      "24th- epoch: 44, train_loss = 16.414396811276674, train_acc = 0.9687936655798789\n",
      "test Acc 0.9608938547486033:\n",
      "24th- epoch: 45, train_loss = 16.1349302791059, train_acc = 0.9692594317652539\n",
      "test Acc 0.9608938547486033:\n",
      "24th- epoch: 46, train_loss = 15.865348413586617, train_acc = 0.9697251979506288\n",
      "test Acc 0.9618249534450651:\n",
      "24th- epoch: 47, train_loss = 15.605135086923838, train_acc = 0.9704238472286912\n",
      "test Acc 0.9632216014897579:\n",
      "24th- epoch: 48, train_loss = 15.353306578472257, train_acc = 0.9712389380530974\n",
      "test Acc 0.9641527001862198:\n",
      "24th- epoch: 49, train_loss = 15.10928832180798, train_acc = 0.9715882626921285\n",
      "test Acc 0.9646182495344506:\n",
      "24th- epoch: 50, train_loss = 14.87303300946951, train_acc = 0.971821145784816\n",
      "test Acc 0.9646182495344506:\n",
      "24th- epoch: 51, train_loss = 14.643812134861946, train_acc = 0.9724033535165347\n",
      "test Acc 0.9650837988826816:\n",
      "24th- epoch: 52, train_loss = 14.421289373189211, train_acc = 0.9731020027945971\n",
      "test Acc 0.9655493482309124:\n",
      "24th- epoch: 53, train_loss = 14.205439113080502, train_acc = 0.9735677689799721\n",
      "test Acc 0.9660148975791434:\n",
      "24th- epoch: 54, train_loss = 13.99672120809555, train_acc = 0.9738006520726595\n",
      "test Acc 0.9664804469273743:\n",
      "24th- epoch: 55, train_loss = 13.794777821749449, train_acc = 0.9739170936190032\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 56, train_loss = 13.599274296313524, train_acc = 0.9742664182580345\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 57, train_loss = 13.409925147891045, train_acc = 0.9747321844434094\n",
      "test Acc 0.9669459962756052:\n",
      "24th- epoch: 58, train_loss = 13.226075038313866, train_acc = 0.9748486259897532\n",
      "test Acc 0.9669459962756052:\n",
      "24th- epoch: 59, train_loss = 13.047445300966501, train_acc = 0.9750815090824406\n",
      "test Acc 0.9669459962756052:\n",
      "24th- epoch: 60, train_loss = 12.87338550388813, train_acc = 0.9755472752678156\n",
      "test Acc 0.9669459962756052:\n",
      "24th- epoch: 61, train_loss = 12.703430023044348, train_acc = 0.9755472752678156\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 62, train_loss = 12.538299731910229, train_acc = 0.9756637168141593\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 63, train_loss = 12.377402111887932, train_acc = 0.975780158360503\n",
      "test Acc 0.9674115456238361:\n",
      "24th- epoch: 64, train_loss = 12.220319848507643, train_acc = 0.9758965999068467\n",
      "test Acc 0.9683426443202979:\n",
      "24th- epoch: 65, train_loss = 12.067459367215633, train_acc = 0.9761294829995343\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 66, train_loss = 11.918944019824266, train_acc = 0.976245924545878\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 67, train_loss = 11.773940231651068, train_acc = 0.9767116907312529\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 68, train_loss = 11.632459670305252, train_acc = 0.9769445738239404\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 69, train_loss = 11.494376365095377, train_acc = 0.9775267815556591\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 70, train_loss = 11.359565027058125, train_acc = 0.9777596646483465\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 71, train_loss = 11.227484084665775, train_acc = 0.977992547741034\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 72, train_loss = 11.098179407417774, train_acc = 0.9782254308337215\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 73, train_loss = 10.971683878451586, train_acc = 0.9782254308337215\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 74, train_loss = 10.847726019099355, train_acc = 0.9783418723800652\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 75, train_loss = 10.726468287408352, train_acc = 0.9785747554727526\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 76, train_loss = 10.60747898556292, train_acc = 0.9785747554727526\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 77, train_loss = 10.490605756640434, train_acc = 0.9785747554727526\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 78, train_loss = 10.375968052074313, train_acc = 0.9788076385654402\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 79, train_loss = 10.263472206890583, train_acc = 0.9789240801117839\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 80, train_loss = 10.153202982619405, train_acc = 0.9791569632044713\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 81, train_loss = 10.044978830963373, train_acc = 0.9792734047508151\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 82, train_loss = 9.938556175678968, train_acc = 0.9792734047508151\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 83, train_loss = 9.834275782108307, train_acc = 0.9792734047508151\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 84, train_loss = 9.731569577008486, train_acc = 0.9795062878435026\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 85, train_loss = 9.63068101555109, train_acc = 0.9796227293898463\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 86, train_loss = 9.530849851667881, train_acc = 0.9798556124825337\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 87, train_loss = 9.432501383125782, train_acc = 0.9800884955752213\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 88, train_loss = 9.33614382892847, train_acc = 0.9800884955752213\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 89, train_loss = 9.24142924696207, train_acc = 0.9804378202142524\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 90, train_loss = 9.148381929844618, train_acc = 0.9805542617605962\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 91, train_loss = 9.056931477040052, train_acc = 0.9805542617605962\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 92, train_loss = 8.966253073886037, train_acc = 0.9807871448532837\n",
      "test Acc 0.9688081936685289:\n",
      "24th- epoch: 93, train_loss = 8.876849858090281, train_acc = 0.9811364694923148\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 94, train_loss = 8.788585482165217, train_acc = 0.9811364694923148\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 95, train_loss = 8.70186292566359, train_acc = 0.9813693525850024\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 96, train_loss = 8.61634610593319, train_acc = 0.9813693525850024\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 97, train_loss = 8.531980816274881, train_acc = 0.9814857941313461\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 98, train_loss = 8.448802379891276, train_acc = 0.9816022356776898\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 99, train_loss = 8.366961382329464, train_acc = 0.981951560316721\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 100, train_loss = 8.286206001415849, train_acc = 0.9821844434094085\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 101, train_loss = 8.206535547971725, train_acc = 0.9823008849557522\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 102, train_loss = 8.12780386954546, train_acc = 0.9823008849557522\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 103, train_loss = 8.050189236178994, train_acc = 0.9823008849557522\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 104, train_loss = 7.97358332760632, train_acc = 0.9827666511411272\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 105, train_loss = 7.897958610206842, train_acc = 0.9829995342338146\n",
      "test Acc 0.9697392923649907:\n",
      "24th- epoch: 106, train_loss = 7.823364593088627, train_acc = 0.9834653004191896\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 107, train_loss = 7.749846909195185, train_acc = 0.983698183511877\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 108, train_loss = 7.67715178988874, train_acc = 0.9839310666045645\n",
      "test Acc 0.9706703910614525:\n",
      "24th- epoch: 109, train_loss = 7.60545077547431, train_acc = 0.9840475081509082\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 110, train_loss = 7.534774657338858, train_acc = 0.9842803912435957\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 111, train_loss = 7.465023627504706, train_acc = 0.9845132743362832\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 112, train_loss = 7.395911553874612, train_acc = 0.9846297158826269\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 113, train_loss = 7.3279105219990015, train_acc = 0.9847461574289706\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 114, train_loss = 7.260633647441864, train_acc = 0.9852119236143456\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 115, train_loss = 7.194083768874407, train_acc = 0.985444806707033\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 116, train_loss = 7.128529312089086, train_acc = 0.9856776897997206\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 117, train_loss = 7.063483335077763, train_acc = 0.9857941313460643\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 118, train_loss = 6.999506348744035, train_acc = 0.985910572892408\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 119, train_loss = 6.936602272093296, train_acc = 0.985910572892408\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 120, train_loss = 6.874548118561506, train_acc = 0.985910572892408\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 121, train_loss = 6.8132389113307, train_acc = 0.985910572892408\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 122, train_loss = 6.752952931448817, train_acc = 0.9861434559850955\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 123, train_loss = 6.693141648545861, train_acc = 0.9862598975314392\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 124, train_loss = 6.634287057444453, train_acc = 0.986376339077783\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 125, train_loss = 6.576138796284795, train_acc = 0.9864927806241267\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 126, train_loss = 6.518759813159704, train_acc = 0.9864927806241267\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 127, train_loss = 6.462131122127175, train_acc = 0.9867256637168141\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 128, train_loss = 6.406055359169841, train_acc = 0.9867256637168141\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 129, train_loss = 6.350850271061063, train_acc = 0.9868421052631579\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 130, train_loss = 6.2963057197630405, train_acc = 0.9869585468095017\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 131, train_loss = 6.242438131943345, train_acc = 0.9869585468095017\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 132, train_loss = 6.189242018386722, train_acc = 0.9871914299021891\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 133, train_loss = 6.136654065921903, train_acc = 0.9873078714485328\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 134, train_loss = 6.084857482463121, train_acc = 0.9873078714485328\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 135, train_loss = 6.033457972109318, train_acc = 0.9873078714485328\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 136, train_loss = 5.9827050771564245, train_acc = 0.9874243129948765\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 137, train_loss = 5.932538375258446, train_acc = 0.9874243129948765\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 138, train_loss = 5.882920794188976, train_acc = 0.9875407545412203\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 139, train_loss = 5.834043415263295, train_acc = 0.9876571960875641\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 140, train_loss = 5.785748116672039, train_acc = 0.9877736376339078\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 141, train_loss = 5.738070318475366, train_acc = 0.9877736376339078\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 142, train_loss = 5.691105613484979, train_acc = 0.9878900791802515\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 143, train_loss = 5.64456594735384, train_acc = 0.9883558453656265\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 144, train_loss = 5.598744118586183, train_acc = 0.9885887284583139\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 145, train_loss = 5.553449423983693, train_acc = 0.9885887284583139\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 146, train_loss = 5.5087764617055655, train_acc = 0.9887051700046576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 147, train_loss = 5.464680893346667, train_acc = 0.9888216115510013\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 148, train_loss = 5.421193255111575, train_acc = 0.9889380530973452\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 149, train_loss = 5.378166601061821, train_acc = 0.9889380530973452\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 150, train_loss = 5.335729109123349, train_acc = 0.9889380530973452\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 151, train_loss = 5.293880704790354, train_acc = 0.9889380530973452\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 152, train_loss = 5.252505626529455, train_acc = 0.9889380530973452\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 153, train_loss = 5.21172877587378, train_acc = 0.9889380530973452\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 154, train_loss = 5.1713164485991, train_acc = 0.9889380530973452\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 155, train_loss = 5.131399614736438, train_acc = 0.9889380530973452\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 156, train_loss = 5.092026447877288, train_acc = 0.9889380530973452\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 157, train_loss = 5.053138170391321, train_acc = 0.9890544946436889\n",
      "test Acc 0.9771880819366853:\n",
      "24th- epoch: 158, train_loss = 5.01466721855104, train_acc = 0.9892873777363763\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 159, train_loss = 4.976818937808275, train_acc = 0.9892873777363763\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 160, train_loss = 4.939348794519901, train_acc = 0.98940381928272\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 161, train_loss = 4.902295107021928, train_acc = 0.98940381928272\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 162, train_loss = 4.86586300842464, train_acc = 0.98940381928272\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 163, train_loss = 4.82979322783649, train_acc = 0.9896367023754076\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 164, train_loss = 4.794090695679188, train_acc = 0.9896367023754076\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 165, train_loss = 4.758887950330973, train_acc = 0.9897531439217513\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 166, train_loss = 4.7241952661424875, train_acc = 0.9897531439217513\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 167, train_loss = 4.689897928386927, train_acc = 0.9899860270144387\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 168, train_loss = 4.656027710065246, train_acc = 0.99033535165347\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 169, train_loss = 4.622383926995099, train_acc = 0.99033535165347\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 170, train_loss = 4.589311424642801, train_acc = 0.9904517931998137\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 171, train_loss = 4.556705172173679, train_acc = 0.9905682347461574\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 172, train_loss = 4.524325520731509, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 173, train_loss = 4.49246309325099, train_acc = 0.9910340009315324\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 174, train_loss = 4.460992453619838, train_acc = 0.9911504424778761\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 175, train_loss = 4.429969236254692, train_acc = 0.9912668840242198\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 176, train_loss = 4.399216099642217, train_acc = 0.9913833255705635\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 177, train_loss = 4.368948036804795, train_acc = 0.9913833255705635\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 178, train_loss = 4.338883638381958, train_acc = 0.9913833255705635\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 179, train_loss = 4.309316257014871, train_acc = 0.9913833255705635\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 180, train_loss = 4.280231051146984, train_acc = 0.9914997671169073\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 181, train_loss = 4.251223755069077, train_acc = 0.9914997671169073\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 182, train_loss = 4.222641967236996, train_acc = 0.9914997671169073\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 183, train_loss = 4.194340934045613, train_acc = 0.9914997671169073\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 184, train_loss = 4.166412283666432, train_acc = 0.9914997671169073\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 185, train_loss = 4.138725007884204, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 186, train_loss = 4.111460291780531, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 187, train_loss = 4.084458229131997, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 188, train_loss = 4.057922069914639, train_acc = 0.9918490917559385\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 189, train_loss = 4.031714793294668, train_acc = 0.9918490917559385\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 190, train_loss = 4.005783320404589, train_acc = 0.9918490917559385\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 191, train_loss = 3.9801198579370975, train_acc = 0.9918490917559385\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 192, train_loss = 3.9548998596146703, train_acc = 0.9919655333022822\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 193, train_loss = 3.9298164593055844, train_acc = 0.9919655333022822\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 194, train_loss = 3.9052070090547204, train_acc = 0.992081974848626\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 195, train_loss = 3.880701328627765, train_acc = 0.992081974848626\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 196, train_loss = 3.856621311046183, train_acc = 0.9921984163949698\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 197, train_loss = 3.832850530743599, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 198, train_loss = 3.809156301431358, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 199, train_loss = 3.7859852770343423, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 200, train_loss = 3.76285879034549, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 201, train_loss = 3.7401160895824432, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 202, train_loss = 3.7176122488453984, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 203, train_loss = 3.6954414285719395, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 204, train_loss = 3.6733172023668885, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 205, train_loss = 3.651704305782914, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 206, train_loss = 3.6300854813307524, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 207, train_loss = 3.6088935723528266, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 208, train_loss = 3.5878908801823854, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 209, train_loss = 3.5671589067205787, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 210, train_loss = 3.546513288281858, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 211, train_loss = 3.526327303610742, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 212, train_loss = 3.5062447609379888, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 213, train_loss = 3.4863513624295592, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 214, train_loss = 3.4667317857965827, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 215, train_loss = 3.447283498942852, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 216, train_loss = 3.4281212352216244, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 217, train_loss = 3.4090937795117497, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 218, train_loss = 3.3903059028089046, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 219, train_loss = 3.3717218451201916, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 220, train_loss = 3.3532984787598252, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 221, train_loss = 3.3351735211908817, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 222, train_loss = 3.317146100103855, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 223, train_loss = 3.299325662665069, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 224, train_loss = 3.281730454415083, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 225, train_loss = 3.264239271171391, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 226, train_loss = 3.247044436633587, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 227, train_loss = 3.2299412032589316, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 228, train_loss = 3.2129883589223027, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 229, train_loss = 3.196336115244776, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 230, train_loss = 3.1797464578412473, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 231, train_loss = 3.1632939926348627, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 232, train_loss = 3.147220662329346, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 233, train_loss = 3.1311314962804317, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 234, train_loss = 3.1150882430374622, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 235, train_loss = 3.099534561857581, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 236, train_loss = 3.0839348868466914, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 237, train_loss = 3.0685021081008017, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 238, train_loss = 3.0532604549080133, train_acc = 0.9934792734047508\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 239, train_loss = 3.0381527822464705, train_acc = 0.9934792734047508\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 240, train_loss = 3.0232232701964676, train_acc = 0.9934792734047508\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 241, train_loss = 3.0083554591983557, train_acc = 0.9935957149510946\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 242, train_loss = 2.9938398730009794, train_acc = 0.9935957149510946\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 243, train_loss = 2.979128906968981, train_acc = 0.9935957149510946\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 244, train_loss = 2.964735396206379, train_acc = 0.9935957149510946\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 245, train_loss = 2.9506755522452295, train_acc = 0.9937121564974383\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 246, train_loss = 2.9365198290906847, train_acc = 0.9939450395901258\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 247, train_loss = 2.9226196273230016, train_acc = 0.9939450395901258\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 248, train_loss = 2.908784778788686, train_acc = 0.9940614811364695\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 249, train_loss = 2.895157571416348, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 250, train_loss = 2.8815727145411074, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 251, train_loss = 2.8682317943312228, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 252, train_loss = 2.8548487494699657, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 253, train_loss = 2.841689081862569, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 254, train_loss = 2.8287675441242754, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 255, train_loss = 2.815822476055473, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 256, train_loss = 2.8031142218969762, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 257, train_loss = 2.7903990116901696, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 258, train_loss = 2.778023441787809, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 259, train_loss = 2.765485368669033, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 260, train_loss = 2.7533680028282106, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 261, train_loss = 2.741147084161639, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 262, train_loss = 2.7292000339366496, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 263, train_loss = 2.7172811166383326, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 264, train_loss = 2.7055823928676546, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 265, train_loss = 2.6937651708722115, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 266, train_loss = 2.682367878034711, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 267, train_loss = 2.6708430401049554, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 268, train_loss = 2.6596885421313345, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 269, train_loss = 2.64836142398417, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 270, train_loss = 2.6373760835267603, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 271, train_loss = 2.6264209747314453, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 272, train_loss = 2.615538897458464, train_acc = 0.994294364229157\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 273, train_loss = 2.6047928538173437, train_acc = 0.9944108057755007\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 274, train_loss = 2.5941518056206405, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 275, train_loss = 2.583518146071583, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 276, train_loss = 2.5732554118148983, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 277, train_loss = 2.5628047683276236, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 278, train_loss = 2.552761769387871, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 279, train_loss = 2.5425215754657984, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 280, train_loss = 2.532563636545092, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 281, train_loss = 2.522674844134599, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 282, train_loss = 2.512766853440553, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 283, train_loss = 2.5030819289386272, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 284, train_loss = 2.4935637074522674, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 285, train_loss = 2.4839233024977148, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 286, train_loss = 2.4745923168957233, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 287, train_loss = 2.4651931021362543, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 288, train_loss = 2.455960191786289, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 289, train_loss = 2.446813880931586, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 290, train_loss = 2.4379079677164555, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 291, train_loss = 2.4287076890468597, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 292, train_loss = 2.4199153599329293, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 293, train_loss = 2.4111757669597864, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 294, train_loss = 2.40250259405002, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 295, train_loss = 2.3937708982266486, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 296, train_loss = 2.3853405811823905, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 297, train_loss = 2.376804381608963, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 298, train_loss = 2.3684685714542866, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 299, train_loss = 2.360247254371643, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 300, train_loss = 2.3520085141062737, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 301, train_loss = 2.343854334205389, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 302, train_loss = 2.3358860574662685, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 303, train_loss = 2.327837459743023, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 304, train_loss = 2.3200035903137177, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 305, train_loss = 2.3120770268142223, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 306, train_loss = 2.304349149344489, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 307, train_loss = 2.296797204762697, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 308, train_loss = 2.2889526572544128, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 309, train_loss = 2.2815839361865073, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 310, train_loss = 2.274091113358736, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 311, train_loss = 2.2666749816853553, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 312, train_loss = 2.2593256670515984, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 313, train_loss = 2.2520860109943897, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 314, train_loss = 2.2449394303839654, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 315, train_loss = 2.2378414932172745, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 316, train_loss = 2.2308030165731907, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 317, train_loss = 2.2238306154031307, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 318, train_loss = 2.217004630714655, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 319, train_loss = 2.2101625353097916, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 320, train_loss = 2.203347969800234, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 321, train_loss = 2.196686428040266, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 322, train_loss = 2.1900169763248414, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 323, train_loss = 2.183432662161067, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 324, train_loss = 2.1769734781701118, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 325, train_loss = 2.1704621438402683, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 326, train_loss = 2.1641111832577735, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 327, train_loss = 2.157805658876896, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 328, train_loss = 2.151401122333482, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 329, train_loss = 2.14519518869929, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 330, train_loss = 2.139151557115838, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 331, train_loss = 2.1329329051077366, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 332, train_loss = 2.127065844833851, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 333, train_loss = 2.1209272295236588, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 334, train_loss = 2.115054405061528, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 335, train_loss = 2.1091661092359573, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 336, train_loss = 2.103321884991601, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 337, train_loss = 2.097505260258913, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 338, train_loss = 2.0918247997760773, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 339, train_loss = 2.086201890138909, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 340, train_loss = 2.0805100202560425, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 341, train_loss = 2.0749681491870433, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 342, train_loss = 2.069433316588402, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 343, train_loss = 2.063926746370271, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 344, train_loss = 2.0585678468924016, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 345, train_loss = 2.0531617638189346, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 346, train_loss = 2.047842025756836, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 347, train_loss = 2.0424650572240353, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 348, train_loss = 2.0372638900298625, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 349, train_loss = 2.0320958718657494, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 350, train_loss = 2.026988911209628, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 351, train_loss = 2.021872166544199, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 352, train_loss = 2.016874163178727, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 353, train_loss = 2.0118224148172885, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 354, train_loss = 2.0069113436620682, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 355, train_loss = 2.0019145731348544, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 356, train_loss = 1.9971995551604778, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 357, train_loss = 1.99227674305439, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 358, train_loss = 1.9875061560887843, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 359, train_loss = 1.9827924605924636, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 360, train_loss = 1.9781368623953313, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 361, train_loss = 1.973415832966566, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 362, train_loss = 1.968749015359208, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 363, train_loss = 1.9642015434801579, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 364, train_loss = 1.9596801947336644, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 365, train_loss = 1.9550743598956615, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 366, train_loss = 1.9506612420082092, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 367, train_loss = 1.9461698941886425, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 368, train_loss = 1.9417360934894532, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 369, train_loss = 1.9373308334033936, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 370, train_loss = 1.9331115770619363, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 371, train_loss = 1.928746412275359, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 372, train_loss = 1.9244769711513072, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 373, train_loss = 1.920249669579789, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 374, train_loss = 1.9160857077222317, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 375, train_loss = 1.9119127057492733, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "24th- epoch: 376, train_loss = 1.9077855225186795, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 377, train_loss = 1.903698842972517, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 378, train_loss = 1.8996097147464752, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 379, train_loss = 1.8955173182766885, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 380, train_loss = 1.8916567265987396, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 381, train_loss = 1.8876803878229111, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 382, train_loss = 1.8837195585947484, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 383, train_loss = 1.8797887600958347, train_acc = 0.995575221238938\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 384, train_loss = 1.8761394943576306, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 385, train_loss = 1.8721533566713333, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 386, train_loss = 1.8683023899793625, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 387, train_loss = 1.8646509174723178, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 388, train_loss = 1.860801324248314, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 389, train_loss = 1.85721817612648, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 390, train_loss = 1.853451669216156, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 391, train_loss = 1.8497590571641922, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 392, train_loss = 1.8460869105765596, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 393, train_loss = 1.8425460383296013, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 394, train_loss = 1.8389756554970518, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 395, train_loss = 1.8354818919906393, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 396, train_loss = 1.831920842290856, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 397, train_loss = 1.8284168988466263, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 398, train_loss = 1.8250109689543024, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 399, train_loss = 1.821518886834383, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 400, train_loss = 1.8182231932878494, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 401, train_loss = 1.8147825909545645, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 402, train_loss = 1.8114500617375597, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 403, train_loss = 1.8081168929347768, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 404, train_loss = 1.8047853956231847, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 405, train_loss = 1.8014560217270628, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 406, train_loss = 1.7983639476587996, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 407, train_loss = 1.7949950223555788, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 408, train_loss = 1.7918986715376377, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 409, train_loss = 1.7886374704539776, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 410, train_loss = 1.7854856736958027, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 411, train_loss = 1.78237944340799, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 412, train_loss = 1.779293067753315, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 413, train_loss = 1.7760950463125482, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 414, train_loss = 1.773097655386664, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 415, train_loss = 1.770033061504364, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 416, train_loss = 1.767032902687788, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 417, train_loss = 1.7641125060617924, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 418, train_loss = 1.761089606792666, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 419, train_loss = 1.758055992424488, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 420, train_loss = 1.7551588887581602, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 421, train_loss = 1.7522950805723667, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 422, train_loss = 1.7494002456078306, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 423, train_loss = 1.7464684074511752, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 424, train_loss = 1.7436285068979487, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 425, train_loss = 1.7409398766467348, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 426, train_loss = 1.7380232587456703, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 427, train_loss = 1.7351978173246607, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 428, train_loss = 1.7323788814246655, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 429, train_loss = 1.72978415095713, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 430, train_loss = 1.7268792478134856, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 431, train_loss = 1.7243415837874636, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 432, train_loss = 1.7215547673404217, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 433, train_loss = 1.718960028141737, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 434, train_loss = 1.716315115452744, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 435, train_loss = 1.7136012749979272, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 436, train_loss = 1.7110226737568155, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 437, train_loss = 1.7084428271045908, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 438, train_loss = 1.7057844983646646, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 439, train_loss = 1.703417887329124, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 440, train_loss = 1.700707377283834, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 441, train_loss = 1.6982615130254999, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 442, train_loss = 1.695618811994791, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 443, train_loss = 1.693289658636786, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 444, train_loss = 1.6907231397926807, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 445, train_loss = 1.6882836496224627, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 446, train_loss = 1.685895969509147, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 447, train_loss = 1.6833986962446943, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 448, train_loss = 1.680968765169382, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 449, train_loss = 1.678699292242527, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 450, train_loss = 1.6761982241878286, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 451, train_loss = 1.6739502648124471, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 452, train_loss = 1.6715296494076028, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 453, train_loss = 1.6692631343612447, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 454, train_loss = 1.666864866972901, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 455, train_loss = 1.664529682486318, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 456, train_loss = 1.6623670980334282, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 457, train_loss = 1.66007984301541, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 458, train_loss = 1.6578036273131147, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 459, train_loss = 1.6555536165833473, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 460, train_loss = 1.6534051907947287, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 461, train_loss = 1.6510793989291415, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 462, train_loss = 1.64888257405255, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 463, train_loss = 1.6468718374380842, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 464, train_loss = 1.6446031307568774, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 465, train_loss = 1.642437300295569, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 466, train_loss = 1.6403081180760637, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 467, train_loss = 1.6382378712296486, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 468, train_loss = 1.636061287135817, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 469, train_loss = 1.6339831911027431, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 470, train_loss = 1.6319124674191698, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 471, train_loss = 1.6298589991638437, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 472, train_loss = 1.6278188960859552, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 473, train_loss = 1.6257175728678703, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 474, train_loss = 1.6237648403039202, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 475, train_loss = 1.6217467611422762, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 476, train_loss = 1.6196512877941132, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 477, train_loss = 1.6177276583621278, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 478, train_loss = 1.6157695638248697, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 479, train_loss = 1.613738783984445, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 480, train_loss = 1.6118992244591936, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 481, train_loss = 1.6099279137561098, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 482, train_loss = 1.6079467721283436, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 483, train_loss = 1.6061088541755453, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 484, train_loss = 1.6041960380971432, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 485, train_loss = 1.6022928357124329, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 486, train_loss = 1.6004239469766617, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 487, train_loss = 1.5985028905561194, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 488, train_loss = 1.5966914097080007, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 489, train_loss = 1.594908078550361, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 490, train_loss = 1.592992290854454, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 491, train_loss = 1.5911630280315876, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 492, train_loss = 1.5894775874912739, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 493, train_loss = 1.587639905512333, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 494, train_loss = 1.5857820311794057, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 495, train_loss = 1.5841229297220707, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 496, train_loss = 1.5822459483752027, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 497, train_loss = 1.5805246904492378, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 498, train_loss = 1.5788479348411784, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "24th- epoch: 499, train_loss = 1.5771276714513078, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████▌              | 24/30 [2:39:26<39:50, 398.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "25th- epoch: 0, train_loss = 271.74858820438385, train_acc = 0.4646017699115044\n",
      "test Acc 0.4930167597765363:\n",
      "25th- epoch: 1, train_loss = 208.97802984714508, train_acc = 0.4983698183511877\n",
      "test Acc 0.4995344506517691:\n",
      "25th- epoch: 2, train_loss = 168.3291267156601, train_acc = 0.5075687005123428\n",
      "test Acc 0.5297951582867784:\n",
      "25th- epoch: 3, train_loss = 146.24063098430634, train_acc = 0.626339077782953\n",
      "test Acc 0.6871508379888268:\n",
      "25th- epoch: 4, train_loss = 127.87817716598511, train_acc = 0.7038891476478808\n",
      "test Acc 0.7295158286778398:\n",
      "25th- epoch: 5, train_loss = 111.50468480587006, train_acc = 0.7526781555659059\n",
      "test Acc 0.7774674115456238:\n",
      "25th- epoch: 6, train_loss = 97.47330597043037, train_acc = 0.7943642291569633\n",
      "test Acc 0.8040037243947858:\n",
      "25th- epoch: 7, train_loss = 85.7675312757492, train_acc = 0.813344201210992\n",
      "test Acc 0.8184357541899442:\n",
      "25th- epoch: 8, train_loss = 76.01066300272942, train_acc = 0.8305775500698649\n",
      "test Acc 0.8412476722532588:\n",
      "25th- epoch: 9, train_loss = 67.88478481769562, train_acc = 0.8550302748020494\n",
      "test Acc 0.8705772811918063:\n",
      "25th- epoch: 10, train_loss = 61.12355759739876, train_acc = 0.8747088961341407\n",
      "test Acc 0.8808193668528864:\n",
      "25th- epoch: 11, train_loss = 55.4901497066021, train_acc = 0.8865859338612017\n",
      "test Acc 0.8915270018621974:\n",
      "25th- epoch: 12, train_loss = 50.78026433289051, train_acc = 0.895668374476013\n",
      "test Acc 0.8961824953445066:\n",
      "25th- epoch: 13, train_loss = 46.79938022792339, train_acc = 0.9052165812761993\n",
      "test Acc 0.9050279329608939:\n",
      "25th- epoch: 14, train_loss = 43.40899038314819, train_acc = 0.9166278528178854\n",
      "test Acc 0.9180633147113594:\n",
      "25th- epoch: 15, train_loss = 40.49681468307972, train_acc = 0.9274569166278528\n",
      "test Acc 0.9250465549348231:\n",
      "25th- epoch: 16, train_loss = 37.97198313474655, train_acc = 0.933977643223102\n",
      "test Acc 0.9352886405959032:\n",
      "25th- epoch: 17, train_loss = 35.77129529416561, train_acc = 0.9387517466231952\n",
      "test Acc 0.9385474860335196:\n",
      "25th- epoch: 18, train_loss = 33.84746906161308, train_acc = 0.9457382394038193\n",
      "test Acc 0.9404096834264432:\n",
      "25th- epoch: 19, train_loss = 32.154326505959034, train_acc = 0.9481835118770378\n",
      "test Acc 0.9418063314711359:\n",
      "25th- epoch: 20, train_loss = 30.656893879175186, train_acc = 0.9499301350721937\n",
      "test Acc 0.9441340782122905:\n",
      "25th- epoch: 21, train_loss = 29.32519042491913, train_acc = 0.951560316721006\n",
      "test Acc 0.9459962756052142:\n",
      "25th- epoch: 22, train_loss = 28.134747497737408, train_acc = 0.952026082906381\n",
      "test Acc 0.9478584729981379:\n",
      "25th- epoch: 23, train_loss = 27.063874930143356, train_acc = 0.9536562645551933\n",
      "test Acc 0.9497206703910615:\n",
      "25th- epoch: 24, train_loss = 26.094871379435062, train_acc = 0.9548206800186306\n",
      "test Acc 0.9497206703910615:\n",
      "25th- epoch: 25, train_loss = 25.21476600319147, train_acc = 0.9563344201210993\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 26, train_loss = 24.41007098555565, train_acc = 0.9570330693991617\n",
      "test Acc 0.9515828677839852:\n",
      "25th- epoch: 27, train_loss = 23.669240564107895, train_acc = 0.9580810433162552\n",
      "test Acc 0.952048417132216:\n",
      "25th- epoch: 28, train_loss = 22.98614802584052, train_acc = 0.9591290172333489\n",
      "test Acc 0.9529795158286778:\n",
      "25th- epoch: 29, train_loss = 22.352919340133667, train_acc = 0.96040987424313\n",
      "test Acc 0.9539106145251397:\n",
      "25th- epoch: 30, train_loss = 21.762664407491684, train_acc = 0.9602934326967862\n",
      "test Acc 0.9548417132216015:\n",
      "25th- epoch: 31, train_loss = 21.210920456796885, train_acc = 0.9609920819748486\n",
      "test Acc 0.9557728119180633:\n",
      "25th- epoch: 32, train_loss = 20.693309754133224, train_acc = 0.9614578481602236\n",
      "test Acc 0.9562383612662942:\n",
      "25th- epoch: 33, train_loss = 20.205414287745953, train_acc = 0.961690731252911\n",
      "test Acc 0.9585661080074488:\n",
      "25th- epoch: 34, train_loss = 19.743755113333464, train_acc = 0.962156497438286\n",
      "test Acc 0.9585661080074488:\n",
      "25th- epoch: 35, train_loss = 19.306423664093018, train_acc = 0.9630880298090359\n",
      "test Acc 0.9590316573556797:\n",
      "25th- epoch: 36, train_loss = 18.890210051089525, train_acc = 0.9636702375407545\n",
      "test Acc 0.9594972067039106:\n",
      "25th- epoch: 37, train_loss = 18.493070390075445, train_acc = 0.9647182114578482\n",
      "test Acc 0.9604283054003724:\n",
      "25th- epoch: 38, train_loss = 18.114499386399984, train_acc = 0.9653004191895669\n",
      "test Acc 0.9608938547486033:\n",
      "25th- epoch: 39, train_loss = 17.752189800143242, train_acc = 0.9658826269212856\n",
      "test Acc 0.9613594040968343:\n",
      "25th- epoch: 40, train_loss = 17.405806727707386, train_acc = 0.9664648346530041\n",
      "test Acc 0.962756052141527:\n",
      "25th- epoch: 41, train_loss = 17.074043944478035, train_acc = 0.9671634839310667\n",
      "test Acc 0.962756052141527:\n",
      "25th- epoch: 42, train_loss = 16.755336064845324, train_acc = 0.9682114578481602\n",
      "test Acc 0.9641527001862198:\n",
      "25th- epoch: 43, train_loss = 16.448914099484682, train_acc = 0.9689101071262226\n",
      "test Acc 0.9641527001862198:\n",
      "25th- epoch: 44, train_loss = 16.154044549912214, train_acc = 0.97007452258966\n",
      "test Acc 0.9646182495344506:\n",
      "25th- epoch: 45, train_loss = 15.870980180799961, train_acc = 0.9704238472286912\n",
      "test Acc 0.9646182495344506:\n",
      "25th- epoch: 46, train_loss = 15.59857938811183, train_acc = 0.9706567303213787\n",
      "test Acc 0.9655493482309124:\n",
      "25th- epoch: 47, train_loss = 15.335957534611225, train_acc = 0.9713553795994411\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 48, train_loss = 15.08182542026043, train_acc = 0.9720540288775035\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 49, train_loss = 14.836454473435879, train_acc = 0.972286911970191\n",
      "test Acc 0.9660148975791434:\n",
      "25th- epoch: 50, train_loss = 14.599378794431686, train_acc = 0.9725197950628784\n",
      "test Acc 0.9669459962756052:\n",
      "25th- epoch: 51, train_loss = 14.36992409452796, train_acc = 0.9726362366092222\n",
      "test Acc 0.9674115456238361:\n",
      "25th- epoch: 52, train_loss = 14.146824065595865, train_acc = 0.9729855612482534\n",
      "test Acc 0.9674115456238361:\n",
      "25th- epoch: 53, train_loss = 13.930238515138626, train_acc = 0.9734513274336283\n",
      "test Acc 0.9674115456238361:\n",
      "25th- epoch: 54, train_loss = 13.719887299463153, train_acc = 0.9736842105263158\n",
      "test Acc 0.9674115456238361:\n",
      "25th- epoch: 55, train_loss = 13.516422729939222, train_acc = 0.9739170936190032\n",
      "test Acc 0.9669459962756052:\n",
      "25th- epoch: 56, train_loss = 13.319820063188672, train_acc = 0.9739170936190032\n",
      "test Acc 0.9669459962756052:\n",
      "25th- epoch: 57, train_loss = 13.129156650975347, train_acc = 0.9743828598043782\n",
      "test Acc 0.9669459962756052:\n",
      "25th- epoch: 58, train_loss = 12.94426704570651, train_acc = 0.9749650675360969\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 59, train_loss = 12.764778949320316, train_acc = 0.975314392175128\n",
      "test Acc 0.9678770949720671:\n",
      "25th- epoch: 60, train_loss = 12.590433148667216, train_acc = 0.9756637168141593\n",
      "test Acc 0.9688081936685289:\n",
      "25th- epoch: 61, train_loss = 12.420939449220896, train_acc = 0.9760130414531905\n",
      "test Acc 0.9692737430167597:\n",
      "25th- epoch: 62, train_loss = 12.25613472983241, train_acc = 0.9761294829995343\n",
      "test Acc 0.9692737430167597:\n",
      "25th- epoch: 63, train_loss = 12.095711510628462, train_acc = 0.9765952491849091\n",
      "test Acc 0.9692737430167597:\n",
      "25th- epoch: 64, train_loss = 11.93961377441883, train_acc = 0.9769445738239404\n",
      "test Acc 0.9692737430167597:\n",
      "25th- epoch: 65, train_loss = 11.787487199530005, train_acc = 0.9770610153702841\n",
      "test Acc 0.9692737430167597:\n",
      "25th- epoch: 66, train_loss = 11.639219541102648, train_acc = 0.9770610153702841\n",
      "test Acc 0.9692737430167597:\n",
      "25th- epoch: 67, train_loss = 11.494627648964524, train_acc = 0.9772938984629715\n",
      "test Acc 0.9692737430167597:\n",
      "25th- epoch: 68, train_loss = 11.353778440505266, train_acc = 0.9777596646483465\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 69, train_loss = 11.216129131615162, train_acc = 0.9778761061946902\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 70, train_loss = 11.08167852833867, train_acc = 0.977992547741034\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 71, train_loss = 10.950314570218325, train_acc = 0.9782254308337215\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 72, train_loss = 10.821977786719799, train_acc = 0.9784583139264089\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 73, train_loss = 10.696580111980438, train_acc = 0.9784583139264089\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 74, train_loss = 10.57378738373518, train_acc = 0.9784583139264089\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 75, train_loss = 10.453824505209923, train_acc = 0.9786911970190965\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 76, train_loss = 10.336480028927326, train_acc = 0.9788076385654402\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 77, train_loss = 10.221676927059889, train_acc = 0.9789240801117839\n",
      "test Acc 0.9702048417132216:\n",
      "25th- epoch: 78, train_loss = 10.109206326305866, train_acc = 0.9789240801117839\n",
      "test Acc 0.9702048417132216:\n",
      "25th- epoch: 79, train_loss = 9.999023973941803, train_acc = 0.9790405216581276\n",
      "test Acc 0.9702048417132216:\n",
      "25th- epoch: 80, train_loss = 9.890943516045809, train_acc = 0.9790405216581276\n",
      "test Acc 0.9702048417132216:\n",
      "25th- epoch: 81, train_loss = 9.785025883466005, train_acc = 0.9790405216581276\n",
      "test Acc 0.9702048417132216:\n",
      "25th- epoch: 82, train_loss = 9.681150656193495, train_acc = 0.9790405216581276\n",
      "test Acc 0.9702048417132216:\n",
      "25th- epoch: 83, train_loss = 9.578954063355923, train_acc = 0.9791569632044713\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 84, train_loss = 9.478843297809362, train_acc = 0.9792734047508151\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 85, train_loss = 9.380520679056644, train_acc = 0.9793898462971589\n",
      "test Acc 0.9697392923649907:\n",
      "25th- epoch: 86, train_loss = 9.28407046943903, train_acc = 0.9796227293898463\n",
      "test Acc 0.9702048417132216:\n",
      "25th- epoch: 87, train_loss = 9.189430259168148, train_acc = 0.97973917093619\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 88, train_loss = 9.0962716601789, train_acc = 0.97973917093619\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 89, train_loss = 9.004663981497288, train_acc = 0.9799720540288775\n",
      "test Acc 0.9711359404096834:\n",
      "25th- epoch: 90, train_loss = 8.914660047739744, train_acc = 0.980204937121565\n",
      "test Acc 0.9711359404096834:\n",
      "25th- epoch: 91, train_loss = 8.825966941192746, train_acc = 0.9803213786679087\n",
      "test Acc 0.9716014897579144:\n",
      "25th- epoch: 92, train_loss = 8.738792775198817, train_acc = 0.98067070330694\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 93, train_loss = 8.653142340481281, train_acc = 0.9809035863996274\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 94, train_loss = 8.568601885810494, train_acc = 0.9814857941313461\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 95, train_loss = 8.485652927309275, train_acc = 0.9816022356776898\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 96, train_loss = 8.403907161206007, train_acc = 0.981951560316721\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 97, train_loss = 8.323534425348043, train_acc = 0.9823008849557522\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 98, train_loss = 8.244181031361222, train_acc = 0.9824173265020959\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 99, train_loss = 8.165951615199447, train_acc = 0.9824173265020959\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 100, train_loss = 8.088913213461637, train_acc = 0.9828830926874709\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 101, train_loss = 8.012708885595202, train_acc = 0.9829995342338146\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 102, train_loss = 7.937737785279751, train_acc = 0.9833488588728458\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 103, train_loss = 7.86369882337749, train_acc = 0.9835817419655333\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 104, train_loss = 7.790858408436179, train_acc = 0.983698183511877\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 105, train_loss = 7.718996608629823, train_acc = 0.9840475081509082\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 106, train_loss = 7.648090351372957, train_acc = 0.9840475081509082\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 107, train_loss = 7.57809697650373, train_acc = 0.984163949697252\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 108, train_loss = 7.508821938186884, train_acc = 0.9842803912435957\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 109, train_loss = 7.440761113539338, train_acc = 0.9842803912435957\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 110, train_loss = 7.373910542577505, train_acc = 0.9843968327899395\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 111, train_loss = 7.30788709782064, train_acc = 0.9846297158826269\n",
      "test Acc 0.9739292364990689:\n",
      "25th- epoch: 112, train_loss = 7.242892540991306, train_acc = 0.9846297158826269\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 113, train_loss = 7.178698914125562, train_acc = 0.9848625989753144\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 114, train_loss = 7.115292580798268, train_acc = 0.9849790405216581\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 115, train_loss = 7.0528259091079235, train_acc = 0.9855612482533768\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 116, train_loss = 6.991264404729009, train_acc = 0.9856776897997206\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 117, train_loss = 6.930408837273717, train_acc = 0.985910572892408\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 118, train_loss = 6.870380522683263, train_acc = 0.9862598975314392\n",
      "test Acc 0.972998137802607:\n",
      "25th- epoch: 119, train_loss = 6.8110883589833975, train_acc = 0.9864927806241267\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 120, train_loss = 6.752544455230236, train_acc = 0.9866092221704704\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 121, train_loss = 6.694785341620445, train_acc = 0.9866092221704704\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 122, train_loss = 6.637857474386692, train_acc = 0.9868421052631579\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 123, train_loss = 6.581515170633793, train_acc = 0.9870749883558454\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 124, train_loss = 6.525903647765517, train_acc = 0.9871914299021891\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 125, train_loss = 6.4709267150610685, train_acc = 0.9871914299021891\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 126, train_loss = 6.4168174639344215, train_acc = 0.9874243129948765\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 127, train_loss = 6.36327763274312, train_acc = 0.9875407545412203\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 128, train_loss = 6.310451861470938, train_acc = 0.9875407545412203\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 129, train_loss = 6.258264467120171, train_acc = 0.9876571960875641\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 130, train_loss = 6.20681769028306, train_acc = 0.9876571960875641\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 131, train_loss = 6.155698407441378, train_acc = 0.9877736376339078\n",
      "test Acc 0.973463687150838:\n",
      "25th- epoch: 132, train_loss = 6.105479668825865, train_acc = 0.9877736376339078\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 133, train_loss = 6.055615155026317, train_acc = 0.9878900791802515\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 134, train_loss = 6.006491582840681, train_acc = 0.9880065207265952\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 135, train_loss = 5.95810804516077, train_acc = 0.9880065207265952\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 136, train_loss = 5.9102783016860485, train_acc = 0.9880065207265952\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 137, train_loss = 5.863126687705517, train_acc = 0.9881229622729389\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 138, train_loss = 5.816613407805562, train_acc = 0.9882394038192828\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 139, train_loss = 5.7707885801792145, train_acc = 0.9882394038192828\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 140, train_loss = 5.725117051973939, train_acc = 0.9882394038192828\n",
      "test Acc 0.9748603351955307:\n",
      "25th- epoch: 141, train_loss = 5.6803110502660275, train_acc = 0.9883558453656265\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 142, train_loss = 5.635944873094559, train_acc = 0.9885887284583139\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 143, train_loss = 5.592218371108174, train_acc = 0.9885887284583139\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 144, train_loss = 5.549085730686784, train_acc = 0.9888216115510013\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 145, train_loss = 5.506474386900663, train_acc = 0.9889380530973452\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 146, train_loss = 5.4643082190304995, train_acc = 0.9891709361900326\n",
      "test Acc 0.9753258845437617:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 147, train_loss = 5.422796191647649, train_acc = 0.9891709361900326\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 148, train_loss = 5.381727814674377, train_acc = 0.9892873777363763\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 149, train_loss = 5.341168146580458, train_acc = 0.9892873777363763\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 150, train_loss = 5.301121221855283, train_acc = 0.9892873777363763\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 151, train_loss = 5.26144687179476, train_acc = 0.9892873777363763\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 152, train_loss = 5.222408444620669, train_acc = 0.9892873777363763\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 153, train_loss = 5.183732503093779, train_acc = 0.9892873777363763\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 154, train_loss = 5.145485931076109, train_acc = 0.9895202608290639\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 155, train_loss = 5.107822082936764, train_acc = 0.9895202608290639\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 156, train_loss = 5.070531499572098, train_acc = 0.9895202608290639\n",
      "test Acc 0.9762569832402235:\n",
      "25th- epoch: 157, train_loss = 5.033903541974723, train_acc = 0.9895202608290639\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 158, train_loss = 4.997638564556837, train_acc = 0.9895202608290639\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 159, train_loss = 4.961753627285361, train_acc = 0.9897531439217513\n",
      "test Acc 0.9771880819366853:\n",
      "25th- epoch: 160, train_loss = 4.926517211832106, train_acc = 0.989869585468095\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 161, train_loss = 4.891525765880942, train_acc = 0.9899860270144387\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 162, train_loss = 4.856947145424783, train_acc = 0.9902189101071263\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 163, train_loss = 4.822793356142938, train_acc = 0.99033535165347\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 164, train_loss = 4.788893601857126, train_acc = 0.9904517931998137\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 165, train_loss = 4.755467160604894, train_acc = 0.9904517931998137\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 166, train_loss = 4.722455834038556, train_acc = 0.9904517931998137\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 167, train_loss = 4.68965850956738, train_acc = 0.9905682347461574\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 168, train_loss = 4.657152630388737, train_acc = 0.9905682347461574\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 169, train_loss = 4.62543045822531, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 170, train_loss = 4.593890220858157, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 171, train_loss = 4.562977046705782, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 172, train_loss = 4.532109667547047, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 173, train_loss = 4.5014785612002015, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 174, train_loss = 4.471282006241381, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 175, train_loss = 4.4416472520679235, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 176, train_loss = 4.412531088106334, train_acc = 0.9911504424778761\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 177, train_loss = 4.383960324339569, train_acc = 0.9912668840242198\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 178, train_loss = 4.355585896410048, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 179, train_loss = 4.327622310258448, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 180, train_loss = 4.299777834676206, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 181, train_loss = 4.27256287727505, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 182, train_loss = 4.245493207126856, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 183, train_loss = 4.2189515782520175, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 184, train_loss = 4.19252002146095, train_acc = 0.9914997671169073\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 185, train_loss = 4.166396842338145, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 186, train_loss = 4.1406513703987, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 187, train_loss = 4.115272646769881, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 188, train_loss = 4.090083885006607, train_acc = 0.9917326502095948\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 189, train_loss = 4.065166388638318, train_acc = 0.9918490917559385\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 190, train_loss = 4.040542318485677, train_acc = 0.9918490917559385\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 191, train_loss = 4.016243320889771, train_acc = 0.9918490917559385\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 192, train_loss = 3.992330583743751, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 193, train_loss = 3.968416458927095, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 194, train_loss = 3.945019306614995, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 195, train_loss = 3.9217448150739074, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 196, train_loss = 3.898806937970221, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 197, train_loss = 3.8760949885472655, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 198, train_loss = 3.853649413213134, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 199, train_loss = 3.8314089654013515, train_acc = 0.9921984163949698\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 200, train_loss = 3.809470080770552, train_acc = 0.9921984163949698\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 201, train_loss = 3.7876536026597023, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 202, train_loss = 3.7662471001967788, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 203, train_loss = 3.7449476728215814, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 204, train_loss = 3.7239457070827484, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 205, train_loss = 3.7030350165441632, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 206, train_loss = 3.682408378459513, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 207, train_loss = 3.6619950430467725, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 208, train_loss = 3.641681930050254, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 209, train_loss = 3.621762073133141, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 210, train_loss = 3.601996444631368, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 211, train_loss = 3.5823308513499796, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 212, train_loss = 3.563128673005849, train_acc = 0.9925477410340009\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 213, train_loss = 3.5438963123597205, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 214, train_loss = 3.5248244553804398, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 215, train_loss = 3.5061593730933964, train_acc = 0.9926641825803446\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 216, train_loss = 3.4875548388808966, train_acc = 0.9927806241266884\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 217, train_loss = 3.4692182070575655, train_acc = 0.9928970656730322\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 218, train_loss = 3.45099656842649, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 219, train_loss = 3.432937240228057, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 220, train_loss = 3.415174105670303, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 221, train_loss = 3.3974788771010935, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 222, train_loss = 3.3800065428949893, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 223, train_loss = 3.3627459802664816, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 224, train_loss = 3.345555340871215, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 225, train_loss = 3.328629599418491, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 226, train_loss = 3.31174805900082, train_acc = 0.9931299487657196\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 227, train_loss = 3.2950727217830718, train_acc = 0.9931299487657196\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 228, train_loss = 3.2786418460309505, train_acc = 0.9931299487657196\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 229, train_loss = 3.2622323743999004, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 230, train_loss = 3.2460820921696723, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 231, train_loss = 3.229949743952602, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 232, train_loss = 3.214181264396757, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 233, train_loss = 3.1983464043587446, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 234, train_loss = 3.1827493850141764, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 235, train_loss = 3.1672921292483807, train_acc = 0.9933628318584071\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 236, train_loss = 3.151923051569611, train_acc = 0.9937121564974383\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 237, train_loss = 3.1367419264279306, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 238, train_loss = 3.121700835879892, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 239, train_loss = 3.1067977882921696, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 240, train_loss = 3.0918386639095843, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 241, train_loss = 3.0772484447807074, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 242, train_loss = 3.0625991853885353, train_acc = 0.993828598043782\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 243, train_loss = 3.0481971432454884, train_acc = 0.993828598043782\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 244, train_loss = 3.033753791823983, train_acc = 0.993828598043782\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 245, train_loss = 3.0195292835123837, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 246, train_loss = 3.0054755159653723, train_acc = 0.9939450395901258\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 247, train_loss = 2.9915926069952548, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 248, train_loss = 2.977767776697874, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 249, train_loss = 2.9640143220312893, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 250, train_loss = 2.950543179642409, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 251, train_loss = 2.937101378571242, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 252, train_loss = 2.9237107788212597, train_acc = 0.9941779226828132\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 253, train_loss = 2.9105674107559025, train_acc = 0.9941779226828132\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 254, train_loss = 2.897412004414946, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 255, train_loss = 2.8844593721441925, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 256, train_loss = 2.871618479024619, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 257, train_loss = 2.858852215576917, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 258, train_loss = 2.8462499384768307, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 259, train_loss = 2.833768176380545, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 260, train_loss = 2.821204525884241, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 261, train_loss = 2.8090762407518923, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 262, train_loss = 2.7968752742744982, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 263, train_loss = 2.784745112527162, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 264, train_loss = 2.7727820896543562, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 265, train_loss = 2.760884278919548, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 266, train_loss = 2.7492377194575965, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 267, train_loss = 2.737651349976659, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 268, train_loss = 2.7260500960983336, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 269, train_loss = 2.71481221774593, train_acc = 0.9944108057755007\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 270, train_loss = 2.7034450373612344, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 271, train_loss = 2.69222254678607, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 272, train_loss = 2.681148688774556, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 273, train_loss = 2.670133044477552, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 274, train_loss = 2.659267685841769, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 275, train_loss = 2.6483377809636295, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 276, train_loss = 2.6376624051481485, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 277, train_loss = 2.627015318721533, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 278, train_loss = 2.616478921379894, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 279, train_loss = 2.606031782925129, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 280, train_loss = 2.5957119949162006, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 281, train_loss = 2.58556138118729, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 282, train_loss = 2.5752488202415407, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 283, train_loss = 2.5651692296378314, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 284, train_loss = 2.555191097315401, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 285, train_loss = 2.5452828486450016, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 286, train_loss = 2.5354950297623873, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 287, train_loss = 2.525721636135131, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 288, train_loss = 2.51609089365229, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 289, train_loss = 2.506558586610481, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 290, train_loss = 2.497098373947665, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 291, train_loss = 2.487741455435753, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 292, train_loss = 2.478400783613324, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 293, train_loss = 2.4692615289241076, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 294, train_loss = 2.460249437019229, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 295, train_loss = 2.4511742256581783, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 296, train_loss = 2.4421393293887377, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 297, train_loss = 2.4334268867969513, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 298, train_loss = 2.424560182960704, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 299, train_loss = 2.41593049839139, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 300, train_loss = 2.4072872966062278, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 301, train_loss = 2.398787821410224, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 302, train_loss = 2.3903348967432976, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 303, train_loss = 2.3819274331908673, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 304, train_loss = 2.373651448637247, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 305, train_loss = 2.3653540443629026, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 306, train_loss = 2.3573446080554277, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 307, train_loss = 2.3491833738517016, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 308, train_loss = 2.3412154123652726, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 309, train_loss = 2.333373526809737, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 310, train_loss = 2.325504545122385, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 311, train_loss = 2.3176833253819495, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 312, train_loss = 2.310002477839589, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 313, train_loss = 2.302358102751896, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 314, train_loss = 2.2948658782988787, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 315, train_loss = 2.2873369362205267, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 316, train_loss = 2.2798962623346597, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 317, train_loss = 2.2725850455462933, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 318, train_loss = 2.2653440341819078, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 319, train_loss = 2.258082414744422, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 320, train_loss = 2.250980995595455, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 321, train_loss = 2.243872795952484, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 322, train_loss = 2.2368977579753846, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 323, train_loss = 2.229938131989911, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 324, train_loss = 2.223109868587926, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 325, train_loss = 2.21620662137866, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 326, train_loss = 2.2095119927544147, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 327, train_loss = 2.202744676498696, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 328, train_loss = 2.1961913716513664, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 329, train_loss = 2.189416355220601, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 330, train_loss = 2.183009388623759, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 331, train_loss = 2.176535915583372, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 332, train_loss = 2.170235353289172, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 333, train_loss = 2.1637812678236514, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 334, train_loss = 2.15765721607022, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 335, train_loss = 2.151389679638669, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 336, train_loss = 2.145250202389434, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 337, train_loss = 2.139128550887108, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 338, train_loss = 2.133061531931162, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 339, train_loss = 2.127113697351888, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 340, train_loss = 2.1211630788166076, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 341, train_loss = 2.1153512981254607, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 342, train_loss = 2.109487413195893, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 343, train_loss = 2.103715109406039, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 344, train_loss = 2.097981699509546, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 345, train_loss = 2.092300595715642, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 346, train_loss = 2.0867276682984084, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 347, train_loss = 2.081180054694414, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 348, train_loss = 2.075640660477802, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 349, train_loss = 2.0700827830005437, train_acc = 0.9951094550535631\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 350, train_loss = 2.0646571603138, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 351, train_loss = 2.05932926828973, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 352, train_loss = 2.0539696768391877, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 353, train_loss = 2.048678335500881, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 354, train_loss = 2.0433850705157965, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 355, train_loss = 2.0383040488231927, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 356, train_loss = 2.033079569460824, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 357, train_loss = 2.027975657954812, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 358, train_loss = 2.0229837503284216, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 359, train_loss = 2.0179441508371383, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 360, train_loss = 2.0129732470959425, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 361, train_loss = 2.00799061357975, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 362, train_loss = 2.00318310293369, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 363, train_loss = 1.9984125953633338, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 364, train_loss = 1.9934680461883545, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 365, train_loss = 1.9887309446930885, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 366, train_loss = 1.9839634310919791, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 367, train_loss = 1.9793171435594559, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 368, train_loss = 1.9746439319569618, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 369, train_loss = 1.970021791756153, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 370, train_loss = 1.9655036192853004, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 371, train_loss = 1.9609788979869336, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 372, train_loss = 1.9564420592505485, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 373, train_loss = 1.9519772070925683, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 374, train_loss = 1.9475461703259498, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 375, train_loss = 1.943190858932212, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 376, train_loss = 1.9388099287170917, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 377, train_loss = 1.9345434803981334, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 378, train_loss = 1.930287116440013, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 379, train_loss = 1.9259384796023369, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 380, train_loss = 1.9218234196305275, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 381, train_loss = 1.9175758709898219, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 382, train_loss = 1.9133910374948755, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 383, train_loss = 1.9093682281672955, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 384, train_loss = 1.9053588783135638, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 385, train_loss = 1.9012035802006721, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 386, train_loss = 1.8972852242877707, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 387, train_loss = 1.8933274311712012, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 388, train_loss = 1.8892728002974764, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 389, train_loss = 1.8854800326516852, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 390, train_loss = 1.8815107457339764, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 391, train_loss = 1.8776788748800755, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 392, train_loss = 1.8739382786443457, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 393, train_loss = 1.8700957037508488, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 394, train_loss = 1.8663288181414828, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 395, train_loss = 1.8625494688749313, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 396, train_loss = 1.8589426539838314, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 397, train_loss = 1.8552854284644127, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 398, train_loss = 1.8516076356172562, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 399, train_loss = 1.8479351848363876, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 400, train_loss = 1.8444601247319952, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 401, train_loss = 1.8408159712562338, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 402, train_loss = 1.837298821657896, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 403, train_loss = 1.8337662828853354, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 404, train_loss = 1.8303908668458462, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 405, train_loss = 1.8268761187791824, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 406, train_loss = 1.8234678009757772, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 407, train_loss = 1.8200911780586466, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 408, train_loss = 1.816716299741529, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 409, train_loss = 1.8133341682842001, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 410, train_loss = 1.8100683080265298, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 411, train_loss = 1.8067730454495177, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 412, train_loss = 1.8034656792879105, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 413, train_loss = 1.8002534011611715, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 414, train_loss = 1.7969828670611605, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 415, train_loss = 1.7938253469765186, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 416, train_loss = 1.7905925773084164, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 417, train_loss = 1.7875102820107713, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 418, train_loss = 1.784322970896028, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 419, train_loss = 1.781300500035286, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 420, train_loss = 1.7781797721982002, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 421, train_loss = 1.7751235775649548, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 422, train_loss = 1.7720373222837225, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 423, train_loss = 1.769043163745664, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 424, train_loss = 1.7661204388132319, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 425, train_loss = 1.7630311759421602, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 426, train_loss = 1.760101123363711, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 427, train_loss = 1.7571552383014932, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 428, train_loss = 1.754311390221119, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 429, train_loss = 1.7513961555669084, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 430, train_loss = 1.7485299967229366, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 431, train_loss = 1.7456524384906515, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 432, train_loss = 1.7428955821087584, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 433, train_loss = 1.740024404018186, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 434, train_loss = 1.737207024008967, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 435, train_loss = 1.7344461269676685, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 436, train_loss = 1.7317312931409106, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 437, train_loss = 1.7289488291135058, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 438, train_loss = 1.7263502962887287, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 439, train_loss = 1.7236078394344077, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 440, train_loss = 1.7209929762175307, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 441, train_loss = 1.7181631028652191, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 442, train_loss = 1.7154236374190077, train_acc = 0.9958081043316255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 443, train_loss = 1.7127931205322966, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 444, train_loss = 1.7101003663847223, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 445, train_loss = 1.7075472921133041, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 446, train_loss = 1.705092349438928, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 447, train_loss = 1.7024739956250414, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 448, train_loss = 1.6999214192619547, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 449, train_loss = 1.6975101107964292, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 450, train_loss = 1.6949148898711428, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 451, train_loss = 1.6924006342887878, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 452, train_loss = 1.6899149877717718, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 453, train_loss = 1.6875503174960613, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 454, train_loss = 1.6851175738265738, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 455, train_loss = 1.682695416151546, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 456, train_loss = 1.6802459694445133, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 457, train_loss = 1.6778787039220333, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 458, train_loss = 1.6755375303328037, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 459, train_loss = 1.673283806652762, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 460, train_loss = 1.6707336431136355, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 461, train_loss = 1.6686096849152818, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 462, train_loss = 1.6662823235383257, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 463, train_loss = 1.6639723615953699, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 464, train_loss = 1.6616406179964542, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 465, train_loss = 1.6595158515265211, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 466, train_loss = 1.6572404293110594, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 467, train_loss = 1.6550373075297102, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 468, train_loss = 1.6527548817684874, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 469, train_loss = 1.65065899991896, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 470, train_loss = 1.6483772061765194, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 471, train_loss = 1.6462301313877106, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 472, train_loss = 1.6441297270357609, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 473, train_loss = 1.6419157398631796, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 474, train_loss = 1.6398146586725488, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 475, train_loss = 1.637729729176499, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 476, train_loss = 1.6356136599788442, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 477, train_loss = 1.633548287092708, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 478, train_loss = 1.6315075220772997, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 479, train_loss = 1.6294684981694445, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 480, train_loss = 1.6273582068970427, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 481, train_loss = 1.6252545701572672, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 482, train_loss = 1.6233174987137318, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 483, train_loss = 1.6212694756686687, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 484, train_loss = 1.6193211463978514, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 485, train_loss = 1.6174348344793543, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 486, train_loss = 1.6153173918137327, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 487, train_loss = 1.6134277718374506, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 488, train_loss = 1.6113929426064715, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 489, train_loss = 1.6094790560309775, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 490, train_loss = 1.6074590546195395, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 491, train_loss = 1.6056187090580352, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 492, train_loss = 1.6037817734177224, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 493, train_loss = 1.601721088110935, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 494, train_loss = 1.600013988732826, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 495, train_loss = 1.598115415603388, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 496, train_loss = 1.5961981962318532, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 497, train_loss = 1.5943647908861749, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 498, train_loss = 1.5925569621031173, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 499, train_loss = 1.5906950496137142, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████            | 25/30 [2:46:08<33:17, 399.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "26th- epoch: 0, train_loss = 268.70909106731415, train_acc = 0.4767116907312529\n",
      "test Acc 0.48463687150837986:\n",
      "26th- epoch: 1, train_loss = 206.4332436323166, train_acc = 0.49324639031206335\n",
      "test Acc 0.49813780260707635:\n",
      "26th- epoch: 2, train_loss = 169.1033902168274, train_acc = 0.5062878435025617\n",
      "test Acc 0.5256052141527002:\n",
      "26th- epoch: 3, train_loss = 146.68869137763977, train_acc = 0.6199347927340475\n",
      "test Acc 0.6890130353817505:\n",
      "26th- epoch: 4, train_loss = 128.7498933672905, train_acc = 0.7041220307405682\n",
      "test Acc 0.7318435754189944:\n",
      "26th- epoch: 5, train_loss = 112.76524704694748, train_acc = 0.7434792734047508\n",
      "test Acc 0.7732774674115456:\n",
      "26th- epoch: 6, train_loss = 98.77051019668579, train_acc = 0.7873777363763391\n",
      "test Acc 0.8007448789571695:\n",
      "26th- epoch: 7, train_loss = 86.85505858063698, train_acc = 0.8157894736842105\n",
      "test Acc 0.8202979515828678:\n",
      "26th- epoch: 8, train_loss = 76.75961682200432, train_acc = 0.8374476013041453\n",
      "test Acc 0.845437616387337:\n",
      "26th- epoch: 9, train_loss = 68.24825158715248, train_acc = 0.8613181183046111\n",
      "test Acc 0.87243947858473:\n",
      "26th- epoch: 10, train_loss = 61.122150897979736, train_acc = 0.8826269212855147\n",
      "test Acc 0.8868715083798883:\n",
      "26th- epoch: 11, train_loss = 55.188393861055374, train_acc = 0.8922915696320447\n",
      "test Acc 0.8938547486033519:\n",
      "26th- epoch: 12, train_loss = 50.26314088702202, train_acc = 0.9042850489054495\n",
      "test Acc 0.9106145251396648:\n",
      "26th- epoch: 13, train_loss = 46.17482830584049, train_acc = 0.9179087098276665\n",
      "test Acc 0.9208566108007449:\n",
      "26th- epoch: 14, train_loss = 42.75211498141289, train_acc = 0.9281555659059152\n",
      "test Acc 0.9301675977653632:\n",
      "26th- epoch: 15, train_loss = 39.85257941484451, train_acc = 0.933977643223102\n",
      "test Acc 0.9324953445065177:\n",
      "26th- epoch: 16, train_loss = 37.37998056411743, train_acc = 0.9375873311597578\n",
      "test Acc 0.9352886405959032:\n",
      "26th- epoch: 17, train_loss = 35.24473126232624, train_acc = 0.9408476944573824\n",
      "test Acc 0.9380819366852886:\n",
      "26th- epoch: 18, train_loss = 33.38451685011387, train_acc = 0.9422449930135072\n",
      "test Acc 0.9394785847299814:\n",
      "26th- epoch: 19, train_loss = 31.753957375884056, train_acc = 0.9443409408476945\n",
      "test Acc 0.9413407821229051:\n",
      "26th- epoch: 20, train_loss = 30.313082717359066, train_acc = 0.946786213320913\n",
      "test Acc 0.9427374301675978:\n",
      "26th- epoch: 21, train_loss = 29.031759470701218, train_acc = 0.9501630181648812\n",
      "test Acc 0.9450651769087524:\n",
      "26th- epoch: 22, train_loss = 27.884917497634888, train_acc = 0.951560316721006\n",
      "test Acc 0.9478584729981379:\n",
      "26th- epoch: 23, train_loss = 26.850056923925877, train_acc = 0.9530740568234746\n",
      "test Acc 0.9487895716945997:\n",
      "26th- epoch: 24, train_loss = 25.90990173071623, train_acc = 0.9543549138332557\n",
      "test Acc 0.9506517690875232:\n",
      "26th- epoch: 25, train_loss = 25.050737537443638, train_acc = 0.955519329296693\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 26, train_loss = 24.26166144758463, train_acc = 0.9563344201210993\n",
      "test Acc 0.9529795158286778:\n",
      "26th- epoch: 27, train_loss = 23.533012121915817, train_acc = 0.9578481602235678\n",
      "test Acc 0.9539106145251397:\n",
      "26th- epoch: 28, train_loss = 22.857563227415085, train_acc = 0.9591290172333489\n",
      "test Acc 0.9548417132216015:\n",
      "26th- epoch: 29, train_loss = 22.229676458984613, train_acc = 0.9608756404285049\n",
      "test Acc 0.9553072625698324:\n",
      "26th- epoch: 30, train_loss = 21.644085094332695, train_acc = 0.9620400558919422\n",
      "test Acc 0.9553072625698324:\n",
      "26th- epoch: 31, train_loss = 21.095698188990355, train_acc = 0.9622729389846297\n",
      "test Acc 0.9567039106145251:\n",
      "26th- epoch: 32, train_loss = 20.57978782057762, train_acc = 0.9626222636236609\n",
      "test Acc 0.957169459962756:\n",
      "26th- epoch: 33, train_loss = 20.09379293397069, train_acc = 0.9630880298090359\n",
      "test Acc 0.957635009310987:\n",
      "26th- epoch: 34, train_loss = 19.635276556015015, train_acc = 0.9636702375407545\n",
      "test Acc 0.9581005586592178:\n",
      "26th- epoch: 35, train_loss = 19.201274767518044, train_acc = 0.9640195621797858\n",
      "test Acc 0.9585661080074488:\n",
      "26th- epoch: 36, train_loss = 18.788994327187538, train_acc = 0.9648346530041919\n",
      "test Acc 0.9585661080074488:\n",
      "26th- epoch: 37, train_loss = 18.396475858986378, train_acc = 0.9654168607359106\n",
      "test Acc 0.9590316573556797:\n",
      "26th- epoch: 38, train_loss = 18.022111885249615, train_acc = 0.9664648346530041\n",
      "test Acc 0.9590316573556797:\n",
      "26th- epoch: 39, train_loss = 17.66414688900113, train_acc = 0.9670470423847228\n",
      "test Acc 0.9599627560521415:\n",
      "26th- epoch: 40, train_loss = 17.321578536182642, train_acc = 0.9672799254774104\n",
      "test Acc 0.9599627560521415:\n",
      "26th- epoch: 41, train_loss = 16.993651773780584, train_acc = 0.9678621332091291\n",
      "test Acc 0.9604283054003724:\n",
      "26th- epoch: 42, train_loss = 16.67907540127635, train_acc = 0.9683278993945039\n",
      "test Acc 0.9608938547486033:\n",
      "26th- epoch: 43, train_loss = 16.376385129988194, train_acc = 0.9684443409408477\n",
      "test Acc 0.9608938547486033:\n",
      "26th- epoch: 44, train_loss = 16.08567987382412, train_acc = 0.9693758733115976\n",
      "test Acc 0.9613594040968343:\n",
      "26th- epoch: 45, train_loss = 15.807412080466747, train_acc = 0.9694923148579413\n",
      "test Acc 0.9618249534450651:\n",
      "26th- epoch: 46, train_loss = 15.539871480315924, train_acc = 0.9703074056823474\n",
      "test Acc 0.9622905027932961:\n",
      "26th- epoch: 47, train_loss = 15.282319240272045, train_acc = 0.970540288775035\n",
      "test Acc 0.9632216014897579:\n",
      "26th- epoch: 48, train_loss = 15.034082973375916, train_acc = 0.9708896134140661\n",
      "test Acc 0.9636871508379888:\n",
      "26th- epoch: 49, train_loss = 14.794357454404235, train_acc = 0.9714718211457848\n",
      "test Acc 0.9641527001862198:\n",
      "26th- epoch: 50, train_loss = 14.5630576685071, train_acc = 0.971821145784816\n",
      "test Acc 0.9641527001862198:\n",
      "26th- epoch: 51, train_loss = 14.339584369212389, train_acc = 0.9724033535165347\n",
      "test Acc 0.9641527001862198:\n",
      "26th- epoch: 52, train_loss = 14.12380701676011, train_acc = 0.9726362366092222\n",
      "test Acc 0.9646182495344506:\n",
      "26th- epoch: 53, train_loss = 13.915035776793957, train_acc = 0.9731020027945971\n",
      "test Acc 0.9655493482309124:\n",
      "26th- epoch: 54, train_loss = 13.712885104119778, train_acc = 0.9733348858872846\n",
      "test Acc 0.9660148975791434:\n",
      "26th- epoch: 55, train_loss = 13.517281007021666, train_acc = 0.9734513274336283\n",
      "test Acc 0.9674115456238361:\n",
      "26th- epoch: 56, train_loss = 13.327572759240866, train_acc = 0.9741499767116907\n",
      "test Acc 0.9674115456238361:\n",
      "26th- epoch: 57, train_loss = 13.143677219748497, train_acc = 0.9741499767116907\n",
      "test Acc 0.9674115456238361:\n",
      "26th- epoch: 58, train_loss = 12.965049553662539, train_acc = 0.9744993013507219\n",
      "test Acc 0.9669459962756052:\n",
      "26th- epoch: 59, train_loss = 12.791760314255953, train_acc = 0.9748486259897532\n",
      "test Acc 0.9669459962756052:\n",
      "26th- epoch: 60, train_loss = 12.623318266123533, train_acc = 0.975314392175128\n",
      "test Acc 0.9669459962756052:\n",
      "26th- epoch: 61, train_loss = 12.459639582782984, train_acc = 0.9756637168141593\n",
      "test Acc 0.9664804469273743:\n",
      "26th- epoch: 62, train_loss = 12.300377380102873, train_acc = 0.9761294829995343\n",
      "test Acc 0.9664804469273743:\n",
      "26th- epoch: 63, train_loss = 12.145474877208471, train_acc = 0.9764788076385654\n",
      "test Acc 0.9669459962756052:\n",
      "26th- epoch: 64, train_loss = 11.994497265666723, train_acc = 0.9768281322775967\n",
      "test Acc 0.9674115456238361:\n",
      "26th- epoch: 65, train_loss = 11.847169935703278, train_acc = 0.9770610153702841\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 66, train_loss = 11.703546199947596, train_acc = 0.9770610153702841\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 67, train_loss = 11.563071314245462, train_acc = 0.9774103400093154\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 68, train_loss = 11.425512578338385, train_acc = 0.9774103400093154\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 69, train_loss = 11.291135013103485, train_acc = 0.9775267815556591\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 70, train_loss = 11.159775167703629, train_acc = 0.9776432231020028\n",
      "test Acc 0.9678770949720671:\n",
      "26th- epoch: 71, train_loss = 11.031265631318092, train_acc = 0.9777596646483465\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 72, train_loss = 10.905358685180545, train_acc = 0.977992547741034\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 73, train_loss = 10.781855897977948, train_acc = 0.977992547741034\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 74, train_loss = 10.661039980128407, train_acc = 0.9781089892873778\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 75, train_loss = 10.542635340243578, train_acc = 0.9784583139264089\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 76, train_loss = 10.426361806690693, train_acc = 0.9784583139264089\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 77, train_loss = 10.312334453687072, train_acc = 0.9783418723800652\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 78, train_loss = 10.200801631435752, train_acc = 0.9784583139264089\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 79, train_loss = 10.091890998184681, train_acc = 0.9785747554727526\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 80, train_loss = 9.984721560031176, train_acc = 0.9788076385654402\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 81, train_loss = 9.879680110141635, train_acc = 0.9788076385654402\n",
      "test Acc 0.9683426443202979:\n",
      "26th- epoch: 82, train_loss = 9.776268364861608, train_acc = 0.9788076385654402\n",
      "test Acc 0.9688081936685289:\n",
      "26th- epoch: 83, train_loss = 9.674786925315857, train_acc = 0.9788076385654402\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 84, train_loss = 9.574918480589986, train_acc = 0.9788076385654402\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 85, train_loss = 9.476607587188482, train_acc = 0.9791569632044713\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 86, train_loss = 9.379895459860563, train_acc = 0.9793898462971589\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 87, train_loss = 9.285067033022642, train_acc = 0.97973917093619\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 88, train_loss = 9.191556990146637, train_acc = 0.9798556124825337\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 89, train_loss = 9.099700294435024, train_acc = 0.9799720540288775\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 90, train_loss = 9.009179282933474, train_acc = 0.9804378202142524\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 91, train_loss = 8.920100461691618, train_acc = 0.98067070330694\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 92, train_loss = 8.832525871694088, train_acc = 0.98067070330694\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 93, train_loss = 8.746437955647707, train_acc = 0.9811364694923148\n",
      "test Acc 0.9692737430167597:\n",
      "26th- epoch: 94, train_loss = 8.661564335227013, train_acc = 0.9812529110386586\n",
      "test Acc 0.9697392923649907:\n",
      "26th- epoch: 95, train_loss = 8.578133307397366, train_acc = 0.9814857941313461\n",
      "test Acc 0.9697392923649907:\n",
      "26th- epoch: 96, train_loss = 8.495795730501413, train_acc = 0.9814857941313461\n",
      "test Acc 0.9697392923649907:\n",
      "26th- epoch: 97, train_loss = 8.414773127064109, train_acc = 0.9814857941313461\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 98, train_loss = 8.334684688597918, train_acc = 0.9817186772240335\n",
      "test Acc 0.9706703910614525:\n",
      "26th- epoch: 99, train_loss = 8.256014257669449, train_acc = 0.9820680018630648\n",
      "test Acc 0.9706703910614525:\n",
      "26th- epoch: 100, train_loss = 8.178153868764639, train_acc = 0.9823008849557522\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 101, train_loss = 8.101446928456426, train_acc = 0.9826502095947834\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 102, train_loss = 8.025866417214274, train_acc = 0.9831159757801584\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 103, train_loss = 7.95137906447053, train_acc = 0.9833488588728458\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 104, train_loss = 7.877831598743796, train_acc = 0.9833488588728458\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 105, train_loss = 7.8055366817861795, train_acc = 0.9833488588728458\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 106, train_loss = 7.733949098736048, train_acc = 0.9838146250582208\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 107, train_loss = 7.6634962279349566, train_acc = 0.9839310666045645\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 108, train_loss = 7.594080206006765, train_acc = 0.9839310666045645\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 109, train_loss = 7.525483071804047, train_acc = 0.9839310666045645\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 110, train_loss = 7.457899862900376, train_acc = 0.9839310666045645\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 111, train_loss = 7.3911636415869, train_acc = 0.984163949697252\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 112, train_loss = 7.325240610167384, train_acc = 0.9843968327899395\n",
      "test Acc 0.9725325884543762:\n",
      "26th- epoch: 113, train_loss = 7.260304694995284, train_acc = 0.9848625989753144\n",
      "test Acc 0.9725325884543762:\n",
      "26th- epoch: 114, train_loss = 7.196035670116544, train_acc = 0.9850954820680019\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 115, train_loss = 7.132667638361454, train_acc = 0.9850954820680019\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 116, train_loss = 7.070100549608469, train_acc = 0.9850954820680019\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 117, train_loss = 7.008345078676939, train_acc = 0.9852119236143456\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 118, train_loss = 6.947298577055335, train_acc = 0.9853283651606893\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 119, train_loss = 6.887238087132573, train_acc = 0.985444806707033\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 120, train_loss = 6.827615300193429, train_acc = 0.9855612482533768\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 121, train_loss = 6.768510164692998, train_acc = 0.9856776897997206\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 122, train_loss = 6.710308086127043, train_acc = 0.9855612482533768\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 123, train_loss = 6.652937898412347, train_acc = 0.9856776897997206\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 124, train_loss = 6.596260955557227, train_acc = 0.9857941313460643\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 125, train_loss = 6.540274003520608, train_acc = 0.9860270144387517\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 126, train_loss = 6.485217796638608, train_acc = 0.9862598975314392\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 127, train_loss = 6.430717039853334, train_acc = 0.9864927806241267\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 128, train_loss = 6.376942202448845, train_acc = 0.9866092221704704\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 129, train_loss = 6.323877384886146, train_acc = 0.9868421052631579\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 130, train_loss = 6.271481366828084, train_acc = 0.9870749883558454\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 131, train_loss = 6.2197686191648245, train_acc = 0.9873078714485328\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 132, train_loss = 6.168634634464979, train_acc = 0.9875407545412203\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 133, train_loss = 6.11822016723454, train_acc = 0.9876571960875641\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 134, train_loss = 6.068406220525503, train_acc = 0.9880065207265952\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 135, train_loss = 6.019226796925068, train_acc = 0.9881229622729389\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 136, train_loss = 5.970569491386414, train_acc = 0.9882394038192828\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 137, train_loss = 5.922714751213789, train_acc = 0.9883558453656265\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 138, train_loss = 5.875355705618858, train_acc = 0.9883558453656265\n",
      "test Acc 0.9743947858472998:\n",
      "26th- epoch: 139, train_loss = 5.828608429059386, train_acc = 0.9883558453656265\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 140, train_loss = 5.782392326742411, train_acc = 0.9887051700046576\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 141, train_loss = 5.7363256476819515, train_acc = 0.9887051700046576\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 142, train_loss = 5.690828621387482, train_acc = 0.9888216115510013\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 143, train_loss = 5.645619917660952, train_acc = 0.9890544946436889\n",
      "test Acc 0.9757914338919925:\n",
      "26th- epoch: 144, train_loss = 5.601371072232723, train_acc = 0.9890544946436889\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 145, train_loss = 5.557770514860749, train_acc = 0.9891709361900326\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 146, train_loss = 5.514562886208296, train_acc = 0.98940381928272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 147, train_loss = 5.47217077575624, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 148, train_loss = 5.430084876716137, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 149, train_loss = 5.388659778982401, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 150, train_loss = 5.347775993868709, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 151, train_loss = 5.307319967076182, train_acc = 0.9895202608290639\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 152, train_loss = 5.267356352880597, train_acc = 0.9897531439217513\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 153, train_loss = 5.227918453514576, train_acc = 0.9899860270144387\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 154, train_loss = 5.1888387482613325, train_acc = 0.9899860270144387\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 155, train_loss = 5.150466741994023, train_acc = 0.9899860270144387\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 156, train_loss = 5.112429333850741, train_acc = 0.9901024685607824\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 157, train_loss = 5.074761152267456, train_acc = 0.9902189101071263\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 158, train_loss = 5.037716441787779, train_acc = 0.9905682347461574\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 159, train_loss = 5.000908495858312, train_acc = 0.9905682347461574\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 160, train_loss = 4.9647426614537835, train_acc = 0.9905682347461574\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 161, train_loss = 4.928920017555356, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 162, train_loss = 4.893489238806069, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 163, train_loss = 4.8585200840607285, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 164, train_loss = 4.823799580335617, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 165, train_loss = 4.78958320710808, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 166, train_loss = 4.755622231401503, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 167, train_loss = 4.722323823720217, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 168, train_loss = 4.689395154826343, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 169, train_loss = 4.656871813349426, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 170, train_loss = 4.624804281629622, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 171, train_loss = 4.59313743468374, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 172, train_loss = 4.561747335828841, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 173, train_loss = 4.5308777540922165, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 174, train_loss = 4.500118027441204, train_acc = 0.9910340009315324\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 175, train_loss = 4.469922134652734, train_acc = 0.9910340009315324\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 176, train_loss = 4.439949298277497, train_acc = 0.9910340009315324\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 177, train_loss = 4.410465666092932, train_acc = 0.9911504424778761\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 178, train_loss = 4.3812290811911225, train_acc = 0.9911504424778761\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 179, train_loss = 4.352312525734305, train_acc = 0.9912668840242198\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 180, train_loss = 4.323903154581785, train_acc = 0.9912668840242198\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 181, train_loss = 4.295735412277281, train_acc = 0.9913833255705635\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 182, train_loss = 4.268090594559908, train_acc = 0.9914997671169073\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 183, train_loss = 4.24060136359185, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 184, train_loss = 4.213422280736268, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 185, train_loss = 4.186652936041355, train_acc = 0.9916162086632511\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 186, train_loss = 4.16017403639853, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 187, train_loss = 4.133945025503635, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 188, train_loss = 4.107953552156687, train_acc = 0.9916162086632511\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 189, train_loss = 4.08254826720804, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 190, train_loss = 4.057108060456812, train_acc = 0.9919655333022822\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 191, train_loss = 4.032182241789997, train_acc = 0.992081974848626\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 192, train_loss = 4.007348923943937, train_acc = 0.992081974848626\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 193, train_loss = 3.9830525731667876, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 194, train_loss = 3.958819292485714, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 195, train_loss = 3.934922461397946, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 196, train_loss = 3.911324892193079, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 197, train_loss = 3.887929491698742, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 198, train_loss = 3.864765147678554, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 199, train_loss = 3.842043124139309, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 200, train_loss = 3.819398485124111, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 201, train_loss = 3.7970077209174633, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 202, train_loss = 3.7748263655230403, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 203, train_loss = 3.7528840033337474, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 204, train_loss = 3.731260374188423, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 205, train_loss = 3.709782782010734, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 206, train_loss = 3.6885816790163517, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 207, train_loss = 3.6678557889536023, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 208, train_loss = 3.6470829844474792, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 209, train_loss = 3.6266260631382465, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 210, train_loss = 3.606422039680183, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 211, train_loss = 3.586460590362549, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 212, train_loss = 3.5666018947958946, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 213, train_loss = 3.546925944276154, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 214, train_loss = 3.5276838215067983, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 215, train_loss = 3.508453750051558, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 216, train_loss = 3.4893956081941724, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 217, train_loss = 3.47067369800061, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 218, train_loss = 3.4520433517172933, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 219, train_loss = 3.4336002273485065, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 220, train_loss = 3.415404972154647, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 221, train_loss = 3.3974223234690726, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 222, train_loss = 3.3795298226177692, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 223, train_loss = 3.3617584803141654, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 224, train_loss = 3.344275880139321, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 225, train_loss = 3.3268429189920425, train_acc = 0.9930135072193759\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 226, train_loss = 3.3097203210927546, train_acc = 0.9930135072193759\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 227, train_loss = 3.2926984881050885, train_acc = 0.9930135072193759\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 228, train_loss = 3.275882503017783, train_acc = 0.9930135072193759\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 229, train_loss = 3.259341310709715, train_acc = 0.9931299487657196\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 230, train_loss = 3.242813365533948, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 231, train_loss = 3.226496641058475, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 232, train_loss = 3.2102736649103463, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 233, train_loss = 3.194388649892062, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 234, train_loss = 3.1785021387040615, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 235, train_loss = 3.162843876052648, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 236, train_loss = 3.1472424189560115, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 237, train_loss = 3.1318587376736104, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 238, train_loss = 3.1165551035664976, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 239, train_loss = 3.101450625807047, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 240, train_loss = 3.0864599705673754, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 241, train_loss = 3.0717591238208115, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 242, train_loss = 3.0570360929705203, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 243, train_loss = 3.0423350944183767, train_acc = 0.9939450395901258\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 244, train_loss = 3.0279922201298177, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 245, train_loss = 3.0137128699570894, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 246, train_loss = 2.999530777800828, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 247, train_loss = 2.985545300412923, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 248, train_loss = 2.9715909995138645, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 249, train_loss = 2.957944216672331, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 250, train_loss = 2.9440734111703932, train_acc = 0.9940614811364695\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 251, train_loss = 2.9307111240923405, train_acc = 0.9940614811364695\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 252, train_loss = 2.9171667881309986, train_acc = 0.9940614811364695\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 253, train_loss = 2.903979750815779, train_acc = 0.9940614811364695\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 254, train_loss = 2.8907594201155007, train_acc = 0.9941779226828132\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 255, train_loss = 2.877640327438712, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 256, train_loss = 2.864677230361849, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 257, train_loss = 2.8517507375217974, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 258, train_loss = 2.8389103026129305, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 259, train_loss = 2.8263315432704985, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 260, train_loss = 2.8139062989503145, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 261, train_loss = 2.801535958889872, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 262, train_loss = 2.789367212448269, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 263, train_loss = 2.777086147572845, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 264, train_loss = 2.7651918530464172, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 265, train_loss = 2.753351213876158, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 266, train_loss = 2.741472386289388, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 267, train_loss = 2.7297744317911565, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 268, train_loss = 2.718249420169741, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 269, train_loss = 2.7068371451459825, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 270, train_loss = 2.6954204314388335, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 271, train_loss = 2.6842396990396082, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 272, train_loss = 2.6730043566785753, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 273, train_loss = 2.662044660653919, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 274, train_loss = 2.650975981261581, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 275, train_loss = 2.6400976427830756, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 276, train_loss = 2.6294295848347247, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 277, train_loss = 2.6187603124417365, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 278, train_loss = 2.6082257591187954, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 279, train_loss = 2.597712951246649, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "26th- epoch: 280, train_loss = 2.5873824693262577, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 281, train_loss = 2.5771310492418706, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 282, train_loss = 2.5669725239276886, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 283, train_loss = 2.5568855479359627, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 284, train_loss = 2.5469037145376205, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 285, train_loss = 2.537042391952127, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 286, train_loss = 2.5271893427707255, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 287, train_loss = 2.5175174809992313, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 288, train_loss = 2.5078872814774513, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 289, train_loss = 2.4983793385326862, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 290, train_loss = 2.488970669452101, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 291, train_loss = 2.4795410498045385, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 292, train_loss = 2.4702648841775954, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 293, train_loss = 2.4610843807458878, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 294, train_loss = 2.451989032328129, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 295, train_loss = 2.4429410956799984, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 296, train_loss = 2.4340453767217696, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 297, train_loss = 2.4251399622298777, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 298, train_loss = 2.4164449186064303, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 299, train_loss = 2.407744915690273, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 300, train_loss = 2.399200710002333, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 301, train_loss = 2.3906640731729567, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 302, train_loss = 2.3822212170343846, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 303, train_loss = 2.3739326696377248, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 304, train_loss = 2.365636332659051, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 305, train_loss = 2.357425105990842, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 306, train_loss = 2.3493995431344956, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 307, train_loss = 2.341289597330615, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 308, train_loss = 2.3334098395425826, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 309, train_loss = 2.3255029905121773, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 310, train_loss = 2.317688559414819, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 311, train_loss = 2.3099742468912154, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 312, train_loss = 2.3023390148300678, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 313, train_loss = 2.2946832354646176, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 314, train_loss = 2.287283832905814, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 315, train_loss = 2.27980500459671, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 316, train_loss = 2.2725404414813966, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 317, train_loss = 2.26509549212642, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 318, train_loss = 2.257902279496193, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 319, train_loss = 2.250813140301034, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 320, train_loss = 2.243694635806605, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 321, train_loss = 2.236605618149042, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 322, train_loss = 2.229757896391675, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 323, train_loss = 2.2227500949520618, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 324, train_loss = 2.2160926025826484, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 325, train_loss = 2.2091189932543784, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 326, train_loss = 2.202538972022012, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 327, train_loss = 2.1957183133345097, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 328, train_loss = 2.18927260232158, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 329, train_loss = 2.18268949422054, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 330, train_loss = 2.1762528095860034, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 331, train_loss = 2.169858604669571, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 332, train_loss = 2.1634922462981194, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 333, train_loss = 2.157251115888357, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 334, train_loss = 2.151053720386699, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 335, train_loss = 2.14475234108977, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 336, train_loss = 2.138780067441985, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 337, train_loss = 2.132679345784709, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 338, train_loss = 2.126756440848112, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 339, train_loss = 2.1207273590844125, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 340, train_loss = 2.114844435127452, train_acc = 0.9948765719608756\n",
      "test Acc 0.9795158286778398:\n",
      "26th- epoch: 341, train_loss = 2.109119259985164, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 342, train_loss = 2.103233886184171, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 343, train_loss = 2.0975535076577216, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 344, train_loss = 2.091868783114478, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 345, train_loss = 2.086270745843649, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 346, train_loss = 2.080733350245282, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 347, train_loss = 2.075129710137844, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 348, train_loss = 2.069716352969408, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 349, train_loss = 2.0642836827319115, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 350, train_loss = 2.0588377614039928, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 351, train_loss = 2.0535234846174717, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 352, train_loss = 2.048277856083587, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 353, train_loss = 2.0431110933423042, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 354, train_loss = 2.0378153000492603, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 355, train_loss = 2.0327182088512927, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 356, train_loss = 2.0275917772669345, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 357, train_loss = 2.02257568272762, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 358, train_loss = 2.0175233259797096, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 359, train_loss = 2.0125628386158496, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 360, train_loss = 2.0076949186623096, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 361, train_loss = 2.0027202602941543, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 362, train_loss = 1.997959990054369, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 363, train_loss = 1.9931172530632466, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 364, train_loss = 1.9884376537520438, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 365, train_loss = 1.9836598213296384, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 366, train_loss = 1.9790050648152828, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 367, train_loss = 1.9743458789307624, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 368, train_loss = 1.9697390894871205, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 369, train_loss = 1.9652280795853585, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 370, train_loss = 1.9605288046877831, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 371, train_loss = 1.95613569393754, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 372, train_loss = 1.9516746948938817, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 373, train_loss = 1.9472377859055996, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 374, train_loss = 1.9428751729428768, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 375, train_loss = 1.9384716227650642, train_acc = 0.995575221238938\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 376, train_loss = 1.9341537815053016, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 377, train_loss = 1.9299745101016015, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 378, train_loss = 1.9256058011669666, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 379, train_loss = 1.92143040522933, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 380, train_loss = 1.9172780711669475, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 381, train_loss = 1.9131224874872714, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 382, train_loss = 1.9091156993526965, train_acc = 0.9956916627852818\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 383, train_loss = 1.9049262553453445, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 384, train_loss = 1.9009533512871712, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 385, train_loss = 1.8969063994009048, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 386, train_loss = 1.892955542774871, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 387, train_loss = 1.8890357539057732, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 388, train_loss = 1.885021603317, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 389, train_loss = 1.881267361342907, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 390, train_loss = 1.877339361817576, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 391, train_loss = 1.873626579879783, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 392, train_loss = 1.8698170147836208, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 393, train_loss = 1.8660541623830795, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 394, train_loss = 1.8623857609927654, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 395, train_loss = 1.858619018108584, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 396, train_loss = 1.8550010733306408, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 397, train_loss = 1.851298164576292, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 398, train_loss = 1.8477731583407149, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 399, train_loss = 1.8441773107042536, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 400, train_loss = 1.8405623883008957, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 401, train_loss = 1.8370498804142699, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 402, train_loss = 1.8334825312485918, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 403, train_loss = 1.8300549276173115, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 404, train_loss = 1.8265531348297372, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 405, train_loss = 1.8232127452502027, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 406, train_loss = 1.8197338344762102, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 407, train_loss = 1.8164053050568327, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 408, train_loss = 1.8130371806910262, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 409, train_loss = 1.8097791621694341, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 410, train_loss = 1.8063120258739218, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 411, train_loss = 1.80318506679032, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 412, train_loss = 1.7998176204273477, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 413, train_loss = 1.796579897403717, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 414, train_loss = 1.7934902036795393, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 415, train_loss = 1.7901833765208721, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 416, train_loss = 1.7870052742073312, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 417, train_loss = 1.7839487852761522, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 418, train_loss = 1.7807896869489923, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 419, train_loss = 1.7776448366930708, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 420, train_loss = 1.7746094899484888, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 421, train_loss = 1.7715321443974972, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 422, train_loss = 1.76847420015838, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 423, train_loss = 1.7655203776666895, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 424, train_loss = 1.7624723190674558, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 425, train_loss = 1.7595786675810814, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 426, train_loss = 1.756655047298409, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 427, train_loss = 1.7536359193036333, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 428, train_loss = 1.7509011290967464, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 429, train_loss = 1.7479211514582857, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 430, train_loss = 1.7451118727913126, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 431, train_loss = 1.7422316310694441, train_acc = 0.9958081043316255\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 432, train_loss = 1.7394230663776398, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 433, train_loss = 1.7367102255811915, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 434, train_loss = 1.7338580811629072, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 435, train_loss = 1.731095913797617, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 436, train_loss = 1.7284009829163551, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 437, train_loss = 1.7255731088807806, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 438, train_loss = 1.7229720106115565, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 439, train_loss = 1.7203042221954092, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 440, train_loss = 1.7176893291762099, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 441, train_loss = 1.7149998508393764, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 442, train_loss = 1.7124416468432173, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 443, train_loss = 1.7097632425138727, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 444, train_loss = 1.7072206860175356, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 445, train_loss = 1.7046399203827605, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 446, train_loss = 1.7020594576606527, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 447, train_loss = 1.6996526879956946, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 448, train_loss = 1.6970137059688568, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 449, train_loss = 1.6944677209248766, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 450, train_loss = 1.6921324282884598, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 451, train_loss = 1.689634686917998, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 452, train_loss = 1.6872795535018668, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 453, train_loss = 1.6847147172084078, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 454, train_loss = 1.6823835484683514, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 455, train_loss = 1.6800069523742422, train_acc = 0.9958081043316255\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 456, train_loss = 1.6775492578744888, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 457, train_loss = 1.6752714390167966, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 458, train_loss = 1.6728848355123773, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 459, train_loss = 1.6705796296009794, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 460, train_loss = 1.668257205397822, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 461, train_loss = 1.665924284607172, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 462, train_loss = 1.6636955564608797, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 463, train_loss = 1.6613886766135693, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 464, train_loss = 1.6591060807695612, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 465, train_loss = 1.6569410985102877, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 466, train_loss = 1.6546787396073341, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 467, train_loss = 1.6525032967329025, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 468, train_loss = 1.6502460911870003, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 469, train_loss = 1.6481164917349815, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 470, train_loss = 1.6459245259175077, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 471, train_loss = 1.6437394581735134, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 472, train_loss = 1.6416768146445975, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 473, train_loss = 1.6395201893756166, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 474, train_loss = 1.6374200197169557, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 475, train_loss = 1.6353506421437487, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 476, train_loss = 1.6332927445182577, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 477, train_loss = 1.6311919937143102, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 478, train_loss = 1.6291905617108569, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 479, train_loss = 1.6270528361201286, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 480, train_loss = 1.6250830305507407, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 481, train_loss = 1.623073935508728, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 482, train_loss = 1.6211095489561558, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 483, train_loss = 1.6190687343478203, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 484, train_loss = 1.617119237780571, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 485, train_loss = 1.6151010356843472, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 486, train_loss = 1.6131977500626817, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 487, train_loss = 1.6111866297433153, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 488, train_loss = 1.6094022653996944, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 489, train_loss = 1.607378724962473, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 490, train_loss = 1.6055120477685705, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 491, train_loss = 1.6037399681517854, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 492, train_loss = 1.601748594432138, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 493, train_loss = 1.5999108800897375, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 494, train_loss = 1.5980990851530805, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 495, train_loss = 1.5961701100459322, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 496, train_loss = 1.5944231040775776, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 497, train_loss = 1.5925628158147447, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 498, train_loss = 1.590782307088375, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n",
      "26th- epoch: 499, train_loss = 1.589014099270571, train_acc = 0.9959245458779693\n",
      "test Acc 0.9799813780260708:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|██████████████████████████████████████████████████████████████▍         | 26/30 [2:52:46<26:36, 399.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "27th- epoch: 0, train_loss = 272.27817618846893, train_acc = 0.44993013507219376\n",
      "test Acc 0.5111731843575419:\n",
      "27th- epoch: 1, train_loss = 214.04088628292084, train_acc = 0.49406148113646947\n",
      "test Acc 0.5032588454376163:\n",
      "27th- epoch: 2, train_loss = 173.27848941087723, train_acc = 0.5192128551467163\n",
      "test Acc 0.5498137802607076:\n",
      "27th- epoch: 3, train_loss = 149.23352497816086, train_acc = 0.6142291569632045\n",
      "test Acc 0.696927374301676:\n",
      "27th- epoch: 4, train_loss = 129.97974461317062, train_acc = 0.7063344201210993\n",
      "test Acc 0.7239292364990689:\n",
      "27th- epoch: 5, train_loss = 112.911452293396, train_acc = 0.7426641825803446\n",
      "test Acc 0.7690875232774674:\n",
      "27th- epoch: 6, train_loss = 98.35509765148163, train_acc = 0.7870284117373079\n",
      "test Acc 0.792830540037244:\n",
      "27th- epoch: 7, train_loss = 86.3096733391285, train_acc = 0.8077550069864928\n",
      "test Acc 0.8133147113594041:\n",
      "27th- epoch: 8, train_loss = 76.37240156531334, train_acc = 0.8319748486259898\n",
      "test Acc 0.8445065176908753:\n",
      "27th- epoch: 9, train_loss = 68.14315748214722, train_acc = 0.8631811830461108\n",
      "test Acc 0.8719739292364991:\n",
      "27th- epoch: 10, train_loss = 61.30299863219261, train_acc = 0.8756404285048905\n",
      "test Acc 0.8817504655493482:\n",
      "27th- epoch: 11, train_loss = 55.601482912898064, train_acc = 0.8861201676758267\n",
      "test Acc 0.888733705772812:\n",
      "27th- epoch: 12, train_loss = 50.844166561961174, train_acc = 0.8960176991150443\n",
      "test Acc 0.8994413407821229:\n",
      "27th- epoch: 13, train_loss = 46.852357283234596, train_acc = 0.9067303213786679\n",
      "test Acc 0.9134078212290503:\n",
      "27th- epoch: 14, train_loss = 43.47452090680599, train_acc = 0.9209361900326036\n",
      "test Acc 0.9273743016759777:\n",
      "27th- epoch: 15, train_loss = 40.5852510035038, train_acc = 0.9280391243595715\n",
      "test Acc 0.9315642458100558:\n",
      "27th- epoch: 16, train_loss = 38.09326292574406, train_acc = 0.9318816953889147\n",
      "test Acc 0.9329608938547486:\n",
      "27th- epoch: 17, train_loss = 35.92522835731506, train_acc = 0.9343269678621332\n",
      "test Acc 0.9404096834264432:\n",
      "27th- epoch: 18, train_loss = 34.027079954743385, train_acc = 0.9422449930135072\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 19, train_loss = 32.35571217536926, train_acc = 0.9446902654867256\n",
      "test Acc 0.9432029795158287:\n",
      "27th- epoch: 20, train_loss = 30.873624235391617, train_acc = 0.9466697717745691\n",
      "test Acc 0.9436685288640596:\n",
      "27th- epoch: 21, train_loss = 29.55626403540373, train_acc = 0.9481835118770378\n",
      "test Acc 0.9445996275605214:\n",
      "27th- epoch: 22, train_loss = 28.37786664813757, train_acc = 0.9493479273404751\n",
      "test Acc 0.946927374301676:\n",
      "27th- epoch: 23, train_loss = 27.31781231611967, train_acc = 0.9499301350721937\n",
      "test Acc 0.9501862197392924:\n",
      "27th- epoch: 24, train_loss = 26.357232183218002, train_acc = 0.9517931998136935\n",
      "test Acc 0.952513966480447:\n",
      "27th- epoch: 25, train_loss = 25.48206853121519, train_acc = 0.9527247321844434\n",
      "test Acc 0.9539106145251397:\n",
      "27th- epoch: 26, train_loss = 24.682668156921864, train_acc = 0.9554028877503493\n",
      "test Acc 0.9543761638733705:\n",
      "27th- epoch: 27, train_loss = 23.948568239808083, train_acc = 0.9566837447601304\n",
      "test Acc 0.9562383612662942:\n",
      "27th- epoch: 28, train_loss = 23.272419571876526, train_acc = 0.9579646017699115\n",
      "test Acc 0.957169459962756:\n",
      "27th- epoch: 29, train_loss = 22.645464282482862, train_acc = 0.9588961341406614\n",
      "test Acc 0.957635009310987:\n",
      "27th- epoch: 30, train_loss = 22.0613218434155, train_acc = 0.95947834187238\n",
      "test Acc 0.9581005586592178:\n",
      "27th- epoch: 31, train_loss = 21.514597196131945, train_acc = 0.959944108057755\n",
      "test Acc 0.957635009310987:\n",
      "27th- epoch: 32, train_loss = 21.001615580171347, train_acc = 0.9602934326967862\n",
      "test Acc 0.957635009310987:\n",
      "27th- epoch: 33, train_loss = 20.519196663051844, train_acc = 0.9608756404285049\n",
      "test Acc 0.9581005586592178:\n",
      "27th- epoch: 34, train_loss = 20.063666824251413, train_acc = 0.9620400558919422\n",
      "test Acc 0.9590316573556797:\n",
      "27th- epoch: 35, train_loss = 19.632374055683613, train_acc = 0.9627387051700047\n",
      "test Acc 0.9594972067039106:\n",
      "27th- epoch: 36, train_loss = 19.22310784831643, train_acc = 0.9632044713553796\n",
      "test Acc 0.9594972067039106:\n",
      "27th- epoch: 37, train_loss = 18.833639718592167, train_acc = 0.9641360037261295\n",
      "test Acc 0.9599627560521415:\n",
      "27th- epoch: 38, train_loss = 18.462693087756634, train_acc = 0.9649510945505356\n",
      "test Acc 0.9618249534450651:\n",
      "27th- epoch: 39, train_loss = 18.108205195516348, train_acc = 0.9650675360968793\n",
      "test Acc 0.9622905027932961:\n",
      "27th- epoch: 40, train_loss = 17.769070327281952, train_acc = 0.9662319515603167\n",
      "test Acc 0.9632216014897579:\n",
      "27th- epoch: 41, train_loss = 17.44441094622016, train_acc = 0.9671634839310667\n",
      "test Acc 0.9632216014897579:\n",
      "27th- epoch: 42, train_loss = 17.13309644535184, train_acc = 0.9678621332091291\n",
      "test Acc 0.9632216014897579:\n",
      "27th- epoch: 43, train_loss = 16.834186527878046, train_acc = 0.9686772240335352\n",
      "test Acc 0.9632216014897579:\n",
      "27th- epoch: 44, train_loss = 16.546414718031883, train_acc = 0.9694923148579413\n",
      "test Acc 0.9632216014897579:\n",
      "27th- epoch: 45, train_loss = 16.26895710080862, train_acc = 0.9697251979506288\n",
      "test Acc 0.9636871508379888:\n",
      "27th- epoch: 46, train_loss = 16.00183865055442, train_acc = 0.9704238472286912\n",
      "test Acc 0.9646182495344506:\n",
      "27th- epoch: 47, train_loss = 15.74361690506339, train_acc = 0.9706567303213787\n",
      "test Acc 0.9655493482309124:\n",
      "27th- epoch: 48, train_loss = 15.493778347969055, train_acc = 0.9712389380530974\n",
      "test Acc 0.9669459962756052:\n",
      "27th- epoch: 49, train_loss = 15.252034544944763, train_acc = 0.9714718211457848\n",
      "test Acc 0.9674115456238361:\n",
      "27th- epoch: 50, train_loss = 15.018166579306126, train_acc = 0.9719375873311598\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 51, train_loss = 14.791645355522633, train_acc = 0.972286911970191\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 52, train_loss = 14.572026336565614, train_acc = 0.9724033535165347\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 53, train_loss = 14.359357938170433, train_acc = 0.9725197950628784\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 54, train_loss = 14.152749601751566, train_acc = 0.9727526781555659\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 55, train_loss = 13.952284201979637, train_acc = 0.9732184443409408\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 56, train_loss = 13.75786118581891, train_acc = 0.9732184443409408\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 57, train_loss = 13.568604361265898, train_acc = 0.9734513274336283\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 58, train_loss = 13.38443873077631, train_acc = 0.974033535165347\n",
      "test Acc 0.9678770949720671:\n",
      "27th- epoch: 59, train_loss = 13.203947253525257, train_acc = 0.974033535165347\n",
      "test Acc 0.9678770949720671:\n",
      "27th- epoch: 60, train_loss = 13.029280986636877, train_acc = 0.974033535165347\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 61, train_loss = 12.859963305294514, train_acc = 0.9741499767116907\n",
      "test Acc 0.9683426443202979:\n",
      "27th- epoch: 62, train_loss = 12.69499708339572, train_acc = 0.9744993013507219\n",
      "test Acc 0.9688081936685289:\n",
      "27th- epoch: 63, train_loss = 12.534181009978056, train_acc = 0.9747321844434094\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 64, train_loss = 12.377122100442648, train_acc = 0.9750815090824406\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 65, train_loss = 12.223844699561596, train_acc = 0.9751979506287843\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 66, train_loss = 12.074031967669725, train_acc = 0.9754308337214718\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 67, train_loss = 11.927805617451668, train_acc = 0.975780158360503\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 68, train_loss = 11.784971680492163, train_acc = 0.976245924545878\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 69, train_loss = 11.645674655213952, train_acc = 0.9763623660922217\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 70, train_loss = 11.509498737752438, train_acc = 0.9765952491849091\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 71, train_loss = 11.37647520378232, train_acc = 0.9770610153702841\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 72, train_loss = 11.246334047988057, train_acc = 0.9772938984629715\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 73, train_loss = 11.118914915248752, train_acc = 0.9774103400093154\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 74, train_loss = 10.994231386110187, train_acc = 0.9775267815556591\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 75, train_loss = 10.872039061039686, train_acc = 0.9776432231020028\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 76, train_loss = 10.752148173749447, train_acc = 0.9778761061946902\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 77, train_loss = 10.634441662579775, train_acc = 0.977992547741034\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 78, train_loss = 10.51925389841199, train_acc = 0.9781089892873778\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 79, train_loss = 10.406280491501093, train_acc = 0.9782254308337215\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 80, train_loss = 10.295552458614111, train_acc = 0.9781089892873778\n",
      "test Acc 0.9688081936685289:\n",
      "27th- epoch: 81, train_loss = 10.186826102435589, train_acc = 0.9783418723800652\n",
      "test Acc 0.9688081936685289:\n",
      "27th- epoch: 82, train_loss = 10.080035898834467, train_acc = 0.9785747554727526\n",
      "test Acc 0.9688081936685289:\n",
      "27th- epoch: 83, train_loss = 9.975049413740635, train_acc = 0.9788076385654402\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 84, train_loss = 9.871991109102964, train_acc = 0.9788076385654402\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 85, train_loss = 9.770620699971914, train_acc = 0.9789240801117839\n",
      "test Acc 0.9697392923649907:\n",
      "27th- epoch: 86, train_loss = 9.67088896036148, train_acc = 0.9789240801117839\n",
      "test Acc 0.9702048417132216:\n",
      "27th- epoch: 87, train_loss = 9.572844050824642, train_acc = 0.9790405216581276\n",
      "test Acc 0.9702048417132216:\n",
      "27th- epoch: 88, train_loss = 9.476248547434807, train_acc = 0.9791569632044713\n",
      "test Acc 0.9702048417132216:\n",
      "27th- epoch: 89, train_loss = 9.38138510659337, train_acc = 0.9791569632044713\n",
      "test Acc 0.9706703910614525:\n",
      "27th- epoch: 90, train_loss = 9.287843201309443, train_acc = 0.9791569632044713\n",
      "test Acc 0.9706703910614525:\n",
      "27th- epoch: 91, train_loss = 9.196117836982012, train_acc = 0.9791569632044713\n",
      "test Acc 0.9706703910614525:\n",
      "27th- epoch: 92, train_loss = 9.105602890253067, train_acc = 0.9795062878435026\n",
      "test Acc 0.9711359404096834:\n",
      "27th- epoch: 93, train_loss = 9.016438607126474, train_acc = 0.9796227293898463\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 94, train_loss = 8.928667787462473, train_acc = 0.9796227293898463\n",
      "test Acc 0.9720670391061452:\n",
      "27th- epoch: 95, train_loss = 8.842202261090279, train_acc = 0.9798556124825337\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 96, train_loss = 8.756949190050364, train_acc = 0.9799720540288775\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 97, train_loss = 8.6730045825243, train_acc = 0.9804378202142524\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 98, train_loss = 8.590084165334702, train_acc = 0.9804378202142524\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 99, train_loss = 8.508484620600939, train_acc = 0.98067070330694\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 100, train_loss = 8.427764859050512, train_acc = 0.9811364694923148\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 101, train_loss = 8.348064908757806, train_acc = 0.9813693525850024\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 102, train_loss = 8.269435092806816, train_acc = 0.9813693525850024\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 103, train_loss = 8.191972402855754, train_acc = 0.9816022356776898\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 104, train_loss = 8.115382820367813, train_acc = 0.9817186772240335\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 105, train_loss = 8.039830105379224, train_acc = 0.9817186772240335\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 106, train_loss = 7.9650786109268665, train_acc = 0.9818351187703773\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 107, train_loss = 7.891334665939212, train_acc = 0.981951560316721\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 108, train_loss = 7.81846484169364, train_acc = 0.9820680018630648\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 109, train_loss = 7.746770214289427, train_acc = 0.9826502095947834\n",
      "test Acc 0.9725325884543762:\n",
      "27th- epoch: 110, train_loss = 7.675900122150779, train_acc = 0.9826502095947834\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 111, train_loss = 7.605901876464486, train_acc = 0.9831159757801584\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 112, train_loss = 7.536998393014073, train_acc = 0.9834653004191896\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 113, train_loss = 7.4688352812081575, train_acc = 0.9835817419655333\n",
      "test Acc 0.973463687150838:\n",
      "27th- epoch: 114, train_loss = 7.401616794988513, train_acc = 0.983698183511877\n",
      "test Acc 0.973463687150838:\n",
      "27th- epoch: 115, train_loss = 7.335317987948656, train_acc = 0.9840475081509082\n",
      "test Acc 0.973463687150838:\n",
      "27th- epoch: 116, train_loss = 7.269495110958815, train_acc = 0.9842803912435957\n",
      "test Acc 0.973463687150838:\n",
      "27th- epoch: 117, train_loss = 7.204590059816837, train_acc = 0.9842803912435957\n",
      "test Acc 0.973463687150838:\n",
      "27th- epoch: 118, train_loss = 7.140159135684371, train_acc = 0.9846297158826269\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 119, train_loss = 7.0765315964818, train_acc = 0.9846297158826269\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 120, train_loss = 7.013740848749876, train_acc = 0.9846297158826269\n",
      "test Acc 0.972998137802607:\n",
      "27th- epoch: 121, train_loss = 6.951853662729263, train_acc = 0.9849790405216581\n",
      "test Acc 0.973463687150838:\n",
      "27th- epoch: 122, train_loss = 6.890560952946544, train_acc = 0.9853283651606893\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 123, train_loss = 6.830179017037153, train_acc = 0.985444806707033\n",
      "test Acc 0.9743947858472998:\n",
      "27th- epoch: 124, train_loss = 6.770371338352561, train_acc = 0.9856776897997206\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 125, train_loss = 6.71149449236691, train_acc = 0.985910572892408\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 126, train_loss = 6.6532939206808805, train_acc = 0.9861434559850955\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 127, train_loss = 6.595752943307161, train_acc = 0.9861434559850955\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 128, train_loss = 6.53842337988317, train_acc = 0.9862598975314392\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 129, train_loss = 6.482169013470411, train_acc = 0.986376339077783\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 130, train_loss = 6.426475657150149, train_acc = 0.986376339077783\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 131, train_loss = 6.371760573238134, train_acc = 0.9862598975314392\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 132, train_loss = 6.317580029368401, train_acc = 0.9864927806241267\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 133, train_loss = 6.2641214448958635, train_acc = 0.9867256637168141\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 134, train_loss = 6.2113459669053555, train_acc = 0.9867256637168141\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 135, train_loss = 6.159368395805359, train_acc = 0.9870749883558454\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 136, train_loss = 6.107887711375952, train_acc = 0.9871914299021891\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 137, train_loss = 6.057061951607466, train_acc = 0.9873078714485328\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 138, train_loss = 6.006788466125727, train_acc = 0.9875407545412203\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 139, train_loss = 5.956954821944237, train_acc = 0.9876571960875641\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 140, train_loss = 5.9079550337046385, train_acc = 0.9878900791802515\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 141, train_loss = 5.859421717002988, train_acc = 0.9880065207265952\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 142, train_loss = 5.811341254040599, train_acc = 0.9882394038192828\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 143, train_loss = 5.764242151752114, train_acc = 0.9884722869119702\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 144, train_loss = 5.717573558911681, train_acc = 0.9885887284583139\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 145, train_loss = 5.671471122652292, train_acc = 0.9885887284583139\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 146, train_loss = 5.625887947157025, train_acc = 0.9887051700046576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 147, train_loss = 5.580934539437294, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 148, train_loss = 5.5364043321460485, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 149, train_loss = 5.49239120259881, train_acc = 0.9887051700046576\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 150, train_loss = 5.449301339685917, train_acc = 0.9887051700046576\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 151, train_loss = 5.406134927645326, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 152, train_loss = 5.364056909456849, train_acc = 0.9888216115510013\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 153, train_loss = 5.322176340967417, train_acc = 0.9890544946436889\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 154, train_loss = 5.280716372653842, train_acc = 0.9890544946436889\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 155, train_loss = 5.2399262469261885, train_acc = 0.9890544946436889\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 156, train_loss = 5.1996591705828905, train_acc = 0.9890544946436889\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 157, train_loss = 5.15974541567266, train_acc = 0.9891709361900326\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 158, train_loss = 5.120276369154453, train_acc = 0.9892873777363763\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 159, train_loss = 5.081601216457784, train_acc = 0.98940381928272\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 160, train_loss = 5.043118548579514, train_acc = 0.9895202608290639\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 161, train_loss = 5.00519701000303, train_acc = 0.9896367023754076\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 162, train_loss = 4.967628734186292, train_acc = 0.9896367023754076\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 163, train_loss = 4.930659664794803, train_acc = 0.9896367023754076\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 164, train_loss = 4.893967992626131, train_acc = 0.9897531439217513\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 165, train_loss = 4.85808118339628, train_acc = 0.9901024685607824\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 166, train_loss = 4.822429130785167, train_acc = 0.9902189101071263\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 167, train_loss = 4.787291307002306, train_acc = 0.99033535165347\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 168, train_loss = 4.752491224557161, train_acc = 0.99033535165347\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 169, train_loss = 4.718268716707826, train_acc = 0.99033535165347\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 170, train_loss = 4.6841242127120495, train_acc = 0.99033535165347\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 171, train_loss = 4.650450217537582, train_acc = 0.99033535165347\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 172, train_loss = 4.617028665728867, train_acc = 0.9904517931998137\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 173, train_loss = 4.5842723865062, train_acc = 0.9905682347461574\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 174, train_loss = 4.551812196150422, train_acc = 0.9906846762925011\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 175, train_loss = 4.519965128973126, train_acc = 0.990801117838845\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 176, train_loss = 4.488350241445005, train_acc = 0.990801117838845\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 177, train_loss = 4.457164133898914, train_acc = 0.9910340009315324\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 178, train_loss = 4.426346765831113, train_acc = 0.9911504424778761\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 179, train_loss = 4.396101260557771, train_acc = 0.9912668840242198\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 180, train_loss = 4.366134526208043, train_acc = 0.9914997671169073\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 181, train_loss = 4.336499278433621, train_acc = 0.9914997671169073\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 182, train_loss = 4.307332123629749, train_acc = 0.9914997671169073\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 183, train_loss = 4.2783622136339545, train_acc = 0.9914997671169073\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 184, train_loss = 4.249814853072166, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 185, train_loss = 4.221728232689202, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 186, train_loss = 4.193791686557233, train_acc = 0.9917326502095948\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 187, train_loss = 4.166375707834959, train_acc = 0.9917326502095948\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 188, train_loss = 4.139217850752175, train_acc = 0.9917326502095948\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 189, train_loss = 4.11224851757288, train_acc = 0.9918490917559385\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 190, train_loss = 4.085886136628687, train_acc = 0.9918490917559385\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 191, train_loss = 4.059548258781433, train_acc = 0.9918490917559385\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 192, train_loss = 4.033770240843296, train_acc = 0.9919655333022822\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 193, train_loss = 4.008073527365923, train_acc = 0.992081974848626\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 194, train_loss = 3.982848164625466, train_acc = 0.9923148579413135\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 195, train_loss = 3.9578695287927985, train_acc = 0.9924312994876572\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 196, train_loss = 3.933156714774668, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 197, train_loss = 3.908829557709396, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 198, train_loss = 3.884700495749712, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 199, train_loss = 3.8607798563316464, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 200, train_loss = 3.8368947999551892, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 201, train_loss = 3.813716637901962, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 202, train_loss = 3.790523466654122, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 203, train_loss = 3.7677318984642625, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 204, train_loss = 3.745177357457578, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 205, train_loss = 3.7229294814169407, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 206, train_loss = 3.700965542346239, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 207, train_loss = 3.6790507221594453, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 208, train_loss = 3.6575239123776555, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 209, train_loss = 3.636314923875034, train_acc = 0.9925477410340009\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 210, train_loss = 3.615362398326397, train_acc = 0.9926641825803446\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 211, train_loss = 3.5943221375346184, train_acc = 0.9927806241266884\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 212, train_loss = 3.573700275272131, train_acc = 0.9927806241266884\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 213, train_loss = 3.5532566620968282, train_acc = 0.9927806241266884\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 214, train_loss = 3.5328761488199234, train_acc = 0.9928970656730322\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 215, train_loss = 3.5128370276652277, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 216, train_loss = 3.4933065958321095, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 217, train_loss = 3.473498316016048, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 218, train_loss = 3.4542101374827325, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 219, train_loss = 3.435081508010626, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 220, train_loss = 3.4160357168875635, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 221, train_loss = 3.3975050798617303, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 222, train_loss = 3.3788498491048813, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 223, train_loss = 3.3603787035681307, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 224, train_loss = 3.3423392586410046, train_acc = 0.9930135072193759\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 225, train_loss = 3.3241844973526895, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 226, train_loss = 3.3066245554946363, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 227, train_loss = 3.28888633986935, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 228, train_loss = 3.27147613465786, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 229, train_loss = 3.2542810179293156, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 230, train_loss = 3.2371864896267653, train_acc = 0.9931299487657196\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 231, train_loss = 3.2202516957186162, train_acc = 0.9932463903120633\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 232, train_loss = 3.2036455534398556, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 233, train_loss = 3.187124352902174, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 234, train_loss = 3.1706258109770715, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 235, train_loss = 3.1543873217888176, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 236, train_loss = 3.138150562066585, train_acc = 0.9933628318584071\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 237, train_loss = 3.1223232154734433, train_acc = 0.9934792734047508\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 238, train_loss = 3.1066880258731544, train_acc = 0.9934792734047508\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 239, train_loss = 3.0910283024422824, train_acc = 0.9934792734047508\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 240, train_loss = 3.0755621078424156, train_acc = 0.993828598043782\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 241, train_loss = 3.0605355612933636, train_acc = 0.993828598043782\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 242, train_loss = 3.0451941955834627, train_acc = 0.9939450395901258\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 243, train_loss = 3.030367985367775, train_acc = 0.9939450395901258\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 244, train_loss = 3.0155218080617487, train_acc = 0.9940614811364695\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 245, train_loss = 3.0008351765573025, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 246, train_loss = 2.986187761183828, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 247, train_loss = 2.9718960151076317, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 248, train_loss = 2.9579203561879694, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 249, train_loss = 2.9435520893894136, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 250, train_loss = 2.9294425821863115, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 251, train_loss = 2.9159183837473392, train_acc = 0.9941779226828132\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 252, train_loss = 2.902125182095915, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 253, train_loss = 2.8885394423268735, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 254, train_loss = 2.875315561890602, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 255, train_loss = 2.861920027527958, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 256, train_loss = 2.848842591047287, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 257, train_loss = 2.835767727345228, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 258, train_loss = 2.822913615498692, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 259, train_loss = 2.810023126658052, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 260, train_loss = 2.7974808663129807, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 261, train_loss = 2.7848559194244444, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 262, train_loss = 2.7723663984797895, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 263, train_loss = 2.7601463668979704, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 264, train_loss = 2.7481871373020113, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 265, train_loss = 2.735886914189905, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 266, train_loss = 2.724066922906786, train_acc = 0.9944108057755007\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 267, train_loss = 2.7122647911310196, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 268, train_loss = 2.700644813477993, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 269, train_loss = 2.6889892481267452, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 270, train_loss = 2.6775033376179636, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 271, train_loss = 2.6661666953004897, train_acc = 0.9945272473218444\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 272, train_loss = 2.6549446904100478, train_acc = 0.9946436888681882\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 273, train_loss = 2.643856879323721, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 274, train_loss = 2.6326596178114414, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 275, train_loss = 2.6219337158836424, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 276, train_loss = 2.6110890707932413, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 277, train_loss = 2.600410835351795, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 278, train_loss = 2.589739652816206, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 279, train_loss = 2.5792834125459194, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 280, train_loss = 2.5688674189150333, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 281, train_loss = 2.558557529002428, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 282, train_loss = 2.548575558932498, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 283, train_loss = 2.5382756914477795, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 284, train_loss = 2.5283960949163884, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 285, train_loss = 2.5184980432968587, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 286, train_loss = 2.5086644738912582, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 287, train_loss = 2.499039391754195, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 288, train_loss = 2.4894543662667274, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 289, train_loss = 2.479929693043232, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 290, train_loss = 2.4704843026120216, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 291, train_loss = 2.461300455033779, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 292, train_loss = 2.4520264118909836, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 293, train_loss = 2.442895647138357, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 294, train_loss = 2.4339186314027756, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 295, train_loss = 2.4248804685194045, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 296, train_loss = 2.416229096474126, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 297, train_loss = 2.407365669729188, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 298, train_loss = 2.398714240640402, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 299, train_loss = 2.390113828005269, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 300, train_loss = 2.3814552526455373, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 301, train_loss = 2.373216684907675, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 302, train_loss = 2.364747243700549, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 303, train_loss = 2.356607910245657, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 304, train_loss = 2.3483795050997287, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 305, train_loss = 2.340318338247016, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 306, train_loss = 2.3323048402089626, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 307, train_loss = 2.324338987469673, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 308, train_loss = 2.316482278285548, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 309, train_loss = 2.3086113568861037, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 310, train_loss = 2.3009238454978913, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 311, train_loss = 2.2933261159341782, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 312, train_loss = 2.2857706993818283, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 313, train_loss = 2.278244389919564, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 314, train_loss = 2.2707361232023686, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 315, train_loss = 2.263538869796321, train_acc = 0.9947601304145319\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 316, train_loss = 2.256228345213458, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 317, train_loss = 2.2490257136523724, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 318, train_loss = 2.241902068257332, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 319, train_loss = 2.2347297680098563, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 320, train_loss = 2.2278430971782655, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 321, train_loss = 2.220734254689887, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 322, train_loss = 2.2140371885616332, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 323, train_loss = 2.2070363238453865, train_acc = 0.9948765719608756\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 324, train_loss = 2.2003901712596416, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 325, train_loss = 2.193792050005868, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 326, train_loss = 2.186974662123248, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 327, train_loss = 2.1804743569809943, train_acc = 0.9949930135072194\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 328, train_loss = 2.174040000885725, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 329, train_loss = 2.1677287842612714, train_acc = 0.9951094550535631\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 330, train_loss = 2.1612005196511745, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 331, train_loss = 2.154851261526346, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 332, train_loss = 2.148702808888629, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 333, train_loss = 2.1425813909154385, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 334, train_loss = 2.13634825614281, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 335, train_loss = 2.130340624600649, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 336, train_loss = 2.1243846577126533, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 337, train_loss = 2.1182996530551463, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 338, train_loss = 2.1124518264550716, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 339, train_loss = 2.1066160078626126, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 340, train_loss = 2.1008377100806683, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 341, train_loss = 2.0949324767570943, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 342, train_loss = 2.0894355066120625, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 343, train_loss = 2.083630195586011, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 344, train_loss = 2.0781627893447876, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 345, train_loss = 2.072506873635575, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 346, train_loss = 2.0670523319859058, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 347, train_loss = 2.0615470570046455, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 348, train_loss = 2.056228317320347, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 349, train_loss = 2.050830416381359, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 350, train_loss = 2.0454117320477962, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 351, train_loss = 2.040273529710248, train_acc = 0.9952258965999069\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 352, train_loss = 2.0350612464826554, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 353, train_loss = 2.029770066263154, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 354, train_loss = 2.0247009012382478, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 355, train_loss = 2.019575157435611, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 356, train_loss = 2.014609755249694, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 357, train_loss = 2.009605159284547, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 358, train_loss = 2.004544244380668, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 359, train_loss = 1.999705669702962, train_acc = 0.9953423381462506\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 360, train_loss = 1.9949343539774418, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 361, train_loss = 1.9901844449341297, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 362, train_loss = 1.9852708652615547, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 363, train_loss = 1.9804985374212265, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 364, train_loss = 1.9758589155972004, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 365, train_loss = 1.9711457751691341, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 366, train_loss = 1.9666449116775766, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 367, train_loss = 1.9620146168163046, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 368, train_loss = 1.9574539425084367, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 369, train_loss = 1.952978827059269, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 370, train_loss = 1.948478420614265, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 371, train_loss = 1.9440776221454144, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 372, train_loss = 1.9397056376328692, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 373, train_loss = 1.9354240061948076, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 374, train_loss = 1.9310936592519283, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 375, train_loss = 1.9266731614479795, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 376, train_loss = 1.9224744327366352, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 377, train_loss = 1.9183649768820032, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 378, train_loss = 1.9141362309455872, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 379, train_loss = 1.9099164059152827, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 380, train_loss = 1.9059369241585955, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 381, train_loss = 1.9017747640609741, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 382, train_loss = 1.8977748776087537, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 383, train_loss = 1.893937117070891, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 384, train_loss = 1.889817619114183, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 385, train_loss = 1.88597569859121, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 386, train_loss = 1.882022132514976, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 387, train_loss = 1.8780698776245117, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 388, train_loss = 1.8742603994905949, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 389, train_loss = 1.8704461256274953, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 390, train_loss = 1.86677109322045, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 391, train_loss = 1.8629066459834576, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 392, train_loss = 1.8591275550425053, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 393, train_loss = 1.855573465465568, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 394, train_loss = 1.8518143271794543, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 395, train_loss = 1.8482781139900908, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 396, train_loss = 1.8445981243858114, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 397, train_loss = 1.8409453332424164, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 398, train_loss = 1.837533839046955, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 399, train_loss = 1.8339302887907252, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 400, train_loss = 1.830458752810955, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 401, train_loss = 1.8269772045314312, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 402, train_loss = 1.8234371779253706, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 403, train_loss = 1.820156073779799, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 404, train_loss = 1.816709996550344, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 405, train_loss = 1.8133960328996181, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 406, train_loss = 1.8099178621778265, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 407, train_loss = 1.8066544011235237, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "27th- epoch: 408, train_loss = 1.8034238368272781, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "27th- epoch: 409, train_loss = 1.8001511506736279, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "27th- epoch: 410, train_loss = 1.7969511511037126, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "27th- epoch: 411, train_loss = 1.7936774106929079, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "27th- epoch: 412, train_loss = 1.7904348807642236, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "27th- epoch: 413, train_loss = 1.7874026261270046, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "27th- epoch: 414, train_loss = 1.7840792773058638, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "27th- epoch: 415, train_loss = 1.7810691023478284, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 416, train_loss = 1.777889164746739, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 417, train_loss = 1.7747719200560823, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 418, train_loss = 1.7718358114361763, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 419, train_loss = 1.7686779126524925, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 420, train_loss = 1.7657296732068062, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 421, train_loss = 1.7627417296171188, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 422, train_loss = 1.7596859323093668, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 423, train_loss = 1.7568784219911322, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 424, train_loss = 1.7539187222719193, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 425, train_loss = 1.7511168494820595, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 426, train_loss = 1.7482426911592484, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 427, train_loss = 1.7452637428650633, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 428, train_loss = 1.7424509016564116, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 429, train_loss = 1.7395184425404295, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 430, train_loss = 1.7367544559529051, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 431, train_loss = 1.7341791255166754, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 432, train_loss = 1.7312028059968725, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 433, train_loss = 1.7286101765930653, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 434, train_loss = 1.7257989620557055, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 435, train_loss = 1.723033977090381, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 436, train_loss = 1.7205535657703876, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 437, train_loss = 1.7177337097236887, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 438, train_loss = 1.7150982295861468, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 439, train_loss = 1.7125310624251142, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 440, train_loss = 1.7099080519983545, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 441, train_loss = 1.7073460345854983, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 442, train_loss = 1.704708993434906, train_acc = 0.9958081043316255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 443, train_loss = 1.7021603435277939, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 444, train_loss = 1.6996906077256426, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 445, train_loss = 1.697009747265838, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "27th- epoch: 446, train_loss = 1.6946584110846743, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 447, train_loss = 1.6920916537055746, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 448, train_loss = 1.6897335114190355, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 449, train_loss = 1.687207012088038, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 450, train_loss = 1.684821973205544, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 451, train_loss = 1.682423842488788, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 452, train_loss = 1.680081476806663, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 453, train_loss = 1.6776706874370575, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 454, train_loss = 1.6753586468985304, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 455, train_loss = 1.6730085387825966, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 456, train_loss = 1.6706061536679044, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 457, train_loss = 1.668450710712932, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 458, train_loss = 1.6660233462462202, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 459, train_loss = 1.6636005863547325, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 460, train_loss = 1.661328955204226, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 461, train_loss = 1.6592962654540315, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 462, train_loss = 1.6569389464566484, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 463, train_loss = 1.6546173145761713, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 464, train_loss = 1.6524628028273582, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 465, train_loss = 1.650401653139852, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 466, train_loss = 1.6480362552101724, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 467, train_loss = 1.6461272525484674, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 468, train_loss = 1.6438636146485806, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 469, train_loss = 1.6415280501241796, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 470, train_loss = 1.6395070143043995, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 471, train_loss = 1.637419746548403, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 472, train_loss = 1.6354031463270076, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 473, train_loss = 1.6333271637558937, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 474, train_loss = 1.6310587997431867, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 475, train_loss = 1.6289573051035404, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 476, train_loss = 1.6270673696999438, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 477, train_loss = 1.6248748252983205, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 478, train_loss = 1.6229004710912704, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 479, train_loss = 1.6209134223754518, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 480, train_loss = 1.6189488557283767, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 481, train_loss = 1.6167707927525043, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 482, train_loss = 1.615064709156286, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 483, train_loss = 1.6130082719027996, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 484, train_loss = 1.611183209985029, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 485, train_loss = 1.6092494912445545, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 486, train_loss = 1.6074564320151694, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 487, train_loss = 1.6052906115655787, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 488, train_loss = 1.603484523773659, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 489, train_loss = 1.6014009937644005, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 490, train_loss = 1.5998255871236324, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 491, train_loss = 1.5977043497259729, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 492, train_loss = 1.5961761238868348, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 493, train_loss = 1.5940225559170358, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 494, train_loss = 1.5924692476983182, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 495, train_loss = 1.5904837337438948, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 496, train_loss = 1.588753066956997, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 497, train_loss = 1.5868427592213266, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 498, train_loss = 1.5851288102567196, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 499, train_loss = 1.58331760764122, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████▊       | 27/30 [2:59:25<19:56, 398.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "28th- epoch: 0, train_loss = 272.91976618766785, train_acc = 0.4312994876571961\n",
      "test Acc 0.4864990689013035:\n",
      "28th- epoch: 1, train_loss = 208.14823079109192, train_acc = 0.489869585468095\n",
      "test Acc 0.49906890130353815:\n",
      "28th- epoch: 2, train_loss = 167.80877143144608, train_acc = 0.506171401956218\n",
      "test Acc 0.5274674115456238:\n",
      "28th- epoch: 3, train_loss = 144.83801007270813, train_acc = 0.6335584536562645\n",
      "test Acc 0.6899441340782123:\n",
      "28th- epoch: 4, train_loss = 126.54821276664734, train_acc = 0.7087796925943176\n",
      "test Acc 0.7430167597765364:\n",
      "28th- epoch: 5, train_loss = 110.69038552045822, train_acc = 0.7476711690731253\n",
      "test Acc 0.7728119180633147:\n",
      "28th- epoch: 6, train_loss = 97.17808091640472, train_acc = 0.7894736842105263\n",
      "test Acc 0.8063314711359404:\n",
      "28th- epoch: 7, train_loss = 85.75704687833786, train_acc = 0.8143921751280857\n",
      "test Acc 0.8198324022346368:\n",
      "28th- epoch: 8, train_loss = 76.0617646574974, train_acc = 0.8302282254308337\n",
      "test Acc 0.8417132216014898:\n",
      "28th- epoch: 9, train_loss = 67.84591498970985, train_acc = 0.857359105728924\n",
      "test Acc 0.8696461824953445:\n",
      "28th- epoch: 10, train_loss = 60.94007559120655, train_acc = 0.8814625058220773\n",
      "test Acc 0.8878026070763501:\n",
      "28th- epoch: 11, train_loss = 55.158523082733154, train_acc = 0.8924080111783884\n",
      "test Acc 0.8957169459962756:\n",
      "28th- epoch: 12, train_loss = 50.323829755187035, train_acc = 0.9033535165346995\n",
      "test Acc 0.9050279329608939:\n",
      "28th- epoch: 13, train_loss = 46.276178777217865, train_acc = 0.9141825803446669\n",
      "test Acc 0.9171322160148976:\n",
      "28th- epoch: 14, train_loss = 42.87249077856541, train_acc = 0.9234979040521658\n",
      "test Acc 0.9241154562383612:\n",
      "28th- epoch: 15, train_loss = 39.98980367183685, train_acc = 0.931765253842571\n",
      "test Acc 0.931098696461825:\n",
      "28th- epoch: 16, train_loss = 37.52534395456314, train_acc = 0.936190032603633\n",
      "test Acc 0.9352886405959032:\n",
      "28th- epoch: 17, train_loss = 35.39109347760677, train_acc = 0.9404983698183512\n",
      "test Acc 0.9380819366852886:\n",
      "28th- epoch: 18, train_loss = 33.5300779864192, train_acc = 0.9425943176525384\n",
      "test Acc 0.9404096834264432:\n",
      "28th- epoch: 19, train_loss = 31.91296772658825, train_acc = 0.9449231485794132\n",
      "test Acc 0.9432029795158287:\n",
      "28th- epoch: 20, train_loss = 30.492167823016644, train_acc = 0.9473684210526315\n",
      "test Acc 0.9441340782122905:\n",
      "28th- epoch: 21, train_loss = 29.231095254421234, train_acc = 0.9501630181648812\n",
      "test Acc 0.9455307262569832:\n",
      "28th- epoch: 22, train_loss = 28.102891258895397, train_acc = 0.9510945505356311\n",
      "test Acc 0.9487895716945997:\n",
      "28th- epoch: 23, train_loss = 27.086520567536354, train_acc = 0.9534233814625058\n",
      "test Acc 0.9492551210428305:\n",
      "28th- epoch: 24, train_loss = 26.164237543940544, train_acc = 0.9541220307405682\n",
      "test Acc 0.9506517690875232:\n",
      "28th- epoch: 25, train_loss = 25.324318416416645, train_acc = 0.9554028877503493\n",
      "test Acc 0.952048417132216:\n",
      "28th- epoch: 26, train_loss = 24.55467277020216, train_acc = 0.9562179785747554\n",
      "test Acc 0.9529795158286778:\n",
      "28th- epoch: 27, train_loss = 23.845077496021986, train_acc = 0.9574988355845365\n",
      "test Acc 0.9529795158286778:\n",
      "28th- epoch: 28, train_loss = 23.187443893402815, train_acc = 0.9580810433162552\n",
      "test Acc 0.9534450651769087:\n",
      "28th- epoch: 29, train_loss = 22.57587556168437, train_acc = 0.95947834187238\n",
      "test Acc 0.9543761638733705:\n",
      "28th- epoch: 30, train_loss = 22.00397202372551, train_acc = 0.9597112249650676\n",
      "test Acc 0.9548417132216015:\n",
      "28th- epoch: 31, train_loss = 21.467796821147203, train_acc = 0.96040987424313\n",
      "test Acc 0.9553072625698324:\n",
      "28th- epoch: 32, train_loss = 20.963232442736626, train_acc = 0.9607591988821611\n",
      "test Acc 0.9553072625698324:\n",
      "28th- epoch: 33, train_loss = 20.487105559557676, train_acc = 0.9611085235211924\n",
      "test Acc 0.9557728119180633:\n",
      "28th- epoch: 34, train_loss = 20.036189697682858, train_acc = 0.961690731252911\n",
      "test Acc 0.9567039106145251:\n",
      "28th- epoch: 35, train_loss = 19.60763579234481, train_acc = 0.9620400558919422\n",
      "test Acc 0.957635009310987:\n",
      "28th- epoch: 36, train_loss = 19.198848888278008, train_acc = 0.9629715882626921\n",
      "test Acc 0.9581005586592178:\n",
      "28th- epoch: 37, train_loss = 18.809015076607466, train_acc = 0.9636702375407545\n",
      "test Acc 0.9585661080074488:\n",
      "28th- epoch: 38, train_loss = 18.436763420701027, train_acc = 0.963903120633442\n",
      "test Acc 0.9599627560521415:\n",
      "28th- epoch: 39, train_loss = 18.0804391130805, train_acc = 0.9646017699115044\n",
      "test Acc 0.9608938547486033:\n",
      "28th- epoch: 40, train_loss = 17.73951566591859, train_acc = 0.9654168607359106\n",
      "test Acc 0.9618249534450651:\n",
      "28th- epoch: 41, train_loss = 17.41217678785324, train_acc = 0.965649743828598\n",
      "test Acc 0.9618249534450651:\n",
      "28th- epoch: 42, train_loss = 17.097619004547596, train_acc = 0.9664648346530041\n",
      "test Acc 0.9622905027932961:\n",
      "28th- epoch: 43, train_loss = 16.794681150466204, train_acc = 0.9668141592920354\n",
      "test Acc 0.962756052141527:\n",
      "28th- epoch: 44, train_loss = 16.50172234326601, train_acc = 0.9673963670237541\n",
      "test Acc 0.962756052141527:\n",
      "28th- epoch: 45, train_loss = 16.218692678958178, train_acc = 0.9678621332091291\n",
      "test Acc 0.962756052141527:\n",
      "28th- epoch: 46, train_loss = 15.945273708552122, train_acc = 0.9687936655798789\n",
      "test Acc 0.9632216014897579:\n",
      "28th- epoch: 47, train_loss = 15.681340478360653, train_acc = 0.9693758733115976\n",
      "test Acc 0.9636871508379888:\n",
      "28th- epoch: 48, train_loss = 15.426166083663702, train_acc = 0.9698416394969726\n",
      "test Acc 0.9641527001862198:\n",
      "28th- epoch: 49, train_loss = 15.179075244814157, train_acc = 0.9701909641360037\n",
      "test Acc 0.9646182495344506:\n",
      "28th- epoch: 50, train_loss = 14.939976129680872, train_acc = 0.9707731718677224\n",
      "test Acc 0.9660148975791434:\n",
      "28th- epoch: 51, train_loss = 14.708426434546709, train_acc = 0.9708896134140661\n",
      "test Acc 0.9660148975791434:\n",
      "28th- epoch: 52, train_loss = 14.48392041400075, train_acc = 0.9717047042384723\n",
      "test Acc 0.9664804469273743:\n",
      "28th- epoch: 53, train_loss = 14.266552615910769, train_acc = 0.9725197950628784\n",
      "test Acc 0.9660148975791434:\n",
      "28th- epoch: 54, train_loss = 14.055273551493883, train_acc = 0.9727526781555659\n",
      "test Acc 0.9660148975791434:\n",
      "28th- epoch: 55, train_loss = 13.85032618418336, train_acc = 0.9727526781555659\n",
      "test Acc 0.9664804469273743:\n",
      "28th- epoch: 56, train_loss = 13.651742123067379, train_acc = 0.9728691197019096\n",
      "test Acc 0.9669459962756052:\n",
      "28th- epoch: 57, train_loss = 13.459119398146868, train_acc = 0.9731020027945971\n",
      "test Acc 0.9669459962756052:\n",
      "28th- epoch: 58, train_loss = 13.272213557735085, train_acc = 0.9734513274336283\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 59, train_loss = 13.090749202296138, train_acc = 0.9736842105263158\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 60, train_loss = 12.914357773959637, train_acc = 0.974033535165347\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 61, train_loss = 12.743003325536847, train_acc = 0.9742664182580345\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 62, train_loss = 12.576233567669988, train_acc = 0.9742664182580345\n",
      "test Acc 0.9683426443202979:\n",
      "28th- epoch: 63, train_loss = 12.414137691259384, train_acc = 0.9743828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "28th- epoch: 64, train_loss = 12.256474953144789, train_acc = 0.9750815090824406\n",
      "test Acc 0.9683426443202979:\n",
      "28th- epoch: 65, train_loss = 12.102806590497494, train_acc = 0.9754308337214718\n",
      "test Acc 0.9683426443202979:\n",
      "28th- epoch: 66, train_loss = 11.952997274696827, train_acc = 0.9756637168141593\n",
      "test Acc 0.9683426443202979:\n",
      "28th- epoch: 67, train_loss = 11.806786872446537, train_acc = 0.9761294829995343\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 68, train_loss = 11.664047103375196, train_acc = 0.9763623660922217\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 69, train_loss = 11.524724062532187, train_acc = 0.9767116907312529\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 70, train_loss = 11.388542778789997, train_acc = 0.9769445738239404\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 71, train_loss = 11.255687782540917, train_acc = 0.9772938984629715\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 72, train_loss = 11.126096056774259, train_acc = 0.9772938984629715\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 73, train_loss = 10.999393381178379, train_acc = 0.9776432231020028\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 74, train_loss = 10.875610575079918, train_acc = 0.9781089892873778\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 75, train_loss = 10.754401337355375, train_acc = 0.9781089892873778\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 76, train_loss = 10.635795971378684, train_acc = 0.9781089892873778\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 77, train_loss = 10.519743418321013, train_acc = 0.9782254308337215\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 78, train_loss = 10.40589639171958, train_acc = 0.9782254308337215\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 79, train_loss = 10.294095046818256, train_acc = 0.9783418723800652\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 80, train_loss = 10.184537656605244, train_acc = 0.9784583139264089\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 81, train_loss = 10.076994413509965, train_acc = 0.9784583139264089\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 82, train_loss = 9.97148060053587, train_acc = 0.9785747554727526\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 83, train_loss = 9.867919765412807, train_acc = 0.9786911970190965\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 84, train_loss = 9.766157180070877, train_acc = 0.9786911970190965\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 85, train_loss = 9.666045296937227, train_acc = 0.9788076385654402\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 86, train_loss = 9.567194163799286, train_acc = 0.9789240801117839\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 87, train_loss = 9.470444921404123, train_acc = 0.9791569632044713\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 88, train_loss = 9.37534049898386, train_acc = 0.9791569632044713\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 89, train_loss = 9.282019399106503, train_acc = 0.9791569632044713\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 90, train_loss = 9.190173368901014, train_acc = 0.9792734047508151\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 91, train_loss = 9.099845740944147, train_acc = 0.9795062878435026\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 92, train_loss = 9.01106695830822, train_acc = 0.9798556124825337\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 93, train_loss = 8.923623390495777, train_acc = 0.9798556124825337\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 94, train_loss = 8.837507478892803, train_acc = 0.980204937121565\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 95, train_loss = 8.75265671685338, train_acc = 0.9805542617605962\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 96, train_loss = 8.669159967452288, train_acc = 0.9809035863996274\n",
      "test Acc 0.9688081936685289:\n",
      "28th- epoch: 97, train_loss = 8.587013965472579, train_acc = 0.9812529110386586\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 98, train_loss = 8.50592951104045, train_acc = 0.9814857941313461\n",
      "test Acc 0.9692737430167597:\n",
      "28th- epoch: 99, train_loss = 8.426024708896875, train_acc = 0.9817186772240335\n",
      "test Acc 0.9697392923649907:\n",
      "28th- epoch: 100, train_loss = 8.347225442528725, train_acc = 0.9818351187703773\n",
      "test Acc 0.9697392923649907:\n",
      "28th- epoch: 101, train_loss = 8.269695647060871, train_acc = 0.981951560316721\n",
      "test Acc 0.9697392923649907:\n",
      "28th- epoch: 102, train_loss = 8.19306192919612, train_acc = 0.9824173265020959\n",
      "test Acc 0.9697392923649907:\n",
      "28th- epoch: 103, train_loss = 8.117786010727286, train_acc = 0.9826502095947834\n",
      "test Acc 0.9697392923649907:\n",
      "28th- epoch: 104, train_loss = 8.043452894315124, train_acc = 0.9833488588728458\n",
      "test Acc 0.9702048417132216:\n",
      "28th- epoch: 105, train_loss = 7.970161093398929, train_acc = 0.9833488588728458\n",
      "test Acc 0.9702048417132216:\n",
      "28th- epoch: 106, train_loss = 7.897819738835096, train_acc = 0.9833488588728458\n",
      "test Acc 0.9716014897579144:\n",
      "28th- epoch: 107, train_loss = 7.826570404693484, train_acc = 0.9833488588728458\n",
      "test Acc 0.9716014897579144:\n",
      "28th- epoch: 108, train_loss = 7.756244946271181, train_acc = 0.9834653004191896\n",
      "test Acc 0.9720670391061452:\n",
      "28th- epoch: 109, train_loss = 7.686795070767403, train_acc = 0.9838146250582208\n",
      "test Acc 0.9725325884543762:\n",
      "28th- epoch: 110, train_loss = 7.618459971621633, train_acc = 0.9840475081509082\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 111, train_loss = 7.55085588991642, train_acc = 0.9846297158826269\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 112, train_loss = 7.48424132540822, train_acc = 0.9846297158826269\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 113, train_loss = 7.418480211868882, train_acc = 0.9848625989753144\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 114, train_loss = 7.353428998962045, train_acc = 0.9849790405216581\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 115, train_loss = 7.2894086968153715, train_acc = 0.9849790405216581\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 116, train_loss = 7.225917916744947, train_acc = 0.9849790405216581\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 117, train_loss = 7.163000727072358, train_acc = 0.9849790405216581\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 118, train_loss = 7.101136116310954, train_acc = 0.9850954820680019\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 119, train_loss = 7.040135893970728, train_acc = 0.9853283651606893\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 120, train_loss = 6.9800209775567055, train_acc = 0.9857941313460643\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 121, train_loss = 6.920463839545846, train_acc = 0.986376339077783\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 122, train_loss = 6.861680842936039, train_acc = 0.986376339077783\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 123, train_loss = 6.8037047274410725, train_acc = 0.9864927806241267\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 124, train_loss = 6.7462692353874445, train_acc = 0.9864927806241267\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 125, train_loss = 6.6897081304341555, train_acc = 0.9867256637168141\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 126, train_loss = 6.633925588801503, train_acc = 0.9868421052631579\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 127, train_loss = 6.578804478049278, train_acc = 0.9868421052631579\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 128, train_loss = 6.524305783212185, train_acc = 0.9869585468095017\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 129, train_loss = 6.470384726300836, train_acc = 0.9870749883558454\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 130, train_loss = 6.41742436401546, train_acc = 0.9870749883558454\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 131, train_loss = 6.364915255457163, train_acc = 0.9871914299021891\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 132, train_loss = 6.31324839964509, train_acc = 0.9873078714485328\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 133, train_loss = 6.262066317722201, train_acc = 0.9875407545412203\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 134, train_loss = 6.211666956543922, train_acc = 0.9875407545412203\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 135, train_loss = 6.1618006359785795, train_acc = 0.9875407545412203\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 136, train_loss = 6.112583562731743, train_acc = 0.9875407545412203\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 137, train_loss = 6.063842914998531, train_acc = 0.9877736376339078\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 138, train_loss = 6.015678979456425, train_acc = 0.9878900791802515\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 139, train_loss = 5.967861706390977, train_acc = 0.9878900791802515\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 140, train_loss = 5.921007048338652, train_acc = 0.9880065207265952\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 141, train_loss = 5.874613801017404, train_acc = 0.9880065207265952\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 142, train_loss = 5.828957611694932, train_acc = 0.9881229622729389\n",
      "test Acc 0.9743947858472998:\n",
      "28th- epoch: 143, train_loss = 5.783708898350596, train_acc = 0.9881229622729389\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 144, train_loss = 5.739123472943902, train_acc = 0.9883558453656265\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 145, train_loss = 5.694813007488847, train_acc = 0.9883558453656265\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 146, train_loss = 5.65122220851481, train_acc = 0.9883558453656265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 147, train_loss = 5.6080149710178375, train_acc = 0.9887051700046576\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 148, train_loss = 5.565425407141447, train_acc = 0.9887051700046576\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 149, train_loss = 5.523311875760555, train_acc = 0.9888216115510013\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 150, train_loss = 5.481627494096756, train_acc = 0.9888216115510013\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 151, train_loss = 5.440584033727646, train_acc = 0.9888216115510013\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 152, train_loss = 5.399885518476367, train_acc = 0.9889380530973452\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 153, train_loss = 5.359689814969897, train_acc = 0.9889380530973452\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 154, train_loss = 5.3199507389217615, train_acc = 0.9890544946436889\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 155, train_loss = 5.2808651607483625, train_acc = 0.9890544946436889\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 156, train_loss = 5.242123231291771, train_acc = 0.9890544946436889\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 157, train_loss = 5.203964753076434, train_acc = 0.9890544946436889\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 158, train_loss = 5.166113572195172, train_acc = 0.9891709361900326\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 159, train_loss = 5.128778927028179, train_acc = 0.98940381928272\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 160, train_loss = 5.091898396611214, train_acc = 0.98940381928272\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 161, train_loss = 5.055378677323461, train_acc = 0.98940381928272\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 162, train_loss = 5.01938490010798, train_acc = 0.98940381928272\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 163, train_loss = 4.9836579244583845, train_acc = 0.9895202608290639\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 164, train_loss = 4.948510318994522, train_acc = 0.9896367023754076\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 165, train_loss = 4.913774088025093, train_acc = 0.9896367023754076\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 166, train_loss = 4.879341164603829, train_acc = 0.989869585468095\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 167, train_loss = 4.845584754832089, train_acc = 0.99033535165347\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 168, train_loss = 4.812053645029664, train_acc = 0.9904517931998137\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 169, train_loss = 4.778907452709973, train_acc = 0.9904517931998137\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 170, train_loss = 4.746328781358898, train_acc = 0.9904517931998137\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 171, train_loss = 4.713871422223747, train_acc = 0.9905682347461574\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 172, train_loss = 4.681890401057899, train_acc = 0.9905682347461574\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 173, train_loss = 4.650221043266356, train_acc = 0.9906846762925011\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 174, train_loss = 4.619077189825475, train_acc = 0.990801117838845\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 175, train_loss = 4.588013601489365, train_acc = 0.9909175593851887\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 176, train_loss = 4.557500190101564, train_acc = 0.9909175593851887\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 177, train_loss = 4.527266587130725, train_acc = 0.9911504424778761\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 178, train_loss = 4.497602932155132, train_acc = 0.9911504424778761\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 179, train_loss = 4.468041840009391, train_acc = 0.9911504424778761\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 180, train_loss = 4.438899918459356, train_acc = 0.9911504424778761\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 181, train_loss = 4.410146637819707, train_acc = 0.9912668840242198\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 182, train_loss = 4.381545048207045, train_acc = 0.9912668840242198\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 183, train_loss = 4.353490094654262, train_acc = 0.9912668840242198\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 184, train_loss = 4.325770650058985, train_acc = 0.9912668840242198\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 185, train_loss = 4.298097241669893, train_acc = 0.9912668840242198\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 186, train_loss = 4.270941406488419, train_acc = 0.9912668840242198\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 187, train_loss = 4.2440697913989425, train_acc = 0.9912668840242198\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 188, train_loss = 4.21734953019768, train_acc = 0.9916162086632511\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 189, train_loss = 4.190990689210594, train_acc = 0.9917326502095948\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 190, train_loss = 4.164750620722771, train_acc = 0.9918490917559385\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 191, train_loss = 4.1387484623119235, train_acc = 0.9918490917559385\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 192, train_loss = 4.113056221045554, train_acc = 0.9918490917559385\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 193, train_loss = 4.087675116956234, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 194, train_loss = 4.062672468833625, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 195, train_loss = 4.038058061152697, train_acc = 0.9919655333022822\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 196, train_loss = 4.0137585317716, train_acc = 0.992081974848626\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 197, train_loss = 3.989652211777866, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 198, train_loss = 3.965916834771633, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 199, train_loss = 3.9424803433939815, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 200, train_loss = 3.9191787354648113, train_acc = 0.9921984163949698\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 201, train_loss = 3.8962887385860085, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 202, train_loss = 3.8735016584396362, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 203, train_loss = 3.851078034378588, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 204, train_loss = 3.8288891054689884, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 205, train_loss = 3.806887718848884, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 206, train_loss = 3.7851396882906556, train_acc = 0.9923148579413135\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 207, train_loss = 3.7635893328115344, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 208, train_loss = 3.742346316576004, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 209, train_loss = 3.721385981887579, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 210, train_loss = 3.7005562046542764, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 211, train_loss = 3.6799429366365075, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 212, train_loss = 3.659599021077156, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 213, train_loss = 3.639324624091387, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 214, train_loss = 3.6192930825054646, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 215, train_loss = 3.599446195177734, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 216, train_loss = 3.5796868735924363, train_acc = 0.9926641825803446\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 217, train_loss = 3.560319159179926, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 218, train_loss = 3.5411822823807597, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 219, train_loss = 3.5222059600055218, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 220, train_loss = 3.503450907766819, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 221, train_loss = 3.4847887055948377, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 222, train_loss = 3.4666132191196084, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 223, train_loss = 3.448325083591044, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 224, train_loss = 3.430359646677971, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 225, train_loss = 3.4126157769933343, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 226, train_loss = 3.3948905067518353, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 227, train_loss = 3.3774980222806334, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 228, train_loss = 3.3601140584796667, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 229, train_loss = 3.343039392493665, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 230, train_loss = 3.3260561861097813, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 231, train_loss = 3.309255394153297, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 232, train_loss = 3.292606858536601, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 233, train_loss = 3.2762037715874612, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 234, train_loss = 3.259866550564766, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 235, train_loss = 3.2437050081789494, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 236, train_loss = 3.2276782053522766, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 237, train_loss = 3.2118765488266945, train_acc = 0.9930135072193759\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 238, train_loss = 3.196088522672653, train_acc = 0.9931299487657196\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 239, train_loss = 3.1805924787186086, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 240, train_loss = 3.165144357830286, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 241, train_loss = 3.1498288861475885, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 242, train_loss = 3.1347871921025217, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 243, train_loss = 3.1197942052967846, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 244, train_loss = 3.104939257260412, train_acc = 0.9934792734047508\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 245, train_loss = 3.0902737765572965, train_acc = 0.9935957149510946\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 246, train_loss = 3.0755987311713398, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 247, train_loss = 3.061191653367132, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 248, train_loss = 3.046863241586834, train_acc = 0.993828598043782\n",
      "test Acc 0.9781191806331471:\n",
      "28th- epoch: 249, train_loss = 3.0327232968993485, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 250, train_loss = 3.018796865362674, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 251, train_loss = 3.0048122038133442, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 252, train_loss = 2.9909838647581637, train_acc = 0.993828598043782\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 253, train_loss = 2.977240202948451, train_acc = 0.9939450395901258\n",
      "test Acc 0.979050279329609:\n",
      "28th- epoch: 254, train_loss = 2.9637522283010185, train_acc = 0.9939450395901258\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 255, train_loss = 2.9503310471773148, train_acc = 0.9939450395901258\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 256, train_loss = 2.9369717347435653, train_acc = 0.9939450395901258\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 257, train_loss = 2.9237532722763717, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 258, train_loss = 2.9106899253092706, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 259, train_loss = 2.8976800944656134, train_acc = 0.994294364229157\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 260, train_loss = 2.884866505395621, train_acc = 0.9945272473218444\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 261, train_loss = 2.872068712487817, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 262, train_loss = 2.8594047888182104, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 263, train_loss = 2.8469704552553594, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 264, train_loss = 2.834586134646088, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 265, train_loss = 2.8222211063839495, train_acc = 0.9946436888681882\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 266, train_loss = 2.8100935355760157, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 267, train_loss = 2.798025948461145, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 268, train_loss = 2.786016456782818, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 269, train_loss = 2.7741188160143793, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 270, train_loss = 2.7624265626072884, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 271, train_loss = 2.7506890087388456, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 272, train_loss = 2.7392466166056693, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 273, train_loss = 2.7278246195055544, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 274, train_loss = 2.7165117897093296, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 275, train_loss = 2.7050463533960283, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 276, train_loss = 2.694109346717596, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 277, train_loss = 2.683070516679436, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 278, train_loss = 2.672190854791552, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 279, train_loss = 2.66121061751619, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 280, train_loss = 2.650599544402212, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 281, train_loss = 2.6398030393756926, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 282, train_loss = 2.629442295525223, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 283, train_loss = 2.618981335312128, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 284, train_loss = 2.608536581043154, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 285, train_loss = 2.5984322405420244, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 286, train_loss = 2.5881831981241703, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 287, train_loss = 2.5780578539706767, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 288, train_loss = 2.568118532653898, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 289, train_loss = 2.5582343824207783, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 290, train_loss = 2.548318362329155, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 291, train_loss = 2.538714984897524, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 292, train_loss = 2.528956497553736, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 293, train_loss = 2.5194415622390807, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 294, train_loss = 2.5098392218351364, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 295, train_loss = 2.5005642152391374, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 296, train_loss = 2.491178995463997, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 297, train_loss = 2.4817865914665163, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 298, train_loss = 2.472711396869272, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 299, train_loss = 2.4636299372650683, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 300, train_loss = 2.4545286744832993, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 301, train_loss = 2.4454696513712406, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 302, train_loss = 2.4368420490063727, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 303, train_loss = 2.4281194456852973, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 304, train_loss = 2.419587340205908, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 305, train_loss = 2.411061236169189, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 306, train_loss = 2.402369351591915, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 307, train_loss = 2.3941698991693556, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 308, train_loss = 2.3859159438870847, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 309, train_loss = 2.3776674419641495, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 310, train_loss = 2.3693968155421317, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 311, train_loss = 2.361381211783737, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 312, train_loss = 2.3533415063284338, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 313, train_loss = 2.3454738073050976, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 314, train_loss = 2.3376708950381726, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 315, train_loss = 2.32990899682045, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 316, train_loss = 2.322059157071635, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 317, train_loss = 2.314341799588874, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 318, train_loss = 2.3069394540507346, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 319, train_loss = 2.299370636465028, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 320, train_loss = 2.2919039863627404, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 321, train_loss = 2.284416115609929, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 322, train_loss = 2.2771492179017514, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 323, train_loss = 2.270026846555993, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 324, train_loss = 2.2626862477045506, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 325, train_loss = 2.255539022386074, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 326, train_loss = 2.2486380834598094, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 327, train_loss = 2.2414861854631454, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 328, train_loss = 2.234749327180907, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 329, train_loss = 2.2278257708530873, train_acc = 0.9947601304145319\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 330, train_loss = 2.22096320358105, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 331, train_loss = 2.2143115140497684, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 332, train_loss = 2.2075202066916972, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 333, train_loss = 2.2010148961562663, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 334, train_loss = 2.1945078931748867, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 335, train_loss = 2.187786191701889, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 336, train_loss = 2.1815963201224804, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 337, train_loss = 2.175050711957738, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 338, train_loss = 2.168830119073391, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 339, train_loss = 2.162569270702079, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 340, train_loss = 2.156294871121645, train_acc = 0.9948765719608756\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 341, train_loss = 2.1502386804204434, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 342, train_loss = 2.1440408031921834, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 343, train_loss = 2.1382253754418343, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 344, train_loss = 2.132190279662609, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 345, train_loss = 2.1261300034821033, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 346, train_loss = 2.1204815234523267, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 347, train_loss = 2.1144725393969566, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 348, train_loss = 2.108869622228667, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 349, train_loss = 2.102997075766325, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 350, train_loss = 2.0975210182368755, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 351, train_loss = 2.091910743387416, train_acc = 0.9949930135072194\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 352, train_loss = 2.0860858398955315, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 353, train_loss = 2.0808698895853013, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 354, train_loss = 2.075412171659991, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 355, train_loss = 2.069885278819129, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 356, train_loss = 2.06470296648331, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 357, train_loss = 2.059142156271264, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 358, train_loss = 2.0540649741888046, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 359, train_loss = 2.0487289987504482, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 360, train_loss = 2.043711153091863, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 361, train_loss = 2.0383962977211922, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 362, train_loss = 2.0335675042588264, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 363, train_loss = 2.028265369357541, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 364, train_loss = 2.023381181061268, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 365, train_loss = 2.0182577383238822, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 366, train_loss = 2.0135064385831356, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 367, train_loss = 2.0084606434684247, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 368, train_loss = 2.0038544461131096, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 369, train_loss = 1.9988344211596996, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 370, train_loss = 1.9941829207818955, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 371, train_loss = 1.9894765701610595, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 372, train_loss = 1.9846376553177834, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 373, train_loss = 1.9801726813893765, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 374, train_loss = 1.9755966502707452, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 375, train_loss = 1.9710048101842403, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 376, train_loss = 1.9663237892091274, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 377, train_loss = 1.9622008863370866, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 378, train_loss = 1.957470477791503, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 379, train_loss = 1.9532143746037036, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 380, train_loss = 1.948822770267725, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 381, train_loss = 1.9444128461182117, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 382, train_loss = 1.9402848046738654, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 383, train_loss = 1.935991222737357, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 384, train_loss = 1.9315990060567856, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 385, train_loss = 1.9276348624844104, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 386, train_loss = 1.9233839611988515, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 387, train_loss = 1.919104403583333, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 388, train_loss = 1.9152960975188762, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 389, train_loss = 1.9111621230840683, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 390, train_loss = 1.9069244016427547, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 391, train_loss = 1.9032605215907097, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 392, train_loss = 1.8993568073492497, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 393, train_loss = 1.895088082877919, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 394, train_loss = 1.8914365631062537, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 395, train_loss = 1.8874997000675648, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 396, train_loss = 1.8836121410131454, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 397, train_loss = 1.8798448406159878, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 398, train_loss = 1.8762069542426616, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 399, train_loss = 1.8723696147790179, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 400, train_loss = 1.8684276019921526, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 401, train_loss = 1.8650090247392654, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 402, train_loss = 1.8610648649046198, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 403, train_loss = 1.8578327683499083, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 404, train_loss = 1.8540525175631046, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 405, train_loss = 1.8504453612258658, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 406, train_loss = 1.8466692852089182, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 407, train_loss = 1.8436203201999888, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 408, train_loss = 1.8397464578738436, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 409, train_loss = 1.8362837930908427, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 410, train_loss = 1.8329648971557617, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 411, train_loss = 1.8294616291532293, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 412, train_loss = 1.8260884123155847, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 413, train_loss = 1.8227675246307626, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 414, train_loss = 1.8192750215530396, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 415, train_loss = 1.81577769422438, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 416, train_loss = 1.8126080818474293, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 417, train_loss = 1.8093971274793148, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 418, train_loss = 1.8061400204896927, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 419, train_loss = 1.802886001765728, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 420, train_loss = 1.7998494803905487, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 421, train_loss = 1.7964999377727509, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 422, train_loss = 1.7934206972131506, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 423, train_loss = 1.7904652990400791, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 424, train_loss = 1.7869613766670227, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 425, train_loss = 1.7842514924705029, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 426, train_loss = 1.7810725346207619, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 427, train_loss = 1.7778227552771568, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 428, train_loss = 1.774991905898787, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 429, train_loss = 1.7719547661254182, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 430, train_loss = 1.769130157888867, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 431, train_loss = 1.76582470536232, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 432, train_loss = 1.7632744163274765, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 433, train_loss = 1.760005316347815, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 434, train_loss = 1.7575041564414278, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 435, train_loss = 1.7541699893772602, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 436, train_loss = 1.751859962940216, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 437, train_loss = 1.74856787675526, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 438, train_loss = 1.7458711924264207, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 439, train_loss = 1.7433500438928604, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 440, train_loss = 1.7401484748115763, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 441, train_loss = 1.7377995239803568, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 442, train_loss = 1.7348825918743387, train_acc = 0.9958081043316255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 443, train_loss = 1.7323128742864355, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 444, train_loss = 1.7295028964290395, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 445, train_loss = 1.727078472613357, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 446, train_loss = 1.7239977456629276, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 447, train_loss = 1.7217685543000698, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 448, train_loss = 1.7188083343207836, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 449, train_loss = 1.7165616241982207, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 450, train_loss = 1.713654302060604, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 451, train_loss = 1.7113768173148856, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 452, train_loss = 1.7086444000015035, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 453, train_loss = 1.7061296751489863, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 454, train_loss = 1.7036768905818462, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 455, train_loss = 1.7014350816607475, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 456, train_loss = 1.6984847957501188, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 457, train_loss = 1.6964328102767467, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 458, train_loss = 1.6937949719140306, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 459, train_loss = 1.6912268375745043, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 460, train_loss = 1.6889314005384222, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 461, train_loss = 1.686813622713089, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 462, train_loss = 1.6840210147202015, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 463, train_loss = 1.6821227619657293, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 464, train_loss = 1.6794940816471353, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 465, train_loss = 1.677121444256045, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 466, train_loss = 1.6748884407570586, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 467, train_loss = 1.6727668419480324, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 468, train_loss = 1.6702696084976196, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 469, train_loss = 1.667988176108338, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 470, train_loss = 1.6657421080162749, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 471, train_loss = 1.663499609916471, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 472, train_loss = 1.661339377402328, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 473, train_loss = 1.6591494852909818, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 474, train_loss = 1.6567871855804697, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 475, train_loss = 1.6547178426990286, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 476, train_loss = 1.65257116407156, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 477, train_loss = 1.650414615869522, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 478, train_loss = 1.648267988115549, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 479, train_loss = 1.6461427534231916, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 480, train_loss = 1.6440599424531683, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 481, train_loss = 1.6417226208141074, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 482, train_loss = 1.6399848846485838, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 483, train_loss = 1.6375352566828951, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 484, train_loss = 1.6357288137078285, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 485, train_loss = 1.6336835263064131, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 486, train_loss = 1.6314624896040186, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 487, train_loss = 1.6295694038271904, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 488, train_loss = 1.6276018371572718, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 489, train_loss = 1.6254824275383726, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 490, train_loss = 1.6233635867247358, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 491, train_loss = 1.6215965835144743, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 492, train_loss = 1.6193551383912563, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 493, train_loss = 1.6176961809396744, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 494, train_loss = 1.6157542951405048, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 495, train_loss = 1.613682720810175, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 496, train_loss = 1.6117353724548593, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 497, train_loss = 1.6097893913974985, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 498, train_loss = 1.608074693591334, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n",
      "28th- epoch: 499, train_loss = 1.6060939952731133, train_acc = 0.996040987424313\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████▏    | 28/30 [3:06:02<13:16, 398.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "29th- epoch: 0, train_loss = 275.7673946619034, train_acc = 0.41732650209594785\n",
      "test Acc 0.5065176908752328:\n",
      "29th- epoch: 1, train_loss = 210.9153974056244, train_acc = 0.49324639031206335\n",
      "test Acc 0.49906890130353815:\n",
      "29th- epoch: 2, train_loss = 168.0404088497162, train_acc = 0.5207265952491849\n",
      "test Acc 0.5577281191806331:\n",
      "29th- epoch: 3, train_loss = 146.58464908599854, train_acc = 0.621448532836516\n",
      "test Acc 0.6987895716945997:\n",
      "29th- epoch: 4, train_loss = 129.2891944050789, train_acc = 0.7157661853749417\n",
      "test Acc 0.7351024208566108:\n",
      "29th- epoch: 5, train_loss = 113.73839157819748, train_acc = 0.7396367023754076\n",
      "test Acc 0.7630353817504656:\n",
      "29th- epoch: 6, train_loss = 99.96630111336708, train_acc = 0.7796925943176526\n",
      "test Acc 0.8040037243947858:\n",
      "29th- epoch: 7, train_loss = 88.03788223862648, train_acc = 0.8171867722403353\n",
      "test Acc 0.8277467411545624:\n",
      "29th- epoch: 8, train_loss = 77.7258722782135, train_acc = 0.8444340940847694\n",
      "test Acc 0.8584729981378026:\n",
      "29th- epoch: 9, train_loss = 68.90003508329391, train_acc = 0.8683046110852353\n",
      "test Acc 0.8752327746741154:\n",
      "29th- epoch: 10, train_loss = 61.50794178247452, train_acc = 0.8801816488122962\n",
      "test Acc 0.8803538175046555:\n",
      "29th- epoch: 11, train_loss = 55.42822487652302, train_acc = 0.8876339077782953\n",
      "test Acc 0.8878026070763501:\n",
      "29th- epoch: 12, train_loss = 50.45522180199623, train_acc = 0.8964834653004192\n",
      "test Acc 0.8966480446927374:\n",
      "29th- epoch: 13, train_loss = 46.38154113292694, train_acc = 0.9078947368421053\n",
      "test Acc 0.9106145251396648:\n",
      "29th- epoch: 14, train_loss = 42.99633191525936, train_acc = 0.9204704238472287\n",
      "test Acc 0.9203910614525139:\n",
      "29th- epoch: 15, train_loss = 40.13941027224064, train_acc = 0.9295528644620401\n",
      "test Acc 0.9301675977653632:\n",
      "29th- epoch: 16, train_loss = 37.69505698978901, train_acc = 0.9360735910572893\n",
      "test Acc 0.9371508379888268:\n",
      "29th- epoch: 17, train_loss = 35.57725477218628, train_acc = 0.9409641360037261\n",
      "test Acc 0.9399441340782123:\n",
      "29th- epoch: 18, train_loss = 33.72431892901659, train_acc = 0.9444573823940382\n",
      "test Acc 0.9413407821229051:\n",
      "29th- epoch: 19, train_loss = 32.08885020762682, train_acc = 0.9460875640428504\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 20, train_loss = 30.634707652032375, train_acc = 0.9484163949697252\n",
      "test Acc 0.9445996275605214:\n",
      "29th- epoch: 21, train_loss = 29.33433996886015, train_acc = 0.9503959012575687\n",
      "test Acc 0.9459962756052142:\n",
      "29th- epoch: 22, train_loss = 28.16320861130953, train_acc = 0.9514438751746623\n",
      "test Acc 0.9464618249534451:\n",
      "29th- epoch: 23, train_loss = 27.104827530682087, train_acc = 0.9527247321844434\n",
      "test Acc 0.9487895716945997:\n",
      "29th- epoch: 24, train_loss = 26.145846121013165, train_acc = 0.9538891476478808\n",
      "test Acc 0.952048417132216:\n",
      "29th- epoch: 25, train_loss = 25.272147327661514, train_acc = 0.9551700046576619\n",
      "test Acc 0.9529795158286778:\n",
      "29th- epoch: 26, train_loss = 24.472692541778088, train_acc = 0.9569166278528178\n",
      "test Acc 0.9543761638733705:\n",
      "29th- epoch: 27, train_loss = 23.738538317382336, train_acc = 0.9579646017699115\n",
      "test Acc 0.9543761638733705:\n",
      "29th- epoch: 28, train_loss = 23.060486972332, train_acc = 0.9590125756870052\n",
      "test Acc 0.9553072625698324:\n",
      "29th- epoch: 29, train_loss = 22.431446835398674, train_acc = 0.9602934326967862\n",
      "test Acc 0.9567039106145251:\n",
      "29th- epoch: 30, train_loss = 21.844356197863817, train_acc = 0.9607591988821611\n",
      "test Acc 0.957635009310987:\n",
      "29th- epoch: 31, train_loss = 21.295221865177155, train_acc = 0.961690731252911\n",
      "test Acc 0.9581005586592178:\n",
      "29th- epoch: 32, train_loss = 20.779315307736397, train_acc = 0.962156497438286\n",
      "test Acc 0.9581005586592178:\n",
      "29th- epoch: 33, train_loss = 20.292995549738407, train_acc = 0.9628551467163484\n",
      "test Acc 0.9585661080074488:\n",
      "29th- epoch: 34, train_loss = 19.832874588668346, train_acc = 0.9632044713553796\n",
      "test Acc 0.9590316573556797:\n",
      "29th- epoch: 35, train_loss = 19.39743024855852, train_acc = 0.963903120633442\n",
      "test Acc 0.9590316573556797:\n",
      "29th- epoch: 36, train_loss = 18.984246637672186, train_acc = 0.9644853283651607\n",
      "test Acc 0.9590316573556797:\n",
      "29th- epoch: 37, train_loss = 18.591171119362116, train_acc = 0.9648346530041919\n",
      "test Acc 0.9590316573556797:\n",
      "29th- epoch: 38, train_loss = 18.21667107567191, train_acc = 0.9649510945505356\n",
      "test Acc 0.9590316573556797:\n",
      "29th- epoch: 39, train_loss = 17.859407670795918, train_acc = 0.9653004191895669\n",
      "test Acc 0.9590316573556797:\n",
      "29th- epoch: 40, train_loss = 17.5178514868021, train_acc = 0.9658826269212856\n",
      "test Acc 0.9590316573556797:\n",
      "29th- epoch: 41, train_loss = 17.19081422686577, train_acc = 0.9663483931066604\n",
      "test Acc 0.9599627560521415:\n",
      "29th- epoch: 42, train_loss = 16.877344872802496, train_acc = 0.966581276199348\n",
      "test Acc 0.9613594040968343:\n",
      "29th- epoch: 43, train_loss = 16.576343599706888, train_acc = 0.9671634839310667\n",
      "test Acc 0.9618249534450651:\n",
      "29th- epoch: 44, train_loss = 16.287252698093653, train_acc = 0.9672799254774104\n",
      "test Acc 0.9622905027932961:\n",
      "29th- epoch: 45, train_loss = 16.00850860401988, train_acc = 0.9682114578481602\n",
      "test Acc 0.962756052141527:\n",
      "29th- epoch: 46, train_loss = 15.739214420318604, train_acc = 0.9693758733115976\n",
      "test Acc 0.9636871508379888:\n",
      "29th- epoch: 47, train_loss = 15.479303535073996, train_acc = 0.9703074056823474\n",
      "test Acc 0.9641527001862198:\n",
      "29th- epoch: 48, train_loss = 15.228252910077572, train_acc = 0.9712389380530974\n",
      "test Acc 0.9641527001862198:\n",
      "29th- epoch: 49, train_loss = 14.98624500259757, train_acc = 0.9717047042384723\n",
      "test Acc 0.9641527001862198:\n",
      "29th- epoch: 50, train_loss = 14.75242167711258, train_acc = 0.9720540288775035\n",
      "test Acc 0.9641527001862198:\n",
      "29th- epoch: 51, train_loss = 14.526809493079782, train_acc = 0.9724033535165347\n",
      "test Acc 0.9641527001862198:\n",
      "29th- epoch: 52, train_loss = 14.308506963774562, train_acc = 0.9725197950628784\n",
      "test Acc 0.9650837988826816:\n",
      "29th- epoch: 53, train_loss = 14.096775501966476, train_acc = 0.9731020027945971\n",
      "test Acc 0.9655493482309124:\n",
      "29th- epoch: 54, train_loss = 13.890928689390421, train_acc = 0.9732184443409408\n",
      "test Acc 0.9660148975791434:\n",
      "29th- epoch: 55, train_loss = 13.69023733586073, train_acc = 0.9736842105263158\n",
      "test Acc 0.9660148975791434:\n",
      "29th- epoch: 56, train_loss = 13.495309878140688, train_acc = 0.9739170936190032\n",
      "test Acc 0.9660148975791434:\n",
      "29th- epoch: 57, train_loss = 13.306061331182718, train_acc = 0.9743828598043782\n",
      "test Acc 0.9674115456238361:\n",
      "29th- epoch: 58, train_loss = 13.122194338589907, train_acc = 0.9744993013507219\n",
      "test Acc 0.9674115456238361:\n",
      "29th- epoch: 59, train_loss = 12.943476643413305, train_acc = 0.9746157428970657\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 60, train_loss = 12.769882086664438, train_acc = 0.9746157428970657\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 61, train_loss = 12.601074393838644, train_acc = 0.9747321844434094\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 62, train_loss = 12.436437796801329, train_acc = 0.9748486259897532\n",
      "test Acc 0.9678770949720671:\n",
      "29th- epoch: 63, train_loss = 12.276036489754915, train_acc = 0.975314392175128\n",
      "test Acc 0.9674115456238361:\n",
      "29th- epoch: 64, train_loss = 12.11982273682952, train_acc = 0.976245924545878\n",
      "test Acc 0.9674115456238361:\n",
      "29th- epoch: 65, train_loss = 11.967523567378521, train_acc = 0.9765952491849091\n",
      "test Acc 0.9674115456238361:\n",
      "29th- epoch: 66, train_loss = 11.819074880331755, train_acc = 0.9768281322775967\n",
      "test Acc 0.9674115456238361:\n",
      "29th- epoch: 67, train_loss = 11.674205884337425, train_acc = 0.9774103400093154\n",
      "test Acc 0.9674115456238361:\n",
      "29th- epoch: 68, train_loss = 11.532677855342627, train_acc = 0.9776432231020028\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 69, train_loss = 11.394388683140278, train_acc = 0.977992547741034\n",
      "test Acc 0.9688081936685289:\n",
      "29th- epoch: 70, train_loss = 11.259068168699741, train_acc = 0.9782254308337215\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 71, train_loss = 11.127030849456787, train_acc = 0.9784583139264089\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 72, train_loss = 10.99792787246406, train_acc = 0.9785747554727526\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 73, train_loss = 10.871651366353035, train_acc = 0.9789240801117839\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 74, train_loss = 10.747815366834402, train_acc = 0.9789240801117839\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 75, train_loss = 10.626820806413889, train_acc = 0.9790405216581276\n",
      "test Acc 0.9697392923649907:\n",
      "29th- epoch: 76, train_loss = 10.507968036457896, train_acc = 0.9792734047508151\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 77, train_loss = 10.391476664692163, train_acc = 0.9792734047508151\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 78, train_loss = 10.277040112763643, train_acc = 0.9793898462971589\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 79, train_loss = 10.164548732340336, train_acc = 0.9796227293898463\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 80, train_loss = 10.052884873002768, train_acc = 0.97973917093619\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 81, train_loss = 9.942805407568812, train_acc = 0.9798556124825337\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 82, train_loss = 9.834722036495805, train_acc = 0.9798556124825337\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 83, train_loss = 9.729104828089476, train_acc = 0.9798556124825337\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 84, train_loss = 9.625668639317155, train_acc = 0.9798556124825337\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 85, train_loss = 9.524248197674751, train_acc = 0.9799720540288775\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 86, train_loss = 9.424522157758474, train_acc = 0.9800884955752213\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 87, train_loss = 9.32643410935998, train_acc = 0.980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 88, train_loss = 9.229988813400269, train_acc = 0.980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "29th- epoch: 89, train_loss = 9.134961403906345, train_acc = 0.9803213786679087\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 90, train_loss = 9.041494689881802, train_acc = 0.9803213786679087\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 91, train_loss = 8.949528208002448, train_acc = 0.9803213786679087\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 92, train_loss = 8.858950711786747, train_acc = 0.98067070330694\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 93, train_loss = 8.76990413479507, train_acc = 0.9810200279459711\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 94, train_loss = 8.68227731436491, train_acc = 0.9812529110386586\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 95, train_loss = 8.59591668471694, train_acc = 0.9818351187703773\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 96, train_loss = 8.510787101462483, train_acc = 0.9824173265020959\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 97, train_loss = 8.427058396860957, train_acc = 0.9825337680484397\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 98, train_loss = 8.344504497945309, train_acc = 0.9825337680484397\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 99, train_loss = 8.263095486909151, train_acc = 0.9827666511411272\n",
      "test Acc 0.9711359404096834:\n",
      "29th- epoch: 100, train_loss = 8.182744232937694, train_acc = 0.9827666511411272\n",
      "test Acc 0.9716014897579144:\n",
      "29th- epoch: 101, train_loss = 8.103689877316356, train_acc = 0.9832324173265021\n",
      "test Acc 0.9720670391061452:\n",
      "29th- epoch: 102, train_loss = 8.025722414255142, train_acc = 0.9833488588728458\n",
      "test Acc 0.9725325884543762:\n",
      "29th- epoch: 103, train_loss = 7.948813317343593, train_acc = 0.9834653004191896\n",
      "test Acc 0.9725325884543762:\n",
      "29th- epoch: 104, train_loss = 7.873007385060191, train_acc = 0.983698183511877\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 105, train_loss = 7.798244345933199, train_acc = 0.983698183511877\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 106, train_loss = 7.724502144381404, train_acc = 0.983698183511877\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 107, train_loss = 7.65192805416882, train_acc = 0.9838146250582208\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 108, train_loss = 7.580276707187295, train_acc = 0.9840475081509082\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 109, train_loss = 7.509350264444947, train_acc = 0.984163949697252\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 110, train_loss = 7.439616620540619, train_acc = 0.9842803912435957\n",
      "test Acc 0.973463687150838:\n",
      "29th- epoch: 111, train_loss = 7.370759686455131, train_acc = 0.9842803912435957\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 112, train_loss = 7.302930861711502, train_acc = 0.9845132743362832\n",
      "test Acc 0.9743947858472998:\n",
      "29th- epoch: 113, train_loss = 7.235935267060995, train_acc = 0.9846297158826269\n",
      "test Acc 0.9743947858472998:\n",
      "29th- epoch: 114, train_loss = 7.169917177408934, train_acc = 0.9850954820680019\n",
      "test Acc 0.9743947858472998:\n",
      "29th- epoch: 115, train_loss = 7.104814259335399, train_acc = 0.9853283651606893\n",
      "test Acc 0.9743947858472998:\n",
      "29th- epoch: 116, train_loss = 7.0404247138649225, train_acc = 0.9856776897997206\n",
      "test Acc 0.9743947858472998:\n",
      "29th- epoch: 117, train_loss = 6.977053876966238, train_acc = 0.985910572892408\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 118, train_loss = 6.914283553138375, train_acc = 0.9860270144387517\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 119, train_loss = 6.852494664490223, train_acc = 0.9860270144387517\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 120, train_loss = 6.7914445251226425, train_acc = 0.9860270144387517\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 121, train_loss = 6.731223294511437, train_acc = 0.9862598975314392\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 122, train_loss = 6.672028696164489, train_acc = 0.9862598975314392\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 123, train_loss = 6.613378904759884, train_acc = 0.9862598975314392\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 124, train_loss = 6.555493468418717, train_acc = 0.986376339077783\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 125, train_loss = 6.498409636318684, train_acc = 0.986376339077783\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 126, train_loss = 6.442291464656591, train_acc = 0.9864927806241267\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 127, train_loss = 6.386651691049337, train_acc = 0.9867256637168141\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 128, train_loss = 6.331854337826371, train_acc = 0.9864927806241267\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 129, train_loss = 6.277646187692881, train_acc = 0.9866092221704704\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 130, train_loss = 6.224362514913082, train_acc = 0.9869585468095017\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 131, train_loss = 6.171639604493976, train_acc = 0.9870749883558454\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 132, train_loss = 6.119626576080918, train_acc = 0.9871914299021891\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 133, train_loss = 6.06822457537055, train_acc = 0.9874243129948765\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 134, train_loss = 6.017678571864963, train_acc = 0.9874243129948765\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 135, train_loss = 5.967341246083379, train_acc = 0.9875407545412203\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 136, train_loss = 5.917943770065904, train_acc = 0.9876571960875641\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 137, train_loss = 5.869174690917134, train_acc = 0.9876571960875641\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 138, train_loss = 5.82114053145051, train_acc = 0.9877736376339078\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 139, train_loss = 5.773380981758237, train_acc = 0.9878900791802515\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 140, train_loss = 5.7266432121396065, train_acc = 0.9882394038192828\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 141, train_loss = 5.680211205035448, train_acc = 0.9882394038192828\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 142, train_loss = 5.634612280875444, train_acc = 0.9884722869119702\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 143, train_loss = 5.5894942078739405, train_acc = 0.9890544946436889\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 144, train_loss = 5.544853297993541, train_acc = 0.9890544946436889\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 145, train_loss = 5.501022608950734, train_acc = 0.9890544946436889\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 146, train_loss = 5.457431983202696, train_acc = 0.9892873777363763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 147, train_loss = 5.414584573358297, train_acc = 0.9892873777363763\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 148, train_loss = 5.3722118977457285, train_acc = 0.9892873777363763\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 149, train_loss = 5.3306344617158175, train_acc = 0.9892873777363763\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 150, train_loss = 5.289395308122039, train_acc = 0.9892873777363763\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 151, train_loss = 5.24854083172977, train_acc = 0.9892873777363763\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 152, train_loss = 5.208397878333926, train_acc = 0.9892873777363763\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 153, train_loss = 5.168599959462881, train_acc = 0.9892873777363763\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 154, train_loss = 5.1289146058261395, train_acc = 0.98940381928272\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 155, train_loss = 5.090080805122852, train_acc = 0.98940381928272\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 156, train_loss = 5.05143915489316, train_acc = 0.9895202608290639\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 157, train_loss = 5.013491550460458, train_acc = 0.9896367023754076\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 158, train_loss = 4.975962854921818, train_acc = 0.9896367023754076\n",
      "test Acc 0.9753258845437617:\n",
      "29th- epoch: 159, train_loss = 4.93934228643775, train_acc = 0.9897531439217513\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 160, train_loss = 4.902911379933357, train_acc = 0.9897531439217513\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 161, train_loss = 4.866964401677251, train_acc = 0.989869585468095\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 162, train_loss = 4.83157710917294, train_acc = 0.9899860270144387\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 163, train_loss = 4.796605641022325, train_acc = 0.9899860270144387\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 164, train_loss = 4.7619270067662, train_acc = 0.9899860270144387\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 165, train_loss = 4.727827639319003, train_acc = 0.9899860270144387\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 166, train_loss = 4.694063394330442, train_acc = 0.9902189101071263\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 167, train_loss = 4.660582848824561, train_acc = 0.9902189101071263\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 168, train_loss = 4.627755499444902, train_acc = 0.99033535165347\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 169, train_loss = 4.595393222756684, train_acc = 0.9905682347461574\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 170, train_loss = 4.563096287660301, train_acc = 0.990801117838845\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 171, train_loss = 4.531404646113515, train_acc = 0.990801117838845\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 172, train_loss = 4.500066207721829, train_acc = 0.990801117838845\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 173, train_loss = 4.4690715949982405, train_acc = 0.9909175593851887\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 174, train_loss = 4.438355701975524, train_acc = 0.9909175593851887\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 175, train_loss = 4.408292687498033, train_acc = 0.9910340009315324\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 176, train_loss = 4.3783306665718555, train_acc = 0.9911504424778761\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 177, train_loss = 4.348784419707954, train_acc = 0.9911504424778761\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 178, train_loss = 4.319796140305698, train_acc = 0.9911504424778761\n",
      "test Acc 0.9781191806331471:\n",
      "29th- epoch: 179, train_loss = 4.290970276109874, train_acc = 0.9911504424778761\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 180, train_loss = 4.262405380606651, train_acc = 0.9912668840242198\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 181, train_loss = 4.23416877631098, train_acc = 0.9912668840242198\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 182, train_loss = 4.206392983905971, train_acc = 0.9912668840242198\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 183, train_loss = 4.178874548524618, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 184, train_loss = 4.151727909222245, train_acc = 0.9913833255705635\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 185, train_loss = 4.124828963540494, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 186, train_loss = 4.0984601164236665, train_acc = 0.9914997671169073\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 187, train_loss = 4.072371243499219, train_acc = 0.9916162086632511\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 188, train_loss = 4.046507120132446, train_acc = 0.9916162086632511\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 189, train_loss = 4.021021090447903, train_acc = 0.9916162086632511\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 190, train_loss = 3.995940671302378, train_acc = 0.9917326502095948\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 191, train_loss = 3.9711358984932303, train_acc = 0.9917326502095948\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 192, train_loss = 3.9465436404570937, train_acc = 0.9917326502095948\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 193, train_loss = 3.922232103534043, train_acc = 0.9918490917559385\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 194, train_loss = 3.8982334276661277, train_acc = 0.9918490917559385\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 195, train_loss = 3.8745777113363147, train_acc = 0.9919655333022822\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 196, train_loss = 3.8511137375608087, train_acc = 0.9919655333022822\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 197, train_loss = 3.8278569132089615, train_acc = 0.992081974848626\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 198, train_loss = 3.805133760906756, train_acc = 0.9921984163949698\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 199, train_loss = 3.782333567738533, train_acc = 0.9921984163949698\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 200, train_loss = 3.760154642164707, train_acc = 0.9924312994876572\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 201, train_loss = 3.7379223378375173, train_acc = 0.9924312994876572\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 202, train_loss = 3.71604538988322, train_acc = 0.9924312994876572\n",
      "test Acc 0.9799813780260708:\n",
      "29th- epoch: 203, train_loss = 3.694522044621408, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 204, train_loss = 3.673144780099392, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 205, train_loss = 3.6521143717691302, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 206, train_loss = 3.6311055347323418, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 207, train_loss = 3.610471406020224, train_acc = 0.9924312994876572\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 208, train_loss = 3.5901354355737567, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 209, train_loss = 3.5697991587221622, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 210, train_loss = 3.549945008009672, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 211, train_loss = 3.530098434537649, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 212, train_loss = 3.510522522032261, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 213, train_loss = 3.4913567965850234, train_acc = 0.9925477410340009\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 214, train_loss = 3.4721774933859706, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 215, train_loss = 3.4531870456412435, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 216, train_loss = 3.4345484292134643, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 217, train_loss = 3.4160448564216495, train_acc = 0.9926641825803446\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 218, train_loss = 3.3978357845917344, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 219, train_loss = 3.379712348803878, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 220, train_loss = 3.361728404648602, train_acc = 0.9927806241266884\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 221, train_loss = 3.344026056583971, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 222, train_loss = 3.326576668769121, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 223, train_loss = 3.3092510905116796, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 224, train_loss = 3.2919413526542485, train_acc = 0.9928970656730322\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 225, train_loss = 3.2750116512179375, train_acc = 0.9930135072193759\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 226, train_loss = 3.25806791940704, train_acc = 0.9933628318584071\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 227, train_loss = 3.2415232192724943, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 228, train_loss = 3.224894300568849, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 229, train_loss = 3.2086676922626793, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 230, train_loss = 3.1925782025791705, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 231, train_loss = 3.1764823850244284, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 232, train_loss = 3.1606393097899854, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 233, train_loss = 3.1450209617614746, train_acc = 0.9934792734047508\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 234, train_loss = 3.1294679692946374, train_acc = 0.9935957149510946\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 235, train_loss = 3.1141547062434256, train_acc = 0.9935957149510946\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 236, train_loss = 3.0988055714406073, train_acc = 0.9935957149510946\n",
      "test Acc 0.9809124767225326:\n",
      "29th- epoch: 237, train_loss = 3.0838044439442456, train_acc = 0.9935957149510946\n",
      "test Acc 0.9809124767225326:\n",
      "29th- epoch: 238, train_loss = 3.068943440914154, train_acc = 0.9935957149510946\n",
      "test Acc 0.9809124767225326:\n",
      "29th- epoch: 239, train_loss = 3.054032661486417, train_acc = 0.9935957149510946\n",
      "test Acc 0.9809124767225326:\n",
      "29th- epoch: 240, train_loss = 3.039487120229751, train_acc = 0.9937121564974383\n",
      "test Acc 0.9809124767225326:\n",
      "29th- epoch: 241, train_loss = 3.0248839906416833, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "29th- epoch: 242, train_loss = 3.010618491563946, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "29th- epoch: 243, train_loss = 2.9963250779546797, train_acc = 0.993828598043782\n",
      "test Acc 0.9809124767225326:\n",
      "29th- epoch: 244, train_loss = 2.9824278778396547, train_acc = 0.993828598043782\n",
      "test Acc 0.9813780260707635:\n",
      "29th- epoch: 245, train_loss = 2.968476960901171, train_acc = 0.993828598043782\n",
      "test Acc 0.9813780260707635:\n",
      "29th- epoch: 246, train_loss = 2.9545960961841047, train_acc = 0.993828598043782\n",
      "test Acc 0.9813780260707635:\n",
      "29th- epoch: 247, train_loss = 2.9409665600396693, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 248, train_loss = 2.927409393247217, train_acc = 0.9939450395901258\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 249, train_loss = 2.9140385179780424, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 250, train_loss = 2.9007749832235277, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 251, train_loss = 2.887595310807228, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 252, train_loss = 2.8746179663576186, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 253, train_loss = 2.86161228409037, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 254, train_loss = 2.8489863597787917, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 255, train_loss = 2.8362646983005106, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 256, train_loss = 2.8237470067106187, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 257, train_loss = 2.811302825808525, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 258, train_loss = 2.799041642341763, train_acc = 0.9944108057755007\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 259, train_loss = 2.786824708338827, train_acc = 0.9944108057755007\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 260, train_loss = 2.7747829644940794, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 261, train_loss = 2.762867023702711, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 262, train_loss = 2.7509512319229543, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 263, train_loss = 2.739291048143059, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 264, train_loss = 2.7276579192839563, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 265, train_loss = 2.7161934613250196, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 266, train_loss = 2.704729734454304, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 267, train_loss = 2.693438459187746, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 268, train_loss = 2.6822114237584174, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 269, train_loss = 2.6711420975625515, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 270, train_loss = 2.660083765629679, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 271, train_loss = 2.649301455821842, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 272, train_loss = 2.638553111348301, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 273, train_loss = 2.6277600550092757, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 274, train_loss = 2.617102516349405, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 275, train_loss = 2.6067033647559583, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 276, train_loss = 2.596287631895393, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 277, train_loss = 2.5859794379211962, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 278, train_loss = 2.5758162797428668, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 279, train_loss = 2.565670917276293, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 280, train_loss = 2.5556348338723183, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 281, train_loss = 2.5457658865489066, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 282, train_loss = 2.5360194728709757, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 283, train_loss = 2.5263092517852783, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 284, train_loss = 2.51665531238541, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 285, train_loss = 2.507127869874239, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 286, train_loss = 2.497590916696936, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 287, train_loss = 2.4883156097494066, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 288, train_loss = 2.4789905385114253, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 289, train_loss = 2.469844490289688, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 290, train_loss = 2.4607097334228456, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 291, train_loss = 2.4517116346396506, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 292, train_loss = 2.442843060940504, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 293, train_loss = 2.4339634268544614, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 294, train_loss = 2.4252407997846603, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 295, train_loss = 2.4165189415216446, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 296, train_loss = 2.407874384429306, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 297, train_loss = 2.3993550068698823, train_acc = 0.9945272473218444\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 298, train_loss = 2.391035373089835, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 299, train_loss = 2.3826660874765366, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 300, train_loss = 2.374355923384428, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 301, train_loss = 2.3661893606185913, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 302, train_loss = 2.3579881961923093, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 303, train_loss = 2.349989488720894, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 304, train_loss = 2.342099318979308, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 305, train_loss = 2.3341677400749177, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 306, train_loss = 2.32624863833189, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 307, train_loss = 2.3187340174335986, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 308, train_loss = 2.3109539051074535, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 309, train_loss = 2.3034009013790637, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 310, train_loss = 2.2959116536658257, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 311, train_loss = 2.2883891202509403, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 312, train_loss = 2.280962976394221, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 313, train_loss = 2.273718796670437, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 314, train_loss = 2.26655953633599, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 315, train_loss = 2.259325832128525, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 316, train_loss = 2.2521351773757488, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 317, train_loss = 2.2452443677466363, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 318, train_loss = 2.2382374852895737, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 319, train_loss = 2.231369885383174, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 320, train_loss = 2.2244380328338593, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 321, train_loss = 2.2176602706313133, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 322, train_loss = 2.2110349126160145, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 323, train_loss = 2.2042861592490226, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 324, train_loss = 2.1978074957150966, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 325, train_loss = 2.191172906430438, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 326, train_loss = 2.184792010812089, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 327, train_loss = 2.1783231273293495, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 328, train_loss = 2.1719552527647465, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 329, train_loss = 2.165785266784951, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 330, train_loss = 2.159477885812521, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 331, train_loss = 2.153351495740935, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 332, train_loss = 2.1471383173484355, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 333, train_loss = 2.141164629487321, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 334, train_loss = 2.135146789252758, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 335, train_loss = 2.12915392476134, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 336, train_loss = 2.123295685974881, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 337, train_loss = 2.117383901029825, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 338, train_loss = 2.1117172862868756, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 339, train_loss = 2.1059943835716695, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 340, train_loss = 2.1003020245116204, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 341, train_loss = 2.0947103884536773, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 342, train_loss = 2.0890401005744934, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 343, train_loss = 2.0835391618311405, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 344, train_loss = 2.0780475076753646, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 345, train_loss = 2.0725810180883855, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 346, train_loss = 2.067181336460635, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 347, train_loss = 2.0618025846779346, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 348, train_loss = 2.056594190420583, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 349, train_loss = 2.0512564070522785, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 350, train_loss = 2.0461919978260994, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 351, train_loss = 2.040939373197034, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 352, train_loss = 2.0357259039301425, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 353, train_loss = 2.030717248795554, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 354, train_loss = 2.0256649393122643, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 355, train_loss = 2.0206653724890202, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 356, train_loss = 2.0156849536579102, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 357, train_loss = 2.010773827554658, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 358, train_loss = 2.005961611866951, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 359, train_loss = 2.001135937869549, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 360, train_loss = 1.9963203470688313, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 361, train_loss = 1.9916592452209443, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 362, train_loss = 1.9868278354406357, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 363, train_loss = 1.9821758281905204, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 364, train_loss = 1.9775858633220196, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 365, train_loss = 1.973043640377, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 366, train_loss = 1.9684244096279144, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 367, train_loss = 1.9639015707653016, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 368, train_loss = 1.959380389424041, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 369, train_loss = 1.9549513112287968, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 370, train_loss = 1.9505552288610488, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 371, train_loss = 1.9462058655917645, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 372, train_loss = 1.9419084340333939, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 373, train_loss = 1.9375084936618805, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 374, train_loss = 1.9333491188008338, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 375, train_loss = 1.9290609408635646, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 376, train_loss = 1.9249112631659955, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 377, train_loss = 1.9208174869418144, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 378, train_loss = 1.9166638429742306, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 379, train_loss = 1.9125373165588826, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 380, train_loss = 1.9084303751587868, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 381, train_loss = 1.9044535558205098, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 382, train_loss = 1.9005570970475674, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 383, train_loss = 1.8965612787287682, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 384, train_loss = 1.8925295372027904, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 385, train_loss = 1.8887167100328952, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 386, train_loss = 1.8847906962037086, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 387, train_loss = 1.8810505904257298, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 388, train_loss = 1.8771519860019907, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 389, train_loss = 1.8734186254441738, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 390, train_loss = 1.8695990107953548, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 391, train_loss = 1.8659255616366863, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 392, train_loss = 1.8622289201011881, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 393, train_loss = 1.8585896901786327, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 394, train_loss = 1.8549142057308927, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 395, train_loss = 1.8512676171958447, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 396, train_loss = 1.8477122485637665, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 397, train_loss = 1.8442381905624643, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 398, train_loss = 1.840683601796627, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 399, train_loss = 1.8371899649500847, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 400, train_loss = 1.8337240405380726, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 401, train_loss = 1.8302117846906185, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 402, train_loss = 1.8268172902753577, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 403, train_loss = 1.8234754601726308, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 404, train_loss = 1.8201056271791458, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 405, train_loss = 1.8168029325315729, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 406, train_loss = 1.813393246382475, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 407, train_loss = 1.810192427248694, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 408, train_loss = 1.8069695072481409, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 409, train_loss = 1.8036517513683066, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 410, train_loss = 1.8004415929317474, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 411, train_loss = 1.7971838228404522, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 412, train_loss = 1.7940928315510973, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 413, train_loss = 1.7910182401537895, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 414, train_loss = 1.787841159850359, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 415, train_loss = 1.7846898970892653, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 416, train_loss = 1.7816344437887892, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 417, train_loss = 1.7785607589175925, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 418, train_loss = 1.775536596775055, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 419, train_loss = 1.7724584700772539, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 420, train_loss = 1.7695893483469263, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 421, train_loss = 1.7666083984076977, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 422, train_loss = 1.7636166537413374, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 423, train_loss = 1.7607161229243502, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 424, train_loss = 1.7577929645776749, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 425, train_loss = 1.7548975212266669, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 426, train_loss = 1.7520595043897629, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 427, train_loss = 1.7492442466318607, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 428, train_loss = 1.7463364837458357, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 429, train_loss = 1.7435829974710941, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 430, train_loss = 1.740789587260224, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 431, train_loss = 1.7380627220263705, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 432, train_loss = 1.7352727092802525, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 433, train_loss = 1.7325599690666422, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 434, train_loss = 1.7298738086828962, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 435, train_loss = 1.7271989161381498, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 436, train_loss = 1.7244603658327833, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 437, train_loss = 1.7218108189990744, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 438, train_loss = 1.719146080315113, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 439, train_loss = 1.716642688959837, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 440, train_loss = 1.7139395599951968, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 441, train_loss = 1.7114318050444126, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 442, train_loss = 1.7088113414356485, train_acc = 0.9958081043316255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 443, train_loss = 1.7063042236259207, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 444, train_loss = 1.7037390632322058, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 445, train_loss = 1.701180413365364, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 446, train_loss = 1.6987917883088812, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 447, train_loss = 1.6963404156267643, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 448, train_loss = 1.6937873462447897, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 449, train_loss = 1.6913082847604528, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 450, train_loss = 1.6889853155007586, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 451, train_loss = 1.6866096196463332, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 452, train_loss = 1.6841698326170444, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 453, train_loss = 1.6816993044922128, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 454, train_loss = 1.6794664015760645, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 455, train_loss = 1.6770747750997543, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 456, train_loss = 1.6747862560441718, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 457, train_loss = 1.6724995659897104, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 458, train_loss = 1.6701833991101012, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 459, train_loss = 1.6679048041114584, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 460, train_loss = 1.665538796572946, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 461, train_loss = 1.6633929535746574, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 462, train_loss = 1.661147829145193, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 463, train_loss = 1.658907175064087, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 464, train_loss = 1.6567808663239703, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 465, train_loss = 1.6544232865562662, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 466, train_loss = 1.6523569710552692, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 467, train_loss = 1.650142808794044, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 468, train_loss = 1.6480675960192457, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 469, train_loss = 1.645912138163112, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 470, train_loss = 1.643768072128296, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 471, train_loss = 1.6416207030415535, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 472, train_loss = 1.6396133216330782, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 473, train_loss = 1.637533733039163, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 474, train_loss = 1.6354596056044102, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 475, train_loss = 1.6333291878690943, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 476, train_loss = 1.6313271969556808, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 477, train_loss = 1.629354503005743, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 478, train_loss = 1.6272719675907865, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 479, train_loss = 1.6253254674375057, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 480, train_loss = 1.6232847770443186, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 481, train_loss = 1.6212176779517904, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 482, train_loss = 1.6193192539503798, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 483, train_loss = 1.6175163151929155, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 484, train_loss = 1.61538775509689, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 485, train_loss = 1.6135471822926775, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 486, train_loss = 1.6116112247109413, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 487, train_loss = 1.6096225591609254, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 488, train_loss = 1.607859699637629, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 489, train_loss = 1.6058514267206192, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 490, train_loss = 1.6039992943406105, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 491, train_loss = 1.6022424945840612, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 492, train_loss = 1.6002616373589262, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 493, train_loss = 1.59845856949687, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 494, train_loss = 1.596658861846663, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 495, train_loss = 1.594849077402614, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 496, train_loss = 1.5930643355241045, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 497, train_loss = 1.5911580733954906, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 498, train_loss = 1.5895546823740005, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "29th- epoch: 499, train_loss = 1.5876492646639235, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████▌  | 29/30 [3:12:41<06:38, 398.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "30th- epoch: 0, train_loss = 275.2713733911514, train_acc = 0.4310666045645086\n",
      "test Acc 0.4860335195530726:\n",
      "30th- epoch: 1, train_loss = 213.03013241291046, train_acc = 0.4889380530973451\n",
      "test Acc 0.49394785847299816:\n",
      "30th- epoch: 2, train_loss = 169.12113535404205, train_acc = 0.504424778761062\n",
      "test Acc 0.5619180633147114:\n",
      "30th- epoch: 3, train_loss = 145.5456187725067, train_acc = 0.6403120633442012\n",
      "test Acc 0.6918063314711359:\n",
      "30th- epoch: 4, train_loss = 127.2639799118042, train_acc = 0.7102934326967862\n",
      "test Acc 0.7281191806331471:\n",
      "30th- epoch: 5, train_loss = 111.69275951385498, train_acc = 0.7423148579413135\n",
      "test Acc 0.7686219739292365:\n",
      "30th- epoch: 6, train_loss = 98.41777011752129, train_acc = 0.7833022822543083\n",
      "test Acc 0.7951582867783985:\n",
      "30th- epoch: 7, train_loss = 87.09753957390785, train_acc = 0.8162552398695855\n",
      "test Acc 0.8198324022346368:\n",
      "30th- epoch: 8, train_loss = 77.37160724401474, train_acc = 0.8408244061481136\n",
      "test Acc 0.8533519553072626:\n",
      "30th- epoch: 9, train_loss = 69.02940219640732, train_acc = 0.8653935724266418\n",
      "test Acc 0.8761638733705773:\n",
      "30th- epoch: 10, train_loss = 61.9540029168129, train_acc = 0.8794829995342338\n",
      "test Acc 0.8845437616387337:\n",
      "30th- epoch: 11, train_loss = 56.01994517445564, train_acc = 0.8900791802515138\n",
      "test Acc 0.8910614525139665:\n",
      "30th- epoch: 12, train_loss = 51.08709117770195, train_acc = 0.8962505822077317\n",
      "test Acc 0.8947858472998138:\n",
      "30th- epoch: 13, train_loss = 46.98166561126709, train_acc = 0.905798789007918\n",
      "test Acc 0.9110800744878957:\n",
      "30th- epoch: 14, train_loss = 43.537083461880684, train_acc = 0.9188402421984164\n",
      "test Acc 0.9231843575418994:\n",
      "30th- epoch: 15, train_loss = 40.61754335463047, train_acc = 0.9287377736376339\n",
      "test Acc 0.9273743016759777:\n",
      "30th- epoch: 16, train_loss = 38.10628788173199, train_acc = 0.9335118770377271\n",
      "test Acc 0.9352886405959032:\n",
      "30th- epoch: 17, train_loss = 35.92380380630493, train_acc = 0.9395668374476013\n",
      "test Acc 0.9404096834264432:\n",
      "30th- epoch: 18, train_loss = 34.01932377368212, train_acc = 0.9438751746623195\n",
      "test Acc 0.9422718808193669:\n",
      "30th- epoch: 19, train_loss = 32.34965171664953, train_acc = 0.945854680950163\n",
      "test Acc 0.9450651769087524:\n",
      "30th- epoch: 20, train_loss = 30.869315683841705, train_acc = 0.9486492780624126\n",
      "test Acc 0.9478584729981379:\n",
      "30th- epoch: 21, train_loss = 29.555760391056538, train_acc = 0.9507452258965999\n",
      "test Acc 0.9492551210428305:\n",
      "30th- epoch: 22, train_loss = 28.379775784909725, train_acc = 0.9516767582673498\n",
      "test Acc 0.9497206703910615:\n",
      "30th- epoch: 23, train_loss = 27.32094145566225, train_acc = 0.9536562645551933\n",
      "test Acc 0.9506517690875232:\n",
      "30th- epoch: 24, train_loss = 26.35940073430538, train_acc = 0.9547042384722869\n",
      "test Acc 0.9511173184357542:\n",
      "30th- epoch: 25, train_loss = 25.481234587728977, train_acc = 0.9551700046576619\n",
      "test Acc 0.9511173184357542:\n",
      "30th- epoch: 26, train_loss = 24.675950400531292, train_acc = 0.956450861667443\n",
      "test Acc 0.952513966480447:\n",
      "30th- epoch: 27, train_loss = 23.933494344353676, train_acc = 0.9578481602235678\n",
      "test Acc 0.9529795158286778:\n",
      "30th- epoch: 28, train_loss = 23.245149191468954, train_acc = 0.9585468095016302\n",
      "test Acc 0.9543761638733705:\n",
      "30th- epoch: 29, train_loss = 22.602971121668816, train_acc = 0.9593619003260363\n",
      "test Acc 0.9548417132216015:\n",
      "30th- epoch: 30, train_loss = 22.00132490694523, train_acc = 0.959944108057755\n",
      "test Acc 0.9553072625698324:\n",
      "30th- epoch: 31, train_loss = 21.438937041908503, train_acc = 0.9608756404285049\n",
      "test Acc 0.9553072625698324:\n",
      "30th- epoch: 32, train_loss = 20.90997327491641, train_acc = 0.9614578481602236\n",
      "test Acc 0.9557728119180633:\n",
      "30th- epoch: 33, train_loss = 20.41152197495103, train_acc = 0.9620400558919422\n",
      "test Acc 0.9567039106145251:\n",
      "30th- epoch: 34, train_loss = 19.941243644803762, train_acc = 0.9626222636236609\n",
      "test Acc 0.957169459962756:\n",
      "30th- epoch: 35, train_loss = 19.496882613748312, train_acc = 0.9634373544480671\n",
      "test Acc 0.9581005586592178:\n",
      "30th- epoch: 36, train_loss = 19.075122874230146, train_acc = 0.9644853283651607\n",
      "test Acc 0.9585661080074488:\n",
      "30th- epoch: 37, train_loss = 18.674053102731705, train_acc = 0.9647182114578482\n",
      "test Acc 0.9590316573556797:\n",
      "30th- epoch: 38, train_loss = 18.292297929525375, train_acc = 0.9651839776432231\n",
      "test Acc 0.9599627560521415:\n",
      "30th- epoch: 39, train_loss = 17.927622377872467, train_acc = 0.965649743828598\n",
      "test Acc 0.9604283054003724:\n",
      "30th- epoch: 40, train_loss = 17.57890536636114, train_acc = 0.966115510013973\n",
      "test Acc 0.9613594040968343:\n",
      "30th- epoch: 41, train_loss = 17.245450492948294, train_acc = 0.9668141592920354\n",
      "test Acc 0.9618249534450651:\n",
      "30th- epoch: 42, train_loss = 16.925596207380295, train_acc = 0.9673963670237541\n",
      "test Acc 0.962756052141527:\n",
      "30th- epoch: 43, train_loss = 16.618552792817354, train_acc = 0.9677456916627852\n",
      "test Acc 0.9636871508379888:\n",
      "30th- epoch: 44, train_loss = 16.323337115347385, train_acc = 0.9687936655798789\n",
      "test Acc 0.9646182495344506:\n",
      "30th- epoch: 45, train_loss = 16.03872972726822, train_acc = 0.969608756404285\n",
      "test Acc 0.9646182495344506:\n",
      "30th- epoch: 46, train_loss = 15.764100778847933, train_acc = 0.9704238472286912\n",
      "test Acc 0.9650837988826816:\n",
      "30th- epoch: 47, train_loss = 15.498988136649132, train_acc = 0.9714718211457848\n",
      "test Acc 0.9655493482309124:\n",
      "30th- epoch: 48, train_loss = 15.243221338838339, train_acc = 0.9717047042384723\n",
      "test Acc 0.9660148975791434:\n",
      "30th- epoch: 49, train_loss = 14.996027525514364, train_acc = 0.971821145784816\n",
      "test Acc 0.9664804469273743:\n",
      "30th- epoch: 50, train_loss = 14.757059127092361, train_acc = 0.9724033535165347\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 51, train_loss = 14.525751996785402, train_acc = 0.9725197950628784\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 52, train_loss = 14.301748000085354, train_acc = 0.9729855612482534\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 53, train_loss = 14.083922285586596, train_acc = 0.9733348858872846\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 54, train_loss = 13.87223955988884, train_acc = 0.9738006520726595\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 55, train_loss = 13.666880697011948, train_acc = 0.9739170936190032\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 56, train_loss = 13.4676214158535, train_acc = 0.974033535165347\n",
      "test Acc 0.9674115456238361:\n",
      "30th- epoch: 57, train_loss = 13.274261061102152, train_acc = 0.9743828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 58, train_loss = 13.085863530635834, train_acc = 0.9749650675360969\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 59, train_loss = 12.902711912989616, train_acc = 0.975314392175128\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 60, train_loss = 12.724671576172113, train_acc = 0.9755472752678156\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 61, train_loss = 12.551238441839814, train_acc = 0.975780158360503\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 62, train_loss = 12.382696652784944, train_acc = 0.9758965999068467\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 63, train_loss = 12.218482067808509, train_acc = 0.9761294829995343\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 64, train_loss = 12.058634435757995, train_acc = 0.9763623660922217\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 65, train_loss = 11.90270434319973, train_acc = 0.9763623660922217\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 66, train_loss = 11.750751066952944, train_acc = 0.9765952491849091\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 67, train_loss = 11.60243360325694, train_acc = 0.9765952491849091\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 68, train_loss = 11.457649946212769, train_acc = 0.9765952491849091\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 69, train_loss = 11.316422771662474, train_acc = 0.9765952491849091\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 70, train_loss = 11.178189411759377, train_acc = 0.9771774569166278\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 71, train_loss = 11.043203566223383, train_acc = 0.9771774569166278\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 72, train_loss = 10.911215838044882, train_acc = 0.9772938984629715\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 73, train_loss = 10.782194282859564, train_acc = 0.9775267815556591\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 74, train_loss = 10.655949905514717, train_acc = 0.9776432231020028\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 75, train_loss = 10.532698037102818, train_acc = 0.9777596646483465\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 76, train_loss = 10.4121287278831, train_acc = 0.977992547741034\n",
      "test Acc 0.9678770949720671:\n",
      "30th- epoch: 77, train_loss = 10.294098446145654, train_acc = 0.9781089892873778\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 78, train_loss = 10.178397834300995, train_acc = 0.9784583139264089\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 79, train_loss = 10.06498209759593, train_acc = 0.9785747554727526\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 80, train_loss = 9.953851422294974, train_acc = 0.9786911970190965\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 81, train_loss = 9.844839811325073, train_acc = 0.9789240801117839\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 82, train_loss = 9.73789918795228, train_acc = 0.9790405216581276\n",
      "test Acc 0.9688081936685289:\n",
      "30th- epoch: 83, train_loss = 9.633097495883703, train_acc = 0.9790405216581276\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 84, train_loss = 9.530112486332655, train_acc = 0.9791569632044713\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 85, train_loss = 9.429131023585796, train_acc = 0.9793898462971589\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 86, train_loss = 9.330026429146528, train_acc = 0.9795062878435026\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 87, train_loss = 9.232638850808144, train_acc = 0.9798556124825337\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 88, train_loss = 9.136816766113043, train_acc = 0.9798556124825337\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 89, train_loss = 9.042716234922409, train_acc = 0.9800884955752213\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 90, train_loss = 8.950207352638245, train_acc = 0.980204937121565\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 91, train_loss = 8.859286900609732, train_acc = 0.9804378202142524\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 92, train_loss = 8.76978761330247, train_acc = 0.9810200279459711\n",
      "test Acc 0.9706703910614525:\n",
      "30th- epoch: 93, train_loss = 8.681761767715216, train_acc = 0.9813693525850024\n",
      "test Acc 0.9706703910614525:\n",
      "30th- epoch: 94, train_loss = 8.595174074172974, train_acc = 0.9816022356776898\n",
      "test Acc 0.9706703910614525:\n",
      "30th- epoch: 95, train_loss = 8.509952016174793, train_acc = 0.9821844434094085\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 96, train_loss = 8.425930760800838, train_acc = 0.9824173265020959\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 97, train_loss = 8.343159854412079, train_acc = 0.9831159757801584\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 98, train_loss = 8.261673780158162, train_acc = 0.9833488588728458\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 99, train_loss = 8.181287521496415, train_acc = 0.9835817419655333\n",
      "test Acc 0.9711359404096834:\n",
      "30th- epoch: 100, train_loss = 8.102314904332161, train_acc = 0.983698183511877\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 101, train_loss = 8.02425742521882, train_acc = 0.9838146250582208\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 102, train_loss = 7.947442281991243, train_acc = 0.9839310666045645\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 103, train_loss = 7.871824331581593, train_acc = 0.9840475081509082\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 104, train_loss = 7.797305582091212, train_acc = 0.984163949697252\n",
      "test Acc 0.9725325884543762:\n",
      "30th- epoch: 105, train_loss = 7.724011750891805, train_acc = 0.984163949697252\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 106, train_loss = 7.651667948812246, train_acc = 0.9842803912435957\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 107, train_loss = 7.580411372706294, train_acc = 0.9842803912435957\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 108, train_loss = 7.509711092337966, train_acc = 0.9843968327899395\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 109, train_loss = 7.440026776865125, train_acc = 0.9845132743362832\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 110, train_loss = 7.371446814388037, train_acc = 0.9846297158826269\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 111, train_loss = 7.3039535991847515, train_acc = 0.9845132743362832\n",
      "test Acc 0.9739292364990689:\n",
      "30th- epoch: 112, train_loss = 7.237431196495891, train_acc = 0.9848625989753144\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 113, train_loss = 7.1717045698314905, train_acc = 0.9853283651606893\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 114, train_loss = 7.106823751702905, train_acc = 0.9853283651606893\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 115, train_loss = 7.042876413092017, train_acc = 0.985444806707033\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 116, train_loss = 6.979629181325436, train_acc = 0.985444806707033\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 117, train_loss = 6.916954200714827, train_acc = 0.985444806707033\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 118, train_loss = 6.855279861018062, train_acc = 0.985444806707033\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 119, train_loss = 6.794429171830416, train_acc = 0.9855612482533768\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 120, train_loss = 6.734413893893361, train_acc = 0.9856776897997206\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 121, train_loss = 6.67524141445756, train_acc = 0.9857941313460643\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 122, train_loss = 6.616686763241887, train_acc = 0.9860270144387517\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 123, train_loss = 6.559047255665064, train_acc = 0.9860270144387517\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 124, train_loss = 6.502170670777559, train_acc = 0.9861434559850955\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 125, train_loss = 6.445988176390529, train_acc = 0.9862598975314392\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 126, train_loss = 6.390323534607887, train_acc = 0.986376339077783\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 127, train_loss = 6.335433289408684, train_acc = 0.986376339077783\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 128, train_loss = 6.281524581834674, train_acc = 0.986376339077783\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 129, train_loss = 6.228079024702311, train_acc = 0.9864927806241267\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 130, train_loss = 6.175337439402938, train_acc = 0.9868421052631579\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 131, train_loss = 6.123070003464818, train_acc = 0.9874243129948765\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 132, train_loss = 6.071746880188584, train_acc = 0.9877736376339078\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 133, train_loss = 6.021048063412309, train_acc = 0.9878900791802515\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 134, train_loss = 5.970942907035351, train_acc = 0.9881229622729389\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 135, train_loss = 5.921400496736169, train_acc = 0.9881229622729389\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 136, train_loss = 5.872446050867438, train_acc = 0.9881229622729389\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 137, train_loss = 5.824003450572491, train_acc = 0.9882394038192828\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 138, train_loss = 5.776267161592841, train_acc = 0.9883558453656265\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 139, train_loss = 5.72908029705286, train_acc = 0.9883558453656265\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 140, train_loss = 5.6824729554355145, train_acc = 0.9883558453656265\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 141, train_loss = 5.636514950543642, train_acc = 0.9885887284583139\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 142, train_loss = 5.591047106310725, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 143, train_loss = 5.546078549697995, train_acc = 0.9887051700046576\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 144, train_loss = 5.501682003960013, train_acc = 0.9888216115510013\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 145, train_loss = 5.45771823450923, train_acc = 0.9890544946436889\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 146, train_loss = 5.414478091523051, train_acc = 0.9891709361900326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 147, train_loss = 5.371825840324163, train_acc = 0.9891709361900326\n",
      "test Acc 0.9767225325884544:\n",
      "30th- epoch: 148, train_loss = 5.329595686867833, train_acc = 0.9892873777363763\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 149, train_loss = 5.287959480658174, train_acc = 0.98940381928272\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 150, train_loss = 5.246806509792805, train_acc = 0.9895202608290639\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 151, train_loss = 5.206104272976518, train_acc = 0.9896367023754076\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 152, train_loss = 5.165956640616059, train_acc = 0.9897531439217513\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 153, train_loss = 5.126281833276153, train_acc = 0.9901024685607824\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 154, train_loss = 5.087077563628554, train_acc = 0.9901024685607824\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 155, train_loss = 5.048450026661158, train_acc = 0.9902189101071263\n",
      "test Acc 0.9771880819366853:\n",
      "30th- epoch: 156, train_loss = 5.010287370532751, train_acc = 0.99033535165347\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 157, train_loss = 4.9725838750600815, train_acc = 0.99033535165347\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 158, train_loss = 4.935324021615088, train_acc = 0.9904517931998137\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 159, train_loss = 4.898603635840118, train_acc = 0.9905682347461574\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 160, train_loss = 4.862372889183462, train_acc = 0.9905682347461574\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 161, train_loss = 4.826509022153914, train_acc = 0.9905682347461574\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 162, train_loss = 4.791124312207103, train_acc = 0.9905682347461574\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 163, train_loss = 4.756040939129889, train_acc = 0.9905682347461574\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 164, train_loss = 4.721498536877334, train_acc = 0.9905682347461574\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 165, train_loss = 4.6874903393909335, train_acc = 0.9905682347461574\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 166, train_loss = 4.653792682103813, train_acc = 0.9905682347461574\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 167, train_loss = 4.620479884557426, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 168, train_loss = 4.587519608438015, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 169, train_loss = 4.555044682696462, train_acc = 0.9906846762925011\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 170, train_loss = 4.522894104011357, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 171, train_loss = 4.49127082247287, train_acc = 0.9909175593851887\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 172, train_loss = 4.459871758706868, train_acc = 0.9910340009315324\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 173, train_loss = 4.428956679068506, train_acc = 0.9910340009315324\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 174, train_loss = 4.39830704126507, train_acc = 0.9911504424778761\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 175, train_loss = 4.367823103442788, train_acc = 0.9911504424778761\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 176, train_loss = 4.337948927655816, train_acc = 0.9911504424778761\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 177, train_loss = 4.30855595972389, train_acc = 0.9911504424778761\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 178, train_loss = 4.279406088404357, train_acc = 0.9911504424778761\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 179, train_loss = 4.250669713132083, train_acc = 0.9912668840242198\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 180, train_loss = 4.222191545180976, train_acc = 0.9913833255705635\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 181, train_loss = 4.194105866365135, train_acc = 0.9913833255705635\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 182, train_loss = 4.166527269408107, train_acc = 0.9913833255705635\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 183, train_loss = 4.139084798283875, train_acc = 0.9913833255705635\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 184, train_loss = 4.11198456492275, train_acc = 0.9913833255705635\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 185, train_loss = 4.085291163064539, train_acc = 0.9913833255705635\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 186, train_loss = 4.05886444542557, train_acc = 0.9913833255705635\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 187, train_loss = 4.032811291515827, train_acc = 0.9913833255705635\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 188, train_loss = 4.0068391766399145, train_acc = 0.9914997671169073\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 189, train_loss = 3.981429065577686, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 190, train_loss = 3.956140692345798, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 191, train_loss = 3.9312023064121604, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 192, train_loss = 3.90663446392864, train_acc = 0.9916162086632511\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 193, train_loss = 3.882304131053388, train_acc = 0.9917326502095948\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 194, train_loss = 3.858376025222242, train_acc = 0.9917326502095948\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 195, train_loss = 3.8344766721129417, train_acc = 0.9917326502095948\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 196, train_loss = 3.811065354384482, train_acc = 0.9917326502095948\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 197, train_loss = 3.787762896157801, train_acc = 0.9918490917559385\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 198, train_loss = 3.764860681258142, train_acc = 0.9919655333022822\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 199, train_loss = 3.742113792337477, train_acc = 0.9919655333022822\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 200, train_loss = 3.719616557471454, train_acc = 0.992081974848626\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 201, train_loss = 3.6974552012979984, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 202, train_loss = 3.675356563180685, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 203, train_loss = 3.6538469446823, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 204, train_loss = 3.6324918186292052, train_acc = 0.9923148579413135\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 205, train_loss = 3.6112847654148936, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 206, train_loss = 3.590369083918631, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 207, train_loss = 3.5695398142561316, train_acc = 0.9924312994876572\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 208, train_loss = 3.549177810549736, train_acc = 0.9924312994876572\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 209, train_loss = 3.5288475938141346, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 210, train_loss = 3.5087528778240085, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 211, train_loss = 3.4890523366630077, train_acc = 0.9925477410340009\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 212, train_loss = 3.469406221061945, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 213, train_loss = 3.4500127909705043, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 214, train_loss = 3.430818504653871, train_acc = 0.9926641825803446\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 215, train_loss = 3.4118407890200615, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 216, train_loss = 3.393029810860753, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 217, train_loss = 3.374456823337823, train_acc = 0.9927806241266884\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 218, train_loss = 3.355992190539837, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 219, train_loss = 3.3378826598636806, train_acc = 0.9928970656730322\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 220, train_loss = 3.3198131415992975, train_acc = 0.9931299487657196\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 221, train_loss = 3.3020870480686426, train_acc = 0.9931299487657196\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 222, train_loss = 3.2843815800733864, train_acc = 0.9931299487657196\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 223, train_loss = 3.267095854971558, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 224, train_loss = 3.2497302410192788, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 225, train_loss = 3.2327132672071457, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 226, train_loss = 3.2158412504941225, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 227, train_loss = 3.199184389319271, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 228, train_loss = 3.1825389214791358, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 229, train_loss = 3.1662509008310735, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 230, train_loss = 3.15003516478464, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 231, train_loss = 3.134020166937262, train_acc = 0.9932463903120633\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 232, train_loss = 3.118070111144334, train_acc = 0.9933628318584071\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 233, train_loss = 3.102345658931881, train_acc = 0.9934792734047508\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 234, train_loss = 3.086803786456585, train_acc = 0.9934792734047508\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 235, train_loss = 3.0713855414651334, train_acc = 0.9935957149510946\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 236, train_loss = 3.0561261791735888, train_acc = 0.9935957149510946\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 237, train_loss = 3.0410755961202085, train_acc = 0.9937121564974383\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 238, train_loss = 3.026052442844957, train_acc = 0.9937121564974383\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 239, train_loss = 3.0112590813077986, train_acc = 0.9937121564974383\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 240, train_loss = 2.9965609163045883, train_acc = 0.9937121564974383\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 241, train_loss = 2.9820473566651344, train_acc = 0.9937121564974383\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 242, train_loss = 2.967616055626422, train_acc = 0.9937121564974383\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 243, train_loss = 2.9535180684179068, train_acc = 0.993828598043782\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 244, train_loss = 2.9392929286696017, train_acc = 0.993828598043782\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 245, train_loss = 2.92548486078158, train_acc = 0.993828598043782\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 246, train_loss = 2.9115371056832373, train_acc = 0.9940614811364695\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 247, train_loss = 2.897845095489174, train_acc = 0.9940614811364695\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 248, train_loss = 2.8843180746771395, train_acc = 0.9940614811364695\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 249, train_loss = 2.8709314055740833, train_acc = 0.9940614811364695\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 250, train_loss = 2.8576370552182198, train_acc = 0.9941779226828132\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 251, train_loss = 2.8444170407019556, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 252, train_loss = 2.8313175016082823, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 253, train_loss = 2.818582206964493, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 254, train_loss = 2.805600095540285, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 255, train_loss = 2.7929023802280426, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 256, train_loss = 2.780406830366701, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 257, train_loss = 2.76790060242638, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 258, train_loss = 2.7557036988437176, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 259, train_loss = 2.7434472092427313, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 260, train_loss = 2.7314807497896254, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 261, train_loss = 2.7195746055804193, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 262, train_loss = 2.7078777216374874, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 263, train_loss = 2.69611182436347, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 264, train_loss = 2.684539135545492, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 265, train_loss = 2.6731412732042372, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 266, train_loss = 2.6618319577537477, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 267, train_loss = 2.6505253040231764, train_acc = 0.9946436888681882\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 268, train_loss = 2.6393954032100737, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "30th- epoch: 269, train_loss = 2.628460959997028, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 270, train_loss = 2.617483770940453, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 271, train_loss = 2.6066347644664347, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 272, train_loss = 2.596078757196665, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 273, train_loss = 2.5854999125003815, train_acc = 0.9945272473218444\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 274, train_loss = 2.5749867423437536, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 275, train_loss = 2.564385339617729, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 276, train_loss = 2.554192463401705, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 277, train_loss = 2.5442195124924183, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 278, train_loss = 2.534026015549898, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 279, train_loss = 2.5240615815855563, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 280, train_loss = 2.514221398625523, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 281, train_loss = 2.504403834696859, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 282, train_loss = 2.494786072522402, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 283, train_loss = 2.4851779243908823, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 284, train_loss = 2.475741036236286, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 285, train_loss = 2.4663427933119237, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 286, train_loss = 2.457020422909409, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 287, train_loss = 2.4478472718037665, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 288, train_loss = 2.4386745928786695, train_acc = 0.9946436888681882\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 289, train_loss = 2.4298237548209727, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 290, train_loss = 2.4207986420951784, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 291, train_loss = 2.412004182813689, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 292, train_loss = 2.4032502670306712, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 293, train_loss = 2.3945558902341872, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 294, train_loss = 2.3860559600871056, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 295, train_loss = 2.3775465909857303, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 296, train_loss = 2.369074770482257, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 297, train_loss = 2.3608074449002743, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 298, train_loss = 2.3524290062487125, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 299, train_loss = 2.344393915263936, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 300, train_loss = 2.3362799745518714, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 301, train_loss = 2.3283372186124325, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 302, train_loss = 2.3204438511747867, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 303, train_loss = 2.312483962625265, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 304, train_loss = 2.3048480090219527, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 305, train_loss = 2.297138759167865, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 306, train_loss = 2.2895231172442436, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 307, train_loss = 2.282011080533266, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 308, train_loss = 2.274457187624648, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 309, train_loss = 2.2672211427707225, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 310, train_loss = 2.259912883164361, train_acc = 0.9947601304145319\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 311, train_loss = 2.2525944027584046, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 312, train_loss = 2.2455146436113864, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 313, train_loss = 2.238301020115614, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 314, train_loss = 2.2313636306207627, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 315, train_loss = 2.2241994838695973, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 316, train_loss = 2.217447283444926, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 317, train_loss = 2.210549010662362, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 318, train_loss = 2.203853988321498, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 319, train_loss = 2.197072486160323, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 320, train_loss = 2.1904134440701455, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 321, train_loss = 2.183883650926873, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 322, train_loss = 2.1773127801716328, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 323, train_loss = 2.1708808913826942, train_acc = 0.9948765719608756\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 324, train_loss = 2.1645845100283623, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 325, train_loss = 2.158268799306825, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 326, train_loss = 2.151959699811414, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 327, train_loss = 2.145737963495776, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 328, train_loss = 2.139541147975251, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 329, train_loss = 2.133459698408842, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 330, train_loss = 2.1274999666493386, train_acc = 0.9949930135072194\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 331, train_loss = 2.1214925285894424, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 332, train_loss = 2.115552044240758, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 333, train_loss = 2.10979217546992, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 334, train_loss = 2.1037909958977252, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 335, train_loss = 2.0981269876938313, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 336, train_loss = 2.092217080295086, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 337, train_loss = 2.086629302473739, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 338, train_loss = 2.081094489665702, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 339, train_loss = 2.0754564579110593, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 340, train_loss = 2.0700690646190196, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 341, train_loss = 2.06444430234842, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 342, train_loss = 2.0589988057035953, train_acc = 0.9951094550535631\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 343, train_loss = 2.053732631029561, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 344, train_loss = 2.04852615413256, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 345, train_loss = 2.0431204475462437, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 346, train_loss = 2.037934221327305, train_acc = 0.9952258965999069\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 347, train_loss = 2.0327303882222623, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 348, train_loss = 2.027625296264887, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 349, train_loss = 2.022498960373923, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 350, train_loss = 2.017500090179965, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 351, train_loss = 2.0123925048392266, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 352, train_loss = 2.0076470721978694, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 353, train_loss = 2.002667846856639, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 354, train_loss = 1.9978732701856643, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 355, train_loss = 1.9929286788683385, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 356, train_loss = 1.988144564209506, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 357, train_loss = 1.9834750641603023, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 358, train_loss = 1.9787267234642059, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 359, train_loss = 1.974081599386409, train_acc = 0.9953423381462506\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 360, train_loss = 1.9694739244878292, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 361, train_loss = 1.9648624833207577, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 362, train_loss = 1.9603304888587445, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 363, train_loss = 1.9558048769831657, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 364, train_loss = 1.9513719950336963, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 365, train_loss = 1.9468850754201412, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 366, train_loss = 1.942645374685526, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 367, train_loss = 1.9381097815930843, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 368, train_loss = 1.9337291840929538, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 369, train_loss = 1.929635898442939, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 370, train_loss = 1.9253120757639408, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 371, train_loss = 1.9212191116530448, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 372, train_loss = 1.9168628242332488, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 373, train_loss = 1.9127249494194984, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 374, train_loss = 1.9086917962413281, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 375, train_loss = 1.9045263330917805, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 376, train_loss = 1.9004965536296368, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 377, train_loss = 1.8963482877006754, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 378, train_loss = 1.892461964278482, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 379, train_loss = 1.8884518990525976, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 380, train_loss = 1.8845713870832697, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 381, train_loss = 1.8806534769246355, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 382, train_loss = 1.8767947728047147, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 383, train_loss = 1.872984278947115, train_acc = 0.9956916627852818\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 384, train_loss = 1.8691218992462382, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 385, train_loss = 1.8653507754206657, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 386, train_loss = 1.861673685372807, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 387, train_loss = 1.8579385118791834, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 388, train_loss = 1.8542161931982264, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 389, train_loss = 1.8506359880557284, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 390, train_loss = 1.8469429425895214, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 391, train_loss = 1.8434108222136274, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 392, train_loss = 1.839739814400673, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 393, train_loss = 1.836271908134222, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 394, train_loss = 1.8326199278235435, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 395, train_loss = 1.8293540900340304, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 396, train_loss = 1.8257472863188013, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 397, train_loss = 1.822481887997128, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 398, train_loss = 1.818934710114263, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 399, train_loss = 1.8155714297899976, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 400, train_loss = 1.81229018419981, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 401, train_loss = 1.8088327447185293, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 402, train_loss = 1.8055082199862227, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 403, train_loss = 1.802161280065775, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 404, train_loss = 1.799049629480578, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 405, train_loss = 1.79565452656243, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 406, train_loss = 1.792472817003727, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 407, train_loss = 1.7894084801664576, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 408, train_loss = 1.7861694482853636, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 409, train_loss = 1.7830395748605952, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 410, train_loss = 1.779981318861246, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 411, train_loss = 1.7767401722958311, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 412, train_loss = 1.7737029927084222, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 413, train_loss = 1.7707933014025912, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 414, train_loss = 1.7677614527055994, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 415, train_loss = 1.7645504052052274, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 416, train_loss = 1.7617599293589592, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 417, train_loss = 1.7586979158222675, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 418, train_loss = 1.7558611308922991, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 419, train_loss = 1.752999639720656, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 420, train_loss = 1.7500374255469069, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 421, train_loss = 1.7471542259445414, train_acc = 0.9958081043316255\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 422, train_loss = 1.7442978993058205, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 423, train_loss = 1.7414818853139877, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 424, train_loss = 1.7385937968501821, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 425, train_loss = 1.7359832910588011, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 426, train_loss = 1.7331110300729051, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 427, train_loss = 1.730274343281053, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 428, train_loss = 1.7277741730213165, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 429, train_loss = 1.7248672446003184, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 430, train_loss = 1.7222024922957644, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 431, train_loss = 1.719712570309639, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 432, train_loss = 1.7168597554555163, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 433, train_loss = 1.7143719432642683, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 434, train_loss = 1.711651990772225, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 435, train_loss = 1.709013925283216, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 436, train_loss = 1.7065457639982924, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 437, train_loss = 1.7039073618361726, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 438, train_loss = 1.701354437856935, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 439, train_loss = 1.6989503105869517, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 440, train_loss = 1.6963718546321616, train_acc = 0.9958081043316255\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 441, train_loss = 1.6938021531095728, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 442, train_loss = 1.6914973743259907, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 443, train_loss = 1.6888603493571281, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 444, train_loss = 1.6865647746017203, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 445, train_loss = 1.684096978395246, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 446, train_loss = 1.6815400483319536, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 447, train_loss = 1.6794153340160847, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 448, train_loss = 1.6767856801161543, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 449, train_loss = 1.6746051808586344, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 450, train_loss = 1.6721067851176485, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 451, train_loss = 1.6700031930813566, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 452, train_loss = 1.6674854630837217, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 453, train_loss = 1.665297083556652, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 454, train_loss = 1.6629164814949036, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 455, train_loss = 1.6607347117969766, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 456, train_loss = 1.658385444432497, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 457, train_loss = 1.6563300987472758, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 458, train_loss = 1.653953142464161, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 459, train_loss = 1.6518438583007082, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 460, train_loss = 1.6494723533978686, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 461, train_loss = 1.647423772723414, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 462, train_loss = 1.645242071361281, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 463, train_loss = 1.643178710131906, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 464, train_loss = 1.6410244380822405, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 465, train_loss = 1.6388535387814045, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 466, train_loss = 1.6367122320225462, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 467, train_loss = 1.6346073349704966, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 468, train_loss = 1.632530170143582, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 469, train_loss = 1.6306270187487826, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 470, train_loss = 1.628371370374225, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 471, train_loss = 1.626511643291451, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 472, train_loss = 1.6243040362605825, train_acc = 0.9959245458779693\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 473, train_loss = 1.6223393293330446, train_acc = 0.996040987424313\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 474, train_loss = 1.620314922183752, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 475, train_loss = 1.6183534438023344, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 476, train_loss = 1.6162701161811128, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 477, train_loss = 1.6144677536794916, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 478, train_loss = 1.6123106181621552, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 479, train_loss = 1.6104748472571373, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 480, train_loss = 1.6084806000581011, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 481, train_loss = 1.6067107865819708, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 482, train_loss = 1.6047183139016852, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 483, train_loss = 1.6028243066975847, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 484, train_loss = 1.6009000291815028, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 485, train_loss = 1.5991220163414255, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 486, train_loss = 1.5971952813561074, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 487, train_loss = 1.5953389492933638, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 488, train_loss = 1.5935084273223765, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 489, train_loss = 1.591731162101496, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 490, train_loss = 1.5899366711382754, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 491, train_loss = 1.5883395820856094, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 492, train_loss = 1.5862170209293254, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 493, train_loss = 1.5845913055236451, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 494, train_loss = 1.582825168967247, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 495, train_loss = 1.581218947947491, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 496, train_loss = 1.579313697933685, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 497, train_loss = 1.577582837373484, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 498, train_loss = 1.5757904698257335, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 499, train_loss = 1.5741685542161576, train_acc = 0.9961574289706567\n",
      "test Acc 0.9813780260707635:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 30/30 [3:19:19<00:00, 398.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3h 19min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    img_path = 'D:virus/image/2gram_512_pca/image_arr.npy'\n",
    "    label_path = 'D:virus/image/2gram_512_pca/label_arr.npy'\n",
    "    \n",
    "    data_a, label_a = np.load(img_path), np.load(label_path)\n",
    "    \n",
    "    idx = np.argsort(label_a)\n",
    "    \n",
    "    sorted_data = data_a[idx]\n",
    "    sorted_label = sorted(label_a)\n",
    "        \n",
    "    BATCH_SIZE = 64\n",
    "    TOTAL = 30\n",
    "    EPOCH = 500\n",
    "    NUM_CLASS = 9\n",
    "    LR = 0.005\n",
    "    SEED = [s for s in range(TOTAL)]\n",
    "    INPUT_NODES = 512                   \n",
    "    \n",
    "    CUDA_N = 'cuda:0'\n",
    "    \n",
    "    # creating data indices for spliting\n",
    "    full_dataset = CustomDataset(sorted_data, sorted_label)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # spliting\n",
    "    torch.manual_seed(10)\n",
    "    train_dataset, test_dataset = data.random_split(full_dataset, [train_size, test_size])\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    loss_total = []\n",
    "    acc_total = []\n",
    "    pred_total = []\n",
    "    true_total = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(TOTAL)):\n",
    "        \n",
    "        device = torch.device(CUDA_N if torch.cuda.is_available() else 'cpu')\n",
    "        torch.manual_seed(SEED[i])\n",
    "        net = Algorithm1(INPUT_NODES, NUM_CLASS)           \n",
    "        net.to(device)\n",
    "        print(net)\n",
    "        \n",
    "        softmax = nn.Softmax()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=LR, momentum = 0.1)\n",
    "        \n",
    "        loss_list = []\n",
    "        train_acc_list = []\n",
    "        test_acc_list = []\n",
    "        \n",
    "        pred_temp = []\n",
    "        true_temp = []\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            net.train()\n",
    "            running_loss = 0\n",
    "            total = train_size\n",
    "            correct = 0 \n",
    "            \n",
    "            for step, image_and_label in enumerate(train_loader):\n",
    "                inputs, labels = image_and_label            \n",
    "                inputs, labels = inputs.type(torch.FloatTensor).to(device), labels.type(torch.LongTensor).to(device)\n",
    "                \n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, pred = torch.max(outputs, dim=1)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            train_acc = correct/total\n",
    "            loss_list.append(running_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "            print('{}th- epoch: {}, train_loss = {}, train_acc = {}'.format(i+1, epoch, running_loss, train_acc))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                correct = 0\n",
    "                total = test_size\n",
    "                pt, tt = [], []\n",
    "                \n",
    "                for step_t, image_and_label_t in enumerate(test_loader):\n",
    "                    inputs_t, labels_t = image_and_label_t            \n",
    "                    inputs_t, labels_t = inputs_t.type(torch.FloatTensor).to(device), labels_t.type(torch.LongTensor).to(device)\n",
    "                    \n",
    "                    outputs_t = net(inputs_t)\n",
    "                    outputs_t = softmax(outputs_t)\n",
    "                    \n",
    "                    # test accuracy\n",
    "                    _, pred_t = torch.max(outputs_t, dim = 1)\n",
    "                    \n",
    "                    pt.append(pred_t)\n",
    "                    tt.append(labels_t)\n",
    "                    \n",
    "                    correct += (pred_t == labels_t).sum().item()\n",
    "                    \n",
    "                pred_temp.append(torch.cat(pt))\n",
    "                true_temp.append(torch.cat(tt))\n",
    "                \n",
    "                test_acc = correct/total\n",
    "                test_acc_list.append(test_acc)\n",
    "                \n",
    "                print('test Acc {}:'.format(test_acc))\n",
    "                \n",
    "        best_result_index = np.argmax(np.array(test_acc_list))\n",
    "        loss_total.append(loss_list[best_result_index])\n",
    "        acc_total.append(test_acc_list[best_result_index])\n",
    "        pred_total.append(pred_temp[best_result_index].tolist())\n",
    "        true_total.append(true_temp[best_result_index].tolist())\n",
    "        \n",
    "    file_name = 'res/Algorithm1_2gram'\n",
    "    torch.save(net.state_dict(), file_name +'.pth')\n",
    "    \n",
    "    loss_DF = pd.DataFrame(loss_total)\n",
    "    loss_DF.to_csv(file_name+\" loss.csv\")\n",
    "    \n",
    "    acc_DF = pd.DataFrame(acc_total)\n",
    "    acc_DF.to_csv(file_name +\" acc.csv\")\n",
    "    \n",
    "    pred_DF = pd.DataFrame(pred_total)\n",
    "    pred_DF.to_csv(file_name +\" pred.csv\")\n",
    "    \n",
    "    true_DF = pd.DataFrame(true_total)\n",
    "    true_DF.to_csv(file_name +\" true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
