{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import utility.Data_loader as D\n",
    "from utility.Model import Base\n",
    "from utility.Custom import CustomDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline 2gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                       | 0/10736 [00:00<?, ?it/s]\n",
      "  4%|███                                                                        | 435/10736 [00:00<00:02, 4318.50it/s]\n",
      "  9%|██████▌                                                                    | 931/10736 [00:00<00:02, 4483.93it/s]\n",
      " 13%|█████████▌                                                                | 1395/10736 [00:00<00:02, 4519.95it/s]\n",
      " 18%|████████████▉                                                             | 1884/10736 [00:00<00:01, 4615.40it/s]\n",
      " 21%|███████████████▊                                                          | 2294/10736 [00:00<00:01, 4436.84it/s]\n",
      " 25%|██████████████████▋                                                       | 2713/10736 [00:00<00:01, 4349.87it/s]\n",
      " 30%|█████████████████████▊                                                    | 3172/10736 [00:00<00:01, 4409.93it/s]\n",
      " 34%|█████████████████████████▎                                                | 3668/10736 [00:00<00:01, 4408.90it/s]\n",
      " 39%|████████████████████████████▊                                             | 4181/10736 [00:00<00:01, 4500.11it/s]\n",
      " 43%|███████████████████████████████▊                                          | 4615/10736 [00:01<00:01, 4302.60it/s]\n",
      " 47%|██████████████████████████████████▋                                       | 5036/10736 [00:01<00:01, 4091.63it/s]\n",
      " 51%|██████████████████████████████████████                                    | 5525/10736 [00:01<00:01, 4294.09it/s]\n",
      " 56%|█████████████████████████████████████████▏                                | 5971/10736 [00:01<00:01, 4331.09it/s]\n",
      " 60%|████████████████████████████████████████████▌                             | 6471/10736 [00:01<00:00, 4512.00it/s]\n",
      " 64%|███████████████████████████████████████████████▋                          | 6924/10736 [00:01<00:00, 4433.24it/s]\n",
      " 71%|████████████████████████████████████████████████████▎                     | 7583/10736 [00:01<00:00, 4759.21it/s]\n",
      " 77%|████████████████████████████████████████████████████████▋                 | 8225/10736 [00:01<00:00, 5036.98it/s]\n",
      " 82%|████████████████████████████████████████████████████████████▍             | 8765/10736 [00:01<00:00, 4982.91it/s]\n",
      " 86%|███████████████████████████████████████████████████████████████▉          | 9271/10736 [00:02<00:00, 4736.67it/s]\n",
      " 91%|███████████████████████████████████████████████████████████████████▏      | 9753/10736 [00:02<00:00, 4754.92it/s]\n",
      " 95%|█████████████████████████████████████████████████████████████████████▋   | 10250/10736 [00:02<00:00, 4807.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████▉| 10735/10736 [00:02<00:00, 4694.62it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 10736/10736 [00:02<00:00, 4611.24it/s]\n",
      "  0%|                                                                                          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "1th- epoch: 0, train_loss = 437.7357115447521, train_acc = 0.8015836050302748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DTools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:98: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.8449720670391061:\n",
      "1th- epoch: 1, train_loss = 76.71140099316835, train_acc = 0.9116208663251048\n",
      "test Acc 0.9185288640595903:\n",
      "1th- epoch: 2, train_loss = 49.811029298231006, train_acc = 0.9315323707498836\n",
      "test Acc 0.9287709497206704:\n",
      "1th- epoch: 3, train_loss = 36.609036672860384, train_acc = 0.9438751746623195\n",
      "test Acc 0.9408752327746741:\n",
      "1th- epoch: 4, train_loss = 28.84055909141898, train_acc = 0.9522589659990685\n",
      "test Acc 0.946927374301676:\n",
      "1th- epoch: 5, train_loss = 23.815698344260454, train_acc = 0.9585468095016302\n",
      "test Acc 0.9511173184357542:\n",
      "1th- epoch: 6, train_loss = 20.44900844991207, train_acc = 0.963903120633442\n",
      "test Acc 0.9557728119180633:\n",
      "1th- epoch: 7, train_loss = 17.943198543041945, train_acc = 0.9669306008383791\n",
      "test Acc 0.9553072625698324:\n",
      "1th- epoch: 8, train_loss = 15.83447863906622, train_acc = 0.9698416394969726\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 9, train_loss = 14.156963773071766, train_acc = 0.9721704704238472\n",
      "test Acc 0.957169459962756:\n",
      "1th- epoch: 10, train_loss = 12.714954420924187, train_acc = 0.9748486259897532\n",
      "test Acc 0.9581005586592178:\n",
      "1th- epoch: 11, train_loss = 11.527128603309393, train_acc = 0.9764788076385654\n",
      "test Acc 0.9590316573556797:\n",
      "1th- epoch: 12, train_loss = 10.51280108653009, train_acc = 0.977992547741034\n",
      "test Acc 0.9608938547486033:\n",
      "1th- epoch: 13, train_loss = 9.708578955382109, train_acc = 0.9804378202142524\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 14, train_loss = 9.04492642171681, train_acc = 0.9809035863996274\n",
      "test Acc 0.962756052141527:\n",
      "1th- epoch: 15, train_loss = 8.469662696123123, train_acc = 0.9821844434094085\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 16, train_loss = 7.923003686591983, train_acc = 0.9831159757801584\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 17, train_loss = 7.516642767935991, train_acc = 0.984163949697252\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 18, train_loss = 7.102552734315395, train_acc = 0.9853283651606893\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 19, train_loss = 6.755655989050865, train_acc = 0.9860270144387517\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 20, train_loss = 6.4466868825256824, train_acc = 0.9864927806241267\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 21, train_loss = 6.1631822027266026, train_acc = 0.9870749883558454\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 22, train_loss = 5.90138167142868, train_acc = 0.9876571960875641\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 23, train_loss = 5.664761987514794, train_acc = 0.9880065207265952\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 24, train_loss = 5.4514128575101495, train_acc = 0.9877736376339078\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 25, train_loss = 5.248016260564327, train_acc = 0.9884722869119702\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 26, train_loss = 5.059437063522637, train_acc = 0.9888216115510013\n",
      "test Acc 0.9641527001862198:\n",
      "1th- epoch: 27, train_loss = 4.889735403470695, train_acc = 0.9890544946436889\n",
      "test Acc 0.9646182495344506:\n",
      "1th- epoch: 28, train_loss = 4.750787377357483, train_acc = 0.9890544946436889\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 29, train_loss = 4.603748203255236, train_acc = 0.9892873777363763\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 30, train_loss = 4.48384440690279, train_acc = 0.9892873777363763\n",
      "test Acc 0.9655493482309124:\n",
      "1th- epoch: 31, train_loss = 4.351944147143513, train_acc = 0.98940381928272\n",
      "test Acc 0.9660148975791434:\n",
      "1th- epoch: 32, train_loss = 4.245727484114468, train_acc = 0.9896367023754076\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 33, train_loss = 4.133768692612648, train_acc = 0.9901024685607824\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 34, train_loss = 4.03788564959541, train_acc = 0.9901024685607824\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 35, train_loss = 3.9573556012474, train_acc = 0.9905682347461574\n",
      "test Acc 0.9669459962756052:\n",
      "1th- epoch: 36, train_loss = 3.8711926452815533, train_acc = 0.9905682347461574\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 37, train_loss = 3.7979513010941446, train_acc = 0.9906846762925011\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 38, train_loss = 3.7220222554169595, train_acc = 0.9906846762925011\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 39, train_loss = 3.6609960622154176, train_acc = 0.990801117838845\n",
      "test Acc 0.9678770949720671:\n",
      "1th- epoch: 40, train_loss = 3.5971775823272765, train_acc = 0.9911504424778761\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 41, train_loss = 3.5328870438970625, train_acc = 0.9911504424778761\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 42, train_loss = 3.473427554126829, train_acc = 0.9912668840242198\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 43, train_loss = 3.4176809987984598, train_acc = 0.9912668840242198\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 44, train_loss = 3.366476950701326, train_acc = 0.9914997671169073\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 45, train_loss = 3.323860531207174, train_acc = 0.9916162086632511\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 46, train_loss = 3.2731015705503523, train_acc = 0.9916162086632511\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 47, train_loss = 3.234815500676632, train_acc = 0.9919655333022822\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 48, train_loss = 3.1963000767864287, train_acc = 0.9919655333022822\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 49, train_loss = 3.154674429446459, train_acc = 0.9921984163949698\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 50, train_loss = 3.1225526940543205, train_acc = 0.9921984163949698\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 51, train_loss = 3.0883949249982834, train_acc = 0.9921984163949698\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 52, train_loss = 3.0576024539768696, train_acc = 0.9921984163949698\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 53, train_loss = 3.0298975619953126, train_acc = 0.9921984163949698\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 54, train_loss = 2.993030243786052, train_acc = 0.9921984163949698\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 55, train_loss = 2.979443362681195, train_acc = 0.9921984163949698\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 56, train_loss = 2.945249203592539, train_acc = 0.9924312994876572\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 57, train_loss = 2.9257716748397797, train_acc = 0.9925477410340009\n",
      "test Acc 0.9702048417132216:\n",
      "1th- epoch: 58, train_loss = 2.89597803237848, train_acc = 0.9926641825803446\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 59, train_loss = 2.8720782548189163, train_acc = 0.9926641825803446\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 60, train_loss = 2.8540641739964485, train_acc = 0.9926641825803446\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 61, train_loss = 2.8253268834669143, train_acc = 0.9927806241266884\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 62, train_loss = 2.8043987303972244, train_acc = 0.9926641825803446\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 63, train_loss = 2.784038492711261, train_acc = 0.9928970656730322\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 64, train_loss = 2.7606789506971836, train_acc = 0.9927806241266884\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 65, train_loss = 2.750114753842354, train_acc = 0.9928970656730322\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 66, train_loss = 2.729023028165102, train_acc = 0.9928970656730322\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 67, train_loss = 2.7078016388695687, train_acc = 0.9930135072193759\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 68, train_loss = 2.6983423705678433, train_acc = 0.9930135072193759\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 69, train_loss = 2.676691601751372, train_acc = 0.9931299487657196\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 70, train_loss = 2.6614565837662667, train_acc = 0.9933628318584071\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 71, train_loss = 2.6455735464114696, train_acc = 0.9932463903120633\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 72, train_loss = 2.6293714318890125, train_acc = 0.9932463903120633\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 73, train_loss = 2.6202832635026425, train_acc = 0.9933628318584071\n",
      "test Acc 0.9716014897579144:\n",
      "1th- epoch: 74, train_loss = 2.598987051518634, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 75, train_loss = 2.594751801341772, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "1th- epoch: 76, train_loss = 2.575121942907572, train_acc = 0.9933628318584071\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 77, train_loss = 2.571782535640523, train_acc = 0.9934792734047508\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 78, train_loss = 2.550562546821311, train_acc = 0.9933628318584071\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 79, train_loss = 2.544654702069238, train_acc = 0.9934792734047508\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 80, train_loss = 2.5201479245442897, train_acc = 0.9935957149510946\n",
      "test Acc 0.972998137802607:\n",
      "1th- epoch: 81, train_loss = 2.52011439204216, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "1th- epoch: 82, train_loss = 2.502516048727557, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "1th- epoch: 83, train_loss = 2.4940631065983325, train_acc = 0.9933628318584071\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 84, train_loss = 2.4857041761279106, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "1th- epoch: 85, train_loss = 2.47812441107817, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 86, train_loss = 2.4525370225310326, train_acc = 0.9935957149510946\n",
      "test Acc 0.972998137802607:\n",
      "1th- epoch: 87, train_loss = 2.4538558088243008, train_acc = 0.9934792734047508\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 88, train_loss = 2.429278453113511, train_acc = 0.9934792734047508\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 89, train_loss = 2.4267977699637413, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 90, train_loss = 2.4093212336301804, train_acc = 0.9934792734047508\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 91, train_loss = 2.3960878055077046, train_acc = 0.9934792734047508\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 92, train_loss = 2.394346675602719, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 93, train_loss = 2.3868674226105213, train_acc = 0.9935957149510946\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 94, train_loss = 2.3811063293833286, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 95, train_loss = 2.3664445467293262, train_acc = 0.9935957149510946\n",
      "test Acc 0.972998137802607:\n",
      "1th- epoch: 96, train_loss = 2.3713614034932107, train_acc = 0.9935957149510946\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 97, train_loss = 2.3549376118462533, train_acc = 0.9937121564974383\n",
      "test Acc 0.973463687150838:\n",
      "1th- epoch: 98, train_loss = 2.3466002816567197, train_acc = 0.9937121564974383\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 99, train_loss = 2.3404484590282664, train_acc = 0.9935957149510946\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 100, train_loss = 2.336410392075777, train_acc = 0.993828598043782\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 101, train_loss = 2.328748875646852, train_acc = 0.9940614811364695\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 102, train_loss = 2.320440015406348, train_acc = 0.9940614811364695\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 103, train_loss = 2.3181988609721884, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "1th- epoch: 104, train_loss = 2.306631986051798, train_acc = 0.9939450395901258\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 105, train_loss = 2.302051187842153, train_acc = 0.9941779226828132\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 106, train_loss = 2.2883649294963107, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 107, train_loss = 2.285928330034949, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 108, train_loss = 2.2773688273737207, train_acc = 0.9940614811364695\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 109, train_loss = 2.274425856769085, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 110, train_loss = 2.2601857284316793, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 111, train_loss = 2.2600118977716193, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 112, train_loss = 2.2549269708106294, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 113, train_loss = 2.2539084689924493, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 114, train_loss = 2.2441744891693816, train_acc = 0.9941779226828132\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 115, train_loss = 2.2371669908752665, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 116, train_loss = 2.2268479900667444, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 117, train_loss = 2.225422542542219, train_acc = 0.9940614811364695\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 118, train_loss = 2.224850522936322, train_acc = 0.9941779226828132\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 119, train_loss = 2.2203723242273554, train_acc = 0.9939450395901258\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 120, train_loss = 2.206577856093645, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 121, train_loss = 2.2062762876739725, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "1th- epoch: 122, train_loss = 2.2046080976724625, train_acc = 0.994294364229157\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 123, train_loss = 2.1943294344237074, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 124, train_loss = 2.185114166350104, train_acc = 0.994294364229157\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 125, train_loss = 2.1844094643602148, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 126, train_loss = 2.179689078242518, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 127, train_loss = 2.1809827461838722, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 128, train_loss = 2.1745572611689568, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 129, train_loss = 2.1638482796261087, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 130, train_loss = 2.167729770182632, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 131, train_loss = 2.160926735610701, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 132, train_loss = 2.1522065550088882, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 133, train_loss = 2.1564618920674548, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 134, train_loss = 2.152057584375143, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 135, train_loss = 2.1414412992307916, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 136, train_loss = 2.1431397745618597, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 137, train_loss = 2.131613222300075, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 138, train_loss = 2.1281607089331374, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 139, train_loss = 2.1344910860061646, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 140, train_loss = 2.1221082657575607, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 141, train_loss = 2.128852161229588, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 142, train_loss = 2.1169572584331036, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 143, train_loss = 2.118772432208061, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 144, train_loss = 2.111859153956175, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 145, train_loss = 2.106283288449049, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 146, train_loss = 2.1056731678545475, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 147, train_loss = 2.10736522951629, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 148, train_loss = 2.096734163700603, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 149, train_loss = 2.0967117896070704, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 150, train_loss = 2.0924228293588385, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 151, train_loss = 2.093161945580505, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 152, train_loss = 2.0937182133784518, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 153, train_loss = 2.085580031038262, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 154, train_loss = 2.076995834708214, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 155, train_loss = 2.0757258558878675, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 156, train_loss = 2.079241110594012, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 157, train_loss = 2.068815480917692, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 158, train_loss = 2.076916365593206, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 159, train_loss = 2.0654678927967325, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 160, train_loss = 2.0582026441697963, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 161, train_loss = 2.0623608504538424, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 162, train_loss = 2.0623272098600864, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 163, train_loss = 2.0571095682680607, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 164, train_loss = 2.052369157492649, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 165, train_loss = 2.050202393264044, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 166, train_loss = 2.0522615375812165, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 167, train_loss = 2.040668595582247, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 168, train_loss = 2.045829893380869, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 169, train_loss = 2.0462538984720595, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 170, train_loss = 2.0382566464249976, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 171, train_loss = 2.039593023539055, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 172, train_loss = 2.0332806184887886, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 173, train_loss = 2.038292370736599, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 174, train_loss = 2.025456997274887, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 175, train_loss = 2.0365756948594935, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 176, train_loss = 2.0261379393632524, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 177, train_loss = 2.0303978038136847, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 178, train_loss = 2.030502364039421, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 179, train_loss = 2.0183265320956707, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 180, train_loss = 2.0199738790397532, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 181, train_loss = 2.017067141830921, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 182, train_loss = 2.0124894070322625, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 183, train_loss = 2.0170412522857077, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 184, train_loss = 2.010292289138306, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 185, train_loss = 2.014310492842924, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 186, train_loss = 2.0020114704966545, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 187, train_loss = 2.0030394991044886, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 188, train_loss = 2.0084427297115326, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 189, train_loss = 1.9976032860577106, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 190, train_loss = 1.9966573578421958, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 191, train_loss = 2.005021808028687, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 192, train_loss = 1.9917483627796173, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 193, train_loss = 1.9988013704423793, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 194, train_loss = 1.9887859697337262, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 195, train_loss = 1.9974526278674603, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 196, train_loss = 1.9847856487031095, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 197, train_loss = 1.9920695361797698, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 198, train_loss = 1.980502374470234, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 199, train_loss = 1.9850942231714725, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 200, train_loss = 1.9879640701110475, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 201, train_loss = 1.9813910238444805, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 202, train_loss = 1.977483427792322, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 203, train_loss = 1.9746435172855854, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 204, train_loss = 1.9786843620240688, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 205, train_loss = 1.974528819322586, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 206, train_loss = 1.976153690367937, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 207, train_loss = 1.9762552889878862, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 208, train_loss = 1.9647697061300278, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 209, train_loss = 1.966807782649994, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 210, train_loss = 1.9688712631468661, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 211, train_loss = 1.9635293048922904, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 212, train_loss = 1.967209613590967, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 213, train_loss = 1.9594124493305571, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 214, train_loss = 1.9640639859135263, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 215, train_loss = 1.9547525073285215, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 216, train_loss = 1.9593905856017955, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 217, train_loss = 1.9547028901870362, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 218, train_loss = 1.9567980493302457, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 219, train_loss = 1.950155720114708, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 220, train_loss = 1.9526297934353352, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 221, train_loss = 1.9503829193417914, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 222, train_loss = 1.9463361551170237, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 223, train_loss = 1.9443792912061326, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 224, train_loss = 1.9466285246307962, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 225, train_loss = 1.9438773940200917, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 226, train_loss = 1.9498718976974487, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 227, train_loss = 1.9383578250999562, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 228, train_loss = 1.9402191539411433, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 229, train_loss = 1.9378592942957766, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 230, train_loss = 1.9461412144009955, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 231, train_loss = 1.9360339852864854, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 232, train_loss = 1.9353004122967832, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 233, train_loss = 1.9362004796857946, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 234, train_loss = 1.9356722558732145, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 235, train_loss = 1.9302469839458354, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 236, train_loss = 1.927058930217754, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 237, train_loss = 1.9263559530372731, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 238, train_loss = 1.9258984439074993, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 239, train_loss = 1.924370660155546, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 240, train_loss = 1.9215113843674771, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 241, train_loss = 1.9220159662072547, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 242, train_loss = 1.921072854369413, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 243, train_loss = 1.9201527970726602, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 244, train_loss = 1.9170870780944824, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 245, train_loss = 1.9190571221406572, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 246, train_loss = 1.917564246803522, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 247, train_loss = 1.9127342675928958, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 248, train_loss = 1.915720995515585, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 249, train_loss = 1.91198305162834, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 250, train_loss = 1.9096274127368815, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 251, train_loss = 1.9112815248663537, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 252, train_loss = 1.9105913365783636, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 253, train_loss = 1.9048754498362541, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 254, train_loss = 1.9090807673637755, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 255, train_loss = 1.9086073425714858, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 256, train_loss = 1.9063324344460852, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 257, train_loss = 1.9052167559566442, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 258, train_loss = 1.9035864174365997, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 259, train_loss = 1.8984155617654324, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 260, train_loss = 1.9008434216084424, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 261, train_loss = 1.8973001216945704, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 262, train_loss = 1.8989966486988124, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 263, train_loss = 1.8959683751163539, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 264, train_loss = 1.8966626363398973, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 265, train_loss = 1.8966203033924103, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 266, train_loss = 1.891656570136547, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 267, train_loss = 1.8954657576978207, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 268, train_loss = 1.8907311049697455, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 269, train_loss = 1.8927810167369898, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 270, train_loss = 1.8933667540550232, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 271, train_loss = 1.8902420736849308, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 272, train_loss = 1.8885593799350318, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 273, train_loss = 1.8900703887047712, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 274, train_loss = 1.8865913276968058, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 275, train_loss = 1.8888376131653786, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 276, train_loss = 1.8821138950588647, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 277, train_loss = 1.883288568496937, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 278, train_loss = 1.8813918170926627, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 279, train_loss = 1.8781199430522975, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 280, train_loss = 1.881187321007019, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 281, train_loss = 1.878055358916754, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 282, train_loss = 1.8797046778199729, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 283, train_loss = 1.8775286239979323, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 284, train_loss = 1.8766457574965898, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 285, train_loss = 1.8743155002593994, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 286, train_loss = 1.8774586121144239, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 287, train_loss = 1.87701522684074, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 288, train_loss = 1.8733802313508932, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 289, train_loss = 1.873801657318836, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 290, train_loss = 1.8692275807261467, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 291, train_loss = 1.8655295222997665, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 292, train_loss = 1.8679951640369836, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 293, train_loss = 1.8647379328904208, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 294, train_loss = 1.8647420617344324, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 295, train_loss = 1.8624298547802027, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 296, train_loss = 1.8624884548189584, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 297, train_loss = 1.860795615852112, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 298, train_loss = 1.8655163335206453, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 299, train_loss = 1.855297947913641, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 300, train_loss = 1.8610443957149982, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 301, train_loss = 1.8572566347720567, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 302, train_loss = 1.8600002489984035, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 303, train_loss = 1.8534617622790392, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 304, train_loss = 1.8532976073620375, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 305, train_loss = 1.8575842293503229, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 306, train_loss = 1.852550745010376, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 307, train_loss = 1.8564599963428918, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 308, train_loss = 1.85242223367095, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 309, train_loss = 1.8547812327742577, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 310, train_loss = 1.8529936944541987, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 311, train_loss = 1.852989381790394, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 312, train_loss = 1.8519648189248983, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 313, train_loss = 1.8531943323614541, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 314, train_loss = 1.8474500812590122, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 315, train_loss = 1.8500967659056187, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 316, train_loss = 1.8483787029981613, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 317, train_loss = 1.846820529550314, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 318, train_loss = 1.8481297405960504, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 319, train_loss = 1.850976262241602, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 320, train_loss = 1.8437428077158984, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 321, train_loss = 1.8446003484132234, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 322, train_loss = 1.8408462057414, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 323, train_loss = 1.8454478879866656, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 324, train_loss = 1.8439199663698673, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 325, train_loss = 1.841679705918068, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 326, train_loss = 1.8401156452891883, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 327, train_loss = 1.8400047421455383, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 328, train_loss = 1.8404317324457224, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 329, train_loss = 1.8337172394094523, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 330, train_loss = 1.8337785750627518, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 331, train_loss = 1.8341036525962409, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 332, train_loss = 1.8362371710536536, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 333, train_loss = 1.8320423811674118, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 334, train_loss = 1.8308300053176936, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 335, train_loss = 1.830961711704731, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 336, train_loss = 1.8328614657220896, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 337, train_loss = 1.8333315625786781, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 338, train_loss = 1.8310124402341899, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 339, train_loss = 1.8274013946356717, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 340, train_loss = 1.8260084887442645, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 341, train_loss = 1.8262886516749859, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 342, train_loss = 1.824172105640173, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 343, train_loss = 1.8258943209948484, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 344, train_loss = 1.829157367348671, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 345, train_loss = 1.828147817403078, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 346, train_loss = 1.8254746670427267, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 347, train_loss = 1.8229047308268491, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 348, train_loss = 1.8197428025305271, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 349, train_loss = 1.8236257756652776, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 350, train_loss = 1.8193888390960637, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 351, train_loss = 1.8245154122414533, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 352, train_loss = 1.8189647632243577, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 353, train_loss = 1.8163814867439214, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 354, train_loss = 1.82295129695558, train_acc = 0.9945272473218444\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 355, train_loss = 1.818429745733738, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 356, train_loss = 1.8158845392463263, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 357, train_loss = 1.8177712696196977, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 358, train_loss = 1.8166628057661, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 359, train_loss = 1.8178825912473258, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 360, train_loss = 1.8120694818499032, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 361, train_loss = 1.8117801807820797, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 362, train_loss = 1.817579410970211, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 363, train_loss = 1.810989090561634, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 364, train_loss = 1.814295661955839, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 365, train_loss = 1.8108413653972093, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 366, train_loss = 1.812698860972887, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 367, train_loss = 1.8091095549461897, train_acc = 0.9945272473218444\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 368, train_loss = 1.809298936277628, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 369, train_loss = 1.8064544213411864, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 370, train_loss = 1.810500182211399, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 371, train_loss = 1.8096643475291785, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 372, train_loss = 1.8059449680149555, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 373, train_loss = 1.806230142712593, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 374, train_loss = 1.8037795709969942, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 375, train_loss = 1.8007798232138157, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 376, train_loss = 1.8039767406880856, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 377, train_loss = 1.8036115355789661, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 378, train_loss = 1.8063830832543317, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 379, train_loss = 1.8012459675373975, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 380, train_loss = 1.798051963240141, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 381, train_loss = 1.7960770303907339, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 382, train_loss = 1.7960524944064673, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 383, train_loss = 1.7970481204392854, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 384, train_loss = 1.799071617424488, train_acc = 0.9945272473218444\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 385, train_loss = 1.7960183719696943, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 386, train_loss = 1.7950652949512005, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 387, train_loss = 1.7995588965713978, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 388, train_loss = 1.7969168114068452, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 389, train_loss = 1.7918488370778505, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 390, train_loss = 1.7904025837779045, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 391, train_loss = 1.7948822105827276, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 392, train_loss = 1.7947479213180486, train_acc = 0.9945272473218444\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 393, train_loss = 1.7940653748810291, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 394, train_loss = 1.789132609963417, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 395, train_loss = 1.7899985859694425, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 396, train_loss = 1.786580736428732, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 397, train_loss = 1.7918347294034902, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 398, train_loss = 1.784148404985899, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 399, train_loss = 1.787887491285801, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 400, train_loss = 1.7859795751573984, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 401, train_loss = 1.7924605359730776, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 402, train_loss = 1.7829801490006503, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 403, train_loss = 1.7868866547942162, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 404, train_loss = 1.7814029045403004, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 405, train_loss = 1.7866856890323106, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 406, train_loss = 1.780489827186102, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 407, train_loss = 1.783703306078678, train_acc = 0.9946436888681882\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 408, train_loss = 1.7779422240855638, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 409, train_loss = 1.7781006594595965, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 410, train_loss = 1.7858391851186752, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 411, train_loss = 1.7772841528058052, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 412, train_loss = 1.782681092619896, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 413, train_loss = 1.7763345216808375, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 414, train_loss = 1.777469972759718, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 415, train_loss = 1.7840976727602538, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 416, train_loss = 1.7739829955098685, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 417, train_loss = 1.776859058678383, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 418, train_loss = 1.7776086789963301, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 419, train_loss = 1.781335132807726, train_acc = 0.9946436888681882\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 420, train_loss = 1.7822828069329262, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 421, train_loss = 1.781574111431837, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 422, train_loss = 1.7716628102061804, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 423, train_loss = 1.7763635752198752, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 424, train_loss = 1.7753937182424124, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 425, train_loss = 1.7718667412700597, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 426, train_loss = 1.784666965395445, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 427, train_loss = 1.7738839238882065, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 428, train_loss = 1.768815395742422, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 429, train_loss = 1.7693703075347003, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 430, train_loss = 1.773969075322384, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 431, train_loss = 1.7667958475649357, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 432, train_loss = 1.768202974140877, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 433, train_loss = 1.7736787907779217, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 434, train_loss = 1.7691671550273895, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 435, train_loss = 1.767782206326956, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 436, train_loss = 1.765220576286083, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 437, train_loss = 1.7697260044515133, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 438, train_loss = 1.7634014040231705, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 439, train_loss = 1.766309847444063, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 440, train_loss = 1.764346399664646, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 441, train_loss = 1.7623549749550875, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 442, train_loss = 1.7688071193697397, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 443, train_loss = 1.7705579946341459, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 444, train_loss = 1.7670093725027982, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 445, train_loss = 1.7731374142167624, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 446, train_loss = 1.761502880603075, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 447, train_loss = 1.7602822035551071, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 448, train_loss = 1.7572268707008334, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 449, train_loss = 1.7608351831731852, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 450, train_loss = 1.7544632094650296, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 451, train_loss = 1.758884884417057, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 452, train_loss = 1.7537141454668017, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 453, train_loss = 1.7572486052813474, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 454, train_loss = 1.7548123759625014, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 455, train_loss = 1.7567159136087867, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 456, train_loss = 1.7536224449722795, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 457, train_loss = 1.7526544568390818, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 458, train_loss = 1.760085966438055, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 459, train_loss = 1.7556856286973925, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 460, train_loss = 1.7504363643674878, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 461, train_loss = 1.7534585471003084, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 462, train_loss = 1.7571091664285632, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 463, train_loss = 1.7619117672293214, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 464, train_loss = 1.755505903318408, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 465, train_loss = 1.7590479503123788, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 466, train_loss = 1.7482812032103539, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 467, train_loss = 1.7509561851620674, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 468, train_loss = 1.746767404183629, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 469, train_loss = 1.7507115962653188, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 470, train_loss = 1.7493128006608458, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 471, train_loss = 1.7507746157498332, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 472, train_loss = 1.7429791788308648, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 473, train_loss = 1.7508949476032285, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 474, train_loss = 1.7574766837060452, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 475, train_loss = 1.7496362651436357, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 476, train_loss = 1.7423818757088156, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 477, train_loss = 1.7417375457735034, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 478, train_loss = 1.7464121654629707, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 479, train_loss = 1.7425964127032785, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 480, train_loss = 1.741452395915985, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 481, train_loss = 1.7419371257274179, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 482, train_loss = 1.743908831223962, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 483, train_loss = 1.7413939771504374, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 484, train_loss = 1.7414017406554194, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 485, train_loss = 1.7493290677666664, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 486, train_loss = 1.7416463233530521, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 487, train_loss = 1.7414071050734492, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 488, train_loss = 1.7454025658516912, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 489, train_loss = 1.7399424153118161, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 490, train_loss = 1.7430243641138077, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 491, train_loss = 1.744847654059413, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 492, train_loss = 1.7499040601105662, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 493, train_loss = 1.741077231868985, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 494, train_loss = 1.7363494709134102, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 495, train_loss = 1.7359920081944438, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 496, train_loss = 1.7395870027394267, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 497, train_loss = 1.7362918369472027, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 498, train_loss = 1.734323363751173, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 499, train_loss = 1.7359754567296477, train_acc = 0.9947601304145319\n",
      "test Acc 0.978584729981378:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|██▋                                                                            | 1/30 [09:02<4:22:17, 542.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "2th- epoch: 0, train_loss = 348.1798088774085, train_acc = 0.8027480204937122\n",
      "test Acc 0.8780260707635009:\n",
      "2th- epoch: 1, train_loss = 83.89756106399, train_acc = 0.9103400093153237\n",
      "test Acc 0.9171322160148976:\n",
      "2th- epoch: 2, train_loss = 54.87077693641186, train_acc = 0.9311830461108523\n",
      "test Acc 0.9287709497206704:\n",
      "2th- epoch: 3, train_loss = 39.708538685692474, train_acc = 0.9450395901257569\n",
      "test Acc 0.9292364990689013:\n",
      "2th- epoch: 4, train_loss = 31.673463960411027, train_acc = 0.9513274336283186\n",
      "test Acc 0.9343575418994413:\n",
      "2th- epoch: 5, train_loss = 25.739568799734116, train_acc = 0.9571495109455054\n",
      "test Acc 0.9436685288640596:\n",
      "2th- epoch: 6, train_loss = 21.217171291820705, train_acc = 0.9644853283651607\n",
      "test Acc 0.9459962756052142:\n",
      "2th- epoch: 7, train_loss = 18.179091492667794, train_acc = 0.9670470423847228\n",
      "test Acc 0.946927374301676:\n",
      "2th- epoch: 8, train_loss = 15.809505396522582, train_acc = 0.9692594317652539\n",
      "test Acc 0.9506517690875232:\n",
      "2th- epoch: 9, train_loss = 13.837988968007267, train_acc = 0.9724033535165347\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 10, train_loss = 12.235773286782205, train_acc = 0.9754308337214718\n",
      "test Acc 0.952048417132216:\n",
      "2th- epoch: 11, train_loss = 10.865901371464133, train_acc = 0.9782254308337215\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 12, train_loss = 9.667559111490846, train_acc = 0.9799720540288775\n",
      "test Acc 0.9515828677839852:\n",
      "2th- epoch: 13, train_loss = 8.722776395268738, train_acc = 0.9827666511411272\n",
      "test Acc 0.952513966480447:\n",
      "2th- epoch: 14, train_loss = 7.9691180773079395, train_acc = 0.983698183511877\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 15, train_loss = 7.368353203870356, train_acc = 0.9846297158826269\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 16, train_loss = 6.887186186388135, train_acc = 0.9853283651606893\n",
      "test Acc 0.952048417132216:\n",
      "2th- epoch: 17, train_loss = 6.4584998660720885, train_acc = 0.986376339077783\n",
      "test Acc 0.9539106145251397:\n",
      "2th- epoch: 18, train_loss = 6.085054239723831, train_acc = 0.986376339077783\n",
      "test Acc 0.9567039106145251:\n",
      "2th- epoch: 19, train_loss = 5.77884842036292, train_acc = 0.9871914299021891\n",
      "test Acc 0.957635009310987:\n",
      "2th- epoch: 20, train_loss = 5.496164612006396, train_acc = 0.9882394038192828\n",
      "test Acc 0.9581005586592178:\n",
      "2th- epoch: 21, train_loss = 5.2743467362597585, train_acc = 0.9887051700046576\n",
      "test Acc 0.9594972067039106:\n",
      "2th- epoch: 22, train_loss = 5.058641445823014, train_acc = 0.9892873777363763\n",
      "test Acc 0.9590316573556797:\n",
      "2th- epoch: 23, train_loss = 4.875161572126672, train_acc = 0.9896367023754076\n",
      "test Acc 0.9594972067039106:\n",
      "2th- epoch: 24, train_loss = 4.726824595592916, train_acc = 0.99033535165347\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 25, train_loss = 4.596675991313532, train_acc = 0.9904517931998137\n",
      "test Acc 0.9613594040968343:\n",
      "2th- epoch: 26, train_loss = 4.482305955607444, train_acc = 0.9905682347461574\n",
      "test Acc 0.9613594040968343:\n",
      "2th- epoch: 27, train_loss = 4.377408730331808, train_acc = 0.990801117838845\n",
      "test Acc 0.9613594040968343:\n",
      "2th- epoch: 28, train_loss = 4.267031119205058, train_acc = 0.9909175593851887\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 29, train_loss = 4.174216746119782, train_acc = 0.9909175593851887\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 30, train_loss = 4.090833327965811, train_acc = 0.9909175593851887\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 31, train_loss = 4.011232592863962, train_acc = 0.9909175593851887\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 32, train_loss = 3.9191869283095, train_acc = 0.9912668840242198\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 33, train_loss = 3.8546015026513487, train_acc = 0.9912668840242198\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 34, train_loss = 3.7808253921102732, train_acc = 0.9912668840242198\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 35, train_loss = 3.71150444727391, train_acc = 0.9912668840242198\n",
      "test Acc 0.9632216014897579:\n",
      "2th- epoch: 36, train_loss = 3.6679659127257764, train_acc = 0.9914997671169073\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 37, train_loss = 3.588898036861792, train_acc = 0.9916162086632511\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 38, train_loss = 3.524873268790543, train_acc = 0.9916162086632511\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 39, train_loss = 3.468362539075315, train_acc = 0.9916162086632511\n",
      "test Acc 0.9636871508379888:\n",
      "2th- epoch: 40, train_loss = 3.4233207462821156, train_acc = 0.9916162086632511\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 41, train_loss = 3.369638609699905, train_acc = 0.9918490917559385\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 42, train_loss = 3.3442804301157594, train_acc = 0.9919655333022822\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 43, train_loss = 3.2921012002043426, train_acc = 0.9921984163949698\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 44, train_loss = 3.2330140054691583, train_acc = 0.9921984163949698\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 45, train_loss = 3.187265286454931, train_acc = 0.9923148579413135\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 46, train_loss = 3.159208147204481, train_acc = 0.9923148579413135\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 47, train_loss = 3.119962870841846, train_acc = 0.9923148579413135\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 48, train_loss = 3.086238137912005, train_acc = 0.9926641825803446\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 49, train_loss = 3.05862581753172, train_acc = 0.9926641825803446\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 50, train_loss = 3.0169601675588638, train_acc = 0.9924312994876572\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 51, train_loss = 2.9958043192746118, train_acc = 0.9928970656730322\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 52, train_loss = 2.9520487268455327, train_acc = 0.9927806241266884\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 53, train_loss = 2.9456457941560075, train_acc = 0.9927806241266884\n",
      "test Acc 0.9646182495344506:\n",
      "2th- epoch: 54, train_loss = 2.901692924555391, train_acc = 0.9928970656730322\n",
      "test Acc 0.9650837988826816:\n",
      "2th- epoch: 55, train_loss = 2.8772781569277868, train_acc = 0.9928970656730322\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 56, train_loss = 2.8504055740777403, train_acc = 0.9932463903120633\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 57, train_loss = 2.810872277477756, train_acc = 0.9931299487657196\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 58, train_loss = 2.7978830975480378, train_acc = 0.9931299487657196\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 59, train_loss = 2.775868014781736, train_acc = 0.9932463903120633\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 60, train_loss = 2.750890895957127, train_acc = 0.9932463903120633\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 61, train_loss = 2.7572922337567434, train_acc = 0.9931299487657196\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 62, train_loss = 2.70592945930548, train_acc = 0.9934792734047508\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 63, train_loss = 2.6989020127803087, train_acc = 0.9933628318584071\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 64, train_loss = 2.6570369575638324, train_acc = 0.9933628318584071\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 65, train_loss = 2.6458892262307927, train_acc = 0.9933628318584071\n",
      "test Acc 0.9655493482309124:\n",
      "2th- epoch: 66, train_loss = 2.6177154302131385, train_acc = 0.9932463903120633\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 67, train_loss = 2.6118304564151913, train_acc = 0.9931299487657196\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 68, train_loss = 2.585725206648931, train_acc = 0.9933628318584071\n",
      "test Acc 0.9660148975791434:\n",
      "2th- epoch: 69, train_loss = 2.570941373705864, train_acc = 0.9931299487657196\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 70, train_loss = 2.55050439783372, train_acc = 0.9933628318584071\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 71, train_loss = 2.53034990420565, train_acc = 0.9931299487657196\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 72, train_loss = 2.5100704932119697, train_acc = 0.9932463903120633\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 73, train_loss = 2.5083674921188504, train_acc = 0.9932463903120633\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 74, train_loss = 2.494474058272317, train_acc = 0.9932463903120633\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 75, train_loss = 2.485374367563054, train_acc = 0.9933628318584071\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 76, train_loss = 2.469762575579807, train_acc = 0.9933628318584071\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 77, train_loss = 2.442173535237089, train_acc = 0.9933628318584071\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 78, train_loss = 2.434177224058658, train_acc = 0.9934792734047508\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 79, train_loss = 2.4179643758106977, train_acc = 0.9934792734047508\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 80, train_loss = 2.4124148851260543, train_acc = 0.9934792734047508\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 81, train_loss = 2.4018565989099443, train_acc = 0.9937121564974383\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 82, train_loss = 2.3928479726891965, train_acc = 0.9935957149510946\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 83, train_loss = 2.378158653853461, train_acc = 0.9935957149510946\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 84, train_loss = 2.37422008800786, train_acc = 0.9937121564974383\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 85, train_loss = 2.3568594104144722, train_acc = 0.9937121564974383\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 86, train_loss = 2.3494542478583753, train_acc = 0.9939450395901258\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 87, train_loss = 2.339272142504342, train_acc = 0.9940614811364695\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 88, train_loss = 2.3259245177032426, train_acc = 0.9940614811364695\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 89, train_loss = 2.315301689784974, train_acc = 0.994294364229157\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 90, train_loss = 2.317328689619899, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 91, train_loss = 2.305624149623327, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 92, train_loss = 2.2967496007913724, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 93, train_loss = 2.2894425028935075, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 94, train_loss = 2.2895469460636377, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 95, train_loss = 2.2735181091120467, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 96, train_loss = 2.2721141142537817, train_acc = 0.9945272473218444\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 97, train_loss = 2.267881925101392, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 98, train_loss = 2.2590060039656237, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 99, train_loss = 2.250460598501377, train_acc = 0.9945272473218444\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 100, train_loss = 2.245387947652489, train_acc = 0.9945272473218444\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 101, train_loss = 2.245289076003246, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 102, train_loss = 2.232655653730035, train_acc = 0.9945272473218444\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 103, train_loss = 2.2266136911930516, train_acc = 0.9946436888681882\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 104, train_loss = 2.2294515861431137, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 105, train_loss = 2.239584635128267, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 106, train_loss = 2.226191054098308, train_acc = 0.9946436888681882\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 107, train_loss = 2.2118131852475926, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 108, train_loss = 2.2050594034371898, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 109, train_loss = 2.203338513732888, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 110, train_loss = 2.1953487881692126, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 111, train_loss = 2.191011382616125, train_acc = 0.9948765719608756\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 112, train_loss = 2.1887191911228, train_acc = 0.9948765719608756\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 113, train_loss = 2.181171824107878, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 114, train_loss = 2.176718753762543, train_acc = 0.9948765719608756\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 115, train_loss = 2.1726553469197825, train_acc = 0.9948765719608756\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 116, train_loss = 2.168478370527737, train_acc = 0.9948765719608756\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 117, train_loss = 2.165798564790748, train_acc = 0.9948765719608756\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 118, train_loss = 2.1655896892771125, train_acc = 0.9948765719608756\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 119, train_loss = 2.1601670454256237, train_acc = 0.9948765719608756\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 120, train_loss = 2.1587420174619183, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 121, train_loss = 2.1505952052539214, train_acc = 0.9948765719608756\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 122, train_loss = 2.1495154480217025, train_acc = 0.9948765719608756\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 123, train_loss = 2.1440117323072627, train_acc = 0.9948765719608756\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 124, train_loss = 2.149522187304683, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 125, train_loss = 2.157040648162365, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 126, train_loss = 2.142133462592028, train_acc = 0.9948765719608756\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 127, train_loss = 2.1370170675218105, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 128, train_loss = 2.126876499154605, train_acc = 0.9948765719608756\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 129, train_loss = 2.1215158343547955, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 130, train_loss = 2.1259007261833176, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 131, train_loss = 2.125442142598331, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 132, train_loss = 2.1297858537873253, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 133, train_loss = 2.1183963427320123, train_acc = 0.9948765719608756\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 134, train_loss = 2.108729184605181, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 135, train_loss = 2.1048009475925937, train_acc = 0.9948765719608756\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 136, train_loss = 2.1066563110798597, train_acc = 0.9948765719608756\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 137, train_loss = 2.1017491795355454, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 138, train_loss = 2.1040357407182455, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 139, train_loss = 2.111488861613907, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 140, train_loss = 2.110069197951816, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 141, train_loss = 2.102724950760603, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 142, train_loss = 2.088093451806344, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 143, train_loss = 2.095121887163259, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 144, train_loss = 2.0927673326805234, train_acc = 0.9948765719608756\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 145, train_loss = 2.0721966655692086, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 146, train_loss = 2.0684983137762174, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 147, train_loss = 2.073629397316836, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 148, train_loss = 2.0651669703656808, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 149, train_loss = 2.0629018899053335, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 150, train_loss = 2.066206293529831, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 151, train_loss = 2.061928133480251, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 152, train_loss = 2.0548043527523987, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 153, train_loss = 2.0554643577197567, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 154, train_loss = 2.0597125133499503, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 155, train_loss = 2.0557894523371942, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 156, train_loss = 2.051094039052259, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 157, train_loss = 2.0500615626806393, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 158, train_loss = 2.057839330867864, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 159, train_loss = 2.044125074520707, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 160, train_loss = 2.0431747107650153, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "2th- epoch: 161, train_loss = 2.039449187926948, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 162, train_loss = 2.045465217262972, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 163, train_loss = 2.039302288845647, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 164, train_loss = 2.0461336905136704, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 165, train_loss = 2.0339893375639804, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 166, train_loss = 2.03543364192592, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 167, train_loss = 2.026821168430615, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 168, train_loss = 2.03197070985334, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 169, train_loss = 2.0245558746973984, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 170, train_loss = 2.0303918877616525, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 171, train_loss = 2.025507592887152, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 172, train_loss = 2.0279103278298862, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 173, train_loss = 2.0218067855457775, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 174, train_loss = 2.0237617061357014, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 175, train_loss = 2.0184921426698565, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 176, train_loss = 2.020491139672231, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 177, train_loss = 2.01337169110775, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 178, train_loss = 2.0251855623791926, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 179, train_loss = 2.018830284185242, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 180, train_loss = 2.0158962800051086, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 181, train_loss = 2.008260181173682, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 182, train_loss = 2.0106489204918034, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "2th- epoch: 183, train_loss = 2.005013447254896, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 184, train_loss = 2.015175271779299, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 185, train_loss = 2.011239600076806, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 186, train_loss = 2.0037635772605427, train_acc = 0.9949930135072194\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 187, train_loss = 1.996360280259978, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 188, train_loss = 2.0012665797839873, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 189, train_loss = 1.9981168058584444, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 190, train_loss = 1.9999719221959822, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 191, train_loss = 1.9955284601892345, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 192, train_loss = 1.996485095762182, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 193, train_loss = 1.993494353548158, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 194, train_loss = 1.997157336503733, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 195, train_loss = 1.9912512957234867, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 196, train_loss = 1.9941821992397308, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 197, train_loss = 1.9878343964810483, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 198, train_loss = 1.9919285653159022, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 199, train_loss = 1.985618893057108, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 200, train_loss = 1.9869604685227387, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 201, train_loss = 1.9827193291857839, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 202, train_loss = 1.9862503201584332, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 203, train_loss = 1.9812564442981966, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 204, train_loss = 1.9856159848277457, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 205, train_loss = 1.9789159093052149, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 206, train_loss = 1.981395243667066, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 207, train_loss = 1.9786001204629429, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 208, train_loss = 1.9788029442424886, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 209, train_loss = 1.976185331121087, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 210, train_loss = 1.9769229631056078, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 211, train_loss = 1.9745424085413106, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 212, train_loss = 1.977978955314029, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 213, train_loss = 1.9740922152996063, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 214, train_loss = 1.9845665541361086, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 215, train_loss = 1.977673068002332, train_acc = 0.9949930135072194\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 216, train_loss = 1.9831415740773082, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 217, train_loss = 1.9716847424278967, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 218, train_loss = 1.9716054117307067, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 219, train_loss = 1.967209842056036, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 220, train_loss = 1.9670610570465215, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 221, train_loss = 1.9617877108976245, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 222, train_loss = 1.970439113676548, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 223, train_loss = 1.958692797459662, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 224, train_loss = 1.9645553712616675, train_acc = 0.9949930135072194\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 225, train_loss = 1.9620112090487964, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 226, train_loss = 1.9623629047418945, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 227, train_loss = 1.9607482943683863, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 228, train_loss = 1.9624190150643699, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 229, train_loss = 1.9599412244861014, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 230, train_loss = 1.9633325822651386, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 231, train_loss = 1.9497216548770666, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 232, train_loss = 1.951804862357676, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 233, train_loss = 1.94826465472579, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 234, train_loss = 1.9549664634396322, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 235, train_loss = 1.9481401319499128, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 236, train_loss = 1.9470676283235662, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 237, train_loss = 1.9457454078947194, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 238, train_loss = 1.948333508335054, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 239, train_loss = 1.9453771977568977, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 240, train_loss = 1.9545518060331233, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 241, train_loss = 1.9511537051876076, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 242, train_loss = 1.944787412736332, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 243, train_loss = 1.941854945383966, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 244, train_loss = 1.9423760253412183, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 245, train_loss = 1.9423066095332615, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 246, train_loss = 1.952035536058247, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 247, train_loss = 1.943918986711651, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 248, train_loss = 1.9415090192924254, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "2th- epoch: 249, train_loss = 1.9394287317991257, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 250, train_loss = 1.9387539643794298, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 251, train_loss = 1.9378691379388329, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 252, train_loss = 1.9328689972462598, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 253, train_loss = 1.931911550782388, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 254, train_loss = 1.9326443714089692, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 255, train_loss = 1.9301053984090686, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 256, train_loss = 1.9305180739611387, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 257, train_loss = 1.9290207289159298, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 258, train_loss = 1.9318533106707036, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 259, train_loss = 1.9359293612651527, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 260, train_loss = 1.9409671425819397, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 261, train_loss = 1.9371068269538227, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 262, train_loss = 1.9345128958520945, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 263, train_loss = 1.934851677477127, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 264, train_loss = 1.933298268035287, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 265, train_loss = 1.9344744124973658, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 266, train_loss = 1.9306465356203262, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 267, train_loss = 1.9225513680430595, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 268, train_loss = 1.922337480209535, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 269, train_loss = 1.931929412909085, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 270, train_loss = 1.9275556706415955, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 271, train_loss = 1.929115610808367, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 272, train_loss = 1.925078839994967, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 273, train_loss = 1.9262350665812846, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 274, train_loss = 1.9240292540343944, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 275, train_loss = 1.9261713535524905, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 276, train_loss = 1.923470653273398, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 277, train_loss = 1.9245744730869774, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 278, train_loss = 1.922340245306259, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 279, train_loss = 1.918423361465102, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 280, train_loss = 1.9199995769595262, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 281, train_loss = 1.9174241172149777, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 282, train_loss = 1.918153372273082, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 283, train_loss = 1.9137575553322677, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 284, train_loss = 1.907965107500786, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 285, train_loss = 1.9068481451831758, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 286, train_loss = 1.9112997230549809, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 287, train_loss = 1.9019749698636588, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 288, train_loss = 1.903659730538493, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 289, train_loss = 1.900681139115477, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 290, train_loss = 1.9031974971294403, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 291, train_loss = 1.9044096386060119, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 292, train_loss = 1.8984028746781405, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 293, train_loss = 1.9037479017861187, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 294, train_loss = 1.8997107204049826, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 295, train_loss = 1.8994043543934822, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 296, train_loss = 1.8988691219128668, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 297, train_loss = 1.9038059542363044, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 298, train_loss = 1.8982539904827718, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 299, train_loss = 1.897151147335535, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 300, train_loss = 1.8956612069159746, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 301, train_loss = 1.8974424122425262, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 302, train_loss = 1.8931545269151684, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 303, train_loss = 1.8959776464325842, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 304, train_loss = 1.8891729860042688, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 305, train_loss = 1.894410541135585, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 306, train_loss = 1.8964189174585044, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 307, train_loss = 1.8996620987018105, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 308, train_loss = 1.9003119436092675, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 309, train_loss = 1.896807385928696, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 310, train_loss = 1.8979986873455346, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 311, train_loss = 1.8982857090013567, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 312, train_loss = 1.8898357016441878, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 313, train_loss = 1.8853286653757095, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 314, train_loss = 1.8850006918946747, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 315, train_loss = 1.884019920922583, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 316, train_loss = 1.8853483797574881, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 317, train_loss = 1.8843713539245073, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 318, train_loss = 1.8806239760888275, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 319, train_loss = 1.882259820587933, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 320, train_loss = 1.8849467649124563, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 321, train_loss = 1.888262989319628, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 322, train_loss = 1.8902566653268877, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 323, train_loss = 1.8917041028325912, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 324, train_loss = 1.8882785740715917, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 325, train_loss = 1.8850370291620493, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 326, train_loss = 1.8852999006921891, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 327, train_loss = 1.8792719705961645, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 328, train_loss = 1.875956029020017, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 329, train_loss = 1.8734242177160922, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 330, train_loss = 1.872592740226537, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 331, train_loss = 1.8715492985211313, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 332, train_loss = 1.8731566369533539, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 333, train_loss = 1.874819554388523, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 334, train_loss = 1.8825041431409772, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 335, train_loss = 1.8766416911967099, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 336, train_loss = 1.880354686640203, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 337, train_loss = 1.8741795560345054, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 338, train_loss = 1.8656556817295495, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 339, train_loss = 1.8668734654784203, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 340, train_loss = 1.8638452777231578, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 341, train_loss = 1.8685339246876538, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 342, train_loss = 1.8749333753657993, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 343, train_loss = 1.8706413870677352, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 344, train_loss = 1.8724467161518987, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 345, train_loss = 1.8593424460850656, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 346, train_loss = 1.863674333319068, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 347, train_loss = 1.861796031560516, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 348, train_loss = 1.8631868540833239, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 349, train_loss = 1.872010097373277, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 350, train_loss = 1.8676449613121804, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 351, train_loss = 1.8640504454670008, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 352, train_loss = 1.8590340802038554, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 353, train_loss = 1.8561029049160425, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 354, train_loss = 1.8588895878347103, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 355, train_loss = 1.8602515310049057, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 356, train_loss = 1.8616043417714536, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 357, train_loss = 1.856873872835422, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 358, train_loss = 1.8621458408015314, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 359, train_loss = 1.8628830166126136, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 360, train_loss = 1.8622482409700751, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 361, train_loss = 1.8569219003838953, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 362, train_loss = 1.8535796306096017, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 363, train_loss = 1.8552243543381337, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 364, train_loss = 1.8602400415984448, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 365, train_loss = 1.848026600520825, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 366, train_loss = 1.8535187811066862, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 367, train_loss = 1.8468814835359808, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 368, train_loss = 1.8563233311288059, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 369, train_loss = 1.8553862726839725, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 370, train_loss = 1.8569031893275678, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 371, train_loss = 1.8493782693112735, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 372, train_loss = 1.846818605583394, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 373, train_loss = 1.84768204469583, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "2th- epoch: 374, train_loss = 1.8528944285062607, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 375, train_loss = 1.8417624767462257, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 376, train_loss = 1.8486876006645616, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 377, train_loss = 1.8519718766619917, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 378, train_loss = 1.847091283503687, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 379, train_loss = 1.8409466363082174, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 380, train_loss = 1.8434758343209978, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 381, train_loss = 1.8481942863727454, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 382, train_loss = 1.8425227892585099, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 383, train_loss = 1.841203275602311, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 384, train_loss = 1.840797248762101, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 385, train_loss = 1.8419523919001222, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 386, train_loss = 1.8344375328160822, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 387, train_loss = 1.84369609146961, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 388, train_loss = 1.8451462726516183, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 389, train_loss = 1.8402259408903774, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 390, train_loss = 1.8344716355204582, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 391, train_loss = 1.8362208398466464, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 392, train_loss = 1.8376305680721998, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 393, train_loss = 1.8293684110976756, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 394, train_loss = 1.8364651251176838, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 395, train_loss = 1.8403188474476337, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 396, train_loss = 1.832357863575453, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 397, train_loss = 1.8301222977752332, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 398, train_loss = 1.8309158142656088, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 399, train_loss = 1.835229807678843, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 400, train_loss = 1.8276411715633003, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 401, train_loss = 1.8308554352261126, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 402, train_loss = 1.8338137303071562, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 403, train_loss = 1.8343051630072296, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 404, train_loss = 1.8249436173064169, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 405, train_loss = 1.8306291154585779, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 406, train_loss = 1.8288698246033164, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 407, train_loss = 1.822704474121565, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 408, train_loss = 1.8252862809749786, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 409, train_loss = 1.8280631896777777, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 410, train_loss = 1.8212134731002152, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 411, train_loss = 1.8245485344377812, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 412, train_loss = 1.8244373824709328, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 413, train_loss = 1.8240083336568205, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 414, train_loss = 1.8225028587912675, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 415, train_loss = 1.8258905483671697, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 416, train_loss = 1.8214592672884464, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 417, train_loss = 1.8199514048174024, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 418, train_loss = 1.8227987228892744, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 419, train_loss = 1.8156541084608762, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 420, train_loss = 1.8173677696322557, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 421, train_loss = 1.8204697673209012, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 422, train_loss = 1.815386455040425, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 423, train_loss = 1.8185985543241259, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 424, train_loss = 1.818032925017178, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 425, train_loss = 1.8160310094244778, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 426, train_loss = 1.8152088102360722, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 427, train_loss = 1.8206791869888548, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 428, train_loss = 1.8140377602539957, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 429, train_loss = 1.8111168127506971, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 430, train_loss = 1.816558735910803, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 431, train_loss = 1.8141088153497549, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 432, train_loss = 1.8097092594689457, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 433, train_loss = 1.8154966776928632, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 434, train_loss = 1.809273164253682, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 435, train_loss = 1.8091684142127633, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 436, train_loss = 1.8118100419378607, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 437, train_loss = 1.8113944137730869, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 438, train_loss = 1.8041596887633204, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 439, train_loss = 1.8129949904978275, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 440, train_loss = 1.8102273270487785, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 441, train_loss = 1.8054928124620346, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 442, train_loss = 1.805166619058582, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 443, train_loss = 1.8080567754805088, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 444, train_loss = 1.8014810158201726, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 445, train_loss = 1.8052801618614467, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 446, train_loss = 1.805040850143996, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 447, train_loss = 1.8020735530444654, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 448, train_loss = 1.797791409000638, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 449, train_loss = 1.7991865550429793, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 450, train_loss = 1.7970913271419704, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 451, train_loss = 1.7988975274638506, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 452, train_loss = 1.7939513746387092, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 453, train_loss = 1.7966489200480282, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 454, train_loss = 1.7964288263319759, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 455, train_loss = 1.8016312876716256, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 456, train_loss = 1.8103472993971081, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 457, train_loss = 1.8012189380824566, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 458, train_loss = 1.7931119060813216, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 459, train_loss = 1.7989284683280857, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 460, train_loss = 1.797303477927926, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 461, train_loss = 1.7934825867414474, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 462, train_loss = 1.7948757852427661, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 463, train_loss = 1.798642463676515, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 464, train_loss = 1.7910525865590898, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 465, train_loss = 1.7979684135207208, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 466, train_loss = 1.7948752927331952, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 467, train_loss = 1.7897208725771634, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 468, train_loss = 1.7882552060036687, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 469, train_loss = 1.7906970564945368, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 470, train_loss = 1.786593337848899, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 471, train_loss = 1.7891826261766255, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 472, train_loss = 1.7861343709082576, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 473, train_loss = 1.786429403044167, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 474, train_loss = 1.7820139761752216, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 475, train_loss = 1.7853654436767101, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 476, train_loss = 1.783842319782707, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 477, train_loss = 1.7854984519071877, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 478, train_loss = 1.7805000455118716, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 479, train_loss = 1.7849528744554846, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 480, train_loss = 1.7827499421982793, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 481, train_loss = 1.7869426277466118, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 482, train_loss = 1.7944025291799335, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 483, train_loss = 1.7961272313259542, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 484, train_loss = 1.796619854401797, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 485, train_loss = 1.8005612349807052, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 486, train_loss = 1.7943972779175965, train_acc = 0.9951094550535631\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 487, train_loss = 1.7877049188391538, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "2th- epoch: 488, train_loss = 1.777091703377664, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 489, train_loss = 1.7801347755157622, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 490, train_loss = 1.7786134029738605, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 491, train_loss = 1.777863725394127, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 492, train_loss = 1.774547478344175, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 493, train_loss = 1.781762933198479, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "2th- epoch: 494, train_loss = 1.7788714241905836, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 495, train_loss = 1.7714513948449166, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 496, train_loss = 1.7743485274986597, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 497, train_loss = 1.7748755187058123, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 498, train_loss = 1.7752689692861168, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "2th- epoch: 499, train_loss = 1.769639344260213, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  7%|█████▎                                                                         | 2/30 [18:04<4:13:03, 542.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "3th- epoch: 0, train_loss = 388.12610224913806, train_acc = 0.7977410340009315\n",
      "test Acc 0.9208566108007449:\n",
      "3th- epoch: 1, train_loss = 83.68011605739594, train_acc = 0.9147647880763856\n",
      "test Acc 0.9329608938547486:\n",
      "3th- epoch: 2, train_loss = 53.9398622661829, train_acc = 0.9351420586865393\n",
      "test Acc 0.946927374301676:\n",
      "3th- epoch: 3, train_loss = 39.12549250328448, train_acc = 0.9469026548672567\n",
      "test Acc 0.952513966480447:\n",
      "3th- epoch: 4, train_loss = 29.5703604221344, train_acc = 0.9568001863064741\n",
      "test Acc 0.9557728119180633:\n",
      "3th- epoch: 5, train_loss = 23.84931881725788, train_acc = 0.962156497438286\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 6, train_loss = 20.162835381925106, train_acc = 0.9668141592920354\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 7, train_loss = 17.477806818904355, train_acc = 0.97007452258966\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 8, train_loss = 15.330145510612056, train_acc = 0.9732184443409408\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 9, train_loss = 13.617558089317754, train_acc = 0.9754308337214718\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 10, train_loss = 12.240438006818295, train_acc = 0.977992547741034\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 11, train_loss = 11.136405157623813, train_acc = 0.9791569632044713\n",
      "test Acc 0.9618249534450651:\n",
      "3th- epoch: 12, train_loss = 10.228966524126008, train_acc = 0.9812529110386586\n",
      "test Acc 0.9632216014897579:\n",
      "3th- epoch: 13, train_loss = 9.394429120002314, train_acc = 0.9826502095947834\n",
      "test Acc 0.9636871508379888:\n",
      "3th- epoch: 14, train_loss = 8.684707969427109, train_acc = 0.9835817419655333\n",
      "test Acc 0.9636871508379888:\n",
      "3th- epoch: 15, train_loss = 8.075695794075727, train_acc = 0.9845132743362832\n",
      "test Acc 0.9641527001862198:\n",
      "3th- epoch: 16, train_loss = 7.567179405363277, train_acc = 0.9856776897997206\n",
      "test Acc 0.9641527001862198:\n",
      "3th- epoch: 17, train_loss = 7.1277779676020145, train_acc = 0.9867256637168141\n",
      "test Acc 0.9641527001862198:\n",
      "3th- epoch: 18, train_loss = 6.75555357336998, train_acc = 0.9873078714485328\n",
      "test Acc 0.9641527001862198:\n",
      "3th- epoch: 19, train_loss = 6.401135753840208, train_acc = 0.9877736376339078\n",
      "test Acc 0.9641527001862198:\n",
      "3th- epoch: 20, train_loss = 6.100544846383855, train_acc = 0.9880065207265952\n",
      "test Acc 0.9636871508379888:\n",
      "3th- epoch: 21, train_loss = 5.815950959920883, train_acc = 0.9887051700046576\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 22, train_loss = 5.588390201330185, train_acc = 0.9888216115510013\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 23, train_loss = 5.347052718279883, train_acc = 0.9891709361900326\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 24, train_loss = 5.141683168709278, train_acc = 0.9896367023754076\n",
      "test Acc 0.9646182495344506:\n",
      "3th- epoch: 25, train_loss = 4.973738158587366, train_acc = 0.989869585468095\n",
      "test Acc 0.9646182495344506:\n",
      "3th- epoch: 26, train_loss = 4.797608447726816, train_acc = 0.989869585468095\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 27, train_loss = 4.6433438756503165, train_acc = 0.99033535165347\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 28, train_loss = 4.497641377151012, train_acc = 0.990801117838845\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 29, train_loss = 4.395973823964596, train_acc = 0.9906846762925011\n",
      "test Acc 0.9655493482309124:\n",
      "3th- epoch: 30, train_loss = 4.271021906286478, train_acc = 0.9905682347461574\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 31, train_loss = 4.175374443177134, train_acc = 0.9906846762925011\n",
      "test Acc 0.9655493482309124:\n",
      "3th- epoch: 32, train_loss = 4.057202605064958, train_acc = 0.990801117838845\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 33, train_loss = 3.964108763728291, train_acc = 0.9910340009315324\n",
      "test Acc 0.9655493482309124:\n",
      "3th- epoch: 34, train_loss = 3.8771135262213647, train_acc = 0.9910340009315324\n",
      "test Acc 0.9655493482309124:\n",
      "3th- epoch: 35, train_loss = 3.7981424354948103, train_acc = 0.9910340009315324\n",
      "test Acc 0.9655493482309124:\n",
      "3th- epoch: 36, train_loss = 3.7264094948768616, train_acc = 0.9910340009315324\n",
      "test Acc 0.9664804469273743:\n",
      "3th- epoch: 37, train_loss = 3.658604553434998, train_acc = 0.9910340009315324\n",
      "test Acc 0.9655493482309124:\n",
      "3th- epoch: 38, train_loss = 3.590562588069588, train_acc = 0.9913833255705635\n",
      "test Acc 0.9664804469273743:\n",
      "3th- epoch: 39, train_loss = 3.5266698063351214, train_acc = 0.9917326502095948\n",
      "test Acc 0.9669459962756052:\n",
      "3th- epoch: 40, train_loss = 3.468367753084749, train_acc = 0.9917326502095948\n",
      "test Acc 0.9669459962756052:\n",
      "3th- epoch: 41, train_loss = 3.4091429237741977, train_acc = 0.9917326502095948\n",
      "test Acc 0.9669459962756052:\n",
      "3th- epoch: 42, train_loss = 3.3770559690892696, train_acc = 0.9917326502095948\n",
      "test Acc 0.9669459962756052:\n",
      "3th- epoch: 43, train_loss = 3.31162495422177, train_acc = 0.992081974848626\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 44, train_loss = 3.2770850744564086, train_acc = 0.9921984163949698\n",
      "test Acc 0.9669459962756052:\n",
      "3th- epoch: 45, train_loss = 3.2369379352312535, train_acc = 0.9921984163949698\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 46, train_loss = 3.190596790285781, train_acc = 0.9923148579413135\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 47, train_loss = 3.1519602239131927, train_acc = 0.9923148579413135\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 48, train_loss = 3.1263346436899155, train_acc = 0.9923148579413135\n",
      "test Acc 0.9674115456238361:\n",
      "3th- epoch: 49, train_loss = 3.0890822410583496, train_acc = 0.9925477410340009\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 50, train_loss = 3.053493329556659, train_acc = 0.9925477410340009\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 51, train_loss = 3.0241617660503834, train_acc = 0.9926641825803446\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 52, train_loss = 2.99369137478061, train_acc = 0.9928970656730322\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 53, train_loss = 2.965544506907463, train_acc = 0.9928970656730322\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 54, train_loss = 2.9390635218005627, train_acc = 0.9928970656730322\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 55, train_loss = 2.9165152348577976, train_acc = 0.9930135072193759\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 56, train_loss = 2.8922020990867168, train_acc = 0.9928970656730322\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 57, train_loss = 2.864383687498048, train_acc = 0.9930135072193759\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 58, train_loss = 2.8424434028565884, train_acc = 0.9932463903120633\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 59, train_loss = 2.8211617146153003, train_acc = 0.9933628318584071\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 60, train_loss = 2.800064916489646, train_acc = 0.9934792734047508\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 61, train_loss = 2.7748435761313885, train_acc = 0.9934792734047508\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 62, train_loss = 2.7588310453575104, train_acc = 0.9934792734047508\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 63, train_loss = 2.744795673759654, train_acc = 0.9934792734047508\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 64, train_loss = 2.730527848005295, train_acc = 0.9934792734047508\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 65, train_loss = 2.7115034323651344, train_acc = 0.9934792734047508\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 66, train_loss = 2.687222593696788, train_acc = 0.9934792734047508\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 67, train_loss = 2.665582325309515, train_acc = 0.9934792734047508\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 68, train_loss = 2.6589668963570148, train_acc = 0.9933628318584071\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 69, train_loss = 2.646145787090063, train_acc = 0.9934792734047508\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 70, train_loss = 2.619955964386463, train_acc = 0.9933628318584071\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 71, train_loss = 2.6080395330209285, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 72, train_loss = 2.598376013338566, train_acc = 0.9934792734047508\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 73, train_loss = 2.5827647496480495, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 74, train_loss = 2.56741940358188, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 75, train_loss = 2.5571454018354416, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 76, train_loss = 2.542086930363439, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 77, train_loss = 2.539748062728904, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 78, train_loss = 2.5220712398877367, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 79, train_loss = 2.5097385086119175, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 80, train_loss = 2.498539955704473, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 81, train_loss = 2.49345213919878, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 82, train_loss = 2.4788138220319524, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 83, train_loss = 2.469448265968822, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 84, train_loss = 2.4584122709929943, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 85, train_loss = 2.452625392586924, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 86, train_loss = 2.445314289419912, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 87, train_loss = 2.428846730501391, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 88, train_loss = 2.4249268335988745, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 89, train_loss = 2.412046412588097, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 90, train_loss = 2.4064165962627158, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 91, train_loss = 2.4014031564584, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 92, train_loss = 2.3893077360698953, train_acc = 0.9935957149510946\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 93, train_loss = 2.385150404064916, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 94, train_loss = 2.379982978105545, train_acc = 0.9935957149510946\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 95, train_loss = 2.3661938719451427, train_acc = 0.9935957149510946\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 96, train_loss = 2.353926549316384, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 97, train_loss = 2.3586167754838243, train_acc = 0.9935957149510946\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 98, train_loss = 2.345111694186926, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 99, train_loss = 2.343478262424469, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 100, train_loss = 2.3254952592542395, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 101, train_loss = 2.3240985460579395, train_acc = 0.9935957149510946\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 102, train_loss = 2.3105467321584, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 103, train_loss = 2.30759382864926, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 104, train_loss = 2.3038601590087637, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 105, train_loss = 2.299516615807079, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 106, train_loss = 2.289837274700403, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 107, train_loss = 2.2837345289299265, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 108, train_loss = 2.2812169851968065, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 109, train_loss = 2.275388461886905, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 110, train_loss = 2.266497520147823, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 111, train_loss = 2.2646339213242754, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 112, train_loss = 2.259832214564085, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 113, train_loss = 2.253704760223627, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 114, train_loss = 2.2492224872112274, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "3th- epoch: 115, train_loss = 2.2434142207494006, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 116, train_loss = 2.239981905906461, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 117, train_loss = 2.2334725372493267, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 118, train_loss = 2.2291554486146197, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 119, train_loss = 2.227409493178129, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 120, train_loss = 2.2199402252444997, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 121, train_loss = 2.212363138794899, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 122, train_loss = 2.2153253915021196, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 123, train_loss = 2.2079796256730333, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 124, train_loss = 2.2054634554078802, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 125, train_loss = 2.1987875401973724, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 126, train_loss = 2.1964055709540844, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 127, train_loss = 2.192642747075297, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 128, train_loss = 2.1894789139041677, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 129, train_loss = 2.182864443748258, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 130, train_loss = 2.1814456345746294, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "3th- epoch: 131, train_loss = 2.1764879735419527, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "3th- epoch: 132, train_loss = 2.1734530963003635, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "3th- epoch: 133, train_loss = 2.1732102694222704, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "3th- epoch: 134, train_loss = 2.168357470422052, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "3th- epoch: 135, train_loss = 2.165831963182427, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "3th- epoch: 136, train_loss = 2.163566598086618, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "3th- epoch: 137, train_loss = 2.158380831242539, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 138, train_loss = 2.154868205427192, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 139, train_loss = 2.1493727676570415, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 140, train_loss = 2.1460236894199625, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 141, train_loss = 2.141254303394817, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 142, train_loss = 2.141088025062345, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 143, train_loss = 2.1378072164952755, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 144, train_loss = 2.1356271344120614, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 145, train_loss = 2.1320455260574818, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 146, train_loss = 2.1289882783894427, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 147, train_loss = 2.1272206529974937, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 148, train_loss = 2.1235019639134407, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 149, train_loss = 2.119368112355005, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "3th- epoch: 150, train_loss = 2.1148157616262324, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 151, train_loss = 2.1161750207538716, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 152, train_loss = 2.108901619911194, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 153, train_loss = 2.1096494644880295, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 154, train_loss = 2.107677331834566, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 155, train_loss = 2.1051413317327388, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 156, train_loss = 2.1036099146003835, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 157, train_loss = 2.0969397624139674, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 158, train_loss = 2.1003521743114106, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 159, train_loss = 2.094765231013298, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 160, train_loss = 2.0971496179699898, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 161, train_loss = 2.0887380478088744, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 162, train_loss = 2.091931715607643, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 163, train_loss = 2.0847020682995208, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 164, train_loss = 2.0864002841408364, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 165, train_loss = 2.0801434231107123, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 166, train_loss = 2.0828187502920628, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 167, train_loss = 2.075894365727436, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 168, train_loss = 2.0783836307819, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 169, train_loss = 2.072872471064329, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 170, train_loss = 2.071221263438929, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 171, train_loss = 2.0699717588722706, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 172, train_loss = 2.067780628800392, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 173, train_loss = 2.06477989628911, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 174, train_loss = 2.0637685519759543, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 175, train_loss = 2.0604962768848054, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 176, train_loss = 2.05874315276742, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 177, train_loss = 2.0565307053620927, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 178, train_loss = 2.05572521063732, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 179, train_loss = 2.0564023715560324, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 180, train_loss = 2.0559467884595506, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 181, train_loss = 2.0508759754593484, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 182, train_loss = 2.049868779897224, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 183, train_loss = 2.0467162703280337, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 184, train_loss = 2.0444305638666265, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 185, train_loss = 2.0451467633247375, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 186, train_loss = 2.0430320873856544, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 187, train_loss = 2.0375544267590158, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 188, train_loss = 2.0427054539322853, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 189, train_loss = 2.033908614248503, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 190, train_loss = 2.034665610641241, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 191, train_loss = 2.0314030299778096, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 192, train_loss = 2.030580298334826, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 193, train_loss = 2.032028408080805, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 194, train_loss = 2.0302025589044206, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 195, train_loss = 2.0233523423667066, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 196, train_loss = 2.027688672125805, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 197, train_loss = 2.021789876103867, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 198, train_loss = 2.0255141009693034, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 199, train_loss = 2.0201539720292203, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 200, train_loss = 2.016261748969555, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 201, train_loss = 2.018620315939188, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 202, train_loss = 2.0143525637686253, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 203, train_loss = 2.014733464748133, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 204, train_loss = 2.013153230131138, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 205, train_loss = 2.0097691218252294, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 206, train_loss = 2.014311698556412, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 207, train_loss = 2.0087063784594648, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 208, train_loss = 2.006281763315201, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 209, train_loss = 2.0061149547691457, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 210, train_loss = 2.0023680863087066, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 211, train_loss = 2.0072616736288182, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 212, train_loss = 2.001067658246029, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 213, train_loss = 2.001695603132248, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 214, train_loss = 1.998873585194815, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 215, train_loss = 1.998170644044876, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 216, train_loss = 1.997663049667608, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 217, train_loss = 1.9931536329095252, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 218, train_loss = 1.9995092650060542, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 219, train_loss = 1.9936206825077534, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 220, train_loss = 1.9926058389246464, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 221, train_loss = 1.9898722022771835, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 222, train_loss = 1.991239070892334, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 223, train_loss = 1.9895568887586705, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 224, train_loss = 1.987298123538494, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 225, train_loss = 1.9895654283463955, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 226, train_loss = 1.9827293853159063, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 227, train_loss = 1.9859770300681703, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 228, train_loss = 1.98213191825198, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 229, train_loss = 1.9811363257467747, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 230, train_loss = 1.9833101108670235, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 231, train_loss = 1.9797777806525119, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 232, train_loss = 1.9794834554195404, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 233, train_loss = 1.9786253832280636, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 234, train_loss = 1.978058148175478, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 235, train_loss = 1.9756796546280384, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 236, train_loss = 1.974976987869013, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 237, train_loss = 1.9733560631866567, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 238, train_loss = 1.9714039005339146, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 239, train_loss = 1.9725509348209016, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 240, train_loss = 1.9692146157030948, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 241, train_loss = 1.970695408701431, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 242, train_loss = 1.9720802133088, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 243, train_loss = 1.9664594270288944, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 244, train_loss = 1.9668080881237984, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 245, train_loss = 1.966436383605469, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 246, train_loss = 1.967743918299675, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 247, train_loss = 1.9658449205453508, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 248, train_loss = 1.9609327403013594, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 249, train_loss = 1.970993788272608, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 250, train_loss = 1.9599353981320746, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 251, train_loss = 1.9620049211080186, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 252, train_loss = 1.9600821025669575, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 253, train_loss = 1.9593399937148206, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 254, train_loss = 1.9607586972415447, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 255, train_loss = 1.9569739885628223, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 256, train_loss = 1.9559390097856522, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 257, train_loss = 1.9565887314383872, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 258, train_loss = 1.9537826950545423, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 259, train_loss = 1.9534526703355368, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 260, train_loss = 1.9514240423741285, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 261, train_loss = 1.9512219155731145, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 262, train_loss = 1.949556270003086, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 263, train_loss = 1.9499210914073046, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 264, train_loss = 1.9471695820393506, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 265, train_loss = 1.9509979287686292, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 266, train_loss = 1.945868103444809, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 267, train_loss = 1.9472260872425977, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 268, train_loss = 1.9481848664581776, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 269, train_loss = 1.9452546263637487, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 270, train_loss = 1.939787670969963, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 271, train_loss = 1.944907322525978, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 272, train_loss = 1.9421937825682107, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 273, train_loss = 1.9408630393445492, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 274, train_loss = 1.9367370704712812, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 275, train_loss = 1.9402678372862283, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 276, train_loss = 1.9372735346260015, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 277, train_loss = 1.936879951506853, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 278, train_loss = 1.9338795269432012, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 279, train_loss = 1.9373671226203442, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 280, train_loss = 1.9353770092129707, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 281, train_loss = 1.936649632960325, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 282, train_loss = 1.932051212847, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 283, train_loss = 1.9323462334868964, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 284, train_loss = 1.9304909842612687, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "3th- epoch: 285, train_loss = 1.933677597582573, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 286, train_loss = 1.9269212198851164, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 287, train_loss = 1.9284236220119055, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 288, train_loss = 1.9261063200829085, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 289, train_loss = 1.9264398192462977, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 290, train_loss = 1.9255930644867476, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 291, train_loss = 1.9248702985642012, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 292, train_loss = 1.9229702986776829, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 293, train_loss = 1.92384154847241, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 294, train_loss = 1.9215729037823621, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "3th- epoch: 295, train_loss = 1.921469308435917, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 296, train_loss = 1.9189461320638657, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 297, train_loss = 1.9192685385642108, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 298, train_loss = 1.9186798123118933, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 299, train_loss = 1.9187987496552523, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 300, train_loss = 1.9167125312087592, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 301, train_loss = 1.9175806318817195, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 302, train_loss = 1.9135815327463206, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 303, train_loss = 1.916074754059082, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 304, train_loss = 1.9149617689254228, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 305, train_loss = 1.9132304092345294, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 306, train_loss = 1.9103811395762023, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 307, train_loss = 1.9148881758155767, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 308, train_loss = 1.9127319281396922, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 309, train_loss = 1.9107879089715425, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 310, train_loss = 1.9089079412224237, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 311, train_loss = 1.91115384051227, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 312, train_loss = 1.9064756818115711, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 313, train_loss = 1.9082075357437134, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 314, train_loss = 1.9029754934308585, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 315, train_loss = 1.9063500091433525, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 316, train_loss = 1.9029109788534697, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 317, train_loss = 1.9023302309215069, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 318, train_loss = 1.9063105272653047, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 319, train_loss = 1.903867165237898, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 320, train_loss = 1.904890472680563, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 321, train_loss = 1.9023863412439823, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 322, train_loss = 1.9001583444478456, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 323, train_loss = 1.8988131222722586, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 324, train_loss = 1.8989065190253314, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 325, train_loss = 1.8942457462253515, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 326, train_loss = 1.898208217084175, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 327, train_loss = 1.8944375316204969, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 328, train_loss = 1.8962165266275406, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 329, train_loss = 1.8920254036784172, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 330, train_loss = 1.8927995450794697, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 331, train_loss = 1.8924217956664506, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 332, train_loss = 1.894281475484604, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 333, train_loss = 1.890553350240225, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 334, train_loss = 1.890737528592581, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 335, train_loss = 1.8885673446056899, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 336, train_loss = 1.8933627319929656, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 337, train_loss = 1.888597787678009, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 338, train_loss = 1.8902292562124785, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 339, train_loss = 1.8880182206630707, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 340, train_loss = 1.8887438004312571, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 341, train_loss = 1.8859154457750265, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 342, train_loss = 1.8856437541544437, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 343, train_loss = 1.8860564877686556, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 344, train_loss = 1.8839902194740716, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 345, train_loss = 1.8842285722494125, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 346, train_loss = 1.8816303735075053, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 347, train_loss = 1.8820761926472187, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 348, train_loss = 1.8796106427907944, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 349, train_loss = 1.8832638847234193, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 350, train_loss = 1.878240986407036, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 351, train_loss = 1.8775147336127702, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 352, train_loss = 1.8806023014185484, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 353, train_loss = 1.8798381922242697, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 354, train_loss = 1.8766384286282118, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 355, train_loss = 1.8748351819813251, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 356, train_loss = 1.8749018125236034, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 357, train_loss = 1.8751199232938234, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 358, train_loss = 1.8717177212238312, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 359, train_loss = 1.8729741747083608, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 360, train_loss = 1.8737025260925293, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 361, train_loss = 1.8725750098528806, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 362, train_loss = 1.8722741094825324, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 363, train_loss = 1.8689810658397619, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 364, train_loss = 1.8712767722608987, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 365, train_loss = 1.868012711405754, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 366, train_loss = 1.8679443610308226, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 367, train_loss = 1.868450503796339, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 368, train_loss = 1.8670422012510244, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 369, train_loss = 1.8671667091548443, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 370, train_loss = 1.8637225242855493, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 371, train_loss = 1.8671298188564833, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 372, train_loss = 1.863809139787918, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 373, train_loss = 1.8638808652758598, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 374, train_loss = 1.862980996578699, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 375, train_loss = 1.8647242536244448, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 376, train_loss = 1.8603905575873796, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 377, train_loss = 1.860433196037775, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 378, train_loss = 1.8610564470291138, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 379, train_loss = 1.8582937456667423, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 380, train_loss = 1.8587459363043308, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 381, train_loss = 1.8586485683918, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 382, train_loss = 1.8567506459949072, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 383, train_loss = 1.8579305745661259, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 384, train_loss = 1.8546077547071036, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 385, train_loss = 1.8569494647381362, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 386, train_loss = 1.8540772050619125, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 387, train_loss = 1.8592807687819004, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 388, train_loss = 1.8520971263351385, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 389, train_loss = 1.851586490869522, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 390, train_loss = 1.8506571861507837, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 391, train_loss = 1.8511682649550494, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 392, train_loss = 1.8525481633841991, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 393, train_loss = 1.8501422479748726, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 394, train_loss = 1.8504850702884141, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 395, train_loss = 1.849620478838915, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 396, train_loss = 1.8488918878138065, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 397, train_loss = 1.8453380490245763, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 398, train_loss = 1.850949307292467, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 399, train_loss = 1.8445493429899216, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 400, train_loss = 1.8445379796030466, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 401, train_loss = 1.8433927223086357, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 402, train_loss = 1.8443546717462596, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 403, train_loss = 1.842874060064787, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 404, train_loss = 1.8451739797892515, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 405, train_loss = 1.842801400780445, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 406, train_loss = 1.8397031289932784, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 407, train_loss = 1.8405168491008226, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 408, train_loss = 1.8412632445397321, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 409, train_loss = 1.8373609582486097, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 410, train_loss = 1.8390394473972265, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 411, train_loss = 1.836616904794937, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 412, train_loss = 1.8375469259917736, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 413, train_loss = 1.8382211377320345, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 414, train_loss = 1.8363580567238387, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 415, train_loss = 1.8350302875041962, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 416, train_loss = 1.8361314473149832, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 417, train_loss = 1.8346706157026347, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 418, train_loss = 1.8323609332146589, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 419, train_loss = 1.8329402804374695, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 420, train_loss = 1.8333045914769173, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 421, train_loss = 1.8325966807606164, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 422, train_loss = 1.8310541237297002, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 423, train_loss = 1.8328210090694483, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 424, train_loss = 1.8314396043715533, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 425, train_loss = 1.8301777367887553, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 426, train_loss = 1.8295843228697777, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 427, train_loss = 1.827421374619007, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 428, train_loss = 1.8291296921670437, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 429, train_loss = 1.8263505337235983, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 430, train_loss = 1.8261231742799282, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 431, train_loss = 1.8245984762907028, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 432, train_loss = 1.8267954575421754, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 433, train_loss = 1.8236286205647048, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 434, train_loss = 1.8249366879463196, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 435, train_loss = 1.823451068252325, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 436, train_loss = 1.8255033704190282, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 437, train_loss = 1.8210008963942528, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 438, train_loss = 1.820937088385108, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 439, train_loss = 1.819625203803298, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 440, train_loss = 1.8220968420355348, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 441, train_loss = 1.8212880045175552, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 442, train_loss = 1.818786631032708, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 443, train_loss = 1.817248146981001, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 444, train_loss = 1.8208363316953182, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 445, train_loss = 1.815740184232709, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 446, train_loss = 1.8163170951156644, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 447, train_loss = 1.8168348794133635, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 448, train_loss = 1.8141673120408086, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 449, train_loss = 1.8174049655644922, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 450, train_loss = 1.813632580146077, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 451, train_loss = 1.817688014358282, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 452, train_loss = 1.8111187604517909, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 453, train_loss = 1.8130982778966427, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 454, train_loss = 1.810690185680869, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 455, train_loss = 1.8101535526366206, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 456, train_loss = 1.812830951064825, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 457, train_loss = 1.8102679352014093, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 458, train_loss = 1.8095068496913882, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 459, train_loss = 1.8107601826341124, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 460, train_loss = 1.807496157780406, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 461, train_loss = 1.8102055937051773, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 462, train_loss = 1.8069638994784327, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 463, train_loss = 1.8082076124846935, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 464, train_loss = 1.8051405126898317, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 465, train_loss = 1.8049627716391115, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 466, train_loss = 1.8053522519767284, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 467, train_loss = 1.8042642759828595, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 468, train_loss = 1.8033713015465764, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 469, train_loss = 1.803424006953719, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 470, train_loss = 1.8023342502565356, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 471, train_loss = 1.8025952043681173, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 472, train_loss = 1.8059001502842875, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 473, train_loss = 1.7998148289771052, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 474, train_loss = 1.8004587876348523, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 475, train_loss = 1.7995592268853216, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 476, train_loss = 1.7980805834085913, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 477, train_loss = 1.7996474405081244, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 478, train_loss = 1.798867478966713, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 479, train_loss = 1.7969020741729764, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 480, train_loss = 1.7962964574544458, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 481, train_loss = 1.7944034077227116, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 482, train_loss = 1.79585421954107, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 483, train_loss = 1.7941652561275987, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 484, train_loss = 1.79390109454107, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 485, train_loss = 1.795147546872613, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 486, train_loss = 1.7921744088380365, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 487, train_loss = 1.7931955456733704, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 488, train_loss = 1.7947261457593413, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 489, train_loss = 1.7936438893229933, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 490, train_loss = 1.7905873556883307, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 491, train_loss = 1.7892234635801287, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 492, train_loss = 1.7910167177469702, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 493, train_loss = 1.7897435116319684, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 494, train_loss = 1.79053217668843, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 495, train_loss = 1.7875666854233714, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 496, train_loss = 1.7871344064624282, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 497, train_loss = 1.7878097631037235, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 498, train_loss = 1.7862960025668144, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "3th- epoch: 499, train_loss = 1.7877693747432204, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|███████▉                                                                       | 3/30 [27:05<4:03:52, 541.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "4th- epoch: 0, train_loss = 332.82555980980396, train_acc = 0.8161387983232418\n",
      "test Acc 0.8431098696461825:\n",
      "4th- epoch: 1, train_loss = 73.75272573530674, train_acc = 0.9177922682813228\n",
      "test Acc 0.9213221601489758:\n",
      "4th- epoch: 2, train_loss = 48.56806603074074, train_acc = 0.9368886818816954\n",
      "test Acc 0.9320297951582868:\n",
      "4th- epoch: 3, train_loss = 37.2162012681365, train_acc = 0.9457382394038193\n",
      "test Acc 0.9404096834264432:\n",
      "4th- epoch: 4, train_loss = 29.82457783073187, train_acc = 0.9537727061015371\n",
      "test Acc 0.9427374301675978:\n",
      "4th- epoch: 5, train_loss = 24.459229212254286, train_acc = 0.9595947834187238\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 6, train_loss = 20.642129961401224, train_acc = 0.963903120633442\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 7, train_loss = 17.73470837250352, train_acc = 0.9670470423847228\n",
      "test Acc 0.9497206703910615:\n",
      "4th- epoch: 8, train_loss = 15.601019877940416, train_acc = 0.9707731718677224\n",
      "test Acc 0.952048417132216:\n",
      "4th- epoch: 9, train_loss = 13.805580954998732, train_acc = 0.974033535165347\n",
      "test Acc 0.9553072625698324:\n",
      "4th- epoch: 10, train_loss = 12.395007155835629, train_acc = 0.9763623660922217\n",
      "test Acc 0.9557728119180633:\n",
      "4th- epoch: 11, train_loss = 11.211237030103803, train_acc = 0.9775267815556591\n",
      "test Acc 0.957169459962756:\n",
      "4th- epoch: 12, train_loss = 10.238180184736848, train_acc = 0.9791569632044713\n",
      "test Acc 0.9562383612662942:\n",
      "4th- epoch: 13, train_loss = 9.397285735234618, train_acc = 0.98067070330694\n",
      "test Acc 0.9567039106145251:\n",
      "4th- epoch: 14, train_loss = 8.720966992899776, train_acc = 0.9817186772240335\n",
      "test Acc 0.957169459962756:\n",
      "4th- epoch: 15, train_loss = 8.116976963356137, train_acc = 0.9829995342338146\n",
      "test Acc 0.957169459962756:\n",
      "4th- epoch: 16, train_loss = 7.625637095421553, train_acc = 0.9835817419655333\n",
      "test Acc 0.9599627560521415:\n",
      "4th- epoch: 17, train_loss = 7.1981999119743705, train_acc = 0.9848625989753144\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 18, train_loss = 6.790262463502586, train_acc = 0.9856776897997206\n",
      "test Acc 0.9604283054003724:\n",
      "4th- epoch: 19, train_loss = 6.437670822255313, train_acc = 0.9862598975314392\n",
      "test Acc 0.9618249534450651:\n",
      "4th- epoch: 20, train_loss = 6.136591739952564, train_acc = 0.9868421052631579\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 21, train_loss = 5.828332103788853, train_acc = 0.9873078714485328\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 22, train_loss = 5.582838450558484, train_acc = 0.9881229622729389\n",
      "test Acc 0.9613594040968343:\n",
      "4th- epoch: 23, train_loss = 5.338045088108629, train_acc = 0.9883558453656265\n",
      "test Acc 0.962756052141527:\n",
      "4th- epoch: 24, train_loss = 5.12912268564105, train_acc = 0.9884722869119702\n",
      "test Acc 0.962756052141527:\n",
      "4th- epoch: 25, train_loss = 4.9233660735189915, train_acc = 0.9891709361900326\n",
      "test Acc 0.962756052141527:\n",
      "4th- epoch: 26, train_loss = 4.744566658046097, train_acc = 0.9895202608290639\n",
      "test Acc 0.962756052141527:\n",
      "4th- epoch: 27, train_loss = 4.592389779631048, train_acc = 0.9901024685607824\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 28, train_loss = 4.44849219545722, train_acc = 0.9902189101071263\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 29, train_loss = 4.325917897280306, train_acc = 0.99033535165347\n",
      "test Acc 0.9636871508379888:\n",
      "4th- epoch: 30, train_loss = 4.208735869731754, train_acc = 0.99033535165347\n",
      "test Acc 0.9646182495344506:\n",
      "4th- epoch: 31, train_loss = 4.101288417819887, train_acc = 0.99033535165347\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 32, train_loss = 3.9985516231972724, train_acc = 0.99033535165347\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 33, train_loss = 3.9078818659763783, train_acc = 0.9906846762925011\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 34, train_loss = 3.8267578568775207, train_acc = 0.9906846762925011\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 35, train_loss = 3.7478077996056527, train_acc = 0.9909175593851887\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 36, train_loss = 3.6642456476110965, train_acc = 0.9910340009315324\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 37, train_loss = 3.612149399938062, train_acc = 0.9913833255705635\n",
      "test Acc 0.9650837988826816:\n",
      "4th- epoch: 38, train_loss = 3.533637824235484, train_acc = 0.9914997671169073\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 39, train_loss = 3.467249386012554, train_acc = 0.9916162086632511\n",
      "test Acc 0.9655493482309124:\n",
      "4th- epoch: 40, train_loss = 3.422399577917531, train_acc = 0.9918490917559385\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 41, train_loss = 3.3662474292796105, train_acc = 0.9919655333022822\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 42, train_loss = 3.3086990267038345, train_acc = 0.9919655333022822\n",
      "test Acc 0.9660148975791434:\n",
      "4th- epoch: 43, train_loss = 3.2564712800085545, train_acc = 0.9919655333022822\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 44, train_loss = 3.209256869973615, train_acc = 0.992081974848626\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 45, train_loss = 3.178565137088299, train_acc = 0.992081974848626\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 46, train_loss = 3.133665370522067, train_acc = 0.9921984163949698\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 47, train_loss = 3.0810037441551685, train_acc = 0.9923148579413135\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 48, train_loss = 3.041183090535924, train_acc = 0.9923148579413135\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 49, train_loss = 3.0059952822048217, train_acc = 0.9921984163949698\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 50, train_loss = 2.965893962653354, train_acc = 0.9924312994876572\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 51, train_loss = 2.9303620010614395, train_acc = 0.9924312994876572\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 52, train_loss = 2.89859976246953, train_acc = 0.9924312994876572\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 53, train_loss = 2.8762533962726593, train_acc = 0.9925477410340009\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 54, train_loss = 2.8414644736330956, train_acc = 0.9926641825803446\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 55, train_loss = 2.8108391675632447, train_acc = 0.9927806241266884\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 56, train_loss = 2.7943931445479393, train_acc = 0.9928970656730322\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 57, train_loss = 2.7593353129923344, train_acc = 0.9927806241266884\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 58, train_loss = 2.7436283242423087, train_acc = 0.9927806241266884\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 59, train_loss = 2.718719843775034, train_acc = 0.9928970656730322\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 60, train_loss = 2.6904092070180923, train_acc = 0.9928970656730322\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 61, train_loss = 2.669405164895579, train_acc = 0.9930135072193759\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 62, train_loss = 2.65245795622468, train_acc = 0.9931299487657196\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 63, train_loss = 2.6308653440792114, train_acc = 0.9930135072193759\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 64, train_loss = 2.6177081242203712, train_acc = 0.9931299487657196\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 65, train_loss = 2.594731805147603, train_acc = 0.9932463903120633\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 66, train_loss = 2.5856231052894145, train_acc = 0.9932463903120633\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 67, train_loss = 2.564650073647499, train_acc = 0.9934792734047508\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 68, train_loss = 2.54534625262022, train_acc = 0.9933628318584071\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 69, train_loss = 2.5415898773353547, train_acc = 0.9933628318584071\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 70, train_loss = 2.514461113838479, train_acc = 0.9934792734047508\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 71, train_loss = 2.501668866723776, train_acc = 0.9934792734047508\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 72, train_loss = 2.4881033934652805, train_acc = 0.9935957149510946\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 73, train_loss = 2.477260838029906, train_acc = 0.9937121564974383\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 74, train_loss = 2.4706189706921577, train_acc = 0.993828598043782\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 75, train_loss = 2.447212652536109, train_acc = 0.993828598043782\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 76, train_loss = 2.437829402508214, train_acc = 0.993828598043782\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 77, train_loss = 2.424451782135293, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 78, train_loss = 2.420082616386935, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 79, train_loss = 2.4071805018465966, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 80, train_loss = 2.3975851498544216, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 81, train_loss = 2.38155726226978, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 82, train_loss = 2.3696636743843555, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 83, train_loss = 2.3571918557863683, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 84, train_loss = 2.352285958826542, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 85, train_loss = 2.3403478127438575, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 86, train_loss = 2.3329104457516223, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 87, train_loss = 2.3229000468272716, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 88, train_loss = 2.3136246502399445, train_acc = 0.9937121564974383\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 89, train_loss = 2.310624375939369, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 90, train_loss = 2.306558250216767, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 91, train_loss = 2.2959145333152264, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 92, train_loss = 2.2928809573641047, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 93, train_loss = 2.281820824951865, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 94, train_loss = 2.2795231889467686, train_acc = 0.9941779226828132\n",
      "test Acc 0.9678770949720671:\n",
      "4th- epoch: 95, train_loss = 2.27041507512331, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 96, train_loss = 2.2596516410121694, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 97, train_loss = 2.2525155507028103, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 98, train_loss = 2.249546761275269, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 99, train_loss = 2.237553868442774, train_acc = 0.9940614811364695\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 100, train_loss = 2.2388749979436398, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 101, train_loss = 2.225853351294063, train_acc = 0.9941779226828132\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 102, train_loss = 2.229799526394345, train_acc = 0.994294364229157\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 103, train_loss = 2.2215021984884515, train_acc = 0.9941779226828132\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 104, train_loss = 2.211397076607682, train_acc = 0.9940614811364695\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 105, train_loss = 2.2087932961294428, train_acc = 0.994294364229157\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 106, train_loss = 2.1999600902199745, train_acc = 0.994294364229157\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 107, train_loss = 2.1988851875066757, train_acc = 0.994294364229157\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 108, train_loss = 2.1906100511550903, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 109, train_loss = 2.185673980624415, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "4th- epoch: 110, train_loss = 2.184333043755032, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 111, train_loss = 2.1835438311100006, train_acc = 0.994294364229157\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 112, train_loss = 2.173768130480312, train_acc = 0.994294364229157\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 113, train_loss = 2.169756335555576, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 114, train_loss = 2.1634865986416116, train_acc = 0.994294364229157\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 115, train_loss = 2.1586681343615055, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "4th- epoch: 116, train_loss = 2.1541479775914922, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "4th- epoch: 117, train_loss = 2.147479958832264, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "4th- epoch: 118, train_loss = 2.140246581286192, train_acc = 0.9941779226828132\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 119, train_loss = 2.1398203261196613, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "4th- epoch: 120, train_loss = 2.138278345228173, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 121, train_loss = 2.1410011388361454, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "4th- epoch: 122, train_loss = 2.137336271465756, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 123, train_loss = 2.1309626922011375, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 124, train_loss = 2.1238447166979313, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 125, train_loss = 2.1162761449813843, train_acc = 0.9941779226828132\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 126, train_loss = 2.1180608881404623, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 127, train_loss = 2.113567934720777, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 128, train_loss = 2.1082058859756216, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 129, train_loss = 2.1044554027030244, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 130, train_loss = 2.1023525273194537, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 131, train_loss = 2.0975475000450388, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 132, train_loss = 2.0972753452369943, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 133, train_loss = 2.092379224835895, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 134, train_loss = 2.086691737174988, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 135, train_loss = 2.088985557318665, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 136, train_loss = 2.0884967198362574, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 137, train_loss = 2.0848899768898264, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 138, train_loss = 2.0888402486452833, train_acc = 0.9941779226828132\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 139, train_loss = 2.075413290411234, train_acc = 0.9941779226828132\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 140, train_loss = 2.0708609906723723, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 141, train_loss = 2.068577258498408, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 142, train_loss = 2.0618497245013714, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 143, train_loss = 2.0623838491737843, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 144, train_loss = 2.056080644368194, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 145, train_loss = 2.0594884058227763, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 146, train_loss = 2.055472948937677, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 147, train_loss = 2.0449823985109106, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 148, train_loss = 2.048157458542846, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 149, train_loss = 2.0456135583808646, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 150, train_loss = 2.0384067855775356, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 151, train_loss = 2.0351770346751437, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 152, train_loss = 2.0352377891540527, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 153, train_loss = 2.0373229397227988, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 154, train_loss = 2.03249103075359, train_acc = 0.9941779226828132\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 155, train_loss = 2.031389083713293, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 156, train_loss = 2.0232071690261364, train_acc = 0.9941779226828132\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 157, train_loss = 2.0222134875366464, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 158, train_loss = 2.0259300818433985, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 159, train_loss = 2.0185678551206365, train_acc = 0.9941779226828132\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 160, train_loss = 2.0171217570314184, train_acc = 0.9941779226828132\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 161, train_loss = 2.012361733824946, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "4th- epoch: 162, train_loss = 2.0185191532364115, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 163, train_loss = 2.007759021013044, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 164, train_loss = 2.0064509449293837, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 165, train_loss = 2.003713591664564, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 166, train_loss = 2.00064452982042, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 167, train_loss = 1.9962000747327693, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 168, train_loss = 1.9898672749404795, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 169, train_loss = 1.991882277012337, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 170, train_loss = 1.986603642522823, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 171, train_loss = 1.9878944369847886, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 172, train_loss = 1.9840131650562398, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 173, train_loss = 1.9760551626677625, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 174, train_loss = 1.978946428745985, train_acc = 0.9941779226828132\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 175, train_loss = 1.9725264646112919, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 176, train_loss = 1.974554032087326, train_acc = 0.9941779226828132\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 177, train_loss = 1.967948290228378, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 178, train_loss = 1.9693290975992568, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 179, train_loss = 1.9683411444420926, train_acc = 0.9941779226828132\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 180, train_loss = 1.964873742312193, train_acc = 0.9941779226828132\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 181, train_loss = 1.9663112846319564, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 182, train_loss = 1.9734793789684772, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 183, train_loss = 1.9634232756798156, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 184, train_loss = 1.9546168061788194, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 185, train_loss = 1.9561828176374547, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 186, train_loss = 1.9552800990641117, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "4th- epoch: 187, train_loss = 1.9558252394199371, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 188, train_loss = 1.9544684911961667, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 189, train_loss = 1.9464951865375042, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 190, train_loss = 1.9495588379795663, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 191, train_loss = 1.9408285890822299, train_acc = 0.9941779226828132\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 192, train_loss = 1.9411500592832454, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 193, train_loss = 1.9421463161706924, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 194, train_loss = 1.9401942777330987, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 195, train_loss = 1.9382336896960624, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 196, train_loss = 1.9397231762413867, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 197, train_loss = 1.932244582741987, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 198, train_loss = 1.934606799215544, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 199, train_loss = 1.9304910066421144, train_acc = 0.9941779226828132\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 200, train_loss = 1.925291035324335, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 201, train_loss = 1.9255515709519386, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 202, train_loss = 1.9276713666622527, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 203, train_loss = 1.9240095168352127, train_acc = 0.9941779226828132\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 204, train_loss = 1.91577149432851, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 205, train_loss = 1.9181094926898368, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 206, train_loss = 1.918401513248682, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 207, train_loss = 1.9208237913553603, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 208, train_loss = 1.913448425650131, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 209, train_loss = 1.910321194678545, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 210, train_loss = 1.9123120568692684, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 211, train_loss = 1.9138521701097488, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 212, train_loss = 1.9067313994164579, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 213, train_loss = 1.9079611897468567, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 214, train_loss = 1.9057395222480409, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 215, train_loss = 1.905540941923391, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 216, train_loss = 1.9009696816210635, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 217, train_loss = 1.901026173203718, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 218, train_loss = 1.8991614381666295, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 219, train_loss = 1.8985954523086548, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 220, train_loss = 1.8976106022601016, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 221, train_loss = 1.8969469008152373, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 222, train_loss = 1.8955266972188838, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 223, train_loss = 1.8954119247500785, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 224, train_loss = 1.8876905615325086, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 225, train_loss = 1.8928114920854568, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 226, train_loss = 1.8854940608143806, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 227, train_loss = 1.8906896114349365, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 228, train_loss = 1.8879218598012812, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 229, train_loss = 1.8826032591168769, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 230, train_loss = 1.8810164853930473, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 231, train_loss = 1.877824954688549, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 232, train_loss = 1.8797395924921148, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 233, train_loss = 1.8798598498106003, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 234, train_loss = 1.8749065287411213, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 235, train_loss = 1.8752788243000396, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 236, train_loss = 1.8790299892425537, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 237, train_loss = 1.874913131177891, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 238, train_loss = 1.869996449619066, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 239, train_loss = 1.8718434050679207, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 240, train_loss = 1.8700799110229127, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 241, train_loss = 1.8671515460009687, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 242, train_loss = 1.8681489911978133, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 243, train_loss = 1.8698824408347718, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 244, train_loss = 1.8613281014258973, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 245, train_loss = 1.8636656564776786, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 246, train_loss = 1.8593280452187173, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 247, train_loss = 1.8612355391378514, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 248, train_loss = 1.8657133902306668, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 249, train_loss = 1.8619330947403796, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 250, train_loss = 1.8600755333900452, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 251, train_loss = 1.8586473601753823, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 252, train_loss = 1.8530668790335767, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 253, train_loss = 1.8555690285866149, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 254, train_loss = 1.8510075882077217, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 255, train_loss = 1.8525222440366633, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 256, train_loss = 1.8507670524413697, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 257, train_loss = 1.8509798410232179, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 258, train_loss = 1.8451846900279634, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 259, train_loss = 1.8512645115260966, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 260, train_loss = 1.846899253607262, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 261, train_loss = 1.847833327949047, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 262, train_loss = 1.844372533261776, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 263, train_loss = 1.8456029308144934, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 264, train_loss = 1.8436430804431438, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 265, train_loss = 1.8464556981925853, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 266, train_loss = 1.8414927795529366, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 267, train_loss = 1.8426377773284912, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 268, train_loss = 1.8355354343657382, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 269, train_loss = 1.8387529005412944, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 270, train_loss = 1.837203084200155, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 271, train_loss = 1.8376062512397766, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 272, train_loss = 1.8318475050036795, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 273, train_loss = 1.8357670356635936, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 274, train_loss = 1.8304314116830938, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 275, train_loss = 1.8341244992916472, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 276, train_loss = 1.8291549868881702, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 277, train_loss = 1.8354899287223816, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 278, train_loss = 1.8361030059750192, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 279, train_loss = 1.8267267160117626, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 280, train_loss = 1.8239233493804932, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 281, train_loss = 1.8266076408326626, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 282, train_loss = 1.8195618416066281, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 283, train_loss = 1.821014293760527, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 284, train_loss = 1.8212806756491773, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 285, train_loss = 1.8249761275947094, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 286, train_loss = 1.8217460475862026, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 287, train_loss = 1.8233110544388182, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 288, train_loss = 1.81888697296381, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 289, train_loss = 1.8213576463167556, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 290, train_loss = 1.8173868979210965, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 291, train_loss = 1.8194259628653526, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 292, train_loss = 1.816398922353983, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 293, train_loss = 1.81926580023719, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 294, train_loss = 1.8105526069994085, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 295, train_loss = 1.8120206755702384, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 296, train_loss = 1.809697661548853, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 297, train_loss = 1.8112265194649808, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 298, train_loss = 1.8096477091312408, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 299, train_loss = 1.8099850018625148, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 300, train_loss = 1.8091046151821502, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 301, train_loss = 1.8074637266690843, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 302, train_loss = 1.8056769880349748, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 303, train_loss = 1.804748507856857, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 304, train_loss = 1.80440403270768, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 305, train_loss = 1.806352219224209, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 306, train_loss = 1.8036317552032415, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 307, train_loss = 1.7993006992037408, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 308, train_loss = 1.8031391339900438, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 309, train_loss = 1.801388287305599, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 310, train_loss = 1.8009454905986786, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 311, train_loss = 1.800281041621929, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 312, train_loss = 1.7980301020143088, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 313, train_loss = 1.7984341830015182, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 314, train_loss = 1.7924600429832935, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 315, train_loss = 1.7976458581688348, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 316, train_loss = 1.800975480437046, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 317, train_loss = 1.7956510248186532, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 318, train_loss = 1.7926794476807117, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 319, train_loss = 1.7933068238198757, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 320, train_loss = 1.7963135267200414, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 321, train_loss = 1.7915175209345762, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 322, train_loss = 1.794721713900799, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 323, train_loss = 1.7925054927763995, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 324, train_loss = 1.79005291685462, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 325, train_loss = 1.7903187374176923, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 326, train_loss = 1.7943056350050028, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 327, train_loss = 1.7884857369062956, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 328, train_loss = 1.7852740238013212, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 329, train_loss = 1.7847494470479432, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 330, train_loss = 1.788959631085163, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 331, train_loss = 1.788446461170679, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 332, train_loss = 1.7835653039219324, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 333, train_loss = 1.7900735549628735, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 334, train_loss = 1.783797870069975, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 335, train_loss = 1.7829852737486362, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 336, train_loss = 1.7843781113624573, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 337, train_loss = 1.7815657767059747, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 338, train_loss = 1.7849607405660208, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 339, train_loss = 1.776773358375067, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 340, train_loss = 1.7820044197142124, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "4th- epoch: 341, train_loss = 1.780722195893759, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 342, train_loss = 1.781326503813034, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 343, train_loss = 1.7819543989899103, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 344, train_loss = 1.783398906380171, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 345, train_loss = 1.7779290974140167, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 346, train_loss = 1.7756998141703662, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 347, train_loss = 1.7762902552785818, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 348, train_loss = 1.7787470606563147, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 349, train_loss = 1.7793674754502717, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 350, train_loss = 1.7747705144283827, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 351, train_loss = 1.7811695548298303, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 352, train_loss = 1.7742486322822515, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 353, train_loss = 1.776840467005968, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 354, train_loss = 1.7697835291328374, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 355, train_loss = 1.775686427950859, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 356, train_loss = 1.7722047890129033, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 357, train_loss = 1.7699581111373845, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 358, train_loss = 1.7746264649031218, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 359, train_loss = 1.7707727129163686, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 360, train_loss = 1.764952386409277, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 361, train_loss = 1.7690837122499943, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 362, train_loss = 1.7669111800787505, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 363, train_loss = 1.7688916785118636, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 364, train_loss = 1.7632128459808882, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 365, train_loss = 1.767896576464409, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 366, train_loss = 1.76684158295393, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 367, train_loss = 1.7637620829045773, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 368, train_loss = 1.7653221140208188, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 369, train_loss = 1.7686754080059472, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 370, train_loss = 1.7611372085812036, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 371, train_loss = 1.770770809293026, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 372, train_loss = 1.761446874588728, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 373, train_loss = 1.7678115529415663, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 374, train_loss = 1.7580942884087563, train_acc = 0.9945272473218444\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 375, train_loss = 1.765360414981842, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 376, train_loss = 1.7606619037687778, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 377, train_loss = 1.7616856023669243, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 378, train_loss = 1.7579263100924436, train_acc = 0.9945272473218444\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 379, train_loss = 1.7629239025118295, train_acc = 0.9945272473218444\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 380, train_loss = 1.7645790825190488, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 381, train_loss = 1.7573848540487234, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 382, train_loss = 1.7578327469527721, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 383, train_loss = 1.7554293548164424, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 384, train_loss = 1.7570788599550724, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 385, train_loss = 1.7567657977342606, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "4th- epoch: 386, train_loss = 1.758404452353716, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 387, train_loss = 1.7575691801903304, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 388, train_loss = 1.7572033604083117, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 389, train_loss = 1.7541252436640207, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 390, train_loss = 1.7484472133219242, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 391, train_loss = 1.7525922780332621, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 392, train_loss = 1.7545814712939318, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 393, train_loss = 1.7530042876896914, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 394, train_loss = 1.7525553864834365, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 395, train_loss = 1.7489377359452192, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 396, train_loss = 1.7506462683377322, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 397, train_loss = 1.7508397065103054, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 398, train_loss = 1.7466954924166203, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "4th- epoch: 399, train_loss = 1.7476731650531292, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 400, train_loss = 1.7511241473257542, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 401, train_loss = 1.7526843609812204, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 402, train_loss = 1.7492251520452555, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 403, train_loss = 1.7467160473170225, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 404, train_loss = 1.7485554652812425, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 405, train_loss = 1.7485476980509702, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 406, train_loss = 1.7447142712771893, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 407, train_loss = 1.7423236270842608, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 408, train_loss = 1.7504896260797977, train_acc = 0.9945272473218444\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 409, train_loss = 1.738091936946148, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 410, train_loss = 1.7431878745555878, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 411, train_loss = 1.7427325944008771, train_acc = 0.9944108057755007\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 412, train_loss = 1.7414100244641304, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 413, train_loss = 1.74077076712274, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 414, train_loss = 1.7424071567656938, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 415, train_loss = 1.7448647320270538, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 416, train_loss = 1.74400869384408, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 417, train_loss = 1.7420251878502313, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 418, train_loss = 1.739172250032425, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 419, train_loss = 1.7391731180250645, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 420, train_loss = 1.7388906031847, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 421, train_loss = 1.7361988524498884, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 422, train_loss = 1.7385687828063965, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 423, train_loss = 1.7400744693877641, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 424, train_loss = 1.7404663202760275, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 425, train_loss = 1.7363502656517085, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 426, train_loss = 1.7354164272546768, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 427, train_loss = 1.7360542255046312, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 428, train_loss = 1.7342365135846194, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 429, train_loss = 1.7328764200210571, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 430, train_loss = 1.7306091474893037, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 431, train_loss = 1.7348511753079947, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 432, train_loss = 1.7304003362951335, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 433, train_loss = 1.7303189486265182, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 434, train_loss = 1.7317037445900496, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 435, train_loss = 1.733371521026129, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 436, train_loss = 1.7325323919358198, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 437, train_loss = 1.732310945779318, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 438, train_loss = 1.732468026370043, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 439, train_loss = 1.7295374547538813, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 440, train_loss = 1.7289707946183626, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 441, train_loss = 1.7302424857916776, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 442, train_loss = 1.726052150130272, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 443, train_loss = 1.7300871362385806, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 444, train_loss = 1.7265907538530882, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 445, train_loss = 1.7251181453466415, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 446, train_loss = 1.7284317500889301, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 447, train_loss = 1.7251126170158386, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 448, train_loss = 1.727319428086048, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 449, train_loss = 1.7234784203174058, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 450, train_loss = 1.7206994084117468, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 451, train_loss = 1.723399934679037, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 452, train_loss = 1.7234099383058492, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 453, train_loss = 1.7226217985153198, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 454, train_loss = 1.7277576364576817, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 455, train_loss = 1.7244214353559073, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 456, train_loss = 1.7213561832904816, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 457, train_loss = 1.7205618011357728, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 458, train_loss = 1.7193069532513618, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 459, train_loss = 1.7199541255831718, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 460, train_loss = 1.7191515093145426, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 461, train_loss = 1.724005363881588, train_acc = 0.9945272473218444\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 462, train_loss = 1.7156449941394385, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 463, train_loss = 1.7155387550592422, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 464, train_loss = 1.7176907944085542, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 465, train_loss = 1.717652142047882, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 466, train_loss = 1.716163881123066, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 467, train_loss = 1.7145794654788915, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 468, train_loss = 1.7152748877706472, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 469, train_loss = 1.7160199148056563, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 470, train_loss = 1.7154734916985035, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 471, train_loss = 1.7135153574345168, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 472, train_loss = 1.7190695864555892, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "4th- epoch: 473, train_loss = 1.7164739854633808, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 474, train_loss = 1.7206046717765275, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 475, train_loss = 1.7130586480197962, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 476, train_loss = 1.7146382071077824, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 477, train_loss = 1.7140442257223185, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 478, train_loss = 1.7077489482762758, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 479, train_loss = 1.7093407859501895, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 480, train_loss = 1.710128548234934, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 481, train_loss = 1.7083163795468863, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 482, train_loss = 1.71414135149098, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 483, train_loss = 1.7091640084981918, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 484, train_loss = 1.7103568191232625, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 485, train_loss = 1.7138554751873016, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 486, train_loss = 1.7072983980178833, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 487, train_loss = 1.7084159168007318, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 488, train_loss = 1.7082010383310262, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 489, train_loss = 1.7106503956019878, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 490, train_loss = 1.7102641575038433, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 491, train_loss = 1.7060943270626012, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 492, train_loss = 1.708012916147709, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 493, train_loss = 1.7093700418772642, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 494, train_loss = 1.7059940633771475, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 495, train_loss = 1.7060811842384282, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 496, train_loss = 1.7065361179411411, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 497, train_loss = 1.7028720118105412, train_acc = 0.9945272473218444\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 498, train_loss = 1.705160460114712, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "4th- epoch: 499, train_loss = 1.6999968588352203, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 13%|██████████▌                                                                    | 4/30 [36:05<3:54:41, 541.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "5th- epoch: 0, train_loss = 370.9947271794081, train_acc = 0.8118304611085235\n",
      "test Acc 0.861266294227188:\n",
      "5th- epoch: 1, train_loss = 68.47119829431176, train_acc = 0.9233814625058221\n",
      "test Acc 0.9334264432029795:\n",
      "5th- epoch: 2, train_loss = 46.0054566138424, train_acc = 0.941895668374476\n",
      "test Acc 0.9413407821229051:\n",
      "5th- epoch: 3, train_loss = 35.46444514160976, train_acc = 0.9527247321844434\n",
      "test Acc 0.9436685288640596:\n",
      "5th- epoch: 4, train_loss = 28.910816465504467, train_acc = 0.9590125756870052\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 5, train_loss = 24.097903138957918, train_acc = 0.9642524452724732\n",
      "test Acc 0.9487895716945997:\n",
      "5th- epoch: 6, train_loss = 20.529527474194765, train_acc = 0.9682114578481602\n",
      "test Acc 0.952048417132216:\n",
      "5th- epoch: 7, train_loss = 17.733967100270092, train_acc = 0.972286911970191\n",
      "test Acc 0.9529795158286778:\n",
      "5th- epoch: 8, train_loss = 15.543214432895184, train_acc = 0.9743828598043782\n",
      "test Acc 0.9553072625698324:\n",
      "5th- epoch: 9, train_loss = 13.806584204547107, train_acc = 0.9767116907312529\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 10, train_loss = 12.356964357197285, train_acc = 0.9796227293898463\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 11, train_loss = 11.130743664689362, train_acc = 0.9811364694923148\n",
      "test Acc 0.9562383612662942:\n",
      "5th- epoch: 12, train_loss = 10.093420987017453, train_acc = 0.9824173265020959\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 13, train_loss = 9.169392446987331, train_acc = 0.9835817419655333\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 14, train_loss = 8.436347502283752, train_acc = 0.9845132743362832\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 15, train_loss = 7.7687455313280225, train_acc = 0.9857941313460643\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 16, train_loss = 7.244489029981196, train_acc = 0.9862598975314392\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 17, train_loss = 6.757680889219046, train_acc = 0.9864927806241267\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 18, train_loss = 6.356799148954451, train_acc = 0.9868421052631579\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 19, train_loss = 6.014964018017054, train_acc = 0.9868421052631579\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 20, train_loss = 5.695049789734185, train_acc = 0.9870749883558454\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 21, train_loss = 5.429879221133888, train_acc = 0.9876571960875641\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 22, train_loss = 5.190583652816713, train_acc = 0.9883558453656265\n",
      "test Acc 0.9590316573556797:\n",
      "5th- epoch: 23, train_loss = 4.980021816678345, train_acc = 0.9881229622729389\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 24, train_loss = 4.799081760458648, train_acc = 0.9891709361900326\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 25, train_loss = 4.6409815438091755, train_acc = 0.9892873777363763\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 26, train_loss = 4.488881682045758, train_acc = 0.9897531439217513\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 27, train_loss = 4.359936747699976, train_acc = 0.9896367023754076\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 28, train_loss = 4.234062414616346, train_acc = 0.989869585468095\n",
      "test Acc 0.9604283054003724:\n",
      "5th- epoch: 29, train_loss = 4.118792586028576, train_acc = 0.9901024685607824\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 30, train_loss = 4.022378098219633, train_acc = 0.9905682347461574\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 31, train_loss = 3.928664936684072, train_acc = 0.9906846762925011\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 32, train_loss = 3.82836752012372, train_acc = 0.9911504424778761\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 33, train_loss = 3.758138809353113, train_acc = 0.9909175593851887\n",
      "test Acc 0.9632216014897579:\n",
      "5th- epoch: 34, train_loss = 3.667383878491819, train_acc = 0.9912668840242198\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 35, train_loss = 3.5983905605971813, train_acc = 0.9914997671169073\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 36, train_loss = 3.5158670591190457, train_acc = 0.9917326502095948\n",
      "test Acc 0.9636871508379888:\n",
      "5th- epoch: 37, train_loss = 3.451781508512795, train_acc = 0.9917326502095948\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 38, train_loss = 3.377400944940746, train_acc = 0.9918490917559385\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 39, train_loss = 3.3233685651794076, train_acc = 0.9923148579413135\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 40, train_loss = 3.2647474259138107, train_acc = 0.9921984163949698\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 41, train_loss = 3.1970479101873934, train_acc = 0.9924312994876572\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 42, train_loss = 3.1458223410882056, train_acc = 0.9921984163949698\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 43, train_loss = 3.0995394214987755, train_acc = 0.9926641825803446\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 44, train_loss = 3.050795543938875, train_acc = 0.9925477410340009\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 45, train_loss = 3.005462085362524, train_acc = 0.9925477410340009\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 46, train_loss = 2.9558124118484557, train_acc = 0.9928970656730322\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 47, train_loss = 2.920878928154707, train_acc = 0.9927806241266884\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 48, train_loss = 2.8848031610250473, train_acc = 0.9932463903120633\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 49, train_loss = 2.8520146175287664, train_acc = 0.9932463903120633\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 50, train_loss = 2.8191678398288786, train_acc = 0.9930135072193759\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 51, train_loss = 2.78311850130558, train_acc = 0.9935957149510946\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 52, train_loss = 2.76415037130937, train_acc = 0.9935957149510946\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 53, train_loss = 2.734533343464136, train_acc = 0.9935957149510946\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 54, train_loss = 2.7088102945126593, train_acc = 0.9935957149510946\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 55, train_loss = 2.675988505128771, train_acc = 0.9937121564974383\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 56, train_loss = 2.666906412690878, train_acc = 0.9935957149510946\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 57, train_loss = 2.6367202647961676, train_acc = 0.993828598043782\n",
      "test Acc 0.9646182495344506:\n",
      "5th- epoch: 58, train_loss = 2.603549186140299, train_acc = 0.9940614811364695\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 59, train_loss = 2.592368248850107, train_acc = 0.993828598043782\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 60, train_loss = 2.5851539722643793, train_acc = 0.9939450395901258\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 61, train_loss = 2.5551494546234608, train_acc = 0.9939450395901258\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 62, train_loss = 2.529659152030945, train_acc = 0.9939450395901258\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 63, train_loss = 2.517409441526979, train_acc = 0.9939450395901258\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 64, train_loss = 2.5027389801107347, train_acc = 0.9941779226828132\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 65, train_loss = 2.4856676161289215, train_acc = 0.9939450395901258\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 66, train_loss = 2.465945893432945, train_acc = 0.9940614811364695\n",
      "test Acc 0.9655493482309124:\n",
      "5th- epoch: 67, train_loss = 2.4462525048293173, train_acc = 0.9940614811364695\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 68, train_loss = 2.433749964926392, train_acc = 0.9941779226828132\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 69, train_loss = 2.4186601326800883, train_acc = 0.9941779226828132\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 70, train_loss = 2.404776605311781, train_acc = 0.9944108057755007\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 71, train_loss = 2.395247459411621, train_acc = 0.9944108057755007\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 72, train_loss = 2.3779494711197913, train_acc = 0.994294364229157\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 73, train_loss = 2.367337929783389, train_acc = 0.9941779226828132\n",
      "test Acc 0.9660148975791434:\n",
      "5th- epoch: 74, train_loss = 2.359318217728287, train_acc = 0.9944108057755007\n",
      "test Acc 0.9664804469273743:\n",
      "5th- epoch: 75, train_loss = 2.3435781572479755, train_acc = 0.994294364229157\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 76, train_loss = 2.3343135218601674, train_acc = 0.994294364229157\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 77, train_loss = 2.3090347696561366, train_acc = 0.9944108057755007\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 78, train_loss = 2.311505949823186, train_acc = 0.9946436888681882\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 79, train_loss = 2.3046860843896866, train_acc = 0.9948765719608756\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 80, train_loss = 2.2829999327659607, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 81, train_loss = 2.2895042200107127, train_acc = 0.9945272473218444\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 82, train_loss = 2.2703467186074704, train_acc = 0.9946436888681882\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 83, train_loss = 2.2621284883935004, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 84, train_loss = 2.260124932974577, train_acc = 0.9948765719608756\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 85, train_loss = 2.2380299840588123, train_acc = 0.9946436888681882\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 86, train_loss = 2.238196264952421, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 87, train_loss = 2.2342256146948785, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 88, train_loss = 2.2224909167271107, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 89, train_loss = 2.212463591247797, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 90, train_loss = 2.202842937083915, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 91, train_loss = 2.2043315817136317, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 92, train_loss = 2.195400781929493, train_acc = 0.9946436888681882\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 93, train_loss = 2.190524060279131, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 94, train_loss = 2.180263200076297, train_acc = 0.9946436888681882\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 95, train_loss = 2.181063584983349, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 96, train_loss = 2.1676818665582687, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 97, train_loss = 2.1612667676527053, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 98, train_loss = 2.159485046984628, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 99, train_loss = 2.1554620563983917, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 100, train_loss = 2.1489794477820396, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 101, train_loss = 2.143547722371295, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 102, train_loss = 2.1346865308005363, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 103, train_loss = 2.1329893942456692, train_acc = 0.9948765719608756\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 104, train_loss = 2.1282317477744073, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 105, train_loss = 2.1218861069064587, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 106, train_loss = 2.117267496883869, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 107, train_loss = 2.109793469309807, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 108, train_loss = 2.101283024996519, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 109, train_loss = 2.1068525947630405, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 110, train_loss = 2.1003942551324144, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 111, train_loss = 2.0988689748337492, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "5th- epoch: 112, train_loss = 2.0910520082106814, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 113, train_loss = 2.0859129428863525, train_acc = 0.9948765719608756\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 114, train_loss = 2.080010537058115, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 115, train_loss = 2.0734406696865335, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 116, train_loss = 2.0754425153136253, train_acc = 0.9948765719608756\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 117, train_loss = 2.0654718888690695, train_acc = 0.9948765719608756\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 118, train_loss = 2.064804577617906, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 119, train_loss = 2.062327090650797, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 120, train_loss = 2.0616180896759033, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 121, train_loss = 2.0551418649265543, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 122, train_loss = 2.0549590699374676, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 123, train_loss = 2.054316350608133, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 124, train_loss = 2.0519287263741717, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 125, train_loss = 2.0454477245220914, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 126, train_loss = 2.041358691989444, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 127, train_loss = 2.040494645596482, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 128, train_loss = 2.0387994199991226, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 129, train_loss = 2.0347157741198316, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 130, train_loss = 2.020899262279272, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 131, train_loss = 2.024615233181976, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 132, train_loss = 2.0292522497475147, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 133, train_loss = 2.0185358561575413, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 134, train_loss = 2.0145749039947987, train_acc = 0.9948765719608756\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 135, train_loss = 2.012830497114919, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 136, train_loss = 2.006040543317795, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 137, train_loss = 2.000963824451901, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 138, train_loss = 2.004533921717666, train_acc = 0.9949930135072194\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 139, train_loss = 2.0102478662738577, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 140, train_loss = 2.006259704590775, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 141, train_loss = 1.9937709979712963, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 142, train_loss = 1.98909293115139, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 143, train_loss = 1.9857275473186746, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 144, train_loss = 1.985608384013176, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 145, train_loss = 1.9831160927424207, train_acc = 0.9949930135072194\n",
      "test Acc 0.9683426443202979:\n",
      "5th- epoch: 146, train_loss = 1.9863587295403704, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 147, train_loss = 1.9803165396442637, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 148, train_loss = 1.9818992912769318, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 149, train_loss = 1.97467789798975, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 150, train_loss = 1.9792708767345175, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 151, train_loss = 1.9720760894706473, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 152, train_loss = 1.9744284140178934, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 153, train_loss = 1.9728591939201578, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "5th- epoch: 154, train_loss = 1.9718763530254364, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 155, train_loss = 1.9666730910539627, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 156, train_loss = 1.9655053578317165, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 157, train_loss = 1.9630176685750484, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "5th- epoch: 158, train_loss = 1.963648603647016, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 159, train_loss = 1.9616208871593699, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 160, train_loss = 1.9584094025194645, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 161, train_loss = 1.9636102368822321, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 162, train_loss = 1.9626461999723688, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 163, train_loss = 1.9532980161020532, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 164, train_loss = 1.9547219251981005, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 165, train_loss = 1.952702819078695, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 166, train_loss = 1.949091151356697, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 167, train_loss = 1.950366756587755, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 168, train_loss = 1.9455425751511939, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 169, train_loss = 1.9374845499987714, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 170, train_loss = 1.9367715008556843, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 171, train_loss = 1.9327109952573664, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 172, train_loss = 1.9346492402255535, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 173, train_loss = 1.9450613197986968, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 174, train_loss = 1.9305227746372111, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 175, train_loss = 1.9243557527661324, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 176, train_loss = 1.9334847169811837, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 177, train_loss = 1.9292163153295405, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 178, train_loss = 1.926465476572048, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 179, train_loss = 1.9239778146147728, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 180, train_loss = 1.9225674718618393, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 181, train_loss = 1.9241534073953517, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 182, train_loss = 1.9210618908400647, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 183, train_loss = 1.918797402351629, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 184, train_loss = 1.9229182476992719, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 185, train_loss = 1.915987613319885, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 186, train_loss = 1.9162452556192875, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 187, train_loss = 1.9141542837023735, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 188, train_loss = 1.9161984473466873, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 189, train_loss = 1.9118661135435104, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 190, train_loss = 1.9143180425162427, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 191, train_loss = 1.9220514322514646, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 192, train_loss = 1.918290386616718, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 193, train_loss = 1.9153789791162126, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 194, train_loss = 1.9049333955044858, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 195, train_loss = 1.8989709988236427, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 196, train_loss = 1.9026482912595384, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 197, train_loss = 1.905057483643759, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 198, train_loss = 1.89983470243169, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 199, train_loss = 1.8923959831590764, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 200, train_loss = 1.8891784374718554, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 201, train_loss = 1.8912032793159597, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 202, train_loss = 1.8891074545681477, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 203, train_loss = 1.8864403155748732, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 204, train_loss = 1.8927695515449159, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 205, train_loss = 1.8864519869093783, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "5th- epoch: 206, train_loss = 1.8812402014737017, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 207, train_loss = 1.8802112080156803, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 208, train_loss = 1.8751007330720313, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 209, train_loss = 1.8772161354427226, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 210, train_loss = 1.8751762484316714, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 211, train_loss = 1.8776460128719918, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 212, train_loss = 1.8715620363946073, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 213, train_loss = 1.870709213137161, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 214, train_loss = 1.8724434971809387, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 215, train_loss = 1.8683717399835587, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 216, train_loss = 1.8682848264579661, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 217, train_loss = 1.8657711160485633, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 218, train_loss = 1.86889749270631, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 219, train_loss = 1.8611611053347588, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 220, train_loss = 1.8656868201796897, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 221, train_loss = 1.8608202946488746, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 222, train_loss = 1.8648446599836461, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 223, train_loss = 1.87558263289975, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 224, train_loss = 1.8648928254842758, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 225, train_loss = 1.8627193942666054, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 226, train_loss = 1.8647414855659008, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 227, train_loss = 1.8604939778451808, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 228, train_loss = 1.8606951770489104, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 229, train_loss = 1.8617979536647908, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 230, train_loss = 1.8614385115797631, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 231, train_loss = 1.8623884904081933, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 232, train_loss = 1.8582185879349709, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 233, train_loss = 1.8593678225879557, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 234, train_loss = 1.8561027472023852, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 235, train_loss = 1.8536645472049713, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 236, train_loss = 1.8566673820023425, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 237, train_loss = 1.8521024286746979, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 238, train_loss = 1.8509739277069457, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 239, train_loss = 1.8510233287815936, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 240, train_loss = 1.8511159792542458, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 241, train_loss = 1.8457607266609557, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 242, train_loss = 1.8541731002624147, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 243, train_loss = 1.842067280143965, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 244, train_loss = 1.8455091615323909, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 245, train_loss = 1.8445010855793953, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 246, train_loss = 1.8444643691182137, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 247, train_loss = 1.842538585246075, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "5th- epoch: 248, train_loss = 1.8417247695033439, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 249, train_loss = 1.8396116929943673, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 250, train_loss = 1.8432831217651255, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 251, train_loss = 1.8414472354052123, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 252, train_loss = 1.835081393510336, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 253, train_loss = 1.8333333432674408, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 254, train_loss = 1.8373461067676544, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 255, train_loss = 1.8379176097805612, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 256, train_loss = 1.8366604422626551, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 257, train_loss = 1.8364694615302142, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 258, train_loss = 1.833158191293478, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 259, train_loss = 1.8304097788932268, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 260, train_loss = 1.8349499156174716, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 261, train_loss = 1.8326911156473216, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 262, train_loss = 1.8295474139449652, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 263, train_loss = 1.8308250159025192, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "5th- epoch: 264, train_loss = 1.8312670128943864, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 265, train_loss = 1.8321085957286414, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 266, train_loss = 1.826221987605095, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 267, train_loss = 1.825851379573578, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 268, train_loss = 1.8236444567737635, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 269, train_loss = 1.8248875488934573, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 270, train_loss = 1.821495638549095, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 271, train_loss = 1.8233825005590916, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 272, train_loss = 1.8218004653754178, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 273, train_loss = 1.823427995055681, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 274, train_loss = 1.8245626191201154, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 275, train_loss = 1.8195449225604534, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 276, train_loss = 1.8156164387764875, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 277, train_loss = 1.8225752810540143, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 278, train_loss = 1.818648769200081, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 279, train_loss = 1.815239328891039, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 280, train_loss = 1.8162453273835126, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 281, train_loss = 1.8155616782605648, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 282, train_loss = 1.8143658749759197, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 283, train_loss = 1.8124223910272121, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 284, train_loss = 1.8133983214793261, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 285, train_loss = 1.8133442973194178, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 286, train_loss = 1.8169324534537736, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 287, train_loss = 1.8148865650000516, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 288, train_loss = 1.8122034656407777, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 289, train_loss = 1.8128537870943546, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 290, train_loss = 1.8115288466215134, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 291, train_loss = 1.8140221250650939, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 292, train_loss = 1.8062323691847268, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 293, train_loss = 1.8068576703371946, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 294, train_loss = 1.8104867575166281, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 295, train_loss = 1.8074411563575268, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 296, train_loss = 1.8102881026861724, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 297, train_loss = 1.8153252129850443, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 298, train_loss = 1.808734034508234, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 299, train_loss = 1.8101528944971506, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 300, train_loss = 1.8029023557901382, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 301, train_loss = 1.8054167603550013, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 302, train_loss = 1.8060651794075966, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 303, train_loss = 1.80385453501367, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 304, train_loss = 1.8040946920809802, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 305, train_loss = 1.8003606436250266, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 306, train_loss = 1.8009289751353208, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 307, train_loss = 1.7994475637970027, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 308, train_loss = 1.7956713885068893, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 309, train_loss = 1.7975619261560496, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 310, train_loss = 1.8016333008708898, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 311, train_loss = 1.7991001047194004, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 312, train_loss = 1.800705580651993, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 313, train_loss = 1.8024931562540587, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 314, train_loss = 1.8010455444455147, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 315, train_loss = 1.794309070945019, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 316, train_loss = 1.7991016022861004, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 317, train_loss = 1.8011703888478223, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 318, train_loss = 1.7930896157922689, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 319, train_loss = 1.7981174401938915, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 320, train_loss = 1.7928489409387112, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 321, train_loss = 1.7974975146353245, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 322, train_loss = 1.79205602654838, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 323, train_loss = 1.7926468265650328, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 324, train_loss = 1.7975123400392476, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 325, train_loss = 1.7953231471183244, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 326, train_loss = 1.7924000285565853, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 327, train_loss = 1.7951701966521796, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 328, train_loss = 1.789383447408909, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 329, train_loss = 1.793557122349739, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 330, train_loss = 1.7897803895175457, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 331, train_loss = 1.7890783734619617, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 332, train_loss = 1.7904793433845043, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 333, train_loss = 1.784701889991993, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 334, train_loss = 1.7893946282565594, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 335, train_loss = 1.7833812845346984, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 336, train_loss = 1.7841176291403826, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 337, train_loss = 1.7805983920989092, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 338, train_loss = 1.7807558116910513, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 339, train_loss = 1.7810770893993322, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 340, train_loss = 1.783662964910036, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 341, train_loss = 1.7889726298453752, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 342, train_loss = 1.779516036302084, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 343, train_loss = 1.785570789128542, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 344, train_loss = 1.7871244425477926, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 345, train_loss = 1.788837922125822, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 346, train_loss = 1.7796188866195735, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 347, train_loss = 1.7785689632000867, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 348, train_loss = 1.7836273188295309, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 349, train_loss = 1.7777837614121381, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 350, train_loss = 1.7896374389529228, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 351, train_loss = 1.7742052910325583, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 352, train_loss = 1.7755960052309092, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 353, train_loss = 1.777809951454401, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 354, train_loss = 1.7734923636016902, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 355, train_loss = 1.7827294009330217, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 356, train_loss = 1.7790804840624332, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 357, train_loss = 1.7725084958074149, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 358, train_loss = 1.7720904561283533, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 359, train_loss = 1.7707930815813597, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 360, train_loss = 1.7709471645357553, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 361, train_loss = 1.7711449414491653, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 362, train_loss = 1.7706475220620632, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 363, train_loss = 1.7679707979259547, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 364, train_loss = 1.7686183551850263, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 365, train_loss = 1.7695679242315236, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 366, train_loss = 1.7678795692918357, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 367, train_loss = 1.7756000297667924, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 368, train_loss = 1.7678434178233147, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 369, train_loss = 1.7811970276234206, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 370, train_loss = 1.7675069322285708, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 371, train_loss = 1.7715364272298757, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 372, train_loss = 1.7718288836476859, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 373, train_loss = 1.7724344208836555, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 374, train_loss = 1.764578147471184, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 375, train_loss = 1.771738206356531, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 376, train_loss = 1.7636454539897386, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 377, train_loss = 1.7748176778259221, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 378, train_loss = 1.7613665163516998, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 379, train_loss = 1.7789690444769803, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 380, train_loss = 1.767148770391941, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 381, train_loss = 1.7609995044767857, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 382, train_loss = 1.7638325169682503, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 383, train_loss = 1.7615902771649417, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 384, train_loss = 1.7576022495923098, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 385, train_loss = 1.7588917513785418, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 386, train_loss = 1.758388097077841, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 387, train_loss = 1.7625198351743165, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 388, train_loss = 1.7587718094291631, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 389, train_loss = 1.754511191189522, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 390, train_loss = 1.7617612158355769, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 391, train_loss = 1.755263658851618, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 392, train_loss = 1.7599791971442755, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 393, train_loss = 1.7565486108360346, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 394, train_loss = 1.7581703066825867, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 395, train_loss = 1.7531292425992433, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 396, train_loss = 1.7596318051218987, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 397, train_loss = 1.752203962445492, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 398, train_loss = 1.7509355483052786, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 399, train_loss = 1.756042268127203, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 400, train_loss = 1.7529923779366072, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 401, train_loss = 1.7566494767961558, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 402, train_loss = 1.7501791343092918, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 403, train_loss = 1.7508148737251759, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 404, train_loss = 1.7481183434429113, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 405, train_loss = 1.7542126923799515, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 406, train_loss = 1.7508561400172766, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 407, train_loss = 1.747059150278801, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 408, train_loss = 1.7532462552189827, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 409, train_loss = 1.7487011017801706, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 410, train_loss = 1.7445369909110013, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 411, train_loss = 1.7469107297656592, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 412, train_loss = 1.7450089702906553, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 413, train_loss = 1.7497808945772704, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 414, train_loss = 1.7443838082253933, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 415, train_loss = 1.7493141392769758, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 416, train_loss = 1.745315968990326, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 417, train_loss = 1.7419162268342916, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 418, train_loss = 1.7476180903613567, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 419, train_loss = 1.743493172019953, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 420, train_loss = 1.7416550517082214, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 421, train_loss = 1.7414039596915245, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 422, train_loss = 1.739806018769741, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 423, train_loss = 1.7485608408751432, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 424, train_loss = 1.7397480731306132, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 425, train_loss = 1.737822058290476, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 426, train_loss = 1.7396160600183066, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 427, train_loss = 1.7430400575103704, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 428, train_loss = 1.7394574632344302, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 429, train_loss = 1.7386293845775072, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 430, train_loss = 1.739977352321148, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 431, train_loss = 1.736369858175749, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 432, train_loss = 1.743082918226719, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 433, train_loss = 1.736050891369814, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 434, train_loss = 1.7360489231941756, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 435, train_loss = 1.7357913479208946, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 436, train_loss = 1.7348371781408787, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 437, train_loss = 1.7314728920755442, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 438, train_loss = 1.7343595834972803, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 439, train_loss = 1.7386129684746265, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 440, train_loss = 1.7352638182637747, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 441, train_loss = 1.7329193912446499, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 442, train_loss = 1.7343265948293265, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 443, train_loss = 1.7330851393344346, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 444, train_loss = 1.7373074144124985, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 445, train_loss = 1.7330644875764847, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 446, train_loss = 1.7299414053559303, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 447, train_loss = 1.73168114820146, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 448, train_loss = 1.735656334712985, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 449, train_loss = 1.7296817786991596, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 450, train_loss = 1.7309998137352522, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 451, train_loss = 1.7282960092124995, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 452, train_loss = 1.7269913256168365, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 453, train_loss = 1.7288420672120992, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 454, train_loss = 1.7348434726300184, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 455, train_loss = 1.7267320677638054, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 456, train_loss = 1.724297221750021, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 457, train_loss = 1.7331687100231647, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 458, train_loss = 1.724984942615265, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 459, train_loss = 1.7254796077904757, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 460, train_loss = 1.7245770556182833, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 461, train_loss = 1.7262379427847918, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 462, train_loss = 1.7288131639361382, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 463, train_loss = 1.7222391975519713, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 464, train_loss = 1.7224280225636903, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 465, train_loss = 1.7292592488229275, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 466, train_loss = 1.721283150211093, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 467, train_loss = 1.7262551883904962, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 468, train_loss = 1.7207670795469312, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 469, train_loss = 1.7218656217009993, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 470, train_loss = 1.7198014482855797, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 471, train_loss = 1.7288012144417735, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 472, train_loss = 1.7188279777765274, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 473, train_loss = 1.7196933875529794, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 474, train_loss = 1.7190854921936989, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 475, train_loss = 1.7194242713449057, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 476, train_loss = 1.7229759370238753, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 477, train_loss = 1.719492835298297, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 478, train_loss = 1.7180671046226053, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 479, train_loss = 1.7151365081517724, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 480, train_loss = 1.7234249735920457, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 481, train_loss = 1.7166384185402421, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 482, train_loss = 1.71397515386343, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 483, train_loss = 1.7162934678344755, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 484, train_loss = 1.7179865638463525, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 485, train_loss = 1.7127926821558503, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 486, train_loss = 1.7137804006488295, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 487, train_loss = 1.7139449169189902, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 488, train_loss = 1.7121364461927442, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 489, train_loss = 1.7184216951281996, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 490, train_loss = 1.7115977220237255, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 491, train_loss = 1.7123985973448725, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 492, train_loss = 1.7127499766647816, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 493, train_loss = 1.7105686453433009, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 494, train_loss = 1.7109849316329928, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 495, train_loss = 1.709723482534173, train_acc = 0.9951094550535631\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 496, train_loss = 1.716335968420026, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "5th- epoch: 497, train_loss = 1.7112857811152935, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "5th- epoch: 498, train_loss = 1.7082995039672824, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 499, train_loss = 1.7163413713424234, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█████████████▏                                                                 | 5/30 [45:06<3:45:31, 541.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "6th- epoch: 0, train_loss = 349.0102285593748, train_acc = 0.8161387983232418\n",
      "test Acc 0.8654562383612663:\n",
      "6th- epoch: 1, train_loss = 70.40784086287022, train_acc = 0.9212855146716349\n",
      "test Acc 0.9031657355679702:\n",
      "6th- epoch: 2, train_loss = 46.42570476233959, train_acc = 0.9391010712622264\n",
      "test Acc 0.9432029795158287:\n",
      "6th- epoch: 3, train_loss = 33.63119020778686, train_acc = 0.9507452258965999\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 4, train_loss = 26.58014624333009, train_acc = 0.9585468095016302\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 5, train_loss = 21.895890720188618, train_acc = 0.9644853283651607\n",
      "test Acc 0.9506517690875232:\n",
      "6th- epoch: 6, train_loss = 18.694379299879074, train_acc = 0.9679785747554728\n",
      "test Acc 0.9501862197392924:\n",
      "6th- epoch: 7, train_loss = 16.216425869613886, train_acc = 0.9710060549604099\n",
      "test Acc 0.9515828677839852:\n",
      "6th- epoch: 8, train_loss = 14.237955216318369, train_acc = 0.9732184443409408\n",
      "test Acc 0.9515828677839852:\n",
      "6th- epoch: 9, train_loss = 12.55777719989419, train_acc = 0.9763623660922217\n",
      "test Acc 0.952048417132216:\n",
      "6th- epoch: 10, train_loss = 11.218618399230763, train_acc = 0.9784583139264089\n",
      "test Acc 0.9539106145251397:\n",
      "6th- epoch: 11, train_loss = 10.10557147487998, train_acc = 0.9798556124825337\n",
      "test Acc 0.9548417132216015:\n",
      "6th- epoch: 12, train_loss = 9.24074820172973, train_acc = 0.9812529110386586\n",
      "test Acc 0.9548417132216015:\n",
      "6th- epoch: 13, train_loss = 8.528791472315788, train_acc = 0.9825337680484397\n",
      "test Acc 0.9562383612662942:\n",
      "6th- epoch: 14, train_loss = 7.864701472222805, train_acc = 0.9839310666045645\n",
      "test Acc 0.9567039106145251:\n",
      "6th- epoch: 15, train_loss = 7.36398159340024, train_acc = 0.9846297158826269\n",
      "test Acc 0.9562383612662942:\n",
      "6th- epoch: 16, train_loss = 6.876276241033338, train_acc = 0.9861434559850955\n",
      "test Acc 0.9567039106145251:\n",
      "6th- epoch: 17, train_loss = 6.421373349963687, train_acc = 0.9868421052631579\n",
      "test Acc 0.9567039106145251:\n",
      "6th- epoch: 18, train_loss = 6.038529376150109, train_acc = 0.9880065207265952\n",
      "test Acc 0.9567039106145251:\n",
      "6th- epoch: 19, train_loss = 5.738532772869803, train_acc = 0.9887051700046576\n",
      "test Acc 0.957169459962756:\n",
      "6th- epoch: 20, train_loss = 5.445792840211652, train_acc = 0.9891709361900326\n",
      "test Acc 0.9581005586592178:\n",
      "6th- epoch: 21, train_loss = 5.205317745567299, train_acc = 0.9896367023754076\n",
      "test Acc 0.9585661080074488:\n",
      "6th- epoch: 22, train_loss = 4.974120009690523, train_acc = 0.9897531439217513\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 23, train_loss = 4.788886999129318, train_acc = 0.989869585468095\n",
      "test Acc 0.9590316573556797:\n",
      "6th- epoch: 24, train_loss = 4.6170234704623, train_acc = 0.9897531439217513\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 25, train_loss = 4.469020766555332, train_acc = 0.9901024685607824\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 26, train_loss = 4.336548094986938, train_acc = 0.9905682347461574\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 27, train_loss = 4.195580148487352, train_acc = 0.9904517931998137\n",
      "test Acc 0.9594972067039106:\n",
      "6th- epoch: 28, train_loss = 4.0767972357571125, train_acc = 0.9906846762925011\n",
      "test Acc 0.9590316573556797:\n",
      "6th- epoch: 29, train_loss = 3.9890767000615597, train_acc = 0.9910340009315324\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 30, train_loss = 3.8796681948006153, train_acc = 0.9914997671169073\n",
      "test Acc 0.9604283054003724:\n",
      "6th- epoch: 31, train_loss = 3.793311962275766, train_acc = 0.9911504424778761\n",
      "test Acc 0.9604283054003724:\n",
      "6th- epoch: 32, train_loss = 3.7058666311204433, train_acc = 0.9912668840242198\n",
      "test Acc 0.9599627560521415:\n",
      "6th- epoch: 33, train_loss = 3.6433636968722567, train_acc = 0.9916162086632511\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 34, train_loss = 3.563233982771635, train_acc = 0.9918490917559385\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 35, train_loss = 3.505286625237204, train_acc = 0.9918490917559385\n",
      "test Acc 0.9608938547486033:\n",
      "6th- epoch: 36, train_loss = 3.44421663263347, train_acc = 0.9917326502095948\n",
      "test Acc 0.962756052141527:\n",
      "6th- epoch: 37, train_loss = 3.3667505656485446, train_acc = 0.992081974848626\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 38, train_loss = 3.3187370846862905, train_acc = 0.9918490917559385\n",
      "test Acc 0.9641527001862198:\n",
      "6th- epoch: 39, train_loss = 3.270790309936274, train_acc = 0.9918490917559385\n",
      "test Acc 0.9646182495344506:\n",
      "6th- epoch: 40, train_loss = 3.2256968083092943, train_acc = 0.992081974848626\n",
      "test Acc 0.9650837988826816:\n",
      "6th- epoch: 41, train_loss = 3.162227967113722, train_acc = 0.992081974848626\n",
      "test Acc 0.9650837988826816:\n",
      "6th- epoch: 42, train_loss = 3.1234003988211043, train_acc = 0.9921984163949698\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 43, train_loss = 3.0698727915878408, train_acc = 0.9921984163949698\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 44, train_loss = 3.0359988063573837, train_acc = 0.9924312994876572\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 45, train_loss = 3.0088784880936146, train_acc = 0.9924312994876572\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 46, train_loss = 2.964119626849424, train_acc = 0.9925477410340009\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 47, train_loss = 2.928232209116686, train_acc = 0.9925477410340009\n",
      "test Acc 0.9660148975791434:\n",
      "6th- epoch: 48, train_loss = 2.9036414846777916, train_acc = 0.9926641825803446\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 49, train_loss = 2.8632287606596947, train_acc = 0.9926641825803446\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 50, train_loss = 2.8416228406131268, train_acc = 0.9926641825803446\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 51, train_loss = 2.811619069427252, train_acc = 0.9927806241266884\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 52, train_loss = 2.7813053031568415, train_acc = 0.9927806241266884\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 53, train_loss = 2.7620807513594627, train_acc = 0.9927806241266884\n",
      "test Acc 0.9669459962756052:\n",
      "6th- epoch: 54, train_loss = 2.7279240650241263, train_acc = 0.9930135072193759\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 55, train_loss = 2.7127417835290544, train_acc = 0.9927806241266884\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 56, train_loss = 2.670764774084091, train_acc = 0.9930135072193759\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 57, train_loss = 2.66112894192338, train_acc = 0.9931299487657196\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 58, train_loss = 2.645867322862614, train_acc = 0.9930135072193759\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 59, train_loss = 2.61717551574111, train_acc = 0.9930135072193759\n",
      "test Acc 0.9683426443202979:\n",
      "6th- epoch: 60, train_loss = 2.5854479211266153, train_acc = 0.9928970656730322\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 61, train_loss = 2.566119113296736, train_acc = 0.9931299487657196\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 62, train_loss = 2.567909629375208, train_acc = 0.9930135072193759\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 63, train_loss = 2.550171418755781, train_acc = 0.9932463903120633\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 64, train_loss = 2.502580622851383, train_acc = 0.9931299487657196\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 65, train_loss = 2.508705602318514, train_acc = 0.9931299487657196\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 66, train_loss = 2.4827694135601632, train_acc = 0.9933628318584071\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 67, train_loss = 2.4731359854340553, train_acc = 0.9933628318584071\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 68, train_loss = 2.4473489175434224, train_acc = 0.9933628318584071\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 69, train_loss = 2.4424682185053825, train_acc = 0.9935957149510946\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 70, train_loss = 2.4213277958333492, train_acc = 0.9934792734047508\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 71, train_loss = 2.4232482314109802, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 72, train_loss = 2.3935650885105133, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 73, train_loss = 2.391615644097328, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 74, train_loss = 2.3698796543176286, train_acc = 0.9937121564974383\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 75, train_loss = 2.3601706686313264, train_acc = 0.9937121564974383\n",
      "test Acc 0.9692737430167597:\n",
      "6th- epoch: 76, train_loss = 2.3611989741330035, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 77, train_loss = 2.347804137796629, train_acc = 0.9935957149510946\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 78, train_loss = 2.337312458723318, train_acc = 0.993828598043782\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 79, train_loss = 2.323025692254305, train_acc = 0.993828598043782\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 80, train_loss = 2.315248090773821, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 81, train_loss = 2.3150664815912023, train_acc = 0.9935957149510946\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 82, train_loss = 2.3025231150677428, train_acc = 0.993828598043782\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 83, train_loss = 2.272277402400505, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 84, train_loss = 2.2920531816780567, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 85, train_loss = 2.2784654473070987, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 86, train_loss = 2.2759238953585736, train_acc = 0.993828598043782\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 87, train_loss = 2.25142476829933, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 88, train_loss = 2.2585865072906017, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 89, train_loss = 2.2462203627219424, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 90, train_loss = 2.2442552173743024, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 91, train_loss = 2.223475653678179, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 92, train_loss = 2.2368537870352156, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 93, train_loss = 2.2126780090038665, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 94, train_loss = 2.220997203141451, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 95, train_loss = 2.2052033245563507, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 96, train_loss = 2.2022611064021476, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 97, train_loss = 2.191412063955795, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 98, train_loss = 2.190817611932289, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 99, train_loss = 2.179132776975166, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 100, train_loss = 2.172719382971991, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 101, train_loss = 2.1710287903551944, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 102, train_loss = 2.1600786087219603, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 103, train_loss = 2.1618744023144245, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 104, train_loss = 2.1459751278162003, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 105, train_loss = 2.1537229108507745, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 106, train_loss = 2.148468979925383, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 107, train_loss = 2.1484448214177974, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 108, train_loss = 2.1362145083840005, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 109, train_loss = 2.1319309410755523, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 110, train_loss = 2.120955503254663, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 111, train_loss = 2.1294852159917355, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 112, train_loss = 2.111933560401667, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 113, train_loss = 2.1209536492824554, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 114, train_loss = 2.111729244410526, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 115, train_loss = 2.1101421378552914, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 116, train_loss = 2.0996256209909916, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 117, train_loss = 2.0877208511228673, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 118, train_loss = 2.0933714397251606, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 119, train_loss = 2.0997984272544272, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 120, train_loss = 2.084243113815319, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 121, train_loss = 2.079376672685612, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 122, train_loss = 2.0779063142836094, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 123, train_loss = 2.084878512949217, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 124, train_loss = 2.0629642928834073, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 125, train_loss = 2.0806622467935085, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 126, train_loss = 2.0690700635313988, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 127, train_loss = 2.0521049822564237, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 128, train_loss = 2.0650131801958196, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 129, train_loss = 2.056812584400177, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 130, train_loss = 2.0645993538200855, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 131, train_loss = 2.0548233948647976, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 132, train_loss = 2.04888554912759, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 133, train_loss = 2.0571665205061436, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 134, train_loss = 2.0320246790652163, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 135, train_loss = 2.034838527441025, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 136, train_loss = 2.048308353871107, train_acc = 0.9941779226828132\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 137, train_loss = 2.029080808162689, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 138, train_loss = 2.01819957542466, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "6th- epoch: 139, train_loss = 2.018397760868538, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 140, train_loss = 2.023465048521757, train_acc = 0.9941779226828132\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 141, train_loss = 2.0142185005242936, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 142, train_loss = 2.030825227499008, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 143, train_loss = 2.011803788424004, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 144, train_loss = 2.030366222083103, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 145, train_loss = 2.008258746296633, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 146, train_loss = 1.9939016823773272, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 147, train_loss = 2.010703327774536, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 148, train_loss = 2.0183638160233386, train_acc = 0.9947601304145319\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 149, train_loss = 2.00301567587303, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 150, train_loss = 2.009197006642353, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 151, train_loss = 2.016585299104918, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 152, train_loss = 1.9961268131737597, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 153, train_loss = 1.9888805585796945, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 154, train_loss = 1.9934743556077592, train_acc = 0.9947601304145319\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 155, train_loss = 1.9992481370572932, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 156, train_loss = 1.9877520178561099, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 157, train_loss = 1.9936704349820502, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 158, train_loss = 1.9839419250492938, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 159, train_loss = 1.9825268859858625, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 160, train_loss = 1.9924846614594571, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 161, train_loss = 1.9794888620381244, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 162, train_loss = 1.9802591775660403, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 163, train_loss = 1.9801133585278876, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 164, train_loss = 1.9781175342504866, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 165, train_loss = 1.9759328390355222, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 166, train_loss = 1.97971412044717, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 167, train_loss = 1.9830582824652083, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 168, train_loss = 1.971789671748411, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 169, train_loss = 1.966645019769203, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 170, train_loss = 1.977599826932419, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 171, train_loss = 1.9593199218506925, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 172, train_loss = 1.9670807607471943, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 173, train_loss = 1.9670478515326977, train_acc = 0.9947601304145319\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 174, train_loss = 1.9654187820851803, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 175, train_loss = 1.967047993093729, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 176, train_loss = 1.9530579944257624, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 177, train_loss = 1.9507272827322595, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 178, train_loss = 1.9495432202820666, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 179, train_loss = 1.9450081201794092, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 180, train_loss = 1.9523596937360708, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 181, train_loss = 1.9546464321610983, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 182, train_loss = 1.9495905650255736, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 183, train_loss = 1.9446973241865635, train_acc = 0.9947601304145319\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 184, train_loss = 1.9478529530169908, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 185, train_loss = 1.9502066485583782, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 186, train_loss = 1.948472522199154, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 187, train_loss = 1.9385156842472497, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 188, train_loss = 1.9485109634697437, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 189, train_loss = 1.9416289466025773, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 190, train_loss = 1.9504710795881692, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 191, train_loss = 1.9413017630577087, train_acc = 0.9947601304145319\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 192, train_loss = 1.942244715988636, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 193, train_loss = 1.9425818795862142, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 194, train_loss = 1.9440357573330402, train_acc = 0.9947601304145319\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 195, train_loss = 1.94276574999094, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 196, train_loss = 1.9375222052040044, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 197, train_loss = 1.9315960071980953, train_acc = 0.9947601304145319\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 198, train_loss = 1.93496123701334, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 199, train_loss = 1.9345392224786337, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 200, train_loss = 1.9340996680257376, train_acc = 0.9947601304145319\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 201, train_loss = 1.9318670866487082, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 202, train_loss = 1.9280782317218836, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 203, train_loss = 1.933214428514475, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 204, train_loss = 1.9311764004232828, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 205, train_loss = 1.9239483177661896, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 206, train_loss = 1.9231668772699777, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 207, train_loss = 1.9249065766634885, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 208, train_loss = 1.9214404448866844, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 209, train_loss = 1.9189157076179981, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 210, train_loss = 1.9188403611478861, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 211, train_loss = 1.9179275780916214, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 212, train_loss = 1.9080600080487784, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 213, train_loss = 1.9112179329094943, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 214, train_loss = 1.9115019912424032, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 215, train_loss = 1.9116015657782555, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 216, train_loss = 1.908448114991188, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 217, train_loss = 1.9030305159685668, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 218, train_loss = 1.9100677035748959, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 219, train_loss = 1.9110223203897476, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 220, train_loss = 1.9042290970683098, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 221, train_loss = 1.9033740845916327, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 222, train_loss = 1.9050408937036991, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 223, train_loss = 1.9110311418771744, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 224, train_loss = 1.9100216887891293, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 225, train_loss = 1.9066049779357854, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 226, train_loss = 1.8934491239488125, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 227, train_loss = 1.8945281269552652, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 228, train_loss = 1.899850632995367, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 229, train_loss = 1.9120124131441116, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 230, train_loss = 1.9006301226618234, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "6th- epoch: 231, train_loss = 1.8949101865291595, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 232, train_loss = 1.8846051680448, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 233, train_loss = 1.8866954880359117, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 234, train_loss = 1.8951123779115733, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 235, train_loss = 1.8993022131326143, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 236, train_loss = 1.896759739756817, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 237, train_loss = 1.8956120187940542, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 238, train_loss = 1.8949155645968858, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 239, train_loss = 1.8971016680297907, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 240, train_loss = 1.878328057617182, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 241, train_loss = 1.8780289677379187, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 242, train_loss = 1.8864669874310493, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 243, train_loss = 1.8906108227965888, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 244, train_loss = 1.8838807245192584, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 245, train_loss = 1.877184920012951, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 246, train_loss = 1.881250310689211, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 247, train_loss = 1.884184888243908, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 248, train_loss = 1.8871706003847066, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 249, train_loss = 1.8872342494723853, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 250, train_loss = 1.8826484630408231, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 251, train_loss = 1.890307743102312, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 252, train_loss = 1.8876517278549727, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 253, train_loss = 1.8866839644906577, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 254, train_loss = 1.882332709938055, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 255, train_loss = 1.8813603868184146, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 256, train_loss = 1.8798714267613832, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 257, train_loss = 1.884300102799898, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 258, train_loss = 1.8695730877516326, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 259, train_loss = 1.8645424358546734, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 260, train_loss = 1.8699776952562388, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 261, train_loss = 1.8754269368946552, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 262, train_loss = 1.8814840229752008, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 263, train_loss = 1.8797338170406874, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 264, train_loss = 1.876417137682438, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 265, train_loss = 1.8741301434638444, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 266, train_loss = 1.8758630578813609, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 267, train_loss = 1.8778996393084526, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 268, train_loss = 1.8710846677422523, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 269, train_loss = 1.873090678214794, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 270, train_loss = 1.8643221842648927, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 271, train_loss = 1.8733245680632535, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 272, train_loss = 1.8649881084857043, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 273, train_loss = 1.8678937231597956, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 274, train_loss = 1.8696173926291522, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 275, train_loss = 1.8724610333738383, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 276, train_loss = 1.8564777560532093, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 277, train_loss = 1.8547800369560719, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 278, train_loss = 1.8571506837906782, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 279, train_loss = 1.8570998571813107, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 280, train_loss = 1.858823458343977, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 281, train_loss = 1.865601122379303, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 282, train_loss = 1.8661925978958607, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 283, train_loss = 1.8632539784011897, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 284, train_loss = 1.8625920923950616, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 285, train_loss = 1.8529919472930487, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 286, train_loss = 1.8548261063697282, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 287, train_loss = 1.8580020877125207, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 288, train_loss = 1.8631508635880891, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 289, train_loss = 1.8602024565043394, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 290, train_loss = 1.8606138365867082, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 291, train_loss = 1.8596136880514678, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 292, train_loss = 1.8613093122839928, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 293, train_loss = 1.8510680335166398, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 294, train_loss = 1.8530524596571922, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 295, train_loss = 1.854962800949579, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 296, train_loss = 1.8619290627539158, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 297, train_loss = 1.845191616564989, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 298, train_loss = 1.8439699672162533, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 299, train_loss = 1.8434755019843578, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 300, train_loss = 1.8406397005019244, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 301, train_loss = 1.8427119652333204, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 302, train_loss = 1.8405595695076045, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 303, train_loss = 1.8402756142022554, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 304, train_loss = 1.8391630935075227, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 305, train_loss = 1.836621710419422, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 306, train_loss = 1.8464135763642844, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 307, train_loss = 1.84059883034206, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 308, train_loss = 1.8339585214853287, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 309, train_loss = 1.8358945275249425, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 310, train_loss = 1.837896200508112, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 311, train_loss = 1.8311450543405954, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 312, train_loss = 1.8388423124852125, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 313, train_loss = 1.845620652049547, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 314, train_loss = 1.845687152206665, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 315, train_loss = 1.835774668812519, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 316, train_loss = 1.8406351978483144, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 317, train_loss = 1.8481644926068839, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 318, train_loss = 1.8308657432498876, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 319, train_loss = 1.8330715534684714, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 320, train_loss = 1.82904183366918, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 321, train_loss = 1.8280370881257113, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 322, train_loss = 1.826403579354519, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 323, train_loss = 1.8280807299015578, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 324, train_loss = 1.826801805436844, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 325, train_loss = 1.822779251873726, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 326, train_loss = 1.8235777169466019, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 327, train_loss = 1.8304589850304183, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 328, train_loss = 1.8287171001138631, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 329, train_loss = 1.8231612319650594, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 330, train_loss = 1.8215532563626766, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 331, train_loss = 1.821199856698513, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 332, train_loss = 1.821873314678669, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 333, train_loss = 1.8263000324368477, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 334, train_loss = 1.823836363852024, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 335, train_loss = 1.8217754773795605, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 336, train_loss = 1.8302529702486936, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 337, train_loss = 1.8282869992253836, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 338, train_loss = 1.8285436580481473, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 339, train_loss = 1.82805292433477, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 340, train_loss = 1.8301494581100997, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 341, train_loss = 1.8336957059800625, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 342, train_loss = 1.8162009865045547, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 343, train_loss = 1.8127906558511313, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 344, train_loss = 1.8127855373022612, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 345, train_loss = 1.8140440905990545, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 346, train_loss = 1.8124485053122044, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 347, train_loss = 1.8092698976397514, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 348, train_loss = 1.813010153680807, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 349, train_loss = 1.8089199600217398, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 350, train_loss = 1.8106553243997041, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 351, train_loss = 1.809620731830364, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 352, train_loss = 1.8102024843392428, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 353, train_loss = 1.8109917752444744, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 354, train_loss = 1.8089073027076665, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 355, train_loss = 1.80905850729323, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 356, train_loss = 1.8061039795575198, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 357, train_loss = 1.8055548307893332, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 358, train_loss = 1.809346010297304, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 359, train_loss = 1.808783758431673, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 360, train_loss = 1.804740554332966, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 361, train_loss = 1.8017822305264417, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 362, train_loss = 1.8040180442330893, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 363, train_loss = 1.8020952989754733, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 364, train_loss = 1.79884747043252, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 365, train_loss = 1.799273627490038, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 366, train_loss = 1.8002819009125233, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 367, train_loss = 1.7996947703359183, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 368, train_loss = 1.8010911395249423, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 369, train_loss = 1.7980900406837463, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 370, train_loss = 1.800015670567518, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 371, train_loss = 1.7975734459760133, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 372, train_loss = 1.7981983882782515, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 373, train_loss = 1.8015524546208326, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 374, train_loss = 1.8020547106862068, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 375, train_loss = 1.8065523927507456, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 376, train_loss = 1.8022695717809256, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 377, train_loss = 1.8050844582321588, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 378, train_loss = 1.8065013910236303, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 379, train_loss = 1.7937795991601888, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 380, train_loss = 1.7954470105469227, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 381, train_loss = 1.7907990688981954, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 382, train_loss = 1.7934360019862652, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 383, train_loss = 1.7923303296265658, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "6th- epoch: 384, train_loss = 1.7925046434102114, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 385, train_loss = 1.790645245462656, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 386, train_loss = 1.785396376013523, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 387, train_loss = 1.7869944845733698, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 388, train_loss = 1.7883010245859623, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 389, train_loss = 1.787131184100872, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 390, train_loss = 1.7883780226111412, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 391, train_loss = 1.7877992192807142, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 392, train_loss = 1.7878679359855596, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 393, train_loss = 1.7850109723804053, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 394, train_loss = 1.7797765247523785, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 395, train_loss = 1.7802326629462186, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 396, train_loss = 1.778670040279394, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 397, train_loss = 1.7835365732607897, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 398, train_loss = 1.788435814291006, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 399, train_loss = 1.7944927563366946, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 400, train_loss = 1.7936318355205003, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 401, train_loss = 1.795788628369337, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 402, train_loss = 1.7836110480129719, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 403, train_loss = 1.7830598267319147, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 404, train_loss = 1.7809573151171207, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 405, train_loss = 1.777810795843834, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 406, train_loss = 1.778373117238516, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 407, train_loss = 1.7793319200573023, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 408, train_loss = 1.7776238980295602, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 409, train_loss = 1.77805338674807, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 410, train_loss = 1.7765789230761584, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 411, train_loss = 1.7784578638675157, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 412, train_loss = 1.769588265568018, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 413, train_loss = 1.7717392183840275, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 414, train_loss = 1.77394443625235, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 415, train_loss = 1.7718240817484912, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 416, train_loss = 1.7699786735174712, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 417, train_loss = 1.7732098139822483, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 418, train_loss = 1.7717860154807568, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 419, train_loss = 1.7739251926541328, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 420, train_loss = 1.7709223553538322, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 421, train_loss = 1.7708293534815311, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 422, train_loss = 1.7647948799130972, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 423, train_loss = 1.7651127191784326, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 424, train_loss = 1.766109649091959, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 425, train_loss = 1.76962929716683, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 426, train_loss = 1.7697308970091399, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 427, train_loss = 1.7676573358476162, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 428, train_loss = 1.7676961831748486, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 429, train_loss = 1.7683759331703186, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 430, train_loss = 1.7676386535167694, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 431, train_loss = 1.7615186534821987, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 432, train_loss = 1.761684212833643, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 433, train_loss = 1.7608417558076326, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 434, train_loss = 1.7658019860682543, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 435, train_loss = 1.7640570091607515, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 436, train_loss = 1.7588097689149436, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 437, train_loss = 1.7587655099632684, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 438, train_loss = 1.7571887398662511, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 439, train_loss = 1.7629160707292613, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 440, train_loss = 1.7619947815983323, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 441, train_loss = 1.7634464440343436, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 442, train_loss = 1.7611122665402945, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 443, train_loss = 1.7604132145643234, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 444, train_loss = 1.7632778373808833, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 445, train_loss = 1.757696611181018, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 446, train_loss = 1.7518510483205318, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 447, train_loss = 1.7534729863255052, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 448, train_loss = 1.7530676734895678, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 449, train_loss = 1.75799441584968, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 450, train_loss = 1.7566916371433763, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 451, train_loss = 1.7569420337677002, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 452, train_loss = 1.7575604319572449, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 453, train_loss = 1.7566360495984554, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 454, train_loss = 1.7545460822730092, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 455, train_loss = 1.756344789027935, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 456, train_loss = 1.7540704533457756, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 457, train_loss = 1.7549684892146615, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 458, train_loss = 1.7535656380205182, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 459, train_loss = 1.7535497384815244, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 460, train_loss = 1.7466847697942285, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 461, train_loss = 1.747431787342066, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 462, train_loss = 1.7521085230109747, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 463, train_loss = 1.7523064874112606, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 464, train_loss = 1.7508033787162276, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 465, train_loss = 1.7515019488782855, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 466, train_loss = 1.750558789819479, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 467, train_loss = 1.7502448956220178, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 468, train_loss = 1.7486464592366247, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 469, train_loss = 1.7488196690828772, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 470, train_loss = 1.7479282679705648, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 471, train_loss = 1.7493039183318615, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 472, train_loss = 1.746129949882743, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 473, train_loss = 1.748040604099515, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 474, train_loss = 1.7464658617973328, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 475, train_loss = 1.7444398899824591, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 476, train_loss = 1.738681148737669, train_acc = 0.9948765719608756\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 477, train_loss = 1.7391766955406638, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 478, train_loss = 1.74457439656544, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 479, train_loss = 1.7431654346437426, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 480, train_loss = 1.7436553239822388, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 481, train_loss = 1.7432953913958045, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 482, train_loss = 1.7434098161756992, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 483, train_loss = 1.7431099178938894, train_acc = 0.9948765719608756\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 484, train_loss = 1.7429324140102835, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 485, train_loss = 1.735315889120102, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 486, train_loss = 1.7396408679633169, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 487, train_loss = 1.7335550760180922, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 488, train_loss = 1.7357433512806892, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 489, train_loss = 1.7348234939126996, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 490, train_loss = 1.739241812378168, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 491, train_loss = 1.7400337855069665, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 492, train_loss = 1.7309883274137974, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 493, train_loss = 1.7329476711602183, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 494, train_loss = 1.7371290760784177, train_acc = 0.9949930135072194\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 495, train_loss = 1.7362835978419753, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 496, train_loss = 1.736679048583028, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 497, train_loss = 1.7385327592492104, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 498, train_loss = 1.7364638571889373, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 499, train_loss = 1.7336383499205112, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|███████████████▊                                                               | 6/30 [54:06<3:36:23, 540.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "7th- epoch: 0, train_loss = 341.7264228835702, train_acc = 0.8090358639962739\n",
      "test Acc 0.8021415270018621:\n",
      "7th- epoch: 1, train_loss = 71.26781601365656, train_acc = 0.9140661387983232\n",
      "test Acc 0.9073556797020484:\n",
      "7th- epoch: 2, train_loss = 45.78333774302155, train_acc = 0.9364229156963204\n",
      "test Acc 0.9259776536312849:\n",
      "7th- epoch: 3, train_loss = 33.82201118487865, train_acc = 0.9491150442477876\n",
      "test Acc 0.9376163873370578:\n",
      "7th- epoch: 4, train_loss = 26.917189720552415, train_acc = 0.9573823940381928\n",
      "test Acc 0.9413407821229051:\n",
      "7th- epoch: 5, train_loss = 22.0639718901366, train_acc = 0.9625058220773172\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 6, train_loss = 18.544149862602353, train_acc = 0.965649743828598\n",
      "test Acc 0.9487895716945997:\n",
      "7th- epoch: 7, train_loss = 15.949799706693739, train_acc = 0.9691429902189101\n",
      "test Acc 0.952513966480447:\n",
      "7th- epoch: 8, train_loss = 13.891758034238592, train_acc = 0.9736842105263158\n",
      "test Acc 0.9534450651769087:\n",
      "7th- epoch: 9, train_loss = 12.356614246033132, train_acc = 0.975780158360503\n",
      "test Acc 0.9529795158286778:\n",
      "7th- epoch: 10, train_loss = 11.153547413647175, train_acc = 0.9776432231020028\n",
      "test Acc 0.9529795158286778:\n",
      "7th- epoch: 11, train_loss = 10.140052580507472, train_acc = 0.9786911970190965\n",
      "test Acc 0.9529795158286778:\n",
      "7th- epoch: 12, train_loss = 9.284936584532261, train_acc = 0.9804378202142524\n",
      "test Acc 0.9543761638733705:\n",
      "7th- epoch: 13, train_loss = 8.55232591368258, train_acc = 0.9816022356776898\n",
      "test Acc 0.9548417132216015:\n",
      "7th- epoch: 14, train_loss = 7.945165467914194, train_acc = 0.9829995342338146\n",
      "test Acc 0.9562383612662942:\n",
      "7th- epoch: 15, train_loss = 7.394167377147824, train_acc = 0.9849790405216581\n",
      "test Acc 0.9562383612662942:\n",
      "7th- epoch: 16, train_loss = 6.919601839501411, train_acc = 0.9855612482533768\n",
      "test Acc 0.9562383612662942:\n",
      "7th- epoch: 17, train_loss = 6.505689849378541, train_acc = 0.986376339077783\n",
      "test Acc 0.9557728119180633:\n",
      "7th- epoch: 18, train_loss = 6.146861132234335, train_acc = 0.9873078714485328\n",
      "test Acc 0.9562383612662942:\n",
      "7th- epoch: 19, train_loss = 5.833527659531683, train_acc = 0.9881229622729389\n",
      "test Acc 0.9557728119180633:\n",
      "7th- epoch: 20, train_loss = 5.564035434508696, train_acc = 0.9888216115510013\n",
      "test Acc 0.9557728119180633:\n",
      "7th- epoch: 21, train_loss = 5.300908931298181, train_acc = 0.98940381928272\n",
      "test Acc 0.9562383612662942:\n",
      "7th- epoch: 22, train_loss = 5.090063193929382, train_acc = 0.9899860270144387\n",
      "test Acc 0.957169459962756:\n",
      "7th- epoch: 23, train_loss = 4.901497163344175, train_acc = 0.9901024685607824\n",
      "test Acc 0.9567039106145251:\n",
      "7th- epoch: 24, train_loss = 4.737903133383952, train_acc = 0.9906846762925011\n",
      "test Acc 0.957169459962756:\n",
      "7th- epoch: 25, train_loss = 4.587286006659269, train_acc = 0.990801117838845\n",
      "test Acc 0.957635009310987:\n",
      "7th- epoch: 26, train_loss = 4.4577528645750135, train_acc = 0.9909175593851887\n",
      "test Acc 0.9590316573556797:\n",
      "7th- epoch: 27, train_loss = 4.338490305235609, train_acc = 0.9911504424778761\n",
      "test Acc 0.9590316573556797:\n",
      "7th- epoch: 28, train_loss = 4.229804928414524, train_acc = 0.9912668840242198\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 29, train_loss = 4.141007921425626, train_acc = 0.9912668840242198\n",
      "test Acc 0.9604283054003724:\n",
      "7th- epoch: 30, train_loss = 4.047496818006039, train_acc = 0.9912668840242198\n",
      "test Acc 0.9604283054003724:\n",
      "7th- epoch: 31, train_loss = 3.95878630829975, train_acc = 0.9912668840242198\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 32, train_loss = 3.8762552947737277, train_acc = 0.9913833255705635\n",
      "test Acc 0.9594972067039106:\n",
      "7th- epoch: 33, train_loss = 3.8020001865224913, train_acc = 0.9914997671169073\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 34, train_loss = 3.734500712598674, train_acc = 0.9916162086632511\n",
      "test Acc 0.9594972067039106:\n",
      "7th- epoch: 35, train_loss = 3.6649977853521705, train_acc = 0.9916162086632511\n",
      "test Acc 0.9604283054003724:\n",
      "7th- epoch: 36, train_loss = 3.610532906255685, train_acc = 0.9917326502095948\n",
      "test Acc 0.9599627560521415:\n",
      "7th- epoch: 37, train_loss = 3.5464760650647804, train_acc = 0.9917326502095948\n",
      "test Acc 0.9599627560521415:\n",
      "7th- epoch: 38, train_loss = 3.4943666190374643, train_acc = 0.992081974848626\n",
      "test Acc 0.9599627560521415:\n",
      "7th- epoch: 39, train_loss = 3.4388115578331053, train_acc = 0.9919655333022822\n",
      "test Acc 0.9604283054003724:\n",
      "7th- epoch: 40, train_loss = 3.3875313259195536, train_acc = 0.992081974848626\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 41, train_loss = 3.3442647001938894, train_acc = 0.9921984163949698\n",
      "test Acc 0.9604283054003724:\n",
      "7th- epoch: 42, train_loss = 3.293585971230641, train_acc = 0.9921984163949698\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 43, train_loss = 3.25818061362952, train_acc = 0.9921984163949698\n",
      "test Acc 0.9608938547486033:\n",
      "7th- epoch: 44, train_loss = 3.2117775708902627, train_acc = 0.9923148579413135\n",
      "test Acc 0.9618249534450651:\n",
      "7th- epoch: 45, train_loss = 3.1699983692960814, train_acc = 0.9923148579413135\n",
      "test Acc 0.9613594040968343:\n",
      "7th- epoch: 46, train_loss = 3.1397837275872007, train_acc = 0.9923148579413135\n",
      "test Acc 0.9618249534450651:\n",
      "7th- epoch: 47, train_loss = 3.097401095670648, train_acc = 0.9923148579413135\n",
      "test Acc 0.9618249534450651:\n",
      "7th- epoch: 48, train_loss = 3.060265586944297, train_acc = 0.9923148579413135\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 49, train_loss = 3.022423365386203, train_acc = 0.9924312994876572\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 50, train_loss = 2.9892824604175985, train_acc = 0.9928970656730322\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 51, train_loss = 2.9582831137813628, train_acc = 0.9928970656730322\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 52, train_loss = 2.924833455355838, train_acc = 0.9930135072193759\n",
      "test Acc 0.9622905027932961:\n",
      "7th- epoch: 53, train_loss = 2.9049710041144863, train_acc = 0.9930135072193759\n",
      "test Acc 0.9618249534450651:\n",
      "7th- epoch: 54, train_loss = 2.866786652011797, train_acc = 0.9930135072193759\n",
      "test Acc 0.9618249534450651:\n",
      "7th- epoch: 55, train_loss = 2.843101984472014, train_acc = 0.9930135072193759\n",
      "test Acc 0.962756052141527:\n",
      "7th- epoch: 56, train_loss = 2.8124985746107996, train_acc = 0.9930135072193759\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 57, train_loss = 2.792190366308205, train_acc = 0.9930135072193759\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 58, train_loss = 2.7622752487077378, train_acc = 0.9930135072193759\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 59, train_loss = 2.733485587639734, train_acc = 0.9930135072193759\n",
      "test Acc 0.962756052141527:\n",
      "7th- epoch: 60, train_loss = 2.6984641773742624, train_acc = 0.9928970656730322\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 61, train_loss = 2.6842099871719256, train_acc = 0.9932463903120633\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 62, train_loss = 2.65320399729535, train_acc = 0.9932463903120633\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 63, train_loss = 2.6347138082492165, train_acc = 0.9932463903120633\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 64, train_loss = 2.609428984229453, train_acc = 0.9932463903120633\n",
      "test Acc 0.962756052141527:\n",
      "7th- epoch: 65, train_loss = 2.591707991901785, train_acc = 0.9932463903120633\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 66, train_loss = 2.568914737435989, train_acc = 0.9933628318584071\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 67, train_loss = 2.554122121655382, train_acc = 0.9933628318584071\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 68, train_loss = 2.540273772319779, train_acc = 0.9935957149510946\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 69, train_loss = 2.524907302344218, train_acc = 0.9935957149510946\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 70, train_loss = 2.512826422811486, train_acc = 0.9934792734047508\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 71, train_loss = 2.491772675421089, train_acc = 0.9937121564974383\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 72, train_loss = 2.4792645684210584, train_acc = 0.9937121564974383\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 73, train_loss = 2.4644839058164507, train_acc = 0.9937121564974383\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 74, train_loss = 2.45509371755179, train_acc = 0.9939450395901258\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 75, train_loss = 2.4422615084331483, train_acc = 0.9939450395901258\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 76, train_loss = 2.4304816734511405, train_acc = 0.9940614811364695\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 77, train_loss = 2.4180577895604074, train_acc = 0.9940614811364695\n",
      "test Acc 0.9636871508379888:\n",
      "7th- epoch: 78, train_loss = 2.406583870877512, train_acc = 0.9940614811364695\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 79, train_loss = 2.391558285569772, train_acc = 0.9939450395901258\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 80, train_loss = 2.3849677429534495, train_acc = 0.9939450395901258\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 81, train_loss = 2.374754522694275, train_acc = 0.9939450395901258\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 82, train_loss = 2.3656054271850735, train_acc = 0.9939450395901258\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 83, train_loss = 2.34917431906797, train_acc = 0.9939450395901258\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 84, train_loss = 2.346104354481213, train_acc = 0.9939450395901258\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 85, train_loss = 2.3390153610380366, train_acc = 0.9939450395901258\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 86, train_loss = 2.32385818392504, train_acc = 0.9939450395901258\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 87, train_loss = 2.3145998037653044, train_acc = 0.9939450395901258\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 88, train_loss = 2.312925662728958, train_acc = 0.9939450395901258\n",
      "test Acc 0.9641527001862198:\n",
      "7th- epoch: 89, train_loss = 2.301367046427913, train_acc = 0.9939450395901258\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 90, train_loss = 2.3043578914366663, train_acc = 0.9939450395901258\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 91, train_loss = 2.2966397483833134, train_acc = 0.9939450395901258\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 92, train_loss = 2.2845303310314193, train_acc = 0.993828598043782\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 93, train_loss = 2.27686722332146, train_acc = 0.993828598043782\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 94, train_loss = 2.266668762662448, train_acc = 0.9940614811364695\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 95, train_loss = 2.2593943462707102, train_acc = 0.993828598043782\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 96, train_loss = 2.25479435082525, train_acc = 0.9940614811364695\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 97, train_loss = 2.2524211449781433, train_acc = 0.9939450395901258\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 98, train_loss = 2.2434531702892855, train_acc = 0.9941779226828132\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 99, train_loss = 2.2374755047494546, train_acc = 0.9940614811364695\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 100, train_loss = 2.232340442482382, train_acc = 0.9940614811364695\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 101, train_loss = 2.21791284380015, train_acc = 0.9940614811364695\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 102, train_loss = 2.2187512607779354, train_acc = 0.9941779226828132\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 103, train_loss = 2.211610808968544, train_acc = 0.9940614811364695\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 104, train_loss = 2.207312119193375, train_acc = 0.9941779226828132\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 105, train_loss = 2.2092693699523807, train_acc = 0.9941779226828132\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 106, train_loss = 2.197232687380165, train_acc = 0.9941779226828132\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 107, train_loss = 2.195505568990484, train_acc = 0.9941779226828132\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 108, train_loss = 2.184666625689715, train_acc = 0.9941779226828132\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 109, train_loss = 2.1798453179653734, train_acc = 0.9941779226828132\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 110, train_loss = 2.173980901017785, train_acc = 0.9941779226828132\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 111, train_loss = 2.179125898750499, train_acc = 0.9941779226828132\n",
      "test Acc 0.9650837988826816:\n",
      "7th- epoch: 112, train_loss = 2.1606998033821583, train_acc = 0.994294364229157\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 113, train_loss = 2.1596415113890544, train_acc = 0.994294364229157\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 114, train_loss = 2.1524986689910293, train_acc = 0.994294364229157\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 115, train_loss = 2.1519752938766032, train_acc = 0.994294364229157\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 116, train_loss = 2.147471397300251, train_acc = 0.994294364229157\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 117, train_loss = 2.1484949903097004, train_acc = 0.994294364229157\n",
      "test Acc 0.9655493482309124:\n",
      "7th- epoch: 118, train_loss = 2.140060368226841, train_acc = 0.9944108057755007\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 119, train_loss = 2.137829711311497, train_acc = 0.994294364229157\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 120, train_loss = 2.1329540589358658, train_acc = 0.9944108057755007\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 121, train_loss = 2.1313630015356466, train_acc = 0.9944108057755007\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 122, train_loss = 2.1249297998147085, train_acc = 0.994294364229157\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 123, train_loss = 2.1194575363770127, train_acc = 0.9944108057755007\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 124, train_loss = 2.1229253957862966, train_acc = 0.9944108057755007\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 125, train_loss = 2.10992819321109, train_acc = 0.9944108057755007\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 126, train_loss = 2.1096273343137, train_acc = 0.9944108057755007\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 127, train_loss = 2.1058782542240806, train_acc = 0.9944108057755007\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 128, train_loss = 2.1042355827521533, train_acc = 0.9944108057755007\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 129, train_loss = 2.095265774842119, train_acc = 0.9944108057755007\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 130, train_loss = 2.0980194434523582, train_acc = 0.9944108057755007\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 131, train_loss = 2.0926566434209235, train_acc = 0.9944108057755007\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 132, train_loss = 2.088436158170225, train_acc = 0.9944108057755007\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 133, train_loss = 2.076207165082451, train_acc = 0.9944108057755007\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 134, train_loss = 2.0802587202051654, train_acc = 0.9944108057755007\n",
      "test Acc 0.9669459962756052:\n",
      "7th- epoch: 135, train_loss = 2.0749438599450514, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 136, train_loss = 2.0736110791331157, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 137, train_loss = 2.068534199730493, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 138, train_loss = 2.0685591641813517, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 139, train_loss = 2.0594068560749292, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 140, train_loss = 2.0646211659768596, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 141, train_loss = 2.0535666733048856, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 142, train_loss = 2.0534729815553874, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 143, train_loss = 2.0474484999431297, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 144, train_loss = 2.05310851323884, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 145, train_loss = 2.0443013469921425, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 146, train_loss = 2.041788444388658, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 147, train_loss = 2.036860127118416, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 148, train_loss = 2.03805200883653, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 149, train_loss = 2.036428804276511, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 150, train_loss = 2.0206563136307523, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 151, train_loss = 2.0283169847680256, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 152, train_loss = 2.0320297691505402, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 153, train_loss = 2.028047024155967, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 154, train_loss = 2.0220667087705806, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 155, train_loss = 2.0221080268966034, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 156, train_loss = 2.0118925793794915, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 157, train_loss = 2.009339568670839, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 158, train_loss = 2.0086893070256338, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 159, train_loss = 2.0139293003594503, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 160, train_loss = 2.0073315595509484, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 161, train_loss = 1.996373573783785, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "7th- epoch: 162, train_loss = 2.0001265284372494, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 163, train_loss = 1.993589066900313, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 164, train_loss = 1.9931523948907852, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 165, train_loss = 1.9884737501852214, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 166, train_loss = 1.9875611474271864, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 167, train_loss = 1.9883279964560643, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 168, train_loss = 1.9793576983502135, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 169, train_loss = 1.9867751589044929, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 170, train_loss = 1.985867991577834, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 171, train_loss = 1.9801540111657232, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 172, train_loss = 1.9779321978567168, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 173, train_loss = 1.983818557637278, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 174, train_loss = 1.978709414601326, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 175, train_loss = 1.9741214266396128, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 176, train_loss = 1.9812128784833476, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 177, train_loss = 1.9670408598612994, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 178, train_loss = 1.9715537910815328, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "7th- epoch: 179, train_loss = 1.9673758725402877, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 180, train_loss = 1.9619931394117884, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 181, train_loss = 1.9620061347959563, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 182, train_loss = 1.9584068387630396, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 183, train_loss = 1.954871054564137, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 184, train_loss = 1.9585421498049982, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 185, train_loss = 1.9589150761603378, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 186, train_loss = 1.953961069288198, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 187, train_loss = 1.954225768276956, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 188, train_loss = 1.9438114918302745, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 189, train_loss = 1.9494809704483487, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 190, train_loss = 1.9423833261826076, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 191, train_loss = 1.9375780229456723, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 192, train_loss = 1.940072831872385, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 193, train_loss = 1.945165680081118, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 194, train_loss = 1.9398263556067832, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 195, train_loss = 1.9368112692027353, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 196, train_loss = 1.9421595411840826, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 197, train_loss = 1.9299668318708427, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 198, train_loss = 1.930229370307643, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 199, train_loss = 1.9327175053185783, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 200, train_loss = 1.9363910784595646, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 201, train_loss = 1.9317931326222606, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 202, train_loss = 1.931335344503168, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 203, train_loss = 1.9310654942528345, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 204, train_loss = 1.9244409123784862, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 205, train_loss = 1.9192488119006157, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 206, train_loss = 1.9210345324827358, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 207, train_loss = 1.9181535663083196, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 208, train_loss = 1.916297503223177, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 209, train_loss = 1.912097152962815, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 210, train_loss = 1.912196480028797, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 211, train_loss = 1.9134852879215032, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 212, train_loss = 1.9112902492051944, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 213, train_loss = 1.9104698651935905, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 214, train_loss = 1.9103194974013604, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 215, train_loss = 1.9127103834762238, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 216, train_loss = 1.914189953764435, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 217, train_loss = 1.9033879490452819, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 218, train_loss = 1.9093819140689448, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 219, train_loss = 1.9123015086515807, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 220, train_loss = 1.9106303562875837, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 221, train_loss = 1.910284934390802, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 222, train_loss = 1.897294928203337, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 223, train_loss = 1.903882875049021, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 224, train_loss = 1.9074930921779014, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 225, train_loss = 1.9018948024022393, train_acc = 0.9944108057755007\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 226, train_loss = 1.8964881435967982, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 227, train_loss = 1.8927830135216936, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 228, train_loss = 1.8981597180245444, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 229, train_loss = 1.899061357253231, train_acc = 0.9944108057755007\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 230, train_loss = 1.8869122562464327, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "7th- epoch: 231, train_loss = 1.893781412334647, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 232, train_loss = 1.8934841448790394, train_acc = 0.9944108057755007\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 233, train_loss = 1.8899443800910376, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 234, train_loss = 1.8861684669391252, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 235, train_loss = 1.8844834089977667, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 236, train_loss = 1.8800983075634576, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "7th- epoch: 237, train_loss = 1.8824549727723934, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 238, train_loss = 1.8823457908583805, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 239, train_loss = 1.8778830243390985, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 240, train_loss = 1.8804991487995721, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 241, train_loss = 1.8744166300748475, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 242, train_loss = 1.8808152445126325, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 243, train_loss = 1.8750971055123955, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 244, train_loss = 1.872313970583491, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 245, train_loss = 1.8726027951925062, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 246, train_loss = 1.8746676700538956, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 247, train_loss = 1.8693502274691127, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 248, train_loss = 1.8684469176223502, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 249, train_loss = 1.8726640517706983, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 250, train_loss = 1.8646809786441736, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 251, train_loss = 1.8653459533816203, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 252, train_loss = 1.870584919815883, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 253, train_loss = 1.8630813684430905, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 254, train_loss = 1.8649848230998032, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 255, train_loss = 1.8639560309820808, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 256, train_loss = 1.8600592846050858, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 257, train_loss = 1.861813249764964, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 258, train_loss = 1.8579053541179746, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 259, train_loss = 1.8617765267845243, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 260, train_loss = 1.8630551382084377, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 261, train_loss = 1.8589977716910653, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 262, train_loss = 1.858584044559393, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 263, train_loss = 1.8638171626953408, train_acc = 0.9944108057755007\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 264, train_loss = 1.8537474861950614, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 265, train_loss = 1.859581129043363, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 266, train_loss = 1.8536881616455503, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 267, train_loss = 1.8534860393847339, train_acc = 0.9944108057755007\n",
      "test Acc 0.9697392923649907:\n",
      "7th- epoch: 268, train_loss = 1.855227500316687, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 269, train_loss = 1.8534145851735957, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 270, train_loss = 1.859044776589144, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 271, train_loss = 1.8598034622846171, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 272, train_loss = 1.8480999452003743, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "7th- epoch: 273, train_loss = 1.855451041541528, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 274, train_loss = 1.8617612411035225, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 275, train_loss = 1.8520027122285683, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 276, train_loss = 1.8447772100043949, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 277, train_loss = 1.8465480919112451, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 278, train_loss = 1.8498265109956264, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 279, train_loss = 1.8472365758789238, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 280, train_loss = 1.8459543808421586, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 281, train_loss = 1.8460715224500746, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 282, train_loss = 1.8465569843829144, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 283, train_loss = 1.8484102982620243, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 284, train_loss = 1.8494878973287996, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 285, train_loss = 1.8485526629374363, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 286, train_loss = 1.838485541375121, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 287, train_loss = 1.8428803800197784, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 288, train_loss = 1.8440105396148283, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 289, train_loss = 1.8494424092350528, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 290, train_loss = 1.842069885111414, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 291, train_loss = 1.8365367357910145, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 292, train_loss = 1.8390342121711, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 293, train_loss = 1.8386553461896256, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 294, train_loss = 1.8327150764816906, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 295, train_loss = 1.840270633547334, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 296, train_loss = 1.8417882719368208, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 297, train_loss = 1.8329788798291702, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 298, train_loss = 1.8314802136446815, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 299, train_loss = 1.8258205286983866, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 300, train_loss = 1.828294498147443, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 301, train_loss = 1.8342267899715807, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 302, train_loss = 1.8292728190135676, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 303, train_loss = 1.8267298766877502, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 304, train_loss = 1.8281540283060167, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 305, train_loss = 1.832815508969361, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 306, train_loss = 1.8311695744923782, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 307, train_loss = 1.8200636458641384, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 308, train_loss = 1.825694309984101, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 309, train_loss = 1.8312974722066429, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 310, train_loss = 1.8327332112239674, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 311, train_loss = 1.8246557325765025, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 312, train_loss = 1.8252803166105878, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 313, train_loss = 1.8193959298951086, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 314, train_loss = 1.818853751203278, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 315, train_loss = 1.8192962744506076, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 316, train_loss = 1.8170633580593858, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 317, train_loss = 1.8185569072666112, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 318, train_loss = 1.8225294052390382, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 319, train_loss = 1.8208633063186426, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 320, train_loss = 1.818705306184711, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 321, train_loss = 1.823770875838818, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 322, train_loss = 1.8223866336920764, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 323, train_loss = 1.8180675839830656, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 324, train_loss = 1.8208854503754992, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 325, train_loss = 1.8177504155319184, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 326, train_loss = 1.8141349592769984, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 327, train_loss = 1.812118021887727, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 328, train_loss = 1.814570515678497, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 329, train_loss = 1.8098655221110675, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 330, train_loss = 1.8123560759995598, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 331, train_loss = 1.8144206467841286, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 332, train_loss = 1.8077978779037949, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 333, train_loss = 1.8117739028239157, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 334, train_loss = 1.8092141958186403, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 335, train_loss = 1.8086422499327455, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 336, train_loss = 1.8105294199485797, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 337, train_loss = 1.8066557845158968, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 338, train_loss = 1.8073032293468714, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 339, train_loss = 1.8072693446301855, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 340, train_loss = 1.8034231936617289, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 341, train_loss = 1.8047633899841458, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 342, train_loss = 1.802647757838713, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 343, train_loss = 1.8028163945127744, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 344, train_loss = 1.8028789988020435, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 345, train_loss = 1.803922472143313, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 346, train_loss = 1.8013151706254575, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 347, train_loss = 1.8028418997710105, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 348, train_loss = 1.8036189303093124, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "7th- epoch: 349, train_loss = 1.7978793250222225, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 350, train_loss = 1.8025106211425737, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 351, train_loss = 1.7937497573439032, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 352, train_loss = 1.8009642276447266, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 353, train_loss = 1.7944076801359188, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 354, train_loss = 1.7965127917414065, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 355, train_loss = 1.7970065635745414, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 356, train_loss = 1.7933514460455626, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 357, train_loss = 1.7969777406542562, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 358, train_loss = 1.7922908991749864, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 359, train_loss = 1.7949691608082503, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 360, train_loss = 1.7933738389692735, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 361, train_loss = 1.7927962562825996, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 362, train_loss = 1.791605854377849, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 363, train_loss = 1.7919855973741505, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 364, train_loss = 1.7923425637418404, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 365, train_loss = 1.7873391948523931, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 366, train_loss = 1.7889323478739243, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 367, train_loss = 1.7878891506697983, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 368, train_loss = 1.7859612161119003, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 369, train_loss = 1.7897398809436709, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 370, train_loss = 1.7857678134460002, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 371, train_loss = 1.788634624070255, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 372, train_loss = 1.7855366008589044, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 373, train_loss = 1.78618837511749, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 374, train_loss = 1.7830297731270548, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 375, train_loss = 1.786382446094649, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 376, train_loss = 1.785287360107759, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 377, train_loss = 1.7822281684202608, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 378, train_loss = 1.783600758179091, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 379, train_loss = 1.7805372553411871, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 380, train_loss = 1.7852562968619168, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 381, train_loss = 1.7819477544690017, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 382, train_loss = 1.7818477453256492, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 383, train_loss = 1.7795950313156936, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 384, train_loss = 1.7810893251153175, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 385, train_loss = 1.778973649488762, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 386, train_loss = 1.7805397922638804, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 387, train_loss = 1.7749958606436849, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 388, train_loss = 1.7791020369622856, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 389, train_loss = 1.77744228913798, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 390, train_loss = 1.7715878106246237, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 391, train_loss = 1.7769169012608472, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 392, train_loss = 1.7743953186145518, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 393, train_loss = 1.7784227167721838, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 394, train_loss = 1.7727234017511364, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 395, train_loss = 1.7764255170768593, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 396, train_loss = 1.7696089672390372, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 397, train_loss = 1.777145750966156, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 398, train_loss = 1.77092477408587, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 399, train_loss = 1.7730822354496922, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 400, train_loss = 1.7727108983381186, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 401, train_loss = 1.772105207433924, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 402, train_loss = 1.7686778790375683, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 403, train_loss = 1.77263827380375, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 404, train_loss = 1.7671631254197564, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 405, train_loss = 1.7722267522476614, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 406, train_loss = 1.7678837857674807, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 407, train_loss = 1.769443651108304, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 408, train_loss = 1.7665481118892785, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 409, train_loss = 1.7713558634568471, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 410, train_loss = 1.7715164777764585, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 411, train_loss = 1.7668917280680034, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 412, train_loss = 1.7640712674183305, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 413, train_loss = 1.768729859875748, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 414, train_loss = 1.765357142459834, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 415, train_loss = 1.7651293168310076, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 416, train_loss = 1.7626203053223435, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "7th- epoch: 417, train_loss = 1.7674389372987207, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 418, train_loss = 1.7602704700257163, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 419, train_loss = 1.7622833799978253, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 420, train_loss = 1.7611427715746686, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 421, train_loss = 1.7605840622272808, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 422, train_loss = 1.7598534493299667, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 423, train_loss = 1.761884562234627, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 424, train_loss = 1.7581975186767522, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 425, train_loss = 1.7631293886806816, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 426, train_loss = 1.7588258019823115, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 427, train_loss = 1.7585699671471957, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 428, train_loss = 1.7623559879139066, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 429, train_loss = 1.7570995597343426, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 430, train_loss = 1.7557821061927825, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 431, train_loss = 1.7595482888573315, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 432, train_loss = 1.754321687418269, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 433, train_loss = 1.7596141841204371, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 434, train_loss = 1.75255043793004, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 435, train_loss = 1.7591571575321723, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 436, train_loss = 1.750183977332199, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 437, train_loss = 1.7540369779744651, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 438, train_loss = 1.7540940516919363, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 439, train_loss = 1.753216867800802, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 440, train_loss = 1.750747403682908, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 441, train_loss = 1.754373806557851, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 442, train_loss = 1.7496800858934876, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 443, train_loss = 1.7539406082651112, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 444, train_loss = 1.74873126015882, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 445, train_loss = 1.7514332237187773, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 446, train_loss = 1.7488854312105104, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 447, train_loss = 1.752495334483683, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 448, train_loss = 1.746233391953865, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 449, train_loss = 1.7498567126021953, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 450, train_loss = 1.7439175616018474, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 451, train_loss = 1.7497691882308573, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 452, train_loss = 1.743048852746142, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 453, train_loss = 1.748266655486077, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 454, train_loss = 1.7441922152938787, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 455, train_loss = 1.745892785678734, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 456, train_loss = 1.744634470087476, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 457, train_loss = 1.7432300602376927, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 458, train_loss = 1.7440235487301834, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 459, train_loss = 1.7394295384146972, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 460, train_loss = 1.7446350991376676, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 461, train_loss = 1.74098729963589, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 462, train_loss = 1.743217760391417, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 463, train_loss = 1.740043394092936, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 464, train_loss = 1.740374099186738, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 465, train_loss = 1.7409650345070986, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 466, train_loss = 1.7398437931988155, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 467, train_loss = 1.7379985713632777, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 468, train_loss = 1.737275945561123, train_acc = 0.9951094550535631\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 469, train_loss = 1.7410770518472418, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 470, train_loss = 1.739835564949317, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 471, train_loss = 1.7344223154941574, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 472, train_loss = 1.739394246120355, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 473, train_loss = 1.7362622352084145, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 474, train_loss = 1.7353389746276662, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 475, train_loss = 1.7343644149368629, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 476, train_loss = 1.7353973238205072, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 477, train_loss = 1.7379119302640902, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 478, train_loss = 1.7341463644406758, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 479, train_loss = 1.7362838916596957, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 480, train_loss = 1.7321466765133664, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 481, train_loss = 1.7344978918554261, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 482, train_loss = 1.732166179062915, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "7th- epoch: 483, train_loss = 1.7353497834410518, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 484, train_loss = 1.731497692890116, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 485, train_loss = 1.7290148790780222, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 486, train_loss = 1.7334930979413912, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 487, train_loss = 1.7299061616213294, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 488, train_loss = 1.7307252971659182, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 489, train_loss = 1.7268716652179137, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 490, train_loss = 1.7332040131732356, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 491, train_loss = 1.72742978601309, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 492, train_loss = 1.730506652922486, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 493, train_loss = 1.7296038381755352, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 494, train_loss = 1.7249373006779933, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 495, train_loss = 1.727850074719754, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 496, train_loss = 1.727124975877814, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 497, train_loss = 1.7273966254433617, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 498, train_loss = 1.7278059316595318, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 499, train_loss = 1.7259048818377778, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 23%|█████████████████▉                                                           | 7/30 [1:03:08<3:27:26, 541.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "8th- epoch: 0, train_loss = 339.1973704993725, train_acc = 0.7991383325570564\n",
      "test Acc 0.8626629422718808:\n",
      "8th- epoch: 1, train_loss = 69.94037483260036, train_acc = 0.9186073591057289\n",
      "test Acc 0.9245810055865922:\n",
      "8th- epoch: 2, train_loss = 46.89590674452484, train_acc = 0.9395668374476013\n",
      "test Acc 0.9385474860335196:\n",
      "8th- epoch: 3, train_loss = 36.32233286090195, train_acc = 0.9486492780624126\n",
      "test Acc 0.9459962756052142:\n",
      "8th- epoch: 4, train_loss = 29.398015847429633, train_acc = 0.9558686539357243\n",
      "test Acc 0.9450651769087524:\n",
      "8th- epoch: 5, train_loss = 24.167397817596793, train_acc = 0.9626222636236609\n",
      "test Acc 0.9478584729981379:\n",
      "8th- epoch: 6, train_loss = 20.29112868756056, train_acc = 0.9657661853749417\n",
      "test Acc 0.9483240223463687:\n",
      "8th- epoch: 7, train_loss = 17.423382313922048, train_acc = 0.9710060549604099\n",
      "test Acc 0.9529795158286778:\n",
      "8th- epoch: 8, train_loss = 15.365554391406476, train_acc = 0.974033535165347\n",
      "test Acc 0.9548417132216015:\n",
      "8th- epoch: 9, train_loss = 13.748164193704724, train_acc = 0.9758965999068467\n",
      "test Acc 0.9543761638733705:\n",
      "8th- epoch: 10, train_loss = 12.414046762511134, train_acc = 0.9775267815556591\n",
      "test Acc 0.9562383612662942:\n",
      "8th- epoch: 11, train_loss = 11.315629730001092, train_acc = 0.9800884955752213\n",
      "test Acc 0.9562383612662942:\n",
      "8th- epoch: 12, train_loss = 10.397338408976793, train_acc = 0.9812529110386586\n",
      "test Acc 0.957635009310987:\n",
      "8th- epoch: 13, train_loss = 9.664828292094171, train_acc = 0.9825337680484397\n",
      "test Acc 0.957169459962756:\n",
      "8th- epoch: 14, train_loss = 9.031716258265078, train_acc = 0.9832324173265021\n",
      "test Acc 0.957169459962756:\n",
      "8th- epoch: 15, train_loss = 8.442219106014818, train_acc = 0.9845132743362832\n",
      "test Acc 0.9590316573556797:\n",
      "8th- epoch: 16, train_loss = 7.906110580544919, train_acc = 0.9846297158826269\n",
      "test Acc 0.9594972067039106:\n",
      "8th- epoch: 17, train_loss = 7.446017141919583, train_acc = 0.9855612482533768\n",
      "test Acc 0.9599627560521415:\n",
      "8th- epoch: 18, train_loss = 7.021470403764397, train_acc = 0.9862598975314392\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 19, train_loss = 6.639848932623863, train_acc = 0.9869585468095017\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 20, train_loss = 6.317026766482741, train_acc = 0.9873078714485328\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 21, train_loss = 6.018369261175394, train_acc = 0.9873078714485328\n",
      "test Acc 0.9613594040968343:\n",
      "8th- epoch: 22, train_loss = 5.754518398549408, train_acc = 0.9878900791802515\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 23, train_loss = 5.529822379350662, train_acc = 0.9881229622729389\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 24, train_loss = 5.3185020834207535, train_acc = 0.9883558453656265\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 25, train_loss = 5.110936543438584, train_acc = 0.9885887284583139\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 26, train_loss = 4.911934329662472, train_acc = 0.9890544946436889\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 27, train_loss = 4.770183020737022, train_acc = 0.9890544946436889\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 28, train_loss = 4.626947986427695, train_acc = 0.9892873777363763\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 29, train_loss = 4.482456523925066, train_acc = 0.98940381928272\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 30, train_loss = 4.325808574911207, train_acc = 0.989869585468095\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 31, train_loss = 4.209828926716, train_acc = 0.9901024685607824\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 32, train_loss = 4.084467391017824, train_acc = 0.99033535165347\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 33, train_loss = 3.9929454275406897, train_acc = 0.9899860270144387\n",
      "test Acc 0.9641527001862198:\n",
      "8th- epoch: 34, train_loss = 3.906789386179298, train_acc = 0.99033535165347\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 35, train_loss = 3.8050099052488804, train_acc = 0.990801117838845\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 36, train_loss = 3.7263609059154987, train_acc = 0.9906846762925011\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 37, train_loss = 3.6328891827724874, train_acc = 0.990801117838845\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 38, train_loss = 3.5922817438840866, train_acc = 0.990801117838845\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 39, train_loss = 3.5115477442741394, train_acc = 0.9906846762925011\n",
      "test Acc 0.9650837988826816:\n",
      "8th- epoch: 40, train_loss = 3.4500382929109037, train_acc = 0.9910340009315324\n",
      "test Acc 0.9655493482309124:\n",
      "8th- epoch: 41, train_loss = 3.394486638251692, train_acc = 0.9913833255705635\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 42, train_loss = 3.3456716164946556, train_acc = 0.9916162086632511\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 43, train_loss = 3.295427121222019, train_acc = 0.9918490917559385\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 44, train_loss = 3.2343357626814395, train_acc = 0.9918490917559385\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 45, train_loss = 3.2064466376323253, train_acc = 0.9917326502095948\n",
      "test Acc 0.9664804469273743:\n",
      "8th- epoch: 46, train_loss = 3.149759900989011, train_acc = 0.9919655333022822\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 47, train_loss = 3.1163181103765965, train_acc = 0.992081974848626\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 48, train_loss = 3.0753178633749485, train_acc = 0.9921984163949698\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 49, train_loss = 3.035541918128729, train_acc = 0.992081974848626\n",
      "test Acc 0.9678770949720671:\n",
      "8th- epoch: 50, train_loss = 3.0134787894785404, train_acc = 0.9921984163949698\n",
      "test Acc 0.9683426443202979:\n",
      "8th- epoch: 51, train_loss = 2.9773321400862187, train_acc = 0.9924312994876572\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 52, train_loss = 2.9470195833127946, train_acc = 0.9924312994876572\n",
      "test Acc 0.9697392923649907:\n",
      "8th- epoch: 53, train_loss = 2.9110452744644135, train_acc = 0.9924312994876572\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 54, train_loss = 2.898748803883791, train_acc = 0.9924312994876572\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 55, train_loss = 2.8617212411481887, train_acc = 0.9925477410340009\n",
      "test Acc 0.9706703910614525:\n",
      "8th- epoch: 56, train_loss = 2.846091954736039, train_acc = 0.9925477410340009\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 57, train_loss = 2.820908447029069, train_acc = 0.9926641825803446\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 58, train_loss = 2.7939418193418533, train_acc = 0.9930135072193759\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 59, train_loss = 2.783641494810581, train_acc = 0.9928970656730322\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 60, train_loss = 2.753463851986453, train_acc = 0.9928970656730322\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 61, train_loss = 2.7312839441001415, train_acc = 0.9930135072193759\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 62, train_loss = 2.716349817812443, train_acc = 0.9928970656730322\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 63, train_loss = 2.70797744137235, train_acc = 0.9928970656730322\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 64, train_loss = 2.685370319755748, train_acc = 0.9928970656730322\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 65, train_loss = 2.6707100681960583, train_acc = 0.9930135072193759\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 66, train_loss = 2.651067181257531, train_acc = 0.9930135072193759\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 67, train_loss = 2.6285845551174134, train_acc = 0.9928970656730322\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 68, train_loss = 2.6144375626463443, train_acc = 0.9931299487657196\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 69, train_loss = 2.6032510723453015, train_acc = 0.9932463903120633\n",
      "test Acc 0.9711359404096834:\n",
      "8th- epoch: 70, train_loss = 2.5888142958283424, train_acc = 0.9931299487657196\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 71, train_loss = 2.5658930590143427, train_acc = 0.9932463903120633\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 72, train_loss = 2.5533545402577147, train_acc = 0.9932463903120633\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 73, train_loss = 2.545566794811748, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "8th- epoch: 74, train_loss = 2.540542414993979, train_acc = 0.9933628318584071\n",
      "test Acc 0.9725325884543762:\n",
      "8th- epoch: 75, train_loss = 2.521601352840662, train_acc = 0.9935957149510946\n",
      "test Acc 0.9725325884543762:\n",
      "8th- epoch: 76, train_loss = 2.507281616330147, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 77, train_loss = 2.483060644357465, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 78, train_loss = 2.4806194752454758, train_acc = 0.9933628318584071\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 79, train_loss = 2.4710622938582674, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 80, train_loss = 2.4611652257153764, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 81, train_loss = 2.4462368140229955, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 82, train_loss = 2.4485883029410616, train_acc = 0.9934792734047508\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 83, train_loss = 2.4287258038530126, train_acc = 0.9935957149510946\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 84, train_loss = 2.4285439401865005, train_acc = 0.9935957149510946\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 85, train_loss = 2.415487989783287, train_acc = 0.9937121564974383\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 86, train_loss = 2.4027024122187868, train_acc = 0.9937121564974383\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 87, train_loss = 2.4046737836906686, train_acc = 0.9937121564974383\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 88, train_loss = 2.3905293183634058, train_acc = 0.9939450395901258\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 89, train_loss = 2.385290219099261, train_acc = 0.9939450395901258\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 90, train_loss = 2.3841250551631674, train_acc = 0.9939450395901258\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 91, train_loss = 2.3660990273347124, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 92, train_loss = 2.3661887869238853, train_acc = 0.993828598043782\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 93, train_loss = 2.3540499372174963, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 94, train_loss = 2.3443985184421763, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 95, train_loss = 2.3458747988333926, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 96, train_loss = 2.3335241662571207, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 97, train_loss = 2.330025251954794, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 98, train_loss = 2.318563005537726, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 99, train_loss = 2.3090650402009487, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 100, train_loss = 2.316189287812449, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 101, train_loss = 2.3030196217587218, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 102, train_loss = 2.2930655801901594, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 103, train_loss = 2.2925438409438357, train_acc = 0.9941779226828132\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 104, train_loss = 2.2809091781964526, train_acc = 0.9941779226828132\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 105, train_loss = 2.2784786025295034, train_acc = 0.9941779226828132\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 106, train_loss = 2.2740084566175938, train_acc = 0.9941779226828132\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 107, train_loss = 2.2570371566107497, train_acc = 0.9941779226828132\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 108, train_loss = 2.2596871306886896, train_acc = 0.9941779226828132\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 109, train_loss = 2.2445212876191363, train_acc = 0.994294364229157\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 110, train_loss = 2.253784174681641, train_acc = 0.9941779226828132\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 111, train_loss = 2.235233491868712, train_acc = 0.9941779226828132\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 112, train_loss = 2.2335832802345976, train_acc = 0.9941779226828132\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 113, train_loss = 2.227271690964699, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 114, train_loss = 2.233154730289243, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 115, train_loss = 2.2206990582635626, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 116, train_loss = 2.2260470427572727, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 117, train_loss = 2.2130814865231514, train_acc = 0.994294364229157\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 118, train_loss = 2.2131160721182823, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 119, train_loss = 2.202581165940501, train_acc = 0.994294364229157\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 120, train_loss = 2.200350054888986, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 121, train_loss = 2.191080259741284, train_acc = 0.9941779226828132\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 122, train_loss = 2.190568665624596, train_acc = 0.994294364229157\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 123, train_loss = 2.1699777195462957, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 124, train_loss = 2.1667111217975616, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 125, train_loss = 2.152630530297756, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 126, train_loss = 2.161501275957562, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 127, train_loss = 2.15610722952988, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "8th- epoch: 128, train_loss = 2.148089364171028, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 129, train_loss = 2.142140820622444, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 130, train_loss = 2.1408486937871203, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 131, train_loss = 2.138479513465427, train_acc = 0.9941779226828132\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 132, train_loss = 2.1359655894339085, train_acc = 0.9941779226828132\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 133, train_loss = 2.1315794214606285, train_acc = 0.9941779226828132\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 134, train_loss = 2.1255701519548893, train_acc = 0.994294364229157\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 135, train_loss = 2.120898149907589, train_acc = 0.994294364229157\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 136, train_loss = 2.1160226315259933, train_acc = 0.994294364229157\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 137, train_loss = 2.1165432669222355, train_acc = 0.9941779226828132\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 138, train_loss = 2.1068312314455397, train_acc = 0.994294364229157\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 139, train_loss = 2.1121560682659037, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 140, train_loss = 2.1019016106729396, train_acc = 0.994294364229157\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 141, train_loss = 2.105547159910202, train_acc = 0.994294364229157\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 142, train_loss = 2.105106783390511, train_acc = 0.994294364229157\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 143, train_loss = 2.0959428784553893, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 144, train_loss = 2.0882937287096865, train_acc = 0.994294364229157\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 145, train_loss = 2.089358893514145, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 146, train_loss = 2.0837290746276267, train_acc = 0.994294364229157\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 147, train_loss = 2.0920812785625458, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 148, train_loss = 2.085863083600998, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 149, train_loss = 2.081271720409859, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 150, train_loss = 2.079340372234583, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 151, train_loss = 2.0766770715708844, train_acc = 0.9941779226828132\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 152, train_loss = 2.0717597392504103, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 153, train_loss = 2.0723480830783956, train_acc = 0.9941779226828132\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 154, train_loss = 2.0696915040607564, train_acc = 0.994294364229157\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 155, train_loss = 2.066675641865004, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 156, train_loss = 2.062487033486832, train_acc = 0.994294364229157\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 157, train_loss = 2.0593011627788655, train_acc = 0.9944108057755007\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 158, train_loss = 2.0529002088005655, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 159, train_loss = 2.0530502150650136, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 160, train_loss = 2.048233938694466, train_acc = 0.9944108057755007\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 161, train_loss = 2.0437977723777294, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 162, train_loss = 2.0436837735469453, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 163, train_loss = 2.038717312098015, train_acc = 0.9944108057755007\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 164, train_loss = 2.0344223442371003, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 165, train_loss = 2.0324793830513954, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 166, train_loss = 2.02759474638151, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 167, train_loss = 2.027575969696045, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 168, train_loss = 2.024269698827993, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 169, train_loss = 2.0239330418407917, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 170, train_loss = 2.024179108440876, train_acc = 0.9944108057755007\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 171, train_loss = 2.0189884987776168, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 172, train_loss = 2.0162430368363857, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 173, train_loss = 2.0135717540979385, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 174, train_loss = 2.0118979563121684, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 175, train_loss = 2.008008189499378, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 176, train_loss = 2.006860975176096, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 177, train_loss = 2.0045036015217192, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 178, train_loss = 2.0051024332642555, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 179, train_loss = 1.998271904885769, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 180, train_loss = 2.0019083109800704, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 181, train_loss = 2.0020623219315894, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 182, train_loss = 1.9937317321891896, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 183, train_loss = 1.9916240237653255, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 184, train_loss = 1.9951676527853124, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 185, train_loss = 1.9875287215108983, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 186, train_loss = 1.9866381349856965, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 187, train_loss = 1.9825363233685493, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 188, train_loss = 1.9787332055275328, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 189, train_loss = 1.9782139745657332, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 190, train_loss = 1.976890190213453, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 191, train_loss = 1.9722564741969109, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 192, train_loss = 1.9734677423839457, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 193, train_loss = 1.9695417222683318, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 194, train_loss = 1.9708119953866117, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 195, train_loss = 1.9689736639265902, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 196, train_loss = 1.9649275628034957, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 197, train_loss = 1.9645247819717042, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 198, train_loss = 1.9648377088014968, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 199, train_loss = 1.962803676724434, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 200, train_loss = 1.9608116162125953, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 201, train_loss = 1.9592760515515693, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 202, train_loss = 1.960258784412872, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 203, train_loss = 1.9568144318764098, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 204, train_loss = 1.9577361556584947, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 205, train_loss = 1.952327097475063, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 206, train_loss = 1.951145265251398, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 207, train_loss = 1.9453132773633115, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 208, train_loss = 1.9483221185510047, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 209, train_loss = 1.9432660080492496, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 210, train_loss = 1.945000187784899, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 211, train_loss = 1.9444330011610873, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 212, train_loss = 1.9382162354886532, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 213, train_loss = 1.9401343017816544, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 214, train_loss = 1.93767299503088, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 215, train_loss = 1.936834890395403, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 216, train_loss = 1.9359710949356668, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 217, train_loss = 1.9368117600679398, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 218, train_loss = 1.9301355332136154, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 219, train_loss = 1.9377085665764753, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 220, train_loss = 1.9324490365979727, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 221, train_loss = 1.9336139236984309, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 222, train_loss = 1.9291772978904191, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 223, train_loss = 1.9311989036796149, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 224, train_loss = 1.9261964696052019, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 225, train_loss = 1.9253775092365686, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 226, train_loss = 1.9228063772025052, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 227, train_loss = 1.9253863617777824, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 228, train_loss = 1.9215632739069406, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 229, train_loss = 1.9223764576017857, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 230, train_loss = 1.9197659144701902, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 231, train_loss = 1.9221216924488544, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 232, train_loss = 1.9217201620340347, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 233, train_loss = 1.9141306541860104, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 234, train_loss = 1.9164727292954922, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 235, train_loss = 1.9116547679004725, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 236, train_loss = 1.913248752563959, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 237, train_loss = 1.9117283349332865, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 238, train_loss = 1.9086730678973254, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 239, train_loss = 1.910199182719225, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 240, train_loss = 1.9100565500557423, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 241, train_loss = 1.9065689146518707, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 242, train_loss = 1.9026040372846182, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 243, train_loss = 1.9035697119834367, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 244, train_loss = 1.90104897445417, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 245, train_loss = 1.900805120676523, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 246, train_loss = 1.8998807395400945, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 247, train_loss = 1.8965636938810349, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 248, train_loss = 1.896801928669447, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 249, train_loss = 1.8948933767678682, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 250, train_loss = 1.8964835070073605, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 251, train_loss = 1.894881966203684, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 252, train_loss = 1.8969086272118147, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 253, train_loss = 1.8942124620079994, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 254, train_loss = 1.8912521712481976, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 255, train_loss = 1.8876589635910932, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 256, train_loss = 1.8946123719215393, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 257, train_loss = 1.8944407714006957, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 258, train_loss = 1.884095719695324, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 259, train_loss = 1.8886364636418875, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 260, train_loss = 1.88462033867836, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 261, train_loss = 1.882894042879343, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 262, train_loss = 1.8868444698455278, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 263, train_loss = 1.8837989034655038, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 264, train_loss = 1.8799067574145738, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 265, train_loss = 1.8806046532990877, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 266, train_loss = 1.882433167338604, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 267, train_loss = 1.8795751320722047, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 268, train_loss = 1.878993932157755, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 269, train_loss = 1.8769577667117119, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 270, train_loss = 1.8783558259310666, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 271, train_loss = 1.8743430934846401, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 272, train_loss = 1.8754913099110126, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 273, train_loss = 1.8724966893496457, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 274, train_loss = 1.8716016672551632, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 275, train_loss = 1.8699388479290064, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 276, train_loss = 1.8722521215677261, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 277, train_loss = 1.8721792598662432, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 278, train_loss = 1.8680133434536401, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 279, train_loss = 1.8698492695984896, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 280, train_loss = 1.8657565054891165, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 281, train_loss = 1.863574111222988, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 282, train_loss = 1.8655852998199407, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 283, train_loss = 1.8654985763132572, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 284, train_loss = 1.8649990210833494, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 285, train_loss = 1.8646717183291912, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 286, train_loss = 1.8649543412029743, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 287, train_loss = 1.8623266766371671, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 288, train_loss = 1.8619038611650467, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 289, train_loss = 1.8609397982654627, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 290, train_loss = 1.8616551210579928, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 291, train_loss = 1.8620805144309998, train_acc = 0.9944108057755007\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 292, train_loss = 1.8585994628665503, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 293, train_loss = 1.8598781886103097, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 294, train_loss = 1.8573226878943387, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 295, train_loss = 1.8585593812167645, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 296, train_loss = 1.859903850912815, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 297, train_loss = 1.855922414601082, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 298, train_loss = 1.8578206101956312, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 299, train_loss = 1.8548323164286558, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 300, train_loss = 1.8558014072477818, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 301, train_loss = 1.855343838542467, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 302, train_loss = 1.8516063801944256, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 303, train_loss = 1.8536612068710383, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 304, train_loss = 1.8507254719734192, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 305, train_loss = 1.8507695806620177, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 306, train_loss = 1.850436265260214, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 307, train_loss = 1.852125883102417, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 308, train_loss = 1.8513898936507758, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 309, train_loss = 1.8484344941971358, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 310, train_loss = 1.8493038552405778, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 311, train_loss = 1.849263305455679, train_acc = 0.9945272473218444\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 312, train_loss = 1.8455466317536775, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 313, train_loss = 1.8449189849197865, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 314, train_loss = 1.8444095787999686, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 315, train_loss = 1.844242046267027, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 316, train_loss = 1.8468723446130753, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 317, train_loss = 1.8435734075901564, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 318, train_loss = 1.840658001601696, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 319, train_loss = 1.839997080474859, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 320, train_loss = 1.8412180629966315, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 321, train_loss = 1.8403036283852998, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 322, train_loss = 1.8387855676410254, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 323, train_loss = 1.8372900424001273, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 324, train_loss = 1.8410248359141406, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 325, train_loss = 1.8406090711650904, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 326, train_loss = 1.8351182440819684, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 327, train_loss = 1.8386489202675875, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 328, train_loss = 1.8336217552423477, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 329, train_loss = 1.8315166532993317, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 330, train_loss = 1.8340883391501848, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 331, train_loss = 1.83455747491098, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 332, train_loss = 1.8327147873642389, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 333, train_loss = 1.8333338635566179, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 334, train_loss = 1.8290711591544095, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 335, train_loss = 1.828139098972315, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 336, train_loss = 1.8275234289467335, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 337, train_loss = 1.8303392516972963, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 338, train_loss = 1.8308698584733065, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 339, train_loss = 1.8265329487621784, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 340, train_loss = 1.826233595609665, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 341, train_loss = 1.82456879192614, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 342, train_loss = 1.8242312595248222, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 343, train_loss = 1.8245666772127151, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 344, train_loss = 1.8236768059432507, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 345, train_loss = 1.8227976188063622, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 346, train_loss = 1.8233428920211736, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 347, train_loss = 1.8218447603285313, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 348, train_loss = 1.8218341556785163, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 349, train_loss = 1.8189780749380589, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 350, train_loss = 1.8187482170760632, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 351, train_loss = 1.8206789170799311, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 352, train_loss = 1.819442124426132, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 353, train_loss = 1.8189616041781846, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 354, train_loss = 1.8167985243198927, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 355, train_loss = 1.8172950980660971, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 356, train_loss = 1.8150599971413612, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 357, train_loss = 1.812118543923134, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 358, train_loss = 1.8121278968901606, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 359, train_loss = 1.8153861338942079, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 360, train_loss = 1.811197413757327, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 361, train_loss = 1.8119440091249999, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 362, train_loss = 1.8124352470040321, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 363, train_loss = 1.8109072831721278, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 364, train_loss = 1.8101617271750001, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 365, train_loss = 1.8091118459851714, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 366, train_loss = 1.8073548798711272, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 367, train_loss = 1.809367277965066, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 368, train_loss = 1.8081045771687059, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 369, train_loss = 1.8057508058845997, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 370, train_loss = 1.8080257748515578, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 371, train_loss = 1.805000816777465, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 372, train_loss = 1.8074390230030986, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 373, train_loss = 1.8065069876611233, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 374, train_loss = 1.8042263388633728, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 375, train_loss = 1.8071612591593293, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 376, train_loss = 1.8036851522774668, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 377, train_loss = 1.8036395559756784, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 378, train_loss = 1.8016558947711019, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 379, train_loss = 1.800779901444912, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 380, train_loss = 1.8000267495663138, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 381, train_loss = 1.8029765424580546, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 382, train_loss = 1.8007261330931215, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 383, train_loss = 1.8020327538251877, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 384, train_loss = 1.7984168604016304, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 385, train_loss = 1.7957115098834038, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 386, train_loss = 1.7966999200434657, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 387, train_loss = 1.7966526535601588, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 388, train_loss = 1.7952234111726284, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 389, train_loss = 1.7956390542240115, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 390, train_loss = 1.794247455894947, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 391, train_loss = 1.7973229003400775, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 392, train_loss = 1.8003013941197423, train_acc = 0.9945272473218444\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 393, train_loss = 1.797726576522109, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 394, train_loss = 1.7974063667206792, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 395, train_loss = 1.7928300810308428, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 396, train_loss = 1.793760454907897, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 397, train_loss = 1.7940744782536058, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 398, train_loss = 1.7925016544759274, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 399, train_loss = 1.791253987699747, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 400, train_loss = 1.7931132626981707, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 401, train_loss = 1.7891643444745569, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 402, train_loss = 1.7893171459436417, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 403, train_loss = 1.786619134247303, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 404, train_loss = 1.7910140206367942, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 405, train_loss = 1.7859629591257544, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 406, train_loss = 1.7877324558794498, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 407, train_loss = 1.7880525290966034, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 408, train_loss = 1.7864872391073732, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 409, train_loss = 1.7857727222144604, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 410, train_loss = 1.7858405920414953, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 411, train_loss = 1.7866058734507533, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 412, train_loss = 1.784279104322195, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 413, train_loss = 1.7837365667073755, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 414, train_loss = 1.7837235306651564, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 415, train_loss = 1.783571995794773, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 416, train_loss = 1.7823690623044968, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 417, train_loss = 1.7835968707950087, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 418, train_loss = 1.7825786657631397, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 419, train_loss = 1.784822786852601, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 420, train_loss = 1.7850155023188563, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 421, train_loss = 1.7808600440621376, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 422, train_loss = 1.782578680664301, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 423, train_loss = 1.7803310540766688, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 424, train_loss = 1.78113001708698, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 425, train_loss = 1.7808238168508979, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 426, train_loss = 1.7786779925227165, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 427, train_loss = 1.7767771879880456, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 428, train_loss = 1.7806023520679446, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 429, train_loss = 1.7761805963964434, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 430, train_loss = 1.7753721761255292, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 431, train_loss = 1.7763266203255625, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 432, train_loss = 1.775593823447707, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 433, train_loss = 1.7745710176677676, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 434, train_loss = 1.776199263826129, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 435, train_loss = 1.7709953847079305, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 436, train_loss = 1.7724192291498184, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 437, train_loss = 1.7727501851768466, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 438, train_loss = 1.7718085311353207, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 439, train_loss = 1.771664809435606, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 440, train_loss = 1.772324327379465, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 441, train_loss = 1.7688841981143923, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 442, train_loss = 1.769295913472888, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 443, train_loss = 1.7715463464410277, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 444, train_loss = 1.7710552786738845, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 445, train_loss = 1.767844249799964, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 446, train_loss = 1.7718186092824908, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 447, train_loss = 1.7686558924615383, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 448, train_loss = 1.7713958409876795, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 449, train_loss = 1.7668097727000713, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 450, train_loss = 1.7685018889606, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 451, train_loss = 1.765292922660592, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 452, train_loss = 1.7651815551071195, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 453, train_loss = 1.762633040547371, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 454, train_loss = 1.7639948390424252, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 455, train_loss = 1.7627881442458602, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 456, train_loss = 1.7654819997696904, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 457, train_loss = 1.765155362591031, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 458, train_loss = 1.7645756763668032, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 459, train_loss = 1.7628209876565961, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 460, train_loss = 1.7625264624803094, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 461, train_loss = 1.761620320379734, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 462, train_loss = 1.762232535824296, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 463, train_loss = 1.760502884790185, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 464, train_loss = 1.7628689371049404, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "8th- epoch: 465, train_loss = 1.7594628185033798, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 466, train_loss = 1.7603481846599607, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 467, train_loss = 1.7618828117847443, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 468, train_loss = 1.7589078173041344, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 469, train_loss = 1.7585918977856636, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 470, train_loss = 1.7588252574205399, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 471, train_loss = 1.7555169438273879, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 472, train_loss = 1.7568295933306217, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 473, train_loss = 1.7568038403987885, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 474, train_loss = 1.7561688013374805, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 475, train_loss = 1.7552198134362698, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 476, train_loss = 1.7536751044244738, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 477, train_loss = 1.753574209913495, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 478, train_loss = 1.7524264802486869, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 479, train_loss = 1.7518113603146048, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 480, train_loss = 1.7513177978544263, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 481, train_loss = 1.7524284410028486, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 482, train_loss = 1.7505198220460443, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 483, train_loss = 1.7535763457417488, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 484, train_loss = 1.7524456841201754, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 485, train_loss = 1.751620606824872, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 486, train_loss = 1.7507801515312167, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 487, train_loss = 1.7486184922308894, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 488, train_loss = 1.7482910801918479, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 489, train_loss = 1.746563823267934, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 490, train_loss = 1.7489978646190139, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 491, train_loss = 1.7469999591558008, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 492, train_loss = 1.7465159582643537, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 493, train_loss = 1.7480119044630555, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 494, train_loss = 1.7478631238191156, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 495, train_loss = 1.7468129359185696, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 496, train_loss = 1.7463831578643294, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 497, train_loss = 1.745928301170352, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 498, train_loss = 1.7429064276366262, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "8th- epoch: 499, train_loss = 1.7438643500208855, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 27%|████████████████████▌                                                        | 8/30 [1:12:16<3:19:10, 543.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "9th- epoch: 0, train_loss = 368.19730184972286, train_acc = 0.8115975780158361\n",
      "test Acc 0.8291433891992551:\n",
      "9th- epoch: 1, train_loss = 73.70202206540853, train_acc = 0.9188402421984164\n",
      "test Acc 0.9324953445065177:\n",
      "9th- epoch: 2, train_loss = 51.00434489734471, train_acc = 0.9359571495109456\n",
      "test Acc 0.9408752327746741:\n",
      "9th- epoch: 3, train_loss = 37.877200522925705, train_acc = 0.946320447135538\n",
      "test Acc 0.9413407821229051:\n",
      "9th- epoch: 4, train_loss = 29.46470863185823, train_acc = 0.9534233814625058\n",
      "test Acc 0.9413407821229051:\n",
      "9th- epoch: 5, train_loss = 24.22730489168316, train_acc = 0.9581974848625989\n",
      "test Acc 0.9459962756052142:\n",
      "9th- epoch: 6, train_loss = 20.33285787096247, train_acc = 0.9628551467163484\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 7, train_loss = 17.331867629196495, train_acc = 0.9676292501164415\n",
      "test Acc 0.9487895716945997:\n",
      "9th- epoch: 8, train_loss = 15.121002606116235, train_acc = 0.9707731718677224\n",
      "test Acc 0.9529795158286778:\n",
      "9th- epoch: 9, train_loss = 13.430690979585052, train_acc = 0.9736842105263158\n",
      "test Acc 0.9539106145251397:\n",
      "9th- epoch: 10, train_loss = 12.080143954604864, train_acc = 0.9764788076385654\n",
      "test Acc 0.9548417132216015:\n",
      "9th- epoch: 11, train_loss = 11.007860522950068, train_acc = 0.9781089892873778\n",
      "test Acc 0.9543761638733705:\n",
      "9th- epoch: 12, train_loss = 10.0582924883347, train_acc = 0.9799720540288775\n",
      "test Acc 0.9543761638733705:\n",
      "9th- epoch: 13, train_loss = 9.290557146072388, train_acc = 0.9805542617605962\n",
      "test Acc 0.9543761638733705:\n",
      "9th- epoch: 14, train_loss = 8.612751911394298, train_acc = 0.9816022356776898\n",
      "test Acc 0.9529795158286778:\n",
      "9th- epoch: 15, train_loss = 8.051930162124336, train_acc = 0.9821844434094085\n",
      "test Acc 0.9548417132216015:\n",
      "9th- epoch: 16, train_loss = 7.538781787035987, train_acc = 0.9838146250582208\n",
      "test Acc 0.9567039106145251:\n",
      "9th- epoch: 17, train_loss = 7.091604688204825, train_acc = 0.9852119236143456\n",
      "test Acc 0.9581005586592178:\n",
      "9th- epoch: 18, train_loss = 6.710219592321664, train_acc = 0.9857941313460643\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 19, train_loss = 6.382098418427631, train_acc = 0.9862598975314392\n",
      "test Acc 0.9590316573556797:\n",
      "9th- epoch: 20, train_loss = 6.095436406787485, train_acc = 0.9868421052631579\n",
      "test Acc 0.9599627560521415:\n",
      "9th- epoch: 21, train_loss = 5.83022671379149, train_acc = 0.9873078714485328\n",
      "test Acc 0.9599627560521415:\n",
      "9th- epoch: 22, train_loss = 5.5897785243578255, train_acc = 0.9878900791802515\n",
      "test Acc 0.957635009310987:\n",
      "9th- epoch: 23, train_loss = 5.381165843689814, train_acc = 0.9882394038192828\n",
      "test Acc 0.957635009310987:\n",
      "9th- epoch: 24, train_loss = 5.15753721119836, train_acc = 0.9884722869119702\n",
      "test Acc 0.9599627560521415:\n",
      "9th- epoch: 25, train_loss = 4.9984892988577485, train_acc = 0.9888216115510013\n",
      "test Acc 0.9599627560521415:\n",
      "9th- epoch: 26, train_loss = 4.817578629241325, train_acc = 0.9889380530973452\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 27, train_loss = 4.671430099871941, train_acc = 0.98940381928272\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 28, train_loss = 4.536964730126783, train_acc = 0.9896367023754076\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 29, train_loss = 4.401819658698514, train_acc = 0.9896367023754076\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 30, train_loss = 4.292474485002458, train_acc = 0.989869585468095\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 31, train_loss = 4.177752930903807, train_acc = 0.9901024685607824\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 32, train_loss = 4.082384631386958, train_acc = 0.9901024685607824\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 33, train_loss = 3.9877515786793083, train_acc = 0.9906846762925011\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 34, train_loss = 3.8969442218076438, train_acc = 0.9906846762925011\n",
      "test Acc 0.9608938547486033:\n",
      "9th- epoch: 35, train_loss = 3.8131905396003276, train_acc = 0.990801117838845\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 36, train_loss = 3.7401997577399015, train_acc = 0.9909175593851887\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 37, train_loss = 3.669784633908421, train_acc = 0.9912668840242198\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 38, train_loss = 3.59377904178109, train_acc = 0.9913833255705635\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 39, train_loss = 3.543837666977197, train_acc = 0.9913833255705635\n",
      "test Acc 0.9613594040968343:\n",
      "9th- epoch: 40, train_loss = 3.478788430336863, train_acc = 0.9912668840242198\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 41, train_loss = 3.4241336481645703, train_acc = 0.9913833255705635\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 42, train_loss = 3.3720272488426417, train_acc = 0.9917326502095948\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 43, train_loss = 3.3192195820156485, train_acc = 0.9923148579413135\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 44, train_loss = 3.270488265203312, train_acc = 0.9925477410340009\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 45, train_loss = 3.2259980200324208, train_acc = 0.9925477410340009\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 46, train_loss = 3.187365105608478, train_acc = 0.9927806241266884\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 47, train_loss = 3.1671793526038527, train_acc = 0.9925477410340009\n",
      "test Acc 0.9622905027932961:\n",
      "9th- epoch: 48, train_loss = 3.113147920696065, train_acc = 0.9927806241266884\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 49, train_loss = 3.084886766737327, train_acc = 0.9928970656730322\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 50, train_loss = 3.054098666412756, train_acc = 0.9926641825803446\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 51, train_loss = 3.011401761788875, train_acc = 0.9927806241266884\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 52, train_loss = 2.99309314112179, train_acc = 0.9925477410340009\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 53, train_loss = 2.952100890921429, train_acc = 0.9928970656730322\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 54, train_loss = 2.921035127597861, train_acc = 0.9930135072193759\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 55, train_loss = 2.8935978426598012, train_acc = 0.9930135072193759\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 56, train_loss = 2.8603571427520365, train_acc = 0.9928970656730322\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 57, train_loss = 2.8353683404857293, train_acc = 0.9930135072193759\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 58, train_loss = 2.8188753887079656, train_acc = 0.9930135072193759\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 59, train_loss = 2.797270067734644, train_acc = 0.9930135072193759\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 60, train_loss = 2.7673108256421983, train_acc = 0.9931299487657196\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 61, train_loss = 2.7476531456923112, train_acc = 0.9931299487657196\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 62, train_loss = 2.73166592605412, train_acc = 0.9931299487657196\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 63, train_loss = 2.7077026237966493, train_acc = 0.9930135072193759\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 64, train_loss = 2.6858870229916647, train_acc = 0.9932463903120633\n",
      "test Acc 0.9632216014897579:\n",
      "9th- epoch: 65, train_loss = 2.664494337863289, train_acc = 0.9933628318584071\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 66, train_loss = 2.6447321450104937, train_acc = 0.9932463903120633\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 67, train_loss = 2.6310663358308375, train_acc = 0.9932463903120633\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 68, train_loss = 2.6166902247350663, train_acc = 0.9933628318584071\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 69, train_loss = 2.594966383650899, train_acc = 0.9932463903120633\n",
      "test Acc 0.9636871508379888:\n",
      "9th- epoch: 70, train_loss = 2.578276432817802, train_acc = 0.9933628318584071\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 71, train_loss = 2.5724303203169256, train_acc = 0.9937121564974383\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 72, train_loss = 2.550386442570016, train_acc = 0.9937121564974383\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 73, train_loss = 2.5354093372588977, train_acc = 0.993828598043782\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 74, train_loss = 2.528178473934531, train_acc = 0.9939450395901258\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 75, train_loss = 2.51818197988905, train_acc = 0.9939450395901258\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 76, train_loss = 2.502404739498161, train_acc = 0.9940614811364695\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 77, train_loss = 2.493391196243465, train_acc = 0.9939450395901258\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 78, train_loss = 2.4736712145386264, train_acc = 0.9940614811364695\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 79, train_loss = 2.4614800984272733, train_acc = 0.9939450395901258\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 80, train_loss = 2.4504631840391085, train_acc = 0.9937121564974383\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 81, train_loss = 2.4319151814561337, train_acc = 0.9939450395901258\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 82, train_loss = 2.426793629536405, train_acc = 0.9940614811364695\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 83, train_loss = 2.424424167838879, train_acc = 0.9940614811364695\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 84, train_loss = 2.4105776343494654, train_acc = 0.9939450395901258\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 85, train_loss = 2.4019015587400645, train_acc = 0.9941779226828132\n",
      "test Acc 0.9641527001862198:\n",
      "9th- epoch: 86, train_loss = 2.3821264097932726, train_acc = 0.994294364229157\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 87, train_loss = 2.380155867082067, train_acc = 0.9941779226828132\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 88, train_loss = 2.3668005988001823, train_acc = 0.9941779226828132\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 89, train_loss = 2.3590406499570236, train_acc = 0.9941779226828132\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 90, train_loss = 2.3518717722035944, train_acc = 0.9941779226828132\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 91, train_loss = 2.3445402026409283, train_acc = 0.9941779226828132\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 92, train_loss = 2.337421145173721, train_acc = 0.9941779226828132\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 93, train_loss = 2.322662495658733, train_acc = 0.9941779226828132\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 94, train_loss = 2.317306741606444, train_acc = 0.9941779226828132\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 95, train_loss = 2.308850756380707, train_acc = 0.9941779226828132\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 96, train_loss = 2.306923578144051, train_acc = 0.9941779226828132\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 97, train_loss = 2.2946268770610914, train_acc = 0.9941779226828132\n",
      "test Acc 0.9650837988826816:\n",
      "9th- epoch: 98, train_loss = 2.288612501346506, train_acc = 0.9941779226828132\n",
      "test Acc 0.9664804469273743:\n",
      "9th- epoch: 99, train_loss = 2.2820156938396394, train_acc = 0.9941779226828132\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 100, train_loss = 2.278872896451503, train_acc = 0.9941779226828132\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 101, train_loss = 2.267607901711017, train_acc = 0.9941779226828132\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 102, train_loss = 2.2646613663528115, train_acc = 0.9941779226828132\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 103, train_loss = 2.252564929658547, train_acc = 0.9946436888681882\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 104, train_loss = 2.2530594650888816, train_acc = 0.9941779226828132\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 105, train_loss = 2.2406420740298927, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 106, train_loss = 2.2426148989470676, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 107, train_loss = 2.2300302946241572, train_acc = 0.9948765719608756\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 108, train_loss = 2.2315364573150873, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 109, train_loss = 2.221200894098729, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 110, train_loss = 2.22062783758156, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 111, train_loss = 2.2141307074343786, train_acc = 0.9947601304145319\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 112, train_loss = 2.2095840320689604, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 113, train_loss = 2.1976316564250737, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 114, train_loss = 2.1994475852698088, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 115, train_loss = 2.1924948962405324, train_acc = 0.9947601304145319\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 116, train_loss = 2.1891855095745996, train_acc = 0.9947601304145319\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 117, train_loss = 2.1836960274958983, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 118, train_loss = 2.1809898549690843, train_acc = 0.9946436888681882\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 119, train_loss = 2.1729140714742243, train_acc = 0.9951094550535631\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 120, train_loss = 2.173959669424221, train_acc = 0.9946436888681882\n",
      "test Acc 0.9669459962756052:\n",
      "9th- epoch: 121, train_loss = 2.164574180962518, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 122, train_loss = 2.158041334943846, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 123, train_loss = 2.159693364868872, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 124, train_loss = 2.158061681315303, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 125, train_loss = 2.1462074884912, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 126, train_loss = 2.141636162181385, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 127, train_loss = 2.1408389958087355, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 128, train_loss = 2.13724263838958, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 129, train_loss = 2.134356126014609, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 130, train_loss = 2.12790865910938, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 131, train_loss = 2.1272769675706513, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 132, train_loss = 2.1297258772538044, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 133, train_loss = 2.1176730563747697, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 134, train_loss = 2.1216576378210448, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 135, train_loss = 2.117422314535361, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 136, train_loss = 2.1153643992729485, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 137, train_loss = 2.1047288865665905, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 138, train_loss = 2.103578933805693, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 139, train_loss = 2.103841594653204, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 140, train_loss = 2.095006730989553, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 141, train_loss = 2.1032381180557422, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 142, train_loss = 2.0958184498595074, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 143, train_loss = 2.086392978904769, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 144, train_loss = 2.098656195215881, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 145, train_loss = 2.0973370561841875, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 146, train_loss = 2.0893558320822194, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 147, train_loss = 2.079878977849148, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 148, train_loss = 2.072811198886484, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 149, train_loss = 2.089784200594295, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 150, train_loss = 2.081220549531281, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 151, train_loss = 2.064801719679963, train_acc = 0.9951094550535631\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 152, train_loss = 2.0702748540206812, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 153, train_loss = 2.069275800138712, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 154, train_loss = 2.056247382191941, train_acc = 0.9951094550535631\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 155, train_loss = 2.062310906476341, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 156, train_loss = 2.0595105391112156, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 157, train_loss = 2.0645657858694904, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 158, train_loss = 2.0549800432054326, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 159, train_loss = 2.0596668338985182, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 160, train_loss = 2.0514685607049614, train_acc = 0.9949930135072194\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 161, train_loss = 2.047468749457039, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 162, train_loss = 2.0497579291113652, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 163, train_loss = 2.0494294801028445, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 164, train_loss = 2.052977820392698, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 165, train_loss = 2.052003765711561, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 166, train_loss = 2.0391154210083187, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 167, train_loss = 2.0415161171695217, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 168, train_loss = 2.0333568195346743, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 169, train_loss = 2.039135023485869, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 170, train_loss = 2.0383986838860437, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 171, train_loss = 2.0358200968476012, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 172, train_loss = 2.029984615626745, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 173, train_loss = 2.031889627687633, train_acc = 0.9949930135072194\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 174, train_loss = 2.028543509193696, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 175, train_loss = 2.0275841701077297, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 176, train_loss = 2.0235407621366903, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 177, train_loss = 2.0264701368287206, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 178, train_loss = 2.028720231493935, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 179, train_loss = 2.0228956033242866, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 180, train_loss = 2.0219168468611315, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 181, train_loss = 2.0182665574830025, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 182, train_loss = 2.019500336726196, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 183, train_loss = 2.0136919013457373, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 184, train_loss = 2.021346066496335, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 185, train_loss = 2.013586871442385, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 186, train_loss = 2.0139291369123384, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 187, train_loss = 2.0033783548278734, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 188, train_loss = 1.9963250452419743, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 189, train_loss = 1.9965172095689923, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 190, train_loss = 1.991788482060656, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 191, train_loss = 1.9917376937810332, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 192, train_loss = 1.9890211572637782, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 193, train_loss = 1.9868420156417415, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 194, train_loss = 1.9868498831056058, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 195, train_loss = 1.9902072579134256, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 196, train_loss = 1.9920298607321456, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 197, train_loss = 1.9919404201209545, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 198, train_loss = 1.9987020383123308, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 199, train_loss = 1.9948840881697834, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 200, train_loss = 1.991894855396822, train_acc = 0.9948765719608756\n",
      "test Acc 0.9678770949720671:\n",
      "9th- epoch: 201, train_loss = 1.9900966233108193, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 202, train_loss = 1.9880716191837564, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 203, train_loss = 1.9817239289404824, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 204, train_loss = 1.981173214619048, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 205, train_loss = 1.9865438973065466, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 206, train_loss = 1.9843396714422852, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 207, train_loss = 1.9829764914466068, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 208, train_loss = 1.9785955304978415, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 209, train_loss = 1.9758282047696412, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 210, train_loss = 1.970195550005883, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 211, train_loss = 1.9637472372269258, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 212, train_loss = 1.968999563716352, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 213, train_loss = 1.9766755105229095, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 214, train_loss = 1.97409431374399, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 215, train_loss = 1.9735879600048065, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 216, train_loss = 1.9685194113990292, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 217, train_loss = 1.9652533300686628, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 218, train_loss = 1.967569615226239, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 219, train_loss = 1.9715299350209534, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 220, train_loss = 1.9686951289186254, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 221, train_loss = 1.9657077848678455, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 222, train_loss = 1.9605615973705426, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 223, train_loss = 1.9482896691188216, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 224, train_loss = 1.9545504552079365, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 225, train_loss = 1.957829526741989, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 226, train_loss = 1.9497891743667424, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 227, train_loss = 1.9491787498118356, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 228, train_loss = 1.9525751664768904, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 229, train_loss = 1.9442516467534006, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 230, train_loss = 1.9592624807264656, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 231, train_loss = 1.9484818986384198, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 232, train_loss = 1.9517659944831394, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 233, train_loss = 1.9388312156079337, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 234, train_loss = 1.9534982843906619, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 235, train_loss = 1.945599208236672, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 236, train_loss = 1.948541529942304, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 237, train_loss = 1.9513407466001809, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 238, train_loss = 1.9396282507805154, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 239, train_loss = 1.932378369208891, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 240, train_loss = 1.9313766779378057, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 241, train_loss = 1.947402713005431, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 242, train_loss = 1.9336353214457631, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 243, train_loss = 1.942347373755183, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 244, train_loss = 1.9371150123770349, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 245, train_loss = 1.945574980636593, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 246, train_loss = 1.9378851643996313, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 247, train_loss = 1.9322741872165352, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 248, train_loss = 1.933460959000513, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 249, train_loss = 1.9219073539716192, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 250, train_loss = 1.9349850533762947, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 251, train_loss = 1.9191051809466444, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 252, train_loss = 1.9244180574314669, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 253, train_loss = 1.9319186903885566, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 254, train_loss = 1.936026008974295, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 255, train_loss = 1.930613562290091, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 256, train_loss = 1.925839906965848, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 257, train_loss = 1.9330225772573613, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 258, train_loss = 1.9319023906136863, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 259, train_loss = 1.9210948235704564, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 260, train_loss = 1.928621626633685, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 261, train_loss = 1.9184072174830362, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 262, train_loss = 1.9196296259760857, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 263, train_loss = 1.9165391749120317, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 264, train_loss = 1.9123471914208494, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 265, train_loss = 1.9174401529598981, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 266, train_loss = 1.9171792340930551, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 267, train_loss = 1.9175691530108452, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 268, train_loss = 1.9212035417440347, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 269, train_loss = 1.9179621839430183, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 270, train_loss = 1.9059590654214844, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 271, train_loss = 1.9056736778002232, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 272, train_loss = 1.903842902276665, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 273, train_loss = 1.916152687103022, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 274, train_loss = 1.9117805399000645, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 275, train_loss = 1.907005954941269, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 276, train_loss = 1.9183533325558528, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 277, train_loss = 1.916877307172399, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 278, train_loss = 1.9148956974386238, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 279, train_loss = 1.9114004387520254, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 280, train_loss = 1.8971938791801222, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 281, train_loss = 1.9015276977443136, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 282, train_loss = 1.9089317866018973, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 283, train_loss = 1.9125843300134875, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 284, train_loss = 1.9106599490041845, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 285, train_loss = 1.9059725370607339, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 286, train_loss = 1.8899871846660972, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 287, train_loss = 1.900788473081775, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 288, train_loss = 1.8901833647978492, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 289, train_loss = 1.9049566707690246, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 290, train_loss = 1.8902709785033949, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 291, train_loss = 1.9033111905446276, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 292, train_loss = 1.9049576765391976, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 293, train_loss = 1.904845330340322, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 294, train_loss = 1.899317174043972, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 295, train_loss = 1.8996960680815391, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 296, train_loss = 1.8893089448683895, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 297, train_loss = 1.8861343343742192, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 298, train_loss = 1.8925676838553045, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 299, train_loss = 1.8971869349188637, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 300, train_loss = 1.8950426301453263, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 301, train_loss = 1.89476069752709, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 302, train_loss = 1.894222559465561, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 303, train_loss = 1.8922342731675599, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 304, train_loss = 1.897728810668923, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 305, train_loss = 1.8898277302505448, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 306, train_loss = 1.888123533281032, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 307, train_loss = 1.8935350477986503, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 308, train_loss = 1.888974943634821, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 309, train_loss = 1.8932169931940734, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 310, train_loss = 1.8868534944485873, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 311, train_loss = 1.8854185410600621, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 312, train_loss = 1.888356805080548, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 313, train_loss = 1.885980025457684, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 314, train_loss = 1.883831527957227, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 315, train_loss = 1.8834096254140604, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 316, train_loss = 1.8806674287770875, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 317, train_loss = 1.8814827772439457, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 318, train_loss = 1.881963437597733, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 319, train_loss = 1.8760310939105693, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 320, train_loss = 1.8801865878340323, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 321, train_loss = 1.873509709839709, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 322, train_loss = 1.8732424869231181, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 323, train_loss = 1.8719155677390518, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 324, train_loss = 1.8814541908213869, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 325, train_loss = 1.8718670957896393, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 326, train_loss = 1.8750351241906174, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 327, train_loss = 1.8760439830948599, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 328, train_loss = 1.8661067530047148, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 329, train_loss = 1.8647684218012728, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 330, train_loss = 1.8681223226012662, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 331, train_loss = 1.867913772992324, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 332, train_loss = 1.8665280576678924, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 333, train_loss = 1.862713212845847, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 334, train_loss = 1.8649339639232494, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 335, train_loss = 1.8610100604128093, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 336, train_loss = 1.8633733208989725, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 337, train_loss = 1.8650902438093908, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 338, train_loss = 1.8715968363103457, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 339, train_loss = 1.862646329042036, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 340, train_loss = 1.8622799759032205, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 341, train_loss = 1.8590009497129358, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 342, train_loss = 1.8708618858945556, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 343, train_loss = 1.8616392814437859, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 344, train_loss = 1.8589901300147176, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 345, train_loss = 1.8623487465665676, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 346, train_loss = 1.860544924682472, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 347, train_loss = 1.870182402257342, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 348, train_loss = 1.8577765478403307, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 349, train_loss = 1.853866278543137, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 350, train_loss = 1.8565681477775797, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 351, train_loss = 1.8552751126117073, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 352, train_loss = 1.8515294582466595, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 353, train_loss = 1.8550655206199735, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 354, train_loss = 1.8598312400863506, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 355, train_loss = 1.8512557998183183, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 356, train_loss = 1.8516575191752054, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 357, train_loss = 1.858233284787275, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 358, train_loss = 1.85020075913053, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 359, train_loss = 1.8480751253664494, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 360, train_loss = 1.8462618055636995, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 361, train_loss = 1.8514124675421044, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 362, train_loss = 1.8499342178110965, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 363, train_loss = 1.861132142774295, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 364, train_loss = 1.8465156794991344, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 365, train_loss = 1.8434376165969297, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 366, train_loss = 1.8451311878161505, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 367, train_loss = 1.852902486687526, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 368, train_loss = 1.8446270291460678, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 369, train_loss = 1.8422036201809533, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 370, train_loss = 1.8489613826968707, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 371, train_loss = 1.843480323732365, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 372, train_loss = 1.8466298096464016, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 373, train_loss = 1.841107598389499, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 374, train_loss = 1.8479832985321991, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 375, train_loss = 1.8354802121175453, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 376, train_loss = 1.8409684285288677, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 377, train_loss = 1.8438566824188456, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 378, train_loss = 1.8370515719871037, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 379, train_loss = 1.8451537748333067, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 380, train_loss = 1.844421109126415, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 381, train_loss = 1.835958980198484, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 382, train_loss = 1.8521045597153716, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 383, train_loss = 1.847406899847556, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 384, train_loss = 1.8311431682668626, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 385, train_loss = 1.832566071068868, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 386, train_loss = 1.832371136348229, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 387, train_loss = 1.8275404427549802, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 388, train_loss = 1.8299177552689798, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 389, train_loss = 1.8307770557003096, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 390, train_loss = 1.8384422853705473, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 391, train_loss = 1.8272680104710162, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 392, train_loss = 1.8282649731263518, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 393, train_loss = 1.8266298562521115, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 394, train_loss = 1.828954157535918, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 395, train_loss = 1.8376645960961469, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 396, train_loss = 1.8259129495127127, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 397, train_loss = 1.834726647066418, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 398, train_loss = 1.8257856353302486, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 399, train_loss = 1.8224736984120682, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 400, train_loss = 1.832745702995453, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 401, train_loss = 1.824434763926547, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 402, train_loss = 1.8242263943539, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 403, train_loss = 1.82322449516505, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 404, train_loss = 1.820852612669114, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 405, train_loss = 1.8199298972613178, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 406, train_loss = 1.820132044609636, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 407, train_loss = 1.8201906505273655, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 408, train_loss = 1.8201741850934923, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 409, train_loss = 1.8271964328014292, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 410, train_loss = 1.8288061698549427, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 411, train_loss = 1.8169006820535287, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 412, train_loss = 1.8194771363341715, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 413, train_loss = 1.814070875348989, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 414, train_loss = 1.815548187296372, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 415, train_loss = 1.8131953545380384, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 416, train_loss = 1.8173791732697282, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 417, train_loss = 1.8135342667810619, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 418, train_loss = 1.8121837011130992, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 419, train_loss = 1.8123635073716287, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 420, train_loss = 1.810719176166458, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 421, train_loss = 1.8114087460562587, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 422, train_loss = 1.8112483186414465, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 423, train_loss = 1.8084992802760098, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 424, train_loss = 1.808927818434313, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 425, train_loss = 1.8108394206210505, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 426, train_loss = 1.809099967009388, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 427, train_loss = 1.8082964800705668, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 428, train_loss = 1.8073399799468461, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 429, train_loss = 1.8088457907433622, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 430, train_loss = 1.8058555918687489, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 431, train_loss = 1.8072022574779112, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 432, train_loss = 1.8064413303800393, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 433, train_loss = 1.8051817379891872, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 434, train_loss = 1.801062718121102, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 435, train_loss = 1.7994924256054219, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 436, train_loss = 1.7985194735520054, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 437, train_loss = 1.7982490269641858, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 438, train_loss = 1.810242096427828, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 439, train_loss = 1.7982138881052379, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 440, train_loss = 1.7999706981645431, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 441, train_loss = 1.8017310987052042, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 442, train_loss = 1.795406535064103, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 443, train_loss = 1.7969873404072132, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 444, train_loss = 1.798982421430992, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 445, train_loss = 1.8044474733469542, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 446, train_loss = 1.7995303799689282, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 447, train_loss = 1.799228167597903, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 448, train_loss = 1.7978533103887457, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 449, train_loss = 1.797644206439145, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 450, train_loss = 1.796836407855153, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 451, train_loss = 1.796864169446053, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 452, train_loss = 1.7986033881607, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "9th- epoch: 453, train_loss = 1.8035108020994812, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 454, train_loss = 1.7939887484826613, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 455, train_loss = 1.7919457631360274, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 456, train_loss = 1.8072486796008889, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 457, train_loss = 1.7943102012213785, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 458, train_loss = 1.7932005450420547, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 459, train_loss = 1.7886540232866537, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 460, train_loss = 1.7918097550573293, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 461, train_loss = 1.7873536072438583, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 462, train_loss = 1.7955722607730422, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 463, train_loss = 1.7866120612306986, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 464, train_loss = 1.7861665325472131, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 465, train_loss = 1.7850291292415932, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 466, train_loss = 1.7874197544006165, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 467, train_loss = 1.7914944865333382, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 468, train_loss = 1.7849686263361946, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 469, train_loss = 1.7835499049106147, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 470, train_loss = 1.7828502315969672, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 471, train_loss = 1.784263465582626, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 472, train_loss = 1.7810822676401585, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 473, train_loss = 1.7810961727518588, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 474, train_loss = 1.781106000795262, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 475, train_loss = 1.7792908033006825, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 476, train_loss = 1.7792964990076143, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 477, train_loss = 1.7794114327116404, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 478, train_loss = 1.7779642222158145, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 479, train_loss = 1.7739088888920378, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 480, train_loss = 1.7769103710306808, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 481, train_loss = 1.7763447399483994, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 482, train_loss = 1.7767674366768915, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 483, train_loss = 1.772163789049955, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 484, train_loss = 1.7743085413530935, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 485, train_loss = 1.7723270182905253, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 486, train_loss = 1.7756630542862695, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 487, train_loss = 1.7751871188811492, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 488, train_loss = 1.7734201550483704, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 489, train_loss = 1.7729391578759532, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 490, train_loss = 1.7773255821957719, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 491, train_loss = 1.7680724971287418, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 492, train_loss = 1.767594945122255, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 493, train_loss = 1.771163273253478, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 494, train_loss = 1.7710514947830234, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 495, train_loss = 1.76864812077838, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 496, train_loss = 1.7692347006814089, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 497, train_loss = 1.7683183304034173, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "9th- epoch: 498, train_loss = 1.7673971155600157, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 499, train_loss = 1.7672659009695053, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███████████████████████                                                      | 9/30 [1:21:58<3:14:14, 554.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "10th- epoch: 0, train_loss = 372.7387392371893, train_acc = 0.8047275267815557\n",
      "test Acc 0.851024208566108:\n",
      "10th- epoch: 1, train_loss = 68.03886349312961, train_acc = 0.9208197484862599\n",
      "test Acc 0.9297020484171322:\n",
      "10th- epoch: 2, train_loss = 43.68333341414109, train_acc = 0.9437587331159758\n",
      "test Acc 0.9380819366852886:\n",
      "10th- epoch: 3, train_loss = 33.026098353322595, train_acc = 0.9547042384722869\n",
      "test Acc 0.9357541899441341:\n",
      "10th- epoch: 4, train_loss = 26.575786283705384, train_acc = 0.9597112249650676\n",
      "test Acc 0.9399441340782123:\n",
      "10th- epoch: 5, train_loss = 21.63222757866606, train_acc = 0.965649743828598\n",
      "test Acc 0.9455307262569832:\n",
      "10th- epoch: 6, train_loss = 18.079674057662487, train_acc = 0.9693758733115976\n",
      "test Acc 0.9464618249534451:\n",
      "10th- epoch: 7, train_loss = 15.434446342289448, train_acc = 0.9732184443409408\n",
      "test Acc 0.9487895716945997:\n",
      "10th- epoch: 8, train_loss = 13.589593976736069, train_acc = 0.9758965999068467\n",
      "test Acc 0.952048417132216:\n",
      "10th- epoch: 9, train_loss = 12.168642241507769, train_acc = 0.9775267815556591\n",
      "test Acc 0.9553072625698324:\n",
      "10th- epoch: 10, train_loss = 10.932409775443375, train_acc = 0.9785747554727526\n",
      "test Acc 0.957169459962756:\n",
      "10th- epoch: 11, train_loss = 9.889548954553902, train_acc = 0.9810200279459711\n",
      "test Acc 0.957169459962756:\n",
      "10th- epoch: 12, train_loss = 9.038062548264861, train_acc = 0.9826502095947834\n",
      "test Acc 0.9590316573556797:\n",
      "10th- epoch: 13, train_loss = 8.278145796619356, train_acc = 0.9840475081509082\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 14, train_loss = 7.682096500881016, train_acc = 0.9842803912435957\n",
      "test Acc 0.9581005586592178:\n",
      "10th- epoch: 15, train_loss = 7.158270284533501, train_acc = 0.9861434559850955\n",
      "test Acc 0.9581005586592178:\n",
      "10th- epoch: 16, train_loss = 6.700419049710035, train_acc = 0.9867256637168141\n",
      "test Acc 0.9594972067039106:\n",
      "10th- epoch: 17, train_loss = 6.305805536918342, train_acc = 0.9874243129948765\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 18, train_loss = 5.9710466070100665, train_acc = 0.9877736376339078\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 19, train_loss = 5.686019933782518, train_acc = 0.9880065207265952\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 20, train_loss = 5.404874175786972, train_acc = 0.9882394038192828\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 21, train_loss = 5.166249358095229, train_acc = 0.9888216115510013\n",
      "test Acc 0.9641527001862198:\n",
      "10th- epoch: 22, train_loss = 4.946976996026933, train_acc = 0.9895202608290639\n",
      "test Acc 0.9641527001862198:\n",
      "10th- epoch: 23, train_loss = 4.755842977203429, train_acc = 0.989869585468095\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 24, train_loss = 4.584904912859201, train_acc = 0.989869585468095\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 25, train_loss = 4.43909518327564, train_acc = 0.9902189101071263\n",
      "test Acc 0.9641527001862198:\n",
      "10th- epoch: 26, train_loss = 4.278108383063227, train_acc = 0.99033535165347\n",
      "test Acc 0.9636871508379888:\n",
      "10th- epoch: 27, train_loss = 4.155276288744062, train_acc = 0.990801117838845\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 28, train_loss = 4.025821703020483, train_acc = 0.9909175593851887\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 29, train_loss = 3.9166737645864487, train_acc = 0.9909175593851887\n",
      "test Acc 0.9646182495344506:\n",
      "10th- epoch: 30, train_loss = 3.813938658684492, train_acc = 0.9910340009315324\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 31, train_loss = 3.7027816609479487, train_acc = 0.9912668840242198\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 32, train_loss = 3.6196384890936315, train_acc = 0.9912668840242198\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 33, train_loss = 3.52833004668355, train_acc = 0.9913833255705635\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 34, train_loss = 3.454942295793444, train_acc = 0.9913833255705635\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 35, train_loss = 3.3758183023892343, train_acc = 0.9917326502095948\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 36, train_loss = 3.312272595707327, train_acc = 0.9917326502095948\n",
      "test Acc 0.9664804469273743:\n",
      "10th- epoch: 37, train_loss = 3.2508595236577094, train_acc = 0.9918490917559385\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 38, train_loss = 3.1848324588499963, train_acc = 0.9921984163949698\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 39, train_loss = 3.134894603397697, train_acc = 0.992081974848626\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 40, train_loss = 3.0747475675307214, train_acc = 0.9923148579413135\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 41, train_loss = 3.035278124269098, train_acc = 0.9924312994876572\n",
      "test Acc 0.9664804469273743:\n",
      "10th- epoch: 42, train_loss = 2.9825828657485545, train_acc = 0.9924312994876572\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 43, train_loss = 2.9447122565470636, train_acc = 0.9926641825803446\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 44, train_loss = 2.903098402079195, train_acc = 0.9926641825803446\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 45, train_loss = 2.8618816025555134, train_acc = 0.9926641825803446\n",
      "test Acc 0.9660148975791434:\n",
      "10th- epoch: 46, train_loss = 2.831895863171667, train_acc = 0.9926641825803446\n",
      "test Acc 0.9664804469273743:\n",
      "10th- epoch: 47, train_loss = 2.802906721830368, train_acc = 0.9927806241266884\n",
      "test Acc 0.9664804469273743:\n",
      "10th- epoch: 48, train_loss = 2.761479999870062, train_acc = 0.9926641825803446\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 49, train_loss = 2.7453485156875104, train_acc = 0.9927806241266884\n",
      "test Acc 0.9674115456238361:\n",
      "10th- epoch: 50, train_loss = 2.7071121868211776, train_acc = 0.9928970656730322\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 51, train_loss = 2.6817835059482604, train_acc = 0.9928970656730322\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 52, train_loss = 2.65604130551219, train_acc = 0.9930135072193759\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 53, train_loss = 2.633560262620449, train_acc = 0.9931299487657196\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 54, train_loss = 2.609208124456927, train_acc = 0.9931299487657196\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 55, train_loss = 2.59057346615009, train_acc = 0.9933628318584071\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 56, train_loss = 2.5682955496013165, train_acc = 0.9933628318584071\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 57, train_loss = 2.55466290935874, train_acc = 0.9933628318584071\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 58, train_loss = 2.528002145467326, train_acc = 0.9933628318584071\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 59, train_loss = 2.510731940390542, train_acc = 0.9933628318584071\n",
      "test Acc 0.9678770949720671:\n",
      "10th- epoch: 60, train_loss = 2.496781289577484, train_acc = 0.9933628318584071\n",
      "test Acc 0.9683426443202979:\n",
      "10th- epoch: 61, train_loss = 2.4836900383234024, train_acc = 0.9934792734047508\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 62, train_loss = 2.466072690906003, train_acc = 0.9934792734047508\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 63, train_loss = 2.4490254260599613, train_acc = 0.9934792734047508\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 64, train_loss = 2.435929858358577, train_acc = 0.9934792734047508\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 65, train_loss = 2.4214224827010185, train_acc = 0.9934792734047508\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 66, train_loss = 2.4141430631279945, train_acc = 0.9934792734047508\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 67, train_loss = 2.3979632321279496, train_acc = 0.9934792734047508\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 68, train_loss = 2.3803491480648518, train_acc = 0.9934792734047508\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 69, train_loss = 2.3746542807202786, train_acc = 0.9935957149510946\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 70, train_loss = 2.3619075666647404, train_acc = 0.9934792734047508\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 71, train_loss = 2.347970721544698, train_acc = 0.9937121564974383\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 72, train_loss = 2.3406912919599563, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 73, train_loss = 2.329789898125455, train_acc = 0.993828598043782\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 74, train_loss = 2.319501383928582, train_acc = 0.993828598043782\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 75, train_loss = 2.311127209337428, train_acc = 0.993828598043782\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 76, train_loss = 2.2971169475931674, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 77, train_loss = 2.294720691861585, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 78, train_loss = 2.281654303194955, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 79, train_loss = 2.2714951436500996, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 80, train_loss = 2.2679607681930065, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 81, train_loss = 2.257291068555787, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 82, train_loss = 2.2522402454633266, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 83, train_loss = 2.2399541523773223, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 84, train_loss = 2.237483536126092, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 85, train_loss = 2.2280520386993885, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "10th- epoch: 86, train_loss = 2.2236182019114494, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 87, train_loss = 2.216817001462914, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 88, train_loss = 2.210297764511779, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 89, train_loss = 2.2031113071134314, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 90, train_loss = 2.1953373266151175, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 91, train_loss = 2.190620976150967, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 92, train_loss = 2.1907798908650875, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 93, train_loss = 2.181464593857527, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 94, train_loss = 2.1717277243733406, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 95, train_loss = 2.168606915860437, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 96, train_loss = 2.164515934884548, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "10th- epoch: 97, train_loss = 2.1605552645632997, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 98, train_loss = 2.1566480435431004, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 99, train_loss = 2.151265120715834, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 100, train_loss = 2.1470972262322903, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 101, train_loss = 2.140712217777036, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 102, train_loss = 2.1401084264507517, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 103, train_loss = 2.132778728962876, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 104, train_loss = 2.1276034464826807, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 105, train_loss = 2.1238854924449697, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 106, train_loss = 2.1225196657469496, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 107, train_loss = 2.1172236067941412, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 108, train_loss = 2.113905026228167, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 109, train_loss = 2.1124255607137457, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 110, train_loss = 2.110591004253365, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 111, train_loss = 2.107139597297646, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 112, train_loss = 2.1065939416876063, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "10th- epoch: 113, train_loss = 2.102542524575256, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 114, train_loss = 2.092637710273266, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 115, train_loss = 2.092298336327076, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 116, train_loss = 2.0900758877396584, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 117, train_loss = 2.084811116219498, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 118, train_loss = 2.0808802358806133, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 119, train_loss = 2.083836047560908, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 120, train_loss = 2.0779404155910015, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 121, train_loss = 2.0824316665530205, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 122, train_loss = 2.071241838275455, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 123, train_loss = 2.074162026285194, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 124, train_loss = 2.0674356011440977, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 125, train_loss = 2.0637035543331876, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 126, train_loss = 2.0602498861262575, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 127, train_loss = 2.0635759867727757, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 128, train_loss = 2.0572837615618482, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 129, train_loss = 2.0535419235238805, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 130, train_loss = 2.0491815134882927, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 131, train_loss = 2.0500217465450987, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 132, train_loss = 2.045421689748764, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 133, train_loss = 2.0424870550632477, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 134, train_loss = 2.044454591930844, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 135, train_loss = 2.0402944994857535, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 136, train_loss = 2.0340131670236588, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 137, train_loss = 2.0350801162421703, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 138, train_loss = 2.0355464121093974, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 139, train_loss = 2.032781949848868, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 140, train_loss = 2.0241689818212762, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 141, train_loss = 2.0288282856345177, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 142, train_loss = 2.0240175388753414, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 143, train_loss = 2.0220920791034587, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 144, train_loss = 2.0213885816629045, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 145, train_loss = 2.0208042611484416, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 146, train_loss = 2.0196729749441147, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 147, train_loss = 2.0164914652705193, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 148, train_loss = 2.0186530972714536, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 149, train_loss = 2.012052590667736, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 150, train_loss = 2.0116708489949815, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 151, train_loss = 2.008476171642542, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 152, train_loss = 2.0051368810236454, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 153, train_loss = 2.0040127125685103, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 154, train_loss = 2.004707035899628, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 155, train_loss = 2.000156878202688, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 156, train_loss = 2.0003794717486016, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 157, train_loss = 1.9957883420283906, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 158, train_loss = 1.9966355574433692, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 159, train_loss = 1.9976722225546837, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 160, train_loss = 1.9918952149455436, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 161, train_loss = 1.9896584351663478, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 162, train_loss = 1.990187055140268, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 163, train_loss = 1.9882283422048204, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 164, train_loss = 1.9853865194017999, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 165, train_loss = 1.98561006662203, train_acc = 0.9951094550535631\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 166, train_loss = 1.9802480985526927, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 167, train_loss = 1.9807642636005767, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 168, train_loss = 1.977755340456497, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 169, train_loss = 1.9755511569674127, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 170, train_loss = 1.972096525132656, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 171, train_loss = 1.9690921232104301, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 172, train_loss = 1.9642989598214626, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 173, train_loss = 1.9629827302997, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 174, train_loss = 1.9656728319823742, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 175, train_loss = 1.9661249083583243, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 176, train_loss = 1.9600971465115435, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 177, train_loss = 1.9589151951367967, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 178, train_loss = 1.9596006435458548, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 179, train_loss = 1.960291001945734, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 180, train_loss = 1.956499697000254, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 181, train_loss = 1.9550480184261687, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 182, train_loss = 1.9501659087836742, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 183, train_loss = 1.9508030315046199, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 184, train_loss = 1.9541125086252578, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 185, train_loss = 1.9497243625228293, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 186, train_loss = 1.950946783006657, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 187, train_loss = 1.94655740755843, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 188, train_loss = 1.948505477339495, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 189, train_loss = 1.9458077463204972, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 190, train_loss = 1.9442861539428122, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 191, train_loss = 1.9418700188398361, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 192, train_loss = 1.9418805514578708, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 193, train_loss = 1.940011611848604, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 194, train_loss = 1.9412099781329744, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 195, train_loss = 1.935847606509924, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 196, train_loss = 1.936543345451355, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 197, train_loss = 1.932795127213467, train_acc = 0.9952258965999069\n",
      "test Acc 0.9716014897579144:\n",
      "10th- epoch: 198, train_loss = 1.9359403562848456, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 199, train_loss = 1.9349958288366906, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 200, train_loss = 1.9310551509261131, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 201, train_loss = 1.9294964509899728, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 202, train_loss = 1.9301092028617859, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 203, train_loss = 1.927072652906645, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 204, train_loss = 1.9315099989180453, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 205, train_loss = 1.9230802195961587, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 206, train_loss = 1.9250067819957621, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 207, train_loss = 1.92432040971471, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 208, train_loss = 1.923349806398619, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 209, train_loss = 1.9227729576523416, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 210, train_loss = 1.922260268300306, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 211, train_loss = 1.919171302288305, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 212, train_loss = 1.9163226162199862, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 213, train_loss = 1.9184261299669743, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 214, train_loss = 1.918906331062317, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 215, train_loss = 1.9165722628240474, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 216, train_loss = 1.912450021773111, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 217, train_loss = 1.9131600583787076, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 218, train_loss = 1.9153461046516895, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 219, train_loss = 1.9139581136405468, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 220, train_loss = 1.913556764513487, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 221, train_loss = 1.9073096625506878, train_acc = 0.9952258965999069\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 222, train_loss = 1.9108414575457573, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 223, train_loss = 1.908468379318947, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 224, train_loss = 1.906584370881319, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 225, train_loss = 1.9041287451982498, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 226, train_loss = 1.905647136271, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 227, train_loss = 1.904533926397562, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 228, train_loss = 1.9064579544065055, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 229, train_loss = 1.9044203286466654, train_acc = 0.9952258965999069\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 230, train_loss = 1.9000340960919857, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 231, train_loss = 1.8978797259333078, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 232, train_loss = 1.8999250369670335, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 233, train_loss = 1.9011588195862714, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 234, train_loss = 1.8959693064389285, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 235, train_loss = 1.8946742998959962, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 236, train_loss = 1.8958774842321873, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 237, train_loss = 1.8949934405682143, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 238, train_loss = 1.8938591008482035, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 239, train_loss = 1.8898041149077471, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 240, train_loss = 1.890773966908455, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 241, train_loss = 1.8905998480913695, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 242, train_loss = 1.8868364356458187, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 243, train_loss = 1.887888257711893, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 244, train_loss = 1.888599449157482, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 245, train_loss = 1.889501914381981, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 246, train_loss = 1.8890308687987272, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 247, train_loss = 1.886707911879057, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 248, train_loss = 1.8866235787572805, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 249, train_loss = 1.8841401189565659, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 250, train_loss = 1.8822533053753432, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 251, train_loss = 1.8811283546092454, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 252, train_loss = 1.8794440987112466, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 253, train_loss = 1.8788039026258048, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 254, train_loss = 1.878216384589905, train_acc = 0.9953423381462506\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 255, train_loss = 1.8777964586915914, train_acc = 0.9953423381462506\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 256, train_loss = 1.8762677001359407, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 257, train_loss = 1.8746370474400464, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 258, train_loss = 1.8741878954169806, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 259, train_loss = 1.872968969255453, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 260, train_loss = 1.8721407614648342, train_acc = 0.9953423381462506\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 261, train_loss = 1.872551223874325, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 262, train_loss = 1.8711147916910704, train_acc = 0.9953423381462506\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 263, train_loss = 1.8696524078550283, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 264, train_loss = 1.8690397925674915, train_acc = 0.9953423381462506\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 265, train_loss = 1.8680517623724882, train_acc = 0.9953423381462506\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 266, train_loss = 1.8680591210722923, train_acc = 0.9953423381462506\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 267, train_loss = 1.8678616409597453, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 268, train_loss = 1.8663685930368956, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 269, train_loss = 1.8653158098459244, train_acc = 0.9953423381462506\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 270, train_loss = 1.8643041886389256, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 271, train_loss = 1.8637137351033743, train_acc = 0.9953423381462506\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 272, train_loss = 1.8635420923528727, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 273, train_loss = 1.862533412873745, train_acc = 0.9953423381462506\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 274, train_loss = 1.8622892995772418, train_acc = 0.9953423381462506\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 275, train_loss = 1.8596755415201187, train_acc = 0.9953423381462506\n",
      "test Acc 0.972998137802607:\n",
      "10th- epoch: 276, train_loss = 1.8608544853923377, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 277, train_loss = 1.861428822070593, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 278, train_loss = 1.8574528396129608, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 279, train_loss = 1.8555994244816247, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 280, train_loss = 1.8553889282047749, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 281, train_loss = 1.8556907288730145, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 282, train_loss = 1.8562374015746173, train_acc = 0.9953423381462506\n",
      "test Acc 0.973463687150838:\n",
      "10th- epoch: 283, train_loss = 1.8519739670155104, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 284, train_loss = 1.852607972919941, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 285, train_loss = 1.8513784135284368, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 286, train_loss = 1.8509359955787659, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 287, train_loss = 1.851343885064125, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 288, train_loss = 1.849321419984335, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 289, train_loss = 1.8500791353581008, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 290, train_loss = 1.8466943105158862, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 291, train_loss = 1.8475190202298108, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 292, train_loss = 1.8483295626938343, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 293, train_loss = 1.845219367503887, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 294, train_loss = 1.8474083220062312, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 295, train_loss = 1.8441147940757219, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 296, train_loss = 1.8442299005982932, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 297, train_loss = 1.8421672135591507, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 298, train_loss = 1.8448224229214247, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 299, train_loss = 1.8404308395984117, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 300, train_loss = 1.8408502104284707, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 301, train_loss = 1.8395941915514413, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 302, train_loss = 1.8410424677131232, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 303, train_loss = 1.8381060895917471, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 304, train_loss = 1.8391521858575288, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 305, train_loss = 1.83627768108272, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 306, train_loss = 1.8366766845283564, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 307, train_loss = 1.8354575683770236, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 308, train_loss = 1.836276357382303, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 309, train_loss = 1.8351677296159323, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 310, train_loss = 1.8357086852192879, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 311, train_loss = 1.832534256071085, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 312, train_loss = 1.8336979324521963, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 313, train_loss = 1.8315927100775298, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 314, train_loss = 1.8307393814029638, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 315, train_loss = 1.8330708034336567, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 316, train_loss = 1.8320684606733266, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 317, train_loss = 1.827481141925091, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 318, train_loss = 1.8276734401879366, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 319, train_loss = 1.827421364694601, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 320, train_loss = 1.8275128826498985, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 321, train_loss = 1.8256986513733864, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 322, train_loss = 1.8264623433351517, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 323, train_loss = 1.8255599339900073, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 324, train_loss = 1.8236697874963284, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 325, train_loss = 1.823847234249115, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 326, train_loss = 1.820562407374382, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 327, train_loss = 1.8226168379187584, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 328, train_loss = 1.82190166041255, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 329, train_loss = 1.8213533821108285, train_acc = 0.9953423381462506\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 330, train_loss = 1.8175919627246913, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 331, train_loss = 1.8194875518383924, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 332, train_loss = 1.8176413464098005, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 333, train_loss = 1.819164668529993, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 334, train_loss = 1.8170403465628624, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 335, train_loss = 1.8156533328146907, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 336, train_loss = 1.8165726860315772, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 337, train_loss = 1.8158800502569648, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 338, train_loss = 1.8146195337176323, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 339, train_loss = 1.8137303690164117, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 340, train_loss = 1.8133330456912518, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 341, train_loss = 1.8120132784097223, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 342, train_loss = 1.8094574014394311, train_acc = 0.9953423381462506\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 343, train_loss = 1.8118528574705124, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 344, train_loss = 1.8110164441168308, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 345, train_loss = 1.810231938958168, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 346, train_loss = 1.8102258257567883, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 347, train_loss = 1.8085033930838108, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 348, train_loss = 1.8095314602105645, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 349, train_loss = 1.8074425223021535, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 350, train_loss = 1.8066286755056353, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 351, train_loss = 1.8049736221582862, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 352, train_loss = 1.8069405940623255, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 353, train_loss = 1.8068896954209777, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 354, train_loss = 1.8050805081875296, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 355, train_loss = 1.8033956475555897, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 356, train_loss = 1.8016555408685235, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 357, train_loss = 1.8039771479816409, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 358, train_loss = 1.8007950969040394, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 359, train_loss = 1.8016925317497225, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 360, train_loss = 1.8012749304325553, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 361, train_loss = 1.8011652367858915, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 362, train_loss = 1.798488773405552, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 363, train_loss = 1.7978913374245167, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 364, train_loss = 1.7965346785931615, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 365, train_loss = 1.7991493878216716, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 366, train_loss = 1.7979712995438604, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 367, train_loss = 1.7959523970930604, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 368, train_loss = 1.79539140065026, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 369, train_loss = 1.7956023067235947, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 370, train_loss = 1.794970319911954, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 371, train_loss = 1.7952609968633624, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 372, train_loss = 1.7928305466921302, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 373, train_loss = 1.7917299928813009, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 374, train_loss = 1.7907216573803453, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 375, train_loss = 1.7917356279940577, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 376, train_loss = 1.7888488310127286, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 377, train_loss = 1.7910219505429268, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 378, train_loss = 1.7889362263231305, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 379, train_loss = 1.7898157201707363, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 380, train_loss = 1.7886905036866665, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 381, train_loss = 1.7879391759634018, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 382, train_loss = 1.7873888313770294, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 383, train_loss = 1.7848310035915347, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 384, train_loss = 1.7850528943090467, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 385, train_loss = 1.7850122414529324, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 386, train_loss = 1.785671363279107, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 387, train_loss = 1.7844325751066208, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 388, train_loss = 1.7839952943177195, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 389, train_loss = 1.7813966224639444, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 390, train_loss = 1.7804447462112876, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 391, train_loss = 1.7813949634582968, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 392, train_loss = 1.7814468704164028, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 393, train_loss = 1.7786004853696795, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 394, train_loss = 1.7798355792911025, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "10th- epoch: 395, train_loss = 1.7789523924438981, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 396, train_loss = 1.7769921993167372, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 397, train_loss = 1.7762230671942234, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 398, train_loss = 1.7774595742375823, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 399, train_loss = 1.7779817171394825, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 400, train_loss = 1.7742079098970862, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 401, train_loss = 1.7758558715431718, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 402, train_loss = 1.7754173316061497, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 403, train_loss = 1.7728158334939508, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 404, train_loss = 1.772340189665556, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 405, train_loss = 1.773638490587473, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 406, train_loss = 1.7716112211346626, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 407, train_loss = 1.7717265387327643, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 408, train_loss = 1.7711021664290456, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 409, train_loss = 1.770253635942936, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 410, train_loss = 1.7699527156801196, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 411, train_loss = 1.7702967089862796, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 412, train_loss = 1.7675435431301594, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 413, train_loss = 1.767915952950716, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 414, train_loss = 1.7671964702458354, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 415, train_loss = 1.767302128180745, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 416, train_loss = 1.7666746440081624, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 417, train_loss = 1.7649167751224013, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 418, train_loss = 1.7648230157792568, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 419, train_loss = 1.7655801226646872, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 420, train_loss = 1.7649482935667038, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 421, train_loss = 1.7639016794710187, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 422, train_loss = 1.7625081117002992, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 423, train_loss = 1.7624365438969107, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 424, train_loss = 1.762066529438016, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 425, train_loss = 1.7619744340627221, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 426, train_loss = 1.762524388730526, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 427, train_loss = 1.7608079835772514, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 428, train_loss = 1.7598624688835116, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 429, train_loss = 1.7595282035617856, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 430, train_loss = 1.7599764193146257, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 431, train_loss = 1.758406464010477, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 432, train_loss = 1.7569450524897547, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 433, train_loss = 1.7571741441934137, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 434, train_loss = 1.7567977582366439, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 435, train_loss = 1.7557834150939016, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 436, train_loss = 1.754556991159916, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 437, train_loss = 1.755357122674468, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 438, train_loss = 1.7543280720710754, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 439, train_loss = 1.7539690968842478, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 440, train_loss = 1.7537218729703454, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 441, train_loss = 1.7537834991962882, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 442, train_loss = 1.7527382411062717, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 443, train_loss = 1.7519544437527657, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 444, train_loss = 1.750087320804596, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 445, train_loss = 1.7507402375340462, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 446, train_loss = 1.749738824859378, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 447, train_loss = 1.749866193786147, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 448, train_loss = 1.7488735454826383, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 449, train_loss = 1.7494271633477183, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 450, train_loss = 1.7483008143753977, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 451, train_loss = 1.7476459182798862, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 452, train_loss = 1.7466474299581023, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 453, train_loss = 1.7462208556680707, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 454, train_loss = 1.7450736736209365, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 455, train_loss = 1.745466994747403, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 456, train_loss = 1.7457334361970425, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 457, train_loss = 1.7432608467788668, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 458, train_loss = 1.7430040861218004, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 459, train_loss = 1.7431541072874097, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 460, train_loss = 1.7427374521939782, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 461, train_loss = 1.7422284483909607, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 462, train_loss = 1.7418822646141052, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 463, train_loss = 1.739626094698906, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 464, train_loss = 1.740475116923335, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 465, train_loss = 1.7399648278951645, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 466, train_loss = 1.7390118154435186, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 467, train_loss = 1.7384503645153018, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 468, train_loss = 1.7380363941192627, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 469, train_loss = 1.7368714027106762, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 470, train_loss = 1.7368395763187436, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 471, train_loss = 1.736873893692973, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 472, train_loss = 1.7383594401180744, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 473, train_loss = 1.7362430853099795, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 474, train_loss = 1.7348031575529603, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 475, train_loss = 1.7351246227772208, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 476, train_loss = 1.7340926180331735, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 477, train_loss = 1.7334660378546687, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 478, train_loss = 1.7325373093335656, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 479, train_loss = 1.7335745356976986, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 480, train_loss = 1.732921276241541, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 481, train_loss = 1.7306194144039182, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 482, train_loss = 1.7307735346257687, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 483, train_loss = 1.7290155788214179, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 484, train_loss = 1.7289850053639384, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 485, train_loss = 1.7286502768547507, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 486, train_loss = 1.729467463985202, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 487, train_loss = 1.728405901536462, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 488, train_loss = 1.7280438194720773, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 489, train_loss = 1.7278373961598845, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 490, train_loss = 1.7267235852777958, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 491, train_loss = 1.7270938741712598, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 492, train_loss = 1.7277692568750354, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 493, train_loss = 1.726244346544263, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 494, train_loss = 1.7260863060801057, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 495, train_loss = 1.7235573964862851, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 496, train_loss = 1.7248634149582358, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 497, train_loss = 1.7240829331130954, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 498, train_loss = 1.7225036310701398, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 499, train_loss = 1.7232587834150763, train_acc = 0.9953423381462506\n",
      "test Acc 0.9753258845437617:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|█████████████████████████▎                                                  | 10/30 [1:32:01<3:09:45, 569.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "11th- epoch: 0, train_loss = 354.03976848721504, train_acc = 0.808104331625524\n",
      "test Acc 0.8561452513966481:\n",
      "11th- epoch: 1, train_loss = 74.72257940471172, train_acc = 0.9169771774569166\n",
      "test Acc 0.8701117318435754:\n",
      "11th- epoch: 2, train_loss = 48.310905151069164, train_acc = 0.9358407079646017\n",
      "test Acc 0.9352886405959032:\n",
      "11th- epoch: 3, train_loss = 35.324169777333736, train_acc = 0.9469026548672567\n",
      "test Acc 0.9408752327746741:\n",
      "11th- epoch: 4, train_loss = 28.011009074747562, train_acc = 0.955985095482068\n",
      "test Acc 0.9385474860335196:\n",
      "11th- epoch: 5, train_loss = 23.578794062137604, train_acc = 0.9625058220773172\n",
      "test Acc 0.9478584729981379:\n",
      "11th- epoch: 6, train_loss = 20.149947963654995, train_acc = 0.9682114578481602\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 7, train_loss = 17.542635146528482, train_acc = 0.9701909641360037\n",
      "test Acc 0.9539106145251397:\n",
      "11th- epoch: 8, train_loss = 15.351695727556944, train_acc = 0.9719375873311598\n",
      "test Acc 0.9548417132216015:\n",
      "11th- epoch: 9, train_loss = 13.614507887512445, train_acc = 0.9750815090824406\n",
      "test Acc 0.9553072625698324:\n",
      "11th- epoch: 10, train_loss = 12.17401434481144, train_acc = 0.9755472752678156\n",
      "test Acc 0.9534450651769087:\n",
      "11th- epoch: 11, train_loss = 11.008451465517282, train_acc = 0.9776432231020028\n",
      "test Acc 0.9553072625698324:\n",
      "11th- epoch: 12, train_loss = 9.987874630838633, train_acc = 0.9799720540288775\n",
      "test Acc 0.9543761638733705:\n",
      "11th- epoch: 13, train_loss = 9.150228057056665, train_acc = 0.981951560316721\n",
      "test Acc 0.9553072625698324:\n",
      "11th- epoch: 14, train_loss = 8.46529882773757, train_acc = 0.9833488588728458\n",
      "test Acc 0.957635009310987:\n",
      "11th- epoch: 15, train_loss = 7.834011323750019, train_acc = 0.9842803912435957\n",
      "test Acc 0.9585661080074488:\n",
      "11th- epoch: 16, train_loss = 7.303878525272012, train_acc = 0.9848625989753144\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 17, train_loss = 6.8195530865341425, train_acc = 0.9853283651606893\n",
      "test Acc 0.962756052141527:\n",
      "11th- epoch: 18, train_loss = 6.428090652450919, train_acc = 0.985910572892408\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 19, train_loss = 6.0753585789352655, train_acc = 0.9860270144387517\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 20, train_loss = 5.761118961498141, train_acc = 0.986376339077783\n",
      "test Acc 0.9632216014897579:\n",
      "11th- epoch: 21, train_loss = 5.4899464743211865, train_acc = 0.9873078714485328\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 22, train_loss = 5.237418186850846, train_acc = 0.9883558453656265\n",
      "test Acc 0.9664804469273743:\n",
      "11th- epoch: 23, train_loss = 5.010726963169873, train_acc = 0.9885887284583139\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 24, train_loss = 4.823807564564049, train_acc = 0.9897531439217513\n",
      "test Acc 0.9669459962756052:\n",
      "11th- epoch: 25, train_loss = 4.6199632585048676, train_acc = 0.9897531439217513\n",
      "test Acc 0.9683426443202979:\n",
      "11th- epoch: 26, train_loss = 4.436299570836127, train_acc = 0.9899860270144387\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 27, train_loss = 4.285274006426334, train_acc = 0.9902189101071263\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 28, train_loss = 4.163256464060396, train_acc = 0.9906846762925011\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 29, train_loss = 4.038166356738657, train_acc = 0.9906846762925011\n",
      "test Acc 0.9711359404096834:\n",
      "11th- epoch: 30, train_loss = 3.934800162911415, train_acc = 0.9910340009315324\n",
      "test Acc 0.9716014897579144:\n",
      "11th- epoch: 31, train_loss = 3.832150182221085, train_acc = 0.9914997671169073\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 32, train_loss = 3.7566536688245833, train_acc = 0.9916162086632511\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 33, train_loss = 3.6506851254962385, train_acc = 0.992081974848626\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 34, train_loss = 3.581351988017559, train_acc = 0.9921984163949698\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 35, train_loss = 3.5136447525583208, train_acc = 0.992081974848626\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 36, train_loss = 3.4460734464228153, train_acc = 0.9921984163949698\n",
      "test Acc 0.9725325884543762:\n",
      "11th- epoch: 37, train_loss = 3.3731247819960117, train_acc = 0.9923148579413135\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 38, train_loss = 3.3188107647001743, train_acc = 0.9923148579413135\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 39, train_loss = 3.2590199396945536, train_acc = 0.9926641825803446\n",
      "test Acc 0.972998137802607:\n",
      "11th- epoch: 40, train_loss = 3.211642552167177, train_acc = 0.9927806241266884\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 41, train_loss = 3.1608991264365613, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 42, train_loss = 3.1134588136337698, train_acc = 0.9927806241266884\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 43, train_loss = 3.0726183257065713, train_acc = 0.9928970656730322\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 44, train_loss = 3.035809489665553, train_acc = 0.9928970656730322\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 45, train_loss = 2.997716190991923, train_acc = 0.9928970656730322\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 46, train_loss = 2.9624275241512805, train_acc = 0.9928970656730322\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 47, train_loss = 2.9345324572641402, train_acc = 0.9926641825803446\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 48, train_loss = 2.899854425340891, train_acc = 0.9926641825803446\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 49, train_loss = 2.863520175218582, train_acc = 0.9928970656730322\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 50, train_loss = 2.824619713006541, train_acc = 0.9928970656730322\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 51, train_loss = 2.8072396542411298, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 52, train_loss = 2.7828069601673633, train_acc = 0.9932463903120633\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 53, train_loss = 2.7759392634034157, train_acc = 0.9933628318584071\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 54, train_loss = 2.7443050865549594, train_acc = 0.9934792734047508\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 55, train_loss = 2.7160138487815857, train_acc = 0.9934792734047508\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 56, train_loss = 2.691693317145109, train_acc = 0.9933628318584071\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 57, train_loss = 2.66353065893054, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 58, train_loss = 2.647430506767705, train_acc = 0.9934792734047508\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 59, train_loss = 2.6270192563533783, train_acc = 0.9935957149510946\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 60, train_loss = 2.6175133287906647, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 61, train_loss = 2.5908914245665073, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 62, train_loss = 2.5761436646571383, train_acc = 0.9935957149510946\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 63, train_loss = 2.5658491601934657, train_acc = 0.9937121564974383\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 64, train_loss = 2.5425552738597617, train_acc = 0.993828598043782\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 65, train_loss = 2.521737036644481, train_acc = 0.9939450395901258\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 66, train_loss = 2.5020432621240616, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 67, train_loss = 2.4919464848935604, train_acc = 0.993828598043782\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 68, train_loss = 2.485294345766306, train_acc = 0.993828598043782\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 69, train_loss = 2.4665573947131634, train_acc = 0.9939450395901258\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 70, train_loss = 2.455484992475249, train_acc = 0.9939450395901258\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 71, train_loss = 2.4497976787388325, train_acc = 0.993828598043782\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 72, train_loss = 2.425179279060103, train_acc = 0.9939450395901258\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 73, train_loss = 2.413978515774943, train_acc = 0.9939450395901258\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 74, train_loss = 2.4070232324302197, train_acc = 0.993828598043782\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 75, train_loss = 2.401255908072926, train_acc = 0.9939450395901258\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 76, train_loss = 2.379971065907739, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 77, train_loss = 2.3776026306441054, train_acc = 0.9939450395901258\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 78, train_loss = 2.3560584001243114, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 79, train_loss = 2.3529679911443964, train_acc = 0.9939450395901258\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 80, train_loss = 2.345056458027102, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 81, train_loss = 2.3373184017837048, train_acc = 0.993828598043782\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 82, train_loss = 2.3224906139075756, train_acc = 0.9940614811364695\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 83, train_loss = 2.3148712316760793, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 84, train_loss = 2.3000781958689913, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 85, train_loss = 2.2982874835142866, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 86, train_loss = 2.2889931611716747, train_acc = 0.9940614811364695\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 87, train_loss = 2.279054651618935, train_acc = 0.9939450395901258\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 88, train_loss = 2.2697979733347893, train_acc = 0.993828598043782\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 89, train_loss = 2.265113932429813, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 90, train_loss = 2.2565733989467844, train_acc = 0.9939450395901258\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 91, train_loss = 2.2427799850702286, train_acc = 0.994294364229157\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 92, train_loss = 2.2341823814203963, train_acc = 0.993828598043782\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 93, train_loss = 2.2237774655222893, train_acc = 0.9941779226828132\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 94, train_loss = 2.214069319306873, train_acc = 0.9937121564974383\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 95, train_loss = 2.221957595436834, train_acc = 0.9940614811364695\n",
      "test Acc 0.9739292364990689:\n",
      "11th- epoch: 96, train_loss = 2.1982320012757555, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 97, train_loss = 2.2004898140439764, train_acc = 0.9941779226828132\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 98, train_loss = 2.1983170360326767, train_acc = 0.993828598043782\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 99, train_loss = 2.189276439487003, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 100, train_loss = 2.1801688236300834, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 101, train_loss = 2.1818868431146257, train_acc = 0.9940614811364695\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 102, train_loss = 2.1827587485313416, train_acc = 0.9940614811364695\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 103, train_loss = 2.1775120086967945, train_acc = 0.9940614811364695\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 104, train_loss = 2.18121551227523, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 105, train_loss = 2.163456428796053, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 106, train_loss = 2.170491086959373, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 107, train_loss = 2.166284903883934, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 108, train_loss = 2.1548569996957667, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 109, train_loss = 2.1524146025185473, train_acc = 0.9941779226828132\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 110, train_loss = 2.1475030817091465, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 111, train_loss = 2.144656273245346, train_acc = 0.9941779226828132\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 112, train_loss = 2.1387564328615554, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 113, train_loss = 2.1340448024566285, train_acc = 0.9944108057755007\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 114, train_loss = 2.126678742468357, train_acc = 0.9944108057755007\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 115, train_loss = 2.121579062193632, train_acc = 0.994294364229157\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 116, train_loss = 2.120415459095966, train_acc = 0.9944108057755007\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 117, train_loss = 2.1161733741755597, train_acc = 0.9944108057755007\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 118, train_loss = 2.1091650861199014, train_acc = 0.9944108057755007\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 119, train_loss = 2.1104288809001446, train_acc = 0.994294364229157\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 120, train_loss = 2.103466230153572, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 121, train_loss = 2.1086191323702224, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 122, train_loss = 2.1067041966016404, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 123, train_loss = 2.0906731449067593, train_acc = 0.9944108057755007\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 124, train_loss = 2.0874361495370977, train_acc = 0.9944108057755007\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 125, train_loss = 2.08428392308997, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 126, train_loss = 2.09303356212331, train_acc = 0.9944108057755007\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 127, train_loss = 2.0858168129925616, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 128, train_loss = 2.0723003447055817, train_acc = 0.9944108057755007\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 129, train_loss = 2.0726599780027755, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 130, train_loss = 2.068545788526535, train_acc = 0.9944108057755007\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 131, train_loss = 2.0689515831763856, train_acc = 0.9944108057755007\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 132, train_loss = 2.066360125958454, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 133, train_loss = 2.0599758003954776, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 134, train_loss = 2.0561656964127906, train_acc = 0.9944108057755007\n",
      "test Acc 0.9753258845437617:\n",
      "11th- epoch: 135, train_loss = 2.0588330142199993, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 136, train_loss = 2.0539674659376033, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 137, train_loss = 2.0541954562067986, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 138, train_loss = 2.045613816648256, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 139, train_loss = 2.044676800549496, train_acc = 0.9944108057755007\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 140, train_loss = 2.0394303438370116, train_acc = 0.9944108057755007\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 141, train_loss = 2.039947217970621, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 142, train_loss = 2.0364255160093307, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 143, train_loss = 2.0318297657067887, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 144, train_loss = 2.041219354898203, train_acc = 0.9945272473218444\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 145, train_loss = 2.0335008849506266, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 146, train_loss = 2.030210219323635, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 147, train_loss = 2.020837447285885, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 148, train_loss = 2.0185656870598905, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 149, train_loss = 2.0182567574083805, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 150, train_loss = 2.0139565145072993, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 151, train_loss = 2.0140996339614503, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 152, train_loss = 2.0162790529429913, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 153, train_loss = 2.0172033620474394, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 154, train_loss = 2.009743927657837, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 155, train_loss = 2.012863059848314, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 156, train_loss = 2.0145772136747837, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "11th- epoch: 157, train_loss = 2.005582747369772, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 158, train_loss = 1.9995035789906979, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 159, train_loss = 2.0015906120243017, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 160, train_loss = 1.9948592496511992, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 161, train_loss = 1.9962978102266788, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 162, train_loss = 1.9960968904197216, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 163, train_loss = 1.9884535434248392, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 164, train_loss = 1.9927195323107298, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 165, train_loss = 1.991640546679264, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 166, train_loss = 1.9909293043019716, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 167, train_loss = 1.9890697722730692, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 168, train_loss = 1.9863877457974013, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 169, train_loss = 1.980125733971363, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 170, train_loss = 1.9825838046672288, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 171, train_loss = 1.9773749808373395, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 172, train_loss = 1.9764605462551117, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 173, train_loss = 1.9763957224786282, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 174, train_loss = 1.974609407276148, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 175, train_loss = 1.9712775982916355, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 176, train_loss = 1.9630590230226517, train_acc = 0.9946436888681882\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 177, train_loss = 1.9591718800365925, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 178, train_loss = 1.9642527736723423, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 179, train_loss = 1.9657408595085144, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 180, train_loss = 1.9612857600150164, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 181, train_loss = 1.9664810399117414, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 182, train_loss = 1.9628716173174325, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 183, train_loss = 1.9641815299692098, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 184, train_loss = 1.958942037075758, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 185, train_loss = 1.9544048445823137, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 186, train_loss = 1.9567957557737827, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 187, train_loss = 1.9513811630604323, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 188, train_loss = 1.9560846487584058, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 189, train_loss = 1.955324978887802, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 190, train_loss = 1.9486579485237598, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 191, train_loss = 1.9492825008928776, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 192, train_loss = 1.9430026896297932, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 193, train_loss = 1.9452005053462926, train_acc = 0.9946436888681882\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 194, train_loss = 1.9464626064000186, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 195, train_loss = 1.9439960680902004, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 196, train_loss = 1.9409658399818, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 197, train_loss = 1.9390515200793743, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 198, train_loss = 1.9383740300836507, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 199, train_loss = 1.9391773492097855, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 200, train_loss = 1.9406187807617243, train_acc = 0.9946436888681882\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 201, train_loss = 1.9386454137566034, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 202, train_loss = 1.9321920486690942, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 203, train_loss = 1.9333288768830243, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 204, train_loss = 1.9365701340138912, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 205, train_loss = 1.9325277085008565, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 206, train_loss = 1.934587761759758, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 207, train_loss = 1.9300664700567722, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 208, train_loss = 1.9276633175613824, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 209, train_loss = 1.926086463034153, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 210, train_loss = 1.9300729272363242, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 211, train_loss = 1.9261337655188981, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 212, train_loss = 1.9199979466793593, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 213, train_loss = 1.9263295332493726, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 214, train_loss = 1.9206893319787923, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 215, train_loss = 1.9229821786284447, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 216, train_loss = 1.917814521730179, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 217, train_loss = 1.9188247509300709, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 218, train_loss = 1.920625754952198, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 219, train_loss = 1.919607783347601, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 220, train_loss = 1.9156678678991739, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 221, train_loss = 1.9119063975813333, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 222, train_loss = 1.9125219024717808, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 223, train_loss = 1.9106396548449993, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 224, train_loss = 1.9086827685532626, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 225, train_loss = 1.9110746781079797, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 226, train_loss = 1.907822284847498, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 227, train_loss = 1.903950970619917, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 228, train_loss = 1.9047173112630844, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 229, train_loss = 1.905634295195341, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 230, train_loss = 1.9046823543758364, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 231, train_loss = 1.9063448918313952, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 232, train_loss = 1.8987237724213628, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 233, train_loss = 1.90288604174566, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 234, train_loss = 1.8999627033917932, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 235, train_loss = 1.8973961596639128, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 236, train_loss = 1.898878616586444, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 237, train_loss = 1.894748202219489, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 238, train_loss = 1.8935961363167735, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 239, train_loss = 1.8937768091709586, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 240, train_loss = 1.8958692575542955, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 241, train_loss = 1.8931364826858044, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 242, train_loss = 1.8870218209922314, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 243, train_loss = 1.8893679454922676, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 244, train_loss = 1.8889294788241386, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 245, train_loss = 1.8872148779482814, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 246, train_loss = 1.8907206555159064, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 247, train_loss = 1.889672227203846, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 248, train_loss = 1.885788880288601, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 249, train_loss = 1.8836831413209438, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 250, train_loss = 1.8882691686303588, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 251, train_loss = 1.886502418667078, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 252, train_loss = 1.8831371342093917, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 253, train_loss = 1.878350714847329, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 254, train_loss = 1.885469111308339, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 255, train_loss = 1.8772080702037783, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 256, train_loss = 1.8785789671092061, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 257, train_loss = 1.8795760783104924, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 258, train_loss = 1.8784607412962941, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 259, train_loss = 1.8730780954210786, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 260, train_loss = 1.8840805925428867, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 261, train_loss = 1.8787859380245209, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 262, train_loss = 1.8770402111113071, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 263, train_loss = 1.8718541239650222, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 264, train_loss = 1.8749773688614368, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 265, train_loss = 1.8740274508745642, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 266, train_loss = 1.8729197817592649, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 267, train_loss = 1.8728103687317343, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 268, train_loss = 1.8742558620870113, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 269, train_loss = 1.8694320172071457, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 270, train_loss = 1.8647352581174346, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 271, train_loss = 1.863722371563199, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 272, train_loss = 1.8660808242857456, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 273, train_loss = 1.8692320920526981, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 274, train_loss = 1.8674557196645765, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 275, train_loss = 1.865097712725401, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 276, train_loss = 1.8633911572396755, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 277, train_loss = 1.8625442485063104, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 278, train_loss = 1.860489148646593, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 279, train_loss = 1.8585664592683315, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 280, train_loss = 1.8590899581759004, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 281, train_loss = 1.8564881471247645, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 282, train_loss = 1.8586040027439594, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 283, train_loss = 1.8549896938056918, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 284, train_loss = 1.8573551960289478, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 285, train_loss = 1.8522537797689438, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 286, train_loss = 1.8555231280624866, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 287, train_loss = 1.8584816207439872, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 288, train_loss = 1.8570952080190182, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 289, train_loss = 1.8538947751076194, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 290, train_loss = 1.8534229497163324, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 291, train_loss = 1.8476853718311759, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 292, train_loss = 1.850415767476079, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 293, train_loss = 1.8511241301894188, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 294, train_loss = 1.847853480532649, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 295, train_loss = 1.8478112580924062, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 296, train_loss = 1.8523471392691135, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 297, train_loss = 1.8469326210470172, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 298, train_loss = 1.843717448413372, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 299, train_loss = 1.845402106642723, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 300, train_loss = 1.8429220008401899, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 301, train_loss = 1.839897224053857, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 302, train_loss = 1.845182238772395, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 303, train_loss = 1.845015723258257, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 304, train_loss = 1.8396963725535898, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 305, train_loss = 1.8430792639701394, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 306, train_loss = 1.838449738919735, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 307, train_loss = 1.8363463978021173, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 308, train_loss = 1.836297365531209, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 309, train_loss = 1.8361227437853813, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 310, train_loss = 1.8393132227211026, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 311, train_loss = 1.8351096200494794, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 312, train_loss = 1.8346745682210894, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 313, train_loss = 1.8345075187535258, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 314, train_loss = 1.8381188685743837, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 315, train_loss = 1.8338468658475904, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 316, train_loss = 1.829009935259819, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 317, train_loss = 1.8343250105826883, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 318, train_loss = 1.834898139044526, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 319, train_loss = 1.828275798514369, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 320, train_loss = 1.8311644705681829, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 321, train_loss = 1.834074700876954, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 322, train_loss = 1.8306794352829456, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 323, train_loss = 1.8267117353825597, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 324, train_loss = 1.8318934477865696, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 325, train_loss = 1.8294457371084718, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 326, train_loss = 1.8268971939833136, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 327, train_loss = 1.823831441506627, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 328, train_loss = 1.8240281107573537, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 329, train_loss = 1.8235767260193825, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 330, train_loss = 1.821290214851615, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 331, train_loss = 1.8241881939320592, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 332, train_loss = 1.8184846428484889, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 333, train_loss = 1.8185469657182693, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 334, train_loss = 1.8248340537102195, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 335, train_loss = 1.8219790967850713, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 336, train_loss = 1.8163434552698163, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 337, train_loss = 1.8201086620538263, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 338, train_loss = 1.822522143527749, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 339, train_loss = 1.8229627385735512, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 340, train_loss = 1.8201162119657965, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 341, train_loss = 1.8169745430350304, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 342, train_loss = 1.8184839822351933, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 343, train_loss = 1.815441199883935, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 344, train_loss = 1.8152141670434503, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 345, train_loss = 1.8173886810691329, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 346, train_loss = 1.8161702578217955, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 347, train_loss = 1.8149184174835682, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 348, train_loss = 1.8087238036096096, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 349, train_loss = 1.8139207437634468, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 350, train_loss = 1.813908264040947, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 351, train_loss = 1.8114926790149184, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 352, train_loss = 1.8135281788854627, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 353, train_loss = 1.8126594958157511, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 354, train_loss = 1.812001061931369, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 355, train_loss = 1.812853630632162, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 356, train_loss = 1.806594128414872, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 357, train_loss = 1.8082685259432765, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 358, train_loss = 1.8078900737018557, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 359, train_loss = 1.8094777837395668, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 360, train_loss = 1.8088945833296748, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 361, train_loss = 1.808400735259056, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 362, train_loss = 1.8069588653743267, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 363, train_loss = 1.8078411904425593, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 364, train_loss = 1.8076429826469393, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 365, train_loss = 1.808390624821186, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 366, train_loss = 1.8059390274138423, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 367, train_loss = 1.8039621487259865, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 368, train_loss = 1.805220764130354, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 369, train_loss = 1.8051220017223386, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 370, train_loss = 1.8024281064717798, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 371, train_loss = 1.8023595872073201, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 372, train_loss = 1.8013221037836047, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 373, train_loss = 1.801467426121235, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 374, train_loss = 1.8022841376514407, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 375, train_loss = 1.7998241049572243, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 376, train_loss = 1.801384602986218, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 377, train_loss = 1.8027350679039955, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 378, train_loss = 1.797555328659655, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 379, train_loss = 1.7985540914087323, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 380, train_loss = 1.7975240858868347, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 381, train_loss = 1.7954839703961625, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 382, train_loss = 1.7959873154759407, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 383, train_loss = 1.7963150466457591, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 384, train_loss = 1.7934325026944862, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 385, train_loss = 1.796443818755506, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 386, train_loss = 1.7926116945818649, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 387, train_loss = 1.7921647106632008, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 388, train_loss = 1.7917447052896023, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 389, train_loss = 1.7924176466985955, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 390, train_loss = 1.7892596709207282, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 391, train_loss = 1.7966959116383805, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 392, train_loss = 1.7993515816851868, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 393, train_loss = 1.7954441321417107, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 394, train_loss = 1.7973684233948006, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 395, train_loss = 1.7990137115120888, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 396, train_loss = 1.7877035687342868, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 397, train_loss = 1.7867567340508685, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 398, train_loss = 1.7831137726680026, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 399, train_loss = 1.783182855695486, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 400, train_loss = 1.780624121427536, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 401, train_loss = 1.7826649261041894, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 402, train_loss = 1.7864893923178897, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 403, train_loss = 1.7839291393756866, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 404, train_loss = 1.781797755509615, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 405, train_loss = 1.7807941523715272, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 406, train_loss = 1.7833779181019054, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 407, train_loss = 1.7814431649967446, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 408, train_loss = 1.779793031513691, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 409, train_loss = 1.7812650799751282, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 410, train_loss = 1.778952106833458, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 411, train_loss = 1.7770721999331727, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 412, train_loss = 1.777829254664539, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 413, train_loss = 1.779109829418303, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 414, train_loss = 1.7781701385974884, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 415, train_loss = 1.777015831321478, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 416, train_loss = 1.7766182459890842, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 417, train_loss = 1.7761077843606472, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 418, train_loss = 1.7766851435080753, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 419, train_loss = 1.7751220973805175, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 420, train_loss = 1.7741853197439923, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 421, train_loss = 1.7730685211718082, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 422, train_loss = 1.7738611164168105, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 423, train_loss = 1.7726806600912823, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 424, train_loss = 1.77124797180295, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 425, train_loss = 1.7738640755414963, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 426, train_loss = 1.7702298437579884, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 427, train_loss = 1.7700224369764328, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 428, train_loss = 1.7684283927083015, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 429, train_loss = 1.7718994865790592, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 430, train_loss = 1.7695466851218953, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 431, train_loss = 1.7671100894585834, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 432, train_loss = 1.7700040265917778, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 433, train_loss = 1.766461947314383, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 434, train_loss = 1.7667951782568707, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 435, train_loss = 1.7652599662542343, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 436, train_loss = 1.7659733456894173, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 437, train_loss = 1.7652181796729565, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 438, train_loss = 1.7667343306020484, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 439, train_loss = 1.764089355863689, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 440, train_loss = 1.7704993089064374, train_acc = 0.9947601304145319\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 441, train_loss = 1.7723117917776108, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 442, train_loss = 1.7655801065266132, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 443, train_loss = 1.7626089329496608, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 444, train_loss = 1.7607201859354973, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 445, train_loss = 1.759354431182146, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 446, train_loss = 1.76010323563969, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 447, train_loss = 1.7595270114616142, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 448, train_loss = 1.7592817234472022, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 449, train_loss = 1.7582592144608498, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 450, train_loss = 1.7601624950766563, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 451, train_loss = 1.7563146650791168, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 452, train_loss = 1.7644036561250687, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 453, train_loss = 1.7656041408554302, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 454, train_loss = 1.7579108377321973, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 455, train_loss = 1.7545691132545471, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 456, train_loss = 1.7555391949936165, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 457, train_loss = 1.754021889217256, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 458, train_loss = 1.7553571214302792, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 459, train_loss = 1.7544594494029297, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 460, train_loss = 1.7530385529025807, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 461, train_loss = 1.7522351133302436, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 462, train_loss = 1.7537932308987365, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 463, train_loss = 1.7579000828191056, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 464, train_loss = 1.7491378597915173, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 465, train_loss = 1.7499198950827122, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 466, train_loss = 1.7489305026829243, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 467, train_loss = 1.748943688966392, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 468, train_loss = 1.7499865666031837, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 469, train_loss = 1.7543996485546813, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 470, train_loss = 1.7494925148785114, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 471, train_loss = 1.750139004238008, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 472, train_loss = 1.752274226397276, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 473, train_loss = 1.7572309387251153, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 474, train_loss = 1.7551179801448598, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 475, train_loss = 1.743261291332601, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 476, train_loss = 1.7410963959991932, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 477, train_loss = 1.7431786358356476, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 478, train_loss = 1.7431070531383739, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 479, train_loss = 1.746771742902638, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 480, train_loss = 1.7427480916157947, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 481, train_loss = 1.7501161309555755, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 482, train_loss = 1.744029073663114, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 483, train_loss = 1.7441374560221448, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 484, train_loss = 1.7388165655211196, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 485, train_loss = 1.7405238039791584, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 486, train_loss = 1.7409676077440963, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 487, train_loss = 1.7405580294653191, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 488, train_loss = 1.7456234730780125, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 489, train_loss = 1.736794093005301, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 490, train_loss = 1.7372412780896411, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 491, train_loss = 1.745249713458179, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 492, train_loss = 1.7361174561083317, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 493, train_loss = 1.7377217523753643, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 494, train_loss = 1.7349454015493393, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 495, train_loss = 1.7421182207763195, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 496, train_loss = 1.7356501929461956, train_acc = 0.9948765719608756\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 497, train_loss = 1.734168923147081, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 498, train_loss = 1.7340875640511513, train_acc = 0.9949930135072194\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 499, train_loss = 1.734554282076715, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 37%|███████████████████████████▊                                                | 11/30 [1:42:17<3:04:42, 583.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "12th- epoch: 0, train_loss = 386.73953676968813, train_acc = 0.7976245924545878\n",
      "test Acc 0.8435754189944135:\n",
      "12th- epoch: 1, train_loss = 67.08023819606751, train_acc = 0.9149976711690732\n",
      "test Acc 0.9134078212290503:\n",
      "12th- epoch: 2, train_loss = 45.25417100964114, train_acc = 0.9336283185840708\n",
      "test Acc 0.931098696461825:\n",
      "12th- epoch: 3, train_loss = 33.346529389265925, train_acc = 0.9482999534233815\n",
      "test Acc 0.9380819366852886:\n",
      "12th- epoch: 4, train_loss = 26.08491454878822, train_acc = 0.9556357708430367\n",
      "test Acc 0.9390130353817505:\n",
      "12th- epoch: 5, train_loss = 21.161167942686006, train_acc = 0.9634373544480671\n",
      "test Acc 0.9436685288640596:\n",
      "12th- epoch: 6, train_loss = 17.543534443248063, train_acc = 0.9666977177456917\n",
      "test Acc 0.9459962756052142:\n",
      "12th- epoch: 7, train_loss = 14.806490599177778, train_acc = 0.9698416394969726\n",
      "test Acc 0.9473929236499069:\n",
      "12th- epoch: 8, train_loss = 12.663628712762147, train_acc = 0.9729855612482534\n",
      "test Acc 0.9501862197392924:\n",
      "12th- epoch: 9, train_loss = 11.123178277164698, train_acc = 0.9750815090824406\n",
      "test Acc 0.9515828677839852:\n",
      "12th- epoch: 10, train_loss = 9.949429764878005, train_acc = 0.9778761061946902\n",
      "test Acc 0.9543761638733705:\n",
      "12th- epoch: 11, train_loss = 8.981416124850512, train_acc = 0.9793898462971589\n",
      "test Acc 0.9557728119180633:\n",
      "12th- epoch: 12, train_loss = 8.168800347484648, train_acc = 0.9812529110386586\n",
      "test Acc 0.9562383612662942:\n",
      "12th- epoch: 13, train_loss = 7.532968772575259, train_acc = 0.9821844434094085\n",
      "test Acc 0.957635009310987:\n",
      "12th- epoch: 14, train_loss = 6.98721512965858, train_acc = 0.9835817419655333\n",
      "test Acc 0.957169459962756:\n",
      "12th- epoch: 15, train_loss = 6.509256362449378, train_acc = 0.9861434559850955\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 16, train_loss = 6.134600915946066, train_acc = 0.9867256637168141\n",
      "test Acc 0.957169459962756:\n",
      "12th- epoch: 17, train_loss = 5.826691018417478, train_acc = 0.9874243129948765\n",
      "test Acc 0.9581005586592178:\n",
      "12th- epoch: 18, train_loss = 5.5576111655682325, train_acc = 0.9883558453656265\n",
      "test Acc 0.9590316573556797:\n",
      "12th- epoch: 19, train_loss = 5.310380563605577, train_acc = 0.9888216115510013\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 20, train_loss = 5.101346843410283, train_acc = 0.98940381928272\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 21, train_loss = 4.9020847007632256, train_acc = 0.989869585468095\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 22, train_loss = 4.738332768902183, train_acc = 0.99033535165347\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 23, train_loss = 4.5967370620928705, train_acc = 0.9906846762925011\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 24, train_loss = 4.460182738956064, train_acc = 0.9909175593851887\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 25, train_loss = 4.322966616135091, train_acc = 0.9906846762925011\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 26, train_loss = 4.21137365908362, train_acc = 0.9910340009315324\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 27, train_loss = 4.1108630450908095, train_acc = 0.9913833255705635\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 28, train_loss = 4.001472423551604, train_acc = 0.9916162086632511\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 29, train_loss = 3.9033120220992714, train_acc = 0.9918490917559385\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 30, train_loss = 3.825730541255325, train_acc = 0.9919655333022822\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 31, train_loss = 3.741948622977361, train_acc = 0.9918490917559385\n",
      "test Acc 0.9636871508379888:\n",
      "12th- epoch: 32, train_loss = 3.6549373940797523, train_acc = 0.9921984163949698\n",
      "test Acc 0.9641527001862198:\n",
      "12th- epoch: 33, train_loss = 3.5891378093510866, train_acc = 0.9923148579413135\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 34, train_loss = 3.5267532642465085, train_acc = 0.9919655333022822\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 35, train_loss = 3.4503916965331882, train_acc = 0.9923148579413135\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 36, train_loss = 3.3913451705593616, train_acc = 0.992081974848626\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 37, train_loss = 3.3331415937282145, train_acc = 0.9923148579413135\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 38, train_loss = 3.2858789968304336, train_acc = 0.9926641825803446\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 39, train_loss = 3.2326553866732866, train_acc = 0.9925477410340009\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 40, train_loss = 3.183173055178486, train_acc = 0.9926641825803446\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 41, train_loss = 3.1435709015931934, train_acc = 0.9928970656730322\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 42, train_loss = 3.097299629007466, train_acc = 0.9927806241266884\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 43, train_loss = 3.057044940069318, train_acc = 0.9926641825803446\n",
      "test Acc 0.9650837988826816:\n",
      "12th- epoch: 44, train_loss = 3.0194991709431633, train_acc = 0.9930135072193759\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 45, train_loss = 2.9860188816674054, train_acc = 0.9927806241266884\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 46, train_loss = 2.9521910635521635, train_acc = 0.9928970656730322\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 47, train_loss = 2.9182507389923558, train_acc = 0.9928970656730322\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 48, train_loss = 2.8972503792028874, train_acc = 0.9930135072193759\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 49, train_loss = 2.8616273177322, train_acc = 0.9928970656730322\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 50, train_loss = 2.843091586662922, train_acc = 0.9930135072193759\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 51, train_loss = 2.8096873063477688, train_acc = 0.9931299487657196\n",
      "test Acc 0.9655493482309124:\n",
      "12th- epoch: 52, train_loss = 2.7906461938400753, train_acc = 0.9932463903120633\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 53, train_loss = 2.7637493214569986, train_acc = 0.9931299487657196\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 54, train_loss = 2.7460958829615265, train_acc = 0.9933628318584071\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 55, train_loss = 2.720378103549592, train_acc = 0.9931299487657196\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 56, train_loss = 2.7000909853959456, train_acc = 0.9934792734047508\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 57, train_loss = 2.67489179095719, train_acc = 0.9934792734047508\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 58, train_loss = 2.6520674199564382, train_acc = 0.9933628318584071\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 59, train_loss = 2.605006888974458, train_acc = 0.9933628318584071\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 60, train_loss = 2.583515082136728, train_acc = 0.9933628318584071\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 61, train_loss = 2.5563314264873043, train_acc = 0.9933628318584071\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 62, train_loss = 2.5447232386795804, train_acc = 0.9933628318584071\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 63, train_loss = 2.5279429187066853, train_acc = 0.9934792734047508\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 64, train_loss = 2.512611541431397, train_acc = 0.9933628318584071\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 65, train_loss = 2.5042985058389604, train_acc = 0.9934792734047508\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 66, train_loss = 2.4886426272569224, train_acc = 0.9934792734047508\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 67, train_loss = 2.4684010962955654, train_acc = 0.9937121564974383\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 68, train_loss = 2.4599330871133134, train_acc = 0.9939450395901258\n",
      "test Acc 0.9664804469273743:\n",
      "12th- epoch: 69, train_loss = 2.4395233805989847, train_acc = 0.9937121564974383\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 70, train_loss = 2.4278902331134304, train_acc = 0.9937121564974383\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 71, train_loss = 2.415780107374303, train_acc = 0.9937121564974383\n",
      "test Acc 0.9669459962756052:\n",
      "12th- epoch: 72, train_loss = 2.4077951260842383, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 73, train_loss = 2.3895705490140244, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 74, train_loss = 2.3798483387799934, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 75, train_loss = 2.3697956872638315, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 76, train_loss = 2.3662639400572516, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 77, train_loss = 2.3481737424153835, train_acc = 0.9939450395901258\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 78, train_loss = 2.3412637794972397, train_acc = 0.9939450395901258\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 79, train_loss = 2.3282864150824025, train_acc = 0.9939450395901258\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 80, train_loss = 2.3233468423131853, train_acc = 0.9939450395901258\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 81, train_loss = 2.3124461544211954, train_acc = 0.9940614811364695\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 82, train_loss = 2.2984372218488716, train_acc = 0.9939450395901258\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 83, train_loss = 2.294393265445251, train_acc = 0.9939450395901258\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 84, train_loss = 2.2902075068559498, train_acc = 0.9939450395901258\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 85, train_loss = 2.2727531583514065, train_acc = 0.9940614811364695\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 86, train_loss = 2.2747703632339835, train_acc = 0.9939450395901258\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 87, train_loss = 2.2550205911393277, train_acc = 0.9940614811364695\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 88, train_loss = 2.247992463351693, train_acc = 0.9940614811364695\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 89, train_loss = 2.245436239929404, train_acc = 0.9940614811364695\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 90, train_loss = 2.235556405677926, train_acc = 0.9940614811364695\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 91, train_loss = 2.230650795798283, train_acc = 0.9940614811364695\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 92, train_loss = 2.229777478671167, train_acc = 0.9940614811364695\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 93, train_loss = 2.215587400831282, train_acc = 0.9940614811364695\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 94, train_loss = 2.20905207330361, train_acc = 0.9940614811364695\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 95, train_loss = 2.199159662704915, train_acc = 0.9940614811364695\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 96, train_loss = 2.2021656415308826, train_acc = 0.9940614811364695\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 97, train_loss = 2.188160471327137, train_acc = 0.9939450395901258\n",
      "test Acc 0.9683426443202979:\n",
      "12th- epoch: 98, train_loss = 2.1874533309601247, train_acc = 0.9940614811364695\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 99, train_loss = 2.177851843473036, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 100, train_loss = 2.168278388970066, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 101, train_loss = 2.1724277486209758, train_acc = 0.9940614811364695\n",
      "test Acc 0.9688081936685289:\n",
      "12th- epoch: 102, train_loss = 2.1595455773058347, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 103, train_loss = 2.156728280533571, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 104, train_loss = 2.1491704429499805, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 105, train_loss = 2.140244184702169, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 106, train_loss = 2.1370560222421773, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 107, train_loss = 2.1344201376778074, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "12th- epoch: 108, train_loss = 2.1252888897433877, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 109, train_loss = 2.1186001340975054, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 110, train_loss = 2.118018982000649, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 111, train_loss = 2.1103689206647687, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 112, train_loss = 2.103883440606296, train_acc = 0.994294364229157\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 113, train_loss = 2.1049627703614533, train_acc = 0.994294364229157\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 114, train_loss = 2.0991090168245137, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 115, train_loss = 2.0973542488063686, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 116, train_loss = 2.0909066212479956, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 117, train_loss = 2.089016175828874, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 118, train_loss = 2.078267238859553, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 119, train_loss = 2.074709737673402, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 120, train_loss = 2.0747732001473196, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 121, train_loss = 2.0673320603673346, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 122, train_loss = 2.05807398352772, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 123, train_loss = 2.0582822575233877, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 124, train_loss = 2.060069780505728, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 125, train_loss = 2.0473240935243666, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 126, train_loss = 2.0521145000238903, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 127, train_loss = 2.042898484505713, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 128, train_loss = 2.0399168175645173, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 129, train_loss = 2.0369650743086822, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 130, train_loss = 2.0326325104688294, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 131, train_loss = 2.02854418521747, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 132, train_loss = 2.026394112210255, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 133, train_loss = 2.0207762075588107, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 134, train_loss = 2.0210474880295806, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 135, train_loss = 2.0158040248788893, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 136, train_loss = 2.013444528914988, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 137, train_loss = 2.012468575499952, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 138, train_loss = 2.004751853470225, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 139, train_loss = 2.005620296113193, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 140, train_loss = 2.0026079919189215, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 141, train_loss = 1.9926488397759385, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 142, train_loss = 1.9933156346087344, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "12th- epoch: 143, train_loss = 1.9892810013261624, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 144, train_loss = 1.9913126397877932, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 145, train_loss = 1.9850821322761476, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 146, train_loss = 1.9865514487028122, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 147, train_loss = 1.9816842676955275, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 148, train_loss = 1.978680057451129, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 149, train_loss = 1.9747538431547582, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 150, train_loss = 1.9678755452041514, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 151, train_loss = 1.9743098097969778, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 152, train_loss = 1.965329767204821, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 153, train_loss = 1.9630289521883242, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 154, train_loss = 1.9604338567587547, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 155, train_loss = 1.9581358125433326, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 156, train_loss = 1.9587612110190094, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 157, train_loss = 1.951918227772694, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 158, train_loss = 1.9518854919006117, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 159, train_loss = 1.9506739017670043, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 160, train_loss = 1.9449049726244994, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 161, train_loss = 1.9467253773473203, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 162, train_loss = 1.941212975711096, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 163, train_loss = 1.9475017245858908, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 164, train_loss = 1.9327511945739388, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 165, train_loss = 1.9434145417180844, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 166, train_loss = 1.9317734750802629, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 167, train_loss = 1.9322272048448212, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 168, train_loss = 1.9246292863972485, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 169, train_loss = 1.935469248041045, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "12th- epoch: 170, train_loss = 1.9194584310171194, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 171, train_loss = 1.9203689387068152, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 172, train_loss = 1.9299344699829817, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 173, train_loss = 1.9136012247763574, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 174, train_loss = 1.9190525095909834, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 175, train_loss = 1.9147253911942244, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 176, train_loss = 1.9060349186474923, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 177, train_loss = 1.912450719770277, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 178, train_loss = 1.9049824535322841, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "12th- epoch: 179, train_loss = 1.9101391238509677, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 180, train_loss = 1.9101603143790271, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 181, train_loss = 1.9013538788130973, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 182, train_loss = 1.908788865985116, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 183, train_loss = 1.894710392691195, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 184, train_loss = 1.8952245176769793, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 185, train_loss = 1.8970095227414276, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 186, train_loss = 1.895141317130765, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 187, train_loss = 1.888320188591024, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 188, train_loss = 1.893376808759058, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 189, train_loss = 1.8869587198423687, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 190, train_loss = 1.8878740064392332, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 191, train_loss = 1.8810680158494506, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 192, train_loss = 1.8886639868433122, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 193, train_loss = 1.8820266261755023, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 194, train_loss = 1.8767496345099062, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 195, train_loss = 1.8844996789412107, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 196, train_loss = 1.8744274546334054, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 197, train_loss = 1.876338633010164, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 198, train_loss = 1.8754734356480185, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 199, train_loss = 1.8764246394857764, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 200, train_loss = 1.8687737514264882, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 201, train_loss = 1.8691061694116797, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 202, train_loss = 1.863081677671289, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 203, train_loss = 1.8701426880434155, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 204, train_loss = 1.8617820170184132, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 205, train_loss = 1.8626606854086276, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 206, train_loss = 1.8598596838710364, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 207, train_loss = 1.861047732643783, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 208, train_loss = 1.85565724526532, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 209, train_loss = 1.858623287640512, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 210, train_loss = 1.852872264717007, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 211, train_loss = 1.8506431049609091, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 212, train_loss = 1.853011159459129, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 213, train_loss = 1.8543490321317222, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 214, train_loss = 1.8489021929854061, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 215, train_loss = 1.847134037554497, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 216, train_loss = 1.8490144382230937, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 217, train_loss = 1.8402586785668973, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 218, train_loss = 1.8448207477631513, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 219, train_loss = 1.8477752819599118, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 220, train_loss = 1.842701251473045, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 221, train_loss = 1.8351639072934631, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 222, train_loss = 1.8369978786504362, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 223, train_loss = 1.8407999346090946, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 224, train_loss = 1.8344741137698293, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 225, train_loss = 1.8368622898124158, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 226, train_loss = 1.833215345395729, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 227, train_loss = 1.8326560865680221, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 228, train_loss = 1.829712252918398, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 229, train_loss = 1.8277534754015505, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 230, train_loss = 1.824730893218657, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 231, train_loss = 1.8305370262824, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 232, train_loss = 1.823253599315649, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 233, train_loss = 1.8253692110592965, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 234, train_loss = 1.8253553270769771, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 235, train_loss = 1.8214882091560867, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 236, train_loss = 1.821217310760403, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 237, train_loss = 1.8223891624656972, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 238, train_loss = 1.818280529929325, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 239, train_loss = 1.8121966602338944, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 240, train_loss = 1.8149306161794811, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 241, train_loss = 1.8125366388412658, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 242, train_loss = 1.8086630379257258, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 243, train_loss = 1.8112196261063218, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 244, train_loss = 1.81006493899622, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 245, train_loss = 1.8119596934411675, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 246, train_loss = 1.812454876722768, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 247, train_loss = 1.8067986724490765, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 248, train_loss = 1.80882309935987, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 249, train_loss = 1.8075852830370422, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 250, train_loss = 1.8020934923551977, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 251, train_loss = 1.8071028845442925, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 252, train_loss = 1.8002618472091854, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 253, train_loss = 1.8003698176762555, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 254, train_loss = 1.8043195698410273, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 255, train_loss = 1.7961231379304081, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 256, train_loss = 1.8017271724529564, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 257, train_loss = 1.8006442177575082, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 258, train_loss = 1.7970464898680802, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 259, train_loss = 1.7978112894052174, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 260, train_loss = 1.7986384163668845, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 261, train_loss = 1.797357344388729, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 262, train_loss = 1.7903778115287423, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 263, train_loss = 1.7946043788979296, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 264, train_loss = 1.7911302796564996, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 265, train_loss = 1.7900188338535372, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 266, train_loss = 1.7925497372634709, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 267, train_loss = 1.7869696696288884, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 268, train_loss = 1.7944463955645915, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 269, train_loss = 1.7902297511172947, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 270, train_loss = 1.7857698522566352, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 271, train_loss = 1.785231742542237, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 272, train_loss = 1.7877759427356068, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 273, train_loss = 1.7849761634133756, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 274, train_loss = 1.7829988867451902, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 275, train_loss = 1.7874655981140677, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 276, train_loss = 1.778455841820687, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 277, train_loss = 1.782591933151707, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 278, train_loss = 1.7793787684349809, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 279, train_loss = 1.7810602535901126, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 280, train_loss = 1.776782200060552, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 281, train_loss = 1.77862008442753, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 282, train_loss = 1.7734306938946247, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 283, train_loss = 1.7756049589661416, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 284, train_loss = 1.773462499404559, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 285, train_loss = 1.7761591769231018, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 286, train_loss = 1.7739042244793382, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 287, train_loss = 1.7746932030713651, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 288, train_loss = 1.7729926039464772, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 289, train_loss = 1.7759429418074433, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 290, train_loss = 1.769377072021598, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 291, train_loss = 1.7709522099175956, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 292, train_loss = 1.7737826932279859, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 293, train_loss = 1.7699477474670857, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 294, train_loss = 1.7654783540347125, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 295, train_loss = 1.77121845446527, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 296, train_loss = 1.7682667019835208, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 297, train_loss = 1.7695728937105741, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 298, train_loss = 1.7644523036724422, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 299, train_loss = 1.766514779854333, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 300, train_loss = 1.7610420477576554, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 301, train_loss = 1.7663690078479704, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 302, train_loss = 1.7643406745919492, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 303, train_loss = 1.7605123774555977, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 304, train_loss = 1.7564468397758901, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 305, train_loss = 1.7587194632797036, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 306, train_loss = 1.7592751488555223, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 307, train_loss = 1.7608289367053658, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 308, train_loss = 1.7586867093050387, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 309, train_loss = 1.7542184095364064, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 310, train_loss = 1.7614953272568528, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 311, train_loss = 1.7560797607002314, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 312, train_loss = 1.7541132661572192, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 313, train_loss = 1.7572183989395853, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 314, train_loss = 1.7544400081969798, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 315, train_loss = 1.7540268846787512, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 316, train_loss = 1.7503480279410724, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 317, train_loss = 1.7474069179443177, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 318, train_loss = 1.7536276462487876, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 319, train_loss = 1.7487025153823197, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 320, train_loss = 1.7477682242169976, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 321, train_loss = 1.7503023276512977, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 322, train_loss = 1.7496357114578132, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 323, train_loss = 1.7469596527516842, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 324, train_loss = 1.7479978179035243, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 325, train_loss = 1.7482519058103207, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 326, train_loss = 1.7455498850904405, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 327, train_loss = 1.746936731506139, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 328, train_loss = 1.7417022103036288, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 329, train_loss = 1.741211675107479, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 330, train_loss = 1.7470415424031671, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 331, train_loss = 1.739278608612949, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 332, train_loss = 1.7394209648482502, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 333, train_loss = 1.742181895300746, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 334, train_loss = 1.7390704941935837, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 335, train_loss = 1.7425837888440583, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 336, train_loss = 1.73917327876552, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 337, train_loss = 1.7424967802071478, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 338, train_loss = 1.7362857805565, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 339, train_loss = 1.7358072901552077, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 340, train_loss = 1.741417085606372, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 341, train_loss = 1.7340090551879257, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 342, train_loss = 1.7385292185063008, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 343, train_loss = 1.7334956128615886, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 344, train_loss = 1.7353029090445489, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 345, train_loss = 1.7314762752503157, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 346, train_loss = 1.7347097034507897, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 347, train_loss = 1.731000631727511, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 348, train_loss = 1.7392291828000452, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 349, train_loss = 1.7324181344301905, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 350, train_loss = 1.733203484909609, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 351, train_loss = 1.72897796324105, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 352, train_loss = 1.7328134139534086, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 353, train_loss = 1.7273875860555563, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 354, train_loss = 1.7306953989900649, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 355, train_loss = 1.726811894448474, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 356, train_loss = 1.7287567303574178, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 357, train_loss = 1.728677194332704, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 358, train_loss = 1.7259547454304993, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 359, train_loss = 1.7276591780537274, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 360, train_loss = 1.7266710901167244, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 361, train_loss = 1.7233473504893482, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 362, train_loss = 1.7234845071507152, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 363, train_loss = 1.7258669211005326, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 364, train_loss = 1.726042091700947, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 365, train_loss = 1.7247288979997393, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 366, train_loss = 1.724582487338921, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 367, train_loss = 1.7262677511607762, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 368, train_loss = 1.722802586009493, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 369, train_loss = 1.723772461846238, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 370, train_loss = 1.719098307105014, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 371, train_loss = 1.7201723850739654, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 372, train_loss = 1.7205440704710782, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 373, train_loss = 1.7215507147775497, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 374, train_loss = 1.7193644905928522, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 375, train_loss = 1.7177596740366425, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 376, train_loss = 1.7249277671799064, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 377, train_loss = 1.7137508585583419, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 378, train_loss = 1.7198217473051045, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 379, train_loss = 1.716979860299034, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 380, train_loss = 1.7179986456176266, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 381, train_loss = 1.7129441818688065, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 382, train_loss = 1.7170271409268025, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 383, train_loss = 1.715671914309496, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 384, train_loss = 1.7173705899622291, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 385, train_loss = 1.7163810837082565, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 386, train_loss = 1.7149931844614912, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 387, train_loss = 1.7207937751954887, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 388, train_loss = 1.7079643382458016, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 389, train_loss = 1.714133071480319, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 390, train_loss = 1.7163639806967694, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 391, train_loss = 1.711579143855488, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 392, train_loss = 1.7138941011799034, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 393, train_loss = 1.7118511206936091, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 394, train_loss = 1.7143540117831435, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 395, train_loss = 1.7087459722242784, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 396, train_loss = 1.715283072029706, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 397, train_loss = 1.711815661226865, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 398, train_loss = 1.7123089162923861, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 399, train_loss = 1.7091905014531221, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 400, train_loss = 1.7085822818335146, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 401, train_loss = 1.7089107721403707, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 402, train_loss = 1.7104475199012086, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 403, train_loss = 1.7071174806333147, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 404, train_loss = 1.708463115413906, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 405, train_loss = 1.7060122959082946, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 406, train_loss = 1.7090592057502363, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 407, train_loss = 1.7009012155467644, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 408, train_loss = 1.7089054676471278, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 409, train_loss = 1.70434045617003, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 410, train_loss = 1.7041713175422046, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 411, train_loss = 1.7056747711903881, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 412, train_loss = 1.7047082627832424, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 413, train_loss = 1.7000838952953927, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 414, train_loss = 1.7070932999777142, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 415, train_loss = 1.7004709983739303, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 416, train_loss = 1.701633462245809, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 417, train_loss = 1.7002190310449805, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 418, train_loss = 1.7022398000553949, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 419, train_loss = 1.7008244247845141, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 420, train_loss = 1.7002622522268211, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 421, train_loss = 1.6997282704978716, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 422, train_loss = 1.696217741133296, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 423, train_loss = 1.7003093057865044, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 424, train_loss = 1.6948197655146942, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 425, train_loss = 1.7028200177010149, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 426, train_loss = 1.6934868406242458, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 427, train_loss = 1.6971623275312595, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 428, train_loss = 1.6938020261004567, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 429, train_loss = 1.6969219157035695, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 430, train_loss = 1.694494089417276, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 431, train_loss = 1.6985368119057966, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 432, train_loss = 1.6927233600290492, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 433, train_loss = 1.69441681005992, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 434, train_loss = 1.6933268170105293, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 435, train_loss = 1.6941238996369066, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 436, train_loss = 1.6931643372372491, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 437, train_loss = 1.6931217448582174, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 438, train_loss = 1.693155781365931, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 439, train_loss = 1.689562634404865, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 440, train_loss = 1.6984261996112764, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 441, train_loss = 1.6893433937075315, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 442, train_loss = 1.690644377071294, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 443, train_loss = 1.688452048925683, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 444, train_loss = 1.6914833189657656, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 445, train_loss = 1.6920608506334247, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 446, train_loss = 1.689487554365769, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 447, train_loss = 1.6941627226769924, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 448, train_loss = 1.6829593228176236, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 449, train_loss = 1.688285352429375, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 450, train_loss = 1.6882325410842896, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 451, train_loss = 1.689853386633331, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 452, train_loss = 1.6842177364305826, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 453, train_loss = 1.682951845228672, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 454, train_loss = 1.6884315983188571, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 455, train_loss = 1.689354718735558, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 456, train_loss = 1.6803519688546658, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 457, train_loss = 1.685742264307919, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 458, train_loss = 1.6847081339656143, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 459, train_loss = 1.6840325108059915, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 460, train_loss = 1.6825191642419668, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 461, train_loss = 1.6827092063613236, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 462, train_loss = 1.6798058104905067, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 463, train_loss = 1.6866038315201877, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 464, train_loss = 1.68372056602675, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 465, train_loss = 1.6776284703519195, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 466, train_loss = 1.6819496384559898, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 467, train_loss = 1.680285686001298, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 468, train_loss = 1.680647981193033, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 469, train_loss = 1.6809109467285452, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 470, train_loss = 1.6786110615357757, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 471, train_loss = 1.677687166724354, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 472, train_loss = 1.6790623080451041, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 473, train_loss = 1.6791966995224357, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 474, train_loss = 1.67565052700229, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 475, train_loss = 1.6806197306868853, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 476, train_loss = 1.6797040030360222, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 477, train_loss = 1.675979477193323, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 478, train_loss = 1.6753609403967857, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 479, train_loss = 1.6772472993470728, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 480, train_loss = 1.673102839544299, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 481, train_loss = 1.6764915372914402, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 482, train_loss = 1.6746281895320863, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 483, train_loss = 1.6751925447024405, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 484, train_loss = 1.674945630991715, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 485, train_loss = 1.6765455401764484, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 486, train_loss = 1.6765464292111574, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 487, train_loss = 1.6682182111107977, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 488, train_loss = 1.6719225233682664, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 489, train_loss = 1.6703229934646515, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 490, train_loss = 1.669875749546918, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 491, train_loss = 1.6710570962168276, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 492, train_loss = 1.6698585945850937, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 493, train_loss = 1.6696868999133585, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 494, train_loss = 1.6728421410807641, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 495, train_loss = 1.6667344964807853, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 496, train_loss = 1.6709276999608846, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 497, train_loss = 1.6709508479107171, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 498, train_loss = 1.6666279420460341, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 499, train_loss = 1.6640400320029585, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|██████████████████████████████▍                                             | 12/30 [1:52:37<2:58:18, 594.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "13th- epoch: 0, train_loss = 396.98022247850895, train_acc = 0.7973917093619003\n",
      "test Acc 0.8626629422718808:\n",
      "13th- epoch: 1, train_loss = 78.93908730149269, train_acc = 0.9113879832324173\n",
      "test Acc 0.904562383612663:\n",
      "13th- epoch: 2, train_loss = 52.40976497763768, train_acc = 0.9310666045645086\n",
      "test Acc 0.9138733705772812:\n",
      "13th- epoch: 3, train_loss = 38.93943322263658, train_acc = 0.945388914764788\n",
      "test Acc 0.9269087523277467:\n",
      "13th- epoch: 4, train_loss = 31.061842128634453, train_acc = 0.952026082906381\n",
      "test Acc 0.9404096834264432:\n",
      "13th- epoch: 5, train_loss = 25.955715034157038, train_acc = 0.9591290172333489\n",
      "test Acc 0.9464618249534451:\n",
      "13th- epoch: 6, train_loss = 21.874401297420263, train_acc = 0.9634373544480671\n",
      "test Acc 0.9445996275605214:\n",
      "13th- epoch: 7, train_loss = 18.682658572215587, train_acc = 0.966581276199348\n",
      "test Acc 0.9478584729981379:\n",
      "13th- epoch: 8, train_loss = 16.17730055656284, train_acc = 0.9711224965067536\n",
      "test Acc 0.9501862197392924:\n",
      "13th- epoch: 9, train_loss = 14.183765669818968, train_acc = 0.9726362366092222\n",
      "test Acc 0.9492551210428305:\n",
      "13th- epoch: 10, train_loss = 12.640502271708101, train_acc = 0.9749650675360969\n",
      "test Acc 0.9529795158286778:\n",
      "13th- epoch: 11, train_loss = 11.346851348876953, train_acc = 0.9775267815556591\n",
      "test Acc 0.9548417132216015:\n",
      "13th- epoch: 12, train_loss = 10.252218153327703, train_acc = 0.9796227293898463\n",
      "test Acc 0.9557728119180633:\n",
      "13th- epoch: 13, train_loss = 9.41975327488035, train_acc = 0.9817186772240335\n",
      "test Acc 0.9557728119180633:\n",
      "13th- epoch: 14, train_loss = 8.760742236860096, train_acc = 0.9835817419655333\n",
      "test Acc 0.957169459962756:\n",
      "13th- epoch: 15, train_loss = 8.205900982022285, train_acc = 0.9845132743362832\n",
      "test Acc 0.957635009310987:\n",
      "13th- epoch: 16, train_loss = 7.729764504358172, train_acc = 0.9860270144387517\n",
      "test Acc 0.9581005586592178:\n",
      "13th- epoch: 17, train_loss = 7.346440887078643, train_acc = 0.9864927806241267\n",
      "test Acc 0.9581005586592178:\n",
      "13th- epoch: 18, train_loss = 6.969884782098234, train_acc = 0.9874243129948765\n",
      "test Acc 0.9585661080074488:\n",
      "13th- epoch: 19, train_loss = 6.677641973365098, train_acc = 0.9878900791802515\n",
      "test Acc 0.9590316573556797:\n",
      "13th- epoch: 20, train_loss = 6.3678562846034765, train_acc = 0.9880065207265952\n",
      "test Acc 0.9590316573556797:\n",
      "13th- epoch: 21, train_loss = 6.1221024645492435, train_acc = 0.9881229622729389\n",
      "test Acc 0.9594972067039106:\n",
      "13th- epoch: 22, train_loss = 5.891929393867031, train_acc = 0.9882394038192828\n",
      "test Acc 0.9613594040968343:\n",
      "13th- epoch: 23, train_loss = 5.6703209762927145, train_acc = 0.9887051700046576\n",
      "test Acc 0.9613594040968343:\n",
      "13th- epoch: 24, train_loss = 5.477973517263308, train_acc = 0.9887051700046576\n",
      "test Acc 0.9608938547486033:\n",
      "13th- epoch: 25, train_loss = 5.29476520861499, train_acc = 0.9887051700046576\n",
      "test Acc 0.9618249534450651:\n",
      "13th- epoch: 26, train_loss = 5.123501470312476, train_acc = 0.9889380530973452\n",
      "test Acc 0.9604283054003724:\n",
      "13th- epoch: 27, train_loss = 4.965557319810614, train_acc = 0.9889380530973452\n",
      "test Acc 0.9608938547486033:\n",
      "13th- epoch: 28, train_loss = 4.816342891892418, train_acc = 0.98940381928272\n",
      "test Acc 0.9618249534450651:\n",
      "13th- epoch: 29, train_loss = 4.686099691782147, train_acc = 0.98940381928272\n",
      "test Acc 0.9618249534450651:\n",
      "13th- epoch: 30, train_loss = 4.542440244928002, train_acc = 0.9895202608290639\n",
      "test Acc 0.9608938547486033:\n",
      "13th- epoch: 31, train_loss = 4.421338917687535, train_acc = 0.9897531439217513\n",
      "test Acc 0.9613594040968343:\n",
      "13th- epoch: 32, train_loss = 4.291958909947425, train_acc = 0.9899860270144387\n",
      "test Acc 0.9622905027932961:\n",
      "13th- epoch: 33, train_loss = 4.186800572089851, train_acc = 0.9901024685607824\n",
      "test Acc 0.9622905027932961:\n",
      "13th- epoch: 34, train_loss = 4.077296388568357, train_acc = 0.9902189101071263\n",
      "test Acc 0.9613594040968343:\n",
      "13th- epoch: 35, train_loss = 3.9832481695339084, train_acc = 0.99033535165347\n",
      "test Acc 0.9618249534450651:\n",
      "13th- epoch: 36, train_loss = 3.8780862274579704, train_acc = 0.9909175593851887\n",
      "test Acc 0.9618249534450651:\n",
      "13th- epoch: 37, train_loss = 3.797691826010123, train_acc = 0.9911504424778761\n",
      "test Acc 0.9618249534450651:\n",
      "13th- epoch: 38, train_loss = 3.708022302715108, train_acc = 0.9912668840242198\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 39, train_loss = 3.6257325429469347, train_acc = 0.9916162086632511\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 40, train_loss = 3.5564619270153344, train_acc = 0.9917326502095948\n",
      "test Acc 0.9622905027932961:\n",
      "13th- epoch: 41, train_loss = 3.4932865088339895, train_acc = 0.9919655333022822\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 42, train_loss = 3.427644368959591, train_acc = 0.992081974848626\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 43, train_loss = 3.3696230883942917, train_acc = 0.9919655333022822\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 44, train_loss = 3.304670274956152, train_acc = 0.9923148579413135\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 45, train_loss = 3.2475622567581013, train_acc = 0.9923148579413135\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 46, train_loss = 3.2072100995574147, train_acc = 0.992081974848626\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 47, train_loss = 3.1552613438107073, train_acc = 0.9923148579413135\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 48, train_loss = 3.1092084124684334, train_acc = 0.9926641825803446\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 49, train_loss = 3.0726629085838795, train_acc = 0.9925477410340009\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 50, train_loss = 3.022880499600433, train_acc = 0.9926641825803446\n",
      "test Acc 0.9632216014897579:\n",
      "13th- epoch: 51, train_loss = 2.989577297703363, train_acc = 0.9925477410340009\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 52, train_loss = 2.9526866372907534, train_acc = 0.9925477410340009\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 53, train_loss = 2.9034755459288135, train_acc = 0.9926641825803446\n",
      "test Acc 0.9646182495344506:\n",
      "13th- epoch: 54, train_loss = 2.8756482281023636, train_acc = 0.9926641825803446\n",
      "test Acc 0.9641527001862198:\n",
      "13th- epoch: 55, train_loss = 2.847783146542497, train_acc = 0.9926641825803446\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 56, train_loss = 2.8211360295535997, train_acc = 0.9925477410340009\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 57, train_loss = 2.7874427180504426, train_acc = 0.9926641825803446\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 58, train_loss = 2.7641663713147864, train_acc = 0.9927806241266884\n",
      "test Acc 0.9655493482309124:\n",
      "13th- epoch: 59, train_loss = 2.7391092226607725, train_acc = 0.9930135072193759\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 60, train_loss = 2.715168545837514, train_acc = 0.9931299487657196\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 61, train_loss = 2.6987364621600136, train_acc = 0.9928970656730322\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 62, train_loss = 2.6727792201563716, train_acc = 0.9931299487657196\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 63, train_loss = 2.6441829664399847, train_acc = 0.9930135072193759\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 64, train_loss = 2.6313343084184453, train_acc = 0.9930135072193759\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 65, train_loss = 2.610140817356296, train_acc = 0.9930135072193759\n",
      "test Acc 0.9664804469273743:\n",
      "13th- epoch: 66, train_loss = 2.589625520282425, train_acc = 0.9931299487657196\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 67, train_loss = 2.566560411709361, train_acc = 0.9933628318584071\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 68, train_loss = 2.538181811920367, train_acc = 0.9933628318584071\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 69, train_loss = 2.5264059683540836, train_acc = 0.9934792734047508\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 70, train_loss = 2.514109961572103, train_acc = 0.9934792734047508\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 71, train_loss = 2.501741581596434, train_acc = 0.9934792734047508\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 72, train_loss = 2.475443336297758, train_acc = 0.9935957149510946\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 73, train_loss = 2.473407208919525, train_acc = 0.9937121564974383\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 74, train_loss = 2.4509972153464332, train_acc = 0.9937121564974383\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 75, train_loss = 2.4474351489916444, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 76, train_loss = 2.43434755934868, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 77, train_loss = 2.4122156569501385, train_acc = 0.9937121564974383\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 78, train_loss = 2.406676499522291, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 79, train_loss = 2.3884953130036592, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 80, train_loss = 2.385767761967145, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 81, train_loss = 2.368431751965545, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 82, train_loss = 2.3571413410827518, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 83, train_loss = 2.3578418819233775, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 84, train_loss = 2.344146287709009, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 85, train_loss = 2.3325581001117826, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 86, train_loss = 2.32352602732135, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 87, train_loss = 2.308768028393388, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 88, train_loss = 2.3040679516270757, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 89, train_loss = 2.2924129010061733, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 90, train_loss = 2.294586755509954, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 91, train_loss = 2.2793453726917505, train_acc = 0.993828598043782\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 92, train_loss = 2.2739405231550336, train_acc = 0.9940614811364695\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 93, train_loss = 2.264119231782388, train_acc = 0.9941779226828132\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 94, train_loss = 2.2659100948949344, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 95, train_loss = 2.249109037395101, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 96, train_loss = 2.241979739628732, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 97, train_loss = 2.234302228607703, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 98, train_loss = 2.236917528323829, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 99, train_loss = 2.2218098237062804, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 100, train_loss = 2.216800427995622, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 101, train_loss = 2.2078826634096913, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 102, train_loss = 2.2122197679127567, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 103, train_loss = 2.1920161710004322, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 104, train_loss = 2.1967602779041044, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 105, train_loss = 2.179149061907083, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 106, train_loss = 2.1830103835090995, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 107, train_loss = 2.1665444686077535, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 108, train_loss = 2.1726051458972506, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 109, train_loss = 2.1691149997641332, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 110, train_loss = 2.1578871204401366, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "13th- epoch: 111, train_loss = 2.1612177584320307, train_acc = 0.9941779226828132\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 112, train_loss = 2.147807718254626, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 113, train_loss = 2.14814018009929, train_acc = 0.9941779226828132\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 114, train_loss = 2.143025967583526, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 115, train_loss = 2.1343679215642624, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 116, train_loss = 2.135067599650938, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 117, train_loss = 2.123569116636645, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 118, train_loss = 2.131119163997937, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 119, train_loss = 2.116674805234652, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 120, train_loss = 2.1196210793568753, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 121, train_loss = 2.119260143779684, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 122, train_loss = 2.1181942296097986, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 123, train_loss = 2.1062546555767767, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 124, train_loss = 2.1100503533962183, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 125, train_loss = 2.1065907619777136, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 126, train_loss = 2.09477822156623, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 127, train_loss = 2.0935081280767918, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 128, train_loss = 2.0992350800079294, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 129, train_loss = 2.086719561368227, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 130, train_loss = 2.079243876505643, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 131, train_loss = 2.0786777159082703, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 132, train_loss = 2.0789575914968736, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 133, train_loss = 2.0699433321133256, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 134, train_loss = 2.0668443972826935, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 135, train_loss = 2.061994044750463, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 136, train_loss = 2.062446313269902, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 137, train_loss = 2.0523765048128553, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 138, train_loss = 2.0499865601886995, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 139, train_loss = 2.04898463684367, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 140, train_loss = 2.04700125096133, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 141, train_loss = 2.033807603933383, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 142, train_loss = 2.037284965394065, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 143, train_loss = 2.0401410264894366, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 144, train_loss = 2.0363293974660337, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 145, train_loss = 2.0338137351791374, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 146, train_loss = 2.025977901823353, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 147, train_loss = 2.029867860779632, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 148, train_loss = 2.0311358824255876, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 149, train_loss = 2.0235018830862828, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 150, train_loss = 2.0153040271252394, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 151, train_loss = 2.014966171089327, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 152, train_loss = 2.0099538891226985, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 153, train_loss = 2.0146696477604564, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 154, train_loss = 2.007033542264253, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 155, train_loss = 2.0055702375248075, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 156, train_loss = 2.0038898155034985, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 157, train_loss = 2.001803989522159, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 158, train_loss = 1.9992493636382278, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 159, train_loss = 1.9908791673369706, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 160, train_loss = 1.9914483317988925, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 161, train_loss = 1.9971346755046397, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 162, train_loss = 1.9880736214690842, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 163, train_loss = 1.9856373704969883, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 164, train_loss = 1.9797525873000268, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 165, train_loss = 1.97934288912802, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 166, train_loss = 1.9809508904872928, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 167, train_loss = 1.9798557700996753, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 168, train_loss = 1.9732098403328564, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 169, train_loss = 1.9712149886472616, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 170, train_loss = 1.9720982782600913, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 171, train_loss = 1.9684102268947754, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 172, train_loss = 1.970911695389077, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 173, train_loss = 1.9651061000768095, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 174, train_loss = 1.9608951768314, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 175, train_loss = 1.9588624783791602, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 176, train_loss = 1.9568130034895148, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 177, train_loss = 1.959962548542535, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 178, train_loss = 1.9544755302777048, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 179, train_loss = 1.9541509448026773, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 180, train_loss = 1.9509924965968821, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 181, train_loss = 1.9507736570667475, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 182, train_loss = 1.947847325267503, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 183, train_loss = 1.9449575885664672, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 184, train_loss = 1.9451370083261281, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 185, train_loss = 1.9408124165202025, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 186, train_loss = 1.9371674295107368, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 187, train_loss = 1.9390353358758148, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 188, train_loss = 1.9429137699771672, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 189, train_loss = 1.929264555539703, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 190, train_loss = 1.9314718960376922, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 191, train_loss = 1.9335303680563811, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 192, train_loss = 1.9320904957130551, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 193, train_loss = 1.9286024853645358, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 194, train_loss = 1.9287751074007247, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 195, train_loss = 1.9307666498643812, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 196, train_loss = 1.934143767139176, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 197, train_loss = 1.926467558281729, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 198, train_loss = 1.921178121730918, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 199, train_loss = 1.9238270767964423, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 200, train_loss = 1.9188359566032887, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 201, train_loss = 1.9147960248810705, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 202, train_loss = 1.9160125201160554, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 203, train_loss = 1.9184956806711853, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 204, train_loss = 1.9095960514678154, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 205, train_loss = 1.9089606853667647, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 206, train_loss = 1.901694364612922, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 207, train_loss = 1.9097235997614916, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 208, train_loss = 1.912121102301171, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "13th- epoch: 209, train_loss = 1.9045465300732758, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 210, train_loss = 1.911352343391627, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 211, train_loss = 1.9083816419297364, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 212, train_loss = 1.910750838695094, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 213, train_loss = 1.8954554622469004, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 214, train_loss = 1.9012705195636954, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 215, train_loss = 1.9022908392362297, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 216, train_loss = 1.9024344555509742, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 217, train_loss = 1.9003028525912669, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 218, train_loss = 1.8965966342948377, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 219, train_loss = 1.8986587948456872, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 220, train_loss = 1.893549078144133, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 221, train_loss = 1.895035075955093, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 222, train_loss = 1.8894861807057168, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 223, train_loss = 1.8949345003638882, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 224, train_loss = 1.9007877310796175, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 225, train_loss = 1.88604208198376, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 226, train_loss = 1.8963112249039114, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 227, train_loss = 1.9001489932416007, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 228, train_loss = 1.8914902090618853, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 229, train_loss = 1.8966642376035452, train_acc = 0.9949930135072194\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 230, train_loss = 1.8825534415227594, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 231, train_loss = 1.880966924058157, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 232, train_loss = 1.8811538850422949, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 233, train_loss = 1.8738544628722593, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 234, train_loss = 1.8794070870353607, train_acc = 0.9949930135072194\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 235, train_loss = 1.8828847225231584, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 236, train_loss = 1.8785919181100326, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 237, train_loss = 1.8716091278474778, train_acc = 0.9949930135072194\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 238, train_loss = 1.8789696071762592, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 239, train_loss = 1.891312644816935, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 240, train_loss = 1.8811664279346587, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 241, train_loss = 1.8668974309694022, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 242, train_loss = 1.8689644653641153, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 243, train_loss = 1.8799721864925232, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 244, train_loss = 1.8789573937829118, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 245, train_loss = 1.8771176320296945, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 246, train_loss = 1.8651640579337254, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 247, train_loss = 1.8628933662112104, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 248, train_loss = 1.8696053565072361, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 249, train_loss = 1.8766239344404312, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 250, train_loss = 1.8726731466595083, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "13th- epoch: 251, train_loss = 1.8698012593667954, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 252, train_loss = 1.8572296584025025, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 253, train_loss = 1.8593198715243489, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 254, train_loss = 1.8621747985016555, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 255, train_loss = 1.8593666758824838, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 256, train_loss = 1.8570231498451903, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 257, train_loss = 1.8558882185461698, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 258, train_loss = 1.858304473294993, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 259, train_loss = 1.8551561263593612, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 260, train_loss = 1.8534326421795413, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 261, train_loss = 1.8535370474419324, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 262, train_loss = 1.852905506035313, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 263, train_loss = 1.8507753646263154, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 264, train_loss = 1.8497673007659614, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 265, train_loss = 1.853018680747482, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 266, train_loss = 1.8485297407023609, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 267, train_loss = 1.8488372947758762, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 268, train_loss = 1.8446592274849536, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 269, train_loss = 1.8429324577300576, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 270, train_loss = 1.850309407498571, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 271, train_loss = 1.839047590692644, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 272, train_loss = 1.8366320693603484, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 273, train_loss = 1.8400898426043568, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 274, train_loss = 1.8362987443542806, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 275, train_loss = 1.8362890784192132, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 276, train_loss = 1.8335371604916872, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 277, train_loss = 1.8376534368580906, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 278, train_loss = 1.849682028099778, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 279, train_loss = 1.8368647736497223, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 280, train_loss = 1.8382099337177351, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 281, train_loss = 1.8403585013002157, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 282, train_loss = 1.8354043867002474, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 283, train_loss = 1.833713525251369, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 284, train_loss = 1.8354822871478973, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 285, train_loss = 1.8316209620825248, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 286, train_loss = 1.8346468783420278, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 287, train_loss = 1.842602867356618, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 288, train_loss = 1.829341780859977, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 289, train_loss = 1.8330412089126185, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 290, train_loss = 1.8334788134525297, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 291, train_loss = 1.8329014354385436, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 292, train_loss = 1.8273692637885688, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 293, train_loss = 1.8300396930862917, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 294, train_loss = 1.8278756606887328, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 295, train_loss = 1.8201274227612885, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 296, train_loss = 1.8204872321075527, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 297, train_loss = 1.8250519987923326, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 298, train_loss = 1.8239405957283452, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 299, train_loss = 1.8335128766048001, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 300, train_loss = 1.8307747025537537, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 301, train_loss = 1.8199699261022033, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 302, train_loss = 1.815261962285149, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 303, train_loss = 1.8196226590516744, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 304, train_loss = 1.8281815743539482, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 305, train_loss = 1.8343064604123356, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 306, train_loss = 1.8254008953954326, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 307, train_loss = 1.8290817624219926, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 308, train_loss = 1.8185131876234664, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 309, train_loss = 1.8300773740484146, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 310, train_loss = 1.814384323428385, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 311, train_loss = 1.8151495238562347, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 312, train_loss = 1.8160681996960193, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 313, train_loss = 1.8155970516818343, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 314, train_loss = 1.8178570062154904, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 315, train_loss = 1.8143511459929869, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 316, train_loss = 1.8177378675463842, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 317, train_loss = 1.8179074412910268, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 318, train_loss = 1.81976875429973, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 319, train_loss = 1.8186992542614462, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 320, train_loss = 1.8182281944173155, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 321, train_loss = 1.815753986753407, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 322, train_loss = 1.8109486491885036, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 323, train_loss = 1.810613813533564, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 324, train_loss = 1.8152135849231854, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 325, train_loss = 1.8063690049311845, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 326, train_loss = 1.8006346904003294, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 327, train_loss = 1.8004484825505642, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 328, train_loss = 1.8021816483669681, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 329, train_loss = 1.802936825013603, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 330, train_loss = 1.8072401668614475, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 331, train_loss = 1.8026130825310247, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 332, train_loss = 1.8080341271852376, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 333, train_loss = 1.8153637031355174, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 334, train_loss = 1.8070855395199033, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 335, train_loss = 1.8020228002715157, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 336, train_loss = 1.8047732912673382, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 337, train_loss = 1.8021171915606828, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 338, train_loss = 1.7997645406721858, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 339, train_loss = 1.7912484573171241, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 340, train_loss = 1.7965496760589303, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 341, train_loss = 1.7963321690185694, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 342, train_loss = 1.7979663057922153, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 343, train_loss = 1.7967083877883852, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 344, train_loss = 1.7981980782205937, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 345, train_loss = 1.7947297496721148, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 346, train_loss = 1.7949877723585814, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 347, train_loss = 1.7952595871611265, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 348, train_loss = 1.7980659695604118, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 349, train_loss = 1.7957413756957976, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 350, train_loss = 1.789581394288689, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 351, train_loss = 1.7878281124139903, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 352, train_loss = 1.7938452430535108, train_acc = 0.9949930135072194\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 353, train_loss = 1.7920889062079368, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 354, train_loss = 1.7917123369406909, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 355, train_loss = 1.7885832728352398, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 356, train_loss = 1.793474777994561, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 357, train_loss = 1.7896745350008132, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 358, train_loss = 1.791065590150538, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 359, train_loss = 1.788464109718916, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 360, train_loss = 1.7825899065210251, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 361, train_loss = 1.7848085980658652, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 362, train_loss = 1.7875188734251424, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 363, train_loss = 1.7838750890659867, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 364, train_loss = 1.7867890477646142, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 365, train_loss = 1.7839642095641466, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 366, train_loss = 1.7872333805280505, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 367, train_loss = 1.7866026017145487, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 368, train_loss = 1.7785069224555627, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 369, train_loss = 1.7859108041375293, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 370, train_loss = 1.7874505748040974, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 371, train_loss = 1.7741064884830848, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 372, train_loss = 1.7760939128565951, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 373, train_loss = 1.776067403377965, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 374, train_loss = 1.7797447151242523, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 375, train_loss = 1.7776307482999982, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 376, train_loss = 1.7776105070952326, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 377, train_loss = 1.7797826568858, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 378, train_loss = 1.7787663503549993, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 379, train_loss = 1.773411045629473, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 380, train_loss = 1.7805033756085322, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "13th- epoch: 381, train_loss = 1.7879226010627463, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 382, train_loss = 1.7703018303363933, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 383, train_loss = 1.7729312698356807, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 384, train_loss = 1.7703307432457223, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 385, train_loss = 1.7732361115849926, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 386, train_loss = 1.767733259279339, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 387, train_loss = 1.7719912977554486, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 388, train_loss = 1.7730816430412233, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 389, train_loss = 1.772585307713598, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 390, train_loss = 1.7719902360477136, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 391, train_loss = 1.7690921281464398, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 392, train_loss = 1.7685121151953354, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 393, train_loss = 1.7659400552511215, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 394, train_loss = 1.7629488006568863, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 395, train_loss = 1.7618252400643541, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 396, train_loss = 1.7609812288210378, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 397, train_loss = 1.7642790356985643, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 398, train_loss = 1.766350928846805, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 399, train_loss = 1.7640224555507302, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 400, train_loss = 1.76449162280187, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 401, train_loss = 1.7715643880292191, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 402, train_loss = 1.7641379730775952, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 403, train_loss = 1.7603649285956635, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 404, train_loss = 1.758596037980169, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 405, train_loss = 1.7559069502167404, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 406, train_loss = 1.761546197347343, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 407, train_loss = 1.7577223260886967, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 408, train_loss = 1.7609802771694376, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 409, train_loss = 1.7598832726143883, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 410, train_loss = 1.758359534353076, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 411, train_loss = 1.7571693469435559, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 412, train_loss = 1.7560518196187331, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 413, train_loss = 1.7514014995322214, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 414, train_loss = 1.7530278785488917, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 415, train_loss = 1.7554832468740642, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 416, train_loss = 1.7565389536321163, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 417, train_loss = 1.759896055176796, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 418, train_loss = 1.7576941642910242, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 419, train_loss = 1.751726294402033, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 420, train_loss = 1.7523605364040122, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 421, train_loss = 1.7526290978639736, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 422, train_loss = 1.748128503873886, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 423, train_loss = 1.7493880370966508, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 424, train_loss = 1.752301018066646, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 425, train_loss = 1.7522332797161653, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 426, train_loss = 1.754664743784815, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 427, train_loss = 1.7569957872256055, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 428, train_loss = 1.748919732090144, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 429, train_loss = 1.7484815861098468, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 430, train_loss = 1.7453467740342603, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 431, train_loss = 1.7459310083650053, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 432, train_loss = 1.7554444537163363, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 433, train_loss = 1.764550260581018, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 434, train_loss = 1.7478680525309755, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 435, train_loss = 1.7474937747829244, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 436, train_loss = 1.7479939359836862, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 437, train_loss = 1.7525137976408587, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 438, train_loss = 1.7432671060450957, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 439, train_loss = 1.7434535034335568, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 440, train_loss = 1.743504809528531, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 441, train_loss = 1.739929425995797, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 442, train_loss = 1.7432186021469533, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 443, train_loss = 1.7412173454649746, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 444, train_loss = 1.745155907701701, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 445, train_loss = 1.7464402608238743, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 446, train_loss = 1.750129446387291, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 447, train_loss = 1.7403048697524355, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 448, train_loss = 1.738563148152025, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 449, train_loss = 1.737798469759582, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 450, train_loss = 1.7381400656886399, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 451, train_loss = 1.741307104472071, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 452, train_loss = 1.7413097840399132, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 453, train_loss = 1.7461708515547798, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 454, train_loss = 1.7492858953773975, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 455, train_loss = 1.7392807784490287, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 456, train_loss = 1.7400022731162608, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 457, train_loss = 1.7361184617839172, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 458, train_loss = 1.7301887475550757, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 459, train_loss = 1.7323020895346417, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 460, train_loss = 1.7376546931118355, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 461, train_loss = 1.7346824418418691, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 462, train_loss = 1.736923458367528, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 463, train_loss = 1.73492712512234, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 464, train_loss = 1.7285747430287302, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 465, train_loss = 1.7305386631414876, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 466, train_loss = 1.7324102840721025, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 467, train_loss = 1.7340743675231352, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 468, train_loss = 1.7335608288049116, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 469, train_loss = 1.731254490558058, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 470, train_loss = 1.7291997307911515, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 471, train_loss = 1.7258115289732814, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 472, train_loss = 1.7307244037874625, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 473, train_loss = 1.7262981549502001, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 474, train_loss = 1.727558176346065, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 475, train_loss = 1.730845351703465, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 476, train_loss = 1.7325695847757743, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 477, train_loss = 1.7262700235805823, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 478, train_loss = 1.7230967342256918, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 479, train_loss = 1.723455538507551, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 480, train_loss = 1.720884209498763, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 481, train_loss = 1.7269620290026069, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 482, train_loss = 1.724280558526516, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 483, train_loss = 1.725246884241642, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 484, train_loss = 1.7250768927260651, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 485, train_loss = 1.727155261360167, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 486, train_loss = 1.7257243352942169, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 487, train_loss = 1.7308713883758173, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 488, train_loss = 1.7220943688080297, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 489, train_loss = 1.7210783356204047, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 490, train_loss = 1.7236176105216146, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 491, train_loss = 1.7249484198764549, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 492, train_loss = 1.7189691523090005, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 493, train_loss = 1.7197748118414893, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 494, train_loss = 1.720580871529819, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 495, train_loss = 1.7143334945067181, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 496, train_loss = 1.717539225704968, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 497, train_loss = 1.7203504610806704, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 498, train_loss = 1.7208730724305497, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "13th- epoch: 499, train_loss = 1.7164156272410764, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████████████████████████████████▉                                           | 13/30 [2:02:58<2:50:42, 602.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "14th- epoch: 0, train_loss = 373.28292374685407, train_acc = 0.8015836050302748\n",
      "test Acc 0.7905027932960894:\n",
      "14th- epoch: 1, train_loss = 75.65140021685511, train_acc = 0.9142990218910108\n",
      "test Acc 0.9264432029795159:\n",
      "14th- epoch: 2, train_loss = 50.515117327682674, train_acc = 0.9346762925011645\n",
      "test Acc 0.9324953445065177:\n",
      "14th- epoch: 3, train_loss = 36.5691382298246, train_acc = 0.9484163949697252\n",
      "test Acc 0.9436685288640596:\n",
      "14th- epoch: 4, train_loss = 28.669240267947316, train_acc = 0.9573823940381928\n",
      "test Acc 0.9497206703910615:\n",
      "14th- epoch: 5, train_loss = 23.519526038318872, train_acc = 0.9632044713553796\n",
      "test Acc 0.952513966480447:\n",
      "14th- epoch: 6, train_loss = 19.863405941054225, train_acc = 0.9666977177456917\n",
      "test Acc 0.9543761638733705:\n",
      "14th- epoch: 7, train_loss = 17.125474816188216, train_acc = 0.9703074056823474\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 8, train_loss = 15.013463389128447, train_acc = 0.971821145784816\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 9, train_loss = 13.254899524152279, train_acc = 0.9748486259897532\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 10, train_loss = 11.91134992055595, train_acc = 0.9769445738239404\n",
      "test Acc 0.957169459962756:\n",
      "14th- epoch: 11, train_loss = 10.873120272532105, train_acc = 0.9786911970190965\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 12, train_loss = 9.956428376957774, train_acc = 0.9795062878435026\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 13, train_loss = 9.144740303047001, train_acc = 0.98067070330694\n",
      "test Acc 0.9581005586592178:\n",
      "14th- epoch: 14, train_loss = 8.42225457727909, train_acc = 0.981951560316721\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 15, train_loss = 7.830810700543225, train_acc = 0.9832324173265021\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 16, train_loss = 7.356031395494938, train_acc = 0.984163949697252\n",
      "test Acc 0.9594972067039106:\n",
      "14th- epoch: 17, train_loss = 6.927849643863738, train_acc = 0.9853283651606893\n",
      "test Acc 0.9608938547486033:\n",
      "14th- epoch: 18, train_loss = 6.55181113537401, train_acc = 0.985910572892408\n",
      "test Acc 0.962756052141527:\n",
      "14th- epoch: 19, train_loss = 6.221933990716934, train_acc = 0.9867256637168141\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 20, train_loss = 5.960010050795972, train_acc = 0.9871914299021891\n",
      "test Acc 0.9641527001862198:\n",
      "14th- epoch: 21, train_loss = 5.7088377214968204, train_acc = 0.9881229622729389\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 22, train_loss = 5.476949293166399, train_acc = 0.9885887284583139\n",
      "test Acc 0.9646182495344506:\n",
      "14th- epoch: 23, train_loss = 5.266761018894613, train_acc = 0.9890544946436889\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 24, train_loss = 5.079671584069729, train_acc = 0.9892873777363763\n",
      "test Acc 0.9660148975791434:\n",
      "14th- epoch: 25, train_loss = 4.906914166174829, train_acc = 0.9891709361900326\n",
      "test Acc 0.9655493482309124:\n",
      "14th- epoch: 26, train_loss = 4.746128651313484, train_acc = 0.9897531439217513\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 27, train_loss = 4.607676436193287, train_acc = 0.9901024685607824\n",
      "test Acc 0.9669459962756052:\n",
      "14th- epoch: 28, train_loss = 4.483678021468222, train_acc = 0.99033535165347\n",
      "test Acc 0.9664804469273743:\n",
      "14th- epoch: 29, train_loss = 4.388289177790284, train_acc = 0.9905682347461574\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 30, train_loss = 4.251378620043397, train_acc = 0.9904517931998137\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 31, train_loss = 4.13352867634967, train_acc = 0.9909175593851887\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 32, train_loss = 4.032880082260817, train_acc = 0.9910340009315324\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 33, train_loss = 3.9462277120910585, train_acc = 0.9910340009315324\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 34, train_loss = 3.8646951257251203, train_acc = 0.9912668840242198\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 35, train_loss = 3.7944826832972467, train_acc = 0.9917326502095948\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 36, train_loss = 3.6971524064429104, train_acc = 0.9917326502095948\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 37, train_loss = 3.623955570627004, train_acc = 0.9917326502095948\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 38, train_loss = 3.580143614206463, train_acc = 0.992081974848626\n",
      "test Acc 0.9678770949720671:\n",
      "14th- epoch: 39, train_loss = 3.524204517249018, train_acc = 0.9919655333022822\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 40, train_loss = 3.4746426506899297, train_acc = 0.9923148579413135\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 41, train_loss = 3.418978397734463, train_acc = 0.9921984163949698\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 42, train_loss = 3.394597398582846, train_acc = 0.992081974848626\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 43, train_loss = 3.352180020418018, train_acc = 0.9921984163949698\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 44, train_loss = 3.2773195607587695, train_acc = 0.9925477410340009\n",
      "test Acc 0.9688081936685289:\n",
      "14th- epoch: 45, train_loss = 3.2185721858404577, train_acc = 0.9923148579413135\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 46, train_loss = 3.187812556978315, train_acc = 0.9924312994876572\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 47, train_loss = 3.1566040851175785, train_acc = 0.9924312994876572\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 48, train_loss = 3.131081197876483, train_acc = 0.9926641825803446\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 49, train_loss = 3.085577383870259, train_acc = 0.9926641825803446\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 50, train_loss = 3.0453909875359386, train_acc = 0.9925477410340009\n",
      "test Acc 0.9692737430167597:\n",
      "14th- epoch: 51, train_loss = 3.0269543593749404, train_acc = 0.9926641825803446\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 52, train_loss = 2.9984302625525743, train_acc = 0.9926641825803446\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 53, train_loss = 2.9455925195943564, train_acc = 0.9927806241266884\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 54, train_loss = 2.9346035819035023, train_acc = 0.9928970656730322\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 55, train_loss = 2.9097880623303354, train_acc = 0.9931299487657196\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 56, train_loss = 2.8810680280439556, train_acc = 0.9931299487657196\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 57, train_loss = 2.874680223176256, train_acc = 0.9931299487657196\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 58, train_loss = 2.8395333096850663, train_acc = 0.9930135072193759\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 59, train_loss = 2.8091457958798856, train_acc = 0.9932463903120633\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 60, train_loss = 2.772773150820285, train_acc = 0.9933628318584071\n",
      "test Acc 0.9702048417132216:\n",
      "14th- epoch: 61, train_loss = 2.767939413082786, train_acc = 0.9934792734047508\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 62, train_loss = 2.7603865284472704, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 63, train_loss = 2.7361945423763245, train_acc = 0.9932463903120633\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 64, train_loss = 2.704828599235043, train_acc = 0.9935957149510946\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 65, train_loss = 2.6860527948010713, train_acc = 0.9935957149510946\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 66, train_loss = 2.6973562460625544, train_acc = 0.9935957149510946\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 67, train_loss = 2.656620852765627, train_acc = 0.993828598043782\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 68, train_loss = 2.640956800431013, train_acc = 0.9937121564974383\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 69, train_loss = 2.6368836307665333, train_acc = 0.9940614811364695\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 70, train_loss = 2.601258622831665, train_acc = 0.9940614811364695\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 71, train_loss = 2.5891314913751557, train_acc = 0.9940614811364695\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 72, train_loss = 2.5739419198362157, train_acc = 0.9939450395901258\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 73, train_loss = 2.5529737526085228, train_acc = 0.9941779226828132\n",
      "test Acc 0.9711359404096834:\n",
      "14th- epoch: 74, train_loss = 2.54417987447232, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 75, train_loss = 2.5354317212477326, train_acc = 0.9940614811364695\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 76, train_loss = 2.5202488454524428, train_acc = 0.9941779226828132\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 77, train_loss = 2.5190669847652316, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 78, train_loss = 2.4883026177994907, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 79, train_loss = 2.4821062374394387, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 80, train_loss = 2.468635077821091, train_acc = 0.9940614811364695\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 81, train_loss = 2.442518482217565, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 82, train_loss = 2.448478950886056, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 83, train_loss = 2.425295157590881, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 84, train_loss = 2.4197442845907062, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 85, train_loss = 2.4077582804020494, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "14th- epoch: 86, train_loss = 2.39651546231471, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 87, train_loss = 2.393852633656934, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 88, train_loss = 2.381105007836595, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 89, train_loss = 2.3699306942289695, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 90, train_loss = 2.369517479557544, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 91, train_loss = 2.347899135784246, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 92, train_loss = 2.3633108377689496, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 93, train_loss = 2.323959242552519, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 94, train_loss = 2.3308720499044284, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 95, train_loss = 2.310187994153239, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 96, train_loss = 2.3238976622233167, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 97, train_loss = 2.292103675659746, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 98, train_loss = 2.314598409458995, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 99, train_loss = 2.2961121663684025, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 100, train_loss = 2.2639645918970928, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 101, train_loss = 2.2954997224733233, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 102, train_loss = 2.300563650787808, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "14th- epoch: 103, train_loss = 2.2864467334002256, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 104, train_loss = 2.281318080611527, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 105, train_loss = 2.251890717423521, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 106, train_loss = 2.231131068081595, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 107, train_loss = 2.2355015501379967, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 108, train_loss = 2.262167832814157, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 109, train_loss = 2.257791180163622, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 110, train_loss = 2.2283120254287496, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 111, train_loss = 2.209243997349404, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 112, train_loss = 2.2135344421258196, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 113, train_loss = 2.207125773304142, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 114, train_loss = 2.2277432108530775, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 115, train_loss = 2.208877222961746, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 116, train_loss = 2.1861850222339854, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 117, train_loss = 2.227689846768044, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 118, train_loss = 2.2111517001176253, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 119, train_loss = 2.193424710072577, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "14th- epoch: 120, train_loss = 2.1730097761610523, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 121, train_loss = 2.1813879118999466, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 122, train_loss = 2.169104333035648, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 123, train_loss = 2.168290648027323, train_acc = 0.9951094550535631\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 124, train_loss = 2.1514323003357276, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 125, train_loss = 2.155705365934409, train_acc = 0.9951094550535631\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 126, train_loss = 2.1533755030250177, train_acc = 0.9954587796925943\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 127, train_loss = 2.1790445186197758, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 128, train_loss = 2.172511109500192, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 129, train_loss = 2.1742313461145386, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 130, train_loss = 2.147775997989811, train_acc = 0.9951094550535631\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 131, train_loss = 2.135914378799498, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 132, train_loss = 2.1266229891916737, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 133, train_loss = 2.1370356989791617, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 134, train_loss = 2.1190805888036266, train_acc = 0.9951094550535631\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 135, train_loss = 2.1166689755627885, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 136, train_loss = 2.1125898426398635, train_acc = 0.9954587796925943\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 137, train_loss = 2.124045905075036, train_acc = 0.9951094550535631\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 138, train_loss = 2.106528022675775, train_acc = 0.9951094550535631\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 139, train_loss = 2.117858486250043, train_acc = 0.9953423381462506\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 140, train_loss = 2.1171330449869856, train_acc = 0.9951094550535631\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 141, train_loss = 2.0926227811723948, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 142, train_loss = 2.0814717719331384, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 143, train_loss = 2.084589194506407, train_acc = 0.9949930135072194\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 144, train_loss = 2.076458029448986, train_acc = 0.9954587796925943\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 145, train_loss = 2.1067145615816116, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 146, train_loss = 2.109095458232332, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 147, train_loss = 2.1032341507379897, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 148, train_loss = 2.1208663514698856, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 149, train_loss = 2.111860442266334, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 150, train_loss = 2.09331077960087, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 151, train_loss = 2.0988162488793023, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 152, train_loss = 2.100497703999281, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 153, train_loss = 2.0939713275874965, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 154, train_loss = 2.0904877154971473, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 155, train_loss = 2.0912243773345836, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 156, train_loss = 2.089650511741638, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 157, train_loss = 2.085677370429039, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 158, train_loss = 2.079517758160364, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 159, train_loss = 2.077477835759055, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "14th- epoch: 160, train_loss = 2.0750762137467973, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 161, train_loss = 2.0717965085059404, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 162, train_loss = 2.0722740783239715, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 163, train_loss = 2.074953942850698, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 164, train_loss = 2.0720984718645923, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 165, train_loss = 2.066406369849574, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 166, train_loss = 2.0738860741257668, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 167, train_loss = 2.050306824967265, train_acc = 0.9949930135072194\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 168, train_loss = 2.058491639152635, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 169, train_loss = 2.0555954445153475, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 170, train_loss = 2.0449731647968292, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 171, train_loss = 2.0505348835140467, train_acc = 0.9949930135072194\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 172, train_loss = 2.0443972938810475, train_acc = 0.9949930135072194\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 173, train_loss = 2.0457694095675834, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 174, train_loss = 2.0437887143343687, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 175, train_loss = 2.033871453255415, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 176, train_loss = 2.041181939363014, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 177, train_loss = 2.037413395300973, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 178, train_loss = 2.0424820513580926, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 179, train_loss = 2.030818849802017, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 180, train_loss = 2.0328872588579543, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 181, train_loss = 2.0458723815972917, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 182, train_loss = 2.029555555433035, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 183, train_loss = 2.034247004718054, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 184, train_loss = 2.0262344516813755, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 185, train_loss = 2.0299318060278893, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 186, train_loss = 2.0279244550620206, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 187, train_loss = 2.019223782524932, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 188, train_loss = 2.024264319508802, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 189, train_loss = 2.0227784694288857, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 190, train_loss = 2.020654468506109, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 191, train_loss = 2.010417791083455, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 192, train_loss = 2.0126154733006842, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 193, train_loss = 2.0095291920006275, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 194, train_loss = 2.0080051068216562, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 195, train_loss = 2.0078542605042458, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 196, train_loss = 2.002245780080557, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 197, train_loss = 1.9982749056071043, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 198, train_loss = 2.0037457669968717, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 199, train_loss = 2.0025591303710826, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 200, train_loss = 2.000279418483842, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 201, train_loss = 1.9967615784262307, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 202, train_loss = 2.001111324876547, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 203, train_loss = 1.9917247251723893, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 204, train_loss = 1.9938447568565607, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 205, train_loss = 1.9904156234115362, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 206, train_loss = 1.989913362369407, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 207, train_loss = 1.9903055292670615, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 208, train_loss = 1.9922220731968991, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 209, train_loss = 1.983168502629269, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 210, train_loss = 1.9915581892128102, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 211, train_loss = 1.9805130300228484, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 212, train_loss = 1.9800539377029054, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 213, train_loss = 1.9787677197600715, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 214, train_loss = 1.9768902957439423, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 215, train_loss = 1.9764087994699366, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 216, train_loss = 1.9750344660133123, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 217, train_loss = 1.977674564346671, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 218, train_loss = 1.9691487507079728, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 219, train_loss = 1.9683150928467512, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 220, train_loss = 1.9716467522084713, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 221, train_loss = 1.963490913331043, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 222, train_loss = 1.9640892818570137, train_acc = 0.9953423381462506\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 223, train_loss = 1.9618771560490131, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 224, train_loss = 1.9721176705206744, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 225, train_loss = 1.9638350916211493, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 226, train_loss = 1.9585096233640797, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 227, train_loss = 1.9688063866342418, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 228, train_loss = 1.9609690972720273, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 229, train_loss = 1.954988906159997, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 230, train_loss = 1.9504291198099963, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 231, train_loss = 1.9540896899998188, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 232, train_loss = 1.9492291889037006, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 233, train_loss = 1.9591987300664186, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 234, train_loss = 1.9608639813959599, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 235, train_loss = 1.9475640219752677, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 236, train_loss = 1.9466873103228863, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 237, train_loss = 1.9592651656712405, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 238, train_loss = 1.949047307803994, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 239, train_loss = 1.9390858529659454, train_acc = 0.9953423381462506\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 240, train_loss = 1.9493428505957127, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 241, train_loss = 1.9501461175386794, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 242, train_loss = 1.9446951492282096, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 243, train_loss = 1.94151878048433, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 244, train_loss = 1.943298660829896, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 245, train_loss = 1.9368261514755432, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 246, train_loss = 1.9390433585795108, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 247, train_loss = 1.9438137827964965, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 248, train_loss = 1.9382991107704584, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 249, train_loss = 1.9399137807486113, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 250, train_loss = 1.9336522755620535, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 251, train_loss = 1.9299592773022596, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 252, train_loss = 1.9337450501916464, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 253, train_loss = 1.9258148136141244, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 254, train_loss = 1.934891952201724, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 255, train_loss = 1.930011866003042, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 256, train_loss = 1.9276954513043165, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 257, train_loss = 1.926952059060568, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 258, train_loss = 1.927033193409443, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 259, train_loss = 1.9286894009856042, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 260, train_loss = 1.9280832645890769, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 261, train_loss = 1.924355637282133, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 262, train_loss = 1.9241106621921062, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 263, train_loss = 1.9233422167599201, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 264, train_loss = 1.919878196582431, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 265, train_loss = 1.924188449367648, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 266, train_loss = 1.919132793933386, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 267, train_loss = 1.9176796153187752, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 268, train_loss = 1.9255660300550517, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 269, train_loss = 1.9171304454503115, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 270, train_loss = 1.913644035026664, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 271, train_loss = 1.919150280446047, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 272, train_loss = 1.9186350225063507, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 273, train_loss = 1.9104669311491307, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 274, train_loss = 1.9181530717760324, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 275, train_loss = 1.912558559939498, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 276, train_loss = 1.9096229566785041, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 277, train_loss = 1.9055229084042367, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 278, train_loss = 1.9067560372350272, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 279, train_loss = 1.9061949377355631, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 280, train_loss = 1.9118062599154655, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 281, train_loss = 1.8998647170665208, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 282, train_loss = 1.9042595947685186, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 283, train_loss = 1.908263464778429, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 284, train_loss = 1.9083468808385078, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 285, train_loss = 1.898221092298627, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 286, train_loss = 1.8970641350897495, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 287, train_loss = 1.908081620320445, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 288, train_loss = 1.90304989926517, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 289, train_loss = 1.9002911541610956, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 290, train_loss = 1.8944281420262996, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 291, train_loss = 1.8964461584982928, train_acc = 0.9953423381462506\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 292, train_loss = 1.9009196472761687, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 293, train_loss = 1.8917262225004379, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 294, train_loss = 1.893220509722596, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 295, train_loss = 1.889584794640541, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 296, train_loss = 1.8928846530616283, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 297, train_loss = 1.8909048102796078, train_acc = 0.9952258965999069\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 298, train_loss = 1.893749042734271, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 299, train_loss = 1.8935525827109814, train_acc = 0.9949930135072194\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 300, train_loss = 1.8979391486791428, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 301, train_loss = 1.8838395774364471, train_acc = 0.9952258965999069\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 302, train_loss = 1.893652622908121, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 303, train_loss = 1.8877809792757034, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 304, train_loss = 1.8876294282672461, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 305, train_loss = 1.8856980726122856, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 306, train_loss = 1.877011677250266, train_acc = 0.9951094550535631\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 307, train_loss = 1.878745874390006, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 308, train_loss = 1.8810376276669558, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 309, train_loss = 1.8684853985905647, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 310, train_loss = 1.8723115796747152, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 311, train_loss = 1.8705397030862514, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 312, train_loss = 1.874886858597165, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 313, train_loss = 1.8669342348875944, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 314, train_loss = 1.867267300694948, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 315, train_loss = 1.8727743911149446, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 316, train_loss = 1.8676641304045916, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 317, train_loss = 1.8659767055360135, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 318, train_loss = 1.8633698616176844, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 319, train_loss = 1.8596025121805724, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 320, train_loss = 1.861611626431113, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 321, train_loss = 1.8642404334095772, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 322, train_loss = 1.862902361288434, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 323, train_loss = 1.8613456642779056, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 324, train_loss = 1.859516258671647, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 325, train_loss = 1.8575561636534985, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 326, train_loss = 1.8574141394346952, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 327, train_loss = 1.8635577242821455, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 328, train_loss = 1.8565245239587966, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 329, train_loss = 1.8573685083538294, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 330, train_loss = 1.8530715834349394, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 331, train_loss = 1.8518589524028357, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 332, train_loss = 1.8576182499527931, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 333, train_loss = 1.8619496574101504, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 334, train_loss = 1.8564188076707069, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 335, train_loss = 1.8477125173958484, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 336, train_loss = 1.8508800007402897, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 337, train_loss = 1.8479812710138503, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 338, train_loss = 1.8485924440028612, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 339, train_loss = 1.853744217514759, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 340, train_loss = 1.8471272128226701, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 341, train_loss = 1.8461079696717206, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 342, train_loss = 1.8496158098278102, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 343, train_loss = 1.8430748078972101, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 344, train_loss = 1.846107938006753, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 345, train_loss = 1.8460680289717857, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 346, train_loss = 1.840992754936451, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 347, train_loss = 1.8398748760519084, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 348, train_loss = 1.8449615494755562, train_acc = 0.9947601304145319\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 349, train_loss = 1.8431810339388903, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 350, train_loss = 1.8413266701099928, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 351, train_loss = 1.844896974042058, train_acc = 0.9947601304145319\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 352, train_loss = 1.840051290258998, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 353, train_loss = 1.8395188668218907, train_acc = 0.9947601304145319\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 354, train_loss = 1.8369397961942013, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 355, train_loss = 1.8362398110330105, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 356, train_loss = 1.8334150748851243, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 357, train_loss = 1.8370014540851116, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 358, train_loss = 1.8300251656619366, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 359, train_loss = 1.8334114477038383, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 360, train_loss = 1.8397007429448422, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 361, train_loss = 1.8272251716407482, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 362, train_loss = 1.8301695926638786, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 363, train_loss = 1.8333563171327114, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 364, train_loss = 1.8290401306003332, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 365, train_loss = 1.8293034775706474, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 366, train_loss = 1.8261561182735022, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 367, train_loss = 1.8309240750968456, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 368, train_loss = 1.8265581677260343, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 369, train_loss = 1.8227877492608968, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 370, train_loss = 1.8268395823833998, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 371, train_loss = 1.822394667804474, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 372, train_loss = 1.8244461491703987, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 373, train_loss = 1.8316614342329558, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 374, train_loss = 1.83011487746262, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 375, train_loss = 1.8245242076663999, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 376, train_loss = 1.823289256542921, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 377, train_loss = 1.8229834511876106, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 378, train_loss = 1.8236050233244896, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 379, train_loss = 1.8235419504344463, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 380, train_loss = 1.8218813240528107, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 381, train_loss = 1.817527201026678, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 382, train_loss = 1.8226945934293326, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 383, train_loss = 1.816873986274004, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 384, train_loss = 1.8187712654471397, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 385, train_loss = 1.8196539332566317, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 386, train_loss = 1.817229485764983, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 387, train_loss = 1.8098325468599796, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 388, train_loss = 1.8100258322956506, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 389, train_loss = 1.808965643242118, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 390, train_loss = 1.8102574522345094, train_acc = 0.9948765719608756\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 391, train_loss = 1.8089143919351045, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 392, train_loss = 1.8137295953929424, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 393, train_loss = 1.807424354061368, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 394, train_loss = 1.8103749603033066, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 395, train_loss = 1.8099659805593546, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 396, train_loss = 1.805765540644643, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 397, train_loss = 1.8052855357527733, train_acc = 0.9948765719608756\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 398, train_loss = 1.8105015022010775, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 399, train_loss = 1.8090895786881447, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 400, train_loss = 1.8011119812726974, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 401, train_loss = 1.8049942354409723, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 402, train_loss = 1.8052958697080612, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 403, train_loss = 1.8035151362419128, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 404, train_loss = 1.8014986688940553, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 405, train_loss = 1.8001527525484562, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 406, train_loss = 1.8022867689578561, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 407, train_loss = 1.8021727353334427, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 408, train_loss = 1.7985286389739485, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 409, train_loss = 1.7996748027799185, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 410, train_loss = 1.7993779629468918, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 411, train_loss = 1.7996492472739192, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 412, train_loss = 1.7970493348984746, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 413, train_loss = 1.796538074806449, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 414, train_loss = 1.7971483978180913, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 415, train_loss = 1.7957285394222708, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 416, train_loss = 1.7947482491581468, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 417, train_loss = 1.7946031242609024, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 418, train_loss = 1.7971677333116531, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 419, train_loss = 1.7923705714492826, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 420, train_loss = 1.7922441487462493, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 421, train_loss = 1.793672189116478, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 422, train_loss = 1.794980138540268, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 423, train_loss = 1.789638340473175, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 424, train_loss = 1.79022432367492, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 425, train_loss = 1.790482966855052, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 426, train_loss = 1.7922067679464817, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 427, train_loss = 1.7882097512483597, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 428, train_loss = 1.7857007036654977, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 429, train_loss = 1.7892748067824868, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 430, train_loss = 1.7860639567225007, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 431, train_loss = 1.7874110278935404, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 432, train_loss = 1.789452883109334, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 433, train_loss = 1.7867566868662834, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 434, train_loss = 1.786056196942809, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 435, train_loss = 1.7836707619280787, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 436, train_loss = 1.7923887918441324, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 437, train_loss = 1.7825802105217008, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 438, train_loss = 1.7863985747098923, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 439, train_loss = 1.7856302745640278, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 440, train_loss = 1.7855985847563716, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 441, train_loss = 1.7797784358263016, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 442, train_loss = 1.7802501444966765, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 443, train_loss = 1.7864207314996747, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 444, train_loss = 1.7791737342922715, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 445, train_loss = 1.781140934675932, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 446, train_loss = 1.7820893128664466, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 447, train_loss = 1.7842389879078837, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 448, train_loss = 1.7790516329259844, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 449, train_loss = 1.779592232152936, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 450, train_loss = 1.7800201835780172, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 451, train_loss = 1.779137027755496, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 452, train_loss = 1.7792850571422605, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 453, train_loss = 1.774320237338543, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 454, train_loss = 1.7755373530089855, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 455, train_loss = 1.7723071773798438, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 456, train_loss = 1.774615084126708, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 457, train_loss = 1.775821550443652, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 458, train_loss = 1.7759024922997924, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 459, train_loss = 1.7712880397884874, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 460, train_loss = 1.7740837670862675, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 461, train_loss = 1.771724411592004, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 462, train_loss = 1.7724460351018934, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 463, train_loss = 1.7669749644846888, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 464, train_loss = 1.768558940544608, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 465, train_loss = 1.771457675844431, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 466, train_loss = 1.7670775428414345, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 467, train_loss = 1.769707861050847, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 468, train_loss = 1.7706244364380836, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 469, train_loss = 1.7669057175517082, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 470, train_loss = 1.770253953829524, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 471, train_loss = 1.7737045052199392, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 472, train_loss = 1.7764774945826503, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 473, train_loss = 1.7632061491458444, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 474, train_loss = 1.7660901099443436, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 475, train_loss = 1.7631086607725592, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 476, train_loss = 1.763361559555051, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 477, train_loss = 1.7769909054040909, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 478, train_loss = 1.7618870064616203, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 479, train_loss = 1.7610361489205388, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 480, train_loss = 1.7645816740841838, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 481, train_loss = 1.7625883507280378, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 482, train_loss = 1.7623936558811693, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 483, train_loss = 1.76295464609575, train_acc = 0.9952258965999069\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 484, train_loss = 1.7617082633078098, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 485, train_loss = 1.761005407824996, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 486, train_loss = 1.761836248144391, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 487, train_loss = 1.7563003401010064, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 488, train_loss = 1.772172754004714, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 489, train_loss = 1.7602000087499619, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 490, train_loss = 1.7590131188480882, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "14th- epoch: 491, train_loss = 1.7597455332725076, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 492, train_loss = 1.7598141568450956, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 493, train_loss = 1.758214645087719, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 494, train_loss = 1.753045741468668, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 495, train_loss = 1.7522137649357319, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 496, train_loss = 1.7529583002178697, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 497, train_loss = 1.7506681246013613, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 498, train_loss = 1.7487982076854678, train_acc = 0.9952258965999069\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 499, train_loss = 1.7556469639093848, train_acc = 0.9948765719608756\n",
      "test Acc 0.9767225325884544:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|███████████████████████████████████▍                                        | 14/30 [2:13:20<2:42:12, 608.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "15th- epoch: 0, train_loss = 391.6371221318841, train_acc = 0.8014671634839311\n",
      "test Acc 0.9152700186219739:\n",
      "15th- epoch: 1, train_loss = 74.00218634773046, train_acc = 0.9169771774569166\n",
      "test Acc 0.9343575418994413:\n",
      "15th- epoch: 2, train_loss = 47.56759690307081, train_acc = 0.9389846297158826\n",
      "test Acc 0.9459962756052142:\n",
      "15th- epoch: 3, train_loss = 35.468298994004726, train_acc = 0.9491150442477876\n",
      "test Acc 0.9464618249534451:\n",
      "15th- epoch: 4, train_loss = 28.091971199959517, train_acc = 0.9569166278528178\n",
      "test Acc 0.9441340782122905:\n",
      "15th- epoch: 5, train_loss = 23.17427386343479, train_acc = 0.9623893805309734\n",
      "test Acc 0.9450651769087524:\n",
      "15th- epoch: 6, train_loss = 19.63763428106904, train_acc = 0.9679785747554728\n",
      "test Acc 0.952513966480447:\n",
      "15th- epoch: 7, train_loss = 17.054638799279928, train_acc = 0.9714718211457848\n",
      "test Acc 0.9534450651769087:\n",
      "15th- epoch: 8, train_loss = 15.001320634037256, train_acc = 0.9743828598043782\n",
      "test Acc 0.9539106145251397:\n",
      "15th- epoch: 9, train_loss = 13.356339840218425, train_acc = 0.9763623660922217\n",
      "test Acc 0.9557728119180633:\n",
      "15th- epoch: 10, train_loss = 12.078214952722192, train_acc = 0.9786911970190965\n",
      "test Acc 0.9557728119180633:\n",
      "15th- epoch: 11, train_loss = 11.054045550525188, train_acc = 0.9800884955752213\n",
      "test Acc 0.957169459962756:\n",
      "15th- epoch: 12, train_loss = 10.228400064632297, train_acc = 0.9813693525850024\n",
      "test Acc 0.9585661080074488:\n",
      "15th- epoch: 13, train_loss = 9.492881653830409, train_acc = 0.9820680018630648\n",
      "test Acc 0.9590316573556797:\n",
      "15th- epoch: 14, train_loss = 8.877471501007676, train_acc = 0.9829995342338146\n",
      "test Acc 0.9590316573556797:\n",
      "15th- epoch: 15, train_loss = 8.32816112600267, train_acc = 0.9835817419655333\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 16, train_loss = 7.838869152590632, train_acc = 0.9847461574289706\n",
      "test Acc 0.9594972067039106:\n",
      "15th- epoch: 17, train_loss = 7.368589239194989, train_acc = 0.9850954820680019\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 18, train_loss = 6.992366609163582, train_acc = 0.9860270144387517\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 19, train_loss = 6.6337285889312625, train_acc = 0.9867256637168141\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 20, train_loss = 6.308137866668403, train_acc = 0.9871914299021891\n",
      "test Acc 0.9604283054003724:\n",
      "15th- epoch: 21, train_loss = 6.027025539427996, train_acc = 0.9874243129948765\n",
      "test Acc 0.9594972067039106:\n",
      "15th- epoch: 22, train_loss = 5.775520165450871, train_acc = 0.9876571960875641\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 23, train_loss = 5.541823486797512, train_acc = 0.9881229622729389\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 24, train_loss = 5.323677803389728, train_acc = 0.9889380530973452\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 25, train_loss = 5.1240325989201665, train_acc = 0.9895202608290639\n",
      "test Acc 0.9632216014897579:\n",
      "15th- epoch: 26, train_loss = 4.9317883206531405, train_acc = 0.989869585468095\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 27, train_loss = 4.777762752957642, train_acc = 0.9905682347461574\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 28, train_loss = 4.62508584279567, train_acc = 0.9904517931998137\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 29, train_loss = 4.486830177716911, train_acc = 0.9906846762925011\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 30, train_loss = 4.352930411696434, train_acc = 0.9905682347461574\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 31, train_loss = 4.222727733198553, train_acc = 0.990801117838845\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 32, train_loss = 4.105081354267895, train_acc = 0.990801117838845\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 33, train_loss = 4.002427980303764, train_acc = 0.990801117838845\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 34, train_loss = 3.902750503271818, train_acc = 0.9909175593851887\n",
      "test Acc 0.9655493482309124:\n",
      "15th- epoch: 35, train_loss = 3.8142346777021885, train_acc = 0.9910340009315324\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 36, train_loss = 3.7373467325232923, train_acc = 0.9912668840242198\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 37, train_loss = 3.6583316759206355, train_acc = 0.9913833255705635\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 38, train_loss = 3.5867261947132647, train_acc = 0.9913833255705635\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 39, train_loss = 3.521094348281622, train_acc = 0.9914997671169073\n",
      "test Acc 0.9660148975791434:\n",
      "15th- epoch: 40, train_loss = 3.4670663201250136, train_acc = 0.9914997671169073\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 41, train_loss = 3.4076312058605254, train_acc = 0.9916162086632511\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 42, train_loss = 3.360217733774334, train_acc = 0.9919655333022822\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 43, train_loss = 3.3123901546932757, train_acc = 0.9917326502095948\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 44, train_loss = 3.257478404790163, train_acc = 0.9916162086632511\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 45, train_loss = 3.223682451993227, train_acc = 0.9917326502095948\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 46, train_loss = 3.1825163909234107, train_acc = 0.9917326502095948\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 47, train_loss = 3.1431954256258905, train_acc = 0.9918490917559385\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 48, train_loss = 3.1054382980801165, train_acc = 0.9918490917559385\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 49, train_loss = 3.0735032917000353, train_acc = 0.9918490917559385\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 50, train_loss = 3.0406346023082733, train_acc = 0.9919655333022822\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 51, train_loss = 3.012593187391758, train_acc = 0.992081974848626\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 52, train_loss = 2.979857394937426, train_acc = 0.9921984163949698\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 53, train_loss = 2.951471395790577, train_acc = 0.9923148579413135\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 54, train_loss = 2.928325841901824, train_acc = 0.9923148579413135\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 55, train_loss = 2.9056176654994488, train_acc = 0.9924312994876572\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 56, train_loss = 2.878834093688056, train_acc = 0.9925477410340009\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 57, train_loss = 2.8555611446499825, train_acc = 0.9925477410340009\n",
      "test Acc 0.9664804469273743:\n",
      "15th- epoch: 58, train_loss = 2.8378698986489326, train_acc = 0.9926641825803446\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 59, train_loss = 2.8166917748749256, train_acc = 0.9925477410340009\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 60, train_loss = 2.7906752452254295, train_acc = 0.9926641825803446\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 61, train_loss = 2.768799251643941, train_acc = 0.9927806241266884\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 62, train_loss = 2.757582027465105, train_acc = 0.9927806241266884\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 63, train_loss = 2.7417535993736237, train_acc = 0.9927806241266884\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 64, train_loss = 2.7177646209020168, train_acc = 0.9927806241266884\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 65, train_loss = 2.704037168296054, train_acc = 0.9930135072193759\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 66, train_loss = 2.6848014208953828, train_acc = 0.9930135072193759\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 67, train_loss = 2.67227894696407, train_acc = 0.9931299487657196\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 68, train_loss = 2.650722810300067, train_acc = 0.9931299487657196\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 69, train_loss = 2.6404816694557667, train_acc = 0.9932463903120633\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 70, train_loss = 2.628465012880042, train_acc = 0.9931299487657196\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 71, train_loss = 2.6084515328984708, train_acc = 0.9931299487657196\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 72, train_loss = 2.6002088983077556, train_acc = 0.9931299487657196\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 73, train_loss = 2.5889207769650966, train_acc = 0.9931299487657196\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 74, train_loss = 2.5705898615997285, train_acc = 0.9932463903120633\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 75, train_loss = 2.5581058636307716, train_acc = 0.9931299487657196\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 76, train_loss = 2.5479023482184857, train_acc = 0.9931299487657196\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 77, train_loss = 2.538862716406584, train_acc = 0.9932463903120633\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 78, train_loss = 2.523759212344885, train_acc = 0.9933628318584071\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 79, train_loss = 2.51440654322505, train_acc = 0.9932463903120633\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 80, train_loss = 2.5064513359684497, train_acc = 0.9933628318584071\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 81, train_loss = 2.4963060666341335, train_acc = 0.9933628318584071\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 82, train_loss = 2.4924572308082134, train_acc = 0.9933628318584071\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 83, train_loss = 2.4827511112671345, train_acc = 0.9933628318584071\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 84, train_loss = 2.4630509838461876, train_acc = 0.9933628318584071\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 85, train_loss = 2.452879576710984, train_acc = 0.9933628318584071\n",
      "test Acc 0.9674115456238361:\n",
      "15th- epoch: 86, train_loss = 2.44417283940129, train_acc = 0.9933628318584071\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 87, train_loss = 2.442379017593339, train_acc = 0.9933628318584071\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 88, train_loss = 2.4294656676938757, train_acc = 0.9934792734047508\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 89, train_loss = 2.4198557684430853, train_acc = 0.9934792734047508\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 90, train_loss = 2.410647477954626, train_acc = 0.9935957149510946\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 91, train_loss = 2.40135206526611, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 92, train_loss = 2.3927687952527776, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 93, train_loss = 2.384988489211537, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 94, train_loss = 2.3807280225446448, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 95, train_loss = 2.3737800245871767, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 96, train_loss = 2.3644627705216408, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 97, train_loss = 2.357374183833599, train_acc = 0.9937121564974383\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 98, train_loss = 2.360293367295526, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 99, train_loss = 2.3442383632063866, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 100, train_loss = 2.3423758359858766, train_acc = 0.993828598043782\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 101, train_loss = 2.336676569073461, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 102, train_loss = 2.326234392821789, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 103, train_loss = 2.315050615579821, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 104, train_loss = 2.320448315353133, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 105, train_loss = 2.310214148252271, train_acc = 0.9940614811364695\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 106, train_loss = 2.307467067032121, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 107, train_loss = 2.296767068444751, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 108, train_loss = 2.292100727558136, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 109, train_loss = 2.2833070134511217, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 110, train_loss = 2.2788250632584095, train_acc = 0.9940614811364695\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 111, train_loss = 2.2724889231612906, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 112, train_loss = 2.2735950673231855, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 113, train_loss = 2.2671740936348215, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 114, train_loss = 2.25561548396945, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 115, train_loss = 2.2502967590698972, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 116, train_loss = 2.248934945673682, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 117, train_loss = 2.248940688907169, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 118, train_loss = 2.242740428657271, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 119, train_loss = 2.2412893337896094, train_acc = 0.9940614811364695\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 120, train_loss = 2.2403262617299333, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 121, train_loss = 2.2282295239856467, train_acc = 0.9940614811364695\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 122, train_loss = 2.2233106829226017, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 123, train_loss = 2.21550113952253, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 124, train_loss = 2.2196163311600685, train_acc = 0.9940614811364695\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 125, train_loss = 2.2146179527044296, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 126, train_loss = 2.201288985670544, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 127, train_loss = 2.201596561819315, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 128, train_loss = 2.20258514827583, train_acc = 0.9940614811364695\n",
      "test Acc 0.9688081936685289:\n",
      "15th- epoch: 129, train_loss = 2.195256428210996, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 130, train_loss = 2.1919423131039366, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 131, train_loss = 2.190476641058922, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 132, train_loss = 2.1836076552281156, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 133, train_loss = 2.179271721630357, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 134, train_loss = 2.1748201301088557, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 135, train_loss = 2.1794437443604693, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 136, train_loss = 2.171933581470512, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 137, train_loss = 2.166274756193161, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 138, train_loss = 2.1684643564512953, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 139, train_loss = 2.159655431867577, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 140, train_loss = 2.153519450337626, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 141, train_loss = 2.156325813382864, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 142, train_loss = 2.159698205650784, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 143, train_loss = 2.145999154658057, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 144, train_loss = 2.1433198811719194, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 145, train_loss = 2.1444348705699667, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 146, train_loss = 2.132683750241995, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 147, train_loss = 2.1396604055771604, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 148, train_loss = 2.131947338581085, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 149, train_loss = 2.1326368724694476, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 150, train_loss = 2.1236053878674284, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 151, train_loss = 2.1272500815684907, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 152, train_loss = 2.1229908888344653, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 153, train_loss = 2.1201514241402037, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 154, train_loss = 2.1184158002142794, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 155, train_loss = 2.1092311057145707, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 156, train_loss = 2.1141950475866906, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 157, train_loss = 2.1142453216016293, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "15th- epoch: 158, train_loss = 2.1039005133206956, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 159, train_loss = 2.1081986650824547, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 160, train_loss = 2.1010317094624043, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 161, train_loss = 2.099193438887596, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 162, train_loss = 2.100664097815752, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 163, train_loss = 2.103203797072638, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 164, train_loss = 2.096430194855202, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 165, train_loss = 2.0924366042017937, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 166, train_loss = 2.085273812233936, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 167, train_loss = 2.0836330031161197, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 168, train_loss = 2.084448145062197, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 169, train_loss = 2.080556438595522, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 170, train_loss = 2.0762000766699202, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 171, train_loss = 2.078743560879957, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 172, train_loss = 2.0808493979275227, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 173, train_loss = 2.06591957929777, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 174, train_loss = 2.0713328408892266, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 175, train_loss = 2.070074950635899, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 176, train_loss = 2.0687311899964698, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 177, train_loss = 2.062555453449022, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 178, train_loss = 2.0597305558621883, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 179, train_loss = 2.059222740412224, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 180, train_loss = 2.060238661884796, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 181, train_loss = 2.0560481908614747, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 182, train_loss = 2.0536515514249913, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 183, train_loss = 2.054572405933868, train_acc = 0.9940614811364695\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 184, train_loss = 2.047141996503342, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 185, train_loss = 2.0479019967024215, train_acc = 0.9940614811364695\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 186, train_loss = 2.0434895207290538, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 187, train_loss = 2.0461742890183814, train_acc = 0.9940614811364695\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 188, train_loss = 2.053373657166958, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 189, train_loss = 2.0491001792252064, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 190, train_loss = 2.0410507048363797, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 191, train_loss = 2.035825226455927, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 192, train_loss = 2.0363808746333234, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 193, train_loss = 2.0417443364858627, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 194, train_loss = 2.03100250166608, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 195, train_loss = 2.0344561387901194, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 196, train_loss = 2.0365640210802667, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 197, train_loss = 2.037285832047928, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 198, train_loss = 2.0266556603019126, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 199, train_loss = 2.0298128848080523, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 200, train_loss = 2.0311782409553416, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 201, train_loss = 2.0258303371374495, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 202, train_loss = 2.0209064297378063, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 203, train_loss = 2.0217118349974044, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 204, train_loss = 2.017487437755335, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 205, train_loss = 2.022979448258411, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 206, train_loss = 2.0177217560703866, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 207, train_loss = 2.019160355150234, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 208, train_loss = 2.020377541601192, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 209, train_loss = 2.019121478020679, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 210, train_loss = 2.01557369279908, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 211, train_loss = 2.010839331895113, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 212, train_loss = 2.009743555157911, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "15th- epoch: 213, train_loss = 2.013883261650335, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 214, train_loss = 2.002986824780237, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 215, train_loss = 2.0030071710352786, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 216, train_loss = 2.0033473310177214, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 217, train_loss = 2.000591753690969, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 218, train_loss = 1.9966061699087732, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 219, train_loss = 1.9950617204303853, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 220, train_loss = 2.0013617749209516, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 221, train_loss = 1.9983675603871234, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 222, train_loss = 2.0007286754553206, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 223, train_loss = 1.9964434318244457, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 224, train_loss = 1.9900972197647206, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 225, train_loss = 1.9862295612692833, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 226, train_loss = 1.997000350325834, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 227, train_loss = 1.9886263397638686, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 228, train_loss = 1.9936429373919964, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 229, train_loss = 1.9831620690529235, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 230, train_loss = 1.9826781910960563, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 231, train_loss = 1.9769556621904485, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 232, train_loss = 1.981557494669687, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 233, train_loss = 1.9873017966747284, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 234, train_loss = 1.9813955749268644, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 235, train_loss = 1.9781857070629485, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 236, train_loss = 1.9765465781092644, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 237, train_loss = 1.9785666701500304, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 238, train_loss = 1.971678917587269, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 239, train_loss = 1.980865812569391, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 240, train_loss = 1.9781942243571393, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 241, train_loss = 1.9672711752355099, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 242, train_loss = 1.9667382463812828, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 243, train_loss = 1.9683607767219655, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 244, train_loss = 1.968366892368067, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 245, train_loss = 1.9657746441662312, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 246, train_loss = 1.9662495404481888, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 247, train_loss = 1.9648526720702648, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 248, train_loss = 1.9645772005314939, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 249, train_loss = 1.9621125509147532, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 250, train_loss = 1.9613499144616071, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 251, train_loss = 1.9605678382213227, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 252, train_loss = 1.9628673680126667, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 253, train_loss = 1.9573374812607653, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 254, train_loss = 1.9579122165741865, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 255, train_loss = 1.9571247312123887, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 256, train_loss = 1.952288726955885, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 257, train_loss = 1.9549059246783145, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 258, train_loss = 1.9555902803840581, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 259, train_loss = 1.9524384625256062, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 260, train_loss = 1.9488788805902004, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 261, train_loss = 1.9567951038479805, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 262, train_loss = 1.9468594156205654, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 263, train_loss = 1.9496756171283778, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 264, train_loss = 1.9537280723452568, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 265, train_loss = 1.9488304480910301, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 266, train_loss = 1.9403967882099096, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 267, train_loss = 1.940898916363949, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 268, train_loss = 1.9399221936764661, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 269, train_loss = 1.93955909460783, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 270, train_loss = 1.941574395954376, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 271, train_loss = 1.9356871917843819, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 272, train_loss = 1.9372214885952417, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 273, train_loss = 1.9384868989291135, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 274, train_loss = 1.9381207401456777, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 275, train_loss = 1.9353222399950027, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 276, train_loss = 1.9381024055182934, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 277, train_loss = 1.9284253964724485, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 278, train_loss = 1.936184149235487, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 279, train_loss = 1.9310505501925945, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 280, train_loss = 1.9269130192697048, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 281, train_loss = 1.9323298136296216, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 282, train_loss = 1.9228068167867605, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 283, train_loss = 1.9296743398008402, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 284, train_loss = 1.9259494940342847, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 285, train_loss = 1.925158817321062, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 286, train_loss = 1.9209938235580921, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 287, train_loss = 1.9236129981873091, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 288, train_loss = 1.9272277566196863, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 289, train_loss = 1.9192337518034037, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 290, train_loss = 1.919193552195793, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "15th- epoch: 291, train_loss = 1.9226111719908658, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 292, train_loss = 1.9195822551846504, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 293, train_loss = 1.9217713226971682, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 294, train_loss = 1.9165432266891003, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 295, train_loss = 1.9138540128769819, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 296, train_loss = 1.9175023821590003, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 297, train_loss = 1.9124674536287785, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 298, train_loss = 1.9177697499690112, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 299, train_loss = 1.910358232766157, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 300, train_loss = 1.9122635225357953, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 301, train_loss = 1.9168160209956113, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 302, train_loss = 1.9184508522448596, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 303, train_loss = 1.9131958360376302, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 304, train_loss = 1.9071579041483346, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 305, train_loss = 1.908287604659563, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 306, train_loss = 1.9097315656545106, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 307, train_loss = 1.9054137505590916, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 308, train_loss = 1.9083154276013374, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 309, train_loss = 1.9088711701333523, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 310, train_loss = 1.9140898659825325, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 311, train_loss = 1.9032774729130324, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 312, train_loss = 1.9013295633194502, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 313, train_loss = 1.9009306257066783, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 314, train_loss = 1.9101445861160755, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 315, train_loss = 1.8991118744015694, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 316, train_loss = 1.8998301215469837, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 317, train_loss = 1.9005770422518253, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 318, train_loss = 1.8937092944979668, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 319, train_loss = 1.8930850848555565, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 320, train_loss = 1.898492954671383, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 321, train_loss = 1.8979047822358552, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 322, train_loss = 1.902981380611891, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 323, train_loss = 1.8977634596230928, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 324, train_loss = 1.8962750894424971, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "15th- epoch: 325, train_loss = 1.8937600751814898, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 326, train_loss = 1.8932320078311022, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 327, train_loss = 1.897395744919777, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 328, train_loss = 1.8886765278875828, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 329, train_loss = 1.8852317320706788, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 330, train_loss = 1.8888515755534172, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 331, train_loss = 1.8948772139847279, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 332, train_loss = 1.8847990868089255, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 333, train_loss = 1.8829544944164809, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 334, train_loss = 1.884293857961893, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 335, train_loss = 1.8810340488853399, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 336, train_loss = 1.8796680557134096, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 337, train_loss = 1.8861798408033792, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 338, train_loss = 1.8897002475860063, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 339, train_loss = 1.877538949251175, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 340, train_loss = 1.8761009387671947, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 341, train_loss = 1.877533532679081, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 342, train_loss = 1.8787462028267328, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 343, train_loss = 1.8888009327056352, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 344, train_loss = 1.8749035423097666, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 345, train_loss = 1.873928570508724, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 346, train_loss = 1.875504445284605, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 347, train_loss = 1.87295763194561, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 348, train_loss = 1.8696773710253183, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 349, train_loss = 1.8779924710688647, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 350, train_loss = 1.870932299643755, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 351, train_loss = 1.882474205136532, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 352, train_loss = 1.8745384352805559, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 353, train_loss = 1.874995931982994, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 354, train_loss = 1.8718591829237994, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 355, train_loss = 1.8682641237974167, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 356, train_loss = 1.8645968685450498, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 357, train_loss = 1.8716871924698353, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 358, train_loss = 1.862450547516346, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 359, train_loss = 1.862611467629904, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 360, train_loss = 1.861641383409733, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 361, train_loss = 1.8661153403518256, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 362, train_loss = 1.8686644447443541, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 363, train_loss = 1.86389178285026, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 364, train_loss = 1.8720532531442586, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 365, train_loss = 1.8632706627249718, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 366, train_loss = 1.8601963644323405, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 367, train_loss = 1.870723413914675, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 368, train_loss = 1.8649250119924545, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 369, train_loss = 1.8564808989467565, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 370, train_loss = 1.855936889856821, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 371, train_loss = 1.8586359918117523, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 372, train_loss = 1.8549289988877717, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "15th- epoch: 373, train_loss = 1.849619480461115, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 374, train_loss = 1.8561632757482585, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 375, train_loss = 1.8527253344655037, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 376, train_loss = 1.8630101159214973, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 377, train_loss = 1.8533936701714993, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 378, train_loss = 1.8581684306263924, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 379, train_loss = 1.8577372804284096, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 380, train_loss = 1.8485063252446707, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 381, train_loss = 1.8466266455652658, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 382, train_loss = 1.8513212402758654, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 383, train_loss = 1.8493188632128295, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 384, train_loss = 1.8464319494960364, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 385, train_loss = 1.8441839938459452, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 386, train_loss = 1.8442138607206289, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 387, train_loss = 1.8461511904897634, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 388, train_loss = 1.8440952686069068, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 389, train_loss = 1.838647771626711, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 390, train_loss = 1.84510655948543, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 391, train_loss = 1.8441657262446824, train_acc = 0.9944108057755007\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 392, train_loss = 1.8549021830258425, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 393, train_loss = 1.8438999454083387, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 394, train_loss = 1.8410139915940817, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 395, train_loss = 1.8393241961894091, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 396, train_loss = 1.8392694244685117, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 397, train_loss = 1.8434154627320822, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 398, train_loss = 1.835905841231579, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 399, train_loss = 1.8395366618933622, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 400, train_loss = 1.8462885282933712, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 401, train_loss = 1.8304679530265275, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 402, train_loss = 1.835290110349888, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 403, train_loss = 1.8364838349225465, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 404, train_loss = 1.8330869848432485, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 405, train_loss = 1.8302326897683088, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 406, train_loss = 1.831484838068718, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 407, train_loss = 1.8358394180831965, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 408, train_loss = 1.8390447559359018, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 409, train_loss = 1.829143688082695, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 410, train_loss = 1.8282066931424197, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 411, train_loss = 1.82911042496562, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 412, train_loss = 1.8267536610364914, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 413, train_loss = 1.8270171085896436, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 414, train_loss = 1.8247786151769105, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 415, train_loss = 1.8281738050282001, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 416, train_loss = 1.8269156652095262, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 417, train_loss = 1.8230142345128115, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 418, train_loss = 1.8230291791260242, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 419, train_loss = 1.8230645321309566, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 420, train_loss = 1.8270575056376401, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 421, train_loss = 1.826291593402857, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 422, train_loss = 1.8288638070225716, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 423, train_loss = 1.8184976639749948, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 424, train_loss = 1.824500927090412, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 425, train_loss = 1.8265252175333444, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 426, train_loss = 1.8341958075761795, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 427, train_loss = 1.8244901175203267, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 428, train_loss = 1.8393194042146206, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 429, train_loss = 1.8210446958837565, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 430, train_loss = 1.8142796407046262, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 431, train_loss = 1.81690414249897, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 432, train_loss = 1.8135069062409457, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 433, train_loss = 1.8198907102050725, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 434, train_loss = 1.825341023504734, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 435, train_loss = 1.8245693681237753, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 436, train_loss = 1.8137004040181637, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 437, train_loss = 1.8188378401100636, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 438, train_loss = 1.8124713972210884, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 439, train_loss = 1.821156627178425, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 440, train_loss = 1.8128396508691367, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 441, train_loss = 1.8148528064339189, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 442, train_loss = 1.816349929824355, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 443, train_loss = 1.8138784865441266, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 444, train_loss = 1.8131060997548047, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 445, train_loss = 1.812724279865506, train_acc = 0.9944108057755007\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 446, train_loss = 1.8067559649643954, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 447, train_loss = 1.8163564689457417, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 448, train_loss = 1.8029990904033184, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 449, train_loss = 1.8163696291449014, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 450, train_loss = 1.8126651644706726, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 451, train_loss = 1.8045826790330466, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 452, train_loss = 1.8147845889034215, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 453, train_loss = 1.8141126558184624, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 454, train_loss = 1.7972844752221135, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 455, train_loss = 1.8027083252818557, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 456, train_loss = 1.7991713471710682, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 457, train_loss = 1.8010806081147166, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 458, train_loss = 1.8038041231629904, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 459, train_loss = 1.8032307177782059, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 460, train_loss = 1.8053116624505492, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 461, train_loss = 1.798139123871806, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 462, train_loss = 1.7987838387489319, train_acc = 0.9944108057755007\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 463, train_loss = 1.7926748245954514, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 464, train_loss = 1.795817382633686, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 465, train_loss = 1.793180949985981, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 466, train_loss = 1.8029435177595587, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 467, train_loss = 1.7942944553942652, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 468, train_loss = 1.7910887052566977, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 469, train_loss = 1.794375101730111, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 470, train_loss = 1.7945590329618426, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 471, train_loss = 1.803067487970111, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 472, train_loss = 1.7953148347587558, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 473, train_loss = 1.7859284617006779, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 474, train_loss = 1.788819968700409, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 475, train_loss = 1.7923102739005117, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 476, train_loss = 1.791952446103096, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 477, train_loss = 1.7989054980425863, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 478, train_loss = 1.7907655810267897, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 479, train_loss = 1.7863216201512842, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 480, train_loss = 1.7866634118108777, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 481, train_loss = 1.7890584816486808, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 482, train_loss = 1.7867984573094873, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 483, train_loss = 1.7889518948941259, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 484, train_loss = 1.7869522161781788, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 485, train_loss = 1.7822679479868384, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 486, train_loss = 1.781234064445016, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 487, train_loss = 1.7824753771274118, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 488, train_loss = 1.7771140461118193, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 489, train_loss = 1.7853362075984478, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 490, train_loss = 1.7794780122785596, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 491, train_loss = 1.7793489557952853, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 492, train_loss = 1.7822368666529655, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 493, train_loss = 1.789873863264802, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 494, train_loss = 1.7763039283454418, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 495, train_loss = 1.7825988605618477, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 496, train_loss = 1.7883053049445152, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 497, train_loss = 1.7810093462467194, train_acc = 0.9944108057755007\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 498, train_loss = 1.7841447380633326, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 499, train_loss = 1.7777254010288743, train_acc = 0.9944108057755007\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|██████████████████████████████████████                                      | 15/30 [2:23:45<2:33:17, 613.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "16th- epoch: 0, train_loss = 344.01224733889103, train_acc = 0.8107824871914299\n",
      "test Acc 0.8477653631284916:\n",
      "16th- epoch: 1, train_loss = 63.800382360816, train_acc = 0.9237307871448532\n",
      "test Acc 0.9236499068901304:\n",
      "16th- epoch: 2, train_loss = 42.58958747237921, train_acc = 0.9410805775500699\n",
      "test Acc 0.9436685288640596:\n",
      "16th- epoch: 3, train_loss = 31.797758212313056, train_acc = 0.9538891476478808\n",
      "test Acc 0.9473929236499069:\n",
      "16th- epoch: 4, train_loss = 25.773989390581846, train_acc = 0.9612249650675361\n",
      "test Acc 0.952513966480447:\n",
      "16th- epoch: 5, train_loss = 21.49997452273965, train_acc = 0.9658826269212856\n",
      "test Acc 0.9529795158286778:\n",
      "16th- epoch: 6, train_loss = 18.202348789200187, train_acc = 0.9686772240335352\n",
      "test Acc 0.9539106145251397:\n",
      "16th- epoch: 7, train_loss = 15.71439248509705, train_acc = 0.9719375873311598\n",
      "test Acc 0.9539106145251397:\n",
      "16th- epoch: 8, train_loss = 13.803191483020782, train_acc = 0.9746157428970657\n",
      "test Acc 0.9557728119180633:\n",
      "16th- epoch: 9, train_loss = 12.336143583059311, train_acc = 0.9764788076385654\n",
      "test Acc 0.957635009310987:\n",
      "16th- epoch: 10, train_loss = 11.104402244091034, train_acc = 0.9781089892873778\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 11, train_loss = 10.093719057738781, train_acc = 0.9799720540288775\n",
      "test Acc 0.9585661080074488:\n",
      "16th- epoch: 12, train_loss = 9.236568823456764, train_acc = 0.9807871448532837\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 13, train_loss = 8.472186558879912, train_acc = 0.9818351187703773\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 14, train_loss = 7.8514068918302655, train_acc = 0.9839310666045645\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 15, train_loss = 7.315703357569873, train_acc = 0.9852119236143456\n",
      "test Acc 0.9590316573556797:\n",
      "16th- epoch: 16, train_loss = 6.817894548177719, train_acc = 0.9860270144387517\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 17, train_loss = 6.3830242566764355, train_acc = 0.9867256637168141\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 18, train_loss = 6.006064513232559, train_acc = 0.9876571960875641\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 19, train_loss = 5.656027895864099, train_acc = 0.9881229622729389\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 20, train_loss = 5.344757530838251, train_acc = 0.9890544946436889\n",
      "test Acc 0.9608938547486033:\n",
      "16th- epoch: 21, train_loss = 5.082966116722673, train_acc = 0.9892873777363763\n",
      "test Acc 0.9608938547486033:\n",
      "16th- epoch: 22, train_loss = 4.833051116671413, train_acc = 0.9899860270144387\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 23, train_loss = 4.651916529983282, train_acc = 0.9902189101071263\n",
      "test Acc 0.9613594040968343:\n",
      "16th- epoch: 24, train_loss = 4.456074143294245, train_acc = 0.990801117838845\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 25, train_loss = 4.281751075293869, train_acc = 0.9912668840242198\n",
      "test Acc 0.9618249534450651:\n",
      "16th- epoch: 26, train_loss = 4.136456992477179, train_acc = 0.9911504424778761\n",
      "test Acc 0.9622905027932961:\n",
      "16th- epoch: 27, train_loss = 3.994880794081837, train_acc = 0.9916162086632511\n",
      "test Acc 0.9622905027932961:\n",
      "16th- epoch: 28, train_loss = 3.8774209418334067, train_acc = 0.9916162086632511\n",
      "test Acc 0.9622905027932961:\n",
      "16th- epoch: 29, train_loss = 3.7539277733303607, train_acc = 0.9919655333022822\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 30, train_loss = 3.662013191729784, train_acc = 0.9923148579413135\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 31, train_loss = 3.5631020963191986, train_acc = 0.9924312994876572\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 32, train_loss = 3.486518142046407, train_acc = 0.9925477410340009\n",
      "test Acc 0.962756052141527:\n",
      "16th- epoch: 33, train_loss = 3.4072838264983147, train_acc = 0.9926641825803446\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 34, train_loss = 3.3462954226415604, train_acc = 0.9927806241266884\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 35, train_loss = 3.2760934606194496, train_acc = 0.9926641825803446\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 36, train_loss = 3.2136662814300507, train_acc = 0.9926641825803446\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 37, train_loss = 3.160053289262578, train_acc = 0.9927806241266884\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 38, train_loss = 3.1100466810166836, train_acc = 0.9930135072193759\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 39, train_loss = 3.0747422475833446, train_acc = 0.9928970656730322\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 40, train_loss = 3.026766254333779, train_acc = 0.9932463903120633\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 41, train_loss = 2.9849032387137413, train_acc = 0.9933628318584071\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 42, train_loss = 2.9495993319433182, train_acc = 0.9933628318584071\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 43, train_loss = 2.9105820767581463, train_acc = 0.9935957149510946\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 44, train_loss = 2.874939903616905, train_acc = 0.9934792734047508\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 45, train_loss = 2.8528023187536746, train_acc = 0.9934792734047508\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 46, train_loss = 2.8180691860616207, train_acc = 0.9933628318584071\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 47, train_loss = 2.795595161616802, train_acc = 0.9933628318584071\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 48, train_loss = 2.756932071177289, train_acc = 0.9933628318584071\n",
      "test Acc 0.9636871508379888:\n",
      "16th- epoch: 49, train_loss = 2.7407362572848797, train_acc = 0.9932463903120633\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 50, train_loss = 2.708990453509614, train_acc = 0.9931299487657196\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 51, train_loss = 2.686582973925397, train_acc = 0.9931299487657196\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 52, train_loss = 2.663823104230687, train_acc = 0.9930135072193759\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 53, train_loss = 2.6477690935134888, train_acc = 0.9932463903120633\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 54, train_loss = 2.6227072179317474, train_acc = 0.9931299487657196\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 55, train_loss = 2.6073759745340794, train_acc = 0.9933628318584071\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 56, train_loss = 2.5876768964808434, train_acc = 0.9934792734047508\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 57, train_loss = 2.567557457834482, train_acc = 0.9934792734047508\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 58, train_loss = 2.554787117987871, train_acc = 0.9932463903120633\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 59, train_loss = 2.5260300636291504, train_acc = 0.9935957149510946\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 60, train_loss = 2.5166951816063374, train_acc = 0.9934792734047508\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 61, train_loss = 2.5058813702780753, train_acc = 0.9935957149510946\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 62, train_loss = 2.4771345667541027, train_acc = 0.993828598043782\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 63, train_loss = 2.4660756401717663, train_acc = 0.9937121564974383\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 64, train_loss = 2.4554541632533073, train_acc = 0.9935957149510946\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 65, train_loss = 2.4485655601602048, train_acc = 0.9937121564974383\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 66, train_loss = 2.430064251064323, train_acc = 0.9939450395901258\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 67, train_loss = 2.4198684382718056, train_acc = 0.9937121564974383\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 68, train_loss = 2.4103222514968365, train_acc = 0.993828598043782\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 69, train_loss = 2.3983415128896013, train_acc = 0.9937121564974383\n",
      "test Acc 0.9646182495344506:\n",
      "16th- epoch: 70, train_loss = 2.380639623850584, train_acc = 0.9939450395901258\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 71, train_loss = 2.3766467483947054, train_acc = 0.9940614811364695\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 72, train_loss = 2.36694698035717, train_acc = 0.9940614811364695\n",
      "test Acc 0.9650837988826816:\n",
      "16th- epoch: 73, train_loss = 2.349757502437569, train_acc = 0.9937121564974383\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 74, train_loss = 2.3372853733599186, train_acc = 0.9939450395901258\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 75, train_loss = 2.3264079689979553, train_acc = 0.9939450395901258\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 76, train_loss = 2.3208439411828294, train_acc = 0.9939450395901258\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 77, train_loss = 2.3181583596160635, train_acc = 0.9940614811364695\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 78, train_loss = 2.316045401035808, train_acc = 0.9940614811364695\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 79, train_loss = 2.295040043652989, train_acc = 0.9940614811364695\n",
      "test Acc 0.9660148975791434:\n",
      "16th- epoch: 80, train_loss = 2.283837123424746, train_acc = 0.9940614811364695\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 81, train_loss = 2.2820219037821516, train_acc = 0.9939450395901258\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 82, train_loss = 2.2707497850060463, train_acc = 0.9940614811364695\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 83, train_loss = 2.2576818788656965, train_acc = 0.9939450395901258\n",
      "test Acc 0.9664804469273743:\n",
      "16th- epoch: 84, train_loss = 2.2491088435053825, train_acc = 0.9940614811364695\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 85, train_loss = 2.2463595817098394, train_acc = 0.9940614811364695\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 86, train_loss = 2.2347272174665704, train_acc = 0.994294364229157\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 87, train_loss = 2.2363960730144754, train_acc = 0.994294364229157\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 88, train_loss = 2.233485539793037, train_acc = 0.9941779226828132\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 89, train_loss = 2.2246497148880735, train_acc = 0.9944108057755007\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 90, train_loss = 2.2094590490451083, train_acc = 0.9940614811364695\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 91, train_loss = 2.2004396406700835, train_acc = 0.9941779226828132\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 92, train_loss = 2.196046270430088, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 93, train_loss = 2.1890782477566972, train_acc = 0.994294364229157\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 94, train_loss = 2.196097650914453, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 95, train_loss = 2.178857062011957, train_acc = 0.994294364229157\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 96, train_loss = 2.166857392876409, train_acc = 0.9941779226828132\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 97, train_loss = 2.163514348329045, train_acc = 0.9941779226828132\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 98, train_loss = 2.168153385282494, train_acc = 0.994294364229157\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 99, train_loss = 2.154243835597299, train_acc = 0.9941779226828132\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 100, train_loss = 2.1426408091792837, train_acc = 0.9941779226828132\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 101, train_loss = 2.1462579829385504, train_acc = 0.994294364229157\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 102, train_loss = 2.1379555128514767, train_acc = 0.9941779226828132\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 103, train_loss = 2.1320921666920185, train_acc = 0.994294364229157\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 104, train_loss = 2.1241109581897035, train_acc = 0.9941779226828132\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 105, train_loss = 2.127429665415548, train_acc = 0.9941779226828132\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 106, train_loss = 2.115570418536663, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 107, train_loss = 2.1092608409235254, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 108, train_loss = 2.11339269077871, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 109, train_loss = 2.1018617240479216, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 110, train_loss = 2.099853375344537, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 111, train_loss = 2.1023754440248013, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 112, train_loss = 2.092311564832926, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 113, train_loss = 2.0875660801539198, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 114, train_loss = 2.081194657832384, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 115, train_loss = 2.0795103535056114, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 116, train_loss = 2.0761539662489668, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 117, train_loss = 2.071750988601707, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 118, train_loss = 2.072203473537229, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 119, train_loss = 2.071394458413124, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 120, train_loss = 2.0650029765674844, train_acc = 0.994294364229157\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 121, train_loss = 2.0605406165122986, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 122, train_loss = 2.0518246975843795, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 123, train_loss = 2.0518285980215296, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 124, train_loss = 2.0531260545249097, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 125, train_loss = 2.0546056540915743, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 126, train_loss = 2.048078949272167, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 127, train_loss = 2.0508701342041604, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 128, train_loss = 2.0495146538014524, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 129, train_loss = 2.0439691220526583, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 130, train_loss = 2.0377088909153827, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 131, train_loss = 2.0452987030148506, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 132, train_loss = 2.037995797873009, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 133, train_loss = 2.039140480221249, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 134, train_loss = 2.0383912424440496, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 135, train_loss = 2.03223254653858, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 136, train_loss = 2.0160136173362844, train_acc = 0.994294364229157\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 137, train_loss = 2.0113253332674503, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 138, train_loss = 2.0148285888135433, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 139, train_loss = 2.02008531865431, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 140, train_loss = 2.0132173746824265, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 141, train_loss = 2.00759955617832, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 142, train_loss = 2.007260209589731, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 143, train_loss = 2.0077418610453606, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 144, train_loss = 2.0019307993352413, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 145, train_loss = 1.9974485387210734, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 146, train_loss = 2.0034499404137023, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 147, train_loss = 1.991290068894159, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 148, train_loss = 1.9916011206805706, train_acc = 0.994294364229157\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 149, train_loss = 1.9927228304441087, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 150, train_loss = 1.995556354522705, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 151, train_loss = 1.9866586203570478, train_acc = 0.994294364229157\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 152, train_loss = 1.9872669006581418, train_acc = 0.994294364229157\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 153, train_loss = 1.9932107019121759, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 154, train_loss = 1.9781542519922368, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 155, train_loss = 1.98188767087413, train_acc = 0.9941779226828132\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 156, train_loss = 1.9814223150606267, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 157, train_loss = 1.9848217095131986, train_acc = 0.9941779226828132\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 158, train_loss = 1.9705370925366879, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 159, train_loss = 1.977487941563595, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 160, train_loss = 1.9741045907139778, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 161, train_loss = 1.974230429797899, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 162, train_loss = 1.972819559276104, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 163, train_loss = 1.9631173287634738, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 164, train_loss = 1.964708223938942, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "16th- epoch: 165, train_loss = 1.963330164551735, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 166, train_loss = 1.9588219572906382, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 167, train_loss = 1.9636492555146106, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 168, train_loss = 1.9541641821269877, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 169, train_loss = 1.9608033746480942, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 170, train_loss = 1.952976533502806, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 171, train_loss = 1.947670864581596, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 172, train_loss = 1.951277770102024, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 173, train_loss = 1.9421219651703723, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 174, train_loss = 1.9548637457191944, train_acc = 0.994294364229157\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 175, train_loss = 1.9454430788755417, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 176, train_loss = 1.951035997539293, train_acc = 0.994294364229157\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 177, train_loss = 1.9457146637141705, train_acc = 0.994294364229157\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 178, train_loss = 1.9328568304772489, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 179, train_loss = 1.9467173777520657, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 180, train_loss = 1.9445921431179158, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 181, train_loss = 1.9340757454629056, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 182, train_loss = 1.9367563401465304, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 183, train_loss = 1.9382285065948963, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 184, train_loss = 1.9342936935718171, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 185, train_loss = 1.928393553942442, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 186, train_loss = 1.9229371237452142, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 187, train_loss = 1.9338930559461005, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 188, train_loss = 1.9239102217252366, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 189, train_loss = 1.9251054003834724, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 190, train_loss = 1.9323278280789964, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "16th- epoch: 191, train_loss = 1.9194707671995275, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 192, train_loss = 1.909668383479584, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 193, train_loss = 1.923698902130127, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 194, train_loss = 1.9172926147584803, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 195, train_loss = 1.913859209686052, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 196, train_loss = 1.916536272794474, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 197, train_loss = 1.9125774018466473, train_acc = 0.9944108057755007\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 198, train_loss = 1.9155095741152763, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 199, train_loss = 1.9110628577764146, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 200, train_loss = 1.9137585920398124, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 201, train_loss = 1.9069325936143287, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 202, train_loss = 1.9062192874844186, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 203, train_loss = 1.910800305486191, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 204, train_loss = 1.9082382867927663, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 205, train_loss = 1.9080895694787614, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "16th- epoch: 206, train_loss = 1.9042520460789092, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 207, train_loss = 1.8973222747445107, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 208, train_loss = 1.9011309929192066, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 209, train_loss = 1.899779715866316, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 210, train_loss = 1.9062135741114616, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 211, train_loss = 1.8974531814455986, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 212, train_loss = 1.899736050516367, train_acc = 0.9946436888681882\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 213, train_loss = 1.9035458701546304, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 214, train_loss = 1.8941625642182771, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 215, train_loss = 1.8875608469243161, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 216, train_loss = 1.9003111980855465, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 217, train_loss = 1.9066685661673546, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 218, train_loss = 1.9053314303455409, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 219, train_loss = 1.8909289340372197, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 220, train_loss = 1.9018908999860287, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 221, train_loss = 1.8954292846319731, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 222, train_loss = 1.9044821697170846, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 223, train_loss = 1.9010163346829358, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 224, train_loss = 1.8909132542612497, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 225, train_loss = 1.884422597795492, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 226, train_loss = 1.8948340006172657, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 227, train_loss = 1.8928040502069052, train_acc = 0.9946436888681882\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 228, train_loss = 1.8979643657803535, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 229, train_loss = 1.8884142649767455, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 230, train_loss = 1.8931978655455168, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 231, train_loss = 1.8900644009409007, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 232, train_loss = 1.8907038196921349, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 233, train_loss = 1.8904491563735064, train_acc = 0.9946436888681882\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 234, train_loss = 1.8771631345152855, train_acc = 0.9946436888681882\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 235, train_loss = 1.9007584974169731, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 236, train_loss = 1.8944741065206472, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 237, train_loss = 1.8829205371439457, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 238, train_loss = 1.8914499009551946, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 239, train_loss = 1.8844513297080994, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 240, train_loss = 1.871024458348984, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 241, train_loss = 1.8796152360737324, train_acc = 0.9946436888681882\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 242, train_loss = 1.8856476595101412, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 243, train_loss = 1.891128027200466, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 244, train_loss = 1.8846534540352877, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 245, train_loss = 1.8680414569971617, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 246, train_loss = 1.8808512898685876, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 247, train_loss = 1.8866119807062205, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 248, train_loss = 1.8750735595822334, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 249, train_loss = 1.8819591427745763, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 250, train_loss = 1.8836733301577624, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 251, train_loss = 1.870510851353174, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 252, train_loss = 1.8745295628905296, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 253, train_loss = 1.8786804912087973, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 254, train_loss = 1.8752932523784693, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 255, train_loss = 1.8670452001097146, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 256, train_loss = 1.879620527237421, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 257, train_loss = 1.875000632047886, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 258, train_loss = 1.8685825268330518, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 259, train_loss = 1.878740624844795, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 260, train_loss = 1.8696136685612146, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 261, train_loss = 1.8833093134162482, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 262, train_loss = 1.8761424111726228, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 263, train_loss = 1.8617881151440088, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 264, train_loss = 1.8590305671095848, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 265, train_loss = 1.871227948606247, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 266, train_loss = 1.8659086252155248, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 267, train_loss = 1.8676205401716288, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 268, train_loss = 1.8648621564207133, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 269, train_loss = 1.8678653376700822, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 270, train_loss = 1.866884140908951, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 271, train_loss = 1.8608796000480652, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 272, train_loss = 1.8639459125697613, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 273, train_loss = 1.861059583723545, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 274, train_loss = 1.8599967136979103, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 275, train_loss = 1.8642793595790863, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 276, train_loss = 1.8607482997176703, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 277, train_loss = 1.860877063125372, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 278, train_loss = 1.8546331437828485, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 279, train_loss = 1.852204978466034, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 280, train_loss = 1.8591495553555433, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 281, train_loss = 1.858978495001793, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 282, train_loss = 1.8655529171228409, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 283, train_loss = 1.8442878276109695, train_acc = 0.9947601304145319\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 284, train_loss = 1.8494074319896754, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 285, train_loss = 1.8613507573900279, train_acc = 0.9946436888681882\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 286, train_loss = 1.850393964588875, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 287, train_loss = 1.8590173199772835, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 288, train_loss = 1.861555103212595, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 289, train_loss = 1.8454634919762611, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "16th- epoch: 290, train_loss = 1.849433214723831, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 291, train_loss = 1.8613466322422028, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 292, train_loss = 1.8500559652748052, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 293, train_loss = 1.8500905310211238, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 294, train_loss = 1.8582509545085486, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 295, train_loss = 1.8433739356696606, train_acc = 0.9947601304145319\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 296, train_loss = 1.840862629323965, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 297, train_loss = 1.8503017723560333, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 298, train_loss = 1.8561276955006178, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 299, train_loss = 1.8305398995580617, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 300, train_loss = 1.84335732832551, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 301, train_loss = 1.8476350866258144, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 302, train_loss = 1.835709157079691, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 303, train_loss = 1.837781485170126, train_acc = 0.9945272473218444\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 304, train_loss = 1.845601753651863, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 305, train_loss = 1.839956782758236, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 306, train_loss = 1.837713116168743, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 307, train_loss = 1.8314014822244644, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 308, train_loss = 1.8398399017751217, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 309, train_loss = 1.8457424926164094, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 310, train_loss = 1.8332490610482637, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 311, train_loss = 1.832488498330349, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 312, train_loss = 1.8416692701575812, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 313, train_loss = 1.8280376332404558, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 314, train_loss = 1.8342844670114573, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 315, train_loss = 1.8308367294666823, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 316, train_loss = 1.8311452393827494, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "16th- epoch: 317, train_loss = 1.8299239166080952, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 318, train_loss = 1.8415063607099, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 319, train_loss = 1.8296621441841125, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 320, train_loss = 1.8355088420212269, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 321, train_loss = 1.8265574127435684, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 322, train_loss = 1.839457313210005, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 323, train_loss = 1.8291866096260492, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 324, train_loss = 1.8304516201314982, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 325, train_loss = 1.8250057312252466, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 326, train_loss = 1.8268790269794408, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 327, train_loss = 1.8309424122271594, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 328, train_loss = 1.8219782300293446, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 329, train_loss = 1.8345518546702806, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 330, train_loss = 1.8300494104623795, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 331, train_loss = 1.8189316702482756, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 332, train_loss = 1.8220873984100763, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 333, train_loss = 1.8232594070432242, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 334, train_loss = 1.819517937808996, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 335, train_loss = 1.8292747946979944, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 336, train_loss = 1.8198798385856207, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 337, train_loss = 1.8327037605049554, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 338, train_loss = 1.8319780826568604, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 339, train_loss = 1.8126881532371044, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 340, train_loss = 1.817501983285183, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 341, train_loss = 1.8288902007043362, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 342, train_loss = 1.8115795440971851, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 343, train_loss = 1.8162668111326639, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 344, train_loss = 1.8108291663229465, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "16th- epoch: 345, train_loss = 1.8131807446479797, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 346, train_loss = 1.830338461935753, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 347, train_loss = 1.8256089724600315, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 348, train_loss = 1.8083147145807743, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 349, train_loss = 1.8195870431663934, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 350, train_loss = 1.8148423172533512, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 351, train_loss = 1.8253383412957191, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 352, train_loss = 1.8274787502887193, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 353, train_loss = 1.8047558503749315, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 354, train_loss = 1.806647996098036, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 355, train_loss = 1.8109155049023684, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 356, train_loss = 1.814605452120304, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 357, train_loss = 1.804896709829336, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 358, train_loss = 1.8230340418813284, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 359, train_loss = 1.812301181256771, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 360, train_loss = 1.813085574656725, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 361, train_loss = 1.8000067087414209, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 362, train_loss = 1.8031704475579318, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 363, train_loss = 1.8069109842181206, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 364, train_loss = 1.8027976540324744, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 365, train_loss = 1.8236526884138584, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 366, train_loss = 1.8000714716908988, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 367, train_loss = 1.8125835421087686, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 368, train_loss = 1.797210401535267, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 369, train_loss = 1.8112156825663988, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 370, train_loss = 1.8026169314980507, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 371, train_loss = 1.8146721422672272, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 372, train_loss = 1.7962448249163572, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 373, train_loss = 1.8076026687922422, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 374, train_loss = 1.8033777090313379, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 375, train_loss = 1.8113458218576852, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 376, train_loss = 1.800089530646801, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 377, train_loss = 1.7972488341329154, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 378, train_loss = 1.7961470521986485, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 379, train_loss = 1.7940038243832532, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 380, train_loss = 1.8089742114098044, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 381, train_loss = 1.789790923387045, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 382, train_loss = 1.7920749535260256, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 383, train_loss = 1.8102125426084967, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 384, train_loss = 1.7968276527972193, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 385, train_loss = 1.7853022279741708, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 386, train_loss = 1.8022512694296893, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 387, train_loss = 1.7944758646190166, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 388, train_loss = 1.801764694348094, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 389, train_loss = 1.7872497240750818, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 390, train_loss = 1.7883623664674815, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 391, train_loss = 1.7935290883033304, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 392, train_loss = 1.7883360224514036, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "16th- epoch: 393, train_loss = 1.796239191040513, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 394, train_loss = 1.793110144630191, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 395, train_loss = 1.7917117712349864, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 396, train_loss = 1.7859520937054185, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 397, train_loss = 1.7923336612730054, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 398, train_loss = 1.7824740943760844, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 399, train_loss = 1.7944627987890271, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 400, train_loss = 1.793528729423997, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 401, train_loss = 1.7779038436710835, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 402, train_loss = 1.7939393942506285, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 403, train_loss = 1.7770888855011435, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 404, train_loss = 1.7807777300477028, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 405, train_loss = 1.7877159900963306, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 406, train_loss = 1.7939708878548117, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 407, train_loss = 1.7786493487656116, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 408, train_loss = 1.7912628203630447, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 409, train_loss = 1.7754948611109285, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 410, train_loss = 1.787541899830103, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 411, train_loss = 1.774591151624918, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 412, train_loss = 1.7908806701452704, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 413, train_loss = 1.7688535216002492, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 414, train_loss = 1.7878634917287854, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 415, train_loss = 1.7709655115904752, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 416, train_loss = 1.7976253678352805, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 417, train_loss = 1.770617383212084, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 418, train_loss = 1.78991524502635, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 419, train_loss = 1.7805900983512402, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 420, train_loss = 1.7769704933016328, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 421, train_loss = 1.7804719594569178, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 422, train_loss = 1.7684259787201881, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 423, train_loss = 1.7797896924166707, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 424, train_loss = 1.7694461743085412, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 425, train_loss = 1.7795283521263627, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 426, train_loss = 1.7818960112781497, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 427, train_loss = 1.7785095050930977, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 428, train_loss = 1.7851589135825634, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 429, train_loss = 1.7657886582164792, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 430, train_loss = 1.7746878613979788, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 431, train_loss = 1.7714165598154068, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 432, train_loss = 1.7782912303955527, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 433, train_loss = 1.7589467229990987, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 434, train_loss = 1.7824958289711503, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 435, train_loss = 1.7583815852849511, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 436, train_loss = 1.7777020608336898, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 437, train_loss = 1.7766722192318412, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 438, train_loss = 1.7564608504326316, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 439, train_loss = 1.7748384475708008, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 440, train_loss = 1.772807468965766, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 441, train_loss = 1.758689289286849, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 442, train_loss = 1.7725406649260549, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 443, train_loss = 1.7702681769878836, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 444, train_loss = 1.7570960223674774, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 445, train_loss = 1.7718344777822495, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 446, train_loss = 1.7687298357486725, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 447, train_loss = 1.7627825612871675, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 448, train_loss = 1.755540871366975, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 449, train_loss = 1.7710603177547455, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 450, train_loss = 1.750707829996827, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 451, train_loss = 1.7674084044992924, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 452, train_loss = 1.7536395813076524, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 453, train_loss = 1.7684656071214704, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 454, train_loss = 1.761060973003623, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 455, train_loss = 1.7510444410145283, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 456, train_loss = 1.7724479921162128, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 457, train_loss = 1.745001399263856, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 458, train_loss = 1.7657822519540787, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 459, train_loss = 1.74520084883261, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 460, train_loss = 1.7720892168581486, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 461, train_loss = 1.7451647147536278, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 462, train_loss = 1.7686051651835442, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 463, train_loss = 1.7627832889556885, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 464, train_loss = 1.7428011770098237, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 465, train_loss = 1.7609141270368127, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 466, train_loss = 1.7409946409316035, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 467, train_loss = 1.7569537249655696, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 468, train_loss = 1.7410632545797853, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 469, train_loss = 1.7588111199438572, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 470, train_loss = 1.7394602162094088, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 471, train_loss = 1.7575285409839125, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 472, train_loss = 1.757001115634921, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 473, train_loss = 1.7406675616948633, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 474, train_loss = 1.7592658624053001, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 475, train_loss = 1.7567979370505782, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 476, train_loss = 1.7359977612941293, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 477, train_loss = 1.752641371145728, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 478, train_loss = 1.7496353425085545, train_acc = 0.9945272473218444\n",
      "test Acc 0.9725325884543762:\n",
      "16th- epoch: 479, train_loss = 1.740053648754838, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 480, train_loss = 1.7516070542187663, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 481, train_loss = 1.7538297225983115, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 482, train_loss = 1.7354008220136166, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 483, train_loss = 1.7418797078280477, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 484, train_loss = 1.7556193520576926, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 485, train_loss = 1.7370630204677582, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 486, train_loss = 1.7522141349763842, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 487, train_loss = 1.7416349935083417, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 488, train_loss = 1.7384270280599594, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 489, train_loss = 1.750008575618267, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 490, train_loss = 1.7303814714105101, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 491, train_loss = 1.743076046303031, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 492, train_loss = 1.728878262147191, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 493, train_loss = 1.7456797994673252, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 494, train_loss = 1.726921649024007, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 495, train_loss = 1.7434680213482352, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 496, train_loss = 1.737874326601741, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 497, train_loss = 1.7412731523363618, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 498, train_loss = 1.72999972353864, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 499, train_loss = 1.741414651274681, train_acc = 0.9945272473218444\n",
      "test Acc 0.9720670391061452:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|████████████████████████████████████████▌                                   | 16/30 [2:34:13<2:24:08, 617.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "17th- epoch: 0, train_loss = 292.98865822236985, train_acc = 0.8266185374941779\n",
      "test Acc 0.9124767225325885:\n",
      "17th- epoch: 1, train_loss = 63.93983721267432, train_acc = 0.9230321378667908\n",
      "test Acc 0.9250465549348231:\n",
      "17th- epoch: 2, train_loss = 41.46945659653284, train_acc = 0.9439916162086632\n",
      "test Acc 0.9324953445065177:\n",
      "17th- epoch: 3, train_loss = 31.1806959817186, train_acc = 0.9540055891942245\n",
      "test Acc 0.9413407821229051:\n",
      "17th- epoch: 4, train_loss = 25.298961067572236, train_acc = 0.9607591988821611\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 5, train_loss = 21.353945114649832, train_acc = 0.9655333022822543\n",
      "test Acc 0.9534450651769087:\n",
      "17th- epoch: 6, train_loss = 18.19879479147494, train_acc = 0.9693758733115976\n",
      "test Acc 0.9562383612662942:\n",
      "17th- epoch: 7, train_loss = 15.805931423325092, train_acc = 0.9726362366092222\n",
      "test Acc 0.957169459962756:\n",
      "17th- epoch: 8, train_loss = 13.815535222180188, train_acc = 0.9750815090824406\n",
      "test Acc 0.9562383612662942:\n",
      "17th- epoch: 9, train_loss = 12.323646095581353, train_acc = 0.975780158360503\n",
      "test Acc 0.9562383612662942:\n",
      "17th- epoch: 10, train_loss = 11.112785442266613, train_acc = 0.9782254308337215\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 11, train_loss = 10.051426535472274, train_acc = 0.9789240801117839\n",
      "test Acc 0.9590316573556797:\n",
      "17th- epoch: 12, train_loss = 9.231056287419051, train_acc = 0.9805542617605962\n",
      "test Acc 0.9604283054003724:\n",
      "17th- epoch: 13, train_loss = 8.531334365485236, train_acc = 0.9821844434094085\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 14, train_loss = 7.970078090205789, train_acc = 0.9827666511411272\n",
      "test Acc 0.9567039106145251:\n",
      "17th- epoch: 15, train_loss = 7.461535747162998, train_acc = 0.984163949697252\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 16, train_loss = 7.040504236472771, train_acc = 0.9850954820680019\n",
      "test Acc 0.957635009310987:\n",
      "17th- epoch: 17, train_loss = 6.6556123197078705, train_acc = 0.9862598975314392\n",
      "test Acc 0.957635009310987:\n",
      "17th- epoch: 18, train_loss = 6.304776692762971, train_acc = 0.9862598975314392\n",
      "test Acc 0.9567039106145251:\n",
      "17th- epoch: 19, train_loss = 6.017469447106123, train_acc = 0.9867256637168141\n",
      "test Acc 0.957635009310987:\n",
      "17th- epoch: 20, train_loss = 5.75334096304141, train_acc = 0.9869585468095017\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 21, train_loss = 5.4906989799346775, train_acc = 0.9873078714485328\n",
      "test Acc 0.9585661080074488:\n",
      "17th- epoch: 22, train_loss = 5.286177959060296, train_acc = 0.9877736376339078\n",
      "test Acc 0.9594972067039106:\n",
      "17th- epoch: 23, train_loss = 5.069700521649793, train_acc = 0.9883558453656265\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 24, train_loss = 4.889502909267321, train_acc = 0.9885887284583139\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 25, train_loss = 4.733353201067075, train_acc = 0.9888216115510013\n",
      "test Acc 0.962756052141527:\n",
      "17th- epoch: 26, train_loss = 4.588756551966071, train_acc = 0.9892873777363763\n",
      "test Acc 0.9632216014897579:\n",
      "17th- epoch: 27, train_loss = 4.446327116107568, train_acc = 0.9897531439217513\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 28, train_loss = 4.339507295982912, train_acc = 0.989869585468095\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 29, train_loss = 4.231872430304065, train_acc = 0.99033535165347\n",
      "test Acc 0.9646182495344506:\n",
      "17th- epoch: 30, train_loss = 4.143354483414441, train_acc = 0.9904517931998137\n",
      "test Acc 0.9636871508379888:\n",
      "17th- epoch: 31, train_loss = 4.046889893244952, train_acc = 0.9904517931998137\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 32, train_loss = 3.965028571896255, train_acc = 0.9904517931998137\n",
      "test Acc 0.9650837988826816:\n",
      "17th- epoch: 33, train_loss = 3.9006598497508094, train_acc = 0.9906846762925011\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 34, train_loss = 3.810793535434641, train_acc = 0.9909175593851887\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 35, train_loss = 3.7448681644164026, train_acc = 0.9909175593851887\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 36, train_loss = 3.6898915325291455, train_acc = 0.9910340009315324\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 37, train_loss = 3.6239044734975323, train_acc = 0.9911504424778761\n",
      "test Acc 0.9655493482309124:\n",
      "17th- epoch: 38, train_loss = 3.563831653096713, train_acc = 0.9913833255705635\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 39, train_loss = 3.522809016169049, train_acc = 0.9913833255705635\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 40, train_loss = 3.4592950167134404, train_acc = 0.9917326502095948\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 41, train_loss = 3.41886342165526, train_acc = 0.9917326502095948\n",
      "test Acc 0.9669459962756052:\n",
      "17th- epoch: 42, train_loss = 3.3845641459338367, train_acc = 0.9918490917559385\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 43, train_loss = 3.3415893837809563, train_acc = 0.9919655333022822\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 44, train_loss = 3.3154528556624427, train_acc = 0.9918490917559385\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 45, train_loss = 3.290807525976561, train_acc = 0.9919655333022822\n",
      "test Acc 0.9678770949720671:\n",
      "17th- epoch: 46, train_loss = 3.2503343537682667, train_acc = 0.9919655333022822\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 47, train_loss = 3.2223780496278778, train_acc = 0.992081974848626\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 48, train_loss = 3.1851947923423722, train_acc = 0.9921984163949698\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 49, train_loss = 3.1654159746831283, train_acc = 0.9924312994876572\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 50, train_loss = 3.1318078170297667, train_acc = 0.9925477410340009\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 51, train_loss = 3.1078666135435924, train_acc = 0.9925477410340009\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 52, train_loss = 3.0748052849667147, train_acc = 0.9927806241266884\n",
      "test Acc 0.9683426443202979:\n",
      "17th- epoch: 53, train_loss = 3.050789290224202, train_acc = 0.9927806241266884\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 54, train_loss = 3.0197901158826426, train_acc = 0.9927806241266884\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 55, train_loss = 3.004058279795572, train_acc = 0.9927806241266884\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 56, train_loss = 2.976729075773619, train_acc = 0.9927806241266884\n",
      "test Acc 0.9692737430167597:\n",
      "17th- epoch: 57, train_loss = 2.9547862687613815, train_acc = 0.9927806241266884\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 58, train_loss = 2.9385078746126965, train_acc = 0.9927806241266884\n",
      "test Acc 0.9702048417132216:\n",
      "17th- epoch: 59, train_loss = 2.9144364242674783, train_acc = 0.9928970656730322\n",
      "test Acc 0.9697392923649907:\n",
      "17th- epoch: 60, train_loss = 2.882949100458063, train_acc = 0.9927806241266884\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 61, train_loss = 2.8753368832403794, train_acc = 0.9927806241266884\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 62, train_loss = 2.8565361975925043, train_acc = 0.9927806241266884\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 63, train_loss = 2.829656463698484, train_acc = 0.9928970656730322\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 64, train_loss = 2.814155342639424, train_acc = 0.9930135072193759\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 65, train_loss = 2.7924355785362422, train_acc = 0.9931299487657196\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 66, train_loss = 2.7790465420112014, train_acc = 0.9930135072193759\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 67, train_loss = 2.767911053262651, train_acc = 0.9930135072193759\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 68, train_loss = 2.7468596881954, train_acc = 0.9930135072193759\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 69, train_loss = 2.728181562270038, train_acc = 0.9932463903120633\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 70, train_loss = 2.7158819382311776, train_acc = 0.9931299487657196\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 71, train_loss = 2.702765146852471, train_acc = 0.9932463903120633\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 72, train_loss = 2.6827285833423957, train_acc = 0.9933628318584071\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 73, train_loss = 2.6673068123636767, train_acc = 0.9932463903120633\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 74, train_loss = 2.65246959857177, train_acc = 0.9932463903120633\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 75, train_loss = 2.637283570948057, train_acc = 0.9934792734047508\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 76, train_loss = 2.6238466883078218, train_acc = 0.9934792734047508\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 77, train_loss = 2.61104751995299, train_acc = 0.9933628318584071\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 78, train_loss = 2.5958575018448755, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 79, train_loss = 2.5814922691788524, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 80, train_loss = 2.571358761168085, train_acc = 0.9934792734047508\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 81, train_loss = 2.5590012843022123, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 82, train_loss = 2.5499621813651174, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 83, train_loss = 2.5399683703435585, train_acc = 0.9935957149510946\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 84, train_loss = 2.5251865525497124, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 85, train_loss = 2.5131437645759434, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 86, train_loss = 2.5040462982142344, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 87, train_loss = 2.496684854850173, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 88, train_loss = 2.480855434667319, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 89, train_loss = 2.469542744802311, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 90, train_loss = 2.457140540354885, train_acc = 0.9937121564974383\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 91, train_loss = 2.4504111855058, train_acc = 0.9934792734047508\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 92, train_loss = 2.4397721145069227, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 93, train_loss = 2.4397007004590705, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 94, train_loss = 2.4235943079693243, train_acc = 0.9935957149510946\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 95, train_loss = 2.4177786672953516, train_acc = 0.9937121564974383\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 96, train_loss = 2.4063031441764906, train_acc = 0.9937121564974383\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 97, train_loss = 2.39224250044208, train_acc = 0.9937121564974383\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 98, train_loss = 2.388923153397627, train_acc = 0.9937121564974383\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 99, train_loss = 2.376026805024594, train_acc = 0.9937121564974383\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 100, train_loss = 2.3744453986291774, train_acc = 0.9937121564974383\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 101, train_loss = 2.3601750378729776, train_acc = 0.9937121564974383\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 102, train_loss = 2.3540820711059496, train_acc = 0.9937121564974383\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 103, train_loss = 2.3418384697288275, train_acc = 0.9937121564974383\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 104, train_loss = 2.3387447195127606, train_acc = 0.9937121564974383\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 105, train_loss = 2.3289294678834267, train_acc = 0.993828598043782\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 106, train_loss = 2.324577953084372, train_acc = 0.993828598043782\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 107, train_loss = 2.3176392152090557, train_acc = 0.9937121564974383\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 108, train_loss = 2.3069123892346397, train_acc = 0.993828598043782\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 109, train_loss = 2.302990023687016, train_acc = 0.9937121564974383\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 110, train_loss = 2.2920749193872325, train_acc = 0.9939450395901258\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 111, train_loss = 2.2889649957651272, train_acc = 0.9939450395901258\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 112, train_loss = 2.2880438758875243, train_acc = 0.993828598043782\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 113, train_loss = 2.27910681423964, train_acc = 0.9939450395901258\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 114, train_loss = 2.2720395388896577, train_acc = 0.993828598043782\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 115, train_loss = 2.265541079279501, train_acc = 0.9940614811364695\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 116, train_loss = 2.25784402404679, train_acc = 0.9940614811364695\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 117, train_loss = 2.250989198044408, train_acc = 0.9939450395901258\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 118, train_loss = 2.2475331338937394, train_acc = 0.9939450395901258\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 119, train_loss = 2.239842915441841, train_acc = 0.9939450395901258\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 120, train_loss = 2.2385934689082205, train_acc = 0.9939450395901258\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 121, train_loss = 2.225501604087185, train_acc = 0.9940614811364695\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 122, train_loss = 2.2211863597040065, train_acc = 0.993828598043782\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 123, train_loss = 2.2232221541926265, train_acc = 0.9940614811364695\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 124, train_loss = 2.216428992105648, train_acc = 0.9939450395901258\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 125, train_loss = 2.206990258942824, train_acc = 0.9941779226828132\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 126, train_loss = 2.202547427790705, train_acc = 0.9940614811364695\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 127, train_loss = 2.200140523724258, train_acc = 0.9940614811364695\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 128, train_loss = 2.1988757217186503, train_acc = 0.9940614811364695\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 129, train_loss = 2.189850367780309, train_acc = 0.9941779226828132\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 130, train_loss = 2.1889059678069316, train_acc = 0.9941779226828132\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 131, train_loss = 2.1830381967592984, train_acc = 0.9941779226828132\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 132, train_loss = 2.1794181605800986, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 133, train_loss = 2.1789665108080953, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 134, train_loss = 2.170431804843247, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 135, train_loss = 2.1614543628529646, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "17th- epoch: 136, train_loss = 2.1606347079505213, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 137, train_loss = 2.162733654724434, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 138, train_loss = 2.1592686039512046, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 139, train_loss = 2.151587610889692, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 140, train_loss = 2.152763204067014, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 141, train_loss = 2.1442789512802847, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 142, train_loss = 2.142373470356688, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 143, train_loss = 2.134479599946644, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 144, train_loss = 2.13511437503621, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 145, train_loss = 2.1274620383046567, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 146, train_loss = 2.1283099607098848, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 147, train_loss = 2.118578997149598, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "17th- epoch: 148, train_loss = 2.121727985853795, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 149, train_loss = 2.1126195382676087, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 150, train_loss = 2.113797319412697, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 151, train_loss = 2.1074536502710544, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 152, train_loss = 2.1047268735128455, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 153, train_loss = 2.106665683852043, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 154, train_loss = 2.0994189421180636, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 155, train_loss = 2.098206005990505, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 156, train_loss = 2.0957731569069438, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 157, train_loss = 2.090033116575796, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 158, train_loss = 2.093524852709379, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 159, train_loss = 2.087552140292246, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 160, train_loss = 2.084167755849194, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 161, train_loss = 2.0798388515249826, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 162, train_loss = 2.0816972837783396, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 163, train_loss = 2.0772308749728836, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 164, train_loss = 2.074625816429034, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 165, train_loss = 2.0729656449402682, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 166, train_loss = 2.0681077670305967, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 167, train_loss = 2.0690769671928138, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 168, train_loss = 2.065784006146714, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 169, train_loss = 2.0616181630757637, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 170, train_loss = 2.0639121388667263, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 171, train_loss = 2.057761434582062, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 172, train_loss = 2.0577648275648244, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 173, train_loss = 2.054219462152105, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 174, train_loss = 2.0538963605067693, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 175, train_loss = 2.051551594864577, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 176, train_loss = 2.045923194498755, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 177, train_loss = 2.0477155172848143, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 178, train_loss = 2.0407192010316066, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 179, train_loss = 2.039763846027199, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 180, train_loss = 2.0435812521609478, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 181, train_loss = 2.036916228593327, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 182, train_loss = 2.035678662417922, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 183, train_loss = 2.0365829071379267, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 184, train_loss = 2.0333578278659843, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 185, train_loss = 2.0270426911883987, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 186, train_loss = 2.0226844211574644, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 187, train_loss = 2.028259392187465, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 188, train_loss = 2.0218677117372863, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 189, train_loss = 2.025154671689961, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 190, train_loss = 2.0175634268671274, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 191, train_loss = 2.0212657414958812, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 192, train_loss = 2.0159148680977523, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 193, train_loss = 2.0186671945266426, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 194, train_loss = 2.010923217632808, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 195, train_loss = 2.0123448951053433, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 196, train_loss = 2.0082673571887426, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 197, train_loss = 2.010824215831235, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 198, train_loss = 2.0057600663858466, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 199, train_loss = 2.0034695714130066, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 200, train_loss = 2.008704424544703, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 201, train_loss = 2.004523051145952, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 202, train_loss = 2.0013121186057106, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 203, train_loss = 2.000065694155637, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 204, train_loss = 1.9977642624289729, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 205, train_loss = 1.9990054630325176, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 206, train_loss = 1.9927432173280977, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 207, train_loss = 1.9924707941827364, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 208, train_loss = 1.9973187198047526, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 209, train_loss = 1.9923916445695795, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 210, train_loss = 1.9895789818838239, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 211, train_loss = 1.9890707963495515, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 212, train_loss = 1.9892527991905808, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 213, train_loss = 1.9857937329798006, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 214, train_loss = 1.9816704847034998, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 215, train_loss = 1.9846898619434796, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 216, train_loss = 1.9818800195935182, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 217, train_loss = 1.975062615936622, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 218, train_loss = 1.975656496360898, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 219, train_loss = 1.9764482148457319, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 220, train_loss = 1.9794898657128215, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 221, train_loss = 1.9731822208850645, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 222, train_loss = 1.9708849860471673, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 223, train_loss = 1.9715398920234293, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 224, train_loss = 1.9727670498541556, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 225, train_loss = 1.9675437476835214, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 226, train_loss = 1.9710547598660924, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 227, train_loss = 1.9613536382676102, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 228, train_loss = 1.9644520791480318, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 229, train_loss = 1.9650644860812463, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 230, train_loss = 1.9648440798628144, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 231, train_loss = 1.9596371538937092, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 232, train_loss = 1.9597689757938497, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 233, train_loss = 1.9583952617831528, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 234, train_loss = 1.9542813510051928, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 235, train_loss = 1.9587230328470469, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 236, train_loss = 1.9528094237321056, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 237, train_loss = 1.9535434155841358, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 238, train_loss = 1.950262070633471, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 239, train_loss = 1.9529833428678103, train_acc = 0.9945272473218444\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 240, train_loss = 1.9463343496900052, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 241, train_loss = 1.9531144045758992, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 242, train_loss = 1.951273120706901, train_acc = 0.9944108057755007\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 243, train_loss = 1.9459048669668846, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 244, train_loss = 1.9477460330235772, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 245, train_loss = 1.9442018708214164, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 246, train_loss = 1.9438871014281176, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 247, train_loss = 1.9396501525770873, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 248, train_loss = 1.939162696013227, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 249, train_loss = 1.945176029810682, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 250, train_loss = 1.9406179076177068, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 251, train_loss = 1.9339250687044114, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 252, train_loss = 1.9366086437366903, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 253, train_loss = 1.9351683611457702, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 254, train_loss = 1.935956610366702, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 255, train_loss = 1.9359172461554408, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 256, train_loss = 1.9298096052370965, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 257, train_loss = 1.931545663945144, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 258, train_loss = 1.9304313380271196, train_acc = 0.9947601304145319\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 259, train_loss = 1.9281461751961615, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 260, train_loss = 1.924776087194914, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 261, train_loss = 1.9295534128323197, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 262, train_loss = 1.9255724676477257, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 263, train_loss = 1.9259123037045356, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 264, train_loss = 1.9286910826340318, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 265, train_loss = 1.921709919348359, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 266, train_loss = 1.9214944476261735, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 267, train_loss = 1.920108971040463, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 268, train_loss = 1.9156860880029853, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 269, train_loss = 1.9201459259202238, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 270, train_loss = 1.9187417550419923, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 271, train_loss = 1.9177823291684035, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 272, train_loss = 1.9160712195152882, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 273, train_loss = 1.9176684031262994, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 274, train_loss = 1.9150945640576538, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 275, train_loss = 1.9112054856086615, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 276, train_loss = 1.9160158779995982, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 277, train_loss = 1.912590147316223, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 278, train_loss = 1.9084873932006303, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 279, train_loss = 1.9091914614255074, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 280, train_loss = 1.907107916806126, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 281, train_loss = 1.9084782949648798, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 282, train_loss = 1.905946825951105, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 283, train_loss = 1.9099625071976334, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 284, train_loss = 1.9102914108370896, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 285, train_loss = 1.8995896132255439, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 286, train_loss = 1.907929439097643, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 287, train_loss = 1.906369142147014, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 288, train_loss = 1.9026619509386364, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 289, train_loss = 1.9040572225057986, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 290, train_loss = 1.904919555730885, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 291, train_loss = 1.8981694631220307, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 292, train_loss = 1.9055522467533592, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 293, train_loss = 1.9024747968651354, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 294, train_loss = 1.893953099148348, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 295, train_loss = 1.9003253105038311, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 296, train_loss = 1.8979483769799117, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 297, train_loss = 1.8931667736324016, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 298, train_loss = 1.899620085634524, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 299, train_loss = 1.8920953293854836, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 300, train_loss = 1.8935096549394075, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 301, train_loss = 1.887480287143262, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 302, train_loss = 1.8916869686509017, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 303, train_loss = 1.8876332713698503, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 304, train_loss = 1.8901509001443628, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 305, train_loss = 1.8904104198736604, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 306, train_loss = 1.8865064885176253, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 307, train_loss = 1.8859609588689636, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 308, train_loss = 1.887390512303682, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 309, train_loss = 1.8877004055539146, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 310, train_loss = 1.888578048121417, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 311, train_loss = 1.8854316794604529, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 312, train_loss = 1.8860920556762721, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 313, train_loss = 1.8803326544584706, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 314, train_loss = 1.874679740954889, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 315, train_loss = 1.881024739384884, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 316, train_loss = 1.8749907570017967, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 317, train_loss = 1.8798161875456572, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 318, train_loss = 1.8804219873563852, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 319, train_loss = 1.8787876787537243, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 320, train_loss = 1.877032746822806, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 321, train_loss = 1.8722748481377494, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 322, train_loss = 1.8728397082013544, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 323, train_loss = 1.866048623691313, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 324, train_loss = 1.8755038653034717, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 325, train_loss = 1.8702602983394172, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 326, train_loss = 1.8694254104048014, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 327, train_loss = 1.8709844738186803, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 328, train_loss = 1.867712526669493, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 329, train_loss = 1.8651938051916659, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 330, train_loss = 1.873657332820585, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 331, train_loss = 1.8695325190201402, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 332, train_loss = 1.8667168854444753, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 333, train_loss = 1.866162550606532, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 334, train_loss = 1.8675414628814906, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 335, train_loss = 1.8651810752635356, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 336, train_loss = 1.8619955685862806, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 337, train_loss = 1.8695205714611802, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 338, train_loss = 1.8655516362341587, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 339, train_loss = 1.861596875358373, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 340, train_loss = 1.8585165465192404, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 341, train_loss = 1.8631304424488917, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 342, train_loss = 1.8627538409491535, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 343, train_loss = 1.8583448690769728, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 344, train_loss = 1.8567722827428952, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 345, train_loss = 1.857225302635925, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 346, train_loss = 1.8634149797726423, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 347, train_loss = 1.8581853631185368, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 348, train_loss = 1.8560138133761939, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 349, train_loss = 1.8497545473219361, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 350, train_loss = 1.8534000203071628, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 351, train_loss = 1.8544132445240393, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 352, train_loss = 1.8580667765345424, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 353, train_loss = 1.8515693071240094, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 354, train_loss = 1.8495550123043358, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 355, train_loss = 1.8560867489140946, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 356, train_loss = 1.858823600661708, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 357, train_loss = 1.8507320774078835, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 358, train_loss = 1.8497358746826649, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 359, train_loss = 1.8450729347823653, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 360, train_loss = 1.8492895763774868, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 361, train_loss = 1.8447965804080013, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 362, train_loss = 1.8467707697709557, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 363, train_loss = 1.8519586510956287, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 364, train_loss = 1.8487967585970182, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 365, train_loss = 1.846852485643467, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 366, train_loss = 1.843177751667099, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 367, train_loss = 1.8446478678379208, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 368, train_loss = 1.8436554552754387, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 369, train_loss = 1.844463389570592, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 370, train_loss = 1.840414499718463, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 371, train_loss = 1.8375544374866877, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 372, train_loss = 1.8441211390017997, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 373, train_loss = 1.8415489915932994, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 374, train_loss = 1.8396458320785314, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 375, train_loss = 1.8414802224142477, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 376, train_loss = 1.8367038975993637, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 377, train_loss = 1.8324400540732313, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 378, train_loss = 1.8399651526997332, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 379, train_loss = 1.8414091592421755, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 380, train_loss = 1.8399661769217346, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 381, train_loss = 1.8344666350167245, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 382, train_loss = 1.8336012102663517, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 383, train_loss = 1.836381975794211, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 384, train_loss = 1.8333075324480888, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 385, train_loss = 1.827457776904339, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 386, train_loss = 1.8282685518206563, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 387, train_loss = 1.8328707228356507, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 388, train_loss = 1.8330056038685143, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 389, train_loss = 1.8280130602943245, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 390, train_loss = 1.8232894481625408, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 391, train_loss = 1.8295064267294947, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 392, train_loss = 1.8253185836656485, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 393, train_loss = 1.8239226314763073, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 394, train_loss = 1.8228123041335493, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 395, train_loss = 1.8239337347040419, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 396, train_loss = 1.8218106500280555, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 397, train_loss = 1.8253992857935373, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 398, train_loss = 1.8294598824868444, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 399, train_loss = 1.8241119089943822, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 400, train_loss = 1.8232580055482686, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 401, train_loss = 1.8228068591561168, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 402, train_loss = 1.8229028536006808, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 403, train_loss = 1.8148569893091917, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 404, train_loss = 1.816499613079941, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 405, train_loss = 1.8248814955877606, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 406, train_loss = 1.814256902463967, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 407, train_loss = 1.814094053581357, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 408, train_loss = 1.8089030049741268, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 409, train_loss = 1.810657573863864, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 410, train_loss = 1.8143598278984427, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 411, train_loss = 1.817823016695911, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 412, train_loss = 1.8122118247265462, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 413, train_loss = 1.8107260381802917, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 414, train_loss = 1.819121248088777, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 415, train_loss = 1.8145885107514914, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 416, train_loss = 1.8172339336015284, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 417, train_loss = 1.8127762464282569, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 418, train_loss = 1.8080385527573526, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 419, train_loss = 1.8086632865888532, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 420, train_loss = 1.8086415828729514, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 421, train_loss = 1.8153837146237493, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 422, train_loss = 1.8084228009392973, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 423, train_loss = 1.8074882129731122, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 424, train_loss = 1.8073319969698787, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 425, train_loss = 1.81089670304209, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 426, train_loss = 1.8059555896033999, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 427, train_loss = 1.8056437196210027, train_acc = 0.9948765719608756\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 428, train_loss = 1.805791990220314, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 429, train_loss = 1.8068829184339847, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 430, train_loss = 1.806163371540606, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 431, train_loss = 1.8053253393154591, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 432, train_loss = 1.803354822419351, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 433, train_loss = 1.8041334142908454, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 434, train_loss = 1.8026562446320895, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 435, train_loss = 1.8024715696519706, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 436, train_loss = 1.8011397681257222, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 437, train_loss = 1.802346798358485, train_acc = 0.9948765719608756\n",
      "test Acc 0.973463687150838:\n",
      "17th- epoch: 438, train_loss = 1.8036290127784014, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 439, train_loss = 1.8012369499483611, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 440, train_loss = 1.8000438385643065, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 441, train_loss = 1.799957040231675, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 442, train_loss = 1.8025281446462031, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 443, train_loss = 1.7995770131237805, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 444, train_loss = 1.8017069927009288, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 445, train_loss = 1.7998941425175872, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 446, train_loss = 1.7975710027385503, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 447, train_loss = 1.7955193940142635, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 448, train_loss = 1.7956291242444422, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 449, train_loss = 1.793630861589918, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 450, train_loss = 1.795029394183075, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 451, train_loss = 1.7925437341909856, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 452, train_loss = 1.794133338611573, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 453, train_loss = 1.7923629072029144, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 454, train_loss = 1.7888323222287, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 455, train_loss = 1.796280207723612, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 456, train_loss = 1.7919005970470607, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 457, train_loss = 1.7903604780731257, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 458, train_loss = 1.7821062538714614, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 459, train_loss = 1.7866637279221322, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 460, train_loss = 1.7833757532353047, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 461, train_loss = 1.7842674613930285, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 462, train_loss = 1.7907898795383517, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 463, train_loss = 1.785265982762212, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 464, train_loss = 1.78561978469952, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 465, train_loss = 1.7850324241444468, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 466, train_loss = 1.7838178743550088, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 467, train_loss = 1.7869462495145854, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 468, train_loss = 1.781077237566933, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 469, train_loss = 1.778567174449563, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 470, train_loss = 1.779485662089428, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 471, train_loss = 1.7811314756982028, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 472, train_loss = 1.7775812793988734, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 473, train_loss = 1.779964149085572, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 474, train_loss = 1.7822638043144252, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 475, train_loss = 1.787317377369618, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 476, train_loss = 1.7749351823295, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 477, train_loss = 1.7756950012408197, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 478, train_loss = 1.7752654937503394, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 479, train_loss = 1.7789691594953183, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 480, train_loss = 1.7743398548627738, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 481, train_loss = 1.7732156184501946, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 482, train_loss = 1.7704303052742034, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 483, train_loss = 1.7770017257425934, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 484, train_loss = 1.7718591505399672, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 485, train_loss = 1.7696450646035373, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 486, train_loss = 1.7697415333241224, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 487, train_loss = 1.7741421967948554, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 488, train_loss = 1.774139472283423, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 489, train_loss = 1.7745638258493273, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 490, train_loss = 1.7687154966406524, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 491, train_loss = 1.7680603876506211, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 492, train_loss = 1.7690142387727974, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 493, train_loss = 1.7687062601034995, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 494, train_loss = 1.7702816217206419, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 495, train_loss = 1.7688941257074475, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 496, train_loss = 1.7677399019448785, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 497, train_loss = 1.7634237258025678, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 498, train_loss = 1.7660615586210042, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 499, train_loss = 1.7648750354273943, train_acc = 0.9948765719608756\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|███████████████████████████████████████████                                 | 17/30 [2:44:40<2:14:25, 620.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "18th- epoch: 0, train_loss = 375.77528831362724, train_acc = 0.8047275267815557\n",
      "test Acc 0.8966480446927374:\n",
      "18th- epoch: 1, train_loss = 71.2077845390886, train_acc = 0.9168607359105729\n",
      "test Acc 0.9338919925512105:\n",
      "18th- epoch: 2, train_loss = 44.930069817230105, train_acc = 0.9370051234280391\n",
      "test Acc 0.9292364990689013:\n",
      "18th- epoch: 3, train_loss = 33.10799742490053, train_acc = 0.9486492780624126\n",
      "test Acc 0.9390130353817505:\n",
      "18th- epoch: 4, train_loss = 26.260593216866255, train_acc = 0.9561015370284117\n",
      "test Acc 0.9399441340782123:\n",
      "18th- epoch: 5, train_loss = 21.4653194360435, train_acc = 0.9626222636236609\n",
      "test Acc 0.9455307262569832:\n",
      "18th- epoch: 6, train_loss = 17.96140336431563, train_acc = 0.9675128085700978\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 7, train_loss = 15.557438688352704, train_acc = 0.9712389380530974\n",
      "test Acc 0.9501862197392924:\n",
      "18th- epoch: 8, train_loss = 13.62364193983376, train_acc = 0.9732184443409408\n",
      "test Acc 0.9492551210428305:\n",
      "18th- epoch: 9, train_loss = 12.020962178707123, train_acc = 0.9761294829995343\n",
      "test Acc 0.952513966480447:\n",
      "18th- epoch: 10, train_loss = 10.832283800467849, train_acc = 0.9775267815556591\n",
      "test Acc 0.9534450651769087:\n",
      "18th- epoch: 11, train_loss = 9.867848409339786, train_acc = 0.9795062878435026\n",
      "test Acc 0.9543761638733705:\n",
      "18th- epoch: 12, train_loss = 9.083684980869293, train_acc = 0.9818351187703773\n",
      "test Acc 0.9548417132216015:\n",
      "18th- epoch: 13, train_loss = 8.43740921933204, train_acc = 0.9827666511411272\n",
      "test Acc 0.9557728119180633:\n",
      "18th- epoch: 14, train_loss = 7.879717320203781, train_acc = 0.9839310666045645\n",
      "test Acc 0.9557728119180633:\n",
      "18th- epoch: 15, train_loss = 7.400190140120685, train_acc = 0.9849790405216581\n",
      "test Acc 0.9594972067039106:\n",
      "18th- epoch: 16, train_loss = 6.971363988704979, train_acc = 0.9853283651606893\n",
      "test Acc 0.9599627560521415:\n",
      "18th- epoch: 17, train_loss = 6.57188684027642, train_acc = 0.9862598975314392\n",
      "test Acc 0.9599627560521415:\n",
      "18th- epoch: 18, train_loss = 6.229227043688297, train_acc = 0.9866092221704704\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 19, train_loss = 5.911513020284474, train_acc = 0.9871914299021891\n",
      "test Acc 0.9604283054003724:\n",
      "18th- epoch: 20, train_loss = 5.611827663145959, train_acc = 0.9882394038192828\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 21, train_loss = 5.379615279845893, train_acc = 0.9884722869119702\n",
      "test Acc 0.9613594040968343:\n",
      "18th- epoch: 22, train_loss = 5.169494868256152, train_acc = 0.9888216115510013\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 23, train_loss = 4.959510770626366, train_acc = 0.98940381928272\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 24, train_loss = 4.7767693237401545, train_acc = 0.9896367023754076\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 25, train_loss = 4.608843031339347, train_acc = 0.989869585468095\n",
      "test Acc 0.9632216014897579:\n",
      "18th- epoch: 26, train_loss = 4.467149754520506, train_acc = 0.9901024685607824\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 27, train_loss = 4.341491284314543, train_acc = 0.9904517931998137\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 28, train_loss = 4.232821177691221, train_acc = 0.990801117838845\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 29, train_loss = 4.122137228492647, train_acc = 0.9906846762925011\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 30, train_loss = 4.0183556391857564, train_acc = 0.9910340009315324\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 31, train_loss = 3.9252856611274183, train_acc = 0.9911504424778761\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 32, train_loss = 3.8459618487395346, train_acc = 0.9911504424778761\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 33, train_loss = 3.7649679793976247, train_acc = 0.9912668840242198\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 34, train_loss = 3.69622086500749, train_acc = 0.9916162086632511\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 35, train_loss = 3.6187746920622885, train_acc = 0.9916162086632511\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 36, train_loss = 3.5603321022354066, train_acc = 0.9918490917559385\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 37, train_loss = 3.501930858939886, train_acc = 0.9919655333022822\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 38, train_loss = 3.43314894894138, train_acc = 0.9921984163949698\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 39, train_loss = 3.381613989826292, train_acc = 0.992081974848626\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 40, train_loss = 3.3173351525329053, train_acc = 0.9923148579413135\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 41, train_loss = 3.274422659073025, train_acc = 0.9923148579413135\n",
      "test Acc 0.9646182495344506:\n",
      "18th- epoch: 42, train_loss = 3.208886927459389, train_acc = 0.9925477410340009\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 43, train_loss = 3.1641649776138365, train_acc = 0.9924312994876572\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 44, train_loss = 3.123850216390565, train_acc = 0.9926641825803446\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 45, train_loss = 3.0744615111034364, train_acc = 0.9926641825803446\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 46, train_loss = 3.0616264739073813, train_acc = 0.9926641825803446\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 47, train_loss = 3.010850992053747, train_acc = 0.9927806241266884\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 48, train_loss = 2.9755237188655883, train_acc = 0.9927806241266884\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 49, train_loss = 2.9496991101186723, train_acc = 0.9927806241266884\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 50, train_loss = 2.905844658613205, train_acc = 0.9930135072193759\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 51, train_loss = 2.8832638561725616, train_acc = 0.9927806241266884\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 52, train_loss = 2.8324169751722366, train_acc = 0.9931299487657196\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 53, train_loss = 2.809653203934431, train_acc = 0.9930135072193759\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 54, train_loss = 2.77596827596426, train_acc = 0.9932463903120633\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 55, train_loss = 2.7495186913292855, train_acc = 0.9932463903120633\n",
      "test Acc 0.9650837988826816:\n",
      "18th- epoch: 56, train_loss = 2.7363240856211632, train_acc = 0.9933628318584071\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 57, train_loss = 2.7007961086928844, train_acc = 0.9933628318584071\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 58, train_loss = 2.6723213244695216, train_acc = 0.9934792734047508\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 59, train_loss = 2.643500715494156, train_acc = 0.9933628318584071\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 60, train_loss = 2.6398102592211217, train_acc = 0.9934792734047508\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 61, train_loss = 2.611910543171689, train_acc = 0.9934792734047508\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 62, train_loss = 2.5774340655189008, train_acc = 0.9935957149510946\n",
      "test Acc 0.9655493482309124:\n",
      "18th- epoch: 63, train_loss = 2.5660939142107964, train_acc = 0.9934792734047508\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 64, train_loss = 2.5556802202481776, train_acc = 0.9933628318584071\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 65, train_loss = 2.520242340862751, train_acc = 0.9934792734047508\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 66, train_loss = 2.511337912408635, train_acc = 0.9933628318584071\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 67, train_loss = 2.4855106386821717, train_acc = 0.9933628318584071\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 68, train_loss = 2.484223213046789, train_acc = 0.9934792734047508\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 69, train_loss = 2.4499357901513577, train_acc = 0.9937121564974383\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 70, train_loss = 2.425401246873662, train_acc = 0.9935957149510946\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 71, train_loss = 2.424321076599881, train_acc = 0.9935957149510946\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 72, train_loss = 2.3958635937888175, train_acc = 0.9937121564974383\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 73, train_loss = 2.4060897429008037, train_acc = 0.9935957149510946\n",
      "test Acc 0.9664804469273743:\n",
      "18th- epoch: 74, train_loss = 2.376796184806153, train_acc = 0.9937121564974383\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 75, train_loss = 2.3621425342280418, train_acc = 0.993828598043782\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 76, train_loss = 2.351163240848109, train_acc = 0.9935957149510946\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 77, train_loss = 2.343182798475027, train_acc = 0.9935957149510946\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 78, train_loss = 2.318365156650543, train_acc = 0.993828598043782\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 79, train_loss = 2.3243338093161583, train_acc = 0.9935957149510946\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 80, train_loss = 2.302922810195014, train_acc = 0.9937121564974383\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 81, train_loss = 2.3038914874196053, train_acc = 0.9935957149510946\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 82, train_loss = 2.2694337479770184, train_acc = 0.9941779226828132\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 83, train_loss = 2.2768162812571973, train_acc = 0.9939450395901258\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 84, train_loss = 2.258046768605709, train_acc = 0.994294364229157\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 85, train_loss = 2.2494786840397865, train_acc = 0.9939450395901258\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 86, train_loss = 2.2394873325247318, train_acc = 0.9941779226828132\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 87, train_loss = 2.227750262944028, train_acc = 0.9941779226828132\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 88, train_loss = 2.2124946091789752, train_acc = 0.9941779226828132\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 89, train_loss = 2.220475200563669, train_acc = 0.9941779226828132\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 90, train_loss = 2.2138821221888065, train_acc = 0.9945272473218444\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 91, train_loss = 2.21460988256149, train_acc = 0.9944108057755007\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 92, train_loss = 2.1996068928856403, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 93, train_loss = 2.2022257819771767, train_acc = 0.9944108057755007\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 94, train_loss = 2.1873496000189334, train_acc = 0.9945272473218444\n",
      "test Acc 0.9669459962756052:\n",
      "18th- epoch: 95, train_loss = 2.1776075635571033, train_acc = 0.9944108057755007\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 96, train_loss = 2.1689919841010123, train_acc = 0.9946436888681882\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 97, train_loss = 2.155134530039504, train_acc = 0.9945272473218444\n",
      "test Acc 0.9674115456238361:\n",
      "18th- epoch: 98, train_loss = 2.161233764141798, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 99, train_loss = 2.1568234239239246, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 100, train_loss = 2.150373235344887, train_acc = 0.9945272473218444\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 101, train_loss = 2.1372091099619865, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 102, train_loss = 2.132188831688836, train_acc = 0.9944108057755007\n",
      "test Acc 0.9678770949720671:\n",
      "18th- epoch: 103, train_loss = 2.1308118340093642, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 104, train_loss = 2.1180910915136337, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 105, train_loss = 2.115762210218236, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 106, train_loss = 2.11539422464557, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 107, train_loss = 2.1025726695079356, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 108, train_loss = 2.0973996098618954, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 109, train_loss = 2.0923993687611073, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 110, train_loss = 2.0986624632496387, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 111, train_loss = 2.0887883219402283, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 112, train_loss = 2.0858912479598075, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 113, train_loss = 2.0762040961999446, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 114, train_loss = 2.0755636889953166, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 115, train_loss = 2.0617728407960385, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 116, train_loss = 2.0660137918312103, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 117, train_loss = 2.0610031709074974, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 118, train_loss = 2.061169511405751, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 119, train_loss = 2.0604478504974395, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 120, train_loss = 2.058639146387577, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 121, train_loss = 2.060052229790017, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 122, train_loss = 2.050275528104976, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 123, train_loss = 2.0396723536541685, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 124, train_loss = 2.0437828475842252, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 125, train_loss = 2.0393235894152895, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 126, train_loss = 2.034583711414598, train_acc = 0.994294364229157\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 127, train_loss = 2.03409108647611, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 128, train_loss = 2.0306338170776144, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 129, train_loss = 2.022534298361279, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 130, train_loss = 2.0176500690868124, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 131, train_loss = 2.0159472549567, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 132, train_loss = 2.0150204760720953, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 133, train_loss = 2.0119642689824104, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 134, train_loss = 2.0074577355990186, train_acc = 0.9946436888681882\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 135, train_loss = 2.0040180484065786, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 136, train_loss = 2.0015712106833234, train_acc = 0.9944108057755007\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 137, train_loss = 1.9959831709275022, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 138, train_loss = 2.007097231806256, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 139, train_loss = 1.995936474413611, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 140, train_loss = 1.9923835434019566, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 141, train_loss = 1.9881549825659022, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 142, train_loss = 1.9871172346174717, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 143, train_loss = 1.9840149246156216, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 144, train_loss = 1.9815468800952658, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 145, train_loss = 1.979759739129804, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 146, train_loss = 1.9776526167988777, train_acc = 0.9945272473218444\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 147, train_loss = 1.9707340797176585, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 148, train_loss = 1.9716459537157789, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 149, train_loss = 1.969241976737976, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 150, train_loss = 1.9649707017233595, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 151, train_loss = 1.9698703810572624, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 152, train_loss = 1.9673226810991764, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 153, train_loss = 1.96506453177426, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 154, train_loss = 1.9579251570394263, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 155, train_loss = 1.9569085413822904, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 156, train_loss = 1.95564528927207, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 157, train_loss = 1.9613643834600225, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 158, train_loss = 1.9560460597276688, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 159, train_loss = 1.9454588716616854, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 160, train_loss = 1.9450355941662565, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 161, train_loss = 1.9459693543612957, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 162, train_loss = 1.9463099675485864, train_acc = 0.9945272473218444\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 163, train_loss = 1.9403009662637487, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 164, train_loss = 1.9398589171469212, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 165, train_loss = 1.9332651123404503, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 166, train_loss = 1.933434241800569, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 167, train_loss = 1.931870592175983, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 168, train_loss = 1.9274395803222433, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 169, train_loss = 1.9290198957314715, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 170, train_loss = 1.9274095048895106, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 171, train_loss = 1.9228598239133134, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 172, train_loss = 1.927450886578299, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 173, train_loss = 1.9241247400641441, train_acc = 0.9945272473218444\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 174, train_loss = 1.916733200312592, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 175, train_loss = 1.920236243517138, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 176, train_loss = 1.92195427918341, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 177, train_loss = 1.9188536902656779, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 178, train_loss = 1.9135918592801318, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 179, train_loss = 1.9173492913832888, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 180, train_loss = 1.9141217060387135, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 181, train_loss = 1.907226450741291, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 182, train_loss = 1.913415034650825, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 183, train_loss = 1.9125977344810963, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 184, train_loss = 1.908577440888621, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 185, train_loss = 1.9113983610877767, train_acc = 0.9946436888681882\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 186, train_loss = 1.9049795530736446, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 187, train_loss = 1.9077957595000044, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 188, train_loss = 1.8973781814565882, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 189, train_loss = 1.9011889522662386, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 190, train_loss = 1.8969123860588297, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 191, train_loss = 1.8971072857966647, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 192, train_loss = 1.898455087095499, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 193, train_loss = 1.896513911546208, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 194, train_loss = 1.8958919048309326, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 195, train_loss = 1.8877848709234968, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 196, train_loss = 1.8908354652812704, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 197, train_loss = 1.8864283660659567, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 198, train_loss = 1.8898803094634786, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 199, train_loss = 1.8870821855962276, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 200, train_loss = 1.8906047021737322, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 201, train_loss = 1.8851046500494704, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 202, train_loss = 1.8804690092802048, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 203, train_loss = 1.8812121823430061, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 204, train_loss = 1.8826360404491425, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 205, train_loss = 1.8809033830766566, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 206, train_loss = 1.8831851978902705, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 207, train_loss = 1.8777626206283458, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 208, train_loss = 1.8797215856611729, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 209, train_loss = 1.8715232188696973, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 210, train_loss = 1.8732468684320338, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 211, train_loss = 1.8751420676708221, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 212, train_loss = 1.8706455156207085, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 213, train_loss = 1.8675758391618729, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 214, train_loss = 1.8709295417065732, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 215, train_loss = 1.8654291753773578, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 216, train_loss = 1.8681469447910786, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 217, train_loss = 1.8714178067748435, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 218, train_loss = 1.8696525071864016, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 219, train_loss = 1.8719602462952025, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 220, train_loss = 1.8667426978354342, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 221, train_loss = 1.8665930554270744, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 222, train_loss = 1.8685345302219503, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 223, train_loss = 1.8612552409176715, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 224, train_loss = 1.8629979628021829, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 225, train_loss = 1.8662404592032544, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 226, train_loss = 1.8621901881997474, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 227, train_loss = 1.8596043922007084, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 228, train_loss = 1.8582017185981385, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 229, train_loss = 1.8537118062376976, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 230, train_loss = 1.8549856916069984, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 231, train_loss = 1.8489294673199765, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 232, train_loss = 1.8497077350621112, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 233, train_loss = 1.8513185754418373, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 234, train_loss = 1.8518984764814377, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 235, train_loss = 1.8530282638967037, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 236, train_loss = 1.8513470503385179, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 237, train_loss = 1.8510749712586403, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 238, train_loss = 1.8501424926216714, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 239, train_loss = 1.8554188596899621, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 240, train_loss = 1.8516595500404947, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 241, train_loss = 1.8465867191553116, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 242, train_loss = 1.8483102706377394, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 243, train_loss = 1.8411318361759186, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 244, train_loss = 1.8362621714477427, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 245, train_loss = 1.8471207084949128, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 246, train_loss = 1.8409626707434654, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 247, train_loss = 1.8343631625175476, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 248, train_loss = 1.8365060649812222, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 249, train_loss = 1.8373915702104568, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 250, train_loss = 1.8447266196017154, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 251, train_loss = 1.833601490885485, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 252, train_loss = 1.838370828598272, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 253, train_loss = 1.83547167602228, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 254, train_loss = 1.8349307402968407, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 255, train_loss = 1.828150515735615, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 256, train_loss = 1.832553171843756, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 257, train_loss = 1.827703818678856, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 258, train_loss = 1.8292159314150922, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 259, train_loss = 1.8324288104777224, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 260, train_loss = 1.8250032179057598, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 261, train_loss = 1.8283350989222527, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 262, train_loss = 1.8234242175822146, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 263, train_loss = 1.8242763032321818, train_acc = 0.9947601304145319\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 264, train_loss = 1.8241838440299034, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 265, train_loss = 1.827457160979975, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 266, train_loss = 1.8274607956409454, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 267, train_loss = 1.81999147310853, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 268, train_loss = 1.8243232741951942, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 269, train_loss = 1.8241947529022582, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 270, train_loss = 1.8192363493144512, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 271, train_loss = 1.8187003594939597, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 272, train_loss = 1.8206005792017095, train_acc = 0.9948765719608756\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 273, train_loss = 1.8165907226502895, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 274, train_loss = 1.821383950591553, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 275, train_loss = 1.8169691574876197, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 276, train_loss = 1.8154715833370574, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 277, train_loss = 1.814401913434267, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 278, train_loss = 1.8174784742295742, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 279, train_loss = 1.8153387966449372, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 280, train_loss = 1.809894073754549, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 281, train_loss = 1.8152801754768007, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 282, train_loss = 1.8107259447569959, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 283, train_loss = 1.8119079135358334, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 284, train_loss = 1.8063845510478131, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 285, train_loss = 1.807880486070644, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 286, train_loss = 1.8069000939722173, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 287, train_loss = 1.8055467543308623, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 288, train_loss = 1.8001804215018637, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 289, train_loss = 1.8064339931006543, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 290, train_loss = 1.7996738441288471, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 291, train_loss = 1.8039734102785587, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 292, train_loss = 1.7985118813812733, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 293, train_loss = 1.8009874671697617, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 294, train_loss = 1.7939383809571154, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 295, train_loss = 1.7937767666880973, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 296, train_loss = 1.7938467152416706, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 297, train_loss = 1.795705524564255, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 298, train_loss = 1.7973142278497107, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 299, train_loss = 1.7977946624159813, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 300, train_loss = 1.7945618045632727, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 301, train_loss = 1.7934912766213529, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 302, train_loss = 1.7937373109161854, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 303, train_loss = 1.795502383261919, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 304, train_loss = 1.783265184611082, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 305, train_loss = 1.787109284370672, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 306, train_loss = 1.793504646688234, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 307, train_loss = 1.785824105143547, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 308, train_loss = 1.794166376173962, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 309, train_loss = 1.7906121363048442, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 310, train_loss = 1.7844991100137122, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 311, train_loss = 1.7881417870521545, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 312, train_loss = 1.78993658721447, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 313, train_loss = 1.7816714197397232, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 314, train_loss = 1.7869465326075442, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 315, train_loss = 1.7861446675960906, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 316, train_loss = 1.7849822615389712, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 317, train_loss = 1.7857030456070788, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 318, train_loss = 1.7785457049612887, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 319, train_loss = 1.7800703545217402, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 320, train_loss = 1.7803627997636795, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 321, train_loss = 1.7740926283295266, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 322, train_loss = 1.778103418648243, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 323, train_loss = 1.7808194023673423, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 324, train_loss = 1.7844514797325246, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 325, train_loss = 1.7737797411973588, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 326, train_loss = 1.7825421839952469, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 327, train_loss = 1.777040948451031, train_acc = 0.9947601304145319\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 328, train_loss = 1.7787628422374837, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 329, train_loss = 1.7738730547134764, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 330, train_loss = 1.7794652196462266, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 331, train_loss = 1.7731579479877837, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 332, train_loss = 1.777556502551306, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 333, train_loss = 1.778191725432407, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 334, train_loss = 1.7749654005165212, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 335, train_loss = 1.7750794179737568, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 336, train_loss = 1.7750438563525677, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 337, train_loss = 1.7732056751847267, train_acc = 0.9948765719608756\n",
      "test Acc 0.9688081936685289:\n",
      "18th- epoch: 338, train_loss = 1.7717865680460818, train_acc = 0.9947601304145319\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 339, train_loss = 1.7685201528365724, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 340, train_loss = 1.7703184212441556, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 341, train_loss = 1.772144827991724, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 342, train_loss = 1.7734984855051152, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 343, train_loss = 1.7694199867546558, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 344, train_loss = 1.7645883609657176, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 345, train_loss = 1.7598999949696008, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 346, train_loss = 1.7654165352287237, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 347, train_loss = 1.761905195802683, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 348, train_loss = 1.7707065964641515, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 349, train_loss = 1.7625648453831673, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 350, train_loss = 1.7582696613972075, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 351, train_loss = 1.7612831207516138, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 352, train_loss = 1.7637110402283724, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 353, train_loss = 1.7651679466071073, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 354, train_loss = 1.7638889054360334, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 355, train_loss = 1.7662287478742655, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 356, train_loss = 1.7614906368253287, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 357, train_loss = 1.756823543459177, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 358, train_loss = 1.7565201558172703, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 359, train_loss = 1.7670931828615721, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 360, train_loss = 1.759038311749464, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 361, train_loss = 1.7507334326801356, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 362, train_loss = 1.753210468828911, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 363, train_loss = 1.7544083980319556, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 364, train_loss = 1.7572915355267469, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 365, train_loss = 1.7560450149176177, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 366, train_loss = 1.7555269425211009, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 367, train_loss = 1.7502513080835342, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 368, train_loss = 1.7486577170493547, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 369, train_loss = 1.74958154806518, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 370, train_loss = 1.7556679571571294, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 371, train_loss = 1.752174437046051, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 372, train_loss = 1.7421586327254772, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 373, train_loss = 1.7531589977443218, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 374, train_loss = 1.7526920611562673, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 375, train_loss = 1.7542322861554567, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 376, train_loss = 1.7483753847482149, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 377, train_loss = 1.7394887121918146, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 378, train_loss = 1.7441778468491975, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 379, train_loss = 1.7519711256027222, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 380, train_loss = 1.7421626150608063, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 381, train_loss = 1.7457366113958415, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 382, train_loss = 1.750699907541275, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 383, train_loss = 1.7494265375135, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 384, train_loss = 1.7407877395453397, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 385, train_loss = 1.7432650364935398, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 386, train_loss = 1.752170263469452, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 387, train_loss = 1.7512201964855194, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 388, train_loss = 1.7415479545888957, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 389, train_loss = 1.7395559164287988, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 390, train_loss = 1.7425166977045592, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 391, train_loss = 1.7462409088911954, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 392, train_loss = 1.746412126958603, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 393, train_loss = 1.736912775784731, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 394, train_loss = 1.7330923651752528, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 395, train_loss = 1.7357704540190753, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 396, train_loss = 1.7440585581061896, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 397, train_loss = 1.736931345105404, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 398, train_loss = 1.7358710020780563, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 399, train_loss = 1.7350643078389112, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 400, train_loss = 1.7407488388416823, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 401, train_loss = 1.7425046203134116, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 402, train_loss = 1.7341851778328419, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 403, train_loss = 1.7351337584259454, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 404, train_loss = 1.740557786077261, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 405, train_loss = 1.7408953396079596, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 406, train_loss = 1.7381763495504856, train_acc = 0.9951094550535631\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 407, train_loss = 1.732644535601139, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 408, train_loss = 1.7296188312175218, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 409, train_loss = 1.7251373467443045, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 410, train_loss = 1.7285787562432233, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 411, train_loss = 1.733175441622734, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 412, train_loss = 1.7337578063306864, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 413, train_loss = 1.7325423459114973, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 414, train_loss = 1.7308497292397078, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 415, train_loss = 1.7300830868480261, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 416, train_loss = 1.728515158087248, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 417, train_loss = 1.7299844920635223, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 418, train_loss = 1.7314660077390727, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 419, train_loss = 1.730906510114437, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 420, train_loss = 1.7308273377420846, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 421, train_loss = 1.7283059346082155, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 422, train_loss = 1.7307788530888502, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 423, train_loss = 1.7231146320700645, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 424, train_loss = 1.7219185344874859, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 425, train_loss = 1.7268767220375594, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 426, train_loss = 1.7262476856412832, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 427, train_loss = 1.7237676878867205, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 428, train_loss = 1.7237051725387573, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 429, train_loss = 1.7238659461436328, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 430, train_loss = 1.7267808069882449, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 431, train_loss = 1.7261510764656123, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 432, train_loss = 1.7222396060824394, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 433, train_loss = 1.722723058104748, train_acc = 0.9948765719608756\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 434, train_loss = 1.728762383252615, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 435, train_loss = 1.728097745537525, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 436, train_loss = 1.7253629540500697, train_acc = 0.9951094550535631\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 437, train_loss = 1.725711735576624, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 438, train_loss = 1.7184409722685814, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 439, train_loss = 1.7164788370428141, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 440, train_loss = 1.7219760169682559, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 441, train_loss = 1.7207851521670818, train_acc = 0.9951094550535631\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 442, train_loss = 1.7226464884879533, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 443, train_loss = 1.7188723174331244, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 444, train_loss = 1.7187817183730658, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 445, train_loss = 1.7148340791463852, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 446, train_loss = 1.7222447420062963, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 447, train_loss = 1.7247528694570065, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 448, train_loss = 1.716048395872349, train_acc = 0.9949930135072194\n",
      "test Acc 0.9692737430167597:\n",
      "18th- epoch: 449, train_loss = 1.7116681349871214, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 450, train_loss = 1.7176705884339754, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 451, train_loss = 1.7109578512609005, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 452, train_loss = 1.7115965733828489, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "18th- epoch: 453, train_loss = 1.711504622042412, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 454, train_loss = 1.708955381065607, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 455, train_loss = 1.7095622879860457, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 456, train_loss = 1.7083096404967364, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 457, train_loss = 1.7154399640858173, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 458, train_loss = 1.7116312061843928, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 459, train_loss = 1.7124344421026763, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 460, train_loss = 1.7177390828728676, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 461, train_loss = 1.7072478607296944, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 462, train_loss = 1.7093660359678324, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 463, train_loss = 1.7046186178922653, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 464, train_loss = 1.7047355510294437, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 465, train_loss = 1.7078793744149152, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 466, train_loss = 1.7035566555859987, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 467, train_loss = 1.7101778487267438, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 468, train_loss = 1.7083289958536625, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 469, train_loss = 1.7056432788667735, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 470, train_loss = 1.7043500865402166, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 471, train_loss = 1.6969804937543813, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 472, train_loss = 1.699738908559084, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 473, train_loss = 1.7030672816035803, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 474, train_loss = 1.7051473893225193, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 475, train_loss = 1.7105235991475638, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 476, train_loss = 1.704461502522463, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 477, train_loss = 1.7084516659379005, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 478, train_loss = 1.7088498808443546, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 479, train_loss = 1.7072621906700078, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 480, train_loss = 1.6981819458305836, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 481, train_loss = 1.7017958698270377, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 482, train_loss = 1.7060243201849516, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 483, train_loss = 1.699323651700979, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 484, train_loss = 1.696266812592512, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 485, train_loss = 1.69907165816403, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 486, train_loss = 1.700607169419527, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 487, train_loss = 1.7016714314522687, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 488, train_loss = 1.699188556522131, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 489, train_loss = 1.7071315137145575, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 490, train_loss = 1.695140402764082, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 491, train_loss = 1.6955897932348307, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 492, train_loss = 1.6928758049907628, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 493, train_loss = 1.7001820169389248, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 494, train_loss = 1.692035835236311, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 495, train_loss = 1.6971767520008143, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 496, train_loss = 1.6978267269732896, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 497, train_loss = 1.6926029746828135, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 498, train_loss = 1.6983959016797598, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "18th- epoch: 499, train_loss = 1.6963500169513281, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|█████████████████████████████████████████████▌                              | 18/30 [2:55:06<2:04:24, 622.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "19th- epoch: 0, train_loss = 344.95187379419804, train_acc = 0.7951793199813694\n",
      "test Acc 0.8649906890130353:\n",
      "19th- epoch: 1, train_loss = 73.08382979407907, train_acc = 0.9123195156031673\n",
      "test Acc 0.9115456238361266:\n",
      "19th- epoch: 2, train_loss = 48.876350780017674, train_acc = 0.931765253842571\n",
      "test Acc 0.9273743016759777:\n",
      "19th- epoch: 3, train_loss = 35.449312660843134, train_acc = 0.9451560316721006\n",
      "test Acc 0.936219739292365:\n",
      "19th- epoch: 4, train_loss = 26.729714090935886, train_acc = 0.9556357708430367\n",
      "test Acc 0.9422718808193669:\n",
      "19th- epoch: 5, train_loss = 21.602211751043797, train_acc = 0.9640195621797858\n",
      "test Acc 0.9473929236499069:\n",
      "19th- epoch: 6, train_loss = 18.469926939345896, train_acc = 0.9680950163018165\n",
      "test Acc 0.9497206703910615:\n",
      "19th- epoch: 7, train_loss = 16.19393493141979, train_acc = 0.971821145784816\n",
      "test Acc 0.9515828677839852:\n",
      "19th- epoch: 8, train_loss = 14.40142663102597, train_acc = 0.9729855612482534\n",
      "test Acc 0.9562383612662942:\n",
      "19th- epoch: 9, train_loss = 12.995349043048918, train_acc = 0.975780158360503\n",
      "test Acc 0.9585661080074488:\n",
      "19th- epoch: 10, train_loss = 11.85193322878331, train_acc = 0.9776432231020028\n",
      "test Acc 0.9581005586592178:\n",
      "19th- epoch: 11, train_loss = 10.876836572773755, train_acc = 0.9788076385654402\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 12, train_loss = 10.063956782221794, train_acc = 0.9799720540288775\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 13, train_loss = 9.362675367854536, train_acc = 0.9811364694923148\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 14, train_loss = 8.78516913857311, train_acc = 0.9827666511411272\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 15, train_loss = 8.252058664802462, train_acc = 0.9839310666045645\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 16, train_loss = 7.825613610446453, train_acc = 0.9855612482533768\n",
      "test Acc 0.9622905027932961:\n",
      "19th- epoch: 17, train_loss = 7.412459440063685, train_acc = 0.9860270144387517\n",
      "test Acc 0.9613594040968343:\n",
      "19th- epoch: 18, train_loss = 7.053973868954927, train_acc = 0.9864927806241267\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 19, train_loss = 6.733255385886878, train_acc = 0.9869585468095017\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 20, train_loss = 6.428816132247448, train_acc = 0.9871914299021891\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 21, train_loss = 6.1503421501256526, train_acc = 0.9881229622729389\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 22, train_loss = 5.8863849570043385, train_acc = 0.9887051700046576\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 23, train_loss = 5.6612038551829755, train_acc = 0.9887051700046576\n",
      "test Acc 0.9618249534450651:\n",
      "19th- epoch: 24, train_loss = 5.434307804331183, train_acc = 0.9891709361900326\n",
      "test Acc 0.9622905027932961:\n",
      "19th- epoch: 25, train_loss = 5.240742116235197, train_acc = 0.98940381928272\n",
      "test Acc 0.9622905027932961:\n",
      "19th- epoch: 26, train_loss = 5.052098820917308, train_acc = 0.9897531439217513\n",
      "test Acc 0.9632216014897579:\n",
      "19th- epoch: 27, train_loss = 4.889847998972982, train_acc = 0.9901024685607824\n",
      "test Acc 0.9636871508379888:\n",
      "19th- epoch: 28, train_loss = 4.724050635937601, train_acc = 0.9904517931998137\n",
      "test Acc 0.9636871508379888:\n",
      "19th- epoch: 29, train_loss = 4.573436459060758, train_acc = 0.9906846762925011\n",
      "test Acc 0.9641527001862198:\n",
      "19th- epoch: 30, train_loss = 4.437343350145966, train_acc = 0.9910340009315324\n",
      "test Acc 0.9641527001862198:\n",
      "19th- epoch: 31, train_loss = 4.297123107127845, train_acc = 0.9909175593851887\n",
      "test Acc 0.9641527001862198:\n",
      "19th- epoch: 32, train_loss = 4.181886407546699, train_acc = 0.9912668840242198\n",
      "test Acc 0.9646182495344506:\n",
      "19th- epoch: 33, train_loss = 4.068995914421976, train_acc = 0.9911504424778761\n",
      "test Acc 0.9646182495344506:\n",
      "19th- epoch: 34, train_loss = 3.9723269399255514, train_acc = 0.9914997671169073\n",
      "test Acc 0.9646182495344506:\n",
      "19th- epoch: 35, train_loss = 3.872359254397452, train_acc = 0.9918490917559385\n",
      "test Acc 0.9650837988826816:\n",
      "19th- epoch: 36, train_loss = 3.778868422843516, train_acc = 0.9919655333022822\n",
      "test Acc 0.9655493482309124:\n",
      "19th- epoch: 37, train_loss = 3.697200370952487, train_acc = 0.992081974848626\n",
      "test Acc 0.9669459962756052:\n",
      "19th- epoch: 38, train_loss = 3.6229860428720713, train_acc = 0.9923148579413135\n",
      "test Acc 0.9678770949720671:\n",
      "19th- epoch: 39, train_loss = 3.554864509496838, train_acc = 0.9923148579413135\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 40, train_loss = 3.473583855200559, train_acc = 0.9923148579413135\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 41, train_loss = 3.4144812575541437, train_acc = 0.9926641825803446\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 42, train_loss = 3.3576882760971785, train_acc = 0.9927806241266884\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 43, train_loss = 3.3010462932288647, train_acc = 0.9928970656730322\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 44, train_loss = 3.251983243972063, train_acc = 0.9925477410340009\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 45, train_loss = 3.208170361816883, train_acc = 0.9927806241266884\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 46, train_loss = 3.1617871173657477, train_acc = 0.9926641825803446\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 47, train_loss = 3.1208206955343485, train_acc = 0.9928970656730322\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 48, train_loss = 3.0797054287977517, train_acc = 0.9928970656730322\n",
      "test Acc 0.9683426443202979:\n",
      "19th- epoch: 49, train_loss = 3.0378811438567936, train_acc = 0.9927806241266884\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 50, train_loss = 3.0039588091894984, train_acc = 0.9931299487657196\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 51, train_loss = 2.9682877380400896, train_acc = 0.9931299487657196\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 52, train_loss = 2.9435558503028005, train_acc = 0.9931299487657196\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 53, train_loss = 2.9005678358953446, train_acc = 0.9931299487657196\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 54, train_loss = 2.873541876440868, train_acc = 0.9933628318584071\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 55, train_loss = 2.839195726206526, train_acc = 0.9933628318584071\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 56, train_loss = 2.8153419869486243, train_acc = 0.9933628318584071\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 57, train_loss = 2.781690514879301, train_acc = 0.9931299487657196\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 58, train_loss = 2.7618043364491314, train_acc = 0.9932463903120633\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 59, train_loss = 2.733650670852512, train_acc = 0.9937121564974383\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 60, train_loss = 2.7082816138863564, train_acc = 0.9937121564974383\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 61, train_loss = 2.6848953957669437, train_acc = 0.993828598043782\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 62, train_loss = 2.661498710513115, train_acc = 0.9937121564974383\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 63, train_loss = 2.655740049434826, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 64, train_loss = 2.624080667970702, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 65, train_loss = 2.606039531994611, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 66, train_loss = 2.5846662460826337, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 67, train_loss = 2.5779150032904, train_acc = 0.9935957149510946\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 68, train_loss = 2.544211129657924, train_acc = 0.9935957149510946\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 69, train_loss = 2.5231693524401635, train_acc = 0.9935957149510946\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 70, train_loss = 2.5104674918111414, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 71, train_loss = 2.500584112247452, train_acc = 0.9937121564974383\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 72, train_loss = 2.476281157694757, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 73, train_loss = 2.4739305740222335, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 74, train_loss = 2.451423971913755, train_acc = 0.9939450395901258\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 75, train_loss = 2.4284133485052735, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "19th- epoch: 76, train_loss = 2.4285890210885555, train_acc = 0.9940614811364695\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 77, train_loss = 2.4089162291493267, train_acc = 0.993828598043782\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 78, train_loss = 2.3890679399482906, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 79, train_loss = 2.3866841583512723, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 80, train_loss = 2.3659820939647034, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 81, train_loss = 2.3605869656894356, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 82, train_loss = 2.3512424039654434, train_acc = 0.994294364229157\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 83, train_loss = 2.331128509133123, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 84, train_loss = 2.31969333125744, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 85, train_loss = 2.3016104095149785, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 86, train_loss = 2.306644378841156, train_acc = 0.994294364229157\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 87, train_loss = 2.2851650094380602, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 88, train_loss = 2.284930850524688, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 89, train_loss = 2.2657008308160584, train_acc = 0.994294364229157\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 90, train_loss = 2.259898788819555, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 91, train_loss = 2.2501410014228895, train_acc = 0.994294364229157\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 92, train_loss = 2.2369970453437418, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 93, train_loss = 2.2208118103444576, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 94, train_loss = 2.220653373922687, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 95, train_loss = 2.21820595904137, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 96, train_loss = 2.2083710652659647, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 97, train_loss = 2.1975551256909966, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 98, train_loss = 2.1950227977940813, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 99, train_loss = 2.1785165725741535, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 100, train_loss = 2.1802563450764865, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 101, train_loss = 2.1717506784480065, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 102, train_loss = 2.1576384799554944, train_acc = 0.9946436888681882\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 103, train_loss = 2.1541955892462283, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 104, train_loss = 2.147318673087284, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 105, train_loss = 2.1389669466298074, train_acc = 0.9947601304145319\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 106, train_loss = 2.140769197838381, train_acc = 0.9947601304145319\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 107, train_loss = 2.1307995510287583, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 108, train_loss = 2.119952748529613, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 109, train_loss = 2.126227165805176, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 110, train_loss = 2.1136149039957672, train_acc = 0.9947601304145319\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 111, train_loss = 2.0985110907349735, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 112, train_loss = 2.1041915303794667, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 113, train_loss = 2.0939473245525733, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 114, train_loss = 2.0949155907146633, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 115, train_loss = 2.0847978976089507, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 116, train_loss = 2.076680544181727, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 117, train_loss = 2.0801338284509256, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 118, train_loss = 2.075252798385918, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 119, train_loss = 2.057667736313306, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 120, train_loss = 2.068053340539336, train_acc = 0.9951094550535631\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 121, train_loss = 2.0552808066131547, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 122, train_loss = 2.0492055577924475, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 123, train_loss = 2.0456175002036616, train_acc = 0.9948765719608756\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 124, train_loss = 2.041395489941351, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 125, train_loss = 2.034868683083914, train_acc = 0.9951094550535631\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 126, train_loss = 2.0383078776067123, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 127, train_loss = 2.029582498013042, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 128, train_loss = 2.0311240138253197, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 129, train_loss = 2.027616359409876, train_acc = 0.9949930135072194\n",
      "test Acc 0.9697392923649907:\n",
      "19th- epoch: 130, train_loss = 2.0140895512886345, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 131, train_loss = 2.018525550607592, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 132, train_loss = 2.0173318875022233, train_acc = 0.9951094550535631\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 133, train_loss = 2.0051524572772905, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 134, train_loss = 2.0144833248341456, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 135, train_loss = 1.9967515611788258, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 136, train_loss = 2.003664161427878, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 137, train_loss = 1.996265385299921, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 138, train_loss = 1.989520906470716, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 139, train_loss = 1.98530775308609, train_acc = 0.9951094550535631\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 140, train_loss = 1.9913821941008791, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 141, train_loss = 1.9826063914224505, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 142, train_loss = 1.983129782951437, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 143, train_loss = 1.9779539486626163, train_acc = 0.9949930135072194\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 144, train_loss = 1.9748681969940662, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 145, train_loss = 1.9648163532838225, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 146, train_loss = 1.9695313969859853, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 147, train_loss = 1.972770057269372, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 148, train_loss = 1.9639200894162059, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "19th- epoch: 149, train_loss = 1.9614180838689208, train_acc = 0.9951094550535631\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 150, train_loss = 1.9538981862133369, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 151, train_loss = 1.9594996779924259, train_acc = 0.9948765719608756\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 152, train_loss = 1.9580038348212838, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 153, train_loss = 1.953832607716322, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 154, train_loss = 1.9531606069067493, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 155, train_loss = 1.9507550433045253, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 156, train_loss = 1.9485863040899858, train_acc = 0.9949930135072194\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 157, train_loss = 1.939565609791316, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 158, train_loss = 1.9353501327568665, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 159, train_loss = 1.9359505757456645, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 160, train_loss = 1.9338396325474605, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 161, train_loss = 1.9348044100916013, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 162, train_loss = 1.927226510248147, train_acc = 0.9949930135072194\n",
      "test Acc 0.9711359404096834:\n",
      "19th- epoch: 163, train_loss = 1.9191944586345926, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 164, train_loss = 1.9233332903822884, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 165, train_loss = 1.9269387237727642, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 166, train_loss = 1.9112149166176096, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 167, train_loss = 1.9240270992740989, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 168, train_loss = 1.925847614184022, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 169, train_loss = 1.9168524853885174, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 170, train_loss = 1.912918304442428, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 171, train_loss = 1.9030985959107056, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 172, train_loss = 1.914784824475646, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 173, train_loss = 1.9052203750470653, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 174, train_loss = 1.9063621433451772, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 175, train_loss = 1.9091928092529997, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 176, train_loss = 1.9030178695684299, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 177, train_loss = 1.9070945946732536, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 178, train_loss = 1.8966963719576597, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 179, train_loss = 1.894273417419754, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 180, train_loss = 1.8882702369010076, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 181, train_loss = 1.8980415258556604, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 182, train_loss = 1.8975762879708782, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 183, train_loss = 1.8903801465639845, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 184, train_loss = 1.8876614887267351, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 185, train_loss = 1.890164871350862, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 186, train_loss = 1.885112471296452, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 187, train_loss = 1.8851774471113458, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 188, train_loss = 1.8855967378476635, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 189, train_loss = 1.8797494067111984, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 190, train_loss = 1.868595672189258, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 191, train_loss = 1.8746824506670237, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 192, train_loss = 1.8817622177302837, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 193, train_loss = 1.8802711436292157, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 194, train_loss = 1.8765262631932274, train_acc = 0.9949930135072194\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 195, train_loss = 1.8719391456106678, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 196, train_loss = 1.8726627206197008, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 197, train_loss = 1.873090031906031, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 198, train_loss = 1.8681923107942566, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 199, train_loss = 1.871705204830505, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 200, train_loss = 1.867887300089933, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 201, train_loss = 1.8611671173712239, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 202, train_loss = 1.8617695519933477, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 203, train_loss = 1.8624056074768305, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 204, train_loss = 1.8628416849533096, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 205, train_loss = 1.8596856407821178, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 206, train_loss = 1.8574871054734103, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 207, train_loss = 1.8576903274515644, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 208, train_loss = 1.8556506975437514, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 209, train_loss = 1.8537596054375172, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 210, train_loss = 1.8537808489054441, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 211, train_loss = 1.8540092806215398, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 212, train_loss = 1.8496200814843178, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 213, train_loss = 1.8488594989175908, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 214, train_loss = 1.8472233296488412, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 215, train_loss = 1.845756072551012, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 216, train_loss = 1.8483196168090217, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 217, train_loss = 1.8472013871069066, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 218, train_loss = 1.8400337069178931, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 219, train_loss = 1.8444208216969855, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 220, train_loss = 1.8426775615662336, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 221, train_loss = 1.8381452523171902, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 222, train_loss = 1.838152841955889, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 223, train_loss = 1.8391819552634843, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 224, train_loss = 1.8393348126555793, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 225, train_loss = 1.8357897841488011, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 226, train_loss = 1.8338741771876812, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 227, train_loss = 1.834725494205486, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 228, train_loss = 1.8374761268496513, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 229, train_loss = 1.8286203450406902, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 230, train_loss = 1.8284048910136335, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 231, train_loss = 1.8298991018091328, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 232, train_loss = 1.8282935197348706, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 233, train_loss = 1.8255916759371758, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 234, train_loss = 1.8266175991739146, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 235, train_loss = 1.823981826484669, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 236, train_loss = 1.8307628016918898, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 237, train_loss = 1.8287467335467227, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 238, train_loss = 1.8259264280204661, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 239, train_loss = 1.8327840585261583, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 240, train_loss = 1.8237721745972522, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 241, train_loss = 1.8192568241502158, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 242, train_loss = 1.818900981277693, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 243, train_loss = 1.8218972471659072, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 244, train_loss = 1.821625541895628, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 245, train_loss = 1.8168051652610302, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 246, train_loss = 1.8161604988272302, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 247, train_loss = 1.8142080276156776, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 248, train_loss = 1.8172817372833379, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 249, train_loss = 1.8169459092314355, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 250, train_loss = 1.81226965226233, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 251, train_loss = 1.8160356090520509, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 252, train_loss = 1.8181439911131747, train_acc = 0.9949930135072194\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 253, train_loss = 1.80714121152414, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 254, train_loss = 1.81053725379752, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 255, train_loss = 1.8115186374634504, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 256, train_loss = 1.8122888077050447, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 257, train_loss = 1.804563454061281, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 258, train_loss = 1.808131817728281, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 259, train_loss = 1.8058313646470197, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 260, train_loss = 1.8072631992399693, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 261, train_loss = 1.7987441184814088, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 262, train_loss = 1.801534278318286, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 263, train_loss = 1.8069003106211312, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 264, train_loss = 1.80395776219666, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 265, train_loss = 1.8034880055929534, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 266, train_loss = 1.7996541621978395, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 267, train_loss = 1.8008356441860087, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 268, train_loss = 1.8011240158230066, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 269, train_loss = 1.8022991039906628, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 270, train_loss = 1.7874392811208963, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 271, train_loss = 1.7943994191591628, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 272, train_loss = 1.7988897294853814, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 273, train_loss = 1.798096165060997, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 274, train_loss = 1.7992320886696689, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 275, train_loss = 1.7953374634380452, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 276, train_loss = 1.7944417310063727, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 277, train_loss = 1.7862206368590705, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 278, train_loss = 1.7957620744709857, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 279, train_loss = 1.791471941396594, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 280, train_loss = 1.7893814258277416, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 281, train_loss = 1.7931262490455993, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 282, train_loss = 1.785987417504657, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 283, train_loss = 1.7912930591846816, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 284, train_loss = 1.7906910690362565, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 285, train_loss = 1.7924418642069213, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 286, train_loss = 1.7823356880689971, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 287, train_loss = 1.7810650076717138, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 288, train_loss = 1.7839822017704137, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 289, train_loss = 1.7882913972134702, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 290, train_loss = 1.776931454136502, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 291, train_loss = 1.7830012887716293, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 292, train_loss = 1.7811532349442132, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 293, train_loss = 1.7784123153542168, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 294, train_loss = 1.7905462731723674, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 295, train_loss = 1.7761778726126067, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 296, train_loss = 1.7778729398851283, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 297, train_loss = 1.7844423968344927, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 298, train_loss = 1.7846179504995234, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 299, train_loss = 1.7756909026647918, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 300, train_loss = 1.777103329077363, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 301, train_loss = 1.7741047367453575, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 302, train_loss = 1.7721746781026013, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 303, train_loss = 1.7779642467503436, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 304, train_loss = 1.778085217520129, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 305, train_loss = 1.76843186840415, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 306, train_loss = 1.7708153811399825, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 307, train_loss = 1.771532153710723, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 308, train_loss = 1.7719068260048516, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 309, train_loss = 1.7746605488355272, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 310, train_loss = 1.777503339573741, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 311, train_loss = 1.7715510452981107, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 312, train_loss = 1.7683151767705567, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 313, train_loss = 1.770146643742919, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 314, train_loss = 1.7621299891616218, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 315, train_loss = 1.7747238489682786, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 316, train_loss = 1.7632184096728452, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 317, train_loss = 1.7699792180210352, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 318, train_loss = 1.7749830496613868, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 319, train_loss = 1.7742666241829284, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 320, train_loss = 1.7758028631214984, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 321, train_loss = 1.7605544638936408, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 322, train_loss = 1.7611519272322766, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 323, train_loss = 1.764811121567618, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 324, train_loss = 1.767115417867899, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 325, train_loss = 1.7737108531291597, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 326, train_loss = 1.7589446380734444, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 327, train_loss = 1.759320477664005, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 328, train_loss = 1.7649380316142924, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 329, train_loss = 1.766599748923909, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 330, train_loss = 1.7640084444428794, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 331, train_loss = 1.7652146083419211, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 332, train_loss = 1.7629017873550765, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 333, train_loss = 1.7670084380661137, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 334, train_loss = 1.7655737598543055, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 335, train_loss = 1.7641753045027144, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 336, train_loss = 1.7628802135586739, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 337, train_loss = 1.7622768438304774, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 338, train_loss = 1.7641377852414735, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 339, train_loss = 1.7612557752872817, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 340, train_loss = 1.7581065495614894, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 341, train_loss = 1.7602960709482431, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 342, train_loss = 1.7580500773037784, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 343, train_loss = 1.761011267080903, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 344, train_loss = 1.7579720958019607, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 345, train_loss = 1.7574544393573888, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 346, train_loss = 1.7593050331925042, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 347, train_loss = 1.758923309535021, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 348, train_loss = 1.7545571873779409, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 349, train_loss = 1.7471586322935764, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 350, train_loss = 1.7411009302886669, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 351, train_loss = 1.7364956841920502, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 352, train_loss = 1.7458481776411645, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 353, train_loss = 1.7428451006417163, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 354, train_loss = 1.7362240236252546, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 355, train_loss = 1.738103298470378, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 356, train_loss = 1.735379225865472, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 357, train_loss = 1.737639669328928, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 358, train_loss = 1.7348590909095947, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 359, train_loss = 1.743706234410638, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 360, train_loss = 1.743364858761197, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 361, train_loss = 1.7421491561981384, train_acc = 0.9949930135072194\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 362, train_loss = 1.7295929274114314, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 363, train_loss = 1.7328726835548878, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 364, train_loss = 1.7355212680995464, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 365, train_loss = 1.730125518515706, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 366, train_loss = 1.729065672174329, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 367, train_loss = 1.7310345744190272, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 368, train_loss = 1.7308670537022408, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 369, train_loss = 1.7287153763172682, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 370, train_loss = 1.740569720044732, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 371, train_loss = 1.7464620284736156, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 372, train_loss = 1.7346437902597245, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 373, train_loss = 1.7276832529751118, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 374, train_loss = 1.7264063991606236, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 375, train_loss = 1.7387932868150529, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 376, train_loss = 1.7338146157562733, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 377, train_loss = 1.7355370993318502, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 378, train_loss = 1.7315681452455465, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 379, train_loss = 1.7226560773851816, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 380, train_loss = 1.7226987592875957, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 381, train_loss = 1.7344706325384323, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 382, train_loss = 1.7272168466297444, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 383, train_loss = 1.7244564002903644, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 384, train_loss = 1.732372716680402, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 385, train_loss = 1.7283512502908707, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 386, train_loss = 1.7220543076691683, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 387, train_loss = 1.7286791217920836, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 388, train_loss = 1.7370305489748716, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 389, train_loss = 1.7246987000107765, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 390, train_loss = 1.7173920677450951, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 391, train_loss = 1.7280195821076632, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 392, train_loss = 1.7248952233640011, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 393, train_loss = 1.7162103174778167, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 394, train_loss = 1.7212154610606376, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 395, train_loss = 1.7169833170773927, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 396, train_loss = 1.7270805227162782, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 397, train_loss = 1.7256732682290021, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 398, train_loss = 1.716944017127389, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 399, train_loss = 1.7253069002181292, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 400, train_loss = 1.7230383387359325, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 401, train_loss = 1.7241981582192238, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 402, train_loss = 1.7174279956670944, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 403, train_loss = 1.7275690231472254, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 404, train_loss = 1.7304551297274884, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 405, train_loss = 1.733520088106161, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 406, train_loss = 1.7211739712802228, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 407, train_loss = 1.7199746283295099, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 408, train_loss = 1.7194169970753137, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 409, train_loss = 1.7250937999633607, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 410, train_loss = 1.7313505591300782, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 411, train_loss = 1.72934284931398, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 412, train_loss = 1.7303011348994914, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 413, train_loss = 1.7219016123563051, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 414, train_loss = 1.7284764659998473, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 415, train_loss = 1.7254661706683692, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 416, train_loss = 1.7298484960047062, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 417, train_loss = 1.7233157275768463, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 418, train_loss = 1.7254068876209203, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 419, train_loss = 1.7269919508544262, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 420, train_loss = 1.7235053144395351, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 421, train_loss = 1.7243085360678378, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 422, train_loss = 1.724234128370881, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 423, train_loss = 1.7220186976192053, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 424, train_loss = 1.7235495280474424, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 425, train_loss = 1.7259527500718832, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 426, train_loss = 1.7234417547879275, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 427, train_loss = 1.7237529456615448, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 428, train_loss = 1.724194506794447, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 429, train_loss = 1.7188595067709684, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 430, train_loss = 1.7203496936708689, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 431, train_loss = 1.7194889560341835, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 432, train_loss = 1.7210750511439983, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 433, train_loss = 1.7208319318888243, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 434, train_loss = 1.7182979589852039, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 435, train_loss = 1.7091583112778608, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 436, train_loss = 1.7065388833580073, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 437, train_loss = 1.7173495522292797, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 438, train_loss = 1.7159625204803888, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 439, train_loss = 1.7160633858293295, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 440, train_loss = 1.7147206142544746, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 441, train_loss = 1.7201611921191216, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 442, train_loss = 1.7139820214360952, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 443, train_loss = 1.7160707084985916, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 444, train_loss = 1.7208091355860233, train_acc = 0.9949930135072194\n",
      "test Acc 0.972998137802607:\n",
      "19th- epoch: 445, train_loss = 1.7186293484119233, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 446, train_loss = 1.7153143802133854, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 447, train_loss = 1.715106104820734, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 448, train_loss = 1.7154972615244333, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 449, train_loss = 1.7118318763969, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 450, train_loss = 1.7143189404159784, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 451, train_loss = 1.7126901373267174, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 452, train_loss = 1.7107334515603725, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 453, train_loss = 1.7112401512858924, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 454, train_loss = 1.7119633747788612, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 455, train_loss = 1.7089623119682074, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 456, train_loss = 1.7124841747281607, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 457, train_loss = 1.7122738789767027, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 458, train_loss = 1.710018722951645, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 459, train_loss = 1.7090691067278385, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 460, train_loss = 1.7063239943236113, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 461, train_loss = 1.7066697999835014, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 462, train_loss = 1.71196360947215, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 463, train_loss = 1.7092171528784093, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 464, train_loss = 1.7084666316804942, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 465, train_loss = 1.705583337083226, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 466, train_loss = 1.7054330582323018, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 467, train_loss = 1.7075699462147895, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 468, train_loss = 1.7071501271275338, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 469, train_loss = 1.7034051387163345, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 470, train_loss = 1.7045564446598291, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 471, train_loss = 1.7050251178443432, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 472, train_loss = 1.6998756037501153, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 473, train_loss = 1.7051135723886546, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 474, train_loss = 1.7009152825921774, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 475, train_loss = 1.70599765269435, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 476, train_loss = 1.7017016305180732, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 477, train_loss = 1.7038366558554117, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 478, train_loss = 1.7002933652547654, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 479, train_loss = 1.6959865639510099, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 480, train_loss = 1.7006872004421894, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 481, train_loss = 1.701183743774891, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 482, train_loss = 1.6999227584747132, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 483, train_loss = 1.7082649239746388, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 484, train_loss = 1.6952145602554083, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 485, train_loss = 1.6999943939445075, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 486, train_loss = 1.6986073330044746, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 487, train_loss = 1.6966349339636508, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 488, train_loss = 1.6968335794808809, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 489, train_loss = 1.7008636146783829, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 490, train_loss = 1.7008864997478668, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 491, train_loss = 1.694330619648099, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 492, train_loss = 1.695032629504567, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 493, train_loss = 1.6951509708014783, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 494, train_loss = 1.6939215759339277, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 495, train_loss = 1.690228213876253, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 496, train_loss = 1.6939862655999605, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 497, train_loss = 1.6964259867963847, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 498, train_loss = 1.6942528523504734, train_acc = 0.9949930135072194\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 499, train_loss = 1.6951778375951108, train_acc = 0.9949930135072194\n",
      "test Acc 0.9739292364990689:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 63%|████████████████████████████████████████████████▏                           | 19/30 [3:05:27<1:54:01, 621.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "20th- epoch: 0, train_loss = 325.09228829294443, train_acc = 0.8128784350256172\n",
      "test Acc 0.9124767225325885:\n",
      "20th- epoch: 1, train_loss = 67.34057828783989, train_acc = 0.9248952026082906\n",
      "test Acc 0.9380819366852886:\n",
      "20th- epoch: 2, train_loss = 45.20526497066021, train_acc = 0.94014904517932\n",
      "test Acc 0.9427374301675978:\n",
      "20th- epoch: 3, train_loss = 35.22796679288149, train_acc = 0.9513274336283186\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 4, train_loss = 29.20490383543074, train_acc = 0.9571495109455054\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 5, train_loss = 24.44935299642384, train_acc = 0.9615742897065673\n",
      "test Acc 0.9464618249534451:\n",
      "20th- epoch: 6, train_loss = 20.793968498706818, train_acc = 0.9658826269212856\n",
      "test Acc 0.9478584729981379:\n",
      "20th- epoch: 7, train_loss = 17.778037359938025, train_acc = 0.9689101071262226\n",
      "test Acc 0.9487895716945997:\n",
      "20th- epoch: 8, train_loss = 15.434975052252412, train_acc = 0.9698416394969726\n",
      "test Acc 0.9529795158286778:\n",
      "20th- epoch: 9, train_loss = 13.60313936509192, train_acc = 0.9736842105263158\n",
      "test Acc 0.9553072625698324:\n",
      "20th- epoch: 10, train_loss = 12.161919282749295, train_acc = 0.9754308337214718\n",
      "test Acc 0.9581005586592178:\n",
      "20th- epoch: 11, train_loss = 10.962468465790153, train_acc = 0.9772938984629715\n",
      "test Acc 0.9604283054003724:\n",
      "20th- epoch: 12, train_loss = 9.932212591171265, train_acc = 0.9790405216581276\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 13, train_loss = 9.061546539887786, train_acc = 0.9809035863996274\n",
      "test Acc 0.9604283054003724:\n",
      "20th- epoch: 14, train_loss = 8.317461214959621, train_acc = 0.9818351187703773\n",
      "test Acc 0.9604283054003724:\n",
      "20th- epoch: 15, train_loss = 7.678298308514059, train_acc = 0.9832324173265021\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 16, train_loss = 7.169399400241673, train_acc = 0.9852119236143456\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 17, train_loss = 6.714210893958807, train_acc = 0.9856776897997206\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 18, train_loss = 6.346244965679944, train_acc = 0.9862598975314392\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 19, train_loss = 6.015838637016714, train_acc = 0.9869585468095017\n",
      "test Acc 0.9608938547486033:\n",
      "20th- epoch: 20, train_loss = 5.75540708610788, train_acc = 0.9876571960875641\n",
      "test Acc 0.9622905027932961:\n",
      "20th- epoch: 21, train_loss = 5.4842176884412766, train_acc = 0.9883558453656265\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 22, train_loss = 5.26770002534613, train_acc = 0.9888216115510013\n",
      "test Acc 0.9618249534450651:\n",
      "20th- epoch: 23, train_loss = 5.060892221983522, train_acc = 0.9892873777363763\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 24, train_loss = 4.884005842264742, train_acc = 0.9895202608290639\n",
      "test Acc 0.9650837988826816:\n",
      "20th- epoch: 25, train_loss = 4.726249625440687, train_acc = 0.9902189101071263\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 26, train_loss = 4.587671119719744, train_acc = 0.9904517931998137\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 27, train_loss = 4.462721535470337, train_acc = 0.9905682347461574\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 28, train_loss = 4.348416349384934, train_acc = 0.9911504424778761\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 29, train_loss = 4.25354385888204, train_acc = 0.9912668840242198\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 30, train_loss = 4.167903805850074, train_acc = 0.9912668840242198\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 31, train_loss = 4.061482765944675, train_acc = 0.9914997671169073\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 32, train_loss = 3.992129061371088, train_acc = 0.9914997671169073\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 33, train_loss = 3.913943608524278, train_acc = 0.9914997671169073\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 34, train_loss = 3.841032159747556, train_acc = 0.9917326502095948\n",
      "test Acc 0.9664804469273743:\n",
      "20th- epoch: 35, train_loss = 3.778750927420333, train_acc = 0.9917326502095948\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 36, train_loss = 3.7108786180615425, train_acc = 0.9918490917559385\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 37, train_loss = 3.6646353241521865, train_acc = 0.9919655333022822\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 38, train_loss = 3.5782986495178193, train_acc = 0.9919655333022822\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 39, train_loss = 3.5325937047600746, train_acc = 0.9923148579413135\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 40, train_loss = 3.4729517970699817, train_acc = 0.9923148579413135\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 41, train_loss = 3.4279272072017193, train_acc = 0.9923148579413135\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 42, train_loss = 3.383123339386657, train_acc = 0.9923148579413135\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 43, train_loss = 3.341585586545989, train_acc = 0.9923148579413135\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 44, train_loss = 3.290354526368901, train_acc = 0.9924312994876572\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 45, train_loss = 3.2576929107308388, train_acc = 0.9925477410340009\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 46, train_loss = 3.207087580114603, train_acc = 0.9926641825803446\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 47, train_loss = 3.1700622823555022, train_acc = 0.9928970656730322\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 48, train_loss = 3.1380664941389114, train_acc = 0.9925477410340009\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 49, train_loss = 3.1010015085339546, train_acc = 0.9928970656730322\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 50, train_loss = 3.0592488285619766, train_acc = 0.9930135072193759\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 51, train_loss = 3.0307994459290057, train_acc = 0.9927806241266884\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 52, train_loss = 2.993532261578366, train_acc = 0.9927806241266884\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 53, train_loss = 2.9597879860084504, train_acc = 0.9926641825803446\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 54, train_loss = 2.9295684446115047, train_acc = 0.9927806241266884\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 55, train_loss = 2.8913596892962232, train_acc = 0.9927806241266884\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 56, train_loss = 2.8682715259492397, train_acc = 0.9928970656730322\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 57, train_loss = 2.841446013539098, train_acc = 0.9927806241266884\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 58, train_loss = 2.8122910894453526, train_acc = 0.9927806241266884\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 59, train_loss = 2.7935161516070366, train_acc = 0.9928970656730322\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 60, train_loss = 2.7707542987773195, train_acc = 0.9928970656730322\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 61, train_loss = 2.741859635920264, train_acc = 0.9928970656730322\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 62, train_loss = 2.719993775128387, train_acc = 0.9928970656730322\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 63, train_loss = 2.700762984692119, train_acc = 0.9932463903120633\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 64, train_loss = 2.676634976058267, train_acc = 0.9931299487657196\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 65, train_loss = 2.6632718505570665, train_acc = 0.9932463903120633\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 66, train_loss = 2.641231369227171, train_acc = 0.9932463903120633\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 67, train_loss = 2.623830668628216, train_acc = 0.9933628318584071\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 68, train_loss = 2.6090671233832836, train_acc = 0.9935957149510946\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 69, train_loss = 2.5952597223222256, train_acc = 0.9934792734047508\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 70, train_loss = 2.574577954947017, train_acc = 0.9935957149510946\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 71, train_loss = 2.558938759029843, train_acc = 0.9934792734047508\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 72, train_loss = 2.5444262698292732, train_acc = 0.9935957149510946\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 73, train_loss = 2.5316509591648355, train_acc = 0.9933628318584071\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 74, train_loss = 2.5200817981967703, train_acc = 0.993828598043782\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 75, train_loss = 2.5064759701490402, train_acc = 0.993828598043782\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 76, train_loss = 2.500358627527021, train_acc = 0.9934792734047508\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 77, train_loss = 2.4882141737034544, train_acc = 0.9937121564974383\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 78, train_loss = 2.4707894126186147, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 79, train_loss = 2.4622851138701662, train_acc = 0.9935957149510946\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 80, train_loss = 2.4546584164490923, train_acc = 0.993828598043782\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 81, train_loss = 2.441282842308283, train_acc = 0.9937121564974383\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 82, train_loss = 2.4237303994596004, train_acc = 0.9935957149510946\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 83, train_loss = 2.4199965558946133, train_acc = 0.993828598043782\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 84, train_loss = 2.410709537565708, train_acc = 0.9935957149510946\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 85, train_loss = 2.3963701464235783, train_acc = 0.993828598043782\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 86, train_loss = 2.3886910006403923, train_acc = 0.993828598043782\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 87, train_loss = 2.377820074558258, train_acc = 0.993828598043782\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 88, train_loss = 2.3712060203542933, train_acc = 0.993828598043782\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 89, train_loss = 2.367063889862038, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 90, train_loss = 2.3517432747175917, train_acc = 0.9939450395901258\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 91, train_loss = 2.3461301885545254, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 92, train_loss = 2.338309835642576, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 93, train_loss = 2.324073883355595, train_acc = 0.993828598043782\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 94, train_loss = 2.327991227270104, train_acc = 0.993828598043782\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 95, train_loss = 2.317615333944559, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 96, train_loss = 2.3082352416822687, train_acc = 0.9939450395901258\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 97, train_loss = 2.304137864499353, train_acc = 0.993828598043782\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 98, train_loss = 2.298765830695629, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 99, train_loss = 2.2911655282368883, train_acc = 0.9940614811364695\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 100, train_loss = 2.286593878059648, train_acc = 0.9941779226828132\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 101, train_loss = 2.277540296316147, train_acc = 0.994294364229157\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 102, train_loss = 2.2702928049257025, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 103, train_loss = 2.260629511089064, train_acc = 0.994294364229157\n",
      "test Acc 0.9688081936685289:\n",
      "20th- epoch: 104, train_loss = 2.259238095371984, train_acc = 0.994294364229157\n",
      "test Acc 0.9692737430167597:\n",
      "20th- epoch: 105, train_loss = 2.258772554458119, train_acc = 0.9941779226828132\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 106, train_loss = 2.244048658758402, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 107, train_loss = 2.234714468359016, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 108, train_loss = 2.235428113490343, train_acc = 0.994294364229157\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 109, train_loss = 2.2269589951029047, train_acc = 0.994294364229157\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 110, train_loss = 2.2351172044873238, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 111, train_loss = 2.2208001650869846, train_acc = 0.9941779226828132\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 112, train_loss = 2.2263186363270506, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 113, train_loss = 2.212153228581883, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 114, train_loss = 2.213244028389454, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 115, train_loss = 2.205593569786288, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 116, train_loss = 2.2024101117858663, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 117, train_loss = 2.194690795033239, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 118, train_loss = 2.19650185725186, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 119, train_loss = 2.1795289739966393, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 120, train_loss = 2.1774372209911235, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 121, train_loss = 2.1721962405135855, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 122, train_loss = 2.1830977039644495, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 123, train_loss = 2.173364213318564, train_acc = 0.9946436888681882\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 124, train_loss = 2.155646010010969, train_acc = 0.9946436888681882\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 125, train_loss = 2.1563221129472367, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 126, train_loss = 2.153397082001902, train_acc = 0.9946436888681882\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 127, train_loss = 2.1565172225236893, train_acc = 0.9946436888681882\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 128, train_loss = 2.1498722222750075, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 129, train_loss = 2.1493840155308135, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 130, train_loss = 2.1441991006140597, train_acc = 0.9946436888681882\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 131, train_loss = 2.1387523499433883, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 132, train_loss = 2.1345644096727483, train_acc = 0.994294364229157\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 133, train_loss = 2.1493018865585327, train_acc = 0.9946436888681882\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 134, train_loss = 2.1248207216267474, train_acc = 0.9946436888681882\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 135, train_loss = 2.1261142666335218, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 136, train_loss = 2.128311052918434, train_acc = 0.9948765719608756\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 137, train_loss = 2.113791325420607, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 138, train_loss = 2.1068941578269005, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 139, train_loss = 2.1119426314835437, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 140, train_loss = 2.1092062790994532, train_acc = 0.9946436888681882\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 141, train_loss = 2.1076305781607516, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 142, train_loss = 2.0966166866128333, train_acc = 0.9945272473218444\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 143, train_loss = 2.0997149658505805, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 144, train_loss = 2.1069990930263884, train_acc = 0.9947601304145319\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 145, train_loss = 2.0896811808343045, train_acc = 0.9947601304145319\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 146, train_loss = 2.087089102715254, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 147, train_loss = 2.097500253468752, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 148, train_loss = 2.0761771735851653, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 149, train_loss = 2.0735815961961634, train_acc = 0.9946436888681882\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 150, train_loss = 2.0839926302433014, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 151, train_loss = 2.0869903291459195, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 152, train_loss = 2.098972865671385, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 153, train_loss = 2.0873371225898154, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 154, train_loss = 2.0794619296793826, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 155, train_loss = 2.0738310304586776, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 156, train_loss = 2.0747224266524427, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 157, train_loss = 2.0709467816050164, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 158, train_loss = 2.0703929029405117, train_acc = 0.994294364229157\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 159, train_loss = 2.0590544280712493, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 160, train_loss = 2.0571484926040284, train_acc = 0.9947601304145319\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 161, train_loss = 2.04147618758725, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 162, train_loss = 2.0528717053239234, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 163, train_loss = 2.0436192552442662, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 164, train_loss = 2.044861334084999, train_acc = 0.9948765719608756\n",
      "test Acc 0.9711359404096834:\n",
      "20th- epoch: 165, train_loss = 2.0382701729540713, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 166, train_loss = 2.0399274192750454, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 167, train_loss = 2.034723947464954, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 168, train_loss = 2.0334237702190876, train_acc = 0.994294364229157\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 169, train_loss = 2.034767124801874, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 170, train_loss = 2.0289605110883713, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 171, train_loss = 2.0281524807214737, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 172, train_loss = 2.0230764846201055, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 173, train_loss = 2.02218084782362, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 174, train_loss = 2.013210160017479, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 175, train_loss = 2.017702552198898, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 176, train_loss = 2.014057394117117, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 177, train_loss = 2.0139894274179824, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 178, train_loss = 2.006131363392342, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 179, train_loss = 2.0159237906336784, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 180, train_loss = 2.00073479115963, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 181, train_loss = 2.0078139739925973, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 182, train_loss = 1.9991216138005257, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 183, train_loss = 2.001462399959564, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 184, train_loss = 2.0113300482626073, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 185, train_loss = 1.9951395715470426, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 186, train_loss = 1.9943206210737117, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 187, train_loss = 1.998909140645992, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 188, train_loss = 1.9928965370054357, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 189, train_loss = 1.9872902420465834, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 190, train_loss = 1.9863201404805295, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 191, train_loss = 1.9867522306740284, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 192, train_loss = 1.9837128830258735, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 193, train_loss = 1.9872009034152143, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 194, train_loss = 1.9926176604931243, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 195, train_loss = 1.976462074846495, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 196, train_loss = 1.9760666129295714, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 197, train_loss = 1.9792342956061475, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 198, train_loss = 1.9766371597652324, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 199, train_loss = 1.9870423885877244, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 200, train_loss = 1.9708168568904512, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 201, train_loss = 1.9769177362322807, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 202, train_loss = 1.966916885226965, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 203, train_loss = 1.9750332348048687, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 204, train_loss = 1.9811430374975316, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 205, train_loss = 1.9670852956478484, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 206, train_loss = 1.9702734984457493, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 207, train_loss = 1.974875622719992, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 208, train_loss = 1.978218499571085, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 209, train_loss = 1.9781156480312347, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 210, train_loss = 1.9776184273068793, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 211, train_loss = 1.9643845607643016, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 212, train_loss = 1.9778358563780785, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 213, train_loss = 1.969922300428152, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 214, train_loss = 1.977055290073622, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 215, train_loss = 1.9692728618974797, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 216, train_loss = 1.9689197304542176, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 217, train_loss = 1.944780420511961, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 218, train_loss = 1.9638026282191277, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 219, train_loss = 1.9591226589982398, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 220, train_loss = 1.9604806688730605, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 221, train_loss = 1.9597661917214282, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 222, train_loss = 1.9576589899952523, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 223, train_loss = 1.94664366543293, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 224, train_loss = 1.9404602224822156, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 225, train_loss = 1.9467151065473445, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 226, train_loss = 1.949834028899204, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 227, train_loss = 1.938060520857107, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 228, train_loss = 1.9369777987594716, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 229, train_loss = 1.946861578791868, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 230, train_loss = 1.9426331470604055, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 231, train_loss = 1.9443127761478536, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 232, train_loss = 1.9522155585582368, train_acc = 0.994294364229157\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 233, train_loss = 1.954740981280338, train_acc = 0.994294364229157\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 234, train_loss = 1.9357325099408627, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 235, train_loss = 1.9400105463864747, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 236, train_loss = 1.9381127916276455, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 237, train_loss = 1.938032397389179, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 238, train_loss = 1.9402479814889375, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 239, train_loss = 1.937548817426432, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 240, train_loss = 1.9336905305681285, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 241, train_loss = 1.941127609461546, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 242, train_loss = 1.9411674017610494, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 243, train_loss = 1.9326998417673167, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 244, train_loss = 1.9254296272993088, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 245, train_loss = 1.918354401976103, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 246, train_loss = 1.9261121079325676, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 247, train_loss = 1.935652659565676, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 248, train_loss = 1.9329117896559183, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 249, train_loss = 1.9291895553469658, train_acc = 0.9946436888681882\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 250, train_loss = 1.9288217139837798, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 251, train_loss = 1.9275968708097935, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 252, train_loss = 1.9122183894214686, train_acc = 0.9946436888681882\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 253, train_loss = 1.9157751972379629, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 254, train_loss = 1.9283576744201127, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 255, train_loss = 1.9276717180910055, train_acc = 0.994294364229157\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 256, train_loss = 1.93098790323711, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 257, train_loss = 1.9312410851416644, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 258, train_loss = 1.9191496893763542, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 259, train_loss = 1.9185778498649597, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 260, train_loss = 1.924866615474457, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 261, train_loss = 1.923443604260683, train_acc = 0.994294364229157\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 262, train_loss = 1.9115972233412322, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 263, train_loss = 1.9151078748109285, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 264, train_loss = 1.9085157488880213, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 265, train_loss = 1.9054448617098387, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 266, train_loss = 1.9110310263931751, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 267, train_loss = 1.9060350023210049, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 268, train_loss = 1.89886319017387, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 269, train_loss = 1.9036075125040952, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 270, train_loss = 1.9055010564625263, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 271, train_loss = 1.903088932245737, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 272, train_loss = 1.9067542230186518, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 273, train_loss = 1.903211119264597, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 274, train_loss = 1.9111002832651138, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 275, train_loss = 1.898575803876156, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 276, train_loss = 1.905675051122671, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 277, train_loss = 1.9034778314235155, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 278, train_loss = 1.903590695321327, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 279, train_loss = 1.9035289324820042, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 280, train_loss = 1.8967818977835122, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 281, train_loss = 1.9001385234296322, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 282, train_loss = 1.8870664251444396, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 283, train_loss = 1.8871325217187405, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 284, train_loss = 1.9000236354768276, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 285, train_loss = 1.8933919630944729, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 286, train_loss = 1.9007187684474047, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 287, train_loss = 1.8971615632472094, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 288, train_loss = 1.901827440917259, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 289, train_loss = 1.894636057317257, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 290, train_loss = 1.8949326227011625, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 291, train_loss = 1.8920961866679136, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 292, train_loss = 1.8937597746553365, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 293, train_loss = 1.8907746871409472, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 294, train_loss = 1.8917028494179249, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 295, train_loss = 1.8847173253598157, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 296, train_loss = 1.8845667392015457, train_acc = 0.9946436888681882\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 297, train_loss = 1.88940773284412, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 298, train_loss = 1.8786374777555466, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 299, train_loss = 1.8760284682211932, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 300, train_loss = 1.8813547802565154, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 301, train_loss = 1.8806735152902547, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 302, train_loss = 1.8847405972483102, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 303, train_loss = 1.8848285861313343, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 304, train_loss = 1.8770040211675223, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 305, train_loss = 1.877381645143032, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 306, train_loss = 1.8857792938651983, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 307, train_loss = 1.8746796362102032, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 308, train_loss = 1.878622946649557, train_acc = 0.9947601304145319\n",
      "test Acc 0.973463687150838:\n",
      "20th- epoch: 309, train_loss = 1.8892774929699954, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 310, train_loss = 1.8905063731072005, train_acc = 0.9946436888681882\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 311, train_loss = 1.8786850733158644, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 312, train_loss = 1.8825325556099415, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 313, train_loss = 1.8745751343667507, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 314, train_loss = 1.8714149619045202, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 315, train_loss = 1.8724942778644618, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 316, train_loss = 1.8796200839278754, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 317, train_loss = 1.8669851509330329, train_acc = 0.9947601304145319\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 318, train_loss = 1.8739885091781616, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 319, train_loss = 1.8724183030426502, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 320, train_loss = 1.874850582331419, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 321, train_loss = 1.8719998374581337, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 322, train_loss = 1.8640740849077702, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 323, train_loss = 1.8631664353015367, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 324, train_loss = 1.8740816501376685, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 325, train_loss = 1.8679852609930094, train_acc = 0.9947601304145319\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 326, train_loss = 1.8618279298243579, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 327, train_loss = 1.8611613077518996, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 328, train_loss = 1.8639724689128343, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 329, train_loss = 1.862023831665283, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 330, train_loss = 1.8630710082652513, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 331, train_loss = 1.8608144906756934, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 332, train_loss = 1.8630859131517354, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 333, train_loss = 1.857384618371725, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 334, train_loss = 1.8541295938193798, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 335, train_loss = 1.8615207597613335, train_acc = 0.9946436888681882\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 336, train_loss = 1.863826679677004, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 337, train_loss = 1.8626136220991611, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 338, train_loss = 1.8561900767090265, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 339, train_loss = 1.8551940930483397, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 340, train_loss = 1.863076782465214, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 341, train_loss = 1.8609396243991796, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 342, train_loss = 1.8612484099867288, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 343, train_loss = 1.851968627423048, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 344, train_loss = 1.859238470584387, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 345, train_loss = 1.854334931820631, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 346, train_loss = 1.8566288550791796, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 347, train_loss = 1.8550624387862626, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 348, train_loss = 1.8490325982274953, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 349, train_loss = 1.8461163863539696, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 350, train_loss = 1.8525568544864655, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 351, train_loss = 1.8467883467674255, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 352, train_loss = 1.8502545481023844, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 353, train_loss = 1.842950170248514, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 354, train_loss = 1.8495693691074848, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 355, train_loss = 1.8448914550244808, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 356, train_loss = 1.8445447782578412, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 357, train_loss = 1.8442871359584387, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 358, train_loss = 1.8403586397471372, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 359, train_loss = 1.8484438881278038, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 360, train_loss = 1.8489464111626148, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 361, train_loss = 1.8442399203777313, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 362, train_loss = 1.8446059003472328, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 363, train_loss = 1.837012991309166, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 364, train_loss = 1.836655462771887, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 365, train_loss = 1.8351058910193387, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 366, train_loss = 1.8461676513252314, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 367, train_loss = 1.8439635386166628, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 368, train_loss = 1.8418354503810406, train_acc = 0.9947601304145319\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 369, train_loss = 1.8461353617312852, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 370, train_loss = 1.8330387858150061, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 371, train_loss = 1.8351922817528248, train_acc = 0.9946436888681882\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 372, train_loss = 1.8446951483783778, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 373, train_loss = 1.840689841657877, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 374, train_loss = 1.840225392341381, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 375, train_loss = 1.8295068107545376, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 376, train_loss = 1.8328120162186678, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 377, train_loss = 1.8332313895225525, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 378, train_loss = 1.8397307855484542, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 379, train_loss = 1.8425777728261892, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 380, train_loss = 1.8378969468176365, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 381, train_loss = 1.8273209022881929, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 382, train_loss = 1.8299029221234377, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 383, train_loss = 1.8284103013575077, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 384, train_loss = 1.8273099958896637, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 385, train_loss = 1.8260484859347343, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 386, train_loss = 1.8224724320170935, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 387, train_loss = 1.8281910121440887, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 388, train_loss = 1.827656976878643, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 389, train_loss = 1.8236344071628992, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 390, train_loss = 1.829406101256609, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 391, train_loss = 1.8204998150467873, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 392, train_loss = 1.822178952395916, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 393, train_loss = 1.821441294014221, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 394, train_loss = 1.8243910794553813, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 395, train_loss = 1.8197814598679543, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 396, train_loss = 1.8220647300186101, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 397, train_loss = 1.8117094486951828, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 398, train_loss = 1.8145721803011838, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 399, train_loss = 1.8152942769229412, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 400, train_loss = 1.816801529377699, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 401, train_loss = 1.8170647310616914, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 402, train_loss = 1.8215926736593246, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 403, train_loss = 1.8229488941433374, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 404, train_loss = 1.8207408649323042, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 405, train_loss = 1.830338021129137, train_acc = 0.9944108057755007\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 406, train_loss = 1.8173183016479015, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 407, train_loss = 1.8272929315862712, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 408, train_loss = 1.8220270425081253, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 409, train_loss = 1.822912531584734, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 410, train_loss = 1.8185197785496712, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 411, train_loss = 1.8105019976792391, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 412, train_loss = 1.8119758529064711, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 413, train_loss = 1.8074989964661654, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 414, train_loss = 1.8043175178172532, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 415, train_loss = 1.8088854675588664, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 416, train_loss = 1.8122866836783942, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 417, train_loss = 1.8040614748897497, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 418, train_loss = 1.8060005865991116, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 419, train_loss = 1.8086885598895606, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 420, train_loss = 1.8018136309983674, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 421, train_loss = 1.799268620699877, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 422, train_loss = 1.8030278210935649, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 423, train_loss = 1.8048853985965252, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 424, train_loss = 1.8113259188830853, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 425, train_loss = 1.808404521405464, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 426, train_loss = 1.8057277239859104, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 427, train_loss = 1.8106180181202944, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 428, train_loss = 1.8012418995203916, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 429, train_loss = 1.8018826581537724, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 430, train_loss = 1.7999816524388734, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 431, train_loss = 1.794672100484604, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 432, train_loss = 1.794268495083088, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 433, train_loss = 1.8057690983114298, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 434, train_loss = 1.7980672915873583, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 435, train_loss = 1.8096669130027294, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 436, train_loss = 1.7962482968869153, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 437, train_loss = 1.807949078589445, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 438, train_loss = 1.7952182081935462, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 439, train_loss = 1.8009673915803432, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 440, train_loss = 1.7912782207131386, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 441, train_loss = 1.8015379061398562, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 442, train_loss = 1.79579496383667, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 443, train_loss = 1.80245953053236, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 444, train_loss = 1.7931597319839057, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 445, train_loss = 1.8024874590337276, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 446, train_loss = 1.7918003747763578, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 447, train_loss = 1.7995996425452176, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 448, train_loss = 1.8075416224601213, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 449, train_loss = 1.8110571441648062, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 450, train_loss = 1.8024416056869086, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 451, train_loss = 1.7896179097297136, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 452, train_loss = 1.7837011516094208, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 453, train_loss = 1.793379014969105, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 454, train_loss = 1.7976404788496438, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 455, train_loss = 1.7887448519468307, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 456, train_loss = 1.780335874616867, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 457, train_loss = 1.7931851223111153, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 458, train_loss = 1.8166432715952396, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 459, train_loss = 1.801857012003893, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 460, train_loss = 1.7860450421867426, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 461, train_loss = 1.782686530292267, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 462, train_loss = 1.7930874290468637, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 463, train_loss = 1.790336868405575, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 464, train_loss = 1.796180391072994, train_acc = 0.9946436888681882\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 465, train_loss = 1.7856992408633232, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 466, train_loss = 1.779018616914982, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 467, train_loss = 1.7869166135787964, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 468, train_loss = 1.783103904366726, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 469, train_loss = 1.7881942056119442, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 470, train_loss = 1.785625632852316, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 471, train_loss = 1.7841531559824944, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 472, train_loss = 1.7909088308515493, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 473, train_loss = 1.7814134669752093, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 474, train_loss = 1.7900860433874186, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 475, train_loss = 1.778376828879118, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 476, train_loss = 1.772232886403799, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 477, train_loss = 1.7782215997576714, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 478, train_loss = 1.7873395768401679, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 479, train_loss = 1.7813391238451004, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 480, train_loss = 1.770445587739232, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 481, train_loss = 1.7770016888680402, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 482, train_loss = 1.7884022506477777, train_acc = 0.9947601304145319\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 483, train_loss = 1.78369208672666, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 484, train_loss = 1.7850909158587456, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 485, train_loss = 1.778094820678234, train_acc = 0.9947601304145319\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 486, train_loss = 1.7792407919914695, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 487, train_loss = 1.783994293451542, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 488, train_loss = 1.783808872103691, train_acc = 0.9948765719608756\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 489, train_loss = 1.7796241504402133, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 490, train_loss = 1.7768090801837388, train_acc = 0.9946436888681882\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 491, train_loss = 1.7847298631968442, train_acc = 0.9949930135072194\n",
      "test Acc 0.9753258845437617:\n",
      "20th- epoch: 492, train_loss = 1.7801852387638064, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 493, train_loss = 1.7754963922052411, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 494, train_loss = 1.7669856597931357, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 495, train_loss = 1.775226062789443, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 496, train_loss = 1.775602458670619, train_acc = 0.9948765719608756\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 497, train_loss = 1.7793124504387379, train_acc = 0.9946436888681882\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 498, train_loss = 1.7692227934749098, train_acc = 0.9947601304145319\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 499, train_loss = 1.7640513119549723, train_acc = 0.9948765719608756\n",
      "test Acc 0.9757914338919925:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████████████████████████████████████████████████▋                         | 20/30 [3:15:48<1:43:35, 621.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "21th- epoch: 0, train_loss = 427.0531081110239, train_acc = 0.790055891942245\n",
      "test Acc 0.8556797020484171:\n",
      "21th- epoch: 1, train_loss = 94.0101768001914, train_acc = 0.9074289706567303\n",
      "test Acc 0.9236499068901304:\n",
      "21th- epoch: 2, train_loss = 57.27509766817093, train_acc = 0.9288542151839776\n",
      "test Acc 0.9269087523277467:\n",
      "21th- epoch: 3, train_loss = 42.72798257693648, train_acc = 0.9415463437354448\n",
      "test Acc 0.9264432029795159:\n",
      "21th- epoch: 4, train_loss = 33.39505968987942, train_acc = 0.9501630181648812\n",
      "test Acc 0.9283054003724395:\n",
      "21th- epoch: 5, train_loss = 27.575609082356095, train_acc = 0.9572659524918491\n",
      "test Acc 0.931098696461825:\n",
      "21th- epoch: 6, train_loss = 23.263424636796117, train_acc = 0.959944108057755\n",
      "test Acc 0.9348230912476723:\n",
      "21th- epoch: 7, train_loss = 19.872260687872767, train_acc = 0.9627387051700047\n",
      "test Acc 0.9380819366852886:\n",
      "21th- epoch: 8, train_loss = 17.227902511134744, train_acc = 0.9670470423847228\n",
      "test Acc 0.9445996275605214:\n",
      "21th- epoch: 9, train_loss = 15.124999238178134, train_acc = 0.970540288775035\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 10, train_loss = 13.462399379350245, train_acc = 0.9729855612482534\n",
      "test Acc 0.9473929236499069:\n",
      "21th- epoch: 11, train_loss = 12.111336655914783, train_acc = 0.9750815090824406\n",
      "test Acc 0.9539106145251397:\n",
      "21th- epoch: 12, train_loss = 10.937057567760348, train_acc = 0.9774103400093154\n",
      "test Acc 0.9534450651769087:\n",
      "21th- epoch: 13, train_loss = 10.009262444451451, train_acc = 0.9791569632044713\n",
      "test Acc 0.9548417132216015:\n",
      "21th- epoch: 14, train_loss = 9.157873025164008, train_acc = 0.9810200279459711\n",
      "test Acc 0.9548417132216015:\n",
      "21th- epoch: 15, train_loss = 8.403108729049563, train_acc = 0.9817186772240335\n",
      "test Acc 0.9539106145251397:\n",
      "21th- epoch: 16, train_loss = 7.772412938065827, train_acc = 0.9820680018630648\n",
      "test Acc 0.9553072625698324:\n",
      "21th- epoch: 17, train_loss = 7.1560668256133795, train_acc = 0.9834653004191896\n",
      "test Acc 0.9557728119180633:\n",
      "21th- epoch: 18, train_loss = 6.646689027547836, train_acc = 0.9846297158826269\n",
      "test Acc 0.9562383612662942:\n",
      "21th- epoch: 19, train_loss = 6.219490804709494, train_acc = 0.985910572892408\n",
      "test Acc 0.9567039106145251:\n",
      "21th- epoch: 20, train_loss = 5.875340087339282, train_acc = 0.9869585468095017\n",
      "test Acc 0.957169459962756:\n",
      "21th- epoch: 21, train_loss = 5.579125917516649, train_acc = 0.9873078714485328\n",
      "test Acc 0.9567039106145251:\n",
      "21th- epoch: 22, train_loss = 5.314099985174835, train_acc = 0.9877736376339078\n",
      "test Acc 0.9567039106145251:\n",
      "21th- epoch: 23, train_loss = 5.0927058001980186, train_acc = 0.9881229622729389\n",
      "test Acc 0.9562383612662942:\n",
      "21th- epoch: 24, train_loss = 4.889879249036312, train_acc = 0.9889380530973452\n",
      "test Acc 0.957169459962756:\n",
      "21th- epoch: 25, train_loss = 4.689675648696721, train_acc = 0.98940381928272\n",
      "test Acc 0.957635009310987:\n",
      "21th- epoch: 26, train_loss = 4.546273468993604, train_acc = 0.9896367023754076\n",
      "test Acc 0.9608938547486033:\n",
      "21th- epoch: 27, train_loss = 4.391307232901454, train_acc = 0.9897531439217513\n",
      "test Acc 0.9585661080074488:\n",
      "21th- epoch: 28, train_loss = 4.264127358328551, train_acc = 0.989869585468095\n",
      "test Acc 0.9608938547486033:\n",
      "21th- epoch: 29, train_loss = 4.143200407736003, train_acc = 0.9899860270144387\n",
      "test Acc 0.9585661080074488:\n",
      "21th- epoch: 30, train_loss = 4.034433165565133, train_acc = 0.9904517931998137\n",
      "test Acc 0.9590316573556797:\n",
      "21th- epoch: 31, train_loss = 3.9335149717517197, train_acc = 0.9904517931998137\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 32, train_loss = 3.8482700958848, train_acc = 0.9905682347461574\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 33, train_loss = 3.748991026543081, train_acc = 0.990801117838845\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 34, train_loss = 3.67858780734241, train_acc = 0.9906846762925011\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 35, train_loss = 3.589925892651081, train_acc = 0.9909175593851887\n",
      "test Acc 0.9590316573556797:\n",
      "21th- epoch: 36, train_loss = 3.5202646027319133, train_acc = 0.9912668840242198\n",
      "test Acc 0.9594972067039106:\n",
      "21th- epoch: 37, train_loss = 3.4527062131091952, train_acc = 0.9913833255705635\n",
      "test Acc 0.9590316573556797:\n",
      "21th- epoch: 38, train_loss = 3.3788765147328377, train_acc = 0.9916162086632511\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 39, train_loss = 3.3327211481519043, train_acc = 0.9917326502095948\n",
      "test Acc 0.962756052141527:\n",
      "21th- epoch: 40, train_loss = 3.2746105236001313, train_acc = 0.9917326502095948\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 41, train_loss = 3.216456661000848, train_acc = 0.9919655333022822\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 42, train_loss = 3.167633438948542, train_acc = 0.992081974848626\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 43, train_loss = 3.135969588533044, train_acc = 0.9919655333022822\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 44, train_loss = 3.0918203010223806, train_acc = 0.9921984163949698\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 45, train_loss = 3.0449262522161007, train_acc = 0.9921984163949698\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 46, train_loss = 3.00856015086174, train_acc = 0.9923148579413135\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 47, train_loss = 2.973890614695847, train_acc = 0.9927806241266884\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 48, train_loss = 2.9452105471864343, train_acc = 0.9924312994876572\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 49, train_loss = 2.90125949960202, train_acc = 0.9928970656730322\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 50, train_loss = 2.875062944367528, train_acc = 0.9927806241266884\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 51, train_loss = 2.842184275155887, train_acc = 0.9927806241266884\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 52, train_loss = 2.8121963206212968, train_acc = 0.9927806241266884\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 53, train_loss = 2.7853686893358827, train_acc = 0.9928970656730322\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 54, train_loss = 2.7596099337097257, train_acc = 0.9930135072193759\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 55, train_loss = 2.7327005255501717, train_acc = 0.9931299487657196\n",
      "test Acc 0.9641527001862198:\n",
      "21th- epoch: 56, train_loss = 2.7077358439564705, train_acc = 0.9932463903120633\n",
      "test Acc 0.9646182495344506:\n",
      "21th- epoch: 57, train_loss = 2.6872988457325846, train_acc = 0.9932463903120633\n",
      "test Acc 0.9655493482309124:\n",
      "21th- epoch: 58, train_loss = 2.6728013090323657, train_acc = 0.9932463903120633\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 59, train_loss = 2.643206413136795, train_acc = 0.9931299487657196\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 60, train_loss = 2.6290716510266066, train_acc = 0.9932463903120633\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 61, train_loss = 2.6054401209112257, train_acc = 0.9932463903120633\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 62, train_loss = 2.587179481750354, train_acc = 0.9932463903120633\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 63, train_loss = 2.577639936702326, train_acc = 0.9931299487657196\n",
      "test Acc 0.9669459962756052:\n",
      "21th- epoch: 64, train_loss = 2.5523260994814336, train_acc = 0.9933628318584071\n",
      "test Acc 0.9674115456238361:\n",
      "21th- epoch: 65, train_loss = 2.53884305129759, train_acc = 0.9933628318584071\n",
      "test Acc 0.9674115456238361:\n",
      "21th- epoch: 66, train_loss = 2.5203671851195395, train_acc = 0.9934792734047508\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 67, train_loss = 2.510391252115369, train_acc = 0.9933628318584071\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 68, train_loss = 2.4932329955045134, train_acc = 0.9934792734047508\n",
      "test Acc 0.9674115456238361:\n",
      "21th- epoch: 69, train_loss = 2.4756296805571765, train_acc = 0.9934792734047508\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 70, train_loss = 2.462435679277405, train_acc = 0.9934792734047508\n",
      "test Acc 0.9678770949720671:\n",
      "21th- epoch: 71, train_loss = 2.4452702759299427, train_acc = 0.9934792734047508\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 72, train_loss = 2.4359872506465763, train_acc = 0.9934792734047508\n",
      "test Acc 0.9683426443202979:\n",
      "21th- epoch: 73, train_loss = 2.4194810898043215, train_acc = 0.9934792734047508\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 74, train_loss = 2.4135375556070358, train_acc = 0.9934792734047508\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 75, train_loss = 2.408984201028943, train_acc = 0.9934792734047508\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 76, train_loss = 2.3812932858709246, train_acc = 0.9934792734047508\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 77, train_loss = 2.3783593855332583, train_acc = 0.9935957149510946\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 78, train_loss = 2.3668525309767574, train_acc = 0.9935957149510946\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 79, train_loss = 2.36307998560369, train_acc = 0.9937121564974383\n",
      "test Acc 0.9697392923649907:\n",
      "21th- epoch: 80, train_loss = 2.347139830235392, train_acc = 0.993828598043782\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 81, train_loss = 2.33739839727059, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 82, train_loss = 2.323708117706701, train_acc = 0.9939450395901258\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 83, train_loss = 2.3219089317135513, train_acc = 0.9940614811364695\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 84, train_loss = 2.310337317408994, train_acc = 0.9939450395901258\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 85, train_loss = 2.2997191553004086, train_acc = 0.9939450395901258\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 86, train_loss = 2.2913810731843114, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 87, train_loss = 2.2927945218980312, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 88, train_loss = 2.273043713532388, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 89, train_loss = 2.2609836822375655, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 90, train_loss = 2.2653073957189918, train_acc = 0.9941779226828132\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 91, train_loss = 2.2536533803213388, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 92, train_loss = 2.2488969720434397, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 93, train_loss = 2.2358466496225446, train_acc = 0.9944108057755007\n",
      "test Acc 0.9702048417132216:\n",
      "21th- epoch: 94, train_loss = 2.2422387453261763, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 95, train_loss = 2.224285694072023, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 96, train_loss = 2.219349449733272, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 97, train_loss = 2.209014141233638, train_acc = 0.9945272473218444\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 98, train_loss = 2.2067629820667207, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 99, train_loss = 2.1997899101115763, train_acc = 0.9944108057755007\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 100, train_loss = 2.194912983570248, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 101, train_loss = 2.1921407433692366, train_acc = 0.994294364229157\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 102, train_loss = 2.183138510910794, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 103, train_loss = 2.177445152308792, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 104, train_loss = 2.1727514893282205, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 105, train_loss = 2.172923178644851, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 106, train_loss = 2.165676642442122, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 107, train_loss = 2.157522349152714, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 108, train_loss = 2.154077944578603, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 109, train_loss = 2.1458530898671597, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 110, train_loss = 2.1416464364156127, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 111, train_loss = 2.1396490682382137, train_acc = 0.9944108057755007\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 112, train_loss = 2.1333690711762756, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 113, train_loss = 2.1369547485373914, train_acc = 0.9944108057755007\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 114, train_loss = 2.1228915753308684, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 115, train_loss = 2.1199169498868287, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 116, train_loss = 2.1202989226439968, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 117, train_loss = 2.1115706022828817, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 118, train_loss = 2.1086511452449486, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 119, train_loss = 2.1055560811655596, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 120, train_loss = 2.1034982427954674, train_acc = 0.9945272473218444\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 121, train_loss = 2.097730807843618, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 122, train_loss = 2.094010980683379, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 123, train_loss = 2.0872206442290917, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 124, train_loss = 2.090636852546595, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 125, train_loss = 2.081920423428528, train_acc = 0.9946436888681882\n",
      "test Acc 0.9711359404096834:\n",
      "21th- epoch: 126, train_loss = 2.079355530324392, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 127, train_loss = 2.0771280935732648, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 128, train_loss = 2.068781736656092, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 129, train_loss = 2.0693134932080284, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 130, train_loss = 2.0679996103281155, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 131, train_loss = 2.0598925286903977, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 132, train_loss = 2.059597954619676, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 133, train_loss = 2.049061463214457, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 134, train_loss = 2.0468119661090896, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 135, train_loss = 2.047103014658205, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 136, train_loss = 2.0439426904777065, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 137, train_loss = 2.033994063618593, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 138, train_loss = 2.0382848761510104, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 139, train_loss = 2.0356704992009327, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 140, train_loss = 2.0281646080547944, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 141, train_loss = 2.028678391012363, train_acc = 0.9945272473218444\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 142, train_loss = 2.026562601677142, train_acc = 0.9946436888681882\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 143, train_loss = 2.0197489840211347, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 144, train_loss = 2.0232263039797544, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 145, train_loss = 2.016826556180604, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 146, train_loss = 2.0171807123115286, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 147, train_loss = 2.0133435144089162, train_acc = 0.9946436888681882\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 148, train_loss = 2.011051373439841, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 149, train_loss = 2.0127381993224844, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 150, train_loss = 2.003844129969366, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 151, train_loss = 1.996906858868897, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 152, train_loss = 1.998722321121022, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 153, train_loss = 1.9941131226951256, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 154, train_loss = 1.9943257520208135, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 155, train_loss = 1.9977985000004992, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 156, train_loss = 1.9919733270071447, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 157, train_loss = 1.9854401359334588, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 158, train_loss = 1.9924470309633762, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 159, train_loss = 1.9827333035646006, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 160, train_loss = 1.983725028927438, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 161, train_loss = 1.9775146474130452, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 162, train_loss = 1.9795099090551957, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 163, train_loss = 1.977716579916887, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 164, train_loss = 1.9750498345820233, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 165, train_loss = 1.972193717258051, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 166, train_loss = 1.971791629679501, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 167, train_loss = 1.9674348302651197, train_acc = 0.9947601304145319\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 168, train_loss = 1.9682087692199275, train_acc = 0.9948765719608756\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 169, train_loss = 1.96463519660756, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 170, train_loss = 1.9674939735559747, train_acc = 0.9947601304145319\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 171, train_loss = 1.960540448431857, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 172, train_loss = 1.9579616027185693, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 173, train_loss = 1.9556254567578435, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 174, train_loss = 1.954783161985688, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 175, train_loss = 1.9554164197761565, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 176, train_loss = 1.9467824455350637, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 177, train_loss = 1.9426739802584052, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 178, train_loss = 1.9498343418817967, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 179, train_loss = 1.9453068376751617, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 180, train_loss = 1.9438694333657622, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 181, train_loss = 1.9424290717579424, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 182, train_loss = 1.9385156924836338, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 183, train_loss = 1.9393492847448215, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 184, train_loss = 1.9382484058151022, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 185, train_loss = 1.933998386375606, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 186, train_loss = 1.9348818380385637, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 187, train_loss = 1.9319359003566206, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 188, train_loss = 1.931656030821614, train_acc = 0.9947601304145319\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 189, train_loss = 1.9311512199928984, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 190, train_loss = 1.9282330144196749, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 191, train_loss = 1.9247852801345289, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 192, train_loss = 1.926322869316209, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 193, train_loss = 1.9225067171500996, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 194, train_loss = 1.922598976350855, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 195, train_loss = 1.9197914136457257, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 196, train_loss = 1.9175468378816731, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 197, train_loss = 1.9166740491054952, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 198, train_loss = 1.9151020064018667, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 199, train_loss = 1.9141660357709043, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 200, train_loss = 1.912997756153345, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 201, train_loss = 1.9104959885589778, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 202, train_loss = 1.9130794291268103, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 203, train_loss = 1.9098770126583986, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 204, train_loss = 1.9076582887209952, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 205, train_loss = 1.9065117125282995, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 206, train_loss = 1.909889318223577, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 207, train_loss = 1.906870793842245, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 208, train_loss = 1.900789801205974, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 209, train_loss = 1.902387407142669, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 210, train_loss = 1.9031683970242739, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 211, train_loss = 1.902273207437247, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 212, train_loss = 1.9007090292870998, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 213, train_loss = 1.8978098868392408, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 214, train_loss = 1.8977548478287645, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 215, train_loss = 1.898091610695701, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 216, train_loss = 1.8929722348111682, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 217, train_loss = 1.88890786486445, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 218, train_loss = 1.8881363294203766, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 219, train_loss = 1.8881221899646334, train_acc = 0.9948765719608756\n",
      "test Acc 0.9720670391061452:\n",
      "21th- epoch: 220, train_loss = 1.8840659757261164, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 221, train_loss = 1.8851267264108174, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 222, train_loss = 1.8843724173493683, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 223, train_loss = 1.8834959723171778, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 224, train_loss = 1.8820458431728184, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 225, train_loss = 1.881645577494055, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 226, train_loss = 1.8774204947985709, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 227, train_loss = 1.8768165144138038, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 228, train_loss = 1.8806675795349292, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n",
      "21th- epoch: 229, train_loss = 1.8804370394791476, train_acc = 0.9948765719608756\n",
      "test Acc 0.9725325884543762:\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    read_path = 'D:virus/image/2gram_768/'\n",
    "    \n",
    "    temp = [[],[]]\n",
    "    \n",
    "    Loader = D.File_loader()\n",
    "    data_a, label_a = Loader.read_files(read_path, interp = False)\n",
    "    \n",
    "    idx = np.argsort(label_a)\n",
    "    \n",
    "    sorted_data = data_a[idx].reshape(10736, -1)\n",
    "    sorted_label = sorted(label_a)\n",
    "        \n",
    "    BATCH_SIZE = 64\n",
    "    TOTAL = 30\n",
    "    EPOCH = 500\n",
    "    NUM_CLASS = 9\n",
    "    LR = 0.0001\n",
    "    SEED = [s for s in range(TOTAL)]\n",
    "    INPUT_NODES = 768                   \n",
    "    \n",
    "    CUDA_N = 'cuda:1'\n",
    "    \n",
    "    # creating data indices for spliting\n",
    "    full_dataset = CustomDataset(sorted_data, sorted_label)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # spliting\n",
    "    torch.manual_seed(10)\n",
    "    train_dataset, test_dataset = data.random_split(full_dataset, [train_size, test_size])\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    loss_total = []\n",
    "    acc_total = []\n",
    "    pred_total = []\n",
    "    true_total = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(TOTAL)):\n",
    "        \n",
    "        device = torch.device(CUDA_N if torch.cuda.is_available() else 'cpu')\n",
    "        torch.manual_seed(SEED[i])\n",
    "        net = Net(INPUT_NODES, NUM_CLASS)           \n",
    "        net.to(device)\n",
    "        print(net)\n",
    "        \n",
    "        softmax = nn.Softmax()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=LR, momentum = 0.1)\n",
    "        \n",
    "        loss_list = []\n",
    "        train_acc_list = []\n",
    "        test_acc_list = []\n",
    "        \n",
    "        pred_temp = []\n",
    "        true_temp = []\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            net.train()\n",
    "            running_loss = 0\n",
    "            total = train_size\n",
    "            correct = 0 \n",
    "            \n",
    "            for step, image_and_label in enumerate(train_loader):\n",
    "                inputs, labels = image_and_label            \n",
    "                inputs, labels = inputs.type(torch.FloatTensor).to(device), labels.type(torch.LongTensor).to(device)\n",
    "                \n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, pred = torch.max(outputs, dim=1)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            train_acc = correct/total\n",
    "            loss_list.append(running_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "            print('{}th- epoch: {}, train_loss = {}, train_acc = {}'.format(i+1, epoch, running_loss, train_acc))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                correct = 0\n",
    "                total = test_size\n",
    "                pt, tt = [], []\n",
    "                \n",
    "                for step_t, image_and_label_t in enumerate(test_loader):\n",
    "                    inputs_t, labels_t = image_and_label_t            \n",
    "                    inputs_t, labels_t = inputs_t.type(torch.FloatTensor).to(device), labels_t.type(torch.LongTensor).to(device)\n",
    "                    \n",
    "                    outputs_t = net(inputs_t)\n",
    "                    outputs_t = softmax(outputs_t)\n",
    "                    \n",
    "                    # test accuracy\n",
    "                    _, pred_t = torch.max(outputs_t, dim = 1)\n",
    "                    \n",
    "                    pt.append(pred_t)\n",
    "                    tt.append(labels_t)\n",
    "                    \n",
    "                    correct += (pred_t == labels_t).sum().item()\n",
    "                    \n",
    "                pred_temp.append(torch.cat(pt))\n",
    "                true_temp.append(torch.cat(tt))\n",
    "                \n",
    "                test_acc = correct/total\n",
    "                test_acc_list.append(test_acc)\n",
    "                \n",
    "                print('test Acc {}:'.format(test_acc))\n",
    "                \n",
    "        best_result_index = np.argmax(np.array(test_acc_list))\n",
    "        loss_total.append(loss_list[best_result_index])\n",
    "        acc_total.append(test_acc_list[best_result_index])\n",
    "        pred_total.append(pred_temp[best_result_index].tolist())\n",
    "        true_total.append(true_temp[best_result_index].tolist())\n",
    "        \n",
    "    file_name = 'res/2gram_baseline'\n",
    "    torch.save(net.state_dict(), file_name +'.pth')\n",
    "    \n",
    "    loss_DF = pd.DataFrame(loss_total)\n",
    "    loss_DF.to_csv(file_name+\" loss.csv\")\n",
    "    \n",
    "    acc_DF = pd.DataFrame(acc_total)\n",
    "    acc_DF.to_csv(file_name +\" acc.csv\")\n",
    "    \n",
    "    pred_DF = pd.DataFrame(pred_total)\n",
    "    pred_DF.to_csv(file_name +\" pred.csv\")\n",
    "    \n",
    "    true_DF = pd.DataFrame(true_total)\n",
    "    true_DF.to_csv(file_name +\" true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
