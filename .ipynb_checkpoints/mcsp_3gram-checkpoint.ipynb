{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "\n",
    "import utility.Data_loader as D\n",
    "from utility.Model import MCSP\n",
    "from utility.Custom import CustomDataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                    | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "1th- epoch: 0, train_loss = 269.6466189622879, train_acc = 0.4704238472286912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\DTools\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:96: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.5544692737430168:\n",
      "1th- epoch: 1, train_loss = 201.7161432504654, train_acc = 0.55985095482068\n",
      "test Acc 0.574487895716946:\n",
      "1th- epoch: 2, train_loss = 158.2495440840721, train_acc = 0.598625989753144\n",
      "test Acc 0.6433891992551211:\n",
      "1th- epoch: 3, train_loss = 134.24864888191223, train_acc = 0.6723334885887284\n",
      "test Acc 0.7118249534450651:\n",
      "1th- epoch: 4, train_loss = 116.16906243562698, train_acc = 0.7367256637168141\n",
      "test Acc 0.7611731843575419:\n",
      "1th- epoch: 5, train_loss = 100.92556434869766, train_acc = 0.7695621797857476\n",
      "test Acc 0.7830540037243948:\n",
      "1th- epoch: 6, train_loss = 88.15386912226677, train_acc = 0.7856311131811831\n",
      "test Acc 0.803072625698324:\n",
      "1th- epoch: 7, train_loss = 77.63916876912117, train_acc = 0.8176525384257103\n",
      "test Acc 0.8324022346368715:\n",
      "1th- epoch: 8, train_loss = 68.75953707098961, train_acc = 0.8433861201676758\n",
      "test Acc 0.8589385474860335:\n",
      "1th- epoch: 9, train_loss = 61.048555850982666, train_acc = 0.8756404285048905\n",
      "test Acc 0.8924581005586593:\n",
      "1th- epoch: 10, train_loss = 54.345185935497284, train_acc = 0.9056823474615743\n",
      "test Acc 0.9199255121042831:\n",
      "1th- epoch: 11, train_loss = 48.60151346027851, train_acc = 0.9273404750815091\n",
      "test Acc 0.9324953445065177:\n",
      "1th- epoch: 12, train_loss = 43.75121560692787, train_acc = 0.9364229156963204\n",
      "test Acc 0.9380819366852886:\n",
      "1th- epoch: 13, train_loss = 39.70053528249264, train_acc = 0.9384024219841639\n",
      "test Acc 0.9413407821229051:\n",
      "1th- epoch: 14, train_loss = 36.32670298963785, train_acc = 0.9406148113646949\n",
      "test Acc 0.9441340782122905:\n",
      "1th- epoch: 15, train_loss = 33.51056223362684, train_acc = 0.9436422915696321\n",
      "test Acc 0.9487895716945997:\n",
      "1th- epoch: 16, train_loss = 31.139859698712826, train_acc = 0.9481835118770378\n",
      "test Acc 0.9506517690875232:\n",
      "1th- epoch: 17, train_loss = 29.131937228143215, train_acc = 0.9503959012575687\n",
      "test Acc 0.952513966480447:\n",
      "1th- epoch: 18, train_loss = 27.412813656032085, train_acc = 0.952491849091756\n",
      "test Acc 0.9553072625698324:\n",
      "1th- epoch: 19, train_loss = 25.923784390091896, train_acc = 0.9542384722869119\n",
      "test Acc 0.9557728119180633:\n",
      "1th- epoch: 20, train_loss = 24.61983670666814, train_acc = 0.9561015370284117\n",
      "test Acc 0.9567039106145251:\n",
      "1th- epoch: 21, train_loss = 23.46697971969843, train_acc = 0.9578481602235678\n",
      "test Acc 0.957169459962756:\n",
      "1th- epoch: 22, train_loss = 22.43907569348812, train_acc = 0.9592454587796926\n",
      "test Acc 0.9581005586592178:\n",
      "1th- epoch: 23, train_loss = 21.517950855195522, train_acc = 0.9605263157894737\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 24, train_loss = 20.686424884945154, train_acc = 0.9614578481602236\n",
      "test Acc 0.9585661080074488:\n",
      "1th- epoch: 25, train_loss = 19.930496975779533, train_acc = 0.9629715882626921\n",
      "test Acc 0.9590316573556797:\n",
      "1th- epoch: 26, train_loss = 19.23941368609667, train_acc = 0.9635537959944108\n",
      "test Acc 0.9599627560521415:\n",
      "1th- epoch: 27, train_loss = 18.604060605168343, train_acc = 0.9646017699115044\n",
      "test Acc 0.9604283054003724:\n",
      "1th- epoch: 28, train_loss = 18.01719642430544, train_acc = 0.9658826269212856\n",
      "test Acc 0.9604283054003724:\n",
      "1th- epoch: 29, train_loss = 17.472678247839212, train_acc = 0.9669306008383791\n",
      "test Acc 0.9632216014897579:\n",
      "1th- epoch: 30, train_loss = 16.965192675590515, train_acc = 0.9677456916627852\n",
      "test Acc 0.9650837988826816:\n",
      "1th- epoch: 31, train_loss = 16.490298558026552, train_acc = 0.9692594317652539\n",
      "test Acc 0.9664804469273743:\n",
      "1th- epoch: 32, train_loss = 16.044159833341837, train_acc = 0.97007452258966\n",
      "test Acc 0.9674115456238361:\n",
      "1th- epoch: 33, train_loss = 15.623916320502758, train_acc = 0.9708896134140661\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 34, train_loss = 15.22774225473404, train_acc = 0.971821145784816\n",
      "test Acc 0.9683426443202979:\n",
      "1th- epoch: 35, train_loss = 14.853032529354095, train_acc = 0.972286911970191\n",
      "test Acc 0.9688081936685289:\n",
      "1th- epoch: 36, train_loss = 14.497779749333858, train_acc = 0.9727526781555659\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 37, train_loss = 14.160488281399012, train_acc = 0.9736842105263158\n",
      "test Acc 0.9692737430167597:\n",
      "1th- epoch: 38, train_loss = 13.840283092111349, train_acc = 0.9739170936190032\n",
      "test Acc 0.9697392923649907:\n",
      "1th- epoch: 39, train_loss = 13.535810470581055, train_acc = 0.9742664182580345\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 40, train_loss = 13.245530687272549, train_acc = 0.9750815090824406\n",
      "test Acc 0.9706703910614525:\n",
      "1th- epoch: 41, train_loss = 12.968653611838818, train_acc = 0.975314392175128\n",
      "test Acc 0.9711359404096834:\n",
      "1th- epoch: 42, train_loss = 12.70405575633049, train_acc = 0.9764788076385654\n",
      "test Acc 0.9725325884543762:\n",
      "1th- epoch: 43, train_loss = 12.450846698135138, train_acc = 0.9776432231020028\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 44, train_loss = 12.208174981176853, train_acc = 0.9784583139264089\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 45, train_loss = 11.975596271455288, train_acc = 0.9786911970190965\n",
      "test Acc 0.9743947858472998:\n",
      "1th- epoch: 46, train_loss = 11.752260938286781, train_acc = 0.9795062878435026\n",
      "test Acc 0.9753258845437617:\n",
      "1th- epoch: 47, train_loss = 11.53745286166668, train_acc = 0.9796227293898463\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 48, train_loss = 11.33072105050087, train_acc = 0.9798556124825337\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 49, train_loss = 11.131496589630842, train_acc = 0.9799720540288775\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 50, train_loss = 10.939473181962967, train_acc = 0.98067070330694\n",
      "test Acc 0.9757914338919925:\n",
      "1th- epoch: 51, train_loss = 10.7539644241333, train_acc = 0.9813693525850024\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 52, train_loss = 10.57459631562233, train_acc = 0.9813693525850024\n",
      "test Acc 0.9762569832402235:\n",
      "1th- epoch: 53, train_loss = 10.40116535499692, train_acc = 0.9814857941313461\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 54, train_loss = 10.233369622379541, train_acc = 0.9816022356776898\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 55, train_loss = 10.070987608283758, train_acc = 0.9817186772240335\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 56, train_loss = 9.913541341200471, train_acc = 0.9818351187703773\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 57, train_loss = 9.760650200769305, train_acc = 0.981951560316721\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 58, train_loss = 9.61211227811873, train_acc = 0.9824173265020959\n",
      "test Acc 0.9767225325884544:\n",
      "1th- epoch: 59, train_loss = 9.467646727338433, train_acc = 0.9826502095947834\n",
      "test Acc 0.9771880819366853:\n",
      "1th- epoch: 60, train_loss = 9.327025821432471, train_acc = 0.9828830926874709\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 61, train_loss = 9.189842086285353, train_acc = 0.9832324173265021\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 62, train_loss = 9.055949883535504, train_acc = 0.9834653004191896\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 63, train_loss = 8.925140367820859, train_acc = 0.9834653004191896\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 64, train_loss = 8.797644110396504, train_acc = 0.9834653004191896\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 65, train_loss = 8.673196163028479, train_acc = 0.9835817419655333\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 66, train_loss = 8.551455726847053, train_acc = 0.9835817419655333\n",
      "test Acc 0.9776536312849162:\n",
      "1th- epoch: 67, train_loss = 8.432482205331326, train_acc = 0.9835817419655333\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 68, train_loss = 8.316262267529964, train_acc = 0.9838146250582208\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 69, train_loss = 8.202745489776134, train_acc = 0.9840475081509082\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 70, train_loss = 8.091723121702671, train_acc = 0.9842803912435957\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 71, train_loss = 7.983099963515997, train_acc = 0.9843968327899395\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 72, train_loss = 7.876590279862285, train_acc = 0.9846297158826269\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 73, train_loss = 7.77204461582005, train_acc = 0.9849790405216581\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 74, train_loss = 7.669692806899548, train_acc = 0.9850954820680019\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 75, train_loss = 7.569384129717946, train_acc = 0.9850954820680019\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 76, train_loss = 7.471075747162104, train_acc = 0.9849790405216581\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 77, train_loss = 7.3745809476822615, train_acc = 0.9850954820680019\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 78, train_loss = 7.280019896104932, train_acc = 0.9853283651606893\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 79, train_loss = 7.187291508540511, train_acc = 0.9855612482533768\n",
      "test Acc 0.9781191806331471:\n",
      "1th- epoch: 80, train_loss = 7.096096184104681, train_acc = 0.9857941313460643\n",
      "test Acc 0.978584729981378:\n",
      "1th- epoch: 81, train_loss = 7.006498325616121, train_acc = 0.9861434559850955\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 82, train_loss = 6.918615201488137, train_acc = 0.9862598975314392\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 83, train_loss = 6.832475546747446, train_acc = 0.986376339077783\n",
      "test Acc 0.979050279329609:\n",
      "1th- epoch: 84, train_loss = 6.74798727966845, train_acc = 0.9864927806241267\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 85, train_loss = 6.665183678269386, train_acc = 0.9866092221704704\n",
      "test Acc 0.9795158286778398:\n",
      "1th- epoch: 86, train_loss = 6.583709528669715, train_acc = 0.9869585468095017\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 87, train_loss = 6.503741133958101, train_acc = 0.9873078714485328\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 88, train_loss = 6.425193067640066, train_acc = 0.9874243129948765\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 89, train_loss = 6.3480918146669865, train_acc = 0.9874243129948765\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 90, train_loss = 6.272453736513853, train_acc = 0.9876571960875641\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 91, train_loss = 6.198139099404216, train_acc = 0.9876571960875641\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 92, train_loss = 6.125132832676172, train_acc = 0.9880065207265952\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 93, train_loss = 6.053426468744874, train_acc = 0.9883558453656265\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 94, train_loss = 5.982830949127674, train_acc = 0.9883558453656265\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 95, train_loss = 5.913480665534735, train_acc = 0.9884722869119702\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 96, train_loss = 5.845446085557342, train_acc = 0.9885887284583139\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 97, train_loss = 5.778616914525628, train_acc = 0.9887051700046576\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 98, train_loss = 5.713056417182088, train_acc = 0.9887051700046576\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 99, train_loss = 5.648636374622583, train_acc = 0.9890544946436889\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 100, train_loss = 5.585079440847039, train_acc = 0.9891709361900326\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 101, train_loss = 5.522665098309517, train_acc = 0.9895202608290639\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 102, train_loss = 5.46136914845556, train_acc = 0.9896367023754076\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 103, train_loss = 5.401222023181617, train_acc = 0.9896367023754076\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 104, train_loss = 5.3420039070770144, train_acc = 0.9896367023754076\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 105, train_loss = 5.283830696716905, train_acc = 0.989869585468095\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 106, train_loss = 5.226611866615713, train_acc = 0.989869585468095\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 107, train_loss = 5.1703468868508935, train_acc = 0.9902189101071263\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 108, train_loss = 5.115043197758496, train_acc = 0.9904517931998137\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 109, train_loss = 5.060598615556955, train_acc = 0.9905682347461574\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 110, train_loss = 5.007126797921956, train_acc = 0.990801117838845\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 111, train_loss = 4.954493594355881, train_acc = 0.9911504424778761\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 112, train_loss = 4.9028010638430715, train_acc = 0.9912668840242198\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 113, train_loss = 4.851837825961411, train_acc = 0.9912668840242198\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 114, train_loss = 4.8016996728256345, train_acc = 0.9914997671169073\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 115, train_loss = 4.752410371787846, train_acc = 0.9914997671169073\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 116, train_loss = 4.703994138166308, train_acc = 0.9914997671169073\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 117, train_loss = 4.656291044317186, train_acc = 0.9914997671169073\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 118, train_loss = 4.609433796256781, train_acc = 0.9914997671169073\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 119, train_loss = 4.5632769064977765, train_acc = 0.9916162086632511\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 120, train_loss = 4.517920549027622, train_acc = 0.9917326502095948\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 121, train_loss = 4.4732183665037155, train_acc = 0.9918490917559385\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 122, train_loss = 4.42929427139461, train_acc = 0.992081974848626\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 123, train_loss = 4.386069375090301, train_acc = 0.992081974848626\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 124, train_loss = 4.343458267860115, train_acc = 0.992081974848626\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 125, train_loss = 4.301611921750009, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 126, train_loss = 4.260275858454406, train_acc = 0.9923148579413135\n",
      "test Acc 0.9809124767225326:\n",
      "1th- epoch: 127, train_loss = 4.219770863652229, train_acc = 0.9926641825803446\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 128, train_loss = 4.179774472489953, train_acc = 0.9927806241266884\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 129, train_loss = 4.140402710996568, train_acc = 0.9928970656730322\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 130, train_loss = 4.101615701802075, train_acc = 0.9928970656730322\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 131, train_loss = 4.063391612842679, train_acc = 0.9930135072193759\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 132, train_loss = 4.0257824612781405, train_acc = 0.9930135072193759\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 133, train_loss = 3.9888873444870114, train_acc = 0.9931299487657196\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 134, train_loss = 3.952408420853317, train_acc = 0.9932463903120633\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 135, train_loss = 3.9165582498535514, train_acc = 0.9932463903120633\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 136, train_loss = 3.8812565682455897, train_acc = 0.9932463903120633\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 137, train_loss = 3.846432221122086, train_acc = 0.9932463903120633\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 138, train_loss = 3.8121559331193566, train_acc = 0.9934792734047508\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 139, train_loss = 3.7784010162577033, train_acc = 0.9935957149510946\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 140, train_loss = 3.7450850307941437, train_acc = 0.9935957149510946\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 141, train_loss = 3.712337742559612, train_acc = 0.9937121564974383\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 142, train_loss = 3.6801313403993845, train_acc = 0.993828598043782\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 143, train_loss = 3.648360899183899, train_acc = 0.993828598043782\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 144, train_loss = 3.6169481785036623, train_acc = 0.9939450395901258\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 145, train_loss = 3.585963948164135, train_acc = 0.9939450395901258\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 146, train_loss = 3.5555168758146465, train_acc = 0.9940614811364695\n",
      "test Acc 0.9813780260707635:\n",
      "1th- epoch: 147, train_loss = 3.525448170956224, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 148, train_loss = 3.495803155004978, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 149, train_loss = 3.4666131217963994, train_acc = 0.9944108057755007\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 150, train_loss = 3.437725957483053, train_acc = 0.9944108057755007\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 151, train_loss = 3.4093281370587647, train_acc = 0.9945272473218444\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 152, train_loss = 3.381336710881442, train_acc = 0.9946436888681882\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 153, train_loss = 3.353628220502287, train_acc = 0.9946436888681882\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 154, train_loss = 3.3263345402665436, train_acc = 0.9947601304145319\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 155, train_loss = 3.299401435535401, train_acc = 0.9947601304145319\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 156, train_loss = 3.2728324993513525, train_acc = 0.9948765719608756\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 157, train_loss = 3.246619677171111, train_acc = 0.9948765719608756\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 158, train_loss = 3.2207191199995577, train_acc = 0.9948765719608756\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 159, train_loss = 3.1952278283424675, train_acc = 0.9948765719608756\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 160, train_loss = 3.1700091338716447, train_acc = 0.9948765719608756\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 161, train_loss = 3.1452078372240067, train_acc = 0.9948765719608756\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 162, train_loss = 3.1207343824207783, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 163, train_loss = 3.096506129950285, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 164, train_loss = 3.072704663965851, train_acc = 0.9952258965999069\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 165, train_loss = 3.0491370311938226, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 166, train_loss = 3.026062531862408, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "1th- epoch: 167, train_loss = 3.002976545598358, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "1th- epoch: 168, train_loss = 2.980540367309004, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "1th- epoch: 169, train_loss = 2.9581656134687364, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "1th- epoch: 170, train_loss = 2.9360423237085342, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 171, train_loss = 2.914409816265106, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 172, train_loss = 2.8929216167889535, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 173, train_loss = 2.8717204011045396, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 174, train_loss = 2.850849434733391, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 175, train_loss = 2.8301386013627052, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 176, train_loss = 2.809790663421154, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 177, train_loss = 2.7896445230580866, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 178, train_loss = 2.7696761614643037, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 179, train_loss = 2.7501199543476105, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 180, train_loss = 2.7306616716086864, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 181, train_loss = 2.711507791187614, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 182, train_loss = 2.692634748760611, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 183, train_loss = 2.6740781129337847, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 184, train_loss = 2.6556046828627586, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 185, train_loss = 2.6374017694033682, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 186, train_loss = 2.6194307268597186, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 187, train_loss = 2.601701082661748, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 188, train_loss = 2.5842667121905833, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 189, train_loss = 2.5669542371761054, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 190, train_loss = 2.5499216814059764, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 191, train_loss = 2.533041924936697, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 192, train_loss = 2.51656293310225, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 193, train_loss = 2.5000728114973754, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 194, train_loss = 2.4839204363524914, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 195, train_loss = 2.4679051109123975, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 196, train_loss = 2.4520824637729675, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 197, train_loss = 2.436503052012995, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 198, train_loss = 2.4211716391146183, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 199, train_loss = 2.405964880483225, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 200, train_loss = 2.390969234285876, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 201, train_loss = 2.3761805172543973, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 202, train_loss = 2.3615901686716825, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 203, train_loss = 2.3471408300101757, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 204, train_loss = 2.3329448476433754, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "1th- epoch: 205, train_loss = 2.3188119244296104, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 206, train_loss = 2.30492051015608, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 207, train_loss = 2.2913044281303883, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 208, train_loss = 2.277569818077609, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 209, train_loss = 2.2642960872035474, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 210, train_loss = 2.250985602615401, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 211, train_loss = 2.237965311156586, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 212, train_loss = 2.2250205166637897, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 213, train_loss = 2.212267455412075, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 214, train_loss = 2.1996838059276342, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 215, train_loss = 2.1872314151842147, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 216, train_loss = 2.17497714352794, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 217, train_loss = 2.162851380184293, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 218, train_loss = 2.150845402851701, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 219, train_loss = 2.1390734650194645, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 220, train_loss = 2.1274257774930447, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 221, train_loss = 2.1158278312068433, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 222, train_loss = 2.104471082566306, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 223, train_loss = 2.0932590551674366, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 224, train_loss = 2.0821476851124316, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 225, train_loss = 2.071209157584235, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 226, train_loss = 2.060284501640126, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 227, train_loss = 2.0496553864795715, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 228, train_loss = 2.039041633484885, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 229, train_loss = 2.0286964748520404, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 230, train_loss = 2.018346354365349, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 231, train_loss = 2.008144997060299, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 232, train_loss = 1.9981546874623746, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 233, train_loss = 1.9881994612514973, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 234, train_loss = 1.9783421617466956, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 235, train_loss = 1.9687690027058125, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 236, train_loss = 1.959131881594658, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 237, train_loss = 1.9497184816282243, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 238, train_loss = 1.940485417842865, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 239, train_loss = 1.9311757646501064, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 240, train_loss = 1.922200302244164, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 241, train_loss = 1.9131104523548856, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 242, train_loss = 1.9043674072017893, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 243, train_loss = 1.8954626644263044, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 244, train_loss = 1.8868961768457666, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 245, train_loss = 1.8783236952731386, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 246, train_loss = 1.8699205741286278, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 247, train_loss = 1.8615208268165588, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 248, train_loss = 1.8532909415662289, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 249, train_loss = 1.8451656749239191, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 250, train_loss = 1.837073421687819, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 251, train_loss = 1.8291394487023354, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 252, train_loss = 1.8212452990701422, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 253, train_loss = 1.8134500285377726, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 254, train_loss = 1.8057799153029919, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 255, train_loss = 1.7981921335449442, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 256, train_loss = 1.79068475717213, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 257, train_loss = 1.7831653667381033, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 258, train_loss = 1.7759365662932396, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 259, train_loss = 1.768502127379179, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 260, train_loss = 1.7614245055010542, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 261, train_loss = 1.7541785625508055, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 262, train_loss = 1.7472101909806952, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 263, train_loss = 1.7401624160120264, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 264, train_loss = 1.7333056392380968, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 265, train_loss = 1.7264273948967457, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 266, train_loss = 1.7197164656827226, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 267, train_loss = 1.7130160989472643, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 268, train_loss = 1.7063704604515806, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 269, train_loss = 1.6998541504144669, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 270, train_loss = 1.6933305574348196, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 271, train_loss = 1.6869555140146986, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 272, train_loss = 1.6805525608360767, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 273, train_loss = 1.6743088563671336, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 274, train_loss = 1.6680825129151344, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 275, train_loss = 1.6618582332739606, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 276, train_loss = 1.6557486107340083, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 277, train_loss = 1.649823391227983, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 278, train_loss = 1.643768181442283, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "1th- epoch: 279, train_loss = 1.6378587037324905, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 280, train_loss = 1.6320096390554681, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 281, train_loss = 1.6262339180102572, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 282, train_loss = 1.6204800246050581, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 283, train_loss = 1.6147681338479742, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 284, train_loss = 1.6091463280608878, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 285, train_loss = 1.6035338243236765, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 286, train_loss = 1.5979759618639946, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 287, train_loss = 1.5925328781595454, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 288, train_loss = 1.58709028235171, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 289, train_loss = 1.5817144451430067, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 290, train_loss = 1.5763677643844858, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 291, train_loss = 1.5711431776871905, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 292, train_loss = 1.5658618273446336, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 293, train_loss = 1.5607253970811144, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 294, train_loss = 1.5554941283771768, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 295, train_loss = 1.5504607172915712, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "1th- epoch: 296, train_loss = 1.5453752899775282, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 297, train_loss = 1.5404181195190176, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 298, train_loss = 1.5354919781675562, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 299, train_loss = 1.5305500800022855, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 300, train_loss = 1.5256622917950153, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 301, train_loss = 1.5208372958004475, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 302, train_loss = 1.5160855799913406, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 303, train_loss = 1.5113050999352708, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 304, train_loss = 1.5066060088574886, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 305, train_loss = 1.5019355900585651, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 306, train_loss = 1.4973172334721312, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 307, train_loss = 1.492761212051846, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 308, train_loss = 1.4880729652941227, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 309, train_loss = 1.4835210380260833, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 310, train_loss = 1.4789800234138966, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 311, train_loss = 1.474425807595253, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 312, train_loss = 1.4700791637296788, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 313, train_loss = 1.465689065575134, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 314, train_loss = 1.4613384107942693, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 315, train_loss = 1.457126121968031, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 316, train_loss = 1.4528487722272985, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 317, train_loss = 1.448698750406038, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 318, train_loss = 1.444463164836634, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 319, train_loss = 1.4404158753459342, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 320, train_loss = 1.4362250082194805, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 321, train_loss = 1.432188991457224, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 322, train_loss = 1.4281356942956336, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 323, train_loss = 1.4242024831473827, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 324, train_loss = 1.4201882009510882, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 325, train_loss = 1.4162358865141869, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 326, train_loss = 1.412379015237093, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 327, train_loss = 1.408417146652937, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 328, train_loss = 1.4047051283414476, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 329, train_loss = 1.4008664402063005, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 330, train_loss = 1.3970636650919914, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 331, train_loss = 1.3933200314640999, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 332, train_loss = 1.389668734103907, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 333, train_loss = 1.38590033975197, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 334, train_loss = 1.3823365246062167, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 335, train_loss = 1.3785981784458272, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 336, train_loss = 1.3750313483178616, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "1th- epoch: 337, train_loss = 1.3714632714982145, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 338, train_loss = 1.3678388993139379, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 339, train_loss = 1.3643888967926614, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 340, train_loss = 1.3608222951297648, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 341, train_loss = 1.357454703480471, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 342, train_loss = 1.3539095570449717, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 343, train_loss = 1.350622519850731, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 344, train_loss = 1.3471553102135658, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 345, train_loss = 1.3437828334863298, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 346, train_loss = 1.3405010004644282, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 347, train_loss = 1.3371416230802424, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 348, train_loss = 1.3338913309271447, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 349, train_loss = 1.3306108117103577, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 350, train_loss = 1.3273229797487147, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 351, train_loss = 1.3242116968031041, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 352, train_loss = 1.3209848292171955, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 353, train_loss = 1.3178077724878676, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 354, train_loss = 1.3146646929089911, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 355, train_loss = 1.3115959887509234, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 356, train_loss = 1.308426809788216, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 357, train_loss = 1.3054225382511504, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 358, train_loss = 1.302388023585081, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 359, train_loss = 1.2993316873908043, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 360, train_loss = 1.2963426299393177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 361, train_loss = 1.293394435197115, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 362, train_loss = 1.2903908590669744, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 363, train_loss = 1.2875027830596082, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 364, train_loss = 1.284515614330303, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 365, train_loss = 1.2816917076706886, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 366, train_loss = 1.2787188540096395, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 367, train_loss = 1.2759841407532804, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 368, train_loss = 1.273045598238241, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 369, train_loss = 1.2702773846685886, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 370, train_loss = 1.2674981864984147, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 371, train_loss = 1.2647154393489473, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 372, train_loss = 1.2619438618421555, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 373, train_loss = 1.2591873382334597, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 374, train_loss = 1.2565007421071641, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 375, train_loss = 1.2537700533866882, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 376, train_loss = 1.2511139524285682, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 377, train_loss = 1.2484463465516455, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 378, train_loss = 1.2457565255463123, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 379, train_loss = 1.243249996274244, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 380, train_loss = 1.240534772456158, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 381, train_loss = 1.2379374367301352, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 382, train_loss = 1.2354281283915043, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 383, train_loss = 1.2328040413558483, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 384, train_loss = 1.2302961274981499, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 385, train_loss = 1.2277655999059789, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 386, train_loss = 1.2252138418261893, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 387, train_loss = 1.2227689561550505, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 388, train_loss = 1.2203367712791078, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 389, train_loss = 1.2177932895720005, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 390, train_loss = 1.2153838251833804, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 391, train_loss = 1.212925087660551, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 392, train_loss = 1.210534776269924, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 393, train_loss = 1.2081297325785272, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 394, train_loss = 1.2057440653443336, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 395, train_loss = 1.2033446567947976, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 396, train_loss = 1.2010263204574585, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 397, train_loss = 1.1987015902996063, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 398, train_loss = 1.1964029794035014, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 399, train_loss = 1.1940758687851485, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 400, train_loss = 1.1917886485753115, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 401, train_loss = 1.1894625512359198, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 402, train_loss = 1.1873286999762058, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 403, train_loss = 1.1849450232984964, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 404, train_loss = 1.1828394321200904, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 405, train_loss = 1.1805046436784323, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 406, train_loss = 1.1784055083990097, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 407, train_loss = 1.1760925079288427, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 408, train_loss = 1.1740142901835497, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "1th- epoch: 409, train_loss = 1.171785560756689, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 410, train_loss = 1.1696454597113188, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 411, train_loss = 1.1675623754563276, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 412, train_loss = 1.165425748884445, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 413, train_loss = 1.1632936013338622, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 414, train_loss = 1.161224519222742, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 415, train_loss = 1.1591521377267782, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 416, train_loss = 1.1570113177003805, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 417, train_loss = 1.1549522491695825, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 418, train_loss = 1.1529218405485153, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 419, train_loss = 1.150889733195072, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 420, train_loss = 1.1489043670298997, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 421, train_loss = 1.1468639808299486, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 422, train_loss = 1.1447952178714331, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 423, train_loss = 1.1429551703331526, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "1th- epoch: 424, train_loss = 1.140845611691475, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 425, train_loss = 1.1389608569443226, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 426, train_loss = 1.1369303377869073, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 427, train_loss = 1.1350347349944059, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 428, train_loss = 1.1330729176697787, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 429, train_loss = 1.1311511943640653, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 430, train_loss = 1.1293176462349948, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 431, train_loss = 1.1273377127945423, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 432, train_loss = 1.1254767825303134, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 433, train_loss = 1.123586824774975, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 434, train_loss = 1.1217818570730742, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 435, train_loss = 1.1198622149822768, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 436, train_loss = 1.1180567604897078, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 437, train_loss = 1.116259844362503, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 438, train_loss = 1.11435996988439, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 439, train_loss = 1.1126113893988077, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 440, train_loss = 1.1107580227253493, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 441, train_loss = 1.109030603111023, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 442, train_loss = 1.1071546748280525, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 443, train_loss = 1.105466232955223, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 444, train_loss = 1.1036182219686452, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 445, train_loss = 1.101862152427202, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 446, train_loss = 1.1001566698250826, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 447, train_loss = 1.0984522427024785, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 448, train_loss = 1.0966663360595703, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th- epoch: 449, train_loss = 1.0950507000088692, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 450, train_loss = 1.093297461658949, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 451, train_loss = 1.0916065437195357, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 452, train_loss = 1.0898308716714382, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 453, train_loss = 1.0882556761207525, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 454, train_loss = 1.0865428348479327, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 455, train_loss = 1.0848906313476618, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 456, train_loss = 1.0832544093427714, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 457, train_loss = 1.08162441602326, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "1th- epoch: 458, train_loss = 1.079990666359663, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 459, train_loss = 1.0783666856586933, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 460, train_loss = 1.076681132108206, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 461, train_loss = 1.0751374463143293, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 462, train_loss = 1.0735357155499514, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "1th- epoch: 463, train_loss = 1.0719890532491263, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 464, train_loss = 1.0703420365753118, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "1th- epoch: 465, train_loss = 1.0687458837928716, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 466, train_loss = 1.0672059717180673, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "1th- epoch: 467, train_loss = 1.065671374410158, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "1th- epoch: 468, train_loss = 1.0640512059035245, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "1th- epoch: 469, train_loss = 1.0625812262296677, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "1th- epoch: 470, train_loss = 1.0609886782767717, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "1th- epoch: 471, train_loss = 1.059535519540077, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 472, train_loss = 1.057923935353756, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "1th- epoch: 473, train_loss = 1.0565176792442799, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "1th- epoch: 474, train_loss = 1.0550031699240208, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "1th- epoch: 475, train_loss = 1.053489243000513, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "1th- epoch: 476, train_loss = 1.0519461408257484, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "1th- epoch: 477, train_loss = 1.0505774766206741, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 478, train_loss = 1.0490620670316275, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 479, train_loss = 1.0476105461420957, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 480, train_loss = 1.0461182768049184, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 481, train_loss = 1.0447621916828211, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 482, train_loss = 1.0431971413490828, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 483, train_loss = 1.0418325675127562, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 484, train_loss = 1.0403786810638849, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 485, train_loss = 1.038971339672571, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 486, train_loss = 1.0375579434039537, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 487, train_loss = 1.0361773446202278, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 488, train_loss = 1.034702214092249, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 489, train_loss = 1.0334442928433418, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 490, train_loss = 1.031973851233488, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 491, train_loss = 1.0306632009742316, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 492, train_loss = 1.0291978207824286, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 493, train_loss = 1.027917504310608, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 494, train_loss = 1.0265277549624443, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 495, train_loss = 1.025218384951586, train_acc = 0.9981369352585002\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 496, train_loss = 1.0238610965607222, train_acc = 0.9981369352585002\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 497, train_loss = 1.0224527530372143, train_acc = 0.9981369352585002\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 498, train_loss = 1.0211936409177724, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "1th- epoch: 499, train_loss = 1.0197591918113176, train_acc = 0.9981369352585002\n",
      "test Acc 0.9864990689013036:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                      | 1/30 [06:25<3:06:30, 385.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "2th- epoch: 0, train_loss = 275.820517539978, train_acc = 0.4770610153702841\n",
      "test Acc 0.5647113594040968:\n",
      "2th- epoch: 1, train_loss = 208.8468723297119, train_acc = 0.5663716814159292\n",
      "test Acc 0.5796089385474861:\n",
      "2th- epoch: 2, train_loss = 158.40626496076584, train_acc = 0.6022356776897997\n",
      "test Acc 0.6485102420856611:\n",
      "2th- epoch: 3, train_loss = 132.26648408174515, train_acc = 0.6747787610619469\n",
      "test Acc 0.712756052141527:\n",
      "2th- epoch: 4, train_loss = 113.86812955141068, train_acc = 0.731951560316721\n",
      "test Acc 0.7541899441340782:\n",
      "2th- epoch: 5, train_loss = 99.5337001979351, train_acc = 0.7581509082440615\n",
      "test Acc 0.7746741154562383:\n",
      "2th- epoch: 6, train_loss = 87.80244424939156, train_acc = 0.7791103865859339\n",
      "test Acc 0.8007448789571695:\n",
      "2th- epoch: 7, train_loss = 78.05593010783195, train_acc = 0.8140428504890544\n",
      "test Acc 0.8296089385474861:\n",
      "2th- epoch: 8, train_loss = 69.77263250946999, train_acc = 0.8460642757335818\n",
      "test Acc 0.8566108007448789:\n",
      "2th- epoch: 9, train_loss = 62.60005730390549, train_acc = 0.8724965067536097\n",
      "test Acc 0.8784916201117319:\n",
      "2th- epoch: 10, train_loss = 56.352039098739624, train_acc = 0.8953190498369819\n",
      "test Acc 0.9022346368715084:\n",
      "2th- epoch: 11, train_loss = 50.91337190568447, train_acc = 0.9113879832324173\n",
      "test Acc 0.9185288640595903:\n",
      "2th- epoch: 12, train_loss = 46.189953699707985, train_acc = 0.9227992547741034\n",
      "test Acc 0.9315642458100558:\n",
      "2th- epoch: 13, train_loss = 42.097859248518944, train_acc = 0.9301350721937587\n",
      "test Acc 0.936219739292365:\n",
      "2th- epoch: 14, train_loss = 38.56214088946581, train_acc = 0.9358407079646017\n",
      "test Acc 0.9385474860335196:\n",
      "2th- epoch: 15, train_loss = 35.51537336409092, train_acc = 0.9395668374476013\n",
      "test Acc 0.9455307262569832:\n",
      "2th- epoch: 16, train_loss = 32.89416091144085, train_acc = 0.9431765253842571\n",
      "test Acc 0.9473929236499069:\n",
      "2th- epoch: 17, train_loss = 30.63776508718729, train_acc = 0.9457382394038193\n",
      "test Acc 0.9511173184357542:\n",
      "2th- epoch: 18, train_loss = 28.690743625164032, train_acc = 0.9479506287843502\n",
      "test Acc 0.9548417132216015:\n",
      "2th- epoch: 19, train_loss = 27.000947803258896, train_acc = 0.9543549138332557\n",
      "test Acc 0.9567039106145251:\n",
      "2th- epoch: 20, train_loss = 25.526313692331314, train_acc = 0.9566837447601304\n",
      "test Acc 0.957635009310987:\n",
      "2th- epoch: 21, train_loss = 24.23404059559107, train_acc = 0.9585468095016302\n",
      "test Acc 0.9590316573556797:\n",
      "2th- epoch: 22, train_loss = 23.09600841253996, train_acc = 0.9593619003260363\n",
      "test Acc 0.9599627560521415:\n",
      "2th- epoch: 23, train_loss = 22.086221046745777, train_acc = 0.9606427573358174\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 24, train_loss = 21.183668419718742, train_acc = 0.9615742897065673\n",
      "test Acc 0.9604283054003724:\n",
      "2th- epoch: 25, train_loss = 20.37128832191229, train_acc = 0.9629715882626921\n",
      "test Acc 0.9608938547486033:\n",
      "2th- epoch: 26, train_loss = 19.635249935090542, train_acc = 0.9635537959944108\n",
      "test Acc 0.9613594040968343:\n",
      "2th- epoch: 27, train_loss = 18.963758569210768, train_acc = 0.9647182114578482\n",
      "test Acc 0.9618249534450651:\n",
      "2th- epoch: 28, train_loss = 18.347239021211863, train_acc = 0.9650675360968793\n",
      "test Acc 0.9622905027932961:\n",
      "2th- epoch: 29, train_loss = 17.77852352708578, train_acc = 0.9663483931066604\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 30, train_loss = 17.251306734979153, train_acc = 0.9673963670237541\n",
      "test Acc 0.962756052141527:\n",
      "2th- epoch: 31, train_loss = 16.759857524186373, train_acc = 0.9687936655798789\n",
      "test Acc 0.9641527001862198:\n",
      "2th- epoch: 32, train_loss = 16.299654327332973, train_acc = 0.9698416394969726\n",
      "test Acc 0.9664804469273743:\n",
      "2th- epoch: 33, train_loss = 15.86780497431755, train_acc = 0.9703074056823474\n",
      "test Acc 0.9674115456238361:\n",
      "2th- epoch: 34, train_loss = 15.461262099444866, train_acc = 0.9712389380530974\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 35, train_loss = 15.077939704060555, train_acc = 0.9728691197019096\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 36, train_loss = 14.716118443757296, train_acc = 0.9731020027945971\n",
      "test Acc 0.9683426443202979:\n",
      "2th- epoch: 37, train_loss = 14.373419180512428, train_acc = 0.9736842105263158\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 38, train_loss = 14.0477679297328, train_acc = 0.9742664182580345\n",
      "test Acc 0.9688081936685289:\n",
      "2th- epoch: 39, train_loss = 13.737525556236506, train_acc = 0.9747321844434094\n",
      "test Acc 0.9697392923649907:\n",
      "2th- epoch: 40, train_loss = 13.441412005573511, train_acc = 0.9751979506287843\n",
      "test Acc 0.9702048417132216:\n",
      "2th- epoch: 41, train_loss = 13.157943435013294, train_acc = 0.9758965999068467\n",
      "test Acc 0.9706703910614525:\n",
      "2th- epoch: 42, train_loss = 12.886551156640053, train_acc = 0.9761294829995343\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 43, train_loss = 12.626267325133085, train_acc = 0.9769445738239404\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 44, train_loss = 12.37637085840106, train_acc = 0.9771774569166278\n",
      "test Acc 0.972998137802607:\n",
      "2th- epoch: 45, train_loss = 12.1364129409194, train_acc = 0.9772938984629715\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 46, train_loss = 11.905690874904394, train_acc = 0.9777596646483465\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 47, train_loss = 11.683242935687304, train_acc = 0.9778761061946902\n",
      "test Acc 0.973463687150838:\n",
      "2th- epoch: 48, train_loss = 11.468614086508751, train_acc = 0.9782254308337215\n",
      "test Acc 0.9743947858472998:\n",
      "2th- epoch: 49, train_loss = 11.26124732941389, train_acc = 0.9786911970190965\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 50, train_loss = 11.060838054865599, train_acc = 0.9791569632044713\n",
      "test Acc 0.9753258845437617:\n",
      "2th- epoch: 51, train_loss = 10.866958260536194, train_acc = 0.9793898462971589\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 52, train_loss = 10.679399393498898, train_acc = 0.9795062878435026\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 53, train_loss = 10.497727673500776, train_acc = 0.9796227293898463\n",
      "test Acc 0.9757914338919925:\n",
      "2th- epoch: 54, train_loss = 10.321474071592093, train_acc = 0.9798556124825337\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 55, train_loss = 10.149949602782726, train_acc = 0.9803213786679087\n",
      "test Acc 0.9762569832402235:\n",
      "2th- epoch: 56, train_loss = 9.983178850263357, train_acc = 0.9812529110386586\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 57, train_loss = 9.821133891120553, train_acc = 0.9817186772240335\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 58, train_loss = 9.663789173588157, train_acc = 0.9820680018630648\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 59, train_loss = 9.510702420026064, train_acc = 0.9823008849557522\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 60, train_loss = 9.361802894622087, train_acc = 0.9825337680484397\n",
      "test Acc 0.9771880819366853:\n",
      "2th- epoch: 61, train_loss = 9.216829895973206, train_acc = 0.9827666511411272\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 62, train_loss = 9.075592868030071, train_acc = 0.9829995342338146\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 63, train_loss = 8.937793081626296, train_acc = 0.9831159757801584\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 64, train_loss = 8.803418219089508, train_acc = 0.9832324173265021\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 65, train_loss = 8.671910237520933, train_acc = 0.9835817419655333\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 66, train_loss = 8.543371226638556, train_acc = 0.9838146250582208\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 67, train_loss = 8.417739726603031, train_acc = 0.9842803912435957\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 68, train_loss = 8.294785527512431, train_acc = 0.9843968327899395\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 69, train_loss = 8.174347745254636, train_acc = 0.9845132743362832\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 70, train_loss = 8.056778216734529, train_acc = 0.9847461574289706\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 71, train_loss = 7.941912682726979, train_acc = 0.9848625989753144\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 72, train_loss = 7.829680625349283, train_acc = 0.9849790405216581\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 73, train_loss = 7.719738019630313, train_acc = 0.9850954820680019\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 74, train_loss = 7.612089456990361, train_acc = 0.9852119236143456\n",
      "test Acc 0.9776536312849162:\n",
      "2th- epoch: 75, train_loss = 7.5063928086310625, train_acc = 0.985444806707033\n",
      "test Acc 0.9781191806331471:\n",
      "2th- epoch: 76, train_loss = 7.402890060096979, train_acc = 0.985444806707033\n",
      "test Acc 0.978584729981378:\n",
      "2th- epoch: 77, train_loss = 7.301429089158773, train_acc = 0.9856776897997206\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 78, train_loss = 7.201950877904892, train_acc = 0.9857941313460643\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 79, train_loss = 7.104473032057285, train_acc = 0.9860270144387517\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 80, train_loss = 7.00885590352118, train_acc = 0.9862598975314392\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 81, train_loss = 6.914929447695613, train_acc = 0.9862598975314392\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 82, train_loss = 6.822833463549614, train_acc = 0.9864927806241267\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 83, train_loss = 6.732596483081579, train_acc = 0.9869585468095017\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 84, train_loss = 6.644082276150584, train_acc = 0.9870749883558454\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 85, train_loss = 6.557074578478932, train_acc = 0.9871914299021891\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 86, train_loss = 6.471643518656492, train_acc = 0.9874243129948765\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 87, train_loss = 6.387688294053078, train_acc = 0.9874243129948765\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 88, train_loss = 6.305262576788664, train_acc = 0.9876571960875641\n",
      "test Acc 0.9795158286778398:\n",
      "2th- epoch: 89, train_loss = 6.224477948620915, train_acc = 0.9880065207265952\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 90, train_loss = 6.1449358407408, train_acc = 0.9880065207265952\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 91, train_loss = 6.0670433808118105, train_acc = 0.9881229622729389\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 92, train_loss = 5.990465294569731, train_acc = 0.9882394038192828\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 93, train_loss = 5.915423113852739, train_acc = 0.9883558453656265\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 94, train_loss = 5.841739481315017, train_acc = 0.9883558453656265\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 95, train_loss = 5.769470382481813, train_acc = 0.9883558453656265\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 96, train_loss = 5.69858617708087, train_acc = 0.9883558453656265\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 97, train_loss = 5.628888605162501, train_acc = 0.9884722869119702\n",
      "test Acc 0.9804469273743017:\n",
      "2th- epoch: 98, train_loss = 5.560580272227526, train_acc = 0.9884722869119702\n",
      "test Acc 0.9799813780260708:\n",
      "2th- epoch: 99, train_loss = 5.493593196384609, train_acc = 0.9884722869119702\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 100, train_loss = 5.427981904707849, train_acc = 0.9885887284583139\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 101, train_loss = 5.36367700714618, train_acc = 0.9890544946436889\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 102, train_loss = 5.300630404613912, train_acc = 0.9891709361900326\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 103, train_loss = 5.2388106463477015, train_acc = 0.98940381928272\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 104, train_loss = 5.178188445977867, train_acc = 0.9897531439217513\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 105, train_loss = 5.118652089498937, train_acc = 0.99033535165347\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 106, train_loss = 5.060299941338599, train_acc = 0.99033535165347\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 107, train_loss = 5.002939228899777, train_acc = 0.99033535165347\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 108, train_loss = 4.946712096221745, train_acc = 0.9905682347461574\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 109, train_loss = 4.891601894982159, train_acc = 0.9905682347461574\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 110, train_loss = 4.837285636924207, train_acc = 0.9906846762925011\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 111, train_loss = 4.7841207114979625, train_acc = 0.9906846762925011\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 112, train_loss = 4.731762749142945, train_acc = 0.9910340009315324\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 113, train_loss = 4.68043577298522, train_acc = 0.9910340009315324\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 114, train_loss = 4.629782299511135, train_acc = 0.9911504424778761\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 115, train_loss = 4.580408022738993, train_acc = 0.9913833255705635\n",
      "test Acc 0.9813780260707635:\n",
      "2th- epoch: 116, train_loss = 4.531421679072082, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 117, train_loss = 4.483518707565963, train_acc = 0.992081974848626\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 118, train_loss = 4.4364342940971255, train_acc = 0.992081974848626\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 119, train_loss = 4.390305670909584, train_acc = 0.9924312994876572\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 120, train_loss = 4.344719057902694, train_acc = 0.9923148579413135\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 121, train_loss = 4.300029789097607, train_acc = 0.9924312994876572\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 122, train_loss = 4.256105348467827, train_acc = 0.9925477410340009\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 123, train_loss = 4.21286928281188, train_acc = 0.9928970656730322\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 124, train_loss = 4.1704028425738215, train_acc = 0.9928970656730322\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 125, train_loss = 4.12849579192698, train_acc = 0.9930135072193759\n",
      "test Acc 0.9818435754189944:\n",
      "2th- epoch: 126, train_loss = 4.08723899256438, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 127, train_loss = 4.0467324471101165, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 128, train_loss = 4.0068765468895435, train_acc = 0.9937121564974383\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 129, train_loss = 3.9677290888503194, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "2th- epoch: 130, train_loss = 3.9291354194283485, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 131, train_loss = 3.8912885235622525, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 132, train_loss = 3.853817674331367, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "2th- epoch: 133, train_loss = 3.817136103287339, train_acc = 0.9939450395901258\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 134, train_loss = 3.780959746800363, train_acc = 0.9939450395901258\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 135, train_loss = 3.7454388048499823, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 136, train_loss = 3.7104930505156517, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 137, train_loss = 3.6760324239730835, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 138, train_loss = 3.6422184091061354, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 139, train_loss = 3.6088290666230023, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 140, train_loss = 3.576072756201029, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 141, train_loss = 3.5437837396748364, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 142, train_loss = 3.5119346268475056, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 143, train_loss = 3.4806381366215646, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 144, train_loss = 3.4497063639573753, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 145, train_loss = 3.41927102021873, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 146, train_loss = 3.389279432594776, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 147, train_loss = 3.359704448375851, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 148, train_loss = 3.330638276413083, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 149, train_loss = 3.3020175746642053, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 150, train_loss = 3.2738574729301035, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 151, train_loss = 3.246124956291169, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 152, train_loss = 3.2188293230719864, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 153, train_loss = 3.191854089964181, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 154, train_loss = 3.165342988446355, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 155, train_loss = 3.139282610733062, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 156, train_loss = 3.1134707177989185, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 157, train_loss = 3.088226073887199, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 158, train_loss = 3.063122611027211, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 159, train_loss = 3.0385029646568, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 160, train_loss = 3.0143302525393665, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 161, train_loss = 2.99036749266088, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 162, train_loss = 2.9668187755160034, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "2th- epoch: 163, train_loss = 2.9435191955417395, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "2th- epoch: 164, train_loss = 2.920524466317147, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "2th- epoch: 165, train_loss = 2.8979558437131345, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "2th- epoch: 166, train_loss = 2.8756539919413626, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 167, train_loss = 2.853671248536557, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 168, train_loss = 2.832119944971055, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 169, train_loss = 2.810866780113429, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 170, train_loss = 2.7899097870104015, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 171, train_loss = 2.7691864501684904, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 172, train_loss = 2.7488731401972473, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 173, train_loss = 2.728692680131644, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 174, train_loss = 2.7088783867657185, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 175, train_loss = 2.68925192207098, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 176, train_loss = 2.66997386328876, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 177, train_loss = 2.6509589198976755, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 178, train_loss = 2.632146298419684, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 179, train_loss = 2.6135257482528687, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 180, train_loss = 2.595373213291168, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 181, train_loss = 2.5773793153930455, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 182, train_loss = 2.5595802031457424, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "2th- epoch: 183, train_loss = 2.542132329195738, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "2th- epoch: 184, train_loss = 2.524857585551217, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "2th- epoch: 185, train_loss = 2.5078548416495323, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "2th- epoch: 186, train_loss = 2.4909915265161544, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "2th- epoch: 187, train_loss = 2.474515424342826, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "2th- epoch: 188, train_loss = 2.4580795392394066, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "2th- epoch: 189, train_loss = 2.442063298076391, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 190, train_loss = 2.426091445609927, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 191, train_loss = 2.410467903362587, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 192, train_loss = 2.3949535719584674, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 193, train_loss = 2.3797338523436338, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 194, train_loss = 2.3645778447389603, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 195, train_loss = 2.349784268066287, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 196, train_loss = 2.3351432129275054, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 197, train_loss = 2.3205291125923395, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 198, train_loss = 2.306379383429885, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 199, train_loss = 2.2921478282660246, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 200, train_loss = 2.2782958429306746, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 201, train_loss = 2.2644597205799073, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 202, train_loss = 2.250962808728218, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 203, train_loss = 2.2376041144598275, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 204, train_loss = 2.224506365833804, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 205, train_loss = 2.211493890732527, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 206, train_loss = 2.198617545189336, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 207, train_loss = 2.1860668770968914, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 208, train_loss = 2.173590699909255, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 209, train_loss = 2.161170434905216, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 210, train_loss = 2.1491389356087893, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 211, train_loss = 2.1371326346416026, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 212, train_loss = 2.125201686518267, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 213, train_loss = 2.113579975441098, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 214, train_loss = 2.1020736328791827, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 215, train_loss = 2.0906107232440263, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 216, train_loss = 2.0793381955008954, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 217, train_loss = 2.068371909437701, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 218, train_loss = 2.057265942217782, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 219, train_loss = 2.0463665581773967, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 220, train_loss = 2.035674615530297, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 221, train_loss = 2.025040853070095, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 222, train_loss = 2.014486326603219, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 223, train_loss = 2.004199519753456, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 224, train_loss = 1.9940467968117446, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 225, train_loss = 1.9840330847073346, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 226, train_loss = 1.9741530001629144, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 227, train_loss = 1.9643389079719782, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 228, train_loss = 1.9546156246215105, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 229, train_loss = 1.9452349077910185, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 230, train_loss = 1.9356690912973136, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 231, train_loss = 1.9263977855443954, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 232, train_loss = 1.9172070461791009, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 233, train_loss = 1.908129435731098, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 234, train_loss = 1.8991126468172297, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 235, train_loss = 1.8902638560393825, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 236, train_loss = 1.8815252501517534, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 237, train_loss = 1.8729255391517654, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 238, train_loss = 1.8643260126700625, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 239, train_loss = 1.8558832599082962, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 240, train_loss = 1.8475320072611794, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 241, train_loss = 1.8392599126091227, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 242, train_loss = 1.8311183173209429, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 243, train_loss = 1.8230192934861407, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 244, train_loss = 1.8150617940118536, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 245, train_loss = 1.8071873150765896, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 246, train_loss = 1.7993713902542368, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 247, train_loss = 1.7916977368295193, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 248, train_loss = 1.7840733962366357, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 249, train_loss = 1.776522902189754, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 250, train_loss = 1.7690279198577628, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 251, train_loss = 1.7617260105907917, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 252, train_loss = 1.754440282820724, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 253, train_loss = 1.7471855034818873, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 254, train_loss = 1.7400662364671007, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 255, train_loss = 1.7330459033837542, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 256, train_loss = 1.7260612348327413, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 257, train_loss = 1.7191095078596845, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 258, train_loss = 1.712303213775158, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 259, train_loss = 1.7055679559707642, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 260, train_loss = 1.6988692147424445, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 261, train_loss = 1.69220070540905, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 262, train_loss = 1.685715944855474, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 263, train_loss = 1.6792111434042454, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 264, train_loss = 1.672795630991459, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 265, train_loss = 1.6664113464066759, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 266, train_loss = 1.6601933427155018, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 267, train_loss = 1.653953223139979, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 268, train_loss = 1.6478093700716272, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 269, train_loss = 1.641708418726921, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 270, train_loss = 1.6356849210569635, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 271, train_loss = 1.629747435450554, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 272, train_loss = 1.623791036545299, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 273, train_loss = 1.6179859886178747, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 274, train_loss = 1.6121513409307227, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 275, train_loss = 1.606441100477241, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 276, train_loss = 1.600724513293244, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 277, train_loss = 1.59513720870018, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 278, train_loss = 1.5895823426544666, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 279, train_loss = 1.58405140042305, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 280, train_loss = 1.5785680649569258, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 281, train_loss = 1.57323330512736, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 282, train_loss = 1.5678381571779028, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 283, train_loss = 1.562486458569765, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 284, train_loss = 1.5573744041612372, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 285, train_loss = 1.5520537731936201, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 286, train_loss = 1.5469247959554195, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 287, train_loss = 1.541816782206297, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 288, train_loss = 1.5367814004421234, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 289, train_loss = 1.5317193567752838, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 290, train_loss = 1.5267605520784855, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 291, train_loss = 1.5218055868754163, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 292, train_loss = 1.5170253763208166, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 293, train_loss = 1.5120962051441893, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 294, train_loss = 1.5072964740684256, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 295, train_loss = 1.5025747008621693, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 296, train_loss = 1.4978133601834998, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 297, train_loss = 1.4931258807191625, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 298, train_loss = 1.4885130263864994, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "2th- epoch: 299, train_loss = 1.4838670367607847, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 300, train_loss = 1.479393620043993, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 301, train_loss = 1.4748543811729178, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 302, train_loss = 1.4704467144911177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 303, train_loss = 1.466061012179125, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 304, train_loss = 1.461659311025869, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 305, train_loss = 1.457323671609629, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 306, train_loss = 1.4530602507293224, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 307, train_loss = 1.448830431967508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 308, train_loss = 1.4445930334622972, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 309, train_loss = 1.4404169134795666, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 310, train_loss = 1.4362958681886084, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 311, train_loss = 1.4322010725736618, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 312, train_loss = 1.428097606927622, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 313, train_loss = 1.4240641866927035, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 314, train_loss = 1.4200844180886634, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 315, train_loss = 1.4160668005351909, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 316, train_loss = 1.4121531508862972, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 317, train_loss = 1.408240461081732, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 318, train_loss = 1.4044188844854943, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 319, train_loss = 1.400524988770485, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 320, train_loss = 1.396667756140232, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 321, train_loss = 1.3929503758554347, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 322, train_loss = 1.389162169129122, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 323, train_loss = 1.3854477268760093, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 324, train_loss = 1.3817850910127163, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 325, train_loss = 1.3780086102779023, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 326, train_loss = 1.3744315120275132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 327, train_loss = 1.37079692754196, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 328, train_loss = 1.3672138713300228, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 329, train_loss = 1.3637000719900243, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 330, train_loss = 1.360136203467846, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 331, train_loss = 1.3566395603120327, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "2th- epoch: 332, train_loss = 1.3531402212684043, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 333, train_loss = 1.349704310297966, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 334, train_loss = 1.346238932281267, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 335, train_loss = 1.3428677332703955, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 336, train_loss = 1.3394985161721706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 337, train_loss = 1.3361357363755815, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 338, train_loss = 1.3328319415450096, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 339, train_loss = 1.3296031765639782, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 340, train_loss = 1.326214027882088, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 341, train_loss = 1.323078714311123, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 342, train_loss = 1.3198263781960122, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 343, train_loss = 1.3166403509676456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 344, train_loss = 1.3135078747873195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 345, train_loss = 1.3103483617305756, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 346, train_loss = 1.3072376337950118, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 347, train_loss = 1.304147332906723, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 348, train_loss = 1.3011335407500155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 349, train_loss = 1.2979632665519603, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 350, train_loss = 1.2950089909136295, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "2th- epoch: 351, train_loss = 1.291984514624346, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 352, train_loss = 1.289066694676876, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 353, train_loss = 1.2860434291069396, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 354, train_loss = 1.283155104785692, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 355, train_loss = 1.2801895588636398, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 356, train_loss = 1.2772998015279882, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 357, train_loss = 1.2744311901624314, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 358, train_loss = 1.2715944449300878, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 359, train_loss = 1.2686798423528671, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 360, train_loss = 1.2659456506371498, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 361, train_loss = 1.263057615607977, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 362, train_loss = 1.2603166389162652, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 363, train_loss = 1.2575425219838507, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 364, train_loss = 1.2548811945016496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 365, train_loss = 1.2519992354209535, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 366, train_loss = 1.2494209433789365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 367, train_loss = 1.2466770124738105, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 368, train_loss = 1.244035966694355, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 369, train_loss = 1.241493432491552, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 370, train_loss = 1.238759898871649, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 371, train_loss = 1.236363145231735, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 372, train_loss = 1.2337017729878426, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 373, train_loss = 1.2312001449172385, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 374, train_loss = 1.2286097196047194, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 375, train_loss = 1.2261755925719626, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 376, train_loss = 1.2235873974859715, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 377, train_loss = 1.2211413134937175, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 378, train_loss = 1.2186641084845178, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 379, train_loss = 1.2162253421847709, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 380, train_loss = 1.2138316221535206, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 381, train_loss = 1.2114074478740804, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 382, train_loss = 1.209051734476816, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 383, train_loss = 1.2066831874544732, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 384, train_loss = 1.204252800613176, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 385, train_loss = 1.2019105504150502, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 386, train_loss = 1.199601040512789, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 387, train_loss = 1.1972447137231939, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 388, train_loss = 1.1949905517394654, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 389, train_loss = 1.1926782776718028, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 390, train_loss = 1.1903983677621, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 391, train_loss = 1.1881498073635157, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 392, train_loss = 1.1859512217342854, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 393, train_loss = 1.183688680321211, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 394, train_loss = 1.1814732973871287, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 395, train_loss = 1.1792591847479343, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 396, train_loss = 1.1770876621303614, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 397, train_loss = 1.1749714141187724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 398, train_loss = 1.172726417571539, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 399, train_loss = 1.1706542782485485, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 400, train_loss = 1.1684595023689326, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 401, train_loss = 1.1663655328156892, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 402, train_loss = 1.1642415300011635, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 403, train_loss = 1.1621424928307533, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 404, train_loss = 1.1600633598864079, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 405, train_loss = 1.1580422259867191, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 406, train_loss = 1.1559499464929104, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 407, train_loss = 1.1539246886968613, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 408, train_loss = 1.1518646987678949, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 409, train_loss = 1.1499303951859474, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 410, train_loss = 1.1478369521501008, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 411, train_loss = 1.1458983458578587, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 412, train_loss = 1.143900310009485, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 413, train_loss = 1.1419397207500879, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 414, train_loss = 1.1399145560862962, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 415, train_loss = 1.1380355209112167, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 416, train_loss = 1.1361115140316542, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 417, train_loss = 1.1341745145618916, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 418, train_loss = 1.1322335973381996, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 419, train_loss = 1.1303762359020766, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 420, train_loss = 1.1284615831973497, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 421, train_loss = 1.1265417660179082, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 422, train_loss = 1.1247488098742906, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 423, train_loss = 1.1228226957318839, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 424, train_loss = 1.121073067188263, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 425, train_loss = 1.1191307020781096, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 426, train_loss = 1.1173820135591086, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 427, train_loss = 1.1155849931237753, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 428, train_loss = 1.1137446872889996, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 429, train_loss = 1.111956393957371, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 430, train_loss = 1.1101424085500184, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 431, train_loss = 1.1084282795491163, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 432, train_loss = 1.1066080133023206, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 433, train_loss = 1.1049505608680192, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 434, train_loss = 1.1031311700644437, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 435, train_loss = 1.1014393692312296, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 436, train_loss = 1.0996993022563402, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 437, train_loss = 1.0979817037878092, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 438, train_loss = 1.096266151726013, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 439, train_loss = 1.0945921441016253, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 440, train_loss = 1.0929002625343855, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 441, train_loss = 1.0912528298795223, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 442, train_loss = 1.0895131292345468, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 443, train_loss = 1.0878927124140318, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 444, train_loss = 1.086260279029375, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 445, train_loss = 1.0845874187943991, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2th- epoch: 446, train_loss = 1.082981894403929, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 447, train_loss = 1.0813167057931423, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 448, train_loss = 1.0797453336417675, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 449, train_loss = 1.07814928269363, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 450, train_loss = 1.0765292508003768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 451, train_loss = 1.0749461141822394, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 452, train_loss = 1.0733297591505107, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 453, train_loss = 1.0717277551593725, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 454, train_loss = 1.0702070730330888, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 455, train_loss = 1.068704180419445, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 456, train_loss = 1.0670712018909398, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 457, train_loss = 1.0655775964260101, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 458, train_loss = 1.063988304376835, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 459, train_loss = 1.0625148999097291, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 460, train_loss = 1.0610060095787048, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 461, train_loss = 1.0594616755843163, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 462, train_loss = 1.0579355185327586, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 463, train_loss = 1.0564963643846568, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 464, train_loss = 1.0549607997236308, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 465, train_loss = 1.0535593070089817, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 466, train_loss = 1.0520748024282511, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 467, train_loss = 1.050589063524967, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 468, train_loss = 1.0491142061946448, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 469, train_loss = 1.047722360730404, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 470, train_loss = 1.0462323290703353, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 471, train_loss = 1.0448592230677605, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 472, train_loss = 1.0434517413377762, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 473, train_loss = 1.0419733425078448, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 474, train_loss = 1.0405938848853111, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 475, train_loss = 1.0391726133821066, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 476, train_loss = 1.0377173399028834, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 477, train_loss = 1.0363941664400045, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 478, train_loss = 1.0349837392568588, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 479, train_loss = 1.0337038487195969, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 480, train_loss = 1.0322622532548849, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 481, train_loss = 1.0308954678475857, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 482, train_loss = 1.0295837397279684, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 483, train_loss = 1.0281505274178926, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 484, train_loss = 1.026844890177017, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 485, train_loss = 1.025499096751446, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 486, train_loss = 1.0241525483725127, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 487, train_loss = 1.0228893657622393, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 488, train_loss = 1.0215296136739198, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 489, train_loss = 1.0202369689941406, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 490, train_loss = 1.0189727222023066, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 491, train_loss = 1.0176649267377798, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 492, train_loss = 1.0163518103363458, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 493, train_loss = 1.0150244707765523, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 494, train_loss = 1.0138124289514963, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 495, train_loss = 1.0125013229844626, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 496, train_loss = 1.0111584402620792, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 497, train_loss = 1.009914357215166, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 498, train_loss = 1.0086679508385714, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n",
      "2th- epoch: 499, train_loss = 1.007514089345932, train_acc = 0.9981369352585002\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|████▊                                                                    | 2/30 [13:16<3:03:36, 393.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "3th- epoch: 0, train_loss = 273.77631175518036, train_acc = 0.44795062878435027\n",
      "test Acc 0.5363128491620112:\n",
      "3th- epoch: 1, train_loss = 207.16896224021912, train_acc = 0.5172333488588728\n",
      "test Acc 0.5633147113594041:\n",
      "3th- epoch: 2, train_loss = 160.23836833238602, train_acc = 0.5870982766651142\n",
      "test Acc 0.6317504655493482:\n",
      "3th- epoch: 3, train_loss = 135.04963809251785, train_acc = 0.677806241266884\n",
      "test Acc 0.7174115456238361:\n",
      "3th- epoch: 4, train_loss = 116.48655170202255, train_acc = 0.739869585468095\n",
      "test Acc 0.7616387337057728:\n",
      "3th- epoch: 5, train_loss = 101.52563419938087, train_acc = 0.765836050302748\n",
      "test Acc 0.7797951582867784:\n",
      "3th- epoch: 6, train_loss = 89.4405315220356, train_acc = 0.7741034000931533\n",
      "test Acc 0.7825884543761639:\n",
      "3th- epoch: 7, train_loss = 79.56270542740822, train_acc = 0.7927340475081509\n",
      "test Acc 0.8184357541899442:\n",
      "3th- epoch: 8, train_loss = 71.18412646651268, train_acc = 0.8344201210992082\n",
      "test Acc 0.8556797020484171:\n",
      "3th- epoch: 9, train_loss = 63.831776320934296, train_acc = 0.873660922217047\n",
      "test Acc 0.8854748603351955:\n",
      "3th- epoch: 10, train_loss = 57.3065395206213, train_acc = 0.8948532836516069\n",
      "test Acc 0.9050279329608939:\n",
      "3th- epoch: 11, train_loss = 51.56936836242676, train_acc = 0.9110386585933862\n",
      "test Acc 0.9208566108007449:\n",
      "3th- epoch: 12, train_loss = 46.60051749646664, train_acc = 0.926059618071728\n",
      "test Acc 0.9348230912476723:\n",
      "3th- epoch: 13, train_loss = 42.34329143166542, train_acc = 0.936190032603633\n",
      "test Acc 0.9385474860335196:\n",
      "3th- epoch: 14, train_loss = 38.721983671188354, train_acc = 0.9394503959012576\n",
      "test Acc 0.9418063314711359:\n",
      "3th- epoch: 15, train_loss = 35.643997833132744, train_acc = 0.941895668374476\n",
      "test Acc 0.9441340782122905:\n",
      "3th- epoch: 16, train_loss = 33.02367324382067, train_acc = 0.9436422915696321\n",
      "test Acc 0.9487895716945997:\n",
      "3th- epoch: 17, train_loss = 30.785888701677322, train_acc = 0.9501630181648812\n",
      "test Acc 0.9511173184357542:\n",
      "3th- epoch: 18, train_loss = 28.86315819621086, train_acc = 0.9522589659990685\n",
      "test Acc 0.9539106145251397:\n",
      "3th- epoch: 19, train_loss = 27.198801770806313, train_acc = 0.9543549138332557\n",
      "test Acc 0.9557728119180633:\n",
      "3th- epoch: 20, train_loss = 25.748717721551657, train_acc = 0.956450861667443\n",
      "test Acc 0.9567039106145251:\n",
      "3th- epoch: 21, train_loss = 24.47598372027278, train_acc = 0.9593619003260363\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 22, train_loss = 23.349202536046505, train_acc = 0.9601769911504425\n",
      "test Acc 0.957635009310987:\n",
      "3th- epoch: 23, train_loss = 22.3439729064703, train_acc = 0.9613414066138798\n",
      "test Acc 0.9581005586592178:\n",
      "3th- epoch: 24, train_loss = 21.440068289637566, train_acc = 0.962156497438286\n",
      "test Acc 0.9585661080074488:\n",
      "3th- epoch: 25, train_loss = 20.620673209428787, train_acc = 0.9632044713553796\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 26, train_loss = 19.87407675012946, train_acc = 0.9643688868188169\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 27, train_loss = 19.187949113547802, train_acc = 0.9649510945505356\n",
      "test Acc 0.9599627560521415:\n",
      "3th- epoch: 28, train_loss = 18.552501630038023, train_acc = 0.965649743828598\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 29, train_loss = 17.963497169315815, train_acc = 0.9666977177456917\n",
      "test Acc 0.9604283054003724:\n",
      "3th- epoch: 30, train_loss = 17.41592951118946, train_acc = 0.9677456916627852\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 31, train_loss = 16.904245126992464, train_acc = 0.9683278993945039\n",
      "test Acc 0.9608938547486033:\n",
      "3th- epoch: 32, train_loss = 16.424944452941418, train_acc = 0.9686772240335352\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 33, train_loss = 15.974700175225735, train_acc = 0.9689101071262226\n",
      "test Acc 0.9613594040968343:\n",
      "3th- epoch: 34, train_loss = 15.550315458327532, train_acc = 0.9694923148579413\n",
      "test Acc 0.962756052141527:\n",
      "3th- epoch: 35, train_loss = 15.14872170612216, train_acc = 0.9699580810433163\n",
      "test Acc 0.9641527001862198:\n",
      "3th- epoch: 36, train_loss = 14.767646353691816, train_acc = 0.9710060549604099\n",
      "test Acc 0.9650837988826816:\n",
      "3th- epoch: 37, train_loss = 14.405557803809643, train_acc = 0.9720540288775035\n",
      "test Acc 0.9674115456238361:\n",
      "3th- epoch: 38, train_loss = 14.06056160852313, train_acc = 0.9728691197019096\n",
      "test Acc 0.9678770949720671:\n",
      "3th- epoch: 39, train_loss = 13.732098121196032, train_acc = 0.9738006520726595\n",
      "test Acc 0.9683426443202979:\n",
      "3th- epoch: 40, train_loss = 13.418744925409555, train_acc = 0.9742664182580345\n",
      "test Acc 0.9702048417132216:\n",
      "3th- epoch: 41, train_loss = 13.119730908423662, train_acc = 0.9750815090824406\n",
      "test Acc 0.9711359404096834:\n",
      "3th- epoch: 42, train_loss = 12.834586288779974, train_acc = 0.9755472752678156\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 43, train_loss = 12.561799310147762, train_acc = 0.9758965999068467\n",
      "test Acc 0.9716014897579144:\n",
      "3th- epoch: 44, train_loss = 12.300252739340067, train_acc = 0.9768281322775967\n",
      "test Acc 0.972998137802607:\n",
      "3th- epoch: 45, train_loss = 12.049282480031252, train_acc = 0.9772938984629715\n",
      "test Acc 0.9739292364990689:\n",
      "3th- epoch: 46, train_loss = 11.808325603604317, train_acc = 0.9782254308337215\n",
      "test Acc 0.9748603351955307:\n",
      "3th- epoch: 47, train_loss = 11.57669622451067, train_acc = 0.9784583139264089\n",
      "test Acc 0.9757914338919925:\n",
      "3th- epoch: 48, train_loss = 11.353903651237488, train_acc = 0.9793898462971589\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 49, train_loss = 11.13951126113534, train_acc = 0.9798556124825337\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 50, train_loss = 10.932935969904065, train_acc = 0.980204937121565\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 51, train_loss = 10.733732338994741, train_acc = 0.9807871448532837\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 52, train_loss = 10.541447782889009, train_acc = 0.9810200279459711\n",
      "test Acc 0.9767225325884544:\n",
      "3th- epoch: 53, train_loss = 10.355618700385094, train_acc = 0.9812529110386586\n",
      "test Acc 0.9771880819366853:\n",
      "3th- epoch: 54, train_loss = 10.175894940271974, train_acc = 0.9813693525850024\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 55, train_loss = 10.001671133562922, train_acc = 0.9813693525850024\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 56, train_loss = 9.832937277853489, train_acc = 0.9816022356776898\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 57, train_loss = 9.669055126607418, train_acc = 0.9818351187703773\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 58, train_loss = 9.50984501838684, train_acc = 0.9820680018630648\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 59, train_loss = 9.355002976953983, train_acc = 0.9823008849557522\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 60, train_loss = 9.204384690150619, train_acc = 0.9825337680484397\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 61, train_loss = 9.057845065370202, train_acc = 0.9828830926874709\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 62, train_loss = 8.9150624088943, train_acc = 0.9829995342338146\n",
      "test Acc 0.9776536312849162:\n",
      "3th- epoch: 63, train_loss = 8.775952512398362, train_acc = 0.9829995342338146\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 64, train_loss = 8.640369445085526, train_acc = 0.9832324173265021\n",
      "test Acc 0.9781191806331471:\n",
      "3th- epoch: 65, train_loss = 8.508143516257405, train_acc = 0.9832324173265021\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 66, train_loss = 8.37905957736075, train_acc = 0.983698183511877\n",
      "test Acc 0.978584729981378:\n",
      "3th- epoch: 67, train_loss = 8.253129644319415, train_acc = 0.9839310666045645\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 68, train_loss = 8.13025676459074, train_acc = 0.9840475081509082\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 69, train_loss = 8.010213049128652, train_acc = 0.9843968327899395\n",
      "test Acc 0.979050279329609:\n",
      "3th- epoch: 70, train_loss = 7.892922503873706, train_acc = 0.9846297158826269\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 71, train_loss = 7.778200127184391, train_acc = 0.9848625989753144\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 72, train_loss = 7.66610999032855, train_acc = 0.9850954820680019\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 73, train_loss = 7.556616462767124, train_acc = 0.9853283651606893\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 74, train_loss = 7.44961778819561, train_acc = 0.985444806707033\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 75, train_loss = 7.3448957446962595, train_acc = 0.9856776897997206\n",
      "test Acc 0.9795158286778398:\n",
      "3th- epoch: 76, train_loss = 7.242436224594712, train_acc = 0.9857941313460643\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 77, train_loss = 7.142203094437718, train_acc = 0.985910572892408\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 78, train_loss = 7.044032437726855, train_acc = 0.9860270144387517\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 79, train_loss = 6.947959927842021, train_acc = 0.9862598975314392\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 80, train_loss = 6.854106629267335, train_acc = 0.9862598975314392\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 81, train_loss = 6.762206614017487, train_acc = 0.986376339077783\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 82, train_loss = 6.672175161540508, train_acc = 0.9866092221704704\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 83, train_loss = 6.583851279690862, train_acc = 0.9867256637168141\n",
      "test Acc 0.9804469273743017:\n",
      "3th- epoch: 84, train_loss = 6.497430570423603, train_acc = 0.9869585468095017\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 85, train_loss = 6.412415927276015, train_acc = 0.9871914299021891\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 86, train_loss = 6.329165806993842, train_acc = 0.9874243129948765\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 87, train_loss = 6.247568096965551, train_acc = 0.9877736376339078\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 88, train_loss = 6.167423008009791, train_acc = 0.9878900791802515\n",
      "test Acc 0.9799813780260708:\n",
      "3th- epoch: 89, train_loss = 6.0890274327248335, train_acc = 0.9883558453656265\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 90, train_loss = 6.012160666286945, train_acc = 0.9883558453656265\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 91, train_loss = 5.93693340010941, train_acc = 0.9883558453656265\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 92, train_loss = 5.863091053441167, train_acc = 0.9883558453656265\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 93, train_loss = 5.790815489366651, train_acc = 0.9884722869119702\n",
      "test Acc 0.9813780260707635:\n",
      "3th- epoch: 94, train_loss = 5.719910530373454, train_acc = 0.9888216115510013\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 95, train_loss = 5.650321386754513, train_acc = 0.9888216115510013\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 96, train_loss = 5.582253431901336, train_acc = 0.9890544946436889\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 97, train_loss = 5.5153645016252995, train_acc = 0.9892873777363763\n",
      "test Acc 0.9818435754189944:\n",
      "3th- epoch: 98, train_loss = 5.4497781209647655, train_acc = 0.98940381928272\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 99, train_loss = 5.385484437458217, train_acc = 0.9896367023754076\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 100, train_loss = 5.32239643484354, train_acc = 0.9897531439217513\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 101, train_loss = 5.260533227585256, train_acc = 0.99033535165347\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 102, train_loss = 5.199648037552834, train_acc = 0.99033535165347\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 103, train_loss = 5.1401053853333, train_acc = 0.9905682347461574\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 104, train_loss = 5.081555553711951, train_acc = 0.9905682347461574\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 105, train_loss = 5.024188610725105, train_acc = 0.9905682347461574\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 106, train_loss = 4.967730249278247, train_acc = 0.990801117838845\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 107, train_loss = 4.912234633229673, train_acc = 0.990801117838845\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 108, train_loss = 4.857897727750242, train_acc = 0.9906846762925011\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 109, train_loss = 4.804433912970126, train_acc = 0.9909175593851887\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 110, train_loss = 4.751838388852775, train_acc = 0.9910340009315324\n",
      "test Acc 0.9823091247672253:\n",
      "3th- epoch: 111, train_loss = 4.700305354781449, train_acc = 0.9911504424778761\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 112, train_loss = 4.649621970020235, train_acc = 0.9912668840242198\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 113, train_loss = 4.599860354326665, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 114, train_loss = 4.550869659520686, train_acc = 0.9916162086632511\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 115, train_loss = 4.502861567772925, train_acc = 0.9916162086632511\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 116, train_loss = 4.4555528946220875, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 117, train_loss = 4.409099684096873, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 118, train_loss = 4.363496874459088, train_acc = 0.9918490917559385\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 119, train_loss = 4.318452791310847, train_acc = 0.9918490917559385\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 120, train_loss = 4.274234544485807, train_acc = 0.9919655333022822\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 121, train_loss = 4.230806148611009, train_acc = 0.9919655333022822\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 122, train_loss = 4.18803146481514, train_acc = 0.9923148579413135\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 123, train_loss = 4.145952303893864, train_acc = 0.9924312994876572\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 124, train_loss = 4.104638156481087, train_acc = 0.9926641825803446\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 125, train_loss = 4.063979387283325, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 126, train_loss = 4.023994754999876, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 127, train_loss = 3.984550191089511, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 128, train_loss = 3.9458566633984447, train_acc = 0.9931299487657196\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 129, train_loss = 3.907729963771999, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 130, train_loss = 3.870187203399837, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 131, train_loss = 3.8332934649661183, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 132, train_loss = 3.796909206546843, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 133, train_loss = 3.7611916856840253, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 134, train_loss = 3.7257900163531303, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 135, train_loss = 3.6911554876714945, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 136, train_loss = 3.6569746285676956, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 137, train_loss = 3.623407069593668, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 138, train_loss = 3.5902174920774996, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 139, train_loss = 3.557631800416857, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 140, train_loss = 3.525586348026991, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 141, train_loss = 3.4940137048251927, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 142, train_loss = 3.4629321210086346, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 143, train_loss = 3.43239071033895, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 144, train_loss = 3.4022332443855703, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 145, train_loss = 3.37256421148777, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 146, train_loss = 3.343474226538092, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 147, train_loss = 3.3146131616085768, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 148, train_loss = 3.286394171882421, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 149, train_loss = 3.258422217797488, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 150, train_loss = 3.230992461089045, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 151, train_loss = 3.203851331025362, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 152, train_loss = 3.177265963051468, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 153, train_loss = 3.150955414865166, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 154, train_loss = 3.125153139233589, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 155, train_loss = 3.0996571741998196, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 156, train_loss = 3.0745686762966216, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 157, train_loss = 3.0497678606770933, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 158, train_loss = 3.0253224871121347, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 159, train_loss = 3.0012967376969755, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 160, train_loss = 2.9775959365069866, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 161, train_loss = 2.95421976223588, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 162, train_loss = 2.931135105434805, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 163, train_loss = 2.9084117650054395, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 164, train_loss = 2.8861004263162613, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 165, train_loss = 2.8641168288886547, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 166, train_loss = 2.8423264361917973, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 167, train_loss = 2.8210722818039358, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 168, train_loss = 2.8000460057519376, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 169, train_loss = 2.779358023311943, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 170, train_loss = 2.7590194032527506, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 171, train_loss = 2.738850522786379, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 172, train_loss = 2.719222443178296, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 173, train_loss = 2.6996040190570056, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 174, train_loss = 2.680349724367261, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 175, train_loss = 2.661407550331205, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 176, train_loss = 2.642646551132202, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 177, train_loss = 2.624210026115179, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 178, train_loss = 2.606096940813586, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 179, train_loss = 2.588034188374877, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "3th- epoch: 180, train_loss = 2.5703845627140254, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 181, train_loss = 2.5529215801507235, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 182, train_loss = 2.5357649128418416, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 183, train_loss = 2.5187561872880906, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 184, train_loss = 2.501999504165724, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 185, train_loss = 2.485508430749178, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 186, train_loss = 2.469211724353954, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 187, train_loss = 2.4532086737453938, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 188, train_loss = 2.437360330251977, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 189, train_loss = 2.4218380134552717, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 190, train_loss = 2.4063114237505943, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 191, train_loss = 2.3911934706848115, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 192, train_loss = 2.3762231345754117, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 193, train_loss = 2.361510595306754, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 194, train_loss = 2.3468572981655598, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 195, train_loss = 2.332610895857215, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 196, train_loss = 2.318392037646845, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 197, train_loss = 2.3045022406149656, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 198, train_loss = 2.29076053830795, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 199, train_loss = 2.2771545480936766, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 200, train_loss = 2.263826896203682, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 201, train_loss = 2.250601289793849, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 202, train_loss = 2.2375200919341296, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 203, train_loss = 2.2247688435018063, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 204, train_loss = 2.211936232401058, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 205, train_loss = 2.199425544589758, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 206, train_loss = 2.1870090905576944, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 207, train_loss = 2.174702213378623, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 208, train_loss = 2.162606781348586, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 209, train_loss = 2.150845006806776, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 210, train_loss = 2.1389954511541873, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 211, train_loss = 2.127573211910203, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 212, train_loss = 2.116013713181019, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 213, train_loss = 2.1047861638944596, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 214, train_loss = 2.093731206608936, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 215, train_loss = 2.0827098034787923, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 216, train_loss = 2.071735617471859, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 217, train_loss = 2.0611923411488533, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 218, train_loss = 2.050569638609886, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 219, train_loss = 2.040176372975111, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 220, train_loss = 2.029789711115882, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 221, train_loss = 2.0197204139549285, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "3th- epoch: 222, train_loss = 2.0097622957546264, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 223, train_loss = 1.9998194326180965, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 224, train_loss = 1.9898775592446327, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "3th- epoch: 225, train_loss = 1.9804226271808147, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "3th- epoch: 226, train_loss = 1.9707951110322028, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "3th- epoch: 227, train_loss = 1.9614612001460046, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "3th- epoch: 228, train_loss = 1.9520827556261793, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "3th- epoch: 229, train_loss = 1.942868017940782, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "3th- epoch: 230, train_loss = 1.9337993649533018, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "3th- epoch: 231, train_loss = 1.9247887842357159, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "3th- epoch: 232, train_loss = 1.9160180911421776, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "3th- epoch: 233, train_loss = 1.9071088234195486, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "3th- epoch: 234, train_loss = 1.8984742909669876, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 235, train_loss = 1.8899918645620346, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 236, train_loss = 1.8814900243887678, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 237, train_loss = 1.8730261822929606, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 238, train_loss = 1.8647431818535551, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 239, train_loss = 1.8567035844316706, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 240, train_loss = 1.8485137708485126, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 241, train_loss = 1.8404581794748083, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 242, train_loss = 1.83265347906854, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 243, train_loss = 1.8247325631091371, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 244, train_loss = 1.81710998469498, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 245, train_loss = 1.8092504814267159, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 246, train_loss = 1.8018874475965276, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 247, train_loss = 1.7943346127867699, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "3th- epoch: 248, train_loss = 1.7869909877190366, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 249, train_loss = 1.7795244194567204, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 250, train_loss = 1.772450135438703, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 251, train_loss = 1.7652539014816284, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 252, train_loss = 1.7580122934887186, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 253, train_loss = 1.7511439671507105, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 254, train_loss = 1.744157887995243, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 255, train_loss = 1.7374043390154839, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 256, train_loss = 1.7304623076925054, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 257, train_loss = 1.7237915074219927, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 258, train_loss = 1.7172092659166083, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 259, train_loss = 1.7105567181715742, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 260, train_loss = 1.7041046023368835, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 261, train_loss = 1.6975044360151514, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 262, train_loss = 1.691261239349842, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 263, train_loss = 1.6849047193536535, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 264, train_loss = 1.6786450570216402, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 265, train_loss = 1.6725252146134153, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 266, train_loss = 1.6663805296411738, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 267, train_loss = 1.6603362821042538, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 268, train_loss = 1.6542324088513851, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 269, train_loss = 1.64842974266503, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 270, train_loss = 1.6424629800021648, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 271, train_loss = 1.6366955848643556, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 272, train_loss = 1.630910251289606, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 273, train_loss = 1.6251272322842851, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 274, train_loss = 1.6194397620856762, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 275, train_loss = 1.613872703164816, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 276, train_loss = 1.608394286246039, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 277, train_loss = 1.602803991525434, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 278, train_loss = 1.5973163867602125, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 279, train_loss = 1.591977438540198, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 280, train_loss = 1.5864592815050855, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 281, train_loss = 1.5813509114086628, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 282, train_loss = 1.575970869511366, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 283, train_loss = 1.5706903040409088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 284, train_loss = 1.5657060369849205, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 285, train_loss = 1.560546481399797, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 286, train_loss = 1.555472275824286, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 287, train_loss = 1.5504634442040697, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 288, train_loss = 1.545360223739408, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 289, train_loss = 1.5406344309449196, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 290, train_loss = 1.5356802828609943, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 291, train_loss = 1.5308255168492906, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 292, train_loss = 1.526034153997898, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 293, train_loss = 1.5212471298873425, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 294, train_loss = 1.5163937819306739, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 295, train_loss = 1.5118219045107253, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 296, train_loss = 1.5071230729226954, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 297, train_loss = 1.5025823426549323, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 298, train_loss = 1.4979504123330116, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 299, train_loss = 1.493471930443775, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 300, train_loss = 1.4889240972697735, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 301, train_loss = 1.484471506148111, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 302, train_loss = 1.4801275543868542, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 303, train_loss = 1.4757052610511892, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 304, train_loss = 1.4713012513821013, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 305, train_loss = 1.466952605813276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 306, train_loss = 1.4627625842695124, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 307, train_loss = 1.4584178018267266, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 308, train_loss = 1.4543240393395536, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 309, train_loss = 1.4502109761233442, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 310, train_loss = 1.4460957261617295, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 311, train_loss = 1.4419947738642804, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 312, train_loss = 1.4379919481580146, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 313, train_loss = 1.4340360189671628, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 314, train_loss = 1.4300200752913952, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 315, train_loss = 1.426021711260546, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 316, train_loss = 1.422232246666681, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 317, train_loss = 1.418242345273029, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 318, train_loss = 1.4144783963565715, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 319, train_loss = 1.4106509660487063, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 320, train_loss = 1.4068109281361103, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 321, train_loss = 1.403144980489742, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 322, train_loss = 1.3993535675108433, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 323, train_loss = 1.395689754455816, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 324, train_loss = 1.3919366362388246, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 325, train_loss = 1.3884154458646663, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 326, train_loss = 1.3847443449194543, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 327, train_loss = 1.3812730846111663, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 328, train_loss = 1.3776458117063157, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 329, train_loss = 1.3740342035889626, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 330, train_loss = 1.3706814385950565, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 331, train_loss = 1.3671504904632457, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 332, train_loss = 1.36368677765131, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 333, train_loss = 1.3602268708054908, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 334, train_loss = 1.356942143291235, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 335, train_loss = 1.3535377494990826, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 336, train_loss = 1.3502292509074323, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 337, train_loss = 1.3468640496139415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 338, train_loss = 1.3435539181227796, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 339, train_loss = 1.3402601132984273, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 340, train_loss = 1.3370938574080355, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 341, train_loss = 1.333814783662092, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 342, train_loss = 1.3306846258346923, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 343, train_loss = 1.3272787730093114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 344, train_loss = 1.3243814830784686, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 345, train_loss = 1.3212046772241592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 346, train_loss = 1.3181135157938115, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 347, train_loss = 1.314927589148283, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 348, train_loss = 1.3119414001703262, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 349, train_loss = 1.3087542317807674, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 350, train_loss = 1.3058892153203487, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 351, train_loss = 1.30286705493927, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 352, train_loss = 1.2998698304290883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 353, train_loss = 1.2968358844518661, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 354, train_loss = 1.2939684192533605, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 355, train_loss = 1.2908603983814828, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 356, train_loss = 1.288070650130976, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 357, train_loss = 1.2852147817611694, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 358, train_loss = 1.2823755691642873, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 359, train_loss = 1.279500248550903, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 360, train_loss = 1.2766793382470496, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 361, train_loss = 1.273850079625845, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 362, train_loss = 1.2711107867653482, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 363, train_loss = 1.2683851172332652, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 364, train_loss = 1.2656652641599067, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 365, train_loss = 1.26295854896307, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 366, train_loss = 1.260223409801256, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 367, train_loss = 1.2576171196997166, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 368, train_loss = 1.2548714615404606, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 369, train_loss = 1.252307393879164, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 370, train_loss = 1.2496537417173386, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 371, train_loss = 1.247079110413324, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 372, train_loss = 1.2444637368025724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 373, train_loss = 1.2418339190480765, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 374, train_loss = 1.2393790309724864, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 375, train_loss = 1.2368912225065287, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 376, train_loss = 1.2342749163508415, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 377, train_loss = 1.231862415879732, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 378, train_loss = 1.229315231234068, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 379, train_loss = 1.226859848946333, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 380, train_loss = 1.2244418437185232, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 381, train_loss = 1.2219382686016615, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 382, train_loss = 1.2195523952541407, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 383, train_loss = 1.2171084719302598, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 384, train_loss = 1.2146694175899029, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 385, train_loss = 1.212298646569252, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 386, train_loss = 1.2100612757203635, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 387, train_loss = 1.2076706290245056, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "3th- epoch: 388, train_loss = 1.2052404023706913, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 389, train_loss = 1.20300337052322, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 390, train_loss = 1.2006321338412818, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 391, train_loss = 1.1984552306530531, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 392, train_loss = 1.1961793775262777, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 393, train_loss = 1.1938322310743388, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 394, train_loss = 1.1916195265948772, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 395, train_loss = 1.1893976218998432, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 396, train_loss = 1.1870566705765668, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 397, train_loss = 1.1850573023257311, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 398, train_loss = 1.1827484630048275, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 399, train_loss = 1.180679659039015, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 400, train_loss = 1.1783644755778369, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 401, train_loss = 1.176374259084696, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 402, train_loss = 1.1740908101201057, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 403, train_loss = 1.1719821455480997, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 404, train_loss = 1.1699314427969512, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 405, train_loss = 1.1677624719741289, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 406, train_loss = 1.1656999053957406, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 407, train_loss = 1.1636644527316093, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 408, train_loss = 1.1615227522852365, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 409, train_loss = 1.1595086033048574, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 410, train_loss = 1.15736810490489, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 411, train_loss = 1.1555027452704962, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 412, train_loss = 1.1534483979048673, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 413, train_loss = 1.151467613875866, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 414, train_loss = 1.1494596476259176, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 415, train_loss = 1.1475033052265644, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 416, train_loss = 1.1455485249462072, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 417, train_loss = 1.1435687666235026, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 418, train_loss = 1.1416345027682837, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 419, train_loss = 1.139706073940033, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 420, train_loss = 1.1376998250780161, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 421, train_loss = 1.1359292417764664, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 422, train_loss = 1.1338571483793203, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 423, train_loss = 1.1321124719979707, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 424, train_loss = 1.130162250250578, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 425, train_loss = 1.1283723898231983, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 426, train_loss = 1.126427502691513, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 427, train_loss = 1.1247595486638602, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 428, train_loss = 1.1227388655242976, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 429, train_loss = 1.121047896653181, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 430, train_loss = 1.1191364104452077, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 431, train_loss = 1.1174513908626977, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 432, train_loss = 1.1155689135193825, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 433, train_loss = 1.1137546350655612, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 434, train_loss = 1.1120233250258025, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 435, train_loss = 1.110191891581053, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 436, train_loss = 1.108515622705454, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 437, train_loss = 1.1067430575785693, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 438, train_loss = 1.1050948562624399, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 439, train_loss = 1.1032769841549452, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 440, train_loss = 1.1015486096439417, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 441, train_loss = 1.0999079458415508, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 442, train_loss = 1.0982433284225408, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 443, train_loss = 1.0964465104043484, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 444, train_loss = 1.0949062444269657, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3th- epoch: 445, train_loss = 1.093109518289566, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 446, train_loss = 1.091467155754799, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 447, train_loss = 1.0898046543297824, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 448, train_loss = 1.0883041570486967, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 449, train_loss = 1.0865652486681938, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 450, train_loss = 1.0848118128778879, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 451, train_loss = 1.0834107945265714, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 452, train_loss = 1.0817089080810547, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 453, train_loss = 1.080035425722599, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 454, train_loss = 1.0785958332417067, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 455, train_loss = 1.0769832022488117, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 456, train_loss = 1.0753332836029585, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 457, train_loss = 1.0738365314900875, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 458, train_loss = 1.0722194984555244, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 459, train_loss = 1.0707424581050873, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 460, train_loss = 1.069145339220995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 461, train_loss = 1.0676287511887494, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 462, train_loss = 1.0660428293049335, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 463, train_loss = 1.0646299073996488, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 464, train_loss = 1.0630684991774615, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 465, train_loss = 1.0615882513520774, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 466, train_loss = 1.060084411263233, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 467, train_loss = 1.0585601851344109, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 468, train_loss = 1.0571152667107526, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 469, train_loss = 1.0557387793960515, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 470, train_loss = 1.0541368958947714, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 471, train_loss = 1.0527831452491228, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 472, train_loss = 1.0512276515364647, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 473, train_loss = 1.0498309185204562, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 474, train_loss = 1.0484168069961015, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 475, train_loss = 1.047015326708788, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 476, train_loss = 1.0454940684139729, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 477, train_loss = 1.044124032050604, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 478, train_loss = 1.0428752365114633, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 479, train_loss = 1.0412715673446655, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 480, train_loss = 1.0399415666761342, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 481, train_loss = 1.038587308168644, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 482, train_loss = 1.0371112090797396, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 483, train_loss = 1.0358192424027948, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 484, train_loss = 1.034424268946168, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 485, train_loss = 1.0330941937863827, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 486, train_loss = 1.0317228051571874, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 487, train_loss = 1.030257623642683, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 488, train_loss = 1.0291387438774109, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 489, train_loss = 1.0276501302869292, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 490, train_loss = 1.0263513413519831, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 491, train_loss = 1.0250254248530837, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 492, train_loss = 1.023706858351943, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 493, train_loss = 1.0224570992140798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 494, train_loss = 1.021107006818056, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 495, train_loss = 1.0197501530201407, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 496, train_loss = 1.0185479683132144, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 497, train_loss = 1.0172733912913827, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 498, train_loss = 1.015911744281766, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "3th- epoch: 499, train_loss = 1.0147333815693855, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▎                                                                 | 3/30 [20:06<2:59:16, 398.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "4th- epoch: 0, train_loss = 271.90265929698944, train_acc = 0.49371215649743827\n",
      "test Acc 0.5577281191806331:\n",
      "4th- epoch: 1, train_loss = 203.68744921684265, train_acc = 0.5602002794597112\n",
      "test Acc 0.5763500931098696:\n",
      "4th- epoch: 2, train_loss = 155.50412154197693, train_acc = 0.6013041453190499\n",
      "test Acc 0.6452513966480447:\n",
      "4th- epoch: 3, train_loss = 130.59206479787827, train_acc = 0.6888681881695389\n",
      "test Acc 0.729050279329609:\n",
      "4th- epoch: 4, train_loss = 112.58546829223633, train_acc = 0.7437121564974383\n",
      "test Acc 0.765828677839851:\n",
      "4th- epoch: 5, train_loss = 98.29417881369591, train_acc = 0.7674662319515603\n",
      "test Acc 0.7839851024208566:\n",
      "4th- epoch: 6, train_loss = 86.83684462308884, train_acc = 0.7877270610153703\n",
      "test Acc 0.8054003724394786:\n",
      "4th- epoch: 7, train_loss = 77.5464868247509, train_acc = 0.808570097810899\n",
      "test Acc 0.8319366852886406:\n",
      "4th- epoch: 8, train_loss = 69.66715335845947, train_acc = 0.8383791336748952\n",
      "test Acc 0.8575418994413407:\n",
      "4th- epoch: 9, train_loss = 62.725100845098495, train_acc = 0.8693525850023288\n",
      "test Acc 0.8836126629422719:\n",
      "4th- epoch: 10, train_loss = 56.53831100463867, train_acc = 0.8918258034466697\n",
      "test Acc 0.9031657355679702:\n",
      "4th- epoch: 11, train_loss = 51.07930874824524, train_acc = 0.9090591523055426\n",
      "test Acc 0.9241154562383612:\n",
      "4th- epoch: 12, train_loss = 46.32704973220825, train_acc = 0.9251280857009782\n",
      "test Acc 0.9376163873370578:\n",
      "4th- epoch: 13, train_loss = 42.21852111816406, train_acc = 0.9360735910572893\n",
      "test Acc 0.9408752327746741:\n",
      "4th- epoch: 14, train_loss = 38.676987148821354, train_acc = 0.9392175128085701\n",
      "test Acc 0.9441340782122905:\n",
      "4th- epoch: 15, train_loss = 35.630105912685394, train_acc = 0.9427107591988821\n",
      "test Acc 0.9483240223463687:\n",
      "4th- epoch: 16, train_loss = 33.011910654604435, train_acc = 0.9449231485794132\n",
      "test Acc 0.9487895716945997:\n",
      "4th- epoch: 17, train_loss = 30.761096149683, train_acc = 0.9474848625989754\n",
      "test Acc 0.9553072625698324:\n",
      "4th- epoch: 18, train_loss = 28.824159897863865, train_acc = 0.9537727061015371\n",
      "test Acc 0.9562383612662942:\n",
      "4th- epoch: 19, train_loss = 27.148489326238632, train_acc = 0.955519329296693\n",
      "test Acc 0.9594972067039106:\n",
      "4th- epoch: 20, train_loss = 25.689080454409122, train_acc = 0.9573823940381928\n",
      "test Acc 0.9608938547486033:\n",
      "4th- epoch: 21, train_loss = 24.410283379256725, train_acc = 0.9588961341406614\n",
      "test Acc 0.9622905027932961:\n",
      "4th- epoch: 22, train_loss = 23.28104157745838, train_acc = 0.9601769911504425\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 23, train_loss = 22.27542346715927, train_acc = 0.9611085235211924\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 24, train_loss = 21.372006464749575, train_acc = 0.9619236143455985\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 25, train_loss = 20.55596012249589, train_acc = 0.9626222636236609\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 26, train_loss = 19.814268942922354, train_acc = 0.9642524452724732\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 27, train_loss = 19.135434694588184, train_acc = 0.9651839776432231\n",
      "test Acc 0.9632216014897579:\n",
      "4th- epoch: 28, train_loss = 18.510537143796682, train_acc = 0.966115510013973\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 29, train_loss = 17.932202350348234, train_acc = 0.9666977177456917\n",
      "test Acc 0.9641527001862198:\n",
      "4th- epoch: 30, train_loss = 17.394418001174927, train_acc = 0.9673963670237541\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 31, train_loss = 16.89279766008258, train_acc = 0.9683278993945039\n",
      "test Acc 0.9664804469273743:\n",
      "4th- epoch: 32, train_loss = 16.42360984161496, train_acc = 0.9689101071262226\n",
      "test Acc 0.9669459962756052:\n",
      "4th- epoch: 33, train_loss = 15.983260605484247, train_acc = 0.9697251979506288\n",
      "test Acc 0.9674115456238361:\n",
      "4th- epoch: 34, train_loss = 15.568191055208445, train_acc = 0.9713553795994411\n",
      "test Acc 0.9683426443202979:\n",
      "4th- epoch: 35, train_loss = 15.175638072192669, train_acc = 0.972286911970191\n",
      "test Acc 0.9692737430167597:\n",
      "4th- epoch: 36, train_loss = 14.803469277918339, train_acc = 0.9739170936190032\n",
      "test Acc 0.9702048417132216:\n",
      "4th- epoch: 37, train_loss = 14.450024325400591, train_acc = 0.9748486259897532\n",
      "test Acc 0.9720670391061452:\n",
      "4th- epoch: 38, train_loss = 14.113893337547779, train_acc = 0.9755472752678156\n",
      "test Acc 0.9739292364990689:\n",
      "4th- epoch: 39, train_loss = 13.793658692389727, train_acc = 0.9760130414531905\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 40, train_loss = 13.488871406763792, train_acc = 0.9768281322775967\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 41, train_loss = 13.19794051349163, train_acc = 0.9771774569166278\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 42, train_loss = 12.919778183102608, train_acc = 0.9775267815556591\n",
      "test Acc 0.9757914338919925:\n",
      "4th- epoch: 43, train_loss = 12.653625719249249, train_acc = 0.9777596646483465\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 44, train_loss = 12.398666799068451, train_acc = 0.977992547741034\n",
      "test Acc 0.9762569832402235:\n",
      "4th- epoch: 45, train_loss = 12.15399431809783, train_acc = 0.9782254308337215\n",
      "test Acc 0.9771880819366853:\n",
      "4th- epoch: 46, train_loss = 11.918847065418959, train_acc = 0.9785747554727526\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 47, train_loss = 11.692719660699368, train_acc = 0.9791569632044713\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 48, train_loss = 11.474930360913277, train_acc = 0.9799720540288775\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 49, train_loss = 11.2648646235466, train_acc = 0.9805542617605962\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 50, train_loss = 11.061964459717274, train_acc = 0.9811364694923148\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 51, train_loss = 10.865460012108088, train_acc = 0.9817186772240335\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 52, train_loss = 10.67515591904521, train_acc = 0.9816022356776898\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 53, train_loss = 10.491161860525608, train_acc = 0.9818351187703773\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 54, train_loss = 10.313042405992746, train_acc = 0.981951560316721\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 55, train_loss = 10.140453360974789, train_acc = 0.981951560316721\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 56, train_loss = 9.9731486402452, train_acc = 0.9821844434094085\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 57, train_loss = 9.810707619413733, train_acc = 0.9825337680484397\n",
      "test Acc 0.9776536312849162:\n",
      "4th- epoch: 58, train_loss = 9.652958575636148, train_acc = 0.9827666511411272\n",
      "test Acc 0.9781191806331471:\n",
      "4th- epoch: 59, train_loss = 9.499627441167831, train_acc = 0.9827666511411272\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 60, train_loss = 9.350152529776096, train_acc = 0.9828830926874709\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 61, train_loss = 9.204268276691437, train_acc = 0.9829995342338146\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 62, train_loss = 9.062090743333101, train_acc = 0.9828830926874709\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 63, train_loss = 8.923546500504017, train_acc = 0.9828830926874709\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 64, train_loss = 8.788315271958709, train_acc = 0.9831159757801584\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 65, train_loss = 8.656533997505903, train_acc = 0.9831159757801584\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 66, train_loss = 8.528083289042115, train_acc = 0.9832324173265021\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 67, train_loss = 8.402537971735, train_acc = 0.9834653004191896\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 68, train_loss = 8.279913349077106, train_acc = 0.983698183511877\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 69, train_loss = 8.159914365038276, train_acc = 0.9840475081509082\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 70, train_loss = 8.04216481000185, train_acc = 0.9843968327899395\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 71, train_loss = 7.927309071645141, train_acc = 0.9848625989753144\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 72, train_loss = 7.8148950971663, train_acc = 0.9849790405216581\n",
      "test Acc 0.979050279329609:\n",
      "4th- epoch: 73, train_loss = 7.704848663881421, train_acc = 0.9850954820680019\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 74, train_loss = 7.597243336960673, train_acc = 0.9855612482533768\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 75, train_loss = 7.491770684719086, train_acc = 0.9856776897997206\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 76, train_loss = 7.3885326106101274, train_acc = 0.9857941313460643\n",
      "test Acc 0.9795158286778398:\n",
      "4th- epoch: 77, train_loss = 7.287473009899259, train_acc = 0.9857941313460643\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 78, train_loss = 7.188312977552414, train_acc = 0.9857941313460643\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 79, train_loss = 7.091164797544479, train_acc = 0.9857941313460643\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 80, train_loss = 6.995845498517156, train_acc = 0.9862598975314392\n",
      "test Acc 0.9799813780260708:\n",
      "4th- epoch: 81, train_loss = 6.902444215491414, train_acc = 0.9862598975314392\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 82, train_loss = 6.810751352459192, train_acc = 0.9864927806241267\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 83, train_loss = 6.720947971567512, train_acc = 0.9867256637168141\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 84, train_loss = 6.63283652998507, train_acc = 0.9870749883558454\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 85, train_loss = 6.54630096629262, train_acc = 0.9871914299021891\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 86, train_loss = 6.461397238075733, train_acc = 0.9874243129948765\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 87, train_loss = 6.378019813448191, train_acc = 0.9876571960875641\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 88, train_loss = 6.296297425404191, train_acc = 0.9880065207265952\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 89, train_loss = 6.215956753119826, train_acc = 0.9881229622729389\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 90, train_loss = 6.136946378275752, train_acc = 0.9887051700046576\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 91, train_loss = 6.0594527162611485, train_acc = 0.9888216115510013\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 92, train_loss = 5.983420001342893, train_acc = 0.9889380530973452\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 93, train_loss = 5.908766148611903, train_acc = 0.9889380530973452\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 94, train_loss = 5.835549458861351, train_acc = 0.9889380530973452\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 95, train_loss = 5.763740137219429, train_acc = 0.9889380530973452\n",
      "test Acc 0.9809124767225326:\n",
      "4th- epoch: 96, train_loss = 5.693262480199337, train_acc = 0.9889380530973452\n",
      "test Acc 0.9804469273743017:\n",
      "4th- epoch: 97, train_loss = 5.624146299436688, train_acc = 0.9889380530973452\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 98, train_loss = 5.556311162188649, train_acc = 0.9891709361900326\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 99, train_loss = 5.48968097474426, train_acc = 0.9892873777363763\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 100, train_loss = 5.424352669157088, train_acc = 0.9892873777363763\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 101, train_loss = 5.360195723362267, train_acc = 0.989869585468095\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 102, train_loss = 5.297274486161768, train_acc = 0.9901024685607824\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 103, train_loss = 5.235438249073923, train_acc = 0.99033535165347\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 104, train_loss = 5.17474924121052, train_acc = 0.9904517931998137\n",
      "test Acc 0.9813780260707635:\n",
      "4th- epoch: 105, train_loss = 5.1151936408132315, train_acc = 0.9904517931998137\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 106, train_loss = 5.056768105365336, train_acc = 0.9904517931998137\n",
      "test Acc 0.9818435754189944:\n",
      "4th- epoch: 107, train_loss = 4.999332736246288, train_acc = 0.9906846762925011\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 108, train_loss = 4.943016440607607, train_acc = 0.990801117838845\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 109, train_loss = 4.887618584558368, train_acc = 0.990801117838845\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 110, train_loss = 4.833240516483784, train_acc = 0.9909175593851887\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 111, train_loss = 4.779845268465579, train_acc = 0.9909175593851887\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 112, train_loss = 4.727349652908742, train_acc = 0.9909175593851887\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 113, train_loss = 4.675808988511562, train_acc = 0.990801117838845\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 114, train_loss = 4.625062339939177, train_acc = 0.990801117838845\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 115, train_loss = 4.57527578342706, train_acc = 0.9911504424778761\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 116, train_loss = 4.526299771852791, train_acc = 0.9911504424778761\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 117, train_loss = 4.478258459828794, train_acc = 0.9912668840242198\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 118, train_loss = 4.431041303090751, train_acc = 0.9912668840242198\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 119, train_loss = 4.384759395383298, train_acc = 0.9913833255705635\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 120, train_loss = 4.339177800342441, train_acc = 0.9916162086632511\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 121, train_loss = 4.294377881102264, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 122, train_loss = 4.250505133531988, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 123, train_loss = 4.207132777199149, train_acc = 0.992081974848626\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 124, train_loss = 4.164721923880279, train_acc = 0.9921984163949698\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 125, train_loss = 4.122949623502791, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 126, train_loss = 4.081833944655955, train_acc = 0.9924312994876572\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 127, train_loss = 4.041468487121165, train_acc = 0.9925477410340009\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 128, train_loss = 4.001700759865344, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 129, train_loss = 3.9625999685376883, train_acc = 0.9928970656730322\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 130, train_loss = 3.9241516990587115, train_acc = 0.9928970656730322\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 131, train_loss = 3.886240682564676, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 132, train_loss = 3.8490956518799067, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 133, train_loss = 3.8124446468427777, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 134, train_loss = 3.776423134841025, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 135, train_loss = 3.740979792550206, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 136, train_loss = 3.7060912125743926, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 137, train_loss = 3.671821144875139, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 138, train_loss = 3.6380292694084346, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 139, train_loss = 3.6048258799128234, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 140, train_loss = 3.572110055014491, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 141, train_loss = 3.539981564041227, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 142, train_loss = 3.508289507124573, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 143, train_loss = 3.477063160855323, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 144, train_loss = 3.4463994740508497, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 145, train_loss = 3.416022988036275, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 146, train_loss = 3.3862371356226504, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 147, train_loss = 3.356908578891307, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 148, train_loss = 3.3279909207485616, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "4th- epoch: 149, train_loss = 3.299514713231474, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 150, train_loss = 3.2715242342092097, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 151, train_loss = 3.2439366900362074, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 152, train_loss = 3.2167118112556636, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 153, train_loss = 3.1899406923912466, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 154, train_loss = 3.163550500292331, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 155, train_loss = 3.137495041359216, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 156, train_loss = 3.111912614200264, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 157, train_loss = 3.086625749245286, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 158, train_loss = 3.0617031170986593, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 159, train_loss = 3.0372665454633534, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 160, train_loss = 3.0130535010248423, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 161, train_loss = 2.989216346759349, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 162, train_loss = 2.965840080752969, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 163, train_loss = 2.9426514231599867, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 164, train_loss = 2.9199010799638927, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 165, train_loss = 2.8973718490451574, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 166, train_loss = 2.8753131362609565, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 167, train_loss = 2.8534846645779908, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 168, train_loss = 2.8320115697570145, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 169, train_loss = 2.8106718752533197, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 170, train_loss = 2.7899112408049405, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 171, train_loss = 2.7692613061517477, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 172, train_loss = 2.748907597735524, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 173, train_loss = 2.728992810472846, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 174, train_loss = 2.709242648910731, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 175, train_loss = 2.6897481493651867, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 176, train_loss = 2.6705973763018847, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 177, train_loss = 2.6516456375829875, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 178, train_loss = 2.6330343764275312, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 179, train_loss = 2.61457931692712, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 180, train_loss = 2.596581903519109, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 181, train_loss = 2.5786963913124055, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 182, train_loss = 2.561119796708226, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 183, train_loss = 2.543749077944085, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 184, train_loss = 2.5266591261606663, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 185, train_loss = 2.5098197050392628, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 186, train_loss = 2.4931454539764673, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 187, train_loss = 2.4767971970140934, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 188, train_loss = 2.460636243224144, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 189, train_loss = 2.444677595049143, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 190, train_loss = 2.428936241194606, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 191, train_loss = 2.4133595663588494, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 192, train_loss = 2.398067557020113, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 193, train_loss = 2.3829367451835424, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 194, train_loss = 2.367997931316495, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 195, train_loss = 2.353363214759156, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 196, train_loss = 2.338808050379157, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 197, train_loss = 2.324487106874585, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 198, train_loss = 2.310332226799801, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 199, train_loss = 2.2963577918708324, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 200, train_loss = 2.282672232016921, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 201, train_loss = 2.2689420625101775, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 202, train_loss = 2.2556791834067553, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 203, train_loss = 2.242382714524865, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 204, train_loss = 2.2292773958761245, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 205, train_loss = 2.2163894020486623, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 206, train_loss = 2.2036499436944723, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 207, train_loss = 2.1910272743552923, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 208, train_loss = 2.178653535665944, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 209, train_loss = 2.166376506211236, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 210, train_loss = 2.1542986270505935, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 211, train_loss = 2.1423575952649117, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 212, train_loss = 2.1305646982509643, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 213, train_loss = 2.118976892204955, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 214, train_loss = 2.107455729274079, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 215, train_loss = 2.09621665882878, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 216, train_loss = 2.0849699191749096, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 217, train_loss = 2.0740212711971253, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 218, train_loss = 2.0629556986968964, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 219, train_loss = 2.05233263107948, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 220, train_loss = 2.0416238892357796, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 221, train_loss = 2.031157872406766, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 222, train_loss = 2.020779736340046, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 223, train_loss = 2.010444985004142, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 224, train_loss = 2.0003732219338417, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 225, train_loss = 1.9903205893933773, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 226, train_loss = 1.9803899936378002, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 227, train_loss = 1.970652312040329, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 228, train_loss = 1.9610380021622404, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 229, train_loss = 1.9514567503938451, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 230, train_loss = 1.9420449560275301, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 231, train_loss = 1.9327445389935747, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 232, train_loss = 1.9235846312949434, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 233, train_loss = 1.9145708655705675, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 234, train_loss = 1.905520398169756, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 235, train_loss = 1.8967675802996382, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 236, train_loss = 1.8878773314645514, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 237, train_loss = 1.8793290009489283, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 238, train_loss = 1.8707792175700888, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 239, train_loss = 1.862242702394724, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 240, train_loss = 1.8539636358618736, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 241, train_loss = 1.8456837212434039, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 242, train_loss = 1.837453130632639, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 243, train_loss = 1.8294522911310196, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 244, train_loss = 1.821457472979091, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "4th- epoch: 245, train_loss = 1.8135717287659645, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 246, train_loss = 1.8058471655240282, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 247, train_loss = 1.798138864338398, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 248, train_loss = 1.7906024804105982, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 249, train_loss = 1.7830295214662328, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "4th- epoch: 250, train_loss = 1.7757686587283388, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 251, train_loss = 1.7683958982815966, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 252, train_loss = 1.7610618224134669, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 253, train_loss = 1.7540094355354086, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 254, train_loss = 1.7468385746469721, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 255, train_loss = 1.7398988032946363, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 256, train_loss = 1.7329964427044615, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 257, train_loss = 1.7260550496866927, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 258, train_loss = 1.7193432375788689, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 259, train_loss = 1.7125797668704763, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 260, train_loss = 1.7058481959393248, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 261, train_loss = 1.6992832632968202, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 262, train_loss = 1.6927764205029234, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 263, train_loss = 1.6863725744187832, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 264, train_loss = 1.6799719259142876, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 265, train_loss = 1.673556923866272, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 266, train_loss = 1.6673235656926408, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 267, train_loss = 1.6610853783786297, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 268, train_loss = 1.6550134234130383, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 269, train_loss = 1.6489920342573896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 270, train_loss = 1.642897987156175, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 271, train_loss = 1.63700605800841, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 272, train_loss = 1.6311436170944944, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 273, train_loss = 1.6252668300876394, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 274, train_loss = 1.6195605285465717, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 275, train_loss = 1.6137429811060429, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 276, train_loss = 1.60818460828159, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 277, train_loss = 1.6024890193948522, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 278, train_loss = 1.5969405161449686, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 279, train_loss = 1.5914803184568882, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 280, train_loss = 1.5860224118223414, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 281, train_loss = 1.5806381242582574, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 282, train_loss = 1.575405552983284, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 283, train_loss = 1.5700110867619514, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 284, train_loss = 1.5648554736981168, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 285, train_loss = 1.5596350406995043, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 286, train_loss = 1.5544450506567955, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 287, train_loss = 1.5493286674609408, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 288, train_loss = 1.544281228154432, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "4th- epoch: 289, train_loss = 1.5391597847337835, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "4th- epoch: 290, train_loss = 1.5343359832768328, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "4th- epoch: 291, train_loss = 1.529261950403452, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 292, train_loss = 1.5244378025527112, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 293, train_loss = 1.5195693063433282, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 294, train_loss = 1.5148361970786937, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 295, train_loss = 1.510071825236082, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 296, train_loss = 1.5053551457822323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 297, train_loss = 1.5006517097353935, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 298, train_loss = 1.4960836197133176, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 299, train_loss = 1.4914654840831645, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 300, train_loss = 1.4869179651141167, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 301, train_loss = 1.4823120658402331, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 302, train_loss = 1.4777864292263985, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 303, train_loss = 1.4734428550000302, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 304, train_loss = 1.4689429092104547, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 305, train_loss = 1.4644794526393525, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 306, train_loss = 1.4602038003504276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 307, train_loss = 1.4558036550879478, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 308, train_loss = 1.4516031158273108, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 309, train_loss = 1.44742662954377, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 310, train_loss = 1.4432456766371615, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 311, train_loss = 1.4392759588663466, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 312, train_loss = 1.4351662881672382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 313, train_loss = 1.43109967187047, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 314, train_loss = 1.4271696917712688, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 315, train_loss = 1.4231905862689018, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 316, train_loss = 1.4193593636155128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 317, train_loss = 1.4154182262718678, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 318, train_loss = 1.4115661308169365, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 319, train_loss = 1.4078044245834462, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 320, train_loss = 1.4040283784270287, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 321, train_loss = 1.4002066564862616, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 322, train_loss = 1.3965260709519498, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 323, train_loss = 1.3928186036646366, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 324, train_loss = 1.3891895065899007, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 325, train_loss = 1.385565273463726, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 326, train_loss = 1.381870362907648, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 327, train_loss = 1.3784221199457534, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 328, train_loss = 1.3748322762548923, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 329, train_loss = 1.371300617873203, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 330, train_loss = 1.3678286249632947, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 331, train_loss = 1.364410066336859, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "4th- epoch: 332, train_loss = 1.3608779162168503, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 333, train_loss = 1.357528954744339, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 334, train_loss = 1.3541274070739746, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 335, train_loss = 1.350757786363829, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 336, train_loss = 1.3474821845884435, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 337, train_loss = 1.344123284041416, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 338, train_loss = 1.3408385924994946, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 339, train_loss = 1.3375958378310315, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 340, train_loss = 1.334406092762947, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 341, train_loss = 1.331192710727919, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 342, train_loss = 1.3279290559585206, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 343, train_loss = 1.324842372268904, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 344, train_loss = 1.321681095927488, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 345, train_loss = 1.31857067841338, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 346, train_loss = 1.3155106504564174, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 347, train_loss = 1.312471044540871, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 348, train_loss = 1.3094186683301814, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 349, train_loss = 1.306314293295145, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 350, train_loss = 1.303384330123663, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 351, train_loss = 1.3004337536985986, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 352, train_loss = 1.2974673137068748, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 353, train_loss = 1.2945181516115554, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 354, train_loss = 1.2916142729227431, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 355, train_loss = 1.2887235197122209, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 356, train_loss = 1.2858543868060224, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 357, train_loss = 1.2829519783263095, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 358, train_loss = 1.2801685693557374, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 359, train_loss = 1.2774096975917928, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 360, train_loss = 1.274581031233538, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 361, train_loss = 1.2718532991711982, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 362, train_loss = 1.2690079758758657, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 363, train_loss = 1.266321536153555, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 364, train_loss = 1.2636865650420077, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 365, train_loss = 1.2609633157844655, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 366, train_loss = 1.2582400453684386, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 367, train_loss = 1.2556179302337114, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 368, train_loss = 1.2529781249759253, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 369, train_loss = 1.2503588385879993, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 370, train_loss = 1.24779268229031, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 371, train_loss = 1.2451329169271048, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 372, train_loss = 1.2426384948194027, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 373, train_loss = 1.2400679228303488, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 374, train_loss = 1.2375104191305581, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 375, train_loss = 1.234958248824114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 376, train_loss = 1.2324739235045854, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 377, train_loss = 1.229960273951292, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 378, train_loss = 1.227574040502077, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 379, train_loss = 1.2251262118516024, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 380, train_loss = 1.22265699878335, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 381, train_loss = 1.220220668852562, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 382, train_loss = 1.21778647476458, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 383, train_loss = 1.21551950648427, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 384, train_loss = 1.2130754577519838, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 385, train_loss = 1.2107197158038616, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 386, train_loss = 1.2083624017832335, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 387, train_loss = 1.2060166113078594, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 388, train_loss = 1.2037362282571848, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 389, train_loss = 1.20140865072608, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 390, train_loss = 1.1991255717875902, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 391, train_loss = 1.19693691530847, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 392, train_loss = 1.1945812404155731, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 393, train_loss = 1.1924093676207121, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 394, train_loss = 1.1901648752391338, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 395, train_loss = 1.187964995711809, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 396, train_loss = 1.1857622439565603, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 397, train_loss = 1.183530059963232, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 398, train_loss = 1.1813808642327785, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 399, train_loss = 1.1792491562664509, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 400, train_loss = 1.1771109414694365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 401, train_loss = 1.175038170069456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 402, train_loss = 1.1728427037596703, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 403, train_loss = 1.1707642674446106, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 404, train_loss = 1.168677907437086, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 405, train_loss = 1.1666372741165105, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 406, train_loss = 1.16461718454957, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 407, train_loss = 1.1625028712151106, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 408, train_loss = 1.1604777686297894, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 409, train_loss = 1.1584451384842396, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 410, train_loss = 1.1564815727469977, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 411, train_loss = 1.1544177817704622, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 412, train_loss = 1.1524205766618252, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 413, train_loss = 1.1505042351782322, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 414, train_loss = 1.1484920804796275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 415, train_loss = 1.1465640477836132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 416, train_loss = 1.144585981965065, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 417, train_loss = 1.1426682621240616, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 418, train_loss = 1.1407639545795973, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 419, train_loss = 1.1388827276823577, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 420, train_loss = 1.1369955701229628, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 421, train_loss = 1.1350331877765711, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 422, train_loss = 1.1332300764916, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 423, train_loss = 1.1312965787947178, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 424, train_loss = 1.1294520857336465, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 425, train_loss = 1.1276091995241586, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 426, train_loss = 1.1258851972816046, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 427, train_loss = 1.1239972362818662, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 428, train_loss = 1.1221920102834702, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 429, train_loss = 1.1203024747374002, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 430, train_loss = 1.1185518577694893, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 431, train_loss = 1.1167840709385928, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 432, train_loss = 1.1150507082638796, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 433, train_loss = 1.1132692744431552, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 434, train_loss = 1.1115480735898018, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 435, train_loss = 1.1097483523190022, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 436, train_loss = 1.1081070912478026, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 437, train_loss = 1.1062956266105175, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 438, train_loss = 1.1046349021198694, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 439, train_loss = 1.1028928185405675, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 440, train_loss = 1.1012220680713654, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 441, train_loss = 1.099488547682995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 442, train_loss = 1.0978296287357807, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 443, train_loss = 1.0961521305143833, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 444, train_loss = 1.0944839554431383, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4th- epoch: 445, train_loss = 1.0928767385485116, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 446, train_loss = 1.0911776361463126, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 447, train_loss = 1.089540316403145, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 448, train_loss = 1.0879637499747332, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 449, train_loss = 1.0863210658135358, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 450, train_loss = 1.084743868559599, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 451, train_loss = 1.0830911931989249, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 452, train_loss = 1.0815659003856126, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 453, train_loss = 1.0798752581176814, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 454, train_loss = 1.0784845563175622, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 455, train_loss = 1.076846585929161, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 456, train_loss = 1.0753012845816556, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 457, train_loss = 1.0737142898142338, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 458, train_loss = 1.0721643082797527, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 459, train_loss = 1.07063321894384, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 460, train_loss = 1.0691596046090126, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "4th- epoch: 461, train_loss = 1.0676251711847726, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "4th- epoch: 462, train_loss = 1.0661617604491767, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "4th- epoch: 463, train_loss = 1.0646020025014877, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 464, train_loss = 1.063203545898432, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 465, train_loss = 1.0616478696465492, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 466, train_loss = 1.0601717183890287, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 467, train_loss = 1.0587193307874259, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 468, train_loss = 1.0572648011147976, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 469, train_loss = 1.055773983389372, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 470, train_loss = 1.0543756783008575, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 471, train_loss = 1.0528808422386646, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 472, train_loss = 1.0513914674520493, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 473, train_loss = 1.0499729476869106, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 474, train_loss = 1.048576481640339, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 475, train_loss = 1.0471664393990068, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 476, train_loss = 1.0457343471498461, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 477, train_loss = 1.0443570402712794, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 478, train_loss = 1.042871658995864, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 479, train_loss = 1.041655829802039, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 480, train_loss = 1.0402578227221966, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 481, train_loss = 1.0388535757811042, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 482, train_loss = 1.0375194139778614, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 483, train_loss = 1.036175490662572, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 484, train_loss = 1.0347558706998825, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 485, train_loss = 1.033367708325386, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 486, train_loss = 1.0321728164999513, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 487, train_loss = 1.0307625221757917, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 488, train_loss = 1.0295191543846158, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 489, train_loss = 1.0281494458467932, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 490, train_loss = 1.0268900518567534, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 491, train_loss = 1.02545818562794, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 492, train_loss = 1.0242340577096911, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 493, train_loss = 1.022918334856513, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 494, train_loss = 1.021605319037917, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 495, train_loss = 1.020295878246543, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 496, train_loss = 1.0191982636897592, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 497, train_loss = 1.0177797960786847, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 498, train_loss = 1.0165691524744034, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "4th- epoch: 499, train_loss = 1.015270795673132, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█████████▋                                                               | 4/30 [26:56<2:54:03, 401.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "5th- epoch: 0, train_loss = 275.3363128900528, train_acc = 0.44096413600372614\n",
      "test Acc 0.5023277467411545:\n",
      "5th- epoch: 1, train_loss = 207.60424077510834, train_acc = 0.5026781555659059\n",
      "test Acc 0.5181564245810056:\n",
      "5th- epoch: 2, train_loss = 160.3489077091217, train_acc = 0.5841872380065207\n",
      "test Acc 0.6559590316573557:\n",
      "5th- epoch: 3, train_loss = 133.8859977722168, train_acc = 0.6859571495109456\n",
      "test Acc 0.723463687150838:\n",
      "5th- epoch: 4, train_loss = 113.77368795871735, train_acc = 0.7440614811364695\n",
      "test Acc 0.7630353817504656:\n",
      "5th- epoch: 5, train_loss = 98.35113090276718, train_acc = 0.7791103865859339\n",
      "test Acc 0.7905027932960894:\n",
      "5th- epoch: 6, train_loss = 86.17530569434166, train_acc = 0.8015836050302748\n",
      "test Acc 0.8081936685288641:\n",
      "5th- epoch: 7, train_loss = 76.1946656703949, train_acc = 0.8228924080111784\n",
      "test Acc 0.8305400372439479:\n",
      "5th- epoch: 8, train_loss = 67.80225050449371, train_acc = 0.8503726129482999\n",
      "test Acc 0.8594040968342644:\n",
      "5th- epoch: 9, train_loss = 60.71836540102959, train_acc = 0.8769212855146716\n",
      "test Acc 0.888733705772812:\n",
      "5th- epoch: 10, train_loss = 54.75029253959656, train_acc = 0.8976478807638566\n",
      "test Acc 0.9050279329608939:\n",
      "5th- epoch: 11, train_loss = 49.6957478672266, train_acc = 0.9090591523055426\n",
      "test Acc 0.9171322160148976:\n",
      "5th- epoch: 12, train_loss = 45.3775460422039, train_acc = 0.9212855146716349\n",
      "test Acc 0.9278398510242085:\n",
      "5th- epoch: 13, train_loss = 41.65566858649254, train_acc = 0.935258500232883\n",
      "test Acc 0.9352886405959032:\n",
      "5th- epoch: 14, train_loss = 38.42660269141197, train_acc = 0.9394503959012576\n",
      "test Acc 0.9385474860335196:\n",
      "5th- epoch: 15, train_loss = 35.61994018405676, train_acc = 0.941895668374476\n",
      "test Acc 0.9418063314711359:\n",
      "5th- epoch: 16, train_loss = 33.17842450737953, train_acc = 0.944108057755007\n",
      "test Acc 0.9459962756052142:\n",
      "5th- epoch: 17, train_loss = 31.050223477184772, train_acc = 0.945854680950163\n",
      "test Acc 0.9483240223463687:\n",
      "5th- epoch: 18, train_loss = 29.19397859275341, train_acc = 0.9499301350721937\n",
      "test Acc 0.952048417132216:\n",
      "5th- epoch: 19, train_loss = 27.57098438590765, train_acc = 0.9542384722869119\n",
      "test Acc 0.9539106145251397:\n",
      "5th- epoch: 20, train_loss = 26.145615942776203, train_acc = 0.9556357708430367\n",
      "test Acc 0.9548417132216015:\n",
      "5th- epoch: 21, train_loss = 24.884427208453417, train_acc = 0.9572659524918491\n",
      "test Acc 0.9553072625698324:\n",
      "5th- epoch: 22, train_loss = 23.761405609548092, train_acc = 0.9591290172333489\n",
      "test Acc 0.9567039106145251:\n",
      "5th- epoch: 23, train_loss = 22.758872594684362, train_acc = 0.9601769911504425\n",
      "test Acc 0.957635009310987:\n",
      "5th- epoch: 24, train_loss = 21.857540383934975, train_acc = 0.9611085235211924\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 25, train_loss = 21.04102112352848, train_acc = 0.9619236143455985\n",
      "test Acc 0.957169459962756:\n",
      "5th- epoch: 26, train_loss = 20.295867778360844, train_acc = 0.9630880298090359\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 27, train_loss = 19.61187792569399, train_acc = 0.9640195621797858\n",
      "test Acc 0.9581005586592178:\n",
      "5th- epoch: 28, train_loss = 18.98208873346448, train_acc = 0.9648346530041919\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 29, train_loss = 18.399320982396603, train_acc = 0.965649743828598\n",
      "test Acc 0.9585661080074488:\n",
      "5th- epoch: 30, train_loss = 17.857011426240206, train_acc = 0.9662319515603167\n",
      "test Acc 0.9594972067039106:\n",
      "5th- epoch: 31, train_loss = 17.350478526204824, train_acc = 0.9671634839310667\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 32, train_loss = 16.87564130499959, train_acc = 0.9673963670237541\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 33, train_loss = 16.429359298199415, train_acc = 0.9680950163018165\n",
      "test Acc 0.9599627560521415:\n",
      "5th- epoch: 34, train_loss = 16.00891312211752, train_acc = 0.969608756404285\n",
      "test Acc 0.9608938547486033:\n",
      "5th- epoch: 35, train_loss = 15.611409600824118, train_acc = 0.970540288775035\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 36, train_loss = 15.234474025666714, train_acc = 0.9708896134140661\n",
      "test Acc 0.9613594040968343:\n",
      "5th- epoch: 37, train_loss = 14.876136139035225, train_acc = 0.9715882626921285\n",
      "test Acc 0.962756052141527:\n",
      "5th- epoch: 38, train_loss = 14.534891199320555, train_acc = 0.9721704704238472\n",
      "test Acc 0.9641527001862198:\n",
      "5th- epoch: 39, train_loss = 14.209753420203924, train_acc = 0.9731020027945971\n",
      "test Acc 0.9650837988826816:\n",
      "5th- epoch: 40, train_loss = 13.899117778986692, train_acc = 0.9734513274336283\n",
      "test Acc 0.9674115456238361:\n",
      "5th- epoch: 41, train_loss = 13.60141320899129, train_acc = 0.9739170936190032\n",
      "test Acc 0.9697392923649907:\n",
      "5th- epoch: 42, train_loss = 13.316186606884003, train_acc = 0.9747321844434094\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 43, train_loss = 13.042375288903713, train_acc = 0.9749650675360969\n",
      "test Acc 0.9711359404096834:\n",
      "5th- epoch: 44, train_loss = 12.778972566127777, train_acc = 0.9756637168141593\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 45, train_loss = 12.524711482226849, train_acc = 0.9761294829995343\n",
      "test Acc 0.9720670391061452:\n",
      "5th- epoch: 46, train_loss = 12.278986867517233, train_acc = 0.9765952491849091\n",
      "test Acc 0.973463687150838:\n",
      "5th- epoch: 47, train_loss = 12.042365204542875, train_acc = 0.9768281322775967\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 48, train_loss = 11.814789310097694, train_acc = 0.9771774569166278\n",
      "test Acc 0.9739292364990689:\n",
      "5th- epoch: 49, train_loss = 11.595663417130709, train_acc = 0.9775267815556591\n",
      "test Acc 0.9743947858472998:\n",
      "5th- epoch: 50, train_loss = 11.384380418807268, train_acc = 0.9778761061946902\n",
      "test Acc 0.9753258845437617:\n",
      "5th- epoch: 51, train_loss = 11.180659100413322, train_acc = 0.9786911970190965\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 52, train_loss = 10.98366318270564, train_acc = 0.9793898462971589\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 53, train_loss = 10.793053045868874, train_acc = 0.9800884955752213\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 54, train_loss = 10.608809679746628, train_acc = 0.9804378202142524\n",
      "test Acc 0.9762569832402235:\n",
      "5th- epoch: 55, train_loss = 10.430747658014297, train_acc = 0.98067070330694\n",
      "test Acc 0.9767225325884544:\n",
      "5th- epoch: 56, train_loss = 10.25828219205141, train_acc = 0.9811364694923148\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 57, train_loss = 10.090945636853576, train_acc = 0.9811364694923148\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 58, train_loss = 9.92836980894208, train_acc = 0.9814857941313461\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 59, train_loss = 9.770251382142305, train_acc = 0.9817186772240335\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 60, train_loss = 9.616490323096514, train_acc = 0.9818351187703773\n",
      "test Acc 0.9771880819366853:\n",
      "5th- epoch: 61, train_loss = 9.466855607926846, train_acc = 0.9820680018630648\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 62, train_loss = 9.321033859625459, train_acc = 0.9821844434094085\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 63, train_loss = 9.179051157087088, train_acc = 0.9824173265020959\n",
      "test Acc 0.9781191806331471:\n",
      "5th- epoch: 64, train_loss = 9.040625240653753, train_acc = 0.9824173265020959\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 65, train_loss = 8.905722690746188, train_acc = 0.9831159757801584\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 66, train_loss = 8.774281727150083, train_acc = 0.9833488588728458\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 67, train_loss = 8.645581996068358, train_acc = 0.9834653004191896\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 68, train_loss = 8.519860871136189, train_acc = 0.9834653004191896\n",
      "test Acc 0.978584729981378:\n",
      "5th- epoch: 69, train_loss = 8.396923527121544, train_acc = 0.9835817419655333\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 70, train_loss = 8.276721186935902, train_acc = 0.9838146250582208\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 71, train_loss = 8.159201622009277, train_acc = 0.984163949697252\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 72, train_loss = 8.044233137741685, train_acc = 0.9842803912435957\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 73, train_loss = 7.93161298148334, train_acc = 0.9843968327899395\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 74, train_loss = 7.821375297382474, train_acc = 0.9847461574289706\n",
      "test Acc 0.979050279329609:\n",
      "5th- epoch: 75, train_loss = 7.713372299447656, train_acc = 0.9849790405216581\n",
      "test Acc 0.9795158286778398:\n",
      "5th- epoch: 76, train_loss = 7.607479961588979, train_acc = 0.9850954820680019\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 77, train_loss = 7.50376564823091, train_acc = 0.9852119236143456\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 78, train_loss = 7.402133470401168, train_acc = 0.9857941313460643\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 79, train_loss = 7.302473550662398, train_acc = 0.9860270144387517\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 80, train_loss = 7.204907523468137, train_acc = 0.9862598975314392\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 81, train_loss = 7.109008068218827, train_acc = 0.986376339077783\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 82, train_loss = 7.014972817152739, train_acc = 0.9867256637168141\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 83, train_loss = 6.922656271606684, train_acc = 0.9868421052631579\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 84, train_loss = 6.832128208130598, train_acc = 0.9869585468095017\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 85, train_loss = 6.743105785921216, train_acc = 0.9870749883558454\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 86, train_loss = 6.656017582863569, train_acc = 0.9871914299021891\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 87, train_loss = 6.570578549057245, train_acc = 0.9871914299021891\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 88, train_loss = 6.486747328191996, train_acc = 0.9876571960875641\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 89, train_loss = 6.404317511245608, train_acc = 0.9877736376339078\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 90, train_loss = 6.323551708832383, train_acc = 0.9881229622729389\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 91, train_loss = 6.2441064435988665, train_acc = 0.9881229622729389\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 92, train_loss = 6.166254503652453, train_acc = 0.9883558453656265\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 93, train_loss = 6.089831029996276, train_acc = 0.9885887284583139\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 94, train_loss = 6.014768360182643, train_acc = 0.9884722869119702\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 95, train_loss = 5.941033970564604, train_acc = 0.9884722869119702\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 96, train_loss = 5.8683773688972, train_acc = 0.9887051700046576\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 97, train_loss = 5.796625632792711, train_acc = 0.9889380530973452\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 98, train_loss = 5.725953608751297, train_acc = 0.9890544946436889\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 99, train_loss = 5.656861087307334, train_acc = 0.9890544946436889\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 100, train_loss = 5.5887222122401, train_acc = 0.9891709361900326\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 101, train_loss = 5.522021060809493, train_acc = 0.9895202608290639\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 102, train_loss = 5.456270717084408, train_acc = 0.98940381928272\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 103, train_loss = 5.391639268025756, train_acc = 0.989869585468095\n",
      "test Acc 0.9809124767225326:\n",
      "5th- epoch: 104, train_loss = 5.328382274135947, train_acc = 0.989869585468095\n",
      "test Acc 0.9804469273743017:\n",
      "5th- epoch: 105, train_loss = 5.266273465007544, train_acc = 0.989869585468095\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 106, train_loss = 5.205201383680105, train_acc = 0.9901024685607824\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 107, train_loss = 5.145243947394192, train_acc = 0.9902189101071263\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 108, train_loss = 5.086552566848695, train_acc = 0.9905682347461574\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 109, train_loss = 5.028615700080991, train_acc = 0.990801117838845\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 110, train_loss = 4.972019608132541, train_acc = 0.9910340009315324\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 111, train_loss = 4.916348213329911, train_acc = 0.9912668840242198\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 112, train_loss = 4.861621237359941, train_acc = 0.9914997671169073\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 113, train_loss = 4.808139809407294, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 114, train_loss = 4.755438085645437, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 115, train_loss = 4.703766314312816, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 116, train_loss = 4.652969552204013, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 117, train_loss = 4.603128895163536, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 118, train_loss = 4.554214272648096, train_acc = 0.9919655333022822\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 119, train_loss = 4.50614679325372, train_acc = 0.9919655333022822\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 120, train_loss = 4.4588479148224, train_acc = 0.992081974848626\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 121, train_loss = 4.412459073588252, train_acc = 0.9921984163949698\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 122, train_loss = 4.3668216578662395, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 123, train_loss = 4.321942202746868, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 124, train_loss = 4.277894143946469, train_acc = 0.9924312994876572\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 125, train_loss = 4.23454306460917, train_acc = 0.9927806241266884\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 126, train_loss = 4.192123071290553, train_acc = 0.9928970656730322\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 127, train_loss = 4.150169366039336, train_acc = 0.9930135072193759\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 128, train_loss = 4.1091214353218675, train_acc = 0.9930135072193759\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 129, train_loss = 4.068714875727892, train_acc = 0.9931299487657196\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 130, train_loss = 4.029065771959722, train_acc = 0.9932463903120633\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 131, train_loss = 3.9900270281359553, train_acc = 0.9935957149510946\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 132, train_loss = 3.9517010040581226, train_acc = 0.9937121564974383\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 133, train_loss = 3.9138827603310347, train_acc = 0.993828598043782\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 134, train_loss = 3.876839349977672, train_acc = 0.9940614811364695\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 135, train_loss = 3.840290947817266, train_acc = 0.9941779226828132\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 136, train_loss = 3.8043722584843636, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 137, train_loss = 3.768956600688398, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 138, train_loss = 3.7342598820105195, train_acc = 0.994294364229157\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 139, train_loss = 3.7000087266787887, train_acc = 0.9944108057755007\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 140, train_loss = 3.666294646449387, train_acc = 0.9944108057755007\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 141, train_loss = 3.6332097873091698, train_acc = 0.9944108057755007\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 142, train_loss = 3.6006128611043096, train_acc = 0.9944108057755007\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 143, train_loss = 3.568341812118888, train_acc = 0.9945272473218444\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 144, train_loss = 3.5367385260760784, train_acc = 0.9945272473218444\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 145, train_loss = 3.505535390228033, train_acc = 0.9945272473218444\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 146, train_loss = 3.4748867079615593, train_acc = 0.9945272473218444\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 147, train_loss = 3.444585118908435, train_acc = 0.9945272473218444\n",
      "test Acc 0.9818435754189944:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 148, train_loss = 3.4146195924840868, train_acc = 0.9947601304145319\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 149, train_loss = 3.3851739298552275, train_acc = 0.9947601304145319\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 150, train_loss = 3.356052013579756, train_acc = 0.9947601304145319\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 151, train_loss = 3.3275846135802567, train_acc = 0.9948765719608756\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 152, train_loss = 3.2992957774549723, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 153, train_loss = 3.271637145895511, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 154, train_loss = 3.2442327053286135, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 155, train_loss = 3.217229574918747, train_acc = 0.9949930135072194\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 156, train_loss = 3.190602794289589, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 157, train_loss = 3.1644227206707, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 158, train_loss = 3.1383993239142, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 159, train_loss = 3.112809563521296, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 160, train_loss = 3.087678086478263, train_acc = 0.9951094550535631\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 161, train_loss = 3.06279325671494, train_acc = 0.9952258965999069\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 162, train_loss = 3.0383354402147233, train_acc = 0.9952258965999069\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 163, train_loss = 3.0142734753899276, train_acc = 0.9952258965999069\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 164, train_loss = 2.9904292966239154, train_acc = 0.9952258965999069\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 165, train_loss = 2.966908277478069, train_acc = 0.9952258965999069\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 166, train_loss = 2.9438279680907726, train_acc = 0.9952258965999069\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 167, train_loss = 2.920898432377726, train_acc = 0.9952258965999069\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 168, train_loss = 2.898370215203613, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 169, train_loss = 2.8761865086853504, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 170, train_loss = 2.8542529810220003, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 171, train_loss = 2.8326563127338886, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 172, train_loss = 2.811305209528655, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 173, train_loss = 2.7902497188188136, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 174, train_loss = 2.769617347046733, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 175, train_loss = 2.749018108472228, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 176, train_loss = 2.728924669791013, train_acc = 0.9953423381462506\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 177, train_loss = 2.7089808606542647, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 178, train_loss = 2.689352946355939, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 179, train_loss = 2.670129355508834, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 180, train_loss = 2.650856915395707, train_acc = 0.9954587796925943\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 181, train_loss = 2.6321732103824615, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 182, train_loss = 2.61352746700868, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 183, train_loss = 2.595280115958303, train_acc = 0.995575221238938\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 184, train_loss = 2.5771183441393077, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 185, train_loss = 2.5593598920386285, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 186, train_loss = 2.5417208697181195, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 187, train_loss = 2.524362127063796, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 188, train_loss = 2.507339086383581, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 189, train_loss = 2.4904214031994343, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 190, train_loss = 2.4738326787482947, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 191, train_loss = 2.4572370660025626, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 192, train_loss = 2.4411893964279443, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 193, train_loss = 2.4251178160775453, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 194, train_loss = 2.4094824742060155, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 195, train_loss = 2.3940365128219128, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 196, train_loss = 2.3786393993068486, train_acc = 0.9956916627852818\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 197, train_loss = 2.363637354923412, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 198, train_loss = 2.348743970738724, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 199, train_loss = 2.334112723125145, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 200, train_loss = 2.3196948699187487, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 201, train_loss = 2.3053826622199267, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 202, train_loss = 2.2914096110034734, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 203, train_loss = 2.2774573594797403, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 204, train_loss = 2.2638265267014503, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 205, train_loss = 2.2503384880255908, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 206, train_loss = 2.236980924382806, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 207, train_loss = 2.223941471427679, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 208, train_loss = 2.210991083877161, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 209, train_loss = 2.1982973273843527, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 210, train_loss = 2.1856102477759123, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 211, train_loss = 2.1732731226366013, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 212, train_loss = 2.161026343004778, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 213, train_loss = 2.14888502843678, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 214, train_loss = 2.1370256729424, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 215, train_loss = 2.1252373240422457, train_acc = 0.9963903120633442\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 216, train_loss = 2.1137006778735667, train_acc = 0.996506753609688\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 217, train_loss = 2.1022983838338405, train_acc = 0.996506753609688\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 218, train_loss = 2.090931073995307, train_acc = 0.996506753609688\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 219, train_loss = 2.079895415576175, train_acc = 0.996506753609688\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 220, train_loss = 2.0688389490824193, train_acc = 0.996506753609688\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 221, train_loss = 2.058116141706705, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 222, train_loss = 2.047353359637782, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 223, train_loss = 2.0368432488758117, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 224, train_loss = 2.02632816019468, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 225, train_loss = 2.0161645363550633, train_acc = 0.9966231951560317\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 226, train_loss = 2.005971619160846, train_acc = 0.9967396367023754\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 227, train_loss = 1.9959339809138328, train_acc = 0.9968560782487191\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 228, train_loss = 1.9860078010242432, train_acc = 0.9968560782487191\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 229, train_loss = 1.976304680109024, train_acc = 0.9968560782487191\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 230, train_loss = 1.9666050523519516, train_acc = 0.9968560782487191\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 231, train_loss = 1.9570684432983398, train_acc = 0.9968560782487191\n",
      "test Acc 0.9813780260707635:\n",
      "5th- epoch: 232, train_loss = 1.9475998741108924, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 233, train_loss = 1.9384116269648075, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 234, train_loss = 1.929158880142495, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 235, train_loss = 1.919987851055339, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 236, train_loss = 1.9111650250852108, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 237, train_loss = 1.902243753313087, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 238, train_loss = 1.8934036418795586, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 239, train_loss = 1.8848605105886236, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 240, train_loss = 1.8762665390968323, train_acc = 0.9968560782487191\n",
      "test Acc 0.9818435754189944:\n",
      "5th- epoch: 241, train_loss = 1.8677338436245918, train_acc = 0.9968560782487191\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 242, train_loss = 1.859457346261479, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 243, train_loss = 1.8511667028069496, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 244, train_loss = 1.843060682178475, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 245, train_loss = 1.8349456451833248, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 246, train_loss = 1.826880710781552, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 247, train_loss = 1.8190855582943186, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 248, train_loss = 1.8112716898322105, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 249, train_loss = 1.8035881469259039, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 250, train_loss = 1.7958503825357184, train_acc = 0.9972054028877504\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 251, train_loss = 1.788375842035748, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 252, train_loss = 1.7808752618730068, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 253, train_loss = 1.7736127910902724, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 254, train_loss = 1.7662479603895918, train_acc = 0.9973218444340941\n",
      "test Acc 0.9823091247672253:\n",
      "5th- epoch: 255, train_loss = 1.7590254793176427, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 256, train_loss = 1.75183592364192, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 257, train_loss = 1.744890903471969, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 258, train_loss = 1.7377835462102666, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 259, train_loss = 1.7310545766958967, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "5th- epoch: 260, train_loss = 1.724045409471728, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 261, train_loss = 1.7173990346491337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 262, train_loss = 1.7105989133706316, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 263, train_loss = 1.704095020890236, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 264, train_loss = 1.6974103016545996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 265, train_loss = 1.6911023432621732, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 266, train_loss = 1.6845215186476707, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 267, train_loss = 1.6782821578672156, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 268, train_loss = 1.6718871966004372, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 269, train_loss = 1.6657623710343614, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 270, train_loss = 1.659553891629912, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 271, train_loss = 1.6534629948437214, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 272, train_loss = 1.6473697411129251, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 273, train_loss = 1.6415236803004518, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 274, train_loss = 1.6355749579379335, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 275, train_loss = 1.6296822875738144, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 276, train_loss = 1.623832244426012, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 277, train_loss = 1.6182351186871529, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 278, train_loss = 1.612412360846065, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 279, train_loss = 1.6068944210419431, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 280, train_loss = 1.6013219257583842, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 281, train_loss = 1.5956930853426456, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 282, train_loss = 1.5902537914225832, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 283, train_loss = 1.5849170522997156, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 284, train_loss = 1.5795117728412151, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 285, train_loss = 1.5742347637424245, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 286, train_loss = 1.5689308034488931, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 287, train_loss = 1.5636983352014795, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 288, train_loss = 1.5584495775401592, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 289, train_loss = 1.5534083644161, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 290, train_loss = 1.5482518374919891, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 291, train_loss = 1.543149141012691, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 292, train_loss = 1.5382468178868294, train_acc = 0.9975547275267815\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 293, train_loss = 1.533212959766388, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 294, train_loss = 1.5284128350904211, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 295, train_loss = 1.52351688221097, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 296, train_loss = 1.5188027285039425, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 297, train_loss = 1.513896560878493, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 298, train_loss = 1.50937193504069, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 299, train_loss = 1.5047170134494081, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 300, train_loss = 1.4999234800925478, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 301, train_loss = 1.4954861029982567, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 302, train_loss = 1.4908777438104153, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 303, train_loss = 1.48637354868697, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 304, train_loss = 1.4819441810250282, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 305, train_loss = 1.4775424909894355, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 306, train_loss = 1.4731369937653653, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 307, train_loss = 1.4687933872337453, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 308, train_loss = 1.4644855459337123, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 309, train_loss = 1.4602144720847718, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 310, train_loss = 1.4560067914426327, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 311, train_loss = 1.451815877109766, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 312, train_loss = 1.4476353761856444, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 313, train_loss = 1.4435626876656897, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 314, train_loss = 1.4394580858643167, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 315, train_loss = 1.435386920988094, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 316, train_loss = 1.4313799540395848, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 317, train_loss = 1.4274039144511335, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 318, train_loss = 1.4234295040369034, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 319, train_loss = 1.4195257139508612, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 320, train_loss = 1.4155911107663997, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 321, train_loss = 1.4117644776706584, train_acc = 0.9976711690731253\n",
      "test Acc 0.9832402234636871:\n",
      "5th- epoch: 322, train_loss = 1.4079243292217143, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 323, train_loss = 1.404076763719786, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 324, train_loss = 1.4003510822658427, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 325, train_loss = 1.3966116805677302, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 326, train_loss = 1.3928638982470147, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 327, train_loss = 1.3892159822280519, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 328, train_loss = 1.38559165969491, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 329, train_loss = 1.3819045647978783, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 330, train_loss = 1.3783064037561417, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 331, train_loss = 1.3746987245976925, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 332, train_loss = 1.371211105317343, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 333, train_loss = 1.3677056183223613, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 334, train_loss = 1.3642355253105052, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 335, train_loss = 1.3607199527323246, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 336, train_loss = 1.3573849002714269, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 337, train_loss = 1.3539007219369523, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 338, train_loss = 1.3505858145654202, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 339, train_loss = 1.3472311894292943, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 340, train_loss = 1.3438746060128324, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 341, train_loss = 1.3406278503243811, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 342, train_loss = 1.3372995828394778, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 343, train_loss = 1.3340593464672565, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 344, train_loss = 1.3308376583154313, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 345, train_loss = 1.3276243843138218, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 346, train_loss = 1.3244747978751548, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 347, train_loss = 1.3213380972738378, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 348, train_loss = 1.318165474862326, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 349, train_loss = 1.3151183786685579, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 350, train_loss = 1.311987191438675, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 351, train_loss = 1.3089090858702548, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 352, train_loss = 1.3059209038619883, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 353, train_loss = 1.302887186408043, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 354, train_loss = 1.2998511220212094, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 355, train_loss = 1.2968847006559372, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 356, train_loss = 1.2939668645267375, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 357, train_loss = 1.291043233126402, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 358, train_loss = 1.2881056368350983, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 359, train_loss = 1.2852462530136108, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 360, train_loss = 1.2823585495352745, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 361, train_loss = 1.279463890939951, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 362, train_loss = 1.2766215938027017, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 363, train_loss = 1.2738291136920452, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 364, train_loss = 1.2710943768615834, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 365, train_loss = 1.2682621839339845, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 366, train_loss = 1.2655385732650757, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 367, train_loss = 1.2627672925591469, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 368, train_loss = 1.2601025092299096, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 369, train_loss = 1.2574831321835518, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 370, train_loss = 1.2546730426256545, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 371, train_loss = 1.2521103397011757, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 372, train_loss = 1.2494603072409518, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 373, train_loss = 1.2468217313289642, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 374, train_loss = 1.2441981608862989, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 375, train_loss = 1.24171408143593, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 376, train_loss = 1.2390637907083146, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 377, train_loss = 1.2365110305254348, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 378, train_loss = 1.2340132134850137, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 379, train_loss = 1.231450090825092, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 380, train_loss = 1.2289919070899487, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 381, train_loss = 1.2265202105045319, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 382, train_loss = 1.2240103420917876, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 383, train_loss = 1.221593216061592, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 384, train_loss = 1.2191620345111005, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 385, train_loss = 1.2166867827181704, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 386, train_loss = 1.214364831626881, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 387, train_loss = 1.2119296851451509, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 388, train_loss = 1.2095630665426143, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 389, train_loss = 1.2072143778204918, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 390, train_loss = 1.2048851338622626, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 391, train_loss = 1.2025097223522607, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 392, train_loss = 1.2002231292426586, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 393, train_loss = 1.1978777150216047, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 394, train_loss = 1.195687542349333, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 395, train_loss = 1.193385607242817, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 396, train_loss = 1.1911663239297923, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 397, train_loss = 1.1888914344308432, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 398, train_loss = 1.186698891222477, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 399, train_loss = 1.1845298111438751, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 400, train_loss = 1.1822817722859327, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 401, train_loss = 1.1800856875779573, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 402, train_loss = 1.1779711370763835, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 403, train_loss = 1.1757936341164168, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 404, train_loss = 1.1735818684101105, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 405, train_loss = 1.1715030409395695, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 406, train_loss = 1.1694294984044973, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 407, train_loss = 1.167258725821739, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 408, train_loss = 1.1652097838523332, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 409, train_loss = 1.1631508159043733, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 410, train_loss = 1.1611197727324907, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 411, train_loss = 1.1589230386016425, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 412, train_loss = 1.156884061783785, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 413, train_loss = 1.1549363968370017, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 414, train_loss = 1.152844287455082, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 415, train_loss = 1.150889590382576, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 416, train_loss = 1.1488960348069668, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 417, train_loss = 1.146914775163168, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 418, train_loss = 1.1449310556054115, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 419, train_loss = 1.1429666106996592, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 420, train_loss = 1.1410422747430857, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 421, train_loss = 1.1391085398790892, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 422, train_loss = 1.1372700346109923, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 423, train_loss = 1.1351719660160597, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 424, train_loss = 1.1333241251704749, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 425, train_loss = 1.131447535008192, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 426, train_loss = 1.129612147808075, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 427, train_loss = 1.1276874033210333, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 428, train_loss = 1.1258925758302212, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 429, train_loss = 1.1240062130091246, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 430, train_loss = 1.122192415088648, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 431, train_loss = 1.1203602453169879, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 432, train_loss = 1.118504131824011, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 433, train_loss = 1.1167729049921036, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 434, train_loss = 1.1149384255113546, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 435, train_loss = 1.1131863494811114, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 436, train_loss = 1.1112700191733893, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 437, train_loss = 1.109589579195017, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 438, train_loss = 1.1078475192189217, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 439, train_loss = 1.1061036599276122, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 440, train_loss = 1.1043580075202044, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 441, train_loss = 1.1026203632354736, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 442, train_loss = 1.1009154381754342, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 443, train_loss = 1.0992475090024527, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 444, train_loss = 1.0975569151341915, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 445, train_loss = 1.0957875376043376, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 446, train_loss = 1.0941155515611172, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5th- epoch: 447, train_loss = 1.0924959828553256, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 448, train_loss = 1.090817237884039, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 449, train_loss = 1.0890916076896247, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 450, train_loss = 1.0874174634518567, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 451, train_loss = 1.0858696190116461, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 452, train_loss = 1.0842037573456764, train_acc = 0.9979040521658128\n",
      "test Acc 0.984171322160149:\n",
      "5th- epoch: 453, train_loss = 1.082584592193598, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 454, train_loss = 1.0810471810400486, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 455, train_loss = 1.0793864192964975, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 456, train_loss = 1.077828448265791, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 457, train_loss = 1.0762007733283099, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 458, train_loss = 1.0746003724634647, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 459, train_loss = 1.073030311614275, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 460, train_loss = 1.0715566650032997, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 461, train_loss = 1.0699996972980443, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 462, train_loss = 1.0683529004454613, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 463, train_loss = 1.0668012127280235, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 464, train_loss = 1.0653629625739995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 465, train_loss = 1.0637753804621752, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 466, train_loss = 1.0623391047120094, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 467, train_loss = 1.060834219068056, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 468, train_loss = 1.059259720146656, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 469, train_loss = 1.057720072567463, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 470, train_loss = 1.0563236835005227, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 471, train_loss = 1.0548499574360903, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 472, train_loss = 1.0534318139252719, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 473, train_loss = 1.0518044953641947, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 474, train_loss = 1.0503765332105104, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 475, train_loss = 1.0489946864545345, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 476, train_loss = 1.0475774109363556, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 477, train_loss = 1.0460353592934553, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 478, train_loss = 1.0446819563803729, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 479, train_loss = 1.04331498965621, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 480, train_loss = 1.041910501808161, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 481, train_loss = 1.0404750816524029, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 482, train_loss = 1.0390905762615148, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 483, train_loss = 1.0376748852431774, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 484, train_loss = 1.0363104902207851, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 485, train_loss = 1.0348640978336334, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 486, train_loss = 1.0336005948483944, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 487, train_loss = 1.0322432853281498, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 488, train_loss = 1.0307782627642155, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 489, train_loss = 1.0294435198011342, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 490, train_loss = 1.0281477893295232, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 491, train_loss = 1.0267271821794566, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 492, train_loss = 1.0254059682192747, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 493, train_loss = 1.0240771149692591, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 494, train_loss = 1.02267867574119, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 495, train_loss = 1.021434873342514, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 496, train_loss = 1.0201497276721057, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 497, train_loss = 1.0187046925129835, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 498, train_loss = 1.0173785885272082, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "5th- epoch: 499, train_loss = 1.0162047321500722, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|████████████▏                                                            | 5/30 [33:47<2:48:30, 404.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "6th- epoch: 0, train_loss = 270.98560416698456, train_acc = 0.4574988355845366\n",
      "test Acc 0.5595903165735568:\n",
      "6th- epoch: 1, train_loss = 203.3829494714737, train_acc = 0.5625291103865859\n",
      "test Acc 0.5702979515828678:\n",
      "6th- epoch: 2, train_loss = 160.78944951295853, train_acc = 0.5866325104797392\n",
      "test Acc 0.6247672253258846:\n",
      "6th- epoch: 3, train_loss = 136.7337139248848, train_acc = 0.6632510479739171\n",
      "test Acc 0.7113594040968343:\n",
      "6th- epoch: 4, train_loss = 118.74517822265625, train_acc = 0.7304378202142524\n",
      "test Acc 0.7565176908752328:\n",
      "6th- epoch: 5, train_loss = 103.9327083826065, train_acc = 0.7635072193758733\n",
      "test Acc 0.7746741154562383:\n",
      "6th- epoch: 6, train_loss = 91.54173147678375, train_acc = 0.7872612948299953\n",
      "test Acc 0.7956238361266295:\n",
      "6th- epoch: 7, train_loss = 81.34564876556396, train_acc = 0.8014671634839311\n",
      "test Acc 0.8105214152700186:\n",
      "6th- epoch: 8, train_loss = 72.83623391389847, train_acc = 0.8211457848160224\n",
      "test Acc 0.8356610800744879:\n",
      "6th- epoch: 9, train_loss = 65.57700780034065, train_acc = 0.8503726129482999\n",
      "test Acc 0.8556797020484171:\n",
      "6th- epoch: 10, train_loss = 59.31868413090706, train_acc = 0.8744760130414532\n",
      "test Acc 0.883147113594041:\n",
      "6th- epoch: 11, train_loss = 53.89514219760895, train_acc = 0.8964834653004192\n",
      "test Acc 0.9017690875232774:\n",
      "6th- epoch: 12, train_loss = 49.17553794384003, train_acc = 0.91022356776898\n",
      "test Acc 0.9171322160148976:\n",
      "6th- epoch: 13, train_loss = 45.04599767923355, train_acc = 0.922566371681416\n",
      "test Acc 0.9301675977653632:\n",
      "6th- epoch: 14, train_loss = 41.41924238204956, train_acc = 0.933977643223102\n",
      "test Acc 0.936219739292365:\n",
      "6th- epoch: 15, train_loss = 38.227749824523926, train_acc = 0.9378202142524453\n",
      "test Acc 0.9385474860335196:\n",
      "6th- epoch: 16, train_loss = 35.4230522364378, train_acc = 0.9402654867256637\n",
      "test Acc 0.9413407821229051:\n",
      "6th- epoch: 17, train_loss = 32.963616728782654, train_acc = 0.9445738239403819\n",
      "test Acc 0.9450651769087524:\n",
      "6th- epoch: 18, train_loss = 30.813974864780903, train_acc = 0.948067070330694\n",
      "test Acc 0.9483240223463687:\n",
      "6th- epoch: 19, train_loss = 28.934163250029087, train_acc = 0.9501630181648812\n",
      "test Acc 0.952048417132216:\n",
      "6th- epoch: 20, train_loss = 27.284092754125595, train_acc = 0.9529576152771309\n",
      "test Acc 0.9539106145251397:\n",
      "6th- epoch: 21, train_loss = 25.831604570150375, train_acc = 0.9542384722869119\n",
      "test Acc 0.9543761638733705:\n",
      "6th- epoch: 22, train_loss = 24.547448694705963, train_acc = 0.9562179785747554\n",
      "test Acc 0.9557728119180633:\n",
      "6th- epoch: 23, train_loss = 23.4055234529078, train_acc = 0.9578481602235678\n",
      "test Acc 0.9585661080074488:\n",
      "6th- epoch: 24, train_loss = 22.384937796741724, train_acc = 0.9591290172333489\n",
      "test Acc 0.9590316573556797:\n",
      "6th- epoch: 25, train_loss = 21.468132093548775, train_acc = 0.9605263157894737\n",
      "test Acc 0.9585661080074488:\n",
      "6th- epoch: 26, train_loss = 20.63950453698635, train_acc = 0.961690731252911\n",
      "test Acc 0.957635009310987:\n",
      "6th- epoch: 27, train_loss = 19.886217787861824, train_acc = 0.9627387051700047\n",
      "test Acc 0.9581005586592178:\n",
      "6th- epoch: 28, train_loss = 19.19793202728033, train_acc = 0.9646017699115044\n",
      "test Acc 0.9585661080074488:\n",
      "6th- epoch: 29, train_loss = 18.56575347110629, train_acc = 0.9655333022822543\n",
      "test Acc 0.9585661080074488:\n",
      "6th- epoch: 30, train_loss = 17.98155239224434, train_acc = 0.9666977177456917\n",
      "test Acc 0.9590316573556797:\n",
      "6th- epoch: 31, train_loss = 17.439424749463797, train_acc = 0.9678621332091291\n",
      "test Acc 0.9604283054003724:\n",
      "6th- epoch: 32, train_loss = 16.93431708216667, train_acc = 0.9685607824871915\n",
      "test Acc 0.9618249534450651:\n",
      "6th- epoch: 33, train_loss = 16.462383173406124, train_acc = 0.9694923148579413\n",
      "test Acc 0.9636871508379888:\n",
      "6th- epoch: 34, train_loss = 16.019876528531313, train_acc = 0.970540288775035\n",
      "test Acc 0.9655493482309124:\n",
      "6th- epoch: 35, train_loss = 15.603693407028913, train_acc = 0.9713553795994411\n",
      "test Acc 0.9664804469273743:\n",
      "6th- epoch: 36, train_loss = 15.210666116327047, train_acc = 0.9720540288775035\n",
      "test Acc 0.9674115456238361:\n",
      "6th- epoch: 37, train_loss = 14.838544268161058, train_acc = 0.9727526781555659\n",
      "test Acc 0.9678770949720671:\n",
      "6th- epoch: 38, train_loss = 14.485631860792637, train_acc = 0.9739170936190032\n",
      "test Acc 0.9688081936685289:\n",
      "6th- epoch: 39, train_loss = 14.151107225567102, train_acc = 0.974033535165347\n",
      "test Acc 0.9697392923649907:\n",
      "6th- epoch: 40, train_loss = 13.83350881934166, train_acc = 0.9743828598043782\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 41, train_loss = 13.531373053789139, train_acc = 0.9747321844434094\n",
      "test Acc 0.9706703910614525:\n",
      "6th- epoch: 42, train_loss = 13.244160939007998, train_acc = 0.9751979506287843\n",
      "test Acc 0.9716014897579144:\n",
      "6th- epoch: 43, train_loss = 12.970630194991827, train_acc = 0.9756637168141593\n",
      "test Acc 0.9720670391061452:\n",
      "6th- epoch: 44, train_loss = 12.709396064281464, train_acc = 0.976245924545878\n",
      "test Acc 0.9725325884543762:\n",
      "6th- epoch: 45, train_loss = 12.459232456982136, train_acc = 0.9772938984629715\n",
      "test Acc 0.972998137802607:\n",
      "6th- epoch: 46, train_loss = 12.21948992088437, train_acc = 0.9781089892873778\n",
      "test Acc 0.9739292364990689:\n",
      "6th- epoch: 47, train_loss = 11.989450082182884, train_acc = 0.9785747554727526\n",
      "test Acc 0.9743947858472998:\n",
      "6th- epoch: 48, train_loss = 11.768510613590479, train_acc = 0.97973917093619\n",
      "test Acc 0.9748603351955307:\n",
      "6th- epoch: 49, train_loss = 11.556052278727293, train_acc = 0.9799720540288775\n",
      "test Acc 0.9753258845437617:\n",
      "6th- epoch: 50, train_loss = 11.351366806775331, train_acc = 0.9803213786679087\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 51, train_loss = 11.154209703207016, train_acc = 0.9807871448532837\n",
      "test Acc 0.9757914338919925:\n",
      "6th- epoch: 52, train_loss = 10.964143075048923, train_acc = 0.9812529110386586\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 53, train_loss = 10.78050073236227, train_acc = 0.9814857941313461\n",
      "test Acc 0.9762569832402235:\n",
      "6th- epoch: 54, train_loss = 10.60305504873395, train_acc = 0.9817186772240335\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 55, train_loss = 10.431290544569492, train_acc = 0.9818351187703773\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 56, train_loss = 10.264767874032259, train_acc = 0.9817186772240335\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 57, train_loss = 10.103075716644526, train_acc = 0.9818351187703773\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 58, train_loss = 9.945790834724903, train_acc = 0.9818351187703773\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 59, train_loss = 9.792785601690412, train_acc = 0.9818351187703773\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 60, train_loss = 9.643397387117147, train_acc = 0.9818351187703773\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 61, train_loss = 9.497687630355358, train_acc = 0.9821844434094085\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 62, train_loss = 9.355501536279917, train_acc = 0.9824173265020959\n",
      "test Acc 0.9767225325884544:\n",
      "6th- epoch: 63, train_loss = 9.216964773833752, train_acc = 0.9828830926874709\n",
      "test Acc 0.9771880819366853:\n",
      "6th- epoch: 64, train_loss = 9.08173062466085, train_acc = 0.9831159757801584\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 65, train_loss = 8.949801944196224, train_acc = 0.9832324173265021\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 66, train_loss = 8.820906108245254, train_acc = 0.9831159757801584\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 67, train_loss = 8.695002799853683, train_acc = 0.9829995342338146\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 68, train_loss = 8.571954255923629, train_acc = 0.9834653004191896\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 69, train_loss = 8.451664419844747, train_acc = 0.9834653004191896\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 70, train_loss = 8.334159288555384, train_acc = 0.983698183511877\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 71, train_loss = 8.21923241391778, train_acc = 0.9838146250582208\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 72, train_loss = 8.106843743473291, train_acc = 0.9839310666045645\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 73, train_loss = 7.996841434389353, train_acc = 0.984163949697252\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 74, train_loss = 7.889194257557392, train_acc = 0.9842803912435957\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 75, train_loss = 7.783617464825511, train_acc = 0.9846297158826269\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 76, train_loss = 7.679964013397694, train_acc = 0.9848625989753144\n",
      "test Acc 0.9776536312849162:\n",
      "6th- epoch: 77, train_loss = 7.578255692496896, train_acc = 0.9849790405216581\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 78, train_loss = 7.478360995650291, train_acc = 0.9849790405216581\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 79, train_loss = 7.380372507497668, train_acc = 0.9849790405216581\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 80, train_loss = 7.28414043597877, train_acc = 0.9852119236143456\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 81, train_loss = 7.189469218254089, train_acc = 0.9853283651606893\n",
      "test Acc 0.9781191806331471:\n",
      "6th- epoch: 82, train_loss = 7.096604974940419, train_acc = 0.985444806707033\n",
      "test Acc 0.978584729981378:\n",
      "6th- epoch: 83, train_loss = 7.0052735190838575, train_acc = 0.9855612482533768\n",
      "test Acc 0.979050279329609:\n",
      "6th- epoch: 84, train_loss = 6.9156390484422445, train_acc = 0.9856776897997206\n",
      "test Acc 0.979050279329609:\n",
      "6th- epoch: 85, train_loss = 6.827602488920093, train_acc = 0.985910572892408\n",
      "test Acc 0.979050279329609:\n",
      "6th- epoch: 86, train_loss = 6.741239650174975, train_acc = 0.9862598975314392\n",
      "test Acc 0.979050279329609:\n",
      "6th- epoch: 87, train_loss = 6.6564584989100695, train_acc = 0.9866092221704704\n",
      "test Acc 0.979050279329609:\n",
      "6th- epoch: 88, train_loss = 6.57314214296639, train_acc = 0.9866092221704704\n",
      "test Acc 0.979050279329609:\n",
      "6th- epoch: 89, train_loss = 6.491285365074873, train_acc = 0.9868421052631579\n",
      "test Acc 0.979050279329609:\n",
      "6th- epoch: 90, train_loss = 6.410729160532355, train_acc = 0.9868421052631579\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 91, train_loss = 6.331573933362961, train_acc = 0.9870749883558454\n",
      "test Acc 0.9804469273743017:\n",
      "6th- epoch: 92, train_loss = 6.253838965669274, train_acc = 0.9870749883558454\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 93, train_loss = 6.177384078502655, train_acc = 0.9873078714485328\n",
      "test Acc 0.9809124767225326:\n",
      "6th- epoch: 94, train_loss = 6.102331222966313, train_acc = 0.9875407545412203\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 95, train_loss = 6.028767144307494, train_acc = 0.9877736376339078\n",
      "test Acc 0.9818435754189944:\n",
      "6th- epoch: 96, train_loss = 5.95654571428895, train_acc = 0.9878900791802515\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 97, train_loss = 5.885499577969313, train_acc = 0.9881229622729389\n",
      "test Acc 0.9823091247672253:\n",
      "6th- epoch: 98, train_loss = 5.815704088658094, train_acc = 0.9882394038192828\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 99, train_loss = 5.7472203355282545, train_acc = 0.9882394038192828\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 100, train_loss = 5.679724650457501, train_acc = 0.9885887284583139\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 101, train_loss = 5.61344126611948, train_acc = 0.9887051700046576\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 102, train_loss = 5.5483755972236395, train_acc = 0.9889380530973452\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 103, train_loss = 5.484395112842321, train_acc = 0.9890544946436889\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 104, train_loss = 5.421583779156208, train_acc = 0.98940381928272\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 105, train_loss = 5.359984580427408, train_acc = 0.98940381928272\n",
      "test Acc 0.9827746741154563:\n",
      "6th- epoch: 106, train_loss = 5.2994947694242, train_acc = 0.9895202608290639\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 107, train_loss = 5.240045731887221, train_acc = 0.9895202608290639\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 108, train_loss = 5.18159762211144, train_acc = 0.989869585468095\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 109, train_loss = 5.124108772724867, train_acc = 0.989869585468095\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 110, train_loss = 5.067653840407729, train_acc = 0.990801117838845\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 111, train_loss = 5.012150736525655, train_acc = 0.9910340009315324\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 112, train_loss = 4.95766543596983, train_acc = 0.9909175593851887\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 113, train_loss = 4.904151008464396, train_acc = 0.9912668840242198\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 114, train_loss = 4.85167371481657, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 115, train_loss = 4.800096093676984, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 116, train_loss = 4.7493298994377255, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 117, train_loss = 4.699453159235418, train_acc = 0.9916162086632511\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 118, train_loss = 4.65041587408632, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 119, train_loss = 4.602262980304658, train_acc = 0.9918490917559385\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 120, train_loss = 4.554839222691953, train_acc = 0.992081974848626\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 121, train_loss = 4.508194926194847, train_acc = 0.992081974848626\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 122, train_loss = 4.462424053810537, train_acc = 0.9924312994876572\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 123, train_loss = 4.417291219346225, train_acc = 0.9924312994876572\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 124, train_loss = 4.3729793494567275, train_acc = 0.9924312994876572\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 125, train_loss = 4.329391296952963, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 126, train_loss = 4.286534768529236, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 127, train_loss = 4.244379046373069, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 128, train_loss = 4.20276755746454, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 129, train_loss = 4.16194986179471, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 130, train_loss = 4.1218387968838215, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 131, train_loss = 4.082425677217543, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 132, train_loss = 4.043613881804049, train_acc = 0.9927806241266884\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 133, train_loss = 4.005437825806439, train_acc = 0.9927806241266884\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 134, train_loss = 3.967821498401463, train_acc = 0.9927806241266884\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 135, train_loss = 3.9307764461264014, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 136, train_loss = 3.89434115588665, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 137, train_loss = 3.8583769472315907, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 138, train_loss = 3.8230288196355104, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 139, train_loss = 3.7882319083437324, train_acc = 0.9934792734047508\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 140, train_loss = 3.7539363531395793, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 141, train_loss = 3.7201315090060234, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 142, train_loss = 3.6868284018710256, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 143, train_loss = 3.654032035730779, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 144, train_loss = 3.621727582067251, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 145, train_loss = 3.589953977614641, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 146, train_loss = 3.5584553508087993, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 147, train_loss = 3.5275050466880202, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 148, train_loss = 3.496952527668327, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 149, train_loss = 3.4668569923378527, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 150, train_loss = 3.437319533433765, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 151, train_loss = 3.4080908317118883, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 152, train_loss = 3.3792876270599663, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 153, train_loss = 3.35095500620082, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 154, train_loss = 3.3228816599585116, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 155, train_loss = 3.2953701219521463, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 156, train_loss = 3.2681540977209806, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 157, train_loss = 3.2413533967919648, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 158, train_loss = 3.214896621648222, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 159, train_loss = 3.18879660917446, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 160, train_loss = 3.1630564350634813, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 161, train_loss = 3.137718483339995, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 162, train_loss = 3.1126724276691675, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 163, train_loss = 3.088026848156005, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 164, train_loss = 3.0636872588656843, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 165, train_loss = 3.039755303878337, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 166, train_loss = 3.0161067773588, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 167, train_loss = 2.9928213371895254, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 168, train_loss = 2.9698321945033967, train_acc = 0.9952258965999069\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 169, train_loss = 2.9471696759574115, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 170, train_loss = 2.924801966175437, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 171, train_loss = 2.9026942141354084, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 172, train_loss = 2.880958443041891, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 173, train_loss = 2.8594927028752863, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 174, train_loss = 2.83825900638476, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 175, train_loss = 2.8174449768848717, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 176, train_loss = 2.796812196727842, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 177, train_loss = 2.776513817254454, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 178, train_loss = 2.756449953187257, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 179, train_loss = 2.7367586349137127, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 180, train_loss = 2.7172201848588884, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 181, train_loss = 2.697923839557916, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 182, train_loss = 2.6790090650320053, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 183, train_loss = 2.6602534358389676, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 184, train_loss = 2.641759077552706, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 185, train_loss = 2.6235492024570704, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 186, train_loss = 2.605586980935186, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 187, train_loss = 2.587766158860177, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 188, train_loss = 2.5701759532094, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 189, train_loss = 2.552870709914714, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 190, train_loss = 2.5358161237090826, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 191, train_loss = 2.518975565675646, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 192, train_loss = 2.502325586974621, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 193, train_loss = 2.4860259343404323, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 194, train_loss = 2.4698352415580302, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 195, train_loss = 2.4539236314594746, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 196, train_loss = 2.4382111586164683, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 197, train_loss = 2.422705179080367, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 198, train_loss = 2.4073979426175356, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 199, train_loss = 2.3923881866503507, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 200, train_loss = 2.3773476276546717, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 201, train_loss = 2.3627988777589053, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 202, train_loss = 2.348190496908501, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 203, train_loss = 2.3339084319304675, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 204, train_loss = 2.3197620778810233, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 205, train_loss = 2.305865153670311, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "6th- epoch: 206, train_loss = 2.2920752342324704, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "6th- epoch: 207, train_loss = 2.2785525743383914, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 208, train_loss = 2.26504932413809, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 209, train_loss = 2.2519040170591325, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 210, train_loss = 2.2387954730074853, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 211, train_loss = 2.2259326812345535, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 212, train_loss = 2.213248907821253, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 213, train_loss = 2.2005485992413014, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 214, train_loss = 2.1882532984018326, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 215, train_loss = 2.1760685965418816, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 216, train_loss = 2.1640194964129478, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 217, train_loss = 2.1521852996665984, train_acc = 0.9962738705170004\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 218, train_loss = 2.1404028609395027, train_acc = 0.9962738705170004\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 219, train_loss = 2.1288492686580867, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 220, train_loss = 2.117430320708081, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 221, train_loss = 2.1061449504923075, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 222, train_loss = 2.095010232180357, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 223, train_loss = 2.084030219120905, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 224, train_loss = 2.073237132979557, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 225, train_loss = 2.0624210305977613, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 226, train_loss = 2.051879543811083, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 227, train_loss = 2.041418106527999, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 228, train_loss = 2.031188217923045, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 229, train_loss = 2.0209473855793476, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 230, train_loss = 2.01094570197165, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 231, train_loss = 2.0009274010080844, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 232, train_loss = 1.9912012189161032, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 233, train_loss = 1.981512314407155, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 234, train_loss = 1.971898455871269, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 235, train_loss = 1.9624875113368034, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 236, train_loss = 1.953166336985305, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 237, train_loss = 1.9439142129849643, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 238, train_loss = 1.9348217986989766, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 239, train_loss = 1.9257944028358907, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 240, train_loss = 1.9169178288429976, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 241, train_loss = 1.908085610717535, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 242, train_loss = 1.8994742706418037, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 243, train_loss = 1.8908489949535578, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "6th- epoch: 244, train_loss = 1.882341182557866, train_acc = 0.9970889613414066\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 245, train_loss = 1.8738917123991996, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 246, train_loss = 1.865703503252007, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 247, train_loss = 1.8574044728884473, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 248, train_loss = 1.8493051218101755, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 249, train_loss = 1.8413383538136259, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 250, train_loss = 1.8333901105215773, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 251, train_loss = 1.8254855386912823, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "6th- epoch: 252, train_loss = 1.8177340850234032, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 253, train_loss = 1.8101514714071527, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 254, train_loss = 1.8025149194290861, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 255, train_loss = 1.795024435967207, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 256, train_loss = 1.7875608267495409, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 257, train_loss = 1.7802830636501312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 258, train_loss = 1.7729472406208515, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 259, train_loss = 1.7658046731958166, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 260, train_loss = 1.7587242698064074, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 261, train_loss = 1.7516871193656698, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 262, train_loss = 1.7447562081506476, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 263, train_loss = 1.7378330441424623, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 264, train_loss = 1.7309586256742477, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 265, train_loss = 1.724322029738687, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 266, train_loss = 1.7175883738091215, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 267, train_loss = 1.7109643804142252, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 268, train_loss = 1.7044339999556541, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 269, train_loss = 1.6979811961064115, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 270, train_loss = 1.69155026844237, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 271, train_loss = 1.6851473090937361, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 272, train_loss = 1.6789504922926426, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 273, train_loss = 1.6727588549256325, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 274, train_loss = 1.6665723994374275, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 275, train_loss = 1.660444788634777, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 276, train_loss = 1.6544518185546622, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 277, train_loss = 1.648495115339756, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 278, train_loss = 1.6425802832236513, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 279, train_loss = 1.6367144100368023, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 280, train_loss = 1.6309615509817377, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 281, train_loss = 1.6252399807563052, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 282, train_loss = 1.619420152157545, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 283, train_loss = 1.613816918223165, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 284, train_loss = 1.6081434674561024, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 285, train_loss = 1.6026620405027643, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 286, train_loss = 1.5970804765820503, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 287, train_loss = 1.5917865745723248, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 288, train_loss = 1.5863266153028235, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 289, train_loss = 1.5810243698069826, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 290, train_loss = 1.575750662595965, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 291, train_loss = 1.5705522099742666, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 292, train_loss = 1.5653404569020495, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 293, train_loss = 1.560156395076774, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 294, train_loss = 1.5549667602172121, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 295, train_loss = 1.5500184980919585, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 296, train_loss = 1.5449881678214297, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 297, train_loss = 1.539974968880415, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 298, train_loss = 1.5351325733354315, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 299, train_loss = 1.5301877669990063, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 300, train_loss = 1.525338988751173, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 301, train_loss = 1.5206398392328992, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 302, train_loss = 1.5158573178341612, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 303, train_loss = 1.511114951223135, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 304, train_loss = 1.5064682016381994, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 305, train_loss = 1.5018210373818874, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 306, train_loss = 1.4972782818367705, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 307, train_loss = 1.492718314169906, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 308, train_loss = 1.488162818015553, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 309, train_loss = 1.4838203092804179, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 310, train_loss = 1.4793754568090662, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 311, train_loss = 1.4749574176967144, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 312, train_loss = 1.4706392996013165, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 313, train_loss = 1.4663680928642862, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 314, train_loss = 1.4621489395503886, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 315, train_loss = 1.4578144525294192, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 316, train_loss = 1.453642523556482, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 317, train_loss = 1.44955825060606, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 318, train_loss = 1.44538939621998, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 319, train_loss = 1.441292506933678, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 320, train_loss = 1.4372190398280509, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 321, train_loss = 1.4332981507177465, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 322, train_loss = 1.429280374199152, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 323, train_loss = 1.4252777608926408, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 324, train_loss = 1.4213753628428094, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 325, train_loss = 1.4174885501270182, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 326, train_loss = 1.4135581416194327, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 327, train_loss = 1.4098928645253181, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 328, train_loss = 1.406027290970087, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 329, train_loss = 1.402252362400759, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 330, train_loss = 1.398440383374691, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 331, train_loss = 1.394826629490126, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 332, train_loss = 1.391104615002405, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 333, train_loss = 1.3874705049092881, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 334, train_loss = 1.3838926143944263, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 335, train_loss = 1.3801911224727519, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 336, train_loss = 1.376741009473335, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 337, train_loss = 1.3731079983408563, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 338, train_loss = 1.3696579349343665, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 339, train_loss = 1.3662074369494803, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 340, train_loss = 1.362683357030619, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 341, train_loss = 1.3593836936051957, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 342, train_loss = 1.355951880395878, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 343, train_loss = 1.352575107186567, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 344, train_loss = 1.349150389432907, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 345, train_loss = 1.3459117871825583, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 346, train_loss = 1.3426769251818769, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 347, train_loss = 1.3393463504617102, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 348, train_loss = 1.3360384752159007, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 349, train_loss = 1.3329704739153385, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 350, train_loss = 1.3297156505286694, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 351, train_loss = 1.326541541784536, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 352, train_loss = 1.3233015934820287, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 353, train_loss = 1.3203167878091335, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 354, train_loss = 1.3171660266816616, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 355, train_loss = 1.3141493673319928, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 356, train_loss = 1.3110363694722764, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 357, train_loss = 1.3079758435487747, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 358, train_loss = 1.3049775424296968, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 359, train_loss = 1.3020421639084816, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 360, train_loss = 1.2989593409001827, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 361, train_loss = 1.2961234686081298, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 362, train_loss = 1.2931624402408488, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 363, train_loss = 1.2901539069716819, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 364, train_loss = 1.2872765623033047, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 365, train_loss = 1.284453272819519, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 366, train_loss = 1.2816670648753643, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 367, train_loss = 1.278785489499569, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 368, train_loss = 1.275887280702591, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 369, train_loss = 1.273263193666935, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 370, train_loss = 1.270452989905607, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 371, train_loss = 1.2676658295094967, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 372, train_loss = 1.2649047312443145, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 373, train_loss = 1.2622596062719822, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 374, train_loss = 1.2596181966364384, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 375, train_loss = 1.2568778097629547, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 376, train_loss = 1.2542603189940564, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 377, train_loss = 1.2515895428950898, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 378, train_loss = 1.2489888283307664, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 379, train_loss = 1.2462923005223274, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 380, train_loss = 1.2438151712412946, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 381, train_loss = 1.2412423565983772, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 382, train_loss = 1.23865857970668, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 383, train_loss = 1.2360724819009192, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 384, train_loss = 1.2336450691218488, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 385, train_loss = 1.2310527848894708, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 386, train_loss = 1.2286759528215043, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 387, train_loss = 1.226185418665409, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 388, train_loss = 1.223728358745575, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 389, train_loss = 1.2212110820109956, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 390, train_loss = 1.2189176169340499, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 391, train_loss = 1.2164311607484706, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 392, train_loss = 1.214112697809469, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 393, train_loss = 1.2116426974534988, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 394, train_loss = 1.209387204318773, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 395, train_loss = 1.207059244334232, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 396, train_loss = 1.204637375951279, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 397, train_loss = 1.202314502268564, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 398, train_loss = 1.199973692477215, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 399, train_loss = 1.197779691487085, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 400, train_loss = 1.1954670597915538, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 401, train_loss = 1.1932238091831096, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 402, train_loss = 1.1908684447407722, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 403, train_loss = 1.1887754388153553, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "6th- epoch: 404, train_loss = 1.1864283780159894, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 405, train_loss = 1.1843109888432082, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 406, train_loss = 1.1820313396456186, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 407, train_loss = 1.179943105817074, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 408, train_loss = 1.1776862951519433, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 409, train_loss = 1.1755907548067626, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 410, train_loss = 1.1733474458160345, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 411, train_loss = 1.1712942433950957, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 412, train_loss = 1.1691089856030885, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 413, train_loss = 1.1670966558158398, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 414, train_loss = 1.164880108088255, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 415, train_loss = 1.1629305109381676, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 416, train_loss = 1.1607472399773542, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 417, train_loss = 1.1588294195535127, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 418, train_loss = 1.1567544440331403, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 419, train_loss = 1.1546350034477655, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 420, train_loss = 1.1527508372964803, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 421, train_loss = 1.1507215723395348, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 422, train_loss = 1.14866229519248, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 423, train_loss = 1.1468170396983624, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 424, train_loss = 1.144769549369812, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 425, train_loss = 1.1427910799684469, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 426, train_loss = 1.1409207880496979, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 427, train_loss = 1.13895265510655, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 428, train_loss = 1.1369735548796598, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 429, train_loss = 1.1352074034512043, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 430, train_loss = 1.1332930537464563, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 431, train_loss = 1.1312948490085546, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 432, train_loss = 1.1294905220565852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 433, train_loss = 1.1276756016013678, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 434, train_loss = 1.1256662557425443, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 435, train_loss = 1.1240027410385665, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 436, train_loss = 1.1221108672616538, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 437, train_loss = 1.1202855966985226, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 438, train_loss = 1.1184690756199416, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 439, train_loss = 1.1166714007558767, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 440, train_loss = 1.1148040952684823, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 441, train_loss = 1.1131877290608827, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 442, train_loss = 1.1113213697972242, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 443, train_loss = 1.109571990877157, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 444, train_loss = 1.1078573639097158, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 445, train_loss = 1.1060912261309568, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6th- epoch: 446, train_loss = 1.1042612666788045, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 447, train_loss = 1.102721684932476, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 448, train_loss = 1.100958521157736, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 449, train_loss = 1.0992007715103682, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 450, train_loss = 1.0975629141030367, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 451, train_loss = 1.0958765807154123, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 452, train_loss = 1.0940231146814767, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 453, train_loss = 1.0925585950317327, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 454, train_loss = 1.0909250987169798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 455, train_loss = 1.089216719061369, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 456, train_loss = 1.087553227931494, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 457, train_loss = 1.0859149234893266, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 458, train_loss = 1.0842490593495313, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 459, train_loss = 1.0827256528136786, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 460, train_loss = 1.0811159064469393, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 461, train_loss = 1.0794182320532855, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 462, train_loss = 1.0780093160865363, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 463, train_loss = 1.0763273822667543, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 464, train_loss = 1.0747264524397906, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 465, train_loss = 1.0732100804743823, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 466, train_loss = 1.071611958235735, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 467, train_loss = 1.069990012794733, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 468, train_loss = 1.0685876458883286, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 469, train_loss = 1.0670450677571353, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 470, train_loss = 1.0654678232967854, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 471, train_loss = 1.063973435520893, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 472, train_loss = 1.0624591087398585, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 473, train_loss = 1.0608426605758723, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 474, train_loss = 1.0594934386608656, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 475, train_loss = 1.0579688871803228, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 476, train_loss = 1.0563958076236304, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 477, train_loss = 1.0550663471221924, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 478, train_loss = 1.0535721232590731, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 479, train_loss = 1.0520567881467286, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 480, train_loss = 1.0506407767534256, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 481, train_loss = 1.0491542629897594, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 482, train_loss = 1.0476125106215477, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 483, train_loss = 1.0463671448233072, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 484, train_loss = 1.0449239847657736, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 485, train_loss = 1.0434516357781831, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 486, train_loss = 1.0421037313935813, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 487, train_loss = 1.0406498685479164, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 488, train_loss = 1.0391532865760382, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 489, train_loss = 1.037909708917141, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 490, train_loss = 1.0365001522004604, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 491, train_loss = 1.0351092244090978, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 492, train_loss = 1.0336091679928359, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 493, train_loss = 1.0324128096399363, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 494, train_loss = 1.0309857055544853, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 495, train_loss = 1.0295456908643246, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 496, train_loss = 1.0283492033777293, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 497, train_loss = 1.0270337747933809, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 498, train_loss = 1.0256152860820293, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "6th- epoch: 499, train_loss = 1.024271421134472, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██████████████▌                                                          | 6/30 [40:36<2:42:25, 406.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "7th- epoch: 0, train_loss = 269.93716049194336, train_acc = 0.45971122496506756\n",
      "test Acc 0.49162011173184356:\n",
      "7th- epoch: 1, train_loss = 203.13966834545135, train_acc = 0.49394503959012576\n",
      "test Acc 0.49394785847299816:\n",
      "7th- epoch: 2, train_loss = 158.85321080684662, train_acc = 0.5768514205868654\n",
      "test Acc 0.6499068901303539:\n",
      "7th- epoch: 3, train_loss = 134.012016415596, train_acc = 0.6818816953889147\n",
      "test Acc 0.7253258845437617:\n",
      "7th- epoch: 4, train_loss = 115.21793282032013, train_acc = 0.7380065207265952\n",
      "test Acc 0.7537243947858473:\n",
      "7th- epoch: 5, train_loss = 99.99882858991623, train_acc = 0.7598975314392176\n",
      "test Acc 0.7732774674115456:\n",
      "7th- epoch: 6, train_loss = 87.5916111767292, train_acc = 0.7848160223567769\n",
      "test Acc 0.8007448789571695:\n",
      "7th- epoch: 7, train_loss = 77.46150431036949, train_acc = 0.8180018630647415\n",
      "test Acc 0.8337988826815642:\n",
      "7th- epoch: 8, train_loss = 68.97168704867363, train_acc = 0.8506054960409875\n",
      "test Acc 0.8603351955307262:\n",
      "7th- epoch: 9, train_loss = 61.73593494296074, train_acc = 0.8805309734513275\n",
      "test Acc 0.8878026070763501:\n",
      "7th- epoch: 10, train_loss = 55.54248288273811, train_acc = 0.8986958546809501\n",
      "test Acc 0.904562383612663:\n",
      "7th- epoch: 11, train_loss = 50.223585680127144, train_acc = 0.9109222170470423\n",
      "test Acc 0.9180633147113594:\n",
      "7th- epoch: 12, train_loss = 45.63353927433491, train_acc = 0.9258267349790406\n",
      "test Acc 0.9324953445065177:\n",
      "7th- epoch: 13, train_loss = 41.66131477057934, train_acc = 0.9338612016767582\n",
      "test Acc 0.9371508379888268:\n",
      "7th- epoch: 14, train_loss = 38.21655485033989, train_acc = 0.9394503959012576\n",
      "test Acc 0.9394785847299814:\n",
      "7th- epoch: 15, train_loss = 35.23077930510044, train_acc = 0.9413134606427573\n",
      "test Acc 0.9455307262569832:\n",
      "7th- epoch: 16, train_loss = 32.645611234009266, train_acc = 0.9437587331159758\n",
      "test Acc 0.946927374301676:\n",
      "7th- epoch: 17, train_loss = 30.4073368832469, train_acc = 0.9462040055891943\n",
      "test Acc 0.9483240223463687:\n",
      "7th- epoch: 18, train_loss = 28.466979049146175, train_acc = 0.9519096413600373\n",
      "test Acc 0.9543761638733705:\n",
      "7th- epoch: 19, train_loss = 26.78056240826845, train_acc = 0.9547042384722869\n",
      "test Acc 0.9557728119180633:\n",
      "7th- epoch: 20, train_loss = 25.313013404607773, train_acc = 0.9565673032137867\n",
      "test Acc 0.9557728119180633:\n",
      "7th- epoch: 21, train_loss = 24.03034768998623, train_acc = 0.9587796925943176\n",
      "test Acc 0.9562383612662942:\n",
      "7th- epoch: 22, train_loss = 22.899815276265144, train_acc = 0.9605263157894737\n",
      "test Acc 0.957169459962756:\n",
      "7th- epoch: 23, train_loss = 21.897254217416048, train_acc = 0.9618071727992548\n",
      "test Acc 0.957635009310987:\n",
      "7th- epoch: 24, train_loss = 21.000736970454454, train_acc = 0.9623893805309734\n",
      "test Acc 0.9585661080074488:\n",
      "7th- epoch: 25, train_loss = 20.193507954478264, train_acc = 0.9635537959944108\n",
      "test Acc 0.9585661080074488:\n",
      "7th- epoch: 26, train_loss = 19.461542174220085, train_acc = 0.9644853283651607\n",
      "test Acc 0.9594972067039106:\n",
      "7th- epoch: 27, train_loss = 18.7933341935277, train_acc = 0.9653004191895669\n",
      "test Acc 0.9604283054003724:\n",
      "7th- epoch: 28, train_loss = 18.17977264150977, train_acc = 0.9659990684676293\n",
      "test Acc 0.9599627560521415:\n",
      "7th- epoch: 29, train_loss = 17.613655764609575, train_acc = 0.9664648346530041\n",
      "test Acc 0.9599627560521415:\n",
      "7th- epoch: 30, train_loss = 17.087730031460524, train_acc = 0.9678621332091291\n",
      "test Acc 0.9604283054003724:\n",
      "7th- epoch: 31, train_loss = 16.597328271716833, train_acc = 0.9692594317652539\n",
      "test Acc 0.9618249534450651:\n",
      "7th- epoch: 32, train_loss = 16.13859385251999, train_acc = 0.9699580810433163\n",
      "test Acc 0.9632216014897579:\n",
      "7th- epoch: 33, train_loss = 15.707978192716837, train_acc = 0.9713553795994411\n",
      "test Acc 0.9646182495344506:\n",
      "7th- epoch: 34, train_loss = 15.302835542708635, train_acc = 0.9719375873311598\n",
      "test Acc 0.9660148975791434:\n",
      "7th- epoch: 35, train_loss = 14.920481726527214, train_acc = 0.9726362366092222\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 36, train_loss = 14.558142077177763, train_acc = 0.9732184443409408\n",
      "test Acc 0.9664804469273743:\n",
      "7th- epoch: 37, train_loss = 14.214913096278906, train_acc = 0.9736842105263158\n",
      "test Acc 0.9683426443202979:\n",
      "7th- epoch: 38, train_loss = 13.889020185917616, train_acc = 0.9743828598043782\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 39, train_loss = 13.579000357538462, train_acc = 0.9749650675360969\n",
      "test Acc 0.9706703910614525:\n",
      "7th- epoch: 40, train_loss = 13.28331297263503, train_acc = 0.975314392175128\n",
      "test Acc 0.9716014897579144:\n",
      "7th- epoch: 41, train_loss = 13.001418519765139, train_acc = 0.9756637168141593\n",
      "test Acc 0.9725325884543762:\n",
      "7th- epoch: 42, train_loss = 12.73233912140131, train_acc = 0.9758965999068467\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 43, train_loss = 12.474781055003405, train_acc = 0.9763623660922217\n",
      "test Acc 0.973463687150838:\n",
      "7th- epoch: 44, train_loss = 12.228073850274086, train_acc = 0.9770610153702841\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 45, train_loss = 11.991419177502394, train_acc = 0.977992547741034\n",
      "test Acc 0.9739292364990689:\n",
      "7th- epoch: 46, train_loss = 11.764114424586296, train_acc = 0.9788076385654402\n",
      "test Acc 0.9743947858472998:\n",
      "7th- epoch: 47, train_loss = 11.5453010648489, train_acc = 0.9791569632044713\n",
      "test Acc 0.9748603351955307:\n",
      "7th- epoch: 48, train_loss = 11.334519889205694, train_acc = 0.9796227293898463\n",
      "test Acc 0.9753258845437617:\n",
      "7th- epoch: 49, train_loss = 11.131219256669283, train_acc = 0.97973917093619\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 50, train_loss = 10.934688463807106, train_acc = 0.9800884955752213\n",
      "test Acc 0.9762569832402235:\n",
      "7th- epoch: 51, train_loss = 10.74474573880434, train_acc = 0.980204937121565\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 52, train_loss = 10.561046659946442, train_acc = 0.98067070330694\n",
      "test Acc 0.9767225325884544:\n",
      "7th- epoch: 53, train_loss = 10.383018532767892, train_acc = 0.9809035863996274\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 54, train_loss = 10.21058846078813, train_acc = 0.9811364694923148\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 55, train_loss = 10.043212290853262, train_acc = 0.981951560316721\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 56, train_loss = 9.880678340792656, train_acc = 0.9820680018630648\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 57, train_loss = 9.722567277029157, train_acc = 0.9825337680484397\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 58, train_loss = 9.568827839568257, train_acc = 0.9827666511411272\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 59, train_loss = 9.419094912707806, train_acc = 0.9831159757801584\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 60, train_loss = 9.273219749331474, train_acc = 0.9831159757801584\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 61, train_loss = 9.131085485219955, train_acc = 0.9831159757801584\n",
      "test Acc 0.9771880819366853:\n",
      "7th- epoch: 62, train_loss = 8.992428850382566, train_acc = 0.9831159757801584\n",
      "test Acc 0.9776536312849162:\n",
      "7th- epoch: 63, train_loss = 8.857202231884003, train_acc = 0.9831159757801584\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 64, train_loss = 8.725171443074942, train_acc = 0.9831159757801584\n",
      "test Acc 0.9781191806331471:\n",
      "7th- epoch: 65, train_loss = 8.596124976873398, train_acc = 0.9834653004191896\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 66, train_loss = 8.470071889460087, train_acc = 0.983698183511877\n",
      "test Acc 0.978584729981378:\n",
      "7th- epoch: 67, train_loss = 8.346889590844512, train_acc = 0.9840475081509082\n",
      "test Acc 0.979050279329609:\n",
      "7th- epoch: 68, train_loss = 8.226540936157107, train_acc = 0.9842803912435957\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 69, train_loss = 8.108587220311165, train_acc = 0.9842803912435957\n",
      "test Acc 0.9795158286778398:\n",
      "7th- epoch: 70, train_loss = 7.9931621588766575, train_acc = 0.9845132743362832\n",
      "test Acc 0.9799813780260708:\n",
      "7th- epoch: 71, train_loss = 7.880126405507326, train_acc = 0.9845132743362832\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 72, train_loss = 7.7695818319916725, train_acc = 0.9849790405216581\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 73, train_loss = 7.661269370466471, train_acc = 0.985444806707033\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 74, train_loss = 7.555154237896204, train_acc = 0.9856776897997206\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 75, train_loss = 7.451260028406978, train_acc = 0.9856776897997206\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 76, train_loss = 7.3495465237647295, train_acc = 0.9856776897997206\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 77, train_loss = 7.249827506020665, train_acc = 0.9857941313460643\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 78, train_loss = 7.152116449549794, train_acc = 0.9864927806241267\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 79, train_loss = 7.056402212008834, train_acc = 0.9869585468095017\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 80, train_loss = 6.962588354945183, train_acc = 0.9873078714485328\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 81, train_loss = 6.870488615706563, train_acc = 0.9873078714485328\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 82, train_loss = 6.780129270628095, train_acc = 0.9874243129948765\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 83, train_loss = 6.691609147936106, train_acc = 0.9874243129948765\n",
      "test Acc 0.9809124767225326:\n",
      "7th- epoch: 84, train_loss = 6.6048523131757975, train_acc = 0.9874243129948765\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 85, train_loss = 6.519737049937248, train_acc = 0.9874243129948765\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 86, train_loss = 6.436210473999381, train_acc = 0.9875407545412203\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 87, train_loss = 6.354448188096285, train_acc = 0.9875407545412203\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 88, train_loss = 6.274247059598565, train_acc = 0.9875407545412203\n",
      "test Acc 0.9804469273743017:\n",
      "7th- epoch: 89, train_loss = 6.19549966417253, train_acc = 0.9877736376339078\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 90, train_loss = 6.118348307907581, train_acc = 0.9880065207265952\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 91, train_loss = 6.042625719681382, train_acc = 0.9882394038192828\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 92, train_loss = 5.9684285670518875, train_acc = 0.9885887284583139\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 93, train_loss = 5.895566331222653, train_acc = 0.9885887284583139\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 94, train_loss = 5.824082523584366, train_acc = 0.9888216115510013\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 95, train_loss = 5.753964971750975, train_acc = 0.9890544946436889\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 96, train_loss = 5.68513772264123, train_acc = 0.9891709361900326\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 97, train_loss = 5.617583943530917, train_acc = 0.9891709361900326\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 98, train_loss = 5.551307141780853, train_acc = 0.9892873777363763\n",
      "test Acc 0.9823091247672253:\n",
      "7th- epoch: 99, train_loss = 5.4861947521567345, train_acc = 0.98940381928272\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 100, train_loss = 5.422240164130926, train_acc = 0.9896367023754076\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 101, train_loss = 5.359423782676458, train_acc = 0.9896367023754076\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 102, train_loss = 5.297702608630061, train_acc = 0.989869585468095\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 103, train_loss = 5.237110519781709, train_acc = 0.9899860270144387\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 104, train_loss = 5.177588511258364, train_acc = 0.9901024685607824\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 105, train_loss = 5.119123274460435, train_acc = 0.9904517931998137\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 106, train_loss = 5.0616776859387755, train_acc = 0.9904517931998137\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 107, train_loss = 5.005264676176012, train_acc = 0.9906846762925011\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 108, train_loss = 4.950062974356115, train_acc = 0.990801117838845\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 109, train_loss = 4.89577626157552, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 110, train_loss = 4.842542712576687, train_acc = 0.9911504424778761\n",
      "test Acc 0.9818435754189944:\n",
      "7th- epoch: 111, train_loss = 4.790162620134652, train_acc = 0.9914997671169073\n",
      "test Acc 0.9827746741154563:\n",
      "7th- epoch: 112, train_loss = 4.738717867992818, train_acc = 0.9916162086632511\n",
      "test Acc 0.9827746741154563:\n",
      "7th- epoch: 113, train_loss = 4.68819325696677, train_acc = 0.9917326502095948\n",
      "test Acc 0.9827746741154563:\n",
      "7th- epoch: 114, train_loss = 4.638594410382211, train_acc = 0.9917326502095948\n",
      "test Acc 0.9827746741154563:\n",
      "7th- epoch: 115, train_loss = 4.589701612479985, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 116, train_loss = 4.5417168429121375, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 117, train_loss = 4.494551291689277, train_acc = 0.9919655333022822\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 118, train_loss = 4.448157370090485, train_acc = 0.992081974848626\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 119, train_loss = 4.402674729935825, train_acc = 0.9921984163949698\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 120, train_loss = 4.357815781608224, train_acc = 0.9923148579413135\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 121, train_loss = 4.313725692220032, train_acc = 0.9923148579413135\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 122, train_loss = 4.270449968986213, train_acc = 0.9923148579413135\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 123, train_loss = 4.227837008424103, train_acc = 0.9923148579413135\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 124, train_loss = 4.185950612649322, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 125, train_loss = 4.144718469120562, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 126, train_loss = 4.104281652718782, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 127, train_loss = 4.064386798068881, train_acc = 0.9931299487657196\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 128, train_loss = 4.025239600799978, train_acc = 0.9932463903120633\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 129, train_loss = 3.986555333249271, train_acc = 0.9934792734047508\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 130, train_loss = 3.9486117335036397, train_acc = 0.9935957149510946\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 131, train_loss = 3.9112551948055625, train_acc = 0.9937121564974383\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 132, train_loss = 3.874436824582517, train_acc = 0.9937121564974383\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 133, train_loss = 3.8382039917632937, train_acc = 0.9937121564974383\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 134, train_loss = 3.8026023833081126, train_acc = 0.9937121564974383\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 135, train_loss = 3.767412142828107, train_acc = 0.9937121564974383\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 136, train_loss = 3.7328787250444293, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 137, train_loss = 3.6988451555371284, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 138, train_loss = 3.6652429895475507, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 139, train_loss = 3.6323187658563256, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 140, train_loss = 3.599756055511534, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 141, train_loss = 3.5678285816684365, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 142, train_loss = 3.536298992112279, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 143, train_loss = 3.5053320694714785, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 144, train_loss = 3.474841288290918, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 145, train_loss = 3.4447873854078352, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 146, train_loss = 3.4151764786802232, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 147, train_loss = 3.3859844584949315, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 148, train_loss = 3.35738010937348, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 149, train_loss = 3.329024491365999, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 150, train_loss = 3.301117502618581, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 151, train_loss = 3.273651103954762, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 152, train_loss = 3.246428081765771, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 153, train_loss = 3.219713476020843, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 154, train_loss = 3.1932185613550246, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 155, train_loss = 3.1672811545431614, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 156, train_loss = 3.1414966569282115, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 157, train_loss = 3.1162564516998827, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 158, train_loss = 3.091219648718834, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 159, train_loss = 3.0666653905063868, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 160, train_loss = 3.0422953199595213, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 161, train_loss = 3.0184562653303146, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 162, train_loss = 2.9947699420154095, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 163, train_loss = 2.9715339415706694, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 164, train_loss = 2.948631977662444, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 165, train_loss = 2.925947732757777, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 166, train_loss = 2.903621781617403, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 167, train_loss = 2.881637191865593, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 168, train_loss = 2.859940679743886, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 169, train_loss = 2.838518900796771, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 170, train_loss = 2.8174093305133283, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 171, train_loss = 2.7966399346478283, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 172, train_loss = 2.776017388794571, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 173, train_loss = 2.7557649947702885, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 174, train_loss = 2.735705127939582, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 175, train_loss = 2.7160073812119663, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 176, train_loss = 2.696484198793769, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 177, train_loss = 2.6771695190109313, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 178, train_loss = 2.658260276541114, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 179, train_loss = 2.6394269727170467, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 180, train_loss = 2.6209767223335803, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 181, train_loss = 2.602661669254303, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 182, train_loss = 2.5847840695641935, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 183, train_loss = 2.5670252591371536, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 184, train_loss = 2.5495240963064134, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 185, train_loss = 2.5322945551015437, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 186, train_loss = 2.515273828525096, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 187, train_loss = 2.4984892439097166, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 188, train_loss = 2.481909155845642, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 189, train_loss = 2.4655377622693777, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 190, train_loss = 2.4494588517118245, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 191, train_loss = 2.4335370876360685, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 192, train_loss = 2.4178447674494237, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 193, train_loss = 2.402325763599947, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 194, train_loss = 2.3869862016290426, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 195, train_loss = 2.3720228902529925, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 196, train_loss = 2.3570906303357333, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 197, train_loss = 2.342431476339698, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 198, train_loss = 2.327964847208932, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 199, train_loss = 2.313658267259598, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 200, train_loss = 2.299578120233491, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 201, train_loss = 2.2857417806517333, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 202, train_loss = 2.2720326569397002, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 203, train_loss = 2.25858981651254, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 204, train_loss = 2.2451912735123187, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 205, train_loss = 2.2321025088895112, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 206, train_loss = 2.2191317181568593, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 207, train_loss = 2.206303558079526, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 208, train_loss = 2.1937055240850896, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 209, train_loss = 2.1811975811142474, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 210, train_loss = 2.1689062900841236, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 211, train_loss = 2.1567277554422617, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 212, train_loss = 2.1448138144332916, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 213, train_loss = 2.1329127810895443, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 214, train_loss = 2.1212526944000274, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 215, train_loss = 2.1097371720243245, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 216, train_loss = 2.0983172319829464, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 217, train_loss = 2.0871961291413754, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 218, train_loss = 2.0761107846628875, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 219, train_loss = 2.065125435590744, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 220, train_loss = 2.0543232951313257, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 221, train_loss = 2.043638323666528, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 222, train_loss = 2.0331904124468565, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 223, train_loss = 2.02273188973777, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 224, train_loss = 2.0124981713015586, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 225, train_loss = 2.002342812716961, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 226, train_loss = 1.9923288219142705, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 227, train_loss = 1.9823621176183224, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 228, train_loss = 1.972624235553667, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 229, train_loss = 1.9629470177460462, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 230, train_loss = 1.9533705438952893, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 231, train_loss = 1.9439584042411298, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 232, train_loss = 1.9346313688438386, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 233, train_loss = 1.9254549946635962, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 234, train_loss = 1.916343891294673, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 235, train_loss = 1.9074233695864677, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 236, train_loss = 1.8984955314081162, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 237, train_loss = 1.8897355229128152, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 238, train_loss = 1.8810106236487627, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 239, train_loss = 1.872423170832917, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 240, train_loss = 1.8639619555324316, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 241, train_loss = 1.8556202445179224, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 242, train_loss = 1.8473820600192994, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 243, train_loss = 1.839185596210882, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 244, train_loss = 1.831174379796721, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 245, train_loss = 1.8231656333664432, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 246, train_loss = 1.8152965182671323, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "7th- epoch: 247, train_loss = 1.8074471993604675, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 248, train_loss = 1.7998444518307224, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 249, train_loss = 1.7921220069983974, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 250, train_loss = 1.7846056645503268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 251, train_loss = 1.7772039795527235, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 252, train_loss = 1.7697878623148426, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 253, train_loss = 1.7625287330010906, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 254, train_loss = 1.7552701228996739, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 255, train_loss = 1.7481850491603836, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 256, train_loss = 1.7411082530161366, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 257, train_loss = 1.7341222321847454, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 258, train_loss = 1.7271735202521086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 259, train_loss = 1.7203706987202168, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 260, train_loss = 1.7136441009351984, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 261, train_loss = 1.7069554968038574, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 262, train_loss = 1.7002949379384518, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 263, train_loss = 1.6937443589558825, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 264, train_loss = 1.687192352488637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 265, train_loss = 1.680806673481129, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 266, train_loss = 1.674332141294144, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 267, train_loss = 1.6680847747484222, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 268, train_loss = 1.661793103441596, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 269, train_loss = 1.6556323101976886, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 270, train_loss = 1.6495505379280075, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 271, train_loss = 1.6434687165310606, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 272, train_loss = 1.637532631517388, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 273, train_loss = 1.6315822005271912, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 274, train_loss = 1.6257679760456085, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 275, train_loss = 1.6199002427747473, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 276, train_loss = 1.6141688214847818, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "7th- epoch: 277, train_loss = 1.6084324257681146, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 278, train_loss = 1.6028446765849367, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 279, train_loss = 1.597252512932755, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 280, train_loss = 1.591708306223154, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 281, train_loss = 1.5862271139631048, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "7th- epoch: 282, train_loss = 1.5808491632342339, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 283, train_loss = 1.5754552060971037, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 284, train_loss = 1.570123931975104, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 285, train_loss = 1.5649122446775436, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 286, train_loss = 1.5596532374620438, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 287, train_loss = 1.5544888004660606, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 288, train_loss = 1.5493769012391567, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 289, train_loss = 1.5443334704032168, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 290, train_loss = 1.539262386620976, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 291, train_loss = 1.5343822414288297, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 292, train_loss = 1.5293672221014276, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 293, train_loss = 1.5245171064743772, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 294, train_loss = 1.5196722770342603, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 295, train_loss = 1.5148647812893614, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 296, train_loss = 1.5101219825446606, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 297, train_loss = 1.505436945706606, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 298, train_loss = 1.5007081168005243, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 299, train_loss = 1.4961202492704615, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 300, train_loss = 1.491520827054046, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 301, train_loss = 1.4870093762874603, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 302, train_loss = 1.482486198307015, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 303, train_loss = 1.4781128825852647, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 304, train_loss = 1.473626601160504, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 305, train_loss = 1.4693111516535282, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 306, train_loss = 1.4649137370288372, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 307, train_loss = 1.4606177496025339, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 308, train_loss = 1.4564255414297804, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 309, train_loss = 1.4521078454563394, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 310, train_loss = 1.44800915569067, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 311, train_loss = 1.4437731429934502, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 312, train_loss = 1.4397366779739968, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 313, train_loss = 1.4356341983075254, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 314, train_loss = 1.4315316143329255, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 315, train_loss = 1.4276021234691143, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 316, train_loss = 1.4235666804015636, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 317, train_loss = 1.419614303857088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 318, train_loss = 1.415752739936579, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 319, train_loss = 1.4118607963318937, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 320, train_loss = 1.4079688650672324, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 321, train_loss = 1.4041781264240853, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 322, train_loss = 1.4003745913505554, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 323, train_loss = 1.3966008511488326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 324, train_loss = 1.3928984415833838, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 325, train_loss = 1.3891886311466806, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 326, train_loss = 1.3855581544339657, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 327, train_loss = 1.381885418028105, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 328, train_loss = 1.3783091542427428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 329, train_loss = 1.374621098220814, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 330, train_loss = 1.371209288656246, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 331, train_loss = 1.367573029070627, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 332, train_loss = 1.3641773101990111, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 333, train_loss = 1.3606660440564156, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 334, train_loss = 1.3572196860914119, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 335, train_loss = 1.3537801392376423, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 336, train_loss = 1.3504445987637155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 337, train_loss = 1.3469960491056554, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 338, train_loss = 1.3437579448218457, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 339, train_loss = 1.3403854097123258, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 340, train_loss = 1.3371506867115386, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 341, train_loss = 1.333844902634155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 342, train_loss = 1.330657082318794, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 343, train_loss = 1.3274008817970753, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 344, train_loss = 1.3241951589589007, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 345, train_loss = 1.3210560108418576, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 346, train_loss = 1.3179956612293608, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 347, train_loss = 1.3147747752373107, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 348, train_loss = 1.311740840494167, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 349, train_loss = 1.308618066192139, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 350, train_loss = 1.3056208963389508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 351, train_loss = 1.302561556280125, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 352, train_loss = 1.2995269472594373, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 353, train_loss = 1.2965671097044833, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 354, train_loss = 1.2936297965352423, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 355, train_loss = 1.2906090058386326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 356, train_loss = 1.2876510061323643, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 357, train_loss = 1.2847396073048003, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 358, train_loss = 1.2818346532876603, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 359, train_loss = 1.2789415692095645, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 360, train_loss = 1.2760939945583232, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 361, train_loss = 1.2732682364876382, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "7th- epoch: 362, train_loss = 1.270501131832134, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 363, train_loss = 1.2676560766994953, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 364, train_loss = 1.264953464269638, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 365, train_loss = 1.2622040398418903, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 366, train_loss = 1.2595001359586604, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 367, train_loss = 1.2567444021697156, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 368, train_loss = 1.2540913608972915, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 369, train_loss = 1.251467493653763, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 370, train_loss = 1.2488021279568784, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 371, train_loss = 1.2461697608232498, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 372, train_loss = 1.243561105162371, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 373, train_loss = 1.2409786470234394, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 374, train_loss = 1.2384227613802068, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 375, train_loss = 1.2357984781265259, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 376, train_loss = 1.2332768055493943, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 377, train_loss = 1.2308121274108998, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 378, train_loss = 1.228269763290882, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 379, train_loss = 1.2258035664563067, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 380, train_loss = 1.223268831789028, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 381, train_loss = 1.2209230909938924, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 382, train_loss = 1.2184411461348645, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 383, train_loss = 1.2159631897811778, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 384, train_loss = 1.2135819618706591, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 385, train_loss = 1.2112314154510386, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 386, train_loss = 1.2088427655398846, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 387, train_loss = 1.2064702262287028, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 388, train_loss = 1.2041575449402444, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 389, train_loss = 1.2017309367656708, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 390, train_loss = 1.1995212982292287, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 391, train_loss = 1.197176658839453, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 392, train_loss = 1.1948665318195708, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 393, train_loss = 1.1926086992025375, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 394, train_loss = 1.190376665443182, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 395, train_loss = 1.1880935889785178, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 396, train_loss = 1.1859388102893718, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 397, train_loss = 1.1836652370984666, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 398, train_loss = 1.1814207012648694, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 399, train_loss = 1.1793105863034725, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 400, train_loss = 1.1771037342841737, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 401, train_loss = 1.1749604530632496, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 402, train_loss = 1.1727945891325362, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 403, train_loss = 1.170667329162825, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 404, train_loss = 1.168545886874199, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 405, train_loss = 1.1664269976317883, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 406, train_loss = 1.1643799853918608, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 407, train_loss = 1.162239962577587, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 408, train_loss = 1.1601561643183231, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 409, train_loss = 1.1581781556305941, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 410, train_loss = 1.1560677525994834, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 411, train_loss = 1.1540322490036488, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 412, train_loss = 1.1520639521477278, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 413, train_loss = 1.1499809734523296, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 414, train_loss = 1.1480233669281006, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 415, train_loss = 1.1460492946207523, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 416, train_loss = 1.1440349270997103, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 417, train_loss = 1.1420718518493231, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 418, train_loss = 1.1400968432426453, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 419, train_loss = 1.1381352407333907, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 420, train_loss = 1.1362014996411745, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 421, train_loss = 1.1342547498643398, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 422, train_loss = 1.1323466362955514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 423, train_loss = 1.1304858016374055, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 424, train_loss = 1.128577634692192, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 425, train_loss = 1.1266756802797318, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 426, train_loss = 1.1248175725340843, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 427, train_loss = 1.1229157845082227, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 428, train_loss = 1.121099834650522, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 429, train_loss = 1.11927399536944, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 430, train_loss = 1.1173659389314707, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 431, train_loss = 1.1157173551619053, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 432, train_loss = 1.1137889809906483, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 433, train_loss = 1.1120397759077605, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 434, train_loss = 1.1101500652730465, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 435, train_loss = 1.108431726694107, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 436, train_loss = 1.1066928456129972, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 437, train_loss = 1.1048565730452538, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 438, train_loss = 1.10317132374621, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 439, train_loss = 1.1014380989072379, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 440, train_loss = 1.0997376963496208, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 441, train_loss = 1.0979906916618347, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 442, train_loss = 1.0962884773907717, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 443, train_loss = 1.0946752528252546, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 444, train_loss = 1.0929132910969201, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7th- epoch: 445, train_loss = 1.091313877463108, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 446, train_loss = 1.0895375137624796, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 447, train_loss = 1.0879231952130795, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 448, train_loss = 1.0862380055186804, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 449, train_loss = 1.0845965941844042, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 450, train_loss = 1.0829918993113097, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 451, train_loss = 1.081348898500437, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 452, train_loss = 1.0797870295646135, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 453, train_loss = 1.0781523697078228, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 454, train_loss = 1.0765276787278708, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 455, train_loss = 1.074972646922106, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 456, train_loss = 1.0733287123439368, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 457, train_loss = 1.0718310152587947, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 458, train_loss = 1.07023953893804, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 459, train_loss = 1.0686431750655174, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 460, train_loss = 1.067102164030075, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 461, train_loss = 1.0655809293093625, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 462, train_loss = 1.0640353398921434, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 463, train_loss = 1.0625192498264369, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 464, train_loss = 1.0610210361483041, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 465, train_loss = 1.0595358597638551, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 466, train_loss = 1.0580347813665867, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 467, train_loss = 1.0565296461281832, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 468, train_loss = 1.055076523363823, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 469, train_loss = 1.053550904005533, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 470, train_loss = 1.0520936312677804, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 471, train_loss = 1.0506346697511617, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 472, train_loss = 1.0491741746664047, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 473, train_loss = 1.047750053316122, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 474, train_loss = 1.0462620717880782, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 475, train_loss = 1.0448487227258738, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 476, train_loss = 1.043394605309004, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 477, train_loss = 1.041974334657425, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 478, train_loss = 1.0405815218982752, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 479, train_loss = 1.0391066869196948, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 480, train_loss = 1.0377939119935036, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 481, train_loss = 1.0363746496441308, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 482, train_loss = 1.0350450674595777, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 483, train_loss = 1.0335451016726438, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 484, train_loss = 1.032271566480631, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 485, train_loss = 1.0308433584868908, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 486, train_loss = 1.0294820542039815, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 487, train_loss = 1.0281011462211609, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 488, train_loss = 1.0268082208931446, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 489, train_loss = 1.0255089960992336, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 490, train_loss = 1.0241090096533298, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 491, train_loss = 1.02283943691873, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 492, train_loss = 1.0214586357178632, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 493, train_loss = 1.0201722035708372, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 494, train_loss = 1.018906300276285, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 495, train_loss = 1.017563570290804, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 496, train_loss = 1.0162807442247868, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 497, train_loss = 1.0149699176254217, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 498, train_loss = 1.0136802209017333, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "7th- epoch: 499, train_loss = 1.0123714419605676, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|█████████████████                                                        | 7/30 [47:27<2:36:07, 407.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "8th- epoch: 0, train_loss = 269.76105284690857, train_acc = 0.46110852352119236\n",
      "test Acc 0.4883612662942272:\n",
      "8th- epoch: 1, train_loss = 203.96404016017914, train_acc = 0.5071029343269678\n",
      "test Acc 0.5642458100558659:\n",
      "8th- epoch: 2, train_loss = 159.47409534454346, train_acc = 0.5914066138798323\n",
      "test Acc 0.6345437616387337:\n",
      "8th- epoch: 3, train_loss = 133.38012778759003, train_acc = 0.6684909175593852\n",
      "test Acc 0.7094972067039106:\n",
      "8th- epoch: 4, train_loss = 114.2642793059349, train_acc = 0.7392873777363763\n",
      "test Acc 0.7648975791433892:\n",
      "8th- epoch: 5, train_loss = 99.11091563105583, train_acc = 0.7738705170004657\n",
      "test Acc 0.7835195530726257:\n",
      "8th- epoch: 6, train_loss = 86.70107161998749, train_acc = 0.7945971122496507\n",
      "test Acc 0.8081936685288641:\n",
      "8th- epoch: 7, train_loss = 76.48902302980423, train_acc = 0.831858407079646\n",
      "test Acc 0.8440409683426443:\n",
      "8th- epoch: 8, train_loss = 67.95513525605202, train_acc = 0.8634140661387983\n",
      "test Acc 0.8803538175046555:\n",
      "8th- epoch: 9, train_loss = 60.76889097690582, train_acc = 0.8892640894271076\n",
      "test Acc 0.9027001862197392:\n",
      "8th- epoch: 10, train_loss = 54.701311364769936, train_acc = 0.8992780624126688\n",
      "test Acc 0.909217877094972:\n",
      "8th- epoch: 11, train_loss = 49.54666005074978, train_acc = 0.9064974382859804\n",
      "test Acc 0.9138733705772812:\n",
      "8th- epoch: 12, train_loss = 45.12982015311718, train_acc = 0.9169771774569166\n",
      "test Acc 0.9273743016759777:\n",
      "8th- epoch: 13, train_loss = 41.31586903333664, train_acc = 0.9287377736376339\n",
      "test Acc 0.936219739292365:\n",
      "8th- epoch: 14, train_loss = 38.00489170849323, train_acc = 0.9364229156963204\n",
      "test Acc 0.9422718808193669:\n",
      "8th- epoch: 15, train_loss = 35.13311975449324, train_acc = 0.9410805775500699\n",
      "test Acc 0.9441340782122905:\n",
      "8th- epoch: 16, train_loss = 32.648234240710735, train_acc = 0.9438751746623195\n",
      "test Acc 0.9473929236499069:\n",
      "8th- epoch: 17, train_loss = 30.4982425943017, train_acc = 0.9462040055891943\n",
      "test Acc 0.952048417132216:\n",
      "8th- epoch: 18, train_loss = 28.633765026926994, train_acc = 0.9523754075454122\n",
      "test Acc 0.9543761638733705:\n",
      "8th- epoch: 19, train_loss = 27.01089172065258, train_acc = 0.9538891476478808\n",
      "test Acc 0.9562383612662942:\n",
      "8th- epoch: 20, train_loss = 25.592760413885117, train_acc = 0.9561015370284117\n",
      "test Acc 0.957635009310987:\n",
      "8th- epoch: 21, train_loss = 24.346563771367073, train_acc = 0.9585468095016302\n",
      "test Acc 0.9599627560521415:\n",
      "8th- epoch: 22, train_loss = 23.245396491140127, train_acc = 0.9595947834187238\n",
      "test Acc 0.9599627560521415:\n",
      "8th- epoch: 23, train_loss = 22.26554786413908, train_acc = 0.9600605496040987\n",
      "test Acc 0.9599627560521415:\n",
      "8th- epoch: 24, train_loss = 21.38747975602746, train_acc = 0.9614578481602236\n",
      "test Acc 0.9604283054003724:\n",
      "8th- epoch: 25, train_loss = 20.59437942877412, train_acc = 0.9620400558919422\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 26, train_loss = 19.872612703591585, train_acc = 0.9630880298090359\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 27, train_loss = 19.21118798479438, train_acc = 0.9641360037261295\n",
      "test Acc 0.9608938547486033:\n",
      "8th- epoch: 28, train_loss = 18.602421775460243, train_acc = 0.9655333022822543\n",
      "test Acc 0.9618249534450651:\n",
      "8th- epoch: 29, train_loss = 18.03925722837448, train_acc = 0.9662319515603167\n",
      "test Acc 0.9622905027932961:\n",
      "8th- epoch: 30, train_loss = 17.5155347622931, train_acc = 0.9671634839310667\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 31, train_loss = 17.02605986967683, train_acc = 0.9677456916627852\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 32, train_loss = 16.566395699977875, train_acc = 0.9679785747554728\n",
      "test Acc 0.962756052141527:\n",
      "8th- epoch: 33, train_loss = 16.133494928479195, train_acc = 0.9685607824871915\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 34, train_loss = 15.724596709012985, train_acc = 0.9691429902189101\n",
      "test Acc 0.9632216014897579:\n",
      "8th- epoch: 35, train_loss = 15.337403498589993, train_acc = 0.97007452258966\n",
      "test Acc 0.9636871508379888:\n",
      "8th- epoch: 36, train_loss = 14.970018863677979, train_acc = 0.9710060549604099\n",
      "test Acc 0.9646182495344506:\n",
      "8th- epoch: 37, train_loss = 14.621023342013359, train_acc = 0.9720540288775035\n",
      "test Acc 0.9660148975791434:\n",
      "8th- epoch: 38, train_loss = 14.288402877748013, train_acc = 0.9732184443409408\n",
      "test Acc 0.9674115456238361:\n",
      "8th- epoch: 39, train_loss = 13.970256544649601, train_acc = 0.974033535165347\n",
      "test Acc 0.9702048417132216:\n",
      "8th- epoch: 40, train_loss = 13.664322476834059, train_acc = 0.9749650675360969\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 41, train_loss = 13.371001210063696, train_acc = 0.9755472752678156\n",
      "test Acc 0.9716014897579144:\n",
      "8th- epoch: 42, train_loss = 13.089665375649929, train_acc = 0.9761294829995343\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 43, train_loss = 12.819810446351767, train_acc = 0.9767116907312529\n",
      "test Acc 0.9725325884543762:\n",
      "8th- epoch: 44, train_loss = 12.560442131012678, train_acc = 0.9772938984629715\n",
      "test Acc 0.972998137802607:\n",
      "8th- epoch: 45, train_loss = 12.311222672462463, train_acc = 0.9774103400093154\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 46, train_loss = 12.071948632597923, train_acc = 0.9776432231020028\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 47, train_loss = 11.841917600482702, train_acc = 0.9781089892873778\n",
      "test Acc 0.973463687150838:\n",
      "8th- epoch: 48, train_loss = 11.62039988860488, train_acc = 0.9781089892873778\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 49, train_loss = 11.406706001609564, train_acc = 0.9782254308337215\n",
      "test Acc 0.9739292364990689:\n",
      "8th- epoch: 50, train_loss = 11.20063902810216, train_acc = 0.9784583139264089\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 51, train_loss = 11.00147557258606, train_acc = 0.9790405216581276\n",
      "test Acc 0.9748603351955307:\n",
      "8th- epoch: 52, train_loss = 10.809084676206112, train_acc = 0.9795062878435026\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 53, train_loss = 10.622903186827898, train_acc = 0.97973917093619\n",
      "test Acc 0.9753258845437617:\n",
      "8th- epoch: 54, train_loss = 10.442683763802052, train_acc = 0.9803213786679087\n",
      "test Acc 0.9757914338919925:\n",
      "8th- epoch: 55, train_loss = 10.268007272854447, train_acc = 0.9810200279459711\n",
      "test Acc 0.9771880819366853:\n",
      "8th- epoch: 56, train_loss = 10.098506458103657, train_acc = 0.9813693525850024\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 57, train_loss = 9.933821277692914, train_acc = 0.9814857941313461\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 58, train_loss = 9.773678172379732, train_acc = 0.9818351187703773\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 59, train_loss = 9.618033668026328, train_acc = 0.9818351187703773\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 60, train_loss = 9.466595701873302, train_acc = 0.9821844434094085\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 61, train_loss = 9.31927097029984, train_acc = 0.9824173265020959\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 62, train_loss = 9.175826009362936, train_acc = 0.9825337680484397\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 63, train_loss = 9.035904811695218, train_acc = 0.9827666511411272\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 64, train_loss = 8.899224059656262, train_acc = 0.9827666511411272\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 65, train_loss = 8.765910813584924, train_acc = 0.9828830926874709\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 66, train_loss = 8.635711068287492, train_acc = 0.9833488588728458\n",
      "test Acc 0.9776536312849162:\n",
      "8th- epoch: 67, train_loss = 8.508561940863729, train_acc = 0.9832324173265021\n",
      "test Acc 0.9781191806331471:\n",
      "8th- epoch: 68, train_loss = 8.384554039686918, train_acc = 0.9832324173265021\n",
      "test Acc 0.978584729981378:\n",
      "8th- epoch: 69, train_loss = 8.263421349227428, train_acc = 0.9834653004191896\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 70, train_loss = 8.144954128190875, train_acc = 0.983698183511877\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 71, train_loss = 8.02898297086358, train_acc = 0.9839310666045645\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 72, train_loss = 7.91544471681118, train_acc = 0.9840475081509082\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 73, train_loss = 7.804024189710617, train_acc = 0.9842803912435957\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 74, train_loss = 7.694927100092173, train_acc = 0.9847461574289706\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 75, train_loss = 7.588319281116128, train_acc = 0.9850954820680019\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 76, train_loss = 7.483811151236296, train_acc = 0.9855612482533768\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 77, train_loss = 7.381360195577145, train_acc = 0.9860270144387517\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 78, train_loss = 7.2810333874076605, train_acc = 0.9862598975314392\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 79, train_loss = 7.1826855558902025, train_acc = 0.9864927806241267\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 80, train_loss = 7.086455719545484, train_acc = 0.9866092221704704\n",
      "test Acc 0.979050279329609:\n",
      "8th- epoch: 81, train_loss = 6.9921126794070005, train_acc = 0.9867256637168141\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 82, train_loss = 6.899586796760559, train_acc = 0.9867256637168141\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 83, train_loss = 6.809027658775449, train_acc = 0.9868421052631579\n",
      "test Acc 0.9795158286778398:\n",
      "8th- epoch: 84, train_loss = 6.720269750803709, train_acc = 0.9868421052631579\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 85, train_loss = 6.633293900638819, train_acc = 0.9868421052631579\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 86, train_loss = 6.547929655760527, train_acc = 0.9871914299021891\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 87, train_loss = 6.464404245838523, train_acc = 0.9874243129948765\n",
      "test Acc 0.9809124767225326:\n",
      "8th- epoch: 88, train_loss = 6.382413636893034, train_acc = 0.9877736376339078\n",
      "test Acc 0.9813780260707635:\n",
      "8th- epoch: 89, train_loss = 6.301991196349263, train_acc = 0.9881229622729389\n",
      "test Acc 0.9813780260707635:\n",
      "8th- epoch: 90, train_loss = 6.223075412213802, train_acc = 0.9882394038192828\n",
      "test Acc 0.9813780260707635:\n",
      "8th- epoch: 91, train_loss = 6.145653134211898, train_acc = 0.9881229622729389\n",
      "test Acc 0.9813780260707635:\n",
      "8th- epoch: 92, train_loss = 6.069722903892398, train_acc = 0.9881229622729389\n",
      "test Acc 0.9813780260707635:\n",
      "8th- epoch: 93, train_loss = 5.995252396911383, train_acc = 0.9881229622729389\n",
      "test Acc 0.9813780260707635:\n",
      "8th- epoch: 94, train_loss = 5.922096451744437, train_acc = 0.9883558453656265\n",
      "test Acc 0.9813780260707635:\n",
      "8th- epoch: 95, train_loss = 5.85032338835299, train_acc = 0.9885887284583139\n",
      "test Acc 0.9813780260707635:\n",
      "8th- epoch: 96, train_loss = 5.78005038574338, train_acc = 0.9888216115510013\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 97, train_loss = 5.71100714802742, train_acc = 0.9888216115510013\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 98, train_loss = 5.6432122848927975, train_acc = 0.9889380530973452\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 99, train_loss = 5.576758963987231, train_acc = 0.9891709361900326\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 100, train_loss = 5.511516375467181, train_acc = 0.9895202608290639\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 101, train_loss = 5.447367733344436, train_acc = 0.9896367023754076\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 102, train_loss = 5.384441448375583, train_acc = 0.9896367023754076\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 103, train_loss = 5.32282698713243, train_acc = 0.9897531439217513\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 104, train_loss = 5.262217667885125, train_acc = 0.989869585468095\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 105, train_loss = 5.202584086917341, train_acc = 0.9901024685607824\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 106, train_loss = 5.144096638076007, train_acc = 0.9899860270144387\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 107, train_loss = 5.086592282168567, train_acc = 0.9901024685607824\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 108, train_loss = 5.030267481692135, train_acc = 0.9901024685607824\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 109, train_loss = 4.974694726057351, train_acc = 0.9901024685607824\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 110, train_loss = 4.920223979279399, train_acc = 0.9905682347461574\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 111, train_loss = 4.866592147387564, train_acc = 0.9906846762925011\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 112, train_loss = 4.813954244367778, train_acc = 0.9906846762925011\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 113, train_loss = 4.762128454633057, train_acc = 0.9910340009315324\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 114, train_loss = 4.7112630577757955, train_acc = 0.9912668840242198\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 115, train_loss = 4.661324591375887, train_acc = 0.9912668840242198\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 116, train_loss = 4.612420202232897, train_acc = 0.9913833255705635\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 117, train_loss = 4.564293539151549, train_acc = 0.9916162086632511\n",
      "test Acc 0.9813780260707635:\n",
      "8th- epoch: 118, train_loss = 4.517030022107065, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "8th- epoch: 119, train_loss = 4.4703819351270795, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 120, train_loss = 4.424610949121416, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 121, train_loss = 4.379528719000518, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 122, train_loss = 4.335412733256817, train_acc = 0.992081974848626\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 123, train_loss = 4.29160291980952, train_acc = 0.9921984163949698\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 124, train_loss = 4.2488523768261075, train_acc = 0.9925477410340009\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 125, train_loss = 4.206610799767077, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 126, train_loss = 4.165188590064645, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 127, train_loss = 4.124515609815717, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 128, train_loss = 4.0843229200690985, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 129, train_loss = 4.044703739695251, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "8th- epoch: 130, train_loss = 4.0058426121249795, train_acc = 0.9928970656730322\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 131, train_loss = 3.967602496035397, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 132, train_loss = 3.9298714715987444, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 133, train_loss = 3.892738213762641, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 134, train_loss = 3.856189659796655, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 135, train_loss = 3.8202474741265178, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 136, train_loss = 3.784815413877368, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 137, train_loss = 3.7499223393388093, train_acc = 0.9931299487657196\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 138, train_loss = 3.7155529148876667, train_acc = 0.9934792734047508\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 139, train_loss = 3.6817644559778273, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 140, train_loss = 3.6485697315074503, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 141, train_loss = 3.6156935351900756, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "8th- epoch: 142, train_loss = 3.5834647975862026, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 143, train_loss = 3.5516022541560233, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 144, train_loss = 3.5204193401150405, train_acc = 0.9939450395901258\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 145, train_loss = 3.4895636360161006, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 146, train_loss = 3.459293499123305, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 147, train_loss = 3.42925465060398, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 148, train_loss = 3.3998898123390973, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 149, train_loss = 3.3708345275372267, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 150, train_loss = 3.3421861468814313, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 151, train_loss = 3.3139687664806843, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 152, train_loss = 3.2862504478543997, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 153, train_loss = 3.2589490357786417, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 154, train_loss = 3.231966908555478, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 155, train_loss = 3.205367316957563, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 156, train_loss = 3.1790933571755886, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 157, train_loss = 3.153201704379171, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 158, train_loss = 3.1277432274073362, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 159, train_loss = 3.102598052471876, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 160, train_loss = 3.077723289374262, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 161, train_loss = 3.0532179437577724, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 162, train_loss = 3.029024032410234, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 163, train_loss = 3.005267631262541, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 164, train_loss = 2.981989584863186, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 165, train_loss = 2.959035061299801, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 166, train_loss = 2.9362799054943025, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 167, train_loss = 2.9140104264952242, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 168, train_loss = 2.891898391302675, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 169, train_loss = 2.870250760111958, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 170, train_loss = 2.848625011742115, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 171, train_loss = 2.827547916676849, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 172, train_loss = 2.806677393615246, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 173, train_loss = 2.7861282699741423, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 174, train_loss = 2.7658279961906374, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 175, train_loss = 2.74578081863001, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 176, train_loss = 2.726020872592926, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 177, train_loss = 2.7065558317117393, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 178, train_loss = 2.687323838006705, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 179, train_loss = 2.668333414476365, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 180, train_loss = 2.6496890510898083, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 181, train_loss = 2.6312183253467083, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 182, train_loss = 2.6128938738256693, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 183, train_loss = 2.5950970698613673, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 184, train_loss = 2.5773280702997, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 185, train_loss = 2.5598540622740984, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 186, train_loss = 2.5426517215091735, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 187, train_loss = 2.525552124483511, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 188, train_loss = 2.5088622968178242, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 189, train_loss = 2.4922605238389224, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 190, train_loss = 2.4758956376463175, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 191, train_loss = 2.4598004780709743, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 192, train_loss = 2.4437406565994024, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 193, train_loss = 2.4281455762684345, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 194, train_loss = 2.412506186636165, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 195, train_loss = 2.397264279425144, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 196, train_loss = 2.3821117270272225, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 197, train_loss = 2.3672755423467606, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 198, train_loss = 2.3525199710857123, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 199, train_loss = 2.338039896218106, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 200, train_loss = 2.3237601902801543, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 201, train_loss = 2.309767308877781, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 202, train_loss = 2.2957472018897533, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 203, train_loss = 2.2821289997082204, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 204, train_loss = 2.2685739379376173, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 205, train_loss = 2.2552610840648413, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 206, train_loss = 2.242003879742697, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 207, train_loss = 2.2290632885415107, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 208, train_loss = 2.2161633782088757, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 209, train_loss = 2.2035277225077152, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 210, train_loss = 2.191039066761732, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 211, train_loss = 2.1786793142091483, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 212, train_loss = 2.166484822286293, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 213, train_loss = 2.1544530063401908, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 214, train_loss = 2.14260000619106, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 215, train_loss = 2.130863995058462, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 216, train_loss = 2.1193324979394674, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 217, train_loss = 2.1078530356753618, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 218, train_loss = 2.0965811156202108, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 219, train_loss = 2.0854713693261147, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 220, train_loss = 2.0744391393382102, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 221, train_loss = 2.063510023057461, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 222, train_loss = 2.052935768617317, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 223, train_loss = 2.042196190683171, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 224, train_loss = 2.0318348731379956, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 225, train_loss = 2.021427224157378, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 226, train_loss = 2.011217128485441, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 227, train_loss = 2.001074218424037, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 228, train_loss = 1.9911860097199678, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 229, train_loss = 1.9812490039039403, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 230, train_loss = 1.9715217917691916, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 231, train_loss = 1.9618447113316506, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 232, train_loss = 1.9523800953757018, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 233, train_loss = 1.9430351965129375, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 234, train_loss = 1.9336291197687387, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 235, train_loss = 1.9245242612669244, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 236, train_loss = 1.915387723594904, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 237, train_loss = 1.9065115688135847, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 238, train_loss = 1.897608375758864, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 239, train_loss = 1.8888902614125982, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 240, train_loss = 1.8802978607127443, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 241, train_loss = 1.8716832473874092, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 242, train_loss = 1.8632357828319073, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 243, train_loss = 1.855020347982645, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 244, train_loss = 1.846656933426857, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "8th- epoch: 245, train_loss = 1.8385039331624284, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 246, train_loss = 1.8305385248968378, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 247, train_loss = 1.822535770596005, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 248, train_loss = 1.8146189687540755, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 249, train_loss = 1.8068128960439935, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 250, train_loss = 1.7992406176635996, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 251, train_loss = 1.7915429808199406, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 252, train_loss = 1.7840247576823458, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 253, train_loss = 1.7765293506672606, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 254, train_loss = 1.7691204870352522, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 255, train_loss = 1.7619258301565424, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 256, train_loss = 1.7546708123991266, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 257, train_loss = 1.7475405732402578, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 258, train_loss = 1.7404237625887617, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 259, train_loss = 1.7334909066557884, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "8th- epoch: 260, train_loss = 1.7265693558147177, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "8th- epoch: 261, train_loss = 1.7197040282189846, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "8th- epoch: 262, train_loss = 1.7129629018018022, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "8th- epoch: 263, train_loss = 1.7062858827412128, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "8th- epoch: 264, train_loss = 1.69963214173913, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "8th- epoch: 265, train_loss = 1.693060646415688, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "8th- epoch: 266, train_loss = 1.686669461429119, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "8th- epoch: 267, train_loss = 1.6801799796521664, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "8th- epoch: 268, train_loss = 1.673763182014227, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "8th- epoch: 269, train_loss = 1.6675870617618784, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 270, train_loss = 1.6613386633107439, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 271, train_loss = 1.655043931095861, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 272, train_loss = 1.648954477161169, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 273, train_loss = 1.6429367711534724, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 274, train_loss = 1.6368433187017217, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 275, train_loss = 1.6310076167574152, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 276, train_loss = 1.6250673284521326, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 277, train_loss = 1.6192551652202383, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 278, train_loss = 1.6134377358248457, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 279, train_loss = 1.6077877370407805, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 280, train_loss = 1.6020554987480864, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 281, train_loss = 1.5962973721325397, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 282, train_loss = 1.5908640325069427, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 283, train_loss = 1.5853082090616226, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 284, train_loss = 1.5798645889153704, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 285, train_loss = 1.574581254273653, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 286, train_loss = 1.5690746381878853, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 287, train_loss = 1.5639257580041885, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 288, train_loss = 1.5586536104092374, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 289, train_loss = 1.5533641638467088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 290, train_loss = 1.548436769633554, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 291, train_loss = 1.543155169696547, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 292, train_loss = 1.5381904082605615, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 293, train_loss = 1.5331108620157465, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "8th- epoch: 294, train_loss = 1.5282431058585644, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 295, train_loss = 1.523298035026528, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 296, train_loss = 1.51846296840813, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 297, train_loss = 1.5135478277807124, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 298, train_loss = 1.5088571633095853, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 299, train_loss = 1.5040987022221088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 300, train_loss = 1.4994442996685393, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 301, train_loss = 1.4947011793847196, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 302, train_loss = 1.49016274017049, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 303, train_loss = 1.4856229610741138, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 304, train_loss = 1.4810538589954376, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 305, train_loss = 1.4766618472640403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 306, train_loss = 1.4720495119690895, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 307, train_loss = 1.4677566550672054, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 308, train_loss = 1.4633408089284785, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 309, train_loss = 1.4590650138561614, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 310, train_loss = 1.454688033729326, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 311, train_loss = 1.4505251583759673, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 312, train_loss = 1.4461706168949604, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 313, train_loss = 1.4420869598980062, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 314, train_loss = 1.4379246148164384, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 315, train_loss = 1.4338050397927873, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 316, train_loss = 1.4296999834477901, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 317, train_loss = 1.4257182304863818, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 318, train_loss = 1.421705951273907, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 319, train_loss = 1.4177111946046352, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 320, train_loss = 1.4137021067435853, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 321, train_loss = 1.409908031404484, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 322, train_loss = 1.4059071478550322, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 323, train_loss = 1.4021536447107792, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 324, train_loss = 1.3982548502390273, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 325, train_loss = 1.3945171038503759, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 326, train_loss = 1.3907981303636916, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 327, train_loss = 1.3869944761390798, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "8th- epoch: 328, train_loss = 1.3833383123273961, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 329, train_loss = 1.3797203240101226, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 330, train_loss = 1.3760681872372515, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 331, train_loss = 1.3724374038283713, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 332, train_loss = 1.3687795996665955, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 333, train_loss = 1.3653155553038232, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 334, train_loss = 1.3618204556405544, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 335, train_loss = 1.3582418511505239, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 336, train_loss = 1.3547838640515693, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 337, train_loss = 1.3514094911515713, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 338, train_loss = 1.3479525658185594, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 339, train_loss = 1.3446124630863778, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 340, train_loss = 1.3411382312770002, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 341, train_loss = 1.3379139403696172, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 342, train_loss = 1.3344645301694982, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 343, train_loss = 1.331279095262289, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 344, train_loss = 1.3279816930298693, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 345, train_loss = 1.3247770952875726, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 346, train_loss = 1.32151448976947, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 347, train_loss = 1.3183792469208129, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 348, train_loss = 1.315135971934069, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 349, train_loss = 1.312134101986885, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 350, train_loss = 1.3089168506558053, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 351, train_loss = 1.3058876817231067, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 352, train_loss = 1.3027070226962678, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 353, train_loss = 1.2997101905639283, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 354, train_loss = 1.296581532806158, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 355, train_loss = 1.2936533118481748, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 356, train_loss = 1.2905238482053392, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 357, train_loss = 1.2876174238626845, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 358, train_loss = 1.2846289699082263, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "8th- epoch: 359, train_loss = 1.2817477782373317, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 360, train_loss = 1.2787490114569664, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 361, train_loss = 1.2758424666826613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 362, train_loss = 1.2730084198410623, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 363, train_loss = 1.2701777766342275, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 364, train_loss = 1.2672213080222718, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 365, train_loss = 1.2644520687754266, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 366, train_loss = 1.2615921758115292, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 367, train_loss = 1.258856076747179, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 368, train_loss = 1.2561277424101718, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 369, train_loss = 1.2533298532362096, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 370, train_loss = 1.250570720701944, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 371, train_loss = 1.247927815944422, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 372, train_loss = 1.2452128268778324, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 373, train_loss = 1.2424505365197547, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 374, train_loss = 1.2398133277893066, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 375, train_loss = 1.2372646194999106, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 376, train_loss = 1.2345367806847207, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 377, train_loss = 1.2319611671264283, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 378, train_loss = 1.22938471037196, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 379, train_loss = 1.2269130137865432, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 380, train_loss = 1.2243458877201192, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 381, train_loss = 1.2217975904641207, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 382, train_loss = 1.2193300065991934, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 383, train_loss = 1.2168382667005062, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 384, train_loss = 1.2143991403281689, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 385, train_loss = 1.2118942278029863, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 386, train_loss = 1.2094617945549544, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 387, train_loss = 1.2069686303439084, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 388, train_loss = 1.2046576142311096, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 389, train_loss = 1.2022435454127844, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 390, train_loss = 1.1999245770275593, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 391, train_loss = 1.1974104853870813, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 392, train_loss = 1.1952581082878169, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 393, train_loss = 1.1928179872629698, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 394, train_loss = 1.19056404629373, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 395, train_loss = 1.1882419238390867, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 396, train_loss = 1.1860311428608838, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 397, train_loss = 1.183750102907652, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 398, train_loss = 1.181501620769268, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 399, train_loss = 1.1792256819608156, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 400, train_loss = 1.1770223615167197, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 401, train_loss = 1.174939832329983, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 402, train_loss = 1.1726845689117908, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 403, train_loss = 1.1704962266085204, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 404, train_loss = 1.16838581734919, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 405, train_loss = 1.1661007118818816, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 406, train_loss = 1.1641004408302251, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 407, train_loss = 1.1619139946997166, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 408, train_loss = 1.159920318663353, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 409, train_loss = 1.1577568762004375, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 410, train_loss = 1.1555958887038287, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 411, train_loss = 1.1535974256694317, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 412, train_loss = 1.1515480130910873, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 413, train_loss = 1.1495248787105083, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 414, train_loss = 1.1473999048175756, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 415, train_loss = 1.1454472728073597, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 416, train_loss = 1.143419404834276, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 417, train_loss = 1.1415012516081333, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 418, train_loss = 1.1394221112132072, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 419, train_loss = 1.1374538814125117, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 420, train_loss = 1.135477984935278, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 421, train_loss = 1.1335896948876325, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 422, train_loss = 1.131626940012211, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 423, train_loss = 1.1297043934464455, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 424, train_loss = 1.127763314783806, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 425, train_loss = 1.1258907243609428, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 426, train_loss = 1.123901696264511, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 427, train_loss = 1.122093783080345, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 428, train_loss = 1.1202040823700372, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 429, train_loss = 1.1183367272315081, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 430, train_loss = 1.1164770163595676, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 431, train_loss = 1.1146287669835147, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 432, train_loss = 1.1128164244291838, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 433, train_loss = 1.11106144884252, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 434, train_loss = 1.1091922856867313, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 435, train_loss = 1.1074283371272031, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 436, train_loss = 1.105661987006897, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 437, train_loss = 1.1038620881736279, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 438, train_loss = 1.1020117128791753, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 439, train_loss = 1.100329339504242, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 440, train_loss = 1.0986011251807213, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 441, train_loss = 1.0968146696686745, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 442, train_loss = 1.095142636448145, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 443, train_loss = 1.0934166411461774, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 444, train_loss = 1.0915848910808563, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 445, train_loss = 1.0899732584657613, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8th- epoch: 446, train_loss = 1.0883434725401457, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 447, train_loss = 1.0866091499628965, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 448, train_loss = 1.0849528225662652, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 449, train_loss = 1.0832357443869114, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 450, train_loss = 1.0816055126488209, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 451, train_loss = 1.0799786671996117, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 452, train_loss = 1.07833550623036, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 453, train_loss = 1.0766844103636686, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 454, train_loss = 1.0750755754706915, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 455, train_loss = 1.0734205792250577, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 456, train_loss = 1.0719186129572336, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 457, train_loss = 1.0703467813727912, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 458, train_loss = 1.0687295185925905, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 459, train_loss = 1.0671982231142465, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 460, train_loss = 1.0655386187136173, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 461, train_loss = 1.0639624136092607, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 462, train_loss = 1.0624286172387656, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 463, train_loss = 1.060909602791071, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 464, train_loss = 1.0593544306757394, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 465, train_loss = 1.0579367764294147, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 466, train_loss = 1.056306121259695, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 467, train_loss = 1.054821943253046, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 468, train_loss = 1.0533530538377818, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 469, train_loss = 1.0518447967770044, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 470, train_loss = 1.050299664348131, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 471, train_loss = 1.0489024954440538, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 472, train_loss = 1.047342018544441, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 473, train_loss = 1.0459492442605551, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 474, train_loss = 1.0444109675881919, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 475, train_loss = 1.0431033273634966, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 476, train_loss = 1.0415359822509345, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 477, train_loss = 1.0401469195785467, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 478, train_loss = 1.0387164925632533, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 479, train_loss = 1.0372409150004387, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 480, train_loss = 1.035855414957041, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 481, train_loss = 1.0344969717261847, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 482, train_loss = 1.0330962104198989, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 483, train_loss = 1.031675631791586, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 484, train_loss = 1.0303124835190829, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 485, train_loss = 1.0289473397133406, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 486, train_loss = 1.0275590345263481, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 487, train_loss = 1.0261755771934986, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 488, train_loss = 1.0247584246098995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 489, train_loss = 1.0234723811445292, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 490, train_loss = 1.0221486079244642, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 491, train_loss = 1.020747375980136, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 492, train_loss = 1.0195019505918026, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 493, train_loss = 1.0180693926959066, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 494, train_loss = 1.0167808992118808, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 495, train_loss = 1.0155110781342955, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 496, train_loss = 1.0141969261021586, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 497, train_loss = 1.0128614914865466, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 498, train_loss = 1.011581301689148, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "8th- epoch: 499, train_loss = 1.0103194477705983, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|███████████████████▍                                                     | 8/30 [54:19<2:29:51, 408.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "9th- epoch: 0, train_loss = 272.15424251556396, train_acc = 0.45167675826734976\n",
      "test Acc 0.4995344506517691:\n",
      "9th- epoch: 1, train_loss = 204.77607786655426, train_acc = 0.5012808570097811\n",
      "test Acc 0.5013966480446927:\n",
      "9th- epoch: 2, train_loss = 160.43905568122864, train_acc = 0.5781322775966465\n",
      "test Acc 0.633147113594041:\n",
      "9th- epoch: 3, train_loss = 135.11196726560593, train_acc = 0.6660456450861667\n",
      "test Acc 0.7039106145251397:\n",
      "9th- epoch: 4, train_loss = 116.06654274463654, train_acc = 0.7412668840242198\n",
      "test Acc 0.7648975791433892:\n",
      "9th- epoch: 5, train_loss = 100.84743916988373, train_acc = 0.7862133209129017\n",
      "test Acc 0.7946927374301676:\n",
      "9th- epoch: 6, train_loss = 88.43593123555183, train_acc = 0.8049604098742431\n",
      "test Acc 0.803072625698324:\n",
      "9th- epoch: 7, train_loss = 78.31990733742714, train_acc = 0.8100838379133675\n",
      "test Acc 0.813780260707635:\n",
      "9th- epoch: 8, train_loss = 69.9673924446106, train_acc = 0.827433628318584\n",
      "test Acc 0.8431098696461825:\n",
      "9th- epoch: 9, train_loss = 62.984267979860306, train_acc = 0.8606194690265486\n",
      "test Acc 0.87243947858473:\n",
      "9th- epoch: 10, train_loss = 57.076339945197105, train_acc = 0.8887983232417327\n",
      "test Acc 0.8952513966480447:\n",
      "9th- epoch: 11, train_loss = 52.01993450522423, train_acc = 0.9038192827200745\n",
      "test Acc 0.9078212290502793:\n",
      "9th- epoch: 12, train_loss = 47.63777211308479, train_acc = 0.912435957149511\n",
      "test Acc 0.9134078212290503:\n",
      "9th- epoch: 13, train_loss = 43.802171215415, train_acc = 0.9243129948765719\n",
      "test Acc 0.9287709497206704:\n",
      "9th- epoch: 14, train_loss = 40.41977456212044, train_acc = 0.933977643223102\n",
      "test Acc 0.9324953445065177:\n",
      "9th- epoch: 15, train_loss = 37.42184154689312, train_acc = 0.9397997205402888\n",
      "test Acc 0.9394785847299814:\n",
      "9th- epoch: 16, train_loss = 34.7700931429863, train_acc = 0.9429436422915697\n",
      "test Acc 0.9445996275605214:\n",
      "9th- epoch: 17, train_loss = 32.43411008268595, train_acc = 0.9446902654867256\n",
      "test Acc 0.946927374301676:\n",
      "9th- epoch: 18, train_loss = 30.379935808479786, train_acc = 0.9488821611551002\n",
      "test Acc 0.9501862197392924:\n",
      "9th- epoch: 19, train_loss = 28.574122212827206, train_acc = 0.952026082906381\n",
      "test Acc 0.9515828677839852:\n",
      "9th- epoch: 20, train_loss = 26.983489997684956, train_acc = 0.9537727061015371\n",
      "test Acc 0.9543761638733705:\n",
      "9th- epoch: 21, train_loss = 25.581359326839447, train_acc = 0.9552864462040056\n",
      "test Acc 0.9567039106145251:\n",
      "9th- epoch: 22, train_loss = 24.340369552373886, train_acc = 0.9568001863064741\n",
      "test Acc 0.957635009310987:\n",
      "9th- epoch: 23, train_loss = 23.235254295170307, train_acc = 0.9580810433162552\n",
      "test Acc 0.9581005586592178:\n",
      "9th- epoch: 24, train_loss = 22.244537085294724, train_acc = 0.959944108057755\n",
      "test Acc 0.9585661080074488:\n",
      "9th- epoch: 25, train_loss = 21.35068389773369, train_acc = 0.9612249650675361\n",
      "test Acc 0.9585661080074488:\n",
      "9th- epoch: 26, train_loss = 20.540384981781244, train_acc = 0.9628551467163484\n",
      "test Acc 0.9599627560521415:\n",
      "9th- epoch: 27, train_loss = 19.801718022674322, train_acc = 0.9637866790870983\n",
      "test Acc 0.9599627560521415:\n",
      "9th- epoch: 28, train_loss = 19.124570213258266, train_acc = 0.9651839776432231\n",
      "test Acc 0.9599627560521415:\n",
      "9th- epoch: 29, train_loss = 18.500156603753567, train_acc = 0.966115510013973\n",
      "test Acc 0.9599627560521415:\n",
      "9th- epoch: 30, train_loss = 17.92183704301715, train_acc = 0.9663483931066604\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 31, train_loss = 17.38466028124094, train_acc = 0.9672799254774104\n",
      "test Acc 0.9604283054003724:\n",
      "9th- epoch: 32, train_loss = 16.883839942514896, train_acc = 0.9675128085700978\n",
      "test Acc 0.9618249534450651:\n",
      "9th- epoch: 33, train_loss = 16.415684204548597, train_acc = 0.9679785747554728\n",
      "test Acc 0.962756052141527:\n",
      "9th- epoch: 34, train_loss = 15.976525478065014, train_acc = 0.9683278993945039\n",
      "test Acc 0.9646182495344506:\n",
      "9th- epoch: 35, train_loss = 15.564096912741661, train_acc = 0.9698416394969726\n",
      "test Acc 0.9655493482309124:\n",
      "9th- epoch: 36, train_loss = 15.175667639821768, train_acc = 0.9710060549604099\n",
      "test Acc 0.9660148975791434:\n",
      "9th- epoch: 37, train_loss = 14.808904893696308, train_acc = 0.9724033535165347\n",
      "test Acc 0.9674115456238361:\n",
      "9th- epoch: 38, train_loss = 14.462136160582304, train_acc = 0.9733348858872846\n",
      "test Acc 0.9683426443202979:\n",
      "9th- epoch: 39, train_loss = 14.133158389478922, train_acc = 0.9741499767116907\n",
      "test Acc 0.9692737430167597:\n",
      "9th- epoch: 40, train_loss = 13.819931503385305, train_acc = 0.9747321844434094\n",
      "test Acc 0.9706703910614525:\n",
      "9th- epoch: 41, train_loss = 13.521557983011007, train_acc = 0.9750815090824406\n",
      "test Acc 0.9716014897579144:\n",
      "9th- epoch: 42, train_loss = 13.236937638372183, train_acc = 0.9756637168141593\n",
      "test Acc 0.9725325884543762:\n",
      "9th- epoch: 43, train_loss = 12.964843820780516, train_acc = 0.9772938984629715\n",
      "test Acc 0.9739292364990689:\n",
      "9th- epoch: 44, train_loss = 12.704447291791439, train_acc = 0.977992547741034\n",
      "test Acc 0.9743947858472998:\n",
      "9th- epoch: 45, train_loss = 12.454739026725292, train_acc = 0.9784583139264089\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 46, train_loss = 12.214584436267614, train_acc = 0.9790405216581276\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 47, train_loss = 11.98353299871087, train_acc = 0.9791569632044713\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 48, train_loss = 11.761475589126348, train_acc = 0.9793898462971589\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 49, train_loss = 11.547543738037348, train_acc = 0.9800884955752213\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 50, train_loss = 11.341395292431116, train_acc = 0.9803213786679087\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 51, train_loss = 11.142523009330034, train_acc = 0.9804378202142524\n",
      "test Acc 0.9753258845437617:\n",
      "9th- epoch: 52, train_loss = 10.950496446341276, train_acc = 0.9807871448532837\n",
      "test Acc 0.9762569832402235:\n",
      "9th- epoch: 53, train_loss = 10.764747396111488, train_acc = 0.9809035863996274\n",
      "test Acc 0.9767225325884544:\n",
      "9th- epoch: 54, train_loss = 10.584898371249437, train_acc = 0.9810200279459711\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 55, train_loss = 10.410504844039679, train_acc = 0.9812529110386586\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 56, train_loss = 10.24130586721003, train_acc = 0.9814857941313461\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 57, train_loss = 10.077064210548997, train_acc = 0.9816022356776898\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 58, train_loss = 9.917400415986776, train_acc = 0.9817186772240335\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 59, train_loss = 9.762081982567906, train_acc = 0.9817186772240335\n",
      "test Acc 0.978584729981378:\n",
      "9th- epoch: 60, train_loss = 9.610952690243721, train_acc = 0.981951560316721\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 61, train_loss = 9.46374929882586, train_acc = 0.9821844434094085\n",
      "test Acc 0.9781191806331471:\n",
      "9th- epoch: 62, train_loss = 9.320390984416008, train_acc = 0.9825337680484397\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 63, train_loss = 9.18055753223598, train_acc = 0.9827666511411272\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 64, train_loss = 9.044152351096272, train_acc = 0.9827666511411272\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 65, train_loss = 8.910664681345224, train_acc = 0.9828830926874709\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 66, train_loss = 8.780307356268167, train_acc = 0.9833488588728458\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 67, train_loss = 8.653013315051794, train_acc = 0.9834653004191896\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 68, train_loss = 8.528638631105423, train_acc = 0.9833488588728458\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 69, train_loss = 8.407076478004456, train_acc = 0.9835817419655333\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 70, train_loss = 8.28823545947671, train_acc = 0.9838146250582208\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 71, train_loss = 8.171880196779966, train_acc = 0.9839310666045645\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 72, train_loss = 8.058114336803555, train_acc = 0.9840475081509082\n",
      "test Acc 0.9776536312849162:\n",
      "9th- epoch: 73, train_loss = 7.946695322170854, train_acc = 0.9842803912435957\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 74, train_loss = 7.837454542517662, train_acc = 0.9843968327899395\n",
      "test Acc 0.979050279329609:\n",
      "9th- epoch: 75, train_loss = 7.730531660839915, train_acc = 0.9845132743362832\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 76, train_loss = 7.625879710540175, train_acc = 0.9846297158826269\n",
      "test Acc 0.9795158286778398:\n",
      "9th- epoch: 77, train_loss = 7.5235171634703875, train_acc = 0.9847461574289706\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 78, train_loss = 7.423420799896121, train_acc = 0.9848625989753144\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 79, train_loss = 7.325348529964685, train_acc = 0.9850954820680019\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 80, train_loss = 7.229098064824939, train_acc = 0.9852119236143456\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 81, train_loss = 7.1349240224808455, train_acc = 0.9853283651606893\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 82, train_loss = 7.04245494864881, train_acc = 0.985444806707033\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 83, train_loss = 6.9518740344792604, train_acc = 0.9856776897997206\n",
      "test Acc 0.9799813780260708:\n",
      "9th- epoch: 84, train_loss = 6.862992951646447, train_acc = 0.9860270144387517\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 85, train_loss = 6.775948731228709, train_acc = 0.9862598975314392\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 86, train_loss = 6.690602397546172, train_acc = 0.9864927806241267\n",
      "test Acc 0.9804469273743017:\n",
      "9th- epoch: 87, train_loss = 6.606934813782573, train_acc = 0.9867256637168141\n",
      "test Acc 0.9809124767225326:\n",
      "9th- epoch: 88, train_loss = 6.524833178147674, train_acc = 0.9869585468095017\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 89, train_loss = 6.444366930052638, train_acc = 0.9870749883558454\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 90, train_loss = 6.365412766113877, train_acc = 0.9875407545412203\n",
      "test Acc 0.9813780260707635:\n",
      "9th- epoch: 91, train_loss = 6.287984687834978, train_acc = 0.9875407545412203\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 92, train_loss = 6.211911836639047, train_acc = 0.9881229622729389\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 93, train_loss = 6.137389123439789, train_acc = 0.9880065207265952\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 94, train_loss = 6.063977550715208, train_acc = 0.9882394038192828\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 95, train_loss = 5.992074064910412, train_acc = 0.9883558453656265\n",
      "test Acc 0.9818435754189944:\n",
      "9th- epoch: 96, train_loss = 5.921405671164393, train_acc = 0.9884722869119702\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 97, train_loss = 5.852120269089937, train_acc = 0.9884722869119702\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 98, train_loss = 5.78419079631567, train_acc = 0.9885887284583139\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 99, train_loss = 5.71741864643991, train_acc = 0.9890544946436889\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 100, train_loss = 5.65193029679358, train_acc = 0.9890544946436889\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 101, train_loss = 5.587597647681832, train_acc = 0.9892873777363763\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 102, train_loss = 5.524351067841053, train_acc = 0.9895202608290639\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 103, train_loss = 5.462295027449727, train_acc = 0.989869585468095\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 104, train_loss = 5.401429411023855, train_acc = 0.9899860270144387\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 105, train_loss = 5.341500945389271, train_acc = 0.9902189101071263\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 106, train_loss = 5.282669527456164, train_acc = 0.99033535165347\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 107, train_loss = 5.22499340120703, train_acc = 0.9904517931998137\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 108, train_loss = 5.1681774174794555, train_acc = 0.9904517931998137\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 109, train_loss = 5.112458444200456, train_acc = 0.9905682347461574\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 110, train_loss = 5.057628673501313, train_acc = 0.9906846762925011\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 111, train_loss = 5.003825981169939, train_acc = 0.9906846762925011\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 112, train_loss = 4.950934725813568, train_acc = 0.9906846762925011\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 113, train_loss = 4.8988282242789865, train_acc = 0.990801117838845\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 114, train_loss = 4.847681662067771, train_acc = 0.990801117838845\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 115, train_loss = 4.7973488150164485, train_acc = 0.990801117838845\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 116, train_loss = 4.747661975212395, train_acc = 0.990801117838845\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 117, train_loss = 4.698990280739963, train_acc = 0.9909175593851887\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 118, train_loss = 4.650976441800594, train_acc = 0.9911504424778761\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 119, train_loss = 4.603746498934925, train_acc = 0.9912668840242198\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 120, train_loss = 4.557284445501864, train_acc = 0.9914997671169073\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 121, train_loss = 4.5115385772660375, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 122, train_loss = 4.46655985340476, train_acc = 0.9918490917559385\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 123, train_loss = 4.422075948677957, train_acc = 0.992081974848626\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 124, train_loss = 4.378449288196862, train_acc = 0.9923148579413135\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 125, train_loss = 4.335356782190502, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 126, train_loss = 4.293170990422368, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 127, train_loss = 4.251411613076925, train_acc = 0.9925477410340009\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 128, train_loss = 4.210451730526984, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 129, train_loss = 4.170140088535845, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 130, train_loss = 4.130543774925172, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 131, train_loss = 4.091483958996832, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 132, train_loss = 4.053047205321491, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 133, train_loss = 4.015144477598369, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 134, train_loss = 3.977767956443131, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 135, train_loss = 3.9410292776301503, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 136, train_loss = 3.9047383833676577, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 137, train_loss = 3.8691363697871566, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 138, train_loss = 3.834013005718589, train_acc = 0.9935957149510946\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 139, train_loss = 3.79942749068141, train_acc = 0.9935957149510946\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 140, train_loss = 3.765298042446375, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 141, train_loss = 3.7317126700654626, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 142, train_loss = 3.69864400010556, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 143, train_loss = 3.665952076204121, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 144, train_loss = 3.6339202569797635, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 145, train_loss = 3.602310129441321, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 146, train_loss = 3.5713465409353375, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 147, train_loss = 3.5406121853739023, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 148, train_loss = 3.5104846507310867, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 149, train_loss = 3.4807998314499855, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 150, train_loss = 3.451310003641993, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 151, train_loss = 3.4223766792565584, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 152, train_loss = 3.3938883901573718, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 153, train_loss = 3.3657210152596235, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 154, train_loss = 3.3380892225541174, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 155, train_loss = 3.310816498938948, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 156, train_loss = 3.283888903912157, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 157, train_loss = 3.25734174111858, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 158, train_loss = 3.231181025970727, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 159, train_loss = 3.205361779779196, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 160, train_loss = 3.179948022123426, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 161, train_loss = 3.15487252548337, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 162, train_loss = 3.130165979731828, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 163, train_loss = 3.1057051769457757, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 164, train_loss = 3.0816464852541685, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 165, train_loss = 3.0579123054631054, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 166, train_loss = 3.034485022071749, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 167, train_loss = 3.011440835427493, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 168, train_loss = 2.9886780623346567, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 169, train_loss = 2.9662071275524795, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 170, train_loss = 2.94399832515046, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 171, train_loss = 2.922265501692891, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 172, train_loss = 2.9006435782648623, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 173, train_loss = 2.8794510322622955, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 174, train_loss = 2.858460557181388, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 175, train_loss = 2.8377960100769997, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 176, train_loss = 2.8173144087195396, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 177, train_loss = 2.797288427595049, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 178, train_loss = 2.777373427990824, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 179, train_loss = 2.7577387276105583, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 180, train_loss = 2.738549569621682, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 181, train_loss = 2.7193028605543077, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 182, train_loss = 2.700573995243758, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 183, train_loss = 2.6820000330917537, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 184, train_loss = 2.663694703951478, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 185, train_loss = 2.645536730531603, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 186, train_loss = 2.6276716496795416, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 187, train_loss = 2.6100715566426516, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 188, train_loss = 2.5926002603955567, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 189, train_loss = 2.575449702795595, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 190, train_loss = 2.558513338211924, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 191, train_loss = 2.541778747458011, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "9th- epoch: 192, train_loss = 2.5252827450167388, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 193, train_loss = 2.508948192698881, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 194, train_loss = 2.492821066407487, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 195, train_loss = 2.4770167011301965, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 196, train_loss = 2.4612732604146004, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 197, train_loss = 2.445820263819769, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 198, train_loss = 2.4305013474076986, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 199, train_loss = 2.4154400371480733, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 200, train_loss = 2.4005221247207373, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 201, train_loss = 2.3857429549098015, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 202, train_loss = 2.3711340706795454, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 203, train_loss = 2.3566934124100953, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 204, train_loss = 2.3423081927467138, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 205, train_loss = 2.328236595960334, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 206, train_loss = 2.314384122611955, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 207, train_loss = 2.300448849098757, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 208, train_loss = 2.287045045522973, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 209, train_loss = 2.273500893963501, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 210, train_loss = 2.2602736316621304, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 211, train_loss = 2.2470334984827787, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 212, train_loss = 2.234163461951539, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 213, train_loss = 2.2212867829948664, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 214, train_loss = 2.208606356754899, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "9th- epoch: 215, train_loss = 2.196149391354993, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 216, train_loss = 2.1836769345682114, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 217, train_loss = 2.1715993762481958, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 218, train_loss = 2.159420121461153, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 219, train_loss = 2.1476141151506454, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 220, train_loss = 2.1357623643707484, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 221, train_loss = 2.1241629261057824, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 222, train_loss = 2.1127088852226734, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 223, train_loss = 2.101322963135317, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 224, train_loss = 2.090109068201855, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 225, train_loss = 2.07897446048446, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 226, train_loss = 2.06805515778251, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 227, train_loss = 2.0571954536717385, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 228, train_loss = 2.046601791633293, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 229, train_loss = 2.0359628696460277, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 230, train_loss = 2.0254531409591436, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 231, train_loss = 2.0152387376874685, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 232, train_loss = 2.0049123633652925, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 233, train_loss = 1.994885563151911, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 234, train_loss = 1.9848833859432489, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 235, train_loss = 1.9749314163345844, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 236, train_loss = 1.9652754415292293, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 237, train_loss = 1.9555474251974374, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 238, train_loss = 1.946113221347332, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 239, train_loss = 1.936666653258726, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 240, train_loss = 1.9273359093349427, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 241, train_loss = 1.9181836675852537, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 242, train_loss = 1.9090143665671349, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "9th- epoch: 243, train_loss = 1.9001062959432602, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 244, train_loss = 1.8912297345232219, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 245, train_loss = 1.8823862485587597, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 246, train_loss = 1.8737944643944502, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 247, train_loss = 1.8651716721942648, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 248, train_loss = 1.8567927299300209, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 249, train_loss = 1.8483982706675306, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 250, train_loss = 1.8401062214979902, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "9th- epoch: 251, train_loss = 1.8319462165236473, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 252, train_loss = 1.823918666690588, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 253, train_loss = 1.8159187833080068, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 254, train_loss = 1.8080979399383068, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 255, train_loss = 1.8003305420279503, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 256, train_loss = 1.7926560416817665, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 257, train_loss = 1.7850979728391394, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 258, train_loss = 1.777562227100134, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 259, train_loss = 1.7701385380933061, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 260, train_loss = 1.7628462985157967, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 261, train_loss = 1.7555251630255952, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 262, train_loss = 1.7483950232854113, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 263, train_loss = 1.7412507310509682, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 264, train_loss = 1.7342670286307111, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 265, train_loss = 1.7273449575295672, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 266, train_loss = 1.7204408459365368, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 267, train_loss = 1.7136332802474499, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 268, train_loss = 1.7070128606865183, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 269, train_loss = 1.700276662944816, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 270, train_loss = 1.6937319338321686, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 271, train_loss = 1.6872296780347824, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 272, train_loss = 1.6808185143163428, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 273, train_loss = 1.6743998402962461, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "9th- epoch: 274, train_loss = 1.6681893555214629, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "9th- epoch: 275, train_loss = 1.661910923779942, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "9th- epoch: 276, train_loss = 1.655686198384501, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "9th- epoch: 277, train_loss = 1.6496555333724245, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "9th- epoch: 278, train_loss = 1.6436119576683268, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "9th- epoch: 279, train_loss = 1.637509906082414, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "9th- epoch: 280, train_loss = 1.6316627623746172, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "9th- epoch: 281, train_loss = 1.6257564102998003, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "9th- epoch: 282, train_loss = 1.6198224363615736, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "9th- epoch: 283, train_loss = 1.613846139400266, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "9th- epoch: 284, train_loss = 1.6079458432504907, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "9th- epoch: 285, train_loss = 1.6022079637041315, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "9th- epoch: 286, train_loss = 1.5966481702635065, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "9th- epoch: 287, train_loss = 1.5911517118802294, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "9th- epoch: 288, train_loss = 1.5856573147466406, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 289, train_loss = 1.5802146332571283, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 290, train_loss = 1.5748922129860148, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 291, train_loss = 1.5695243254303932, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 292, train_loss = 1.5642728693783283, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 293, train_loss = 1.5590508095920086, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 294, train_loss = 1.5538805909454823, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 295, train_loss = 1.5488053424051031, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 296, train_loss = 1.543703472823836, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 297, train_loss = 1.538686708896421, train_acc = 0.9975547275267815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 298, train_loss = 1.5337406346807256, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 299, train_loss = 1.5287907533347607, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 300, train_loss = 1.5239032307872549, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 301, train_loss = 1.519061534316279, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 302, train_loss = 1.514256201684475, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 303, train_loss = 1.5095364786684513, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 304, train_loss = 1.5048425731947646, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 305, train_loss = 1.5001724809408188, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 306, train_loss = 1.4954808888724074, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 307, train_loss = 1.4909651577472687, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 308, train_loss = 1.4863850958645344, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 309, train_loss = 1.4818547343020327, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 310, train_loss = 1.4774398803710938, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 311, train_loss = 1.4729702186887152, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 312, train_loss = 1.468599520623684, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 313, train_loss = 1.4642543469672091, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 314, train_loss = 1.4599533577566035, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 315, train_loss = 1.4556513503193855, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 316, train_loss = 1.45148255181266, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 317, train_loss = 1.4472346442635171, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 318, train_loss = 1.443052165210247, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 319, train_loss = 1.4388783139293082, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 320, train_loss = 1.4348380627925508, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 321, train_loss = 1.430708700150717, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 322, train_loss = 1.4267101300065406, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "9th- epoch: 323, train_loss = 1.4226894229650497, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "9th- epoch: 324, train_loss = 1.4187349962885492, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "9th- epoch: 325, train_loss = 1.414832113950979, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "9th- epoch: 326, train_loss = 1.410892229527235, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "9th- epoch: 327, train_loss = 1.4070234808023088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "9th- epoch: 328, train_loss = 1.40318987891078, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "9th- epoch: 329, train_loss = 1.3994053440983407, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "9th- epoch: 330, train_loss = 1.3956239049439318, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "9th- epoch: 331, train_loss = 1.3918804749846458, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 332, train_loss = 1.3881390032474883, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 333, train_loss = 1.384489564865362, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 334, train_loss = 1.380806331813801, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 335, train_loss = 1.37719702598406, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 336, train_loss = 1.3735990089480765, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 337, train_loss = 1.3700269696419127, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 338, train_loss = 1.366471125453245, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 339, train_loss = 1.3629669286310673, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 340, train_loss = 1.3594874081318267, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 341, train_loss = 1.3560318711097352, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 342, train_loss = 1.3526263870298862, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 343, train_loss = 1.3491576475207694, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 344, train_loss = 1.3458118910784833, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 345, train_loss = 1.3424252743716352, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 346, train_loss = 1.3391294491593726, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 347, train_loss = 1.3357332361047156, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 348, train_loss = 1.3325603467528708, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 349, train_loss = 1.3292901739478111, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 350, train_loss = 1.3260153544251807, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 351, train_loss = 1.3228306857054122, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 352, train_loss = 1.3196744484012015, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 353, train_loss = 1.3165234439074993, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 354, train_loss = 1.31337844702648, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 355, train_loss = 1.3102312075789087, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 356, train_loss = 1.3071532758767717, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 357, train_loss = 1.3041491632466204, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 358, train_loss = 1.301011414558161, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 359, train_loss = 1.2980503663420677, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 360, train_loss = 1.295077117800247, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 361, train_loss = 1.292049637704622, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 362, train_loss = 1.2891175014083274, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 363, train_loss = 1.2862068836693652, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 364, train_loss = 1.283237487077713, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 365, train_loss = 1.280357348441612, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 366, train_loss = 1.2774894312024117, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 367, train_loss = 1.274642909585964, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 368, train_loss = 1.2717628839309327, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 369, train_loss = 1.2689714568550698, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 370, train_loss = 1.2662258918280713, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 371, train_loss = 1.2633929426665418, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 372, train_loss = 1.2606454106862657, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 373, train_loss = 1.2579076054389589, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 374, train_loss = 1.2551426862482913, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 375, train_loss = 1.252447163045872, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 376, train_loss = 1.2498259444837458, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 377, train_loss = 1.2470872911508195, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 378, train_loss = 1.244476052641403, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 379, train_loss = 1.241802267730236, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 380, train_loss = 1.2391737016732804, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 381, train_loss = 1.236620010167826, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 382, train_loss = 1.234031230211258, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 383, train_loss = 1.23144831758691, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 384, train_loss = 1.2289425544440746, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 385, train_loss = 1.2263590668444522, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 386, train_loss = 1.2238771046395414, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 387, train_loss = 1.221380793780554, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 388, train_loss = 1.2188953061704524, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 389, train_loss = 1.2165038448874839, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 390, train_loss = 1.2140037516946904, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 391, train_loss = 1.2116364811663516, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 392, train_loss = 1.2091288951633032, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 393, train_loss = 1.2068500953319017, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 394, train_loss = 1.2044405974447727, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 395, train_loss = 1.2020885460078716, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 396, train_loss = 1.1997378654778004, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 397, train_loss = 1.197377155214781, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 398, train_loss = 1.1950904379191343, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 399, train_loss = 1.1927914818224963, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 400, train_loss = 1.1904562351701315, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 401, train_loss = 1.188200761884218, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 402, train_loss = 1.1859726136026438, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 403, train_loss = 1.1836724964377936, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 404, train_loss = 1.1815182827413082, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 405, train_loss = 1.1792797607777175, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 406, train_loss = 1.1770546659827232, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 407, train_loss = 1.1749047649500426, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 408, train_loss = 1.1727007938025054, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 409, train_loss = 1.1705958656966686, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 410, train_loss = 1.1683775087294634, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 411, train_loss = 1.1662119626998901, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "9th- epoch: 412, train_loss = 1.1641342391667422, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 413, train_loss = 1.161986656486988, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 414, train_loss = 1.15992377573275, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 415, train_loss = 1.1577999355795328, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 416, train_loss = 1.1557385039923247, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 417, train_loss = 1.153696241468424, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 418, train_loss = 1.1516212622227613, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 419, train_loss = 1.1495707159338053, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 420, train_loss = 1.1475517079234123, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 421, train_loss = 1.145588925719494, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 422, train_loss = 1.1435350167157594, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 423, train_loss = 1.141596045345068, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 424, train_loss = 1.1395896971225739, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 425, train_loss = 1.1376395387051161, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 426, train_loss = 1.1357211520371493, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 427, train_loss = 1.1337666809558868, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 428, train_loss = 1.1318442622723524, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 429, train_loss = 1.1299458506109659, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 430, train_loss = 1.1280498268606607, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 431, train_loss = 1.1260986986162607, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 432, train_loss = 1.1242553194460925, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 433, train_loss = 1.1224561954441015, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 434, train_loss = 1.1205333160760347, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 435, train_loss = 1.1186989210546017, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 436, train_loss = 1.1168576776981354, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 437, train_loss = 1.1150574820640031, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 438, train_loss = 1.1132530135510024, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 439, train_loss = 1.1114030679163989, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 440, train_loss = 1.1096043648722116, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 441, train_loss = 1.1078152507543564, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 442, train_loss = 1.1060760704276618, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 443, train_loss = 1.1042511512932833, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 444, train_loss = 1.1025396833720151, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 445, train_loss = 1.1007773528399412, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9th- epoch: 446, train_loss = 1.0990448569355067, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 447, train_loss = 1.0973517397942487, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 448, train_loss = 1.095593294739956, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 449, train_loss = 1.0938663532433566, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 450, train_loss = 1.092220605671173, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 451, train_loss = 1.0905612657370511, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 452, train_loss = 1.0888562264444772, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 453, train_loss = 1.0872166591288988, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 454, train_loss = 1.0854652797279414, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 455, train_loss = 1.0838242458703462, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 456, train_loss = 1.082211472094059, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 457, train_loss = 1.0806981138885021, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 458, train_loss = 1.0789524118008558, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 459, train_loss = 1.0773836374282837, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 460, train_loss = 1.0757803705928382, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 461, train_loss = 1.0741778947412968, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 462, train_loss = 1.0726331248879433, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 463, train_loss = 1.0710022163984831, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 464, train_loss = 1.0693865281937178, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 465, train_loss = 1.0678711471555289, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 466, train_loss = 1.0662811510264874, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 467, train_loss = 1.0647427824733313, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 468, train_loss = 1.0632562885584775, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 469, train_loss = 1.0616824912431184, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 470, train_loss = 1.0600467212498188, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 471, train_loss = 1.0586427127418574, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 472, train_loss = 1.0571392551064491, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 473, train_loss = 1.0556211968360003, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 474, train_loss = 1.0541074337961618, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 475, train_loss = 1.0526838265359402, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 476, train_loss = 1.0511705266835634, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 477, train_loss = 1.0497465530934278, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 478, train_loss = 1.048174229770666, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 479, train_loss = 1.0467844208178576, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 480, train_loss = 1.045351573586231, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 481, train_loss = 1.0439043877122458, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 482, train_loss = 1.0425438260135707, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 483, train_loss = 1.0409922239778098, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 484, train_loss = 1.0396683191356715, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 485, train_loss = 1.0382506921887398, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 486, train_loss = 1.0368256829679012, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 487, train_loss = 1.035379377513891, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 488, train_loss = 1.0339899634418543, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 489, train_loss = 1.0327161699533463, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 490, train_loss = 1.0312993141415063, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 491, train_loss = 1.02990665906691, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 492, train_loss = 1.0284780537185725, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 493, train_loss = 1.0271730261447374, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 494, train_loss = 1.0259090811014175, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 495, train_loss = 1.0244891345500946, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 496, train_loss = 1.0230830051004887, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 497, train_loss = 1.0218737907707691, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 498, train_loss = 1.0205051973462105, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "9th- epoch: 499, train_loss = 1.0192286992969457, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|█████████████████████▎                                                 | 9/30 [1:01:08<2:23:09, 409.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "10th- epoch: 0, train_loss = 272.06975758075714, train_acc = 0.4632044713553796\n",
      "test Acc 0.5577281191806331:\n",
      "10th- epoch: 1, train_loss = 204.78574299812317, train_acc = 0.5578714485328365\n",
      "test Acc 0.5633147113594041:\n",
      "10th- epoch: 2, train_loss = 159.78799039125443, train_acc = 0.58011178388449\n",
      "test Acc 0.6219739292364991:\n",
      "10th- epoch: 3, train_loss = 134.36815232038498, train_acc = 0.6739636702375408\n",
      "test Acc 0.7271880819366853:\n",
      "10th- epoch: 4, train_loss = 116.00730985403061, train_acc = 0.7401024685607824\n",
      "test Acc 0.7583798882681564:\n",
      "10th- epoch: 5, train_loss = 100.93065190315247, train_acc = 0.7611783884489987\n",
      "test Acc 0.7732774674115456:\n",
      "10th- epoch: 6, train_loss = 88.6639549434185, train_acc = 0.7779459711224965\n",
      "test Acc 0.7914338919925512:\n",
      "10th- epoch: 7, train_loss = 78.77865266799927, train_acc = 0.803213786679087\n",
      "test Acc 0.8161080074487895:\n",
      "10th- epoch: 8, train_loss = 70.52928519248962, train_acc = 0.8302282254308337\n",
      "test Acc 0.8477653631284916:\n",
      "10th- epoch: 9, train_loss = 63.417556405067444, train_acc = 0.8589892873777364\n",
      "test Acc 0.8631284916201117:\n",
      "10th- epoch: 10, train_loss = 57.205161705613136, train_acc = 0.8864694923148579\n",
      "test Acc 0.8933891992551211:\n",
      "10th- epoch: 11, train_loss = 51.76109462976456, train_acc = 0.9046343735444806\n",
      "test Acc 0.9152700186219739:\n",
      "10th- epoch: 12, train_loss = 46.99271059036255, train_acc = 0.9233814625058221\n",
      "test Acc 0.9324953445065177:\n",
      "10th- epoch: 13, train_loss = 42.81821309030056, train_acc = 0.9338612016767582\n",
      "test Acc 0.9352886405959032:\n",
      "10th- epoch: 14, train_loss = 39.186208337545395, train_acc = 0.9371215649743828\n",
      "test Acc 0.9380819366852886:\n",
      "10th- epoch: 15, train_loss = 36.04856413602829, train_acc = 0.9395668374476013\n",
      "test Acc 0.9408752327746741:\n",
      "10th- epoch: 16, train_loss = 33.34918077290058, train_acc = 0.941895668374476\n",
      "test Acc 0.9432029795158287:\n",
      "10th- epoch: 17, train_loss = 31.028371535241604, train_acc = 0.9443409408476945\n",
      "test Acc 0.9478584729981379:\n",
      "10th- epoch: 18, train_loss = 29.0342850163579, train_acc = 0.9471355379599441\n",
      "test Acc 0.9529795158286778:\n",
      "10th- epoch: 19, train_loss = 27.31458142399788, train_acc = 0.9530740568234746\n",
      "test Acc 0.9539106145251397:\n",
      "10th- epoch: 20, train_loss = 25.82111433148384, train_acc = 0.9545877969259432\n",
      "test Acc 0.9557728119180633:\n",
      "10th- epoch: 21, train_loss = 24.51565843820572, train_acc = 0.9568001863064741\n",
      "test Acc 0.9567039106145251:\n",
      "10th- epoch: 22, train_loss = 23.366479959338903, train_acc = 0.9585468095016302\n",
      "test Acc 0.957635009310987:\n",
      "10th- epoch: 23, train_loss = 22.348147466778755, train_acc = 0.9601769911504425\n",
      "test Acc 0.957635009310987:\n",
      "10th- epoch: 24, train_loss = 21.438524831086397, train_acc = 0.9613414066138798\n",
      "test Acc 0.9585661080074488:\n",
      "10th- epoch: 25, train_loss = 20.6190773434937, train_acc = 0.9623893805309734\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 26, train_loss = 19.875417795032263, train_acc = 0.9635537959944108\n",
      "test Acc 0.9599627560521415:\n",
      "10th- epoch: 27, train_loss = 19.19616236910224, train_acc = 0.9641360037261295\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 28, train_loss = 18.56960942223668, train_acc = 0.9653004191895669\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 29, train_loss = 17.98947248235345, train_acc = 0.9662319515603167\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 30, train_loss = 17.450296487659216, train_acc = 0.9671634839310667\n",
      "test Acc 0.9604283054003724:\n",
      "10th- epoch: 31, train_loss = 16.947156954556704, train_acc = 0.9679785747554728\n",
      "test Acc 0.9613594040968343:\n",
      "10th- epoch: 32, train_loss = 16.476169530302286, train_acc = 0.9689101071262226\n",
      "test Acc 0.9622905027932961:\n",
      "10th- epoch: 33, train_loss = 16.033957459032536, train_acc = 0.9697251979506288\n",
      "test Acc 0.962756052141527:\n",
      "10th- epoch: 34, train_loss = 15.617173835635185, train_acc = 0.9699580810433163\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 35, train_loss = 15.223471026867628, train_acc = 0.9707731718677224\n",
      "test Acc 0.9632216014897579:\n",
      "10th- epoch: 36, train_loss = 14.850752957165241, train_acc = 0.9719375873311598\n",
      "test Acc 0.9650837988826816:\n",
      "10th- epoch: 37, train_loss = 14.497501913458109, train_acc = 0.9727526781555659\n",
      "test Acc 0.9692737430167597:\n",
      "10th- epoch: 38, train_loss = 14.162630070000887, train_acc = 0.9735677689799721\n",
      "test Acc 0.9711359404096834:\n",
      "10th- epoch: 39, train_loss = 13.844095010310411, train_acc = 0.9742664182580345\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 40, train_loss = 13.540781456977129, train_acc = 0.9746157428970657\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 41, train_loss = 13.251327633857727, train_acc = 0.9749650675360969\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 42, train_loss = 12.975037723779678, train_acc = 0.9756637168141593\n",
      "test Acc 0.9720670391061452:\n",
      "10th- epoch: 43, train_loss = 12.710579816251993, train_acc = 0.9761294829995343\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 44, train_loss = 12.456984784454107, train_acc = 0.9776432231020028\n",
      "test Acc 0.9725325884543762:\n",
      "10th- epoch: 45, train_loss = 12.21379018574953, train_acc = 0.9778761061946902\n",
      "test Acc 0.9739292364990689:\n",
      "10th- epoch: 46, train_loss = 11.980300154536963, train_acc = 0.9784583139264089\n",
      "test Acc 0.9743947858472998:\n",
      "10th- epoch: 47, train_loss = 11.755662515759468, train_acc = 0.9788076385654402\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 48, train_loss = 11.53952882066369, train_acc = 0.9792734047508151\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 49, train_loss = 11.331474982202053, train_acc = 0.97973917093619\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 50, train_loss = 11.1302923373878, train_acc = 0.97973917093619\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 51, train_loss = 10.935857623815536, train_acc = 0.9800884955752213\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 52, train_loss = 10.748110685497522, train_acc = 0.9803213786679087\n",
      "test Acc 0.9753258845437617:\n",
      "10th- epoch: 53, train_loss = 10.566599503159523, train_acc = 0.9805542617605962\n",
      "test Acc 0.9757914338919925:\n",
      "10th- epoch: 54, train_loss = 10.39087445475161, train_acc = 0.98067070330694\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 55, train_loss = 10.220378134399652, train_acc = 0.9807871448532837\n",
      "test Acc 0.9767225325884544:\n",
      "10th- epoch: 56, train_loss = 10.054837284609675, train_acc = 0.9810200279459711\n",
      "test Acc 0.9771880819366853:\n",
      "10th- epoch: 57, train_loss = 9.89403871446848, train_acc = 0.9812529110386586\n",
      "test Acc 0.9776536312849162:\n",
      "10th- epoch: 58, train_loss = 9.737779406830668, train_acc = 0.9816022356776898\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 59, train_loss = 9.585738228634, train_acc = 0.9817186772240335\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 60, train_loss = 9.437799658626318, train_acc = 0.9821844434094085\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 61, train_loss = 9.293818026781082, train_acc = 0.9826502095947834\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 62, train_loss = 9.15335731767118, train_acc = 0.9829995342338146\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 63, train_loss = 9.016414234414697, train_acc = 0.9829995342338146\n",
      "test Acc 0.9781191806331471:\n",
      "10th- epoch: 64, train_loss = 8.882855907082558, train_acc = 0.9832324173265021\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 65, train_loss = 8.752390917390585, train_acc = 0.9833488588728458\n",
      "test Acc 0.978584729981378:\n",
      "10th- epoch: 66, train_loss = 8.624921452254057, train_acc = 0.9833488588728458\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 67, train_loss = 8.50037513487041, train_acc = 0.9833488588728458\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 68, train_loss = 8.378436353057623, train_acc = 0.983698183511877\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 69, train_loss = 8.258975775912404, train_acc = 0.9839310666045645\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 70, train_loss = 8.142118413001299, train_acc = 0.9840475081509082\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 71, train_loss = 8.027828987687826, train_acc = 0.9842803912435957\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 72, train_loss = 7.915916092693806, train_acc = 0.9845132743362832\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 73, train_loss = 7.8062687665224075, train_acc = 0.9846297158826269\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 74, train_loss = 7.6988470908254385, train_acc = 0.9847461574289706\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 75, train_loss = 7.593666858971119, train_acc = 0.9848625989753144\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 76, train_loss = 7.49074824899435, train_acc = 0.9849790405216581\n",
      "test Acc 0.9799813780260708:\n",
      "10th- epoch: 77, train_loss = 7.389685422182083, train_acc = 0.9849790405216581\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 78, train_loss = 7.29072680324316, train_acc = 0.9852119236143456\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 79, train_loss = 7.193587658926845, train_acc = 0.9853283651606893\n",
      "test Acc 0.979050279329609:\n",
      "10th- epoch: 80, train_loss = 7.098304446786642, train_acc = 0.9855612482533768\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 81, train_loss = 7.004897823557258, train_acc = 0.9856776897997206\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 82, train_loss = 6.913146700710058, train_acc = 0.9860270144387517\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 83, train_loss = 6.8230322152376175, train_acc = 0.986376339077783\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 84, train_loss = 6.73473783954978, train_acc = 0.9868421052631579\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 85, train_loss = 6.6478782799094915, train_acc = 0.9870749883558454\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 86, train_loss = 6.562431685626507, train_acc = 0.9873078714485328\n",
      "test Acc 0.9795158286778398:\n",
      "10th- epoch: 87, train_loss = 6.478628555312753, train_acc = 0.9876571960875641\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 88, train_loss = 6.396295526996255, train_acc = 0.9878900791802515\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 89, train_loss = 6.3156307358294725, train_acc = 0.9881229622729389\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 90, train_loss = 6.236580636352301, train_acc = 0.9881229622729389\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 91, train_loss = 6.158981131389737, train_acc = 0.9883558453656265\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 92, train_loss = 6.082901492714882, train_acc = 0.9883558453656265\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 93, train_loss = 6.008146746084094, train_acc = 0.9887051700046576\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 94, train_loss = 5.934899086132646, train_acc = 0.9887051700046576\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 95, train_loss = 5.862819090485573, train_acc = 0.9889380530973452\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 96, train_loss = 5.792300442233682, train_acc = 0.9891709361900326\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 97, train_loss = 5.7230095732957125, train_acc = 0.98940381928272\n",
      "test Acc 0.9804469273743017:\n",
      "10th- epoch: 98, train_loss = 5.655207950621843, train_acc = 0.9896367023754076\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 99, train_loss = 5.5885470770299435, train_acc = 0.9897531439217513\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 100, train_loss = 5.523177225142717, train_acc = 0.989869585468095\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 101, train_loss = 5.459024138748646, train_acc = 0.989869585468095\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 102, train_loss = 5.39612096734345, train_acc = 0.989869585468095\n",
      "test Acc 0.9809124767225326:\n",
      "10th- epoch: 103, train_loss = 5.334363202564418, train_acc = 0.989869585468095\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 104, train_loss = 5.273750643245876, train_acc = 0.9897531439217513\n",
      "test Acc 0.9813780260707635:\n",
      "10th- epoch: 105, train_loss = 5.214222063310444, train_acc = 0.989869585468095\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 106, train_loss = 5.155760399065912, train_acc = 0.9902189101071263\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 107, train_loss = 5.098350819200277, train_acc = 0.99033535165347\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 108, train_loss = 5.0419841995462775, train_acc = 0.990801117838845\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 109, train_loss = 4.986553783528507, train_acc = 0.9912668840242198\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 110, train_loss = 4.932193596847355, train_acc = 0.9912668840242198\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 111, train_loss = 4.878720711916685, train_acc = 0.9913833255705635\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 112, train_loss = 4.8261256432160735, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "10th- epoch: 113, train_loss = 4.774351729080081, train_acc = 0.9914997671169073\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 114, train_loss = 4.723449124954641, train_acc = 0.9914997671169073\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 115, train_loss = 4.673328057862818, train_acc = 0.9914997671169073\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 116, train_loss = 4.62403370719403, train_acc = 0.9916162086632511\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 117, train_loss = 4.575674092397094, train_acc = 0.9916162086632511\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 118, train_loss = 4.5280705615878105, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 119, train_loss = 4.481260747648776, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 120, train_loss = 4.4354465855285525, train_acc = 0.992081974848626\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 121, train_loss = 4.39029489364475, train_acc = 0.9921984163949698\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 122, train_loss = 4.346141387708485, train_acc = 0.9925477410340009\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 123, train_loss = 4.302539232186973, train_acc = 0.9926641825803446\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 124, train_loss = 4.259718674235046, train_acc = 0.9926641825803446\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 125, train_loss = 4.217580900527537, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 126, train_loss = 4.176056046970189, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 127, train_loss = 4.135217919014394, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 128, train_loss = 4.095057376660407, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 129, train_loss = 4.055524365976453, train_acc = 0.9930135072193759\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 130, train_loss = 4.016542705707252, train_acc = 0.9931299487657196\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 131, train_loss = 3.978386386297643, train_acc = 0.9931299487657196\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 132, train_loss = 3.940811119042337, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 133, train_loss = 3.9036860456690192, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 134, train_loss = 3.867408520542085, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 135, train_loss = 3.831514940597117, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 136, train_loss = 3.7962487172335386, train_acc = 0.9935957149510946\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 137, train_loss = 3.761621472425759, train_acc = 0.9935957149510946\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 138, train_loss = 3.7273816084489226, train_acc = 0.9935957149510946\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 139, train_loss = 3.6937503460794687, train_acc = 0.9935957149510946\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 140, train_loss = 3.6606837129220366, train_acc = 0.9935957149510946\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 141, train_loss = 3.628116961568594, train_acc = 0.9935957149510946\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 142, train_loss = 3.5959464088082314, train_acc = 0.9937121564974383\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 143, train_loss = 3.564376807305962, train_acc = 0.9937121564974383\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 144, train_loss = 3.5332481376826763, train_acc = 0.9937121564974383\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 145, train_loss = 3.5024733473546803, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 146, train_loss = 3.4721136107109487, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 147, train_loss = 3.442236423958093, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 148, train_loss = 3.412853516638279, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 149, train_loss = 3.383846792858094, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 150, train_loss = 3.355252866167575, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 151, train_loss = 3.3270533778704703, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 152, train_loss = 3.2993000079877675, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 153, train_loss = 3.2719177715480328, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 154, train_loss = 3.2448501344770193, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 155, train_loss = 3.2182807102799416, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 156, train_loss = 3.191988855600357, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 157, train_loss = 3.1661810483783484, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 158, train_loss = 3.1407723147422075, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 159, train_loss = 3.1156089096330106, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 160, train_loss = 3.0909610805101693, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 161, train_loss = 3.066471667960286, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 162, train_loss = 3.042460198048502, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 163, train_loss = 3.0188030381686985, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 164, train_loss = 2.99536513723433, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 165, train_loss = 2.972417817916721, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 166, train_loss = 2.9496354162693024, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 167, train_loss = 2.9273092611692846, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 168, train_loss = 2.905053655151278, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 169, train_loss = 2.883311713580042, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 170, train_loss = 2.8617817354388535, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 171, train_loss = 2.840503950137645, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 172, train_loss = 2.81968843517825, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 173, train_loss = 2.798988797236234, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 174, train_loss = 2.7785778804682195, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 175, train_loss = 2.7585611906833947, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "10th- epoch: 176, train_loss = 2.7387750833295286, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 177, train_loss = 2.7192920576781034, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 178, train_loss = 2.700030088890344, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 179, train_loss = 2.6811759509146214, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 180, train_loss = 2.6622921130619943, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 181, train_loss = 2.6437614541500807, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 182, train_loss = 2.6256509497761726, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 183, train_loss = 2.607649252284318, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 184, train_loss = 2.5898641236126423, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 185, train_loss = 2.5724286609329283, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 186, train_loss = 2.555091720074415, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 187, train_loss = 2.5380148459225893, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 188, train_loss = 2.5212173871695995, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 189, train_loss = 2.5045599355362356, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 190, train_loss = 2.4882028778083622, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 191, train_loss = 2.47202678443864, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 192, train_loss = 2.4560699004214257, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 193, train_loss = 2.440305904718116, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 194, train_loss = 2.4248144291341305, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 195, train_loss = 2.4094907231628895, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 196, train_loss = 2.3944196111988276, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 197, train_loss = 2.3795125547330827, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 198, train_loss = 2.3647822979837656, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 199, train_loss = 2.350266083376482, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 200, train_loss = 2.335955925285816, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 201, train_loss = 2.321746629429981, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 202, train_loss = 2.307833731174469, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 203, train_loss = 2.294078019214794, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 204, train_loss = 2.2805113065987825, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 205, train_loss = 2.267042076215148, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 206, train_loss = 2.253787349211052, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 207, train_loss = 2.2406919561326504, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 208, train_loss = 2.2278672934044152, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 209, train_loss = 2.215094828279689, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 210, train_loss = 2.2025469678919762, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 211, train_loss = 2.190140651538968, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 212, train_loss = 2.1779533128719777, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 213, train_loss = 2.1658445422071964, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 214, train_loss = 2.1539611995685846, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "10th- epoch: 215, train_loss = 2.142182622803375, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 216, train_loss = 2.130537312477827, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 217, train_loss = 2.119147053686902, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 218, train_loss = 2.1077553778886795, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 219, train_loss = 2.0966536987107247, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 220, train_loss = 2.0856244035530835, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 221, train_loss = 2.0747093081008643, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 222, train_loss = 2.0639017894864082, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 223, train_loss = 2.053298331098631, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 224, train_loss = 2.0427712600212544, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 225, train_loss = 2.0325060293544084, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 226, train_loss = 2.022244566353038, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 227, train_loss = 2.012132437201217, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 228, train_loss = 2.0021470442879945, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 229, train_loss = 1.9922966312151402, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 230, train_loss = 1.9824819054920226, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 231, train_loss = 1.972957308171317, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 232, train_loss = 1.9633536722976714, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 233, train_loss = 1.9539834663737565, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 234, train_loss = 1.9446946557145566, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 235, train_loss = 1.935442728921771, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 236, train_loss = 1.9264662705827504, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 237, train_loss = 1.917497094720602, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 238, train_loss = 1.9086264353245497, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 239, train_loss = 1.8998457826673985, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 240, train_loss = 1.89130002935417, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 241, train_loss = 1.8826965794432908, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 242, train_loss = 1.8741734407376498, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 243, train_loss = 1.8659165035933256, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 244, train_loss = 1.8576347373891622, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 245, train_loss = 1.8494622681755573, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 246, train_loss = 1.8414354443084449, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 247, train_loss = 1.83347730897367, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 248, train_loss = 1.8255417987238616, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "10th- epoch: 249, train_loss = 1.8178133319597691, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 250, train_loss = 1.8101142805535346, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 251, train_loss = 1.8024266585707664, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 252, train_loss = 1.7949251048266888, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 253, train_loss = 1.7874607082922012, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 254, train_loss = 1.780039059696719, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 255, train_loss = 1.772779818624258, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "10th- epoch: 256, train_loss = 1.7655435713240877, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 257, train_loss = 1.7583598122000694, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 258, train_loss = 1.7513753758976236, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 259, train_loss = 1.7442672165343538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 260, train_loss = 1.7373573035001755, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 261, train_loss = 1.7305133739719167, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 262, train_loss = 1.7236908139893785, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 263, train_loss = 1.7170561080565676, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 264, train_loss = 1.710418930859305, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 265, train_loss = 1.703799175680615, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 266, train_loss = 1.6972795774927363, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 267, train_loss = 1.6908207908272743, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 268, train_loss = 1.6845335165271536, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 269, train_loss = 1.678120364784263, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 270, train_loss = 1.6719692846527323, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 271, train_loss = 1.6657328171422705, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 272, train_loss = 1.6596547787776217, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 273, train_loss = 1.6535998372128233, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 274, train_loss = 1.6475802659988403, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 275, train_loss = 1.6417488232254982, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 276, train_loss = 1.6358014406869188, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 277, train_loss = 1.63000327849295, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 278, train_loss = 1.6242159195244312, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 279, train_loss = 1.6185762906679884, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 280, train_loss = 1.6128838720032945, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 281, train_loss = 1.6072773324558511, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 282, train_loss = 1.601836067973636, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 283, train_loss = 1.5962829738855362, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 284, train_loss = 1.5909130772342905, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 285, train_loss = 1.585460769594647, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 286, train_loss = 1.580183578073047, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 287, train_loss = 1.574884576140903, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 288, train_loss = 1.5696669878670946, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 289, train_loss = 1.5644538352498785, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 290, train_loss = 1.5593779856571928, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 291, train_loss = 1.5542392631759867, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 292, train_loss = 1.549166145385243, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 293, train_loss = 1.5442102974047884, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 294, train_loss = 1.5392389222979546, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10th- epoch: 295, train_loss = 1.534285195171833, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 296, train_loss = 1.5295220477273688, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 297, train_loss = 1.5245580734917894, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 298, train_loss = 1.5198760567000136, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 299, train_loss = 1.5150669453432783, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 300, train_loss = 1.5104277009377256, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 301, train_loss = 1.5057026023278013, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 302, train_loss = 1.5011326844105497, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 303, train_loss = 1.4964983885874972, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 304, train_loss = 1.4919648865470663, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 305, train_loss = 1.4874043861636892, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 306, train_loss = 1.4829866476356983, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 307, train_loss = 1.4785085743060336, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 308, train_loss = 1.4741897011408582, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 309, train_loss = 1.469737625331618, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 310, train_loss = 1.4655724255135283, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 311, train_loss = 1.461198461591266, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 312, train_loss = 1.457039263099432, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 313, train_loss = 1.4527528485050425, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 314, train_loss = 1.4486410034587607, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 315, train_loss = 1.4444936910877004, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 316, train_loss = 1.4404208660125732, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 317, train_loss = 1.4363797791302204, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 318, train_loss = 1.4323644265532494, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 319, train_loss = 1.4283119750907645, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 320, train_loss = 1.4243511570384726, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 321, train_loss = 1.4204739952692762, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 322, train_loss = 1.416583133279346, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 323, train_loss = 1.4126480905106291, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 324, train_loss = 1.4088880084455013, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 325, train_loss = 1.4049503220012411, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 326, train_loss = 1.4012825215468183, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 327, train_loss = 1.3974785804748535, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 328, train_loss = 1.3938207601895556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 329, train_loss = 1.3900332599878311, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 330, train_loss = 1.3863962603500113, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 331, train_loss = 1.3828132698545232, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 332, train_loss = 1.3792254589498043, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 333, train_loss = 1.3756138967582956, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 334, train_loss = 1.3721020991215482, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 335, train_loss = 1.3684994081850164, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 336, train_loss = 1.365127692639362, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 337, train_loss = 1.3615205784444697, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 338, train_loss = 1.3581980380113237, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 339, train_loss = 1.354700431227684, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 340, train_loss = 1.3513470540638082, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 341, train_loss = 1.3479582729632966, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 342, train_loss = 1.3446582953329198, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 343, train_loss = 1.3411724704201333, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 344, train_loss = 1.3380783039028756, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 345, train_loss = 1.3347877338528633, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 346, train_loss = 1.3316041839425452, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 347, train_loss = 1.3283279773895629, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 348, train_loss = 1.3251232181792147, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 349, train_loss = 1.3219919961993583, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 350, train_loss = 1.318912009417545, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 351, train_loss = 1.3157538871164434, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 352, train_loss = 1.3125922977924347, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 353, train_loss = 1.3096350108389743, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 354, train_loss = 1.3065192811191082, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 355, train_loss = 1.3035222391481511, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 356, train_loss = 1.3005247674882412, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 357, train_loss = 1.297512248158455, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 358, train_loss = 1.2945971637964249, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 359, train_loss = 1.2916887079481967, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 360, train_loss = 1.2886073738336563, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 361, train_loss = 1.2858096423442475, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 362, train_loss = 1.2829220394487493, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 363, train_loss = 1.2799604547326453, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 364, train_loss = 1.2772200244362466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 365, train_loss = 1.2744734336738475, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 366, train_loss = 1.2715449717943557, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 367, train_loss = 1.2688860197667964, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 368, train_loss = 1.2661062230472453, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 369, train_loss = 1.2632704985444434, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 370, train_loss = 1.260555174201727, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 371, train_loss = 1.2579004876315594, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 372, train_loss = 1.2550594682688825, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "10th- epoch: 373, train_loss = 1.2526191510260105, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 374, train_loss = 1.2498718909919262, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 375, train_loss = 1.2473239700193517, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 376, train_loss = 1.2446008237893693, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 377, train_loss = 1.2420737792854197, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 378, train_loss = 1.2395299039781094, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 379, train_loss = 1.2368488882784732, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 380, train_loss = 1.2343699385528453, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 381, train_loss = 1.231868242204655, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 382, train_loss = 1.229242131114006, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 383, train_loss = 1.2268254160881042, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 384, train_loss = 1.2244248017668724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 385, train_loss = 1.2218421014840715, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 386, train_loss = 1.2195060129160993, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 387, train_loss = 1.2170425827498548, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 388, train_loss = 1.2146453733439557, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 389, train_loss = 1.212199007452, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 390, train_loss = 1.209852582484018, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 391, train_loss = 1.207413864613045, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 392, train_loss = 1.205068403214682, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 393, train_loss = 1.2027828954160213, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 394, train_loss = 1.2004863086040132, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 395, train_loss = 1.1980756049160846, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 396, train_loss = 1.195858970284462, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 397, train_loss = 1.1935556108946912, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 398, train_loss = 1.1912314668297768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 399, train_loss = 1.188972330361139, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 400, train_loss = 1.1867821142077446, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 401, train_loss = 1.1845117409829982, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 402, train_loss = 1.1824216644163243, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 403, train_loss = 1.180157842754852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 404, train_loss = 1.1779121060972102, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 405, train_loss = 1.1758009530603886, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 406, train_loss = 1.1736221238970757, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 407, train_loss = 1.171472116082441, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 408, train_loss = 1.1692961106891744, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 409, train_loss = 1.1672948002815247, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 410, train_loss = 1.165024655580055, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 411, train_loss = 1.16308319196105, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 412, train_loss = 1.1609722301363945, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 413, train_loss = 1.1588554469053634, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 414, train_loss = 1.1568586031789891, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 415, train_loss = 1.1547125105862506, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 416, train_loss = 1.1527411813731305, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 417, train_loss = 1.150761200755369, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 418, train_loss = 1.1487170681357384, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 419, train_loss = 1.1466114197974093, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 420, train_loss = 1.144810150086414, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 421, train_loss = 1.1427341562812217, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 422, train_loss = 1.1407128150458448, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 423, train_loss = 1.1388497625594027, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 424, train_loss = 1.136833296448458, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 425, train_loss = 1.1348942096228711, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 426, train_loss = 1.1330538814072497, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 427, train_loss = 1.1311157855088823, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 428, train_loss = 1.1291469794814475, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 429, train_loss = 1.127314015000593, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 430, train_loss = 1.1254491594736464, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 431, train_loss = 1.1234156861901283, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 432, train_loss = 1.121732113242615, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 433, train_loss = 1.119896347343456, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 434, train_loss = 1.1179755553603172, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 435, train_loss = 1.1162349060177803, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 436, train_loss = 1.114389845461119, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 437, train_loss = 1.1124679259955883, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 438, train_loss = 1.1107930305297486, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 439, train_loss = 1.1089110796456225, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 440, train_loss = 1.1071779156918637, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 441, train_loss = 1.10541620105505, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 442, train_loss = 1.1037173718214035, train_acc = 0.9979040521658128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 443, train_loss = 1.101947466522688, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 444, train_loss = 1.1002301834523678, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 445, train_loss = 1.0984604408440646, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 446, train_loss = 1.0966819027962629, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 447, train_loss = 1.0949697780015413, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 448, train_loss = 1.093376540899044, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "10th- epoch: 449, train_loss = 1.0917045213282108, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 450, train_loss = 1.0899039419891778, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 451, train_loss = 1.088327052682871, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 452, train_loss = 1.0866149117646273, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 453, train_loss = 1.0850281491875648, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 454, train_loss = 1.0832881964743137, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 455, train_loss = 1.0816911607980728, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 456, train_loss = 1.080087885260582, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 457, train_loss = 1.0784951858222485, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 458, train_loss = 1.076792842388386, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 459, train_loss = 1.0752510502934456, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 460, train_loss = 1.0736835387942847, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 461, train_loss = 1.0720005979237612, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 462, train_loss = 1.0704669853148516, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 463, train_loss = 1.0689052542147692, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 464, train_loss = 1.0673157957789954, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 465, train_loss = 1.0658452225325163, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 466, train_loss = 1.0643206350505352, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 467, train_loss = 1.0627391512098256, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 468, train_loss = 1.0612436806259211, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 469, train_loss = 1.0596580455603544, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 470, train_loss = 1.0581595127878245, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 471, train_loss = 1.0567153953015804, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 472, train_loss = 1.05521591505385, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 473, train_loss = 1.0536307096481323, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 474, train_loss = 1.0522420853376389, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 475, train_loss = 1.050803722202545, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 476, train_loss = 1.0492065337894019, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 477, train_loss = 1.0478212026355322, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 478, train_loss = 1.0463422325847205, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 479, train_loss = 1.0449509794416372, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 480, train_loss = 1.0434692265989725, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 481, train_loss = 1.0421254572866019, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 482, train_loss = 1.0405582152307034, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 483, train_loss = 1.0391870886087418, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 484, train_loss = 1.0378279834985733, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 485, train_loss = 1.0363647999765817, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 486, train_loss = 1.034924349427456, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 487, train_loss = 1.0336725041270256, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 488, train_loss = 1.032152708619833, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 489, train_loss = 1.0309363206324633, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 490, train_loss = 1.029542077332735, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 491, train_loss = 1.0280135957000311, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 492, train_loss = 1.0268350802361965, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 493, train_loss = 1.0254375810327474, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 494, train_loss = 1.0239839504065458, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 495, train_loss = 1.0227573178708553, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 496, train_loss = 1.0214339221420232, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 497, train_loss = 1.0200089116988238, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 498, train_loss = 1.0187354336085264, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "10th- epoch: 499, train_loss = 1.0174469811317977, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███████████████████████▎                                              | 10/30 [1:08:02<2:16:47, 410.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "11th- epoch: 0, train_loss = 275.6589857339859, train_acc = 0.41837447601304145\n",
      "test Acc 0.5535381750465549:\n",
      "11th- epoch: 1, train_loss = 209.76469600200653, train_acc = 0.5557755006986492\n",
      "test Acc 0.5665735567970205:\n",
      "11th- epoch: 2, train_loss = 162.8825917840004, train_acc = 0.5782487191429903\n",
      "test Acc 0.6145251396648045:\n",
      "11th- epoch: 3, train_loss = 136.61919552087784, train_acc = 0.6669771774569166\n",
      "test Acc 0.7090316573556797:\n",
      "11th- epoch: 4, train_loss = 117.15104991197586, train_acc = 0.7396367023754076\n",
      "test Acc 0.7718808193668529:\n",
      "11th- epoch: 5, train_loss = 101.25429937243462, train_acc = 0.7840009315323707\n",
      "test Acc 0.792364990689013:\n",
      "11th- epoch: 6, train_loss = 88.07469192147255, train_acc = 0.8037959944108057\n",
      "test Acc 0.8026070763500931:\n",
      "11th- epoch: 7, train_loss = 77.41857028007507, train_acc = 0.8121797857475547\n",
      "test Acc 0.8128491620111732:\n",
      "11th- epoch: 8, train_loss = 68.7232117652893, train_acc = 0.8263856544014905\n",
      "test Acc 0.8393854748603352:\n",
      "11th- epoch: 9, train_loss = 61.503583282232285, train_acc = 0.8588728458313927\n",
      "test Acc 0.8645251396648045:\n",
      "11th- epoch: 10, train_loss = 55.41862842440605, train_acc = 0.8896134140661388\n",
      "test Acc 0.9022346368715084:\n",
      "11th- epoch: 11, train_loss = 50.19464583694935, train_acc = 0.9170936190032604\n",
      "test Acc 0.9297020484171322:\n",
      "11th- epoch: 12, train_loss = 45.64994755387306, train_acc = 0.9314159292035398\n",
      "test Acc 0.9357541899441341:\n",
      "11th- epoch: 13, train_loss = 41.68478320538998, train_acc = 0.9371215649743828\n",
      "test Acc 0.9380819366852886:\n",
      "11th- epoch: 14, train_loss = 38.235688768327236, train_acc = 0.9411970190964136\n",
      "test Acc 0.9418063314711359:\n",
      "11th- epoch: 15, train_loss = 35.25344429165125, train_acc = 0.9431765253842571\n",
      "test Acc 0.9441340782122905:\n",
      "11th- epoch: 16, train_loss = 32.67890454083681, train_acc = 0.9469026548672567\n",
      "test Acc 0.9497206703910615:\n",
      "11th- epoch: 17, train_loss = 30.45706631988287, train_acc = 0.9506287843502562\n",
      "test Acc 0.9534450651769087:\n",
      "11th- epoch: 18, train_loss = 28.534030586481094, train_acc = 0.9531904983698184\n",
      "test Acc 0.9548417132216015:\n",
      "11th- epoch: 19, train_loss = 26.861479587852955, train_acc = 0.9545877969259432\n",
      "test Acc 0.9562383612662942:\n",
      "11th- epoch: 20, train_loss = 25.398811906576157, train_acc = 0.9563344201210993\n",
      "test Acc 0.957169459962756:\n",
      "11th- epoch: 21, train_loss = 24.113102950155735, train_acc = 0.9586632510479739\n",
      "test Acc 0.957635009310987:\n",
      "11th- epoch: 22, train_loss = 22.974525067955256, train_acc = 0.959944108057755\n",
      "test Acc 0.9581005586592178:\n",
      "11th- epoch: 23, train_loss = 21.95818541944027, train_acc = 0.9619236143455985\n",
      "test Acc 0.9590316573556797:\n",
      "11th- epoch: 24, train_loss = 21.044760528951883, train_acc = 0.9627387051700047\n",
      "test Acc 0.9594972067039106:\n",
      "11th- epoch: 25, train_loss = 20.21773273125291, train_acc = 0.9632044713553796\n",
      "test Acc 0.9599627560521415:\n",
      "11th- epoch: 26, train_loss = 19.464334223419428, train_acc = 0.9642524452724732\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 27, train_loss = 18.776049215346575, train_acc = 0.9647182114578482\n",
      "test Acc 0.9613594040968343:\n",
      "11th- epoch: 28, train_loss = 18.1433069370687, train_acc = 0.9658826269212856\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 29, train_loss = 17.558595038950443, train_acc = 0.9668141592920354\n",
      "test Acc 0.9618249534450651:\n",
      "11th- epoch: 30, train_loss = 17.016281221061945, train_acc = 0.9676292501164415\n",
      "test Acc 0.9622905027932961:\n",
      "11th- epoch: 31, train_loss = 16.511646904051304, train_acc = 0.9683278993945039\n",
      "test Acc 0.962756052141527:\n",
      "11th- epoch: 32, train_loss = 16.04068125039339, train_acc = 0.9694923148579413\n",
      "test Acc 0.9636871508379888:\n",
      "11th- epoch: 33, train_loss = 15.599580902606249, train_acc = 0.9703074056823474\n",
      "test Acc 0.9655493482309124:\n",
      "11th- epoch: 34, train_loss = 15.184495832771063, train_acc = 0.9711224965067536\n",
      "test Acc 0.9678770949720671:\n",
      "11th- epoch: 35, train_loss = 14.792480990290642, train_acc = 0.9719375873311598\n",
      "test Acc 0.9692737430167597:\n",
      "11th- epoch: 36, train_loss = 14.422306835651398, train_acc = 0.9731020027945971\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 37, train_loss = 14.072172999382019, train_acc = 0.9743828598043782\n",
      "test Acc 0.9702048417132216:\n",
      "11th- epoch: 38, train_loss = 13.740526705980301, train_acc = 0.9746157428970657\n",
      "test Acc 0.9706703910614525:\n",
      "11th- epoch: 39, train_loss = 13.425208680331707, train_acc = 0.9748486259897532\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 40, train_loss = 13.125508345663548, train_acc = 0.9754308337214718\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 41, train_loss = 12.840113010257483, train_acc = 0.9760130414531905\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 42, train_loss = 12.567623257637024, train_acc = 0.9768281322775967\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 43, train_loss = 12.30691048875451, train_acc = 0.9771774569166278\n",
      "test Acc 0.9716014897579144:\n",
      "11th- epoch: 44, train_loss = 12.057080302387476, train_acc = 0.9778761061946902\n",
      "test Acc 0.9720670391061452:\n",
      "11th- epoch: 45, train_loss = 11.817475974559784, train_acc = 0.9782254308337215\n",
      "test Acc 0.973463687150838:\n",
      "11th- epoch: 46, train_loss = 11.58748186007142, train_acc = 0.9793898462971589\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 47, train_loss = 11.366335794329643, train_acc = 0.9798556124825337\n",
      "test Acc 0.9743947858472998:\n",
      "11th- epoch: 48, train_loss = 11.153288442641497, train_acc = 0.9805542617605962\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 49, train_loss = 10.948099508881569, train_acc = 0.9809035863996274\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 50, train_loss = 10.750271417200565, train_acc = 0.9811364694923148\n",
      "test Acc 0.9748603351955307:\n",
      "11th- epoch: 51, train_loss = 10.559236872941256, train_acc = 0.9813693525850024\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 52, train_loss = 10.374843070283532, train_acc = 0.9812529110386586\n",
      "test Acc 0.9762569832402235:\n",
      "11th- epoch: 53, train_loss = 10.196486167609692, train_acc = 0.9813693525850024\n",
      "test Acc 0.9767225325884544:\n",
      "11th- epoch: 54, train_loss = 10.023968489840627, train_acc = 0.9816022356776898\n",
      "test Acc 0.9771880819366853:\n",
      "11th- epoch: 55, train_loss = 9.856889018788934, train_acc = 0.9820680018630648\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 56, train_loss = 9.695009870454669, train_acc = 0.9821844434094085\n",
      "test Acc 0.9776536312849162:\n",
      "11th- epoch: 57, train_loss = 9.537956370040774, train_acc = 0.9821844434094085\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 58, train_loss = 9.385397145524621, train_acc = 0.9823008849557522\n",
      "test Acc 0.9781191806331471:\n",
      "11th- epoch: 59, train_loss = 9.237008225172758, train_acc = 0.9826502095947834\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 60, train_loss = 9.092325771227479, train_acc = 0.9826502095947834\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 61, train_loss = 8.951539790257812, train_acc = 0.9829995342338146\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 62, train_loss = 8.814487390220165, train_acc = 0.9833488588728458\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 63, train_loss = 8.681210538372397, train_acc = 0.9835817419655333\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 64, train_loss = 8.551392070949078, train_acc = 0.983698183511877\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 65, train_loss = 8.424493324011564, train_acc = 0.9840475081509082\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 66, train_loss = 8.300597006455064, train_acc = 0.984163949697252\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 67, train_loss = 8.17966316640377, train_acc = 0.9846297158826269\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 68, train_loss = 8.061229167506099, train_acc = 0.9846297158826269\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 69, train_loss = 7.945335194468498, train_acc = 0.9847461574289706\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 70, train_loss = 7.832053543999791, train_acc = 0.9850954820680019\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 71, train_loss = 7.721149638295174, train_acc = 0.9853283651606893\n",
      "test Acc 0.978584729981378:\n",
      "11th- epoch: 72, train_loss = 7.61237414367497, train_acc = 0.9856776897997206\n",
      "test Acc 0.979050279329609:\n",
      "11th- epoch: 73, train_loss = 7.5058890879154205, train_acc = 0.985910572892408\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 74, train_loss = 7.4016035329550505, train_acc = 0.985910572892408\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 75, train_loss = 7.299349306151271, train_acc = 0.9862598975314392\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 76, train_loss = 7.199072046205401, train_acc = 0.986376339077783\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 77, train_loss = 7.100955344736576, train_acc = 0.9867256637168141\n",
      "test Acc 0.9795158286778398:\n",
      "11th- epoch: 78, train_loss = 7.00473165884614, train_acc = 0.9869585468095017\n",
      "test Acc 0.9799813780260708:\n",
      "11th- epoch: 79, train_loss = 6.910252584144473, train_acc = 0.9870749883558454\n",
      "test Acc 0.9813780260707635:\n",
      "11th- epoch: 80, train_loss = 6.817472260445356, train_acc = 0.9871914299021891\n",
      "test Acc 0.9813780260707635:\n",
      "11th- epoch: 81, train_loss = 6.7265390157699585, train_acc = 0.9873078714485328\n",
      "test Acc 0.9813780260707635:\n",
      "11th- epoch: 82, train_loss = 6.637180523946881, train_acc = 0.9873078714485328\n",
      "test Acc 0.9813780260707635:\n",
      "11th- epoch: 83, train_loss = 6.549672087654471, train_acc = 0.9873078714485328\n",
      "test Acc 0.9813780260707635:\n",
      "11th- epoch: 84, train_loss = 6.463702257722616, train_acc = 0.9873078714485328\n",
      "test Acc 0.9813780260707635:\n",
      "11th- epoch: 85, train_loss = 6.379465082660317, train_acc = 0.9878900791802515\n",
      "test Acc 0.9813780260707635:\n",
      "11th- epoch: 86, train_loss = 6.2967721205204725, train_acc = 0.9878900791802515\n",
      "test Acc 0.9813780260707635:\n",
      "11th- epoch: 87, train_loss = 6.215627983212471, train_acc = 0.9881229622729389\n",
      "test Acc 0.9818435754189944:\n",
      "11th- epoch: 88, train_loss = 6.136035086587071, train_acc = 0.9882394038192828\n",
      "test Acc 0.9818435754189944:\n",
      "11th- epoch: 89, train_loss = 6.058056132867932, train_acc = 0.9883558453656265\n",
      "test Acc 0.9818435754189944:\n",
      "11th- epoch: 90, train_loss = 5.9814371187239885, train_acc = 0.9884722869119702\n",
      "test Acc 0.9818435754189944:\n",
      "11th- epoch: 91, train_loss = 5.9063344690948725, train_acc = 0.9884722869119702\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 92, train_loss = 5.83287781663239, train_acc = 0.9884722869119702\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 93, train_loss = 5.760744681581855, train_acc = 0.9884722869119702\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 94, train_loss = 5.690148748457432, train_acc = 0.9884722869119702\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 95, train_loss = 5.620761040598154, train_acc = 0.9884722869119702\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 96, train_loss = 5.552817167714238, train_acc = 0.9889380530973452\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 97, train_loss = 5.486103560775518, train_acc = 0.9892873777363763\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 98, train_loss = 5.4206087831407785, train_acc = 0.9896367023754076\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 99, train_loss = 5.356397887691855, train_acc = 0.989869585468095\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 100, train_loss = 5.293482339940965, train_acc = 0.9899860270144387\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 101, train_loss = 5.231667418032885, train_acc = 0.9902189101071263\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 102, train_loss = 5.171010513789952, train_acc = 0.9902189101071263\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 103, train_loss = 5.11137995775789, train_acc = 0.9905682347461574\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 104, train_loss = 5.0529574658721685, train_acc = 0.9905682347461574\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 105, train_loss = 4.995540694333613, train_acc = 0.9909175593851887\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 106, train_loss = 4.9391465010121465, train_acc = 0.9909175593851887\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 107, train_loss = 4.883724454790354, train_acc = 0.9910340009315324\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 108, train_loss = 4.82937220018357, train_acc = 0.9911504424778761\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 109, train_loss = 4.775974567979574, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 110, train_loss = 4.723547852598131, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 111, train_loss = 4.672041185200214, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 112, train_loss = 4.621329496614635, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "11th- epoch: 113, train_loss = 4.571627504192293, train_acc = 0.9913833255705635\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 114, train_loss = 4.522791535593569, train_acc = 0.9913833255705635\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 115, train_loss = 4.474868361838162, train_acc = 0.9914997671169073\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 116, train_loss = 4.427783325314522, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 117, train_loss = 4.381546377204359, train_acc = 0.9917326502095948\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 118, train_loss = 4.336089912801981, train_acc = 0.9921984163949698\n",
      "test Acc 0.9837057728119181:\n",
      "11th- epoch: 119, train_loss = 4.2914948919788, train_acc = 0.9923148579413135\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 120, train_loss = 4.2475557597354054, train_acc = 0.9923148579413135\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 121, train_loss = 4.204491295851767, train_acc = 0.9923148579413135\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 122, train_loss = 4.16204275470227, train_acc = 0.9923148579413135\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 123, train_loss = 4.120291540399194, train_acc = 0.9926641825803446\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 124, train_loss = 4.079214903526008, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 125, train_loss = 4.03892785962671, train_acc = 0.9928970656730322\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 126, train_loss = 3.999255039729178, train_acc = 0.9928970656730322\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 127, train_loss = 3.9603506503626704, train_acc = 0.9930135072193759\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 128, train_loss = 3.9219609424471855, train_acc = 0.9931299487657196\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 129, train_loss = 3.884327657520771, train_acc = 0.9931299487657196\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 130, train_loss = 3.8473499324172735, train_acc = 0.9930135072193759\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 131, train_loss = 3.8109534103423357, train_acc = 0.9931299487657196\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 132, train_loss = 3.7751802317798138, train_acc = 0.9934792734047508\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 133, train_loss = 3.7399400835856795, train_acc = 0.9934792734047508\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 134, train_loss = 3.705345775000751, train_acc = 0.9935957149510946\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 135, train_loss = 3.6712407702580094, train_acc = 0.9937121564974383\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 136, train_loss = 3.6377589693292975, train_acc = 0.993828598043782\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 137, train_loss = 3.6047171019017696, train_acc = 0.993828598043782\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 138, train_loss = 3.5722462963312864, train_acc = 0.993828598043782\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 139, train_loss = 3.540391913149506, train_acc = 0.993828598043782\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 140, train_loss = 3.50897982949391, train_acc = 0.9939450395901258\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 141, train_loss = 3.477986453101039, train_acc = 0.9940614811364695\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 142, train_loss = 3.447536275256425, train_acc = 0.9941779226828132\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 143, train_loss = 3.41758714010939, train_acc = 0.9941779226828132\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 144, train_loss = 3.38807177497074, train_acc = 0.9941779226828132\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 145, train_loss = 3.359072733204812, train_acc = 0.994294364229157\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 146, train_loss = 3.3303758068941534, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11th- epoch: 147, train_loss = 3.3022872819565237, train_acc = 0.9945272473218444\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 148, train_loss = 3.2744961376301944, train_acc = 0.9945272473218444\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 149, train_loss = 3.2472419030964375, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 150, train_loss = 3.2201820365153253, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 151, train_loss = 3.193716341163963, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 152, train_loss = 3.167537981644273, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 153, train_loss = 3.1417248602956533, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 154, train_loss = 3.116402140352875, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "11th- epoch: 155, train_loss = 3.091426694765687, train_acc = 0.9947601304145319\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 156, train_loss = 3.066629660781473, train_acc = 0.9948765719608756\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 157, train_loss = 3.042330406140536, train_acc = 0.9949930135072194\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 158, train_loss = 3.0182925830595195, train_acc = 0.9949930135072194\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 159, train_loss = 2.9947172668762505, train_acc = 0.9949930135072194\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 160, train_loss = 2.971276814583689, train_acc = 0.9951094550535631\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 161, train_loss = 2.9483857546001673, train_acc = 0.9951094550535631\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 162, train_loss = 2.925668563693762, train_acc = 0.9951094550535631\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 163, train_loss = 2.90342108765617, train_acc = 0.9951094550535631\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 164, train_loss = 2.8813559524714947, train_acc = 0.9952258965999069\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 165, train_loss = 2.8596017197705805, train_acc = 0.9952258965999069\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 166, train_loss = 2.8382169432006776, train_acc = 0.9952258965999069\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 167, train_loss = 2.817077599465847, train_acc = 0.9952258965999069\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 168, train_loss = 2.796187395695597, train_acc = 0.9952258965999069\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 169, train_loss = 2.7757617235183716, train_acc = 0.9952258965999069\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 170, train_loss = 2.755358074326068, train_acc = 0.9952258965999069\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 171, train_loss = 2.7353507936932147, train_acc = 0.9952258965999069\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 172, train_loss = 2.71552004897967, train_acc = 0.9953423381462506\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 173, train_loss = 2.6961723719723523, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 174, train_loss = 2.6768364454619586, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 175, train_loss = 2.6578763402067125, train_acc = 0.9956916627852818\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 176, train_loss = 2.6390543077141047, train_acc = 0.9956916627852818\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 177, train_loss = 2.620676915626973, train_acc = 0.9956916627852818\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 178, train_loss = 2.6025131046772003, train_acc = 0.9958081043316255\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 179, train_loss = 2.5844700031448156, train_acc = 0.9958081043316255\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 180, train_loss = 2.5667465284932405, train_acc = 0.9958081043316255\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 181, train_loss = 2.5493602827191353, train_acc = 0.9958081043316255\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 182, train_loss = 2.5320374730508775, train_acc = 0.9958081043316255\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 183, train_loss = 2.515178294153884, train_acc = 0.9958081043316255\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 184, train_loss = 2.498302049934864, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 185, train_loss = 2.481804442824796, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 186, train_loss = 2.4654411308001727, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 187, train_loss = 2.4493643946480006, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 188, train_loss = 2.4335391838103533, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 189, train_loss = 2.417892395751551, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 190, train_loss = 2.402408716036007, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 191, train_loss = 2.3872023709118366, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 192, train_loss = 2.372198161901906, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 193, train_loss = 2.3574082974810153, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 194, train_loss = 2.342781402170658, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 195, train_loss = 2.328366677509621, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 196, train_loss = 2.3140781361144036, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 197, train_loss = 2.300137494923547, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 198, train_loss = 2.28623083117418, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 199, train_loss = 2.27267322759144, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 200, train_loss = 2.2590842314530164, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 201, train_loss = 2.2457817022223026, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 202, train_loss = 2.232705919770524, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 203, train_loss = 2.219770436407998, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 204, train_loss = 2.2069902506191283, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 205, train_loss = 2.1942482094746083, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 206, train_loss = 2.1818395021837205, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 207, train_loss = 2.1695276976097375, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 208, train_loss = 2.1574201993644238, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 209, train_loss = 2.1453547447454184, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 210, train_loss = 2.1336548253893852, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 211, train_loss = 2.121933999704197, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 212, train_loss = 2.1104209914337844, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 213, train_loss = 2.0990868143271655, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 214, train_loss = 2.087886502267793, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 215, train_loss = 2.0767967216670513, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 216, train_loss = 2.0659230928868055, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 217, train_loss = 2.0551199845504016, train_acc = 0.9966231951560317\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 218, train_loss = 2.0444906533230096, train_acc = 0.9966231951560317\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 219, train_loss = 2.03398459777236, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "11th- epoch: 220, train_loss = 2.0235641587059945, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "11th- epoch: 221, train_loss = 2.013383048819378, train_acc = 0.9968560782487191\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 222, train_loss = 2.003231604816392, train_acc = 0.9968560782487191\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 223, train_loss = 1.993256074609235, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 224, train_loss = 1.9833711597602814, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 225, train_loss = 1.9736874394584447, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 226, train_loss = 1.9640513863414526, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 227, train_loss = 1.9545260213781148, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 228, train_loss = 1.9452543910592794, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 229, train_loss = 1.9359079897403717, train_acc = 0.9970889613414066\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 230, train_loss = 1.9267702797660604, train_acc = 0.9970889613414066\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 231, train_loss = 1.917746944935061, train_acc = 0.9970889613414066\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 232, train_loss = 1.9088844811776653, train_acc = 0.9970889613414066\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 233, train_loss = 1.9000275725265965, train_acc = 0.9970889613414066\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 234, train_loss = 1.8913550240686163, train_acc = 0.9970889613414066\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 235, train_loss = 1.8826928064227104, train_acc = 0.9970889613414066\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 236, train_loss = 1.8742418637266383, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 237, train_loss = 1.86577443650458, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 238, train_loss = 1.8575846031308174, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 239, train_loss = 1.8492974924156442, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 240, train_loss = 1.841184793622233, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 241, train_loss = 1.8332041651010513, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 242, train_loss = 1.8253340920200571, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 243, train_loss = 1.8174261251697317, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 244, train_loss = 1.8097201312193647, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 245, train_loss = 1.8020736873149872, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 246, train_loss = 1.7944533886620775, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 247, train_loss = 1.7869887053966522, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 248, train_loss = 1.7796194491675124, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 249, train_loss = 1.7722370699048042, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 250, train_loss = 1.7649927660822868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 251, train_loss = 1.7578421594807878, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 252, train_loss = 1.7507241318235174, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 253, train_loss = 1.7437226958572865, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 254, train_loss = 1.7367824403336272, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 255, train_loss = 1.7299037339398637, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 256, train_loss = 1.723160537541844, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 257, train_loss = 1.716448999941349, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 258, train_loss = 1.7097993418574333, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 259, train_loss = 1.7032308926573023, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 260, train_loss = 1.6967566224047914, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 261, train_loss = 1.6903924755752087, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 262, train_loss = 1.6839537682244554, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 263, train_loss = 1.6776790047297254, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 264, train_loss = 1.67147020122502, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 265, train_loss = 1.6653261234750971, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 266, train_loss = 1.6591708287596703, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 267, train_loss = 1.6531422721454874, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 268, train_loss = 1.6472301433095708, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 269, train_loss = 1.6412193352589384, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 270, train_loss = 1.6353729292750359, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 271, train_loss = 1.6295787742128596, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 272, train_loss = 1.6238650269806385, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 273, train_loss = 1.6181523440172896, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 274, train_loss = 1.612524300813675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 275, train_loss = 1.6068509867182001, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 276, train_loss = 1.6013309173285961, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 277, train_loss = 1.595812801271677, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 278, train_loss = 1.590410870849155, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 279, train_loss = 1.5850087031722069, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 280, train_loss = 1.5797001235187054, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 281, train_loss = 1.5744600569596514, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 282, train_loss = 1.5692168386885896, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 283, train_loss = 1.5640132812550291, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 284, train_loss = 1.558884268044494, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 285, train_loss = 1.5538179675349966, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 286, train_loss = 1.5487810634076595, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 287, train_loss = 1.5437316410243511, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 288, train_loss = 1.5388832924654707, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 289, train_loss = 1.5338660987326875, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "11th- epoch: 290, train_loss = 1.529053471982479, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 291, train_loss = 1.5242154474253766, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 292, train_loss = 1.519480897753965, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 293, train_loss = 1.5147092479164712, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 294, train_loss = 1.5100083947181702, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 295, train_loss = 1.5053755082190037, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 296, train_loss = 1.5007734621758573, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 297, train_loss = 1.4960288095171563, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 298, train_loss = 1.4914734016056173, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 299, train_loss = 1.4870069424505346, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 300, train_loss = 1.48253806802677, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 301, train_loss = 1.478161754726898, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 302, train_loss = 1.4737912763957866, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 303, train_loss = 1.4694355949759483, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 304, train_loss = 1.4652109841699712, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 305, train_loss = 1.4609160224790685, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 306, train_loss = 1.4566956360940821, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 307, train_loss = 1.452482271939516, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 308, train_loss = 1.4483892768621445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 309, train_loss = 1.4441710822284222, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 310, train_loss = 1.4401724363560788, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 311, train_loss = 1.4360316109959967, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 312, train_loss = 1.4319720678031445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 313, train_loss = 1.4280098415911198, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 314, train_loss = 1.424031684815418, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 315, train_loss = 1.4200251040165313, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 316, train_loss = 1.416149361699354, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 317, train_loss = 1.4123118072748184, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 318, train_loss = 1.4085029524867423, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 319, train_loss = 1.4046664449269883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 320, train_loss = 1.4009700405295007, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 321, train_loss = 1.397199300408829, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 322, train_loss = 1.3935307363863103, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 323, train_loss = 1.38985101506114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 324, train_loss = 1.3861521991784684, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 325, train_loss = 1.3825712576508522, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 326, train_loss = 1.3789861053228378, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 327, train_loss = 1.37544871494174, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 328, train_loss = 1.371947551786434, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 329, train_loss = 1.3684588484466076, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 330, train_loss = 1.3649245873093605, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 331, train_loss = 1.3615152103011496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 332, train_loss = 1.3580447758431546, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 333, train_loss = 1.3547395703499205, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 334, train_loss = 1.3513756468892097, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 335, train_loss = 1.347984912514221, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 336, train_loss = 1.3447028808295727, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 337, train_loss = 1.3414143659174442, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 338, train_loss = 1.3381224125623703, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 339, train_loss = 1.3349178445641883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 340, train_loss = 1.3316303404862992, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 341, train_loss = 1.3285406355862506, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 342, train_loss = 1.325305588543415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 343, train_loss = 1.3221671655774117, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 344, train_loss = 1.3190727432374842, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 345, train_loss = 1.3160031512379646, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 346, train_loss = 1.3129056505858898, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 347, train_loss = 1.3098779407446273, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 348, train_loss = 1.3067024337942712, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 349, train_loss = 1.3036178524489515, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 350, train_loss = 1.300646610558033, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 351, train_loss = 1.2975863528554328, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 352, train_loss = 1.2946107896859758, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 353, train_loss = 1.2917135668103583, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 354, train_loss = 1.2887677016551606, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 355, train_loss = 1.285870272666216, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 356, train_loss = 1.2830403235857375, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 357, train_loss = 1.2801378493313678, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 358, train_loss = 1.2773284949362278, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 359, train_loss = 1.2744621249730699, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 360, train_loss = 1.2716870221192949, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 361, train_loss = 1.2689450706238858, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 362, train_loss = 1.2661844417452812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 363, train_loss = 1.2634414210915565, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 364, train_loss = 1.2607076590065844, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 365, train_loss = 1.2580114702577703, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 366, train_loss = 1.2552949227392673, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 367, train_loss = 1.2526961527764797, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 368, train_loss = 1.2499967056210153, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 369, train_loss = 1.2474092704360373, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 370, train_loss = 1.244723980606068, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 371, train_loss = 1.2421701823477633, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 372, train_loss = 1.2396823416347615, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 373, train_loss = 1.2370853386819363, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 374, train_loss = 1.234518714249134, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "11th- epoch: 375, train_loss = 1.2320161437091883, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 376, train_loss = 1.2295086023805197, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 377, train_loss = 1.2270398450491484, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 378, train_loss = 1.2246264194545802, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 379, train_loss = 1.2221377901732922, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 380, train_loss = 1.2197322212159634, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 381, train_loss = 1.2173382056353148, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 382, train_loss = 1.2149475626647472, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 383, train_loss = 1.212500125169754, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 384, train_loss = 1.210144728422165, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 385, train_loss = 1.2078262828290462, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 386, train_loss = 1.2055175912973937, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 387, train_loss = 1.203122711420292, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 388, train_loss = 1.200861612946028, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 389, train_loss = 1.1985547455551568, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 390, train_loss = 1.1963138543069363, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 391, train_loss = 1.194032408297062, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 392, train_loss = 1.1917764954268932, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 393, train_loss = 1.1895758472383022, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 394, train_loss = 1.1873015562596265, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 395, train_loss = 1.1850990491511766, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 396, train_loss = 1.1829309972526971, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 397, train_loss = 1.1807985728082713, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 398, train_loss = 1.1785862880351488, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 399, train_loss = 1.1764418793318328, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 400, train_loss = 1.1743245770630892, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 401, train_loss = 1.1721805656852666, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 402, train_loss = 1.170052812754875, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 403, train_loss = 1.1679931059479713, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 404, train_loss = 1.1658103528025094, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 405, train_loss = 1.1637845349905547, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 406, train_loss = 1.1617252541182097, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 407, train_loss = 1.15964880460524, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 408, train_loss = 1.1576521185634192, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 409, train_loss = 1.1556162002088968, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 410, train_loss = 1.1536220870912075, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 411, train_loss = 1.1516185986401979, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 412, train_loss = 1.14962519457913, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 413, train_loss = 1.1475915225746576, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 414, train_loss = 1.1456438601016998, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 415, train_loss = 1.1436995690164622, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 416, train_loss = 1.141785687446827, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 417, train_loss = 1.1398417949676514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 418, train_loss = 1.1378990188241005, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 419, train_loss = 1.1360299860534724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 420, train_loss = 1.1341266383824404, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 421, train_loss = 1.1322603908774909, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 422, train_loss = 1.1303767350909766, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 423, train_loss = 1.1284290576877538, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 424, train_loss = 1.1266486011445522, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 425, train_loss = 1.1247469286026899, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 426, train_loss = 1.122893426567316, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 427, train_loss = 1.121127708494896, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 428, train_loss = 1.1192839716968592, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 429, train_loss = 1.1174808541836683, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 430, train_loss = 1.1156526704726275, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 431, train_loss = 1.113892987370491, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 432, train_loss = 1.1121181895432528, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 433, train_loss = 1.1103243082761765, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 434, train_loss = 1.1086586751043797, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 435, train_loss = 1.1068815775215626, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 436, train_loss = 1.1051459945738316, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 437, train_loss = 1.1033699847757816, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 438, train_loss = 1.101765693485504, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 439, train_loss = 1.1000154254434165, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 440, train_loss = 1.0982877922651824, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 441, train_loss = 1.0966346077620983, train_acc = 0.9979040521658128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 442, train_loss = 1.0949451488850173, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 443, train_loss = 1.0932331159710884, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 444, train_loss = 1.091620821505785, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 445, train_loss = 1.0899717795255128, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 446, train_loss = 1.0882219237682875, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 447, train_loss = 1.086672443896532, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 448, train_loss = 1.0850264430046082, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 449, train_loss = 1.0834771295485552, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 450, train_loss = 1.081799933075672, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 451, train_loss = 1.080241646617651, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 452, train_loss = 1.0785953737795353, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 453, train_loss = 1.0770134081540164, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 454, train_loss = 1.075447227805853, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 455, train_loss = 1.0739121586084366, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 456, train_loss = 1.0723527471127454, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 457, train_loss = 1.0707887150347233, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 458, train_loss = 1.0692272099258844, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 459, train_loss = 1.0677136145532131, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 460, train_loss = 1.0661335699260235, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 461, train_loss = 1.0646376150252763, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 462, train_loss = 1.063128607958788, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 463, train_loss = 1.0616165859100875, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 464, train_loss = 1.0601499440672342, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 465, train_loss = 1.0586506289837416, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 466, train_loss = 1.0571737959980965, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 467, train_loss = 1.0556584807636682, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 468, train_loss = 1.054258049785858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 469, train_loss = 1.0527814316155855, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 470, train_loss = 1.0513184554874897, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 471, train_loss = 1.049866863846546, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 472, train_loss = 1.048493100941414, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 473, train_loss = 1.047037205338711, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 474, train_loss = 1.0456296267511789, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 475, train_loss = 1.0441500755550805, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 476, train_loss = 1.0427840538322926, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 477, train_loss = 1.041352491825819, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 478, train_loss = 1.0399962899682578, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "11th- epoch: 479, train_loss = 1.0385981301369611, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 480, train_loss = 1.0371988651750144, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 481, train_loss = 1.035790417343378, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 482, train_loss = 1.0344796180725098, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 483, train_loss = 1.033154313772684, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 484, train_loss = 1.031742268562084, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 485, train_loss = 1.0303992418048438, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 486, train_loss = 1.0290732830762863, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 487, train_loss = 1.0277115367352962, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 488, train_loss = 1.026389241218567, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 489, train_loss = 1.0251025880425004, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 490, train_loss = 1.023753912493703, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 491, train_loss = 1.0223910150380107, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 492, train_loss = 1.0211513030080823, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 493, train_loss = 1.0197920886130305, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 494, train_loss = 1.0185504332184792, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 495, train_loss = 1.0172214011399774, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 496, train_loss = 1.015987339123967, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 497, train_loss = 1.0147164190857438, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 498, train_loss = 1.0135008941142587, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "11th- epoch: 499, train_loss = 1.0122021759598283, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████▋                                            | 11/30 [1:14:52<2:09:56, 410.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "12th- epoch: 0, train_loss = 274.5647315979004, train_acc = 0.45936190032603635\n",
      "test Acc 0.49813780260707635:\n",
      "12th- epoch: 1, train_loss = 210.8331116437912, train_acc = 0.5036096879366558\n",
      "test Acc 0.5558659217877095:\n",
      "12th- epoch: 2, train_loss = 161.7913835644722, train_acc = 0.5890777829529577\n",
      "test Acc 0.63268156424581:\n",
      "12th- epoch: 3, train_loss = 135.23166227340698, train_acc = 0.6757102934326968\n",
      "test Acc 0.7211359404096834:\n",
      "12th- epoch: 4, train_loss = 115.76741999387741, train_acc = 0.7388216115510013\n",
      "test Acc 0.7569832402234636:\n",
      "12th- epoch: 5, train_loss = 100.29210561513901, train_acc = 0.7686306474149976\n",
      "test Acc 0.7807262569832403:\n",
      "12th- epoch: 6, train_loss = 87.77942085266113, train_acc = 0.7951793199813694\n",
      "test Acc 0.7988826815642458:\n",
      "12th- epoch: 7, train_loss = 77.63831448554993, train_acc = 0.8112482533768048\n",
      "test Acc 0.8170391061452514:\n",
      "12th- epoch: 8, train_loss = 69.23000282049179, train_acc = 0.8333721471821146\n",
      "test Acc 0.8440409683426443:\n",
      "12th- epoch: 9, train_loss = 62.12981563806534, train_acc = 0.8610852352119236\n",
      "test Acc 0.8696461824953445:\n",
      "12th- epoch: 10, train_loss = 56.0789582580328, train_acc = 0.8892640894271076\n",
      "test Acc 0.8961824953445066:\n",
      "12th- epoch: 11, train_loss = 50.8746652007103, train_acc = 0.9076618537494178\n",
      "test Acc 0.9175977653631285:\n",
      "12th- epoch: 12, train_loss = 46.363142386078835, train_acc = 0.9237307871448532\n",
      "test Acc 0.9329608938547486:\n",
      "12th- epoch: 13, train_loss = 42.430613592267036, train_acc = 0.9314159292035398\n",
      "test Acc 0.936219739292365:\n",
      "12th- epoch: 14, train_loss = 38.9999720454216, train_acc = 0.936190032603633\n",
      "test Acc 0.9380819366852886:\n",
      "12th- epoch: 15, train_loss = 36.00849720835686, train_acc = 0.94014904517932\n",
      "test Acc 0.9418063314711359:\n",
      "12th- epoch: 16, train_loss = 33.40728134661913, train_acc = 0.9437587331159758\n",
      "test Acc 0.9450651769087524:\n",
      "12th- epoch: 17, train_loss = 31.149430356919765, train_acc = 0.945388914764788\n",
      "test Acc 0.9497206703910615:\n",
      "12th- epoch: 18, train_loss = 29.18924742937088, train_acc = 0.9492314857941313\n",
      "test Acc 0.9543761638733705:\n",
      "12th- epoch: 19, train_loss = 27.484768368303776, train_acc = 0.9536562645551933\n",
      "test Acc 0.9548417132216015:\n",
      "12th- epoch: 20, train_loss = 25.99587332457304, train_acc = 0.9551700046576619\n",
      "test Acc 0.9557728119180633:\n",
      "12th- epoch: 21, train_loss = 24.68611241877079, train_acc = 0.9570330693991617\n",
      "test Acc 0.9562383612662942:\n",
      "12th- epoch: 22, train_loss = 23.52639666199684, train_acc = 0.9590125756870052\n",
      "test Acc 0.957169459962756:\n",
      "12th- epoch: 23, train_loss = 22.494361240416765, train_acc = 0.9601769911504425\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 24, train_loss = 21.5696564540267, train_acc = 0.9612249650675361\n",
      "test Acc 0.9594972067039106:\n",
      "12th- epoch: 25, train_loss = 20.73548986017704, train_acc = 0.9628551467163484\n",
      "test Acc 0.9604283054003724:\n",
      "12th- epoch: 26, train_loss = 19.978376157581806, train_acc = 0.9642524452724732\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 27, train_loss = 19.288154911249876, train_acc = 0.9650675360968793\n",
      "test Acc 0.9599627560521415:\n",
      "12th- epoch: 28, train_loss = 18.65470364317298, train_acc = 0.965649743828598\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 29, train_loss = 18.06934480369091, train_acc = 0.966115510013973\n",
      "test Acc 0.9613594040968343:\n",
      "12th- epoch: 30, train_loss = 17.526010297238827, train_acc = 0.9666977177456917\n",
      "test Acc 0.9618249534450651:\n",
      "12th- epoch: 31, train_loss = 17.020459294319153, train_acc = 0.9672799254774104\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 32, train_loss = 16.547414604574442, train_acc = 0.9676292501164415\n",
      "test Acc 0.9622905027932961:\n",
      "12th- epoch: 33, train_loss = 16.103184588253498, train_acc = 0.9680950163018165\n",
      "test Acc 0.9632216014897579:\n",
      "12th- epoch: 34, train_loss = 15.68509417027235, train_acc = 0.9694923148579413\n",
      "test Acc 0.9646182495344506:\n",
      "12th- epoch: 35, train_loss = 15.29109813645482, train_acc = 0.9712389380530974\n",
      "test Acc 0.9660148975791434:\n",
      "12th- epoch: 36, train_loss = 14.918642651289701, train_acc = 0.9725197950628784\n",
      "test Acc 0.9678770949720671:\n",
      "12th- epoch: 37, train_loss = 14.565874680876732, train_acc = 0.9732184443409408\n",
      "test Acc 0.9697392923649907:\n",
      "12th- epoch: 38, train_loss = 14.230491921305656, train_acc = 0.9738006520726595\n",
      "test Acc 0.9716014897579144:\n",
      "12th- epoch: 39, train_loss = 13.911459129303694, train_acc = 0.9746157428970657\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 40, train_loss = 13.607490222901106, train_acc = 0.9751979506287843\n",
      "test Acc 0.9720670391061452:\n",
      "12th- epoch: 41, train_loss = 13.317478779703379, train_acc = 0.9756637168141593\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 42, train_loss = 13.040542267262936, train_acc = 0.9758965999068467\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 43, train_loss = 12.775564655661583, train_acc = 0.976245924545878\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 44, train_loss = 12.52108596265316, train_acc = 0.9767116907312529\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 45, train_loss = 12.276784859597683, train_acc = 0.9775267815556591\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 46, train_loss = 12.042148776352406, train_acc = 0.9777596646483465\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 47, train_loss = 11.816526643931866, train_acc = 0.9782254308337215\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 48, train_loss = 11.598995450884104, train_acc = 0.9786911970190965\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 49, train_loss = 11.388566195964813, train_acc = 0.9796227293898463\n",
      "test Acc 0.9725325884543762:\n",
      "12th- epoch: 50, train_loss = 11.18506982922554, train_acc = 0.980204937121565\n",
      "test Acc 0.972998137802607:\n",
      "12th- epoch: 51, train_loss = 10.988449320197105, train_acc = 0.980204937121565\n",
      "test Acc 0.973463687150838:\n",
      "12th- epoch: 52, train_loss = 10.798682253807783, train_acc = 0.9804378202142524\n",
      "test Acc 0.9739292364990689:\n",
      "12th- epoch: 53, train_loss = 10.615254826843739, train_acc = 0.9809035863996274\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 54, train_loss = 10.437950532883406, train_acc = 0.9810200279459711\n",
      "test Acc 0.9748603351955307:\n",
      "12th- epoch: 55, train_loss = 10.26625857502222, train_acc = 0.9814857941313461\n",
      "test Acc 0.9753258845437617:\n",
      "12th- epoch: 56, train_loss = 10.100050069391727, train_acc = 0.9814857941313461\n",
      "test Acc 0.9757914338919925:\n",
      "12th- epoch: 57, train_loss = 9.938944969326258, train_acc = 0.9816022356776898\n",
      "test Acc 0.9762569832402235:\n",
      "12th- epoch: 58, train_loss = 9.782166492193937, train_acc = 0.9816022356776898\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 59, train_loss = 9.629665613174438, train_acc = 0.9818351187703773\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 60, train_loss = 9.481449889019132, train_acc = 0.9820680018630648\n",
      "test Acc 0.9767225325884544:\n",
      "12th- epoch: 61, train_loss = 9.336999122053385, train_acc = 0.9823008849557522\n",
      "test Acc 0.9776536312849162:\n",
      "12th- epoch: 62, train_loss = 9.196240026503801, train_acc = 0.9825337680484397\n",
      "test Acc 0.9781191806331471:\n",
      "12th- epoch: 63, train_loss = 9.058832470327616, train_acc = 0.9828830926874709\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 64, train_loss = 8.924709308892488, train_acc = 0.9832324173265021\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 65, train_loss = 8.793928613886237, train_acc = 0.9831159757801584\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 66, train_loss = 8.66605200059712, train_acc = 0.9831159757801584\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 67, train_loss = 8.541247297078371, train_acc = 0.9832324173265021\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 68, train_loss = 8.41933468542993, train_acc = 0.9834653004191896\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 69, train_loss = 8.300134727731347, train_acc = 0.9838146250582208\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 70, train_loss = 8.183342408388853, train_acc = 0.9839310666045645\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 71, train_loss = 8.068957157433033, train_acc = 0.9840475081509082\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 72, train_loss = 7.957062400877476, train_acc = 0.9843968327899395\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 73, train_loss = 7.847423378378153, train_acc = 0.9843968327899395\n",
      "test Acc 0.979050279329609:\n",
      "12th- epoch: 74, train_loss = 7.740096578374505, train_acc = 0.9845132743362832\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 75, train_loss = 7.634861350059509, train_acc = 0.9847461574289706\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 76, train_loss = 7.5317689795047045, train_acc = 0.9848625989753144\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 77, train_loss = 7.430766837671399, train_acc = 0.9848625989753144\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 78, train_loss = 7.33172295615077, train_acc = 0.9850954820680019\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 79, train_loss = 7.234603503718972, train_acc = 0.9852119236143456\n",
      "test Acc 0.9799813780260708:\n",
      "12th- epoch: 80, train_loss = 7.139242514967918, train_acc = 0.9856776897997206\n",
      "test Acc 0.9795158286778398:\n",
      "12th- epoch: 81, train_loss = 7.045731725171208, train_acc = 0.985910572892408\n",
      "test Acc 0.9799813780260708:\n",
      "12th- epoch: 82, train_loss = 6.9538998026400805, train_acc = 0.9861434559850955\n",
      "test Acc 0.9799813780260708:\n",
      "12th- epoch: 83, train_loss = 6.86377876624465, train_acc = 0.9861434559850955\n",
      "test Acc 0.9804469273743017:\n",
      "12th- epoch: 84, train_loss = 6.775166355073452, train_acc = 0.9862598975314392\n",
      "test Acc 0.9804469273743017:\n",
      "12th- epoch: 85, train_loss = 6.688235990703106, train_acc = 0.9867256637168141\n",
      "test Acc 0.9804469273743017:\n",
      "12th- epoch: 86, train_loss = 6.602863913401961, train_acc = 0.9867256637168141\n",
      "test Acc 0.9804469273743017:\n",
      "12th- epoch: 87, train_loss = 6.518828362226486, train_acc = 0.9870749883558454\n",
      "test Acc 0.9804469273743017:\n",
      "12th- epoch: 88, train_loss = 6.436437511816621, train_acc = 0.9873078714485328\n",
      "test Acc 0.9804469273743017:\n",
      "12th- epoch: 89, train_loss = 6.3556060660630465, train_acc = 0.9873078714485328\n",
      "test Acc 0.9804469273743017:\n",
      "12th- epoch: 90, train_loss = 6.2761867847293615, train_acc = 0.9874243129948765\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 91, train_loss = 6.198383137583733, train_acc = 0.9875407545412203\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 92, train_loss = 6.1220996882766485, train_acc = 0.9878900791802515\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 93, train_loss = 6.047116348519921, train_acc = 0.9884722869119702\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 94, train_loss = 5.973577670753002, train_acc = 0.9887051700046576\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 95, train_loss = 5.901336731389165, train_acc = 0.9888216115510013\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 96, train_loss = 5.8305606208741665, train_acc = 0.9888216115510013\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 97, train_loss = 5.761033166199923, train_acc = 0.9889380530973452\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 98, train_loss = 5.692865585908294, train_acc = 0.9891709361900326\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 99, train_loss = 5.625921752303839, train_acc = 0.9891709361900326\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 100, train_loss = 5.560156026855111, train_acc = 0.9895202608290639\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 101, train_loss = 5.495544347912073, train_acc = 0.9895202608290639\n",
      "test Acc 0.9813780260707635:\n",
      "12th- epoch: 102, train_loss = 5.43199048563838, train_acc = 0.9896367023754076\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 103, train_loss = 5.369624525308609, train_acc = 0.9899860270144387\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 104, train_loss = 5.308313827961683, train_acc = 0.9901024685607824\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 105, train_loss = 5.248100170865655, train_acc = 0.99033535165347\n",
      "test Acc 0.9818435754189944:\n",
      "12th- epoch: 106, train_loss = 5.188804196193814, train_acc = 0.9902189101071263\n",
      "test Acc 0.9823091247672253:\n",
      "12th- epoch: 107, train_loss = 5.130664128810167, train_acc = 0.9901024685607824\n",
      "test Acc 0.9823091247672253:\n",
      "12th- epoch: 108, train_loss = 5.0733874794095755, train_acc = 0.9902189101071263\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 109, train_loss = 5.0171948513016105, train_acc = 0.9906846762925011\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 110, train_loss = 4.961872541345656, train_acc = 0.9905682347461574\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 111, train_loss = 4.907581014558673, train_acc = 0.9906846762925011\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 112, train_loss = 4.854253826662898, train_acc = 0.9911504424778761\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 113, train_loss = 4.801754632033408, train_acc = 0.9911504424778761\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 114, train_loss = 4.750233863480389, train_acc = 0.9912668840242198\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 115, train_loss = 4.69964041467756, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 116, train_loss = 4.649738491512835, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 117, train_loss = 4.600626482628286, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 118, train_loss = 4.552342946641147, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 119, train_loss = 4.504918733611703, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 120, train_loss = 4.4581968411803246, train_acc = 0.9919655333022822\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 121, train_loss = 4.412311338819563, train_acc = 0.9919655333022822\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 122, train_loss = 4.367108502425253, train_acc = 0.992081974848626\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 123, train_loss = 4.322603441774845, train_acc = 0.9921984163949698\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 124, train_loss = 4.278666132129729, train_acc = 0.9921984163949698\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 125, train_loss = 4.235562567599118, train_acc = 0.9923148579413135\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 126, train_loss = 4.193165247328579, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 127, train_loss = 4.151392602361739, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 128, train_loss = 4.110299075953662, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 129, train_loss = 4.069906481541693, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 130, train_loss = 4.030127834528685, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 131, train_loss = 3.991023470647633, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 132, train_loss = 3.9526464492082596, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 133, train_loss = 3.9148666532710195, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 134, train_loss = 3.877795360982418, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 135, train_loss = 3.8411536617204547, train_acc = 0.9934792734047508\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 136, train_loss = 3.8051652181893587, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 137, train_loss = 3.769716410897672, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 138, train_loss = 3.73487242590636, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 139, train_loss = 3.7004665164276958, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 140, train_loss = 3.6666587917134166, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 141, train_loss = 3.6334126070141792, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 142, train_loss = 3.6006742948666215, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 143, train_loss = 3.5684475488960743, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 144, train_loss = 3.5366501989774406, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 145, train_loss = 3.5054741501808167, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 146, train_loss = 3.4745911732316017, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 147, train_loss = 3.4443116444163024, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 148, train_loss = 3.414390360470861, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 149, train_loss = 3.3849953073076904, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 150, train_loss = 3.355914043728262, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 151, train_loss = 3.3273305403999984, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 152, train_loss = 3.299129424151033, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 153, train_loss = 3.271419785451144, train_acc = 0.9944108057755007\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 154, train_loss = 3.243992084171623, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 155, train_loss = 3.2170111532323062, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 156, train_loss = 3.190484499093145, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 157, train_loss = 3.164238840341568, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 158, train_loss = 3.1385553306899965, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 159, train_loss = 3.1131301023997366, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 160, train_loss = 3.0880927084945142, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 161, train_loss = 3.0634320112876594, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 162, train_loss = 3.039073806256056, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 163, train_loss = 3.0151356630958617, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 164, train_loss = 2.9914505928754807, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 165, train_loss = 2.9681488326750696, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 166, train_loss = 2.945179086178541, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 167, train_loss = 2.922542652580887, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 168, train_loss = 2.9002017392776906, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 169, train_loss = 2.8782339678145945, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 170, train_loss = 2.8565463894046843, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 171, train_loss = 2.835171092301607, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 172, train_loss = 2.814018512610346, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 173, train_loss = 2.7932061343453825, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 174, train_loss = 2.7726572640240192, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 175, train_loss = 2.7523454972542822, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 176, train_loss = 2.732383986469358, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 177, train_loss = 2.7126048300415277, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 178, train_loss = 2.6931793964467943, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 179, train_loss = 2.6738802981562912, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 180, train_loss = 2.655020121950656, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 181, train_loss = 2.636305606458336, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 182, train_loss = 2.617834595963359, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 183, train_loss = 2.5996894310228527, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 184, train_loss = 2.5817301098722965, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 185, train_loss = 2.5641087002586573, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 186, train_loss = 2.5466054417192936, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 187, train_loss = 2.529447694076225, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 188, train_loss = 2.5124418593477458, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 189, train_loss = 2.4957001314032823, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 190, train_loss = 2.479165192693472, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 191, train_loss = 2.4627863753121346, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 192, train_loss = 2.4467417567502707, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 193, train_loss = 2.4307699755299836, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 194, train_loss = 2.4151494454126805, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 195, train_loss = 2.399699505418539, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 196, train_loss = 2.384408650919795, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 197, train_loss = 2.369423233671114, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 198, train_loss = 2.3545837581623346, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 199, train_loss = 2.3398935354780406, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 200, train_loss = 2.3254687760490924, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 201, train_loss = 2.3112191408872604, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 202, train_loss = 2.29716413654387, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 203, train_loss = 2.283247737912461, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 204, train_loss = 2.269626247463748, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 205, train_loss = 2.2560718811582774, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 206, train_loss = 2.2428756710141897, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 207, train_loss = 2.2296507775317878, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 208, train_loss = 2.216670819791034, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 209, train_loss = 2.203867757692933, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 210, train_loss = 2.1912399518769234, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 211, train_loss = 2.178726602345705, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 212, train_loss = 2.166468984214589, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 213, train_loss = 2.1542849268298596, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "12th- epoch: 214, train_loss = 2.1422763366717845, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 215, train_loss = 2.1304340201895684, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 216, train_loss = 2.1187357355374843, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 217, train_loss = 2.1072293508332223, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 218, train_loss = 2.0958413735497743, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 219, train_loss = 2.0845807946752757, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 220, train_loss = 2.073547213571146, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 221, train_loss = 2.0625952694099396, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 222, train_loss = 2.051847084192559, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 223, train_loss = 2.0411426082719117, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 224, train_loss = 2.030649584485218, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 225, train_loss = 2.0202857546973974, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 226, train_loss = 2.010021895170212, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 227, train_loss = 1.9999130174983293, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 228, train_loss = 1.9898967177141458, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 229, train_loss = 1.980053846957162, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 230, train_loss = 1.9702812656760216, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 231, train_loss = 1.960724952397868, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 232, train_loss = 1.9512136044213548, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 233, train_loss = 1.9417519085109234, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "12th- epoch: 234, train_loss = 1.9324962956598029, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 235, train_loss = 1.9232764268526807, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 236, train_loss = 1.9142832359066233, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 237, train_loss = 1.905266534537077, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 238, train_loss = 1.8964421389391646, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 239, train_loss = 1.8876885809004307, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 240, train_loss = 1.8790704371640459, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "12th- epoch: 241, train_loss = 1.8704958818852901, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 242, train_loss = 1.8620874546468258, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 243, train_loss = 1.8537468077847734, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 244, train_loss = 1.8454797925660387, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 245, train_loss = 1.8373133838176727, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 246, train_loss = 1.8293004222214222, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 247, train_loss = 1.8213328756392002, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 248, train_loss = 1.8134144259383902, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 249, train_loss = 1.805656898766756, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 250, train_loss = 1.7979128634324297, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 251, train_loss = 1.7903220528969541, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 252, train_loss = 1.7827819362282753, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 253, train_loss = 1.7754120317986235, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 254, train_loss = 1.7679372144630179, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 255, train_loss = 1.7607045223703608, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 256, train_loss = 1.7534690462052822, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 257, train_loss = 1.7463129063835368, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 258, train_loss = 1.7392564713954926, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 259, train_loss = 1.7322862086584792, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 260, train_loss = 1.7253406656673178, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 261, train_loss = 1.718547958880663, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 262, train_loss = 1.7117771891644225, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 263, train_loss = 1.7051018191268668, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 264, train_loss = 1.6984357399633154, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 265, train_loss = 1.6919459042837843, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 266, train_loss = 1.685410998761654, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 267, train_loss = 1.6790208170423284, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 268, train_loss = 1.6726625226438046, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 269, train_loss = 1.6663751987507567, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 270, train_loss = 1.6601350381970406, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 271, train_loss = 1.654009641497396, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 272, train_loss = 1.647908840328455, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 273, train_loss = 1.641883666277863, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 274, train_loss = 1.6359370574355125, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "12th- epoch: 275, train_loss = 1.6299642598023638, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 276, train_loss = 1.6241749338805676, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 277, train_loss = 1.618331603705883, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "12th- epoch: 278, train_loss = 1.612620770931244, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 279, train_loss = 1.6069423282751814, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 280, train_loss = 1.6013143534073606, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 281, train_loss = 1.5956978760659695, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 282, train_loss = 1.5902218507835642, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 283, train_loss = 1.5847327647497877, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 284, train_loss = 1.5793301785597578, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 285, train_loss = 1.5739893218269572, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 286, train_loss = 1.5686389046022668, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 287, train_loss = 1.5633342266082764, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 288, train_loss = 1.5581867260625586, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 289, train_loss = 1.5529798455536366, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 290, train_loss = 1.5478466041386127, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 291, train_loss = 1.5427895200555213, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 292, train_loss = 1.5377696938812733, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 293, train_loss = 1.5327594081754796, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 294, train_loss = 1.5277876878972165, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 295, train_loss = 1.5230012561078183, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 296, train_loss = 1.518105961382389, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 297, train_loss = 1.513322964310646, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 298, train_loss = 1.5085921834106557, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 299, train_loss = 1.5038455600733869, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 300, train_loss = 1.4991522245109081, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 301, train_loss = 1.4945810462231748, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 302, train_loss = 1.4899545175139792, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 303, train_loss = 1.4853939513559453, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 304, train_loss = 1.4809214497799985, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 305, train_loss = 1.4764286503195763, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 306, train_loss = 1.4719854891300201, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 307, train_loss = 1.4675919748842716, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 308, train_loss = 1.4632401652634144, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 309, train_loss = 1.458943699777592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 310, train_loss = 1.4546910747885704, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 311, train_loss = 1.4504639481310733, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 312, train_loss = 1.4462530948221684, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 313, train_loss = 1.442071095108986, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 314, train_loss = 1.4379504770040512, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 315, train_loss = 1.4338485238258727, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 316, train_loss = 1.4298071426455863, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 317, train_loss = 1.4257697599823587, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 318, train_loss = 1.4217621684074402, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 319, train_loss = 1.417818482965231, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 320, train_loss = 1.4138862825930119, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 321, train_loss = 1.4099587785894983, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 322, train_loss = 1.4061008927528746, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 323, train_loss = 1.40226936963154, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 324, train_loss = 1.3984691575169563, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 325, train_loss = 1.394705397367943, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 326, train_loss = 1.3910089160199277, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 327, train_loss = 1.3872503526508808, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 328, train_loss = 1.3835705456440337, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 329, train_loss = 1.3799757274682634, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 330, train_loss = 1.3763006515800953, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 331, train_loss = 1.3727749275858514, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 332, train_loss = 1.3691814318299294, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 333, train_loss = 1.365685734897852, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 334, train_loss = 1.3621610986883752, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 335, train_loss = 1.3586780913174152, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 336, train_loss = 1.355218141048681, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 337, train_loss = 1.351837455003988, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 338, train_loss = 1.3483810896868818, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 339, train_loss = 1.345057673752308, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 340, train_loss = 1.3416682109236717, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 341, train_loss = 1.3383656802470796, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 342, train_loss = 1.3350802237982862, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 343, train_loss = 1.3318078207666986, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 344, train_loss = 1.3285399700398557, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 345, train_loss = 1.3253028492326848, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 346, train_loss = 1.3221470539574511, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 347, train_loss = 1.3189130785758607, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 348, train_loss = 1.3157399135525338, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 349, train_loss = 1.312601891637314, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 350, train_loss = 1.3094964263145812, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 351, train_loss = 1.306392899423372, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 352, train_loss = 1.3033445328474045, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 353, train_loss = 1.3002864867448807, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 354, train_loss = 1.2972885146737099, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "12th- epoch: 355, train_loss = 1.2942970804870129, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 356, train_loss = 1.2913495761458762, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 357, train_loss = 1.2883574242587201, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 358, train_loss = 1.2854896013741381, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 359, train_loss = 1.2824740409851074, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 360, train_loss = 1.279582956165541, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 361, train_loss = 1.2766797418589704, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 362, train_loss = 1.273815159976948, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 363, train_loss = 1.2709781949524768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 364, train_loss = 1.2681765941379126, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 365, train_loss = 1.2653737937507685, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 366, train_loss = 1.2625622786581516, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 367, train_loss = 1.2597892557678279, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 368, train_loss = 1.2570282481610775, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 369, train_loss = 1.2543017553689424, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 370, train_loss = 1.251589871942997, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 371, train_loss = 1.248860771447653, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 372, train_loss = 1.246226749062771, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 373, train_loss = 1.2435334784386214, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 374, train_loss = 1.2408803589642048, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 375, train_loss = 1.2383247502148151, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 376, train_loss = 1.2356819324195385, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 377, train_loss = 1.2331470362842083, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 378, train_loss = 1.2305728544888552, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 379, train_loss = 1.228019468486309, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 380, train_loss = 1.225508101284504, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 381, train_loss = 1.2229547078313772, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 382, train_loss = 1.2205153802933637, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 383, train_loss = 1.2180436849594116, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 384, train_loss = 1.2155606212618295, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 385, train_loss = 1.213080565124983, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 386, train_loss = 1.2106695199909154, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 387, train_loss = 1.208264240383869, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 388, train_loss = 1.2058646008372307, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 389, train_loss = 1.2035013499262277, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 390, train_loss = 1.2011403205397073, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 391, train_loss = 1.1987652058305684, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 392, train_loss = 1.1964348889887333, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 393, train_loss = 1.1941723401250783, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 394, train_loss = 1.1918128679099027, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 395, train_loss = 1.1895554562506732, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 396, train_loss = 1.1872294110653456, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 397, train_loss = 1.1850120598974172, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 398, train_loss = 1.1827561160025652, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 399, train_loss = 1.1805531680583954, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 400, train_loss = 1.1783000826835632, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 401, train_loss = 1.1761223326029722, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 402, train_loss = 1.1739075568912085, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 403, train_loss = 1.1717489001748618, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 404, train_loss = 1.1695890476403292, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 405, train_loss = 1.167500981449848, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 406, train_loss = 1.1652890717086848, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 407, train_loss = 1.1631621879932936, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 408, train_loss = 1.1610498813388404, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 409, train_loss = 1.1589247236552183, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 410, train_loss = 1.1568554850819055, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 411, train_loss = 1.1547892304661218, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 412, train_loss = 1.1526791378855705, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 413, train_loss = 1.1506755203008652, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 414, train_loss = 1.1486179071071092, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 415, train_loss = 1.1465623850526754, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 416, train_loss = 1.1445334032177925, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 417, train_loss = 1.1425810555520002, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 418, train_loss = 1.1405737921595573, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 419, train_loss = 1.1386190218327101, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 420, train_loss = 1.136642218887573, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 421, train_loss = 1.1347073254582938, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 422, train_loss = 1.1327803817985114, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 423, train_loss = 1.1308519591984805, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 424, train_loss = 1.1289314776659012, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 425, train_loss = 1.1270112792553846, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 426, train_loss = 1.1251174335775431, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 427, train_loss = 1.1232754041848239, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 428, train_loss = 1.1213907872734126, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 429, train_loss = 1.119565969944233, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 430, train_loss = 1.1177360378205776, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 431, train_loss = 1.1158739142119884, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 432, train_loss = 1.1140384934842587, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 433, train_loss = 1.1122308100166265, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 434, train_loss = 1.1104168978927191, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 435, train_loss = 1.1086601180431899, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 436, train_loss = 1.1068806337716524, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 437, train_loss = 1.1050935573875904, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 438, train_loss = 1.1033231963810977, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 439, train_loss = 1.101637989282608, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 440, train_loss = 1.0998260217311326, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 441, train_loss = 1.0980839133262634, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12th- epoch: 442, train_loss = 1.096406016498804, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 443, train_loss = 1.094706038624281, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 444, train_loss = 1.0929346407356206, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 445, train_loss = 1.0912976749241352, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 446, train_loss = 1.0895901011826936, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 447, train_loss = 1.0878971144557, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 448, train_loss = 1.0862511371669825, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 449, train_loss = 1.0845988964138087, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 450, train_loss = 1.0829269364476204, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 451, train_loss = 1.0813422948122025, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 452, train_loss = 1.0796840004622936, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 453, train_loss = 1.0780384962854441, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 454, train_loss = 1.0764758636651095, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 455, train_loss = 1.074806044489378, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 456, train_loss = 1.0732102766633034, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 457, train_loss = 1.0716351419687271, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 458, train_loss = 1.070053268224001, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 459, train_loss = 1.0684895353915635, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 460, train_loss = 1.0669174281210871, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 461, train_loss = 1.0653331888170214, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 462, train_loss = 1.0638024980871705, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 463, train_loss = 1.0622727039008169, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 464, train_loss = 1.0607613908796338, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 465, train_loss = 1.0592216898949118, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 466, train_loss = 1.0577701392321615, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 467, train_loss = 1.0562393603177043, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 468, train_loss = 1.0547234465630027, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 469, train_loss = 1.0532335328607587, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 470, train_loss = 1.0517178997397423, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 471, train_loss = 1.050255065158126, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 472, train_loss = 1.0487897607235936, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 473, train_loss = 1.047372192144394, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 474, train_loss = 1.0459124681801768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 475, train_loss = 1.0444085163326235, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 476, train_loss = 1.0430001989006996, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 477, train_loss = 1.041572630405426, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 478, train_loss = 1.0401325523853302, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 479, train_loss = 1.0387279950082302, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 480, train_loss = 1.0373249389231205, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 481, train_loss = 1.0359447946102591, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 482, train_loss = 1.0345223881304264, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 483, train_loss = 1.033111301556346, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 484, train_loss = 1.0317595452070236, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 485, train_loss = 1.0303255878388882, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 486, train_loss = 1.029087850198266, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 487, train_loss = 1.0276319608092308, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 488, train_loss = 1.0263242572546005, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 489, train_loss = 1.0249125423579244, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 490, train_loss = 1.0236275767238112, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 491, train_loss = 1.0222615748643875, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 492, train_loss = 1.0209574773907661, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 493, train_loss = 1.01961566011596, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 494, train_loss = 1.0182904017419787, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "12th- epoch: 495, train_loss = 1.0169869263918372, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 496, train_loss = 1.0156699381768703, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 497, train_loss = 1.0144409065396758, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 498, train_loss = 1.0130782735795947, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "12th- epoch: 499, train_loss = 1.0118355179874925, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████                                          | 12/30 [1:21:44<2:03:12, 410.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "13th- epoch: 0, train_loss = 275.10147643089294, train_acc = 0.4105728924080112\n",
      "test Acc 0.5330540037243948:\n",
      "13th- epoch: 1, train_loss = 208.08001828193665, train_acc = 0.53959012575687\n",
      "test Acc 0.5698324022346368:\n",
      "13th- epoch: 2, train_loss = 160.53643137216568, train_acc = 0.5824406148113647\n",
      "test Acc 0.6261638733705773:\n",
      "13th- epoch: 3, train_loss = 134.6813343167305, train_acc = 0.6675593851886353\n",
      "test Acc 0.7178770949720671:\n",
      "13th- epoch: 4, train_loss = 116.07621049880981, train_acc = 0.7417326502095948\n",
      "test Acc 0.7695530726256983:\n",
      "13th- epoch: 5, train_loss = 101.07192885875702, train_acc = 0.7679319981369352\n",
      "test Acc 0.7774674115456238:\n",
      "13th- epoch: 6, train_loss = 88.80297449231148, train_acc = 0.7779459711224965\n",
      "test Acc 0.7914338919925512:\n",
      "13th- epoch: 7, train_loss = 78.79985302686691, train_acc = 0.8012342803912436\n",
      "test Acc 0.8161080074487895:\n",
      "13th- epoch: 8, train_loss = 70.40554305911064, train_acc = 0.8284816022356777\n",
      "test Acc 0.8463687150837989:\n",
      "13th- epoch: 9, train_loss = 63.155814811587334, train_acc = 0.8636469492314858\n",
      "test Acc 0.8803538175046555:\n",
      "13th- epoch: 10, train_loss = 56.84965941309929, train_acc = 0.8935724266418258\n",
      "test Acc 0.909217877094972:\n",
      "13th- epoch: 11, train_loss = 51.37005200982094, train_acc = 0.9142990218910108\n",
      "test Acc 0.9222532588454376:\n",
      "13th- epoch: 12, train_loss = 46.607436776161194, train_acc = 0.928272007452259\n",
      "test Acc 0.9357541899441341:\n",
      "13th- epoch: 13, train_loss = 42.472967475652695, train_acc = 0.9372380065207266\n",
      "test Acc 0.9385474860335196:\n",
      "13th- epoch: 14, train_loss = 38.89572846889496, train_acc = 0.9399161620866325\n",
      "test Acc 0.9418063314711359:\n",
      "13th- epoch: 15, train_loss = 35.81061398237944, train_acc = 0.9421285514671635\n",
      "test Acc 0.9445996275605214:\n",
      "13th- epoch: 16, train_loss = 33.15640711784363, train_acc = 0.9477177456916628\n",
      "test Acc 0.9511173184357542:\n",
      "13th- epoch: 17, train_loss = 30.873849891126156, train_acc = 0.952491849091756\n",
      "test Acc 0.9534450651769087:\n",
      "13th- epoch: 18, train_loss = 28.908233419060707, train_acc = 0.9543549138332557\n",
      "test Acc 0.9543761638733705:\n",
      "13th- epoch: 19, train_loss = 27.208315275609493, train_acc = 0.9566837447601304\n",
      "test Acc 0.9567039106145251:\n",
      "13th- epoch: 20, train_loss = 25.726107999682426, train_acc = 0.9585468095016302\n",
      "test Acc 0.957635009310987:\n",
      "13th- epoch: 21, train_loss = 24.42508602887392, train_acc = 0.959944108057755\n",
      "test Acc 0.957635009310987:\n",
      "13th- epoch: 22, train_loss = 23.27338982000947, train_acc = 0.9607591988821611\n",
      "test Acc 0.9585661080074488:\n",
      "13th- epoch: 23, train_loss = 22.24618886038661, train_acc = 0.9619236143455985\n",
      "test Acc 0.9585661080074488:\n",
      "13th- epoch: 24, train_loss = 21.324125833809376, train_acc = 0.9630880298090359\n",
      "test Acc 0.9585661080074488:\n",
      "13th- epoch: 25, train_loss = 20.49135383963585, train_acc = 0.9637866790870983\n",
      "test Acc 0.9599627560521415:\n",
      "13th- epoch: 26, train_loss = 19.7344790995121, train_acc = 0.9640195621797858\n",
      "test Acc 0.9608938547486033:\n",
      "13th- epoch: 27, train_loss = 19.04184604808688, train_acc = 0.9650675360968793\n",
      "test Acc 0.9622905027932961:\n",
      "13th- epoch: 28, train_loss = 18.40364870801568, train_acc = 0.9654168607359106\n",
      "test Acc 0.9622905027932961:\n",
      "13th- epoch: 29, train_loss = 17.81245880946517, train_acc = 0.966581276199348\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 30, train_loss = 17.262997783720493, train_acc = 0.9666977177456917\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 31, train_loss = 16.7505061365664, train_acc = 0.9675128085700978\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 32, train_loss = 16.2711284160614, train_acc = 0.9680950163018165\n",
      "test Acc 0.962756052141527:\n",
      "13th- epoch: 33, train_loss = 15.820518460124731, train_acc = 0.9691429902189101\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 34, train_loss = 15.394996277987957, train_acc = 0.9697251979506288\n",
      "test Acc 0.9636871508379888:\n",
      "13th- epoch: 35, train_loss = 14.993061114102602, train_acc = 0.9706567303213787\n",
      "test Acc 0.9650837988826816:\n",
      "13th- epoch: 36, train_loss = 14.612854201346636, train_acc = 0.9719375873311598\n",
      "test Acc 0.9660148975791434:\n",
      "13th- epoch: 37, train_loss = 14.252613332122564, train_acc = 0.9731020027945971\n",
      "test Acc 0.9669459962756052:\n",
      "13th- epoch: 38, train_loss = 13.91071331501007, train_acc = 0.9739170936190032\n",
      "test Acc 0.9678770949720671:\n",
      "13th- epoch: 39, train_loss = 13.585928060114384, train_acc = 0.9747321844434094\n",
      "test Acc 0.9706703910614525:\n",
      "13th- epoch: 40, train_loss = 13.276987411081791, train_acc = 0.9756637168141593\n",
      "test Acc 0.9711359404096834:\n",
      "13th- epoch: 41, train_loss = 12.982529420405626, train_acc = 0.9763623660922217\n",
      "test Acc 0.9720670391061452:\n",
      "13th- epoch: 42, train_loss = 12.701287381350994, train_acc = 0.9767116907312529\n",
      "test Acc 0.973463687150838:\n",
      "13th- epoch: 43, train_loss = 12.432737909257412, train_acc = 0.9775267815556591\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 44, train_loss = 12.175956286489964, train_acc = 0.9785747554727526\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 45, train_loss = 11.929711513221264, train_acc = 0.9791569632044713\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 46, train_loss = 11.693148512393236, train_acc = 0.9795062878435026\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 47, train_loss = 11.465927094221115, train_acc = 0.97973917093619\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 48, train_loss = 11.247815489768982, train_acc = 0.980204937121565\n",
      "test Acc 0.9743947858472998:\n",
      "13th- epoch: 49, train_loss = 11.037759110331535, train_acc = 0.9804378202142524\n",
      "test Acc 0.9748603351955307:\n",
      "13th- epoch: 50, train_loss = 10.835159685462713, train_acc = 0.9809035863996274\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 51, train_loss = 10.639704506844282, train_acc = 0.9812529110386586\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 52, train_loss = 10.450964793562889, train_acc = 0.9817186772240335\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 53, train_loss = 10.26838093996048, train_acc = 0.981951560316721\n",
      "test Acc 0.9753258845437617:\n",
      "13th- epoch: 54, train_loss = 10.091535151004791, train_acc = 0.981951560316721\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 55, train_loss = 9.92023342102766, train_acc = 0.981951560316721\n",
      "test Acc 0.9757914338919925:\n",
      "13th- epoch: 56, train_loss = 9.753891963511705, train_acc = 0.9823008849557522\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 57, train_loss = 9.592248309403658, train_acc = 0.9823008849557522\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 58, train_loss = 9.435271793976426, train_acc = 0.9825337680484397\n",
      "test Acc 0.9767225325884544:\n",
      "13th- epoch: 59, train_loss = 9.282820893451571, train_acc = 0.9826502095947834\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 60, train_loss = 9.134468453004956, train_acc = 0.9826502095947834\n",
      "test Acc 0.9771880819366853:\n",
      "13th- epoch: 61, train_loss = 8.989895386621356, train_acc = 0.9829995342338146\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 62, train_loss = 8.849449891597033, train_acc = 0.9831159757801584\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 63, train_loss = 8.712524697184563, train_acc = 0.9833488588728458\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 64, train_loss = 8.5790959559381, train_acc = 0.9835817419655333\n",
      "test Acc 0.9776536312849162:\n",
      "13th- epoch: 65, train_loss = 8.449084091931581, train_acc = 0.9835817419655333\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 66, train_loss = 8.322214605286717, train_acc = 0.9839310666045645\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 67, train_loss = 8.198426350951195, train_acc = 0.9842803912435957\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 68, train_loss = 8.077530885115266, train_acc = 0.9845132743362832\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 69, train_loss = 7.959434807300568, train_acc = 0.9845132743362832\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 70, train_loss = 7.844008892774582, train_acc = 0.9847461574289706\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 71, train_loss = 7.7311278358101845, train_acc = 0.9847461574289706\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 72, train_loss = 7.6207402888685465, train_acc = 0.9848625989753144\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 73, train_loss = 7.5129170473665, train_acc = 0.9850954820680019\n",
      "test Acc 0.9799813780260708:\n",
      "13th- epoch: 74, train_loss = 7.407578570768237, train_acc = 0.9852119236143456\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 75, train_loss = 7.30460718460381, train_acc = 0.9855612482533768\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 76, train_loss = 7.203947616741061, train_acc = 0.9860270144387517\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 77, train_loss = 7.1053358390927315, train_acc = 0.9861434559850955\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 78, train_loss = 7.008687565103173, train_acc = 0.986376339077783\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 79, train_loss = 6.914004584774375, train_acc = 0.9868421052631579\n",
      "test Acc 0.978584729981378:\n",
      "13th- epoch: 80, train_loss = 6.821330599486828, train_acc = 0.9870749883558454\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 81, train_loss = 6.730752972885966, train_acc = 0.9871914299021891\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 82, train_loss = 6.642030615359545, train_acc = 0.9874243129948765\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 83, train_loss = 6.555202251300216, train_acc = 0.9877736376339078\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 84, train_loss = 6.470337005332112, train_acc = 0.9878900791802515\n",
      "test Acc 0.979050279329609:\n",
      "13th- epoch: 85, train_loss = 6.387150282040238, train_acc = 0.9880065207265952\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 86, train_loss = 6.305672645568848, train_acc = 0.9881229622729389\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 87, train_loss = 6.225913194939494, train_acc = 0.9883558453656265\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 88, train_loss = 6.147820774465799, train_acc = 0.9883558453656265\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 89, train_loss = 6.071118367835879, train_acc = 0.9885887284583139\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 90, train_loss = 5.995956555008888, train_acc = 0.9887051700046576\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 91, train_loss = 5.9222804214805365, train_acc = 0.9887051700046576\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 92, train_loss = 5.850015876814723, train_acc = 0.9889380530973452\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 93, train_loss = 5.779374774545431, train_acc = 0.9890544946436889\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 94, train_loss = 5.710092321038246, train_acc = 0.98940381928272\n",
      "test Acc 0.9795158286778398:\n",
      "13th- epoch: 95, train_loss = 5.642252809368074, train_acc = 0.98940381928272\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 96, train_loss = 5.575725149363279, train_acc = 0.9892873777363763\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 97, train_loss = 5.510506519116461, train_acc = 0.9895202608290639\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 98, train_loss = 5.446541556157172, train_acc = 0.9896367023754076\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 99, train_loss = 5.383641351945698, train_acc = 0.9897531439217513\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 100, train_loss = 5.3220282178372145, train_acc = 0.9901024685607824\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 101, train_loss = 5.26145900785923, train_acc = 0.9902189101071263\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 102, train_loss = 5.202082530595362, train_acc = 0.9904517931998137\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 103, train_loss = 5.14374962169677, train_acc = 0.9904517931998137\n",
      "test Acc 0.9809124767225326:\n",
      "13th- epoch: 104, train_loss = 5.086664852686226, train_acc = 0.9904517931998137\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 105, train_loss = 5.030531660653651, train_acc = 0.9904517931998137\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 106, train_loss = 4.975433591753244, train_acc = 0.9905682347461574\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 107, train_loss = 4.92138200160116, train_acc = 0.9909175593851887\n",
      "test Acc 0.9813780260707635:\n",
      "13th- epoch: 108, train_loss = 4.868233756162226, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 109, train_loss = 4.816005404107273, train_acc = 0.9910340009315324\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 110, train_loss = 4.764733937568963, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 111, train_loss = 4.714309277012944, train_acc = 0.9917326502095948\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 112, train_loss = 4.6647190088406205, train_acc = 0.9918490917559385\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 113, train_loss = 4.616067155264318, train_acc = 0.992081974848626\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 114, train_loss = 4.5681595811620355, train_acc = 0.9921984163949698\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 115, train_loss = 4.52114615123719, train_acc = 0.9921984163949698\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 116, train_loss = 4.47491045948118, train_acc = 0.9921984163949698\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 117, train_loss = 4.429441517218947, train_acc = 0.9923148579413135\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 118, train_loss = 4.384659363888204, train_acc = 0.9923148579413135\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 119, train_loss = 4.340641343034804, train_acc = 0.9923148579413135\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 120, train_loss = 4.297324032522738, train_acc = 0.9923148579413135\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 121, train_loss = 4.254721676930785, train_acc = 0.9923148579413135\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 122, train_loss = 4.212711239233613, train_acc = 0.9923148579413135\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 123, train_loss = 4.171325667761266, train_acc = 0.9924312994876572\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 124, train_loss = 4.130859359167516, train_acc = 0.9925477410340009\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 125, train_loss = 4.09087710082531, train_acc = 0.9925477410340009\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 126, train_loss = 4.051695031113923, train_acc = 0.9926641825803446\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 127, train_loss = 4.012951607815921, train_acc = 0.9926641825803446\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 128, train_loss = 3.974974576383829, train_acc = 0.9927806241266884\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 129, train_loss = 3.9376194244250655, train_acc = 0.9932463903120633\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 130, train_loss = 3.9007757613435388, train_acc = 0.9933628318584071\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 131, train_loss = 3.8644906226545572, train_acc = 0.9933628318584071\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 132, train_loss = 3.829000761266798, train_acc = 0.9935957149510946\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 133, train_loss = 3.7938307146541774, train_acc = 0.9935957149510946\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 134, train_loss = 3.759125527460128, train_acc = 0.9939450395901258\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 135, train_loss = 3.7248785602860153, train_acc = 0.9939450395901258\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 136, train_loss = 3.691387746948749, train_acc = 0.9940614811364695\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 137, train_loss = 3.658289846498519, train_acc = 0.9940614811364695\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 138, train_loss = 3.625864301342517, train_acc = 0.9940614811364695\n",
      "test Acc 0.9818435754189944:\n",
      "13th- epoch: 139, train_loss = 3.5938462372869253, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 140, train_loss = 3.562249733135104, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 141, train_loss = 3.5311861499212682, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 142, train_loss = 3.500575051177293, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 143, train_loss = 3.4702885136939585, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 144, train_loss = 3.440595570486039, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 145, train_loss = 3.411149099934846, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 146, train_loss = 3.382277563214302, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 147, train_loss = 3.3537349957041442, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 148, train_loss = 3.3256727349944413, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 149, train_loss = 3.297941406723112, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 150, train_loss = 3.270578983705491, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "13th- epoch: 151, train_loss = 3.2436458482407033, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 152, train_loss = 3.217111950274557, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 153, train_loss = 3.1909307376481593, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 154, train_loss = 3.165139039978385, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 155, train_loss = 3.1397129860706627, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 156, train_loss = 3.114596964791417, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 157, train_loss = 3.089902634266764, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 158, train_loss = 3.0655309557914734, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 159, train_loss = 3.0414572157897055, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 160, train_loss = 3.0177807793952525, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 161, train_loss = 2.9943378544412553, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 162, train_loss = 2.971291195601225, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 163, train_loss = 2.948518296238035, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 164, train_loss = 2.9260260215960443, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 165, train_loss = 2.9037762484513223, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 166, train_loss = 2.8819791725836694, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 167, train_loss = 2.8601960013620555, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 168, train_loss = 2.8389220889657736, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 169, train_loss = 2.817875675391406, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 170, train_loss = 2.79700739053078, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 171, train_loss = 2.776538494275883, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 172, train_loss = 2.7561447874177247, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 173, train_loss = 2.736073464853689, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 174, train_loss = 2.7162661477923393, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 175, train_loss = 2.6968113146722317, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 176, train_loss = 2.6775730792433023, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 177, train_loss = 2.658701092004776, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 178, train_loss = 2.6399324976373464, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 179, train_loss = 2.6214585278648883, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 180, train_loss = 2.6031749739777297, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 181, train_loss = 2.5853212028741837, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 182, train_loss = 2.5673930898774415, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 183, train_loss = 2.5499413907527924, train_acc = 0.995575221238938\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 184, train_loss = 2.532679657218978, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 185, train_loss = 2.5155148338526487, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 186, train_loss = 2.4987798780202866, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 187, train_loss = 2.4820811345707625, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 188, train_loss = 2.4657506172079593, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 189, train_loss = 2.4496071189641953, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 190, train_loss = 2.4335541806649417, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 191, train_loss = 2.417866736650467, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 192, train_loss = 2.4023273803759366, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 193, train_loss = 2.386992320418358, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 194, train_loss = 2.371909437701106, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 195, train_loss = 2.3569909688085318, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 196, train_loss = 2.342337181791663, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 197, train_loss = 2.327863144921139, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 198, train_loss = 2.3135234508663416, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 199, train_loss = 2.2994260359555483, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 200, train_loss = 2.2854777332395315, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 201, train_loss = 2.2718296218663454, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 202, train_loss = 2.2582240228075534, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 203, train_loss = 2.244868627516553, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 204, train_loss = 2.231642210157588, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 205, train_loss = 2.2187039565760642, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 206, train_loss = 2.205828471807763, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 207, train_loss = 2.1931230537593365, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 208, train_loss = 2.1806502018589526, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 209, train_loss = 2.1683537054341286, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 210, train_loss = 2.156162331579253, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 211, train_loss = 2.144127206178382, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 212, train_loss = 2.132211123825982, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 213, train_loss = 2.1205005410593003, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 214, train_loss = 2.10891929641366, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 215, train_loss = 2.097501192241907, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 216, train_loss = 2.0862307138741016, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 217, train_loss = 2.0750618452439085, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 218, train_loss = 2.06411861628294, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 219, train_loss = 2.053174061118625, train_acc = 0.9968560782487191\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 220, train_loss = 2.0425060875713825, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 221, train_loss = 2.0319988280534744, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 222, train_loss = 2.0214638486504555, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 223, train_loss = 2.0111665911972523, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 224, train_loss = 2.0010089637944475, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 225, train_loss = 1.9909823536872864, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 226, train_loss = 1.981067510903813, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 227, train_loss = 1.9712573351571336, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 228, train_loss = 1.9616466537117958, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 229, train_loss = 1.9520420072367415, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 230, train_loss = 1.9426580580184236, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 231, train_loss = 1.9333813848206773, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 232, train_loss = 1.9240927571663633, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 233, train_loss = 1.9151106079807505, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 234, train_loss = 1.9060390777885914, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 235, train_loss = 1.8972672410309315, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 236, train_loss = 1.888482061563991, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 237, train_loss = 1.879835519939661, train_acc = 0.9970889613414066\n",
      "test Acc 0.9827746741154563:\n",
      "13th- epoch: 238, train_loss = 1.871364675462246, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 239, train_loss = 1.8628404065966606, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 240, train_loss = 1.8545322691788897, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 241, train_loss = 1.846280520199798, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 242, train_loss = 1.8382197892060503, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 243, train_loss = 1.8301455216715112, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 244, train_loss = 1.8222007229924202, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 245, train_loss = 1.8143994336714968, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 246, train_loss = 1.806605120538734, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 247, train_loss = 1.798958541243337, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 248, train_loss = 1.7913299960782751, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 249, train_loss = 1.7838995618512854, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 250, train_loss = 1.776430867612362, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 251, train_loss = 1.7691458351910114, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 252, train_loss = 1.7618851078441367, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 253, train_loss = 1.7547563289990649, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 254, train_loss = 1.7476185237756, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 255, train_loss = 1.7406925596296787, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 256, train_loss = 1.733792612911202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 257, train_loss = 1.7268665520241484, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 258, train_loss = 1.720203717588447, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 259, train_loss = 1.7134225368499756, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 260, train_loss = 1.7068045301130041, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 261, train_loss = 1.7003372348845005, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 262, train_loss = 1.6937710978090763, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 263, train_loss = 1.687386468052864, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 264, train_loss = 1.6810967897763476, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 265, train_loss = 1.6748061092803255, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 266, train_loss = 1.6685950383543968, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 267, train_loss = 1.6625000735512003, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 268, train_loss = 1.6563441008329391, train_acc = 0.9974382859804378\n",
      "test Acc 0.9832402234636871:\n",
      "13th- epoch: 269, train_loss = 1.6503855673363432, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 270, train_loss = 1.6444425446679816, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 271, train_loss = 1.6385199079522863, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 272, train_loss = 1.632667368859984, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 273, train_loss = 1.6269718930125237, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 274, train_loss = 1.621167625009548, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "13th- epoch: 275, train_loss = 1.6155091474647634, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 276, train_loss = 1.6099113002419472, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 277, train_loss = 1.6043755573336966, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "13th- epoch: 278, train_loss = 1.5988215059041977, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 279, train_loss = 1.593489510298241, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 280, train_loss = 1.5879957998986356, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 281, train_loss = 1.582709853828419, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 282, train_loss = 1.5773768325452693, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 283, train_loss = 1.5721617068047635, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 284, train_loss = 1.5669801545445807, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 285, train_loss = 1.5618156306445599, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 286, train_loss = 1.5567260272800922, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 287, train_loss = 1.551659935445059, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 288, train_loss = 1.5467011767323129, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 289, train_loss = 1.5417564722592942, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 290, train_loss = 1.5368618220090866, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 291, train_loss = 1.5319720953702927, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 292, train_loss = 1.5272149369120598, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 293, train_loss = 1.5223678797483444, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 294, train_loss = 1.5176641692523845, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 295, train_loss = 1.5129334044759162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 296, train_loss = 1.5083314776420593, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 297, train_loss = 1.5036359876394272, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 298, train_loss = 1.4990870468318462, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 299, train_loss = 1.4945519578759558, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 300, train_loss = 1.4900170713663101, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 301, train_loss = 1.4855291321873665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 302, train_loss = 1.4811419521574862, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 303, train_loss = 1.4767762323026545, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 304, train_loss = 1.472429320216179, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 305, train_loss = 1.4681348092854023, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 306, train_loss = 1.463805727660656, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 307, train_loss = 1.4596313026850112, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 308, train_loss = 1.4553952415590174, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 309, train_loss = 1.4512927271425724, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 310, train_loss = 1.447052410512697, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 311, train_loss = 1.4430276130442508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 312, train_loss = 1.438927439332474, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 313, train_loss = 1.434931106865406, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 314, train_loss = 1.430950375914108, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 315, train_loss = 1.4269971785251983, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 316, train_loss = 1.4230337391491048, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 317, train_loss = 1.4191775570507161, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 318, train_loss = 1.415302595763933, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 319, train_loss = 1.4115296241943724, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 320, train_loss = 1.407733631611336, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 321, train_loss = 1.4039283394813538, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 322, train_loss = 1.4002054345910437, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 323, train_loss = 1.3965451208059676, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 324, train_loss = 1.3928269210155122, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 325, train_loss = 1.3891747308080085, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 326, train_loss = 1.3856069035828114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 327, train_loss = 1.3819755439762957, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 328, train_loss = 1.3784111725981347, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 329, train_loss = 1.3749046139419079, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 330, train_loss = 1.371388131112326, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 331, train_loss = 1.3679849281907082, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 332, train_loss = 1.3644505068659782, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 333, train_loss = 1.36105527728796, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 334, train_loss = 1.3576532689039595, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 335, train_loss = 1.3543654319946654, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 336, train_loss = 1.3509322094614618, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 337, train_loss = 1.3476389187271707, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 338, train_loss = 1.3443758797948249, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 339, train_loss = 1.341060799837578, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 340, train_loss = 1.3378652122919448, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 341, train_loss = 1.3345753301982768, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 342, train_loss = 1.3315007202327251, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 343, train_loss = 1.328225139528513, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 344, train_loss = 1.3251471382682212, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 345, train_loss = 1.3219793103635311, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 346, train_loss = 1.3189383558928967, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 347, train_loss = 1.3158177187142428, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 348, train_loss = 1.3128452574310359, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 349, train_loss = 1.3097156658768654, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 350, train_loss = 1.3067382176814135, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 351, train_loss = 1.3037212739291135, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 352, train_loss = 1.3007640118303243, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 353, train_loss = 1.2978286358120386, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 354, train_loss = 1.2948826576175634, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 355, train_loss = 1.2919921378197614, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 356, train_loss = 1.2890367259678897, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 357, train_loss = 1.2863202579319477, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 358, train_loss = 1.2833759300410748, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 359, train_loss = 1.2806136260333005, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 360, train_loss = 1.2777555299398955, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 361, train_loss = 1.275005280971527, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 362, train_loss = 1.2722415948810522, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 363, train_loss = 1.26942490786314, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 364, train_loss = 1.2667852515878621, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 365, train_loss = 1.2640660790202674, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 366, train_loss = 1.2613162187335547, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 367, train_loss = 1.2586710415780544, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 368, train_loss = 1.2560442574322224, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 369, train_loss = 1.2533830230531748, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 370, train_loss = 1.250762545823818, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 371, train_loss = 1.2481873109936714, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 372, train_loss = 1.2455739974975586, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 373, train_loss = 1.2430732498469297, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 374, train_loss = 1.240455236285925, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 375, train_loss = 1.2379775196313858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 376, train_loss = 1.2354410650732461, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 377, train_loss = 1.2329145036637783, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 378, train_loss = 1.2305668778717518, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 379, train_loss = 1.228017727524275, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 380, train_loss = 1.2255574725568295, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 381, train_loss = 1.2231384316983167, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 382, train_loss = 1.220736245304579, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 383, train_loss = 1.2183088585734367, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 384, train_loss = 1.2159451445040759, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 385, train_loss = 1.2135047217307147, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 386, train_loss = 1.211230722576147, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 387, train_loss = 1.2088398784399033, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 388, train_loss = 1.206594514340395, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 389, train_loss = 1.2042180647549685, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 390, train_loss = 1.2019631564617157, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 391, train_loss = 1.1996152674255427, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 392, train_loss = 1.1973997776804026, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 393, train_loss = 1.1951884503068868, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 394, train_loss = 1.1928920112550259, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 395, train_loss = 1.1907017715275288, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 396, train_loss = 1.1884824285807554, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "13th- epoch: 397, train_loss = 1.186270784586668, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 398, train_loss = 1.1840704828500748, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 399, train_loss = 1.1819398328661919, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 400, train_loss = 1.1797524603607599, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 401, train_loss = 1.1776074146328028, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 402, train_loss = 1.1754801608622074, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 403, train_loss = 1.1733466858568136, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 404, train_loss = 1.1712587612273637, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 405, train_loss = 1.1691451618971769, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 406, train_loss = 1.1671142751874868, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 407, train_loss = 1.1650152566435281, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 408, train_loss = 1.162989366799593, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 409, train_loss = 1.1608528420329094, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 410, train_loss = 1.1588658392429352, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 411, train_loss = 1.1568660202028695, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 412, train_loss = 1.1548402396438178, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 413, train_loss = 1.1529326252639294, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 414, train_loss = 1.150828342884779, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 415, train_loss = 1.148903053253889, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 416, train_loss = 1.1469481214880943, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 417, train_loss = 1.1450398787856102, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 418, train_loss = 1.1429939655063208, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 419, train_loss = 1.1411322107014712, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 420, train_loss = 1.139228609710699, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 421, train_loss = 1.1373484755458776, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 422, train_loss = 1.135363853216404, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 423, train_loss = 1.1334810840489808, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 424, train_loss = 1.1316410501895007, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 425, train_loss = 1.1297197652456816, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 426, train_loss = 1.1278608491120394, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 427, train_loss = 1.126042409479851, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 428, train_loss = 1.1241197250783443, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 429, train_loss = 1.122363838047022, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 430, train_loss = 1.1204750637116376, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 431, train_loss = 1.1186952417192515, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 432, train_loss = 1.1169727941451129, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 433, train_loss = 1.115140156209236, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 434, train_loss = 1.1132821440696716, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 435, train_loss = 1.1115401697752532, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 436, train_loss = 1.1097744181752205, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 437, train_loss = 1.107993738114601, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 438, train_loss = 1.1062489238975104, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 439, train_loss = 1.1046045906841755, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 440, train_loss = 1.1028074646892492, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 441, train_loss = 1.1010768860578537, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13th- epoch: 442, train_loss = 1.099441530794138, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 443, train_loss = 1.097658352315193, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 444, train_loss = 1.0960741055605467, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 445, train_loss = 1.0943796026258497, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 446, train_loss = 1.0926049004046945, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 447, train_loss = 1.0910425794572802, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 448, train_loss = 1.089392336711171, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 449, train_loss = 1.087708188846591, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 450, train_loss = 1.0860313288867474, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 451, train_loss = 1.0843939445912838, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 452, train_loss = 1.0828399807214737, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 453, train_loss = 1.081256426870823, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 454, train_loss = 1.0795738088636426, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 455, train_loss = 1.0780858546495438, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 456, train_loss = 1.0764142175466986, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 457, train_loss = 1.074913130447385, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 458, train_loss = 1.073298575982335, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 459, train_loss = 1.0717790685594082, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 460, train_loss = 1.0702373695821734, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 461, train_loss = 1.0687264005391626, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 462, train_loss = 1.0671765853912802, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 463, train_loss = 1.065650999546051, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 464, train_loss = 1.0641185268759727, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 465, train_loss = 1.0626608567981748, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 466, train_loss = 1.0610926610679599, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 467, train_loss = 1.0596971958875656, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 468, train_loss = 1.0582062751054764, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 469, train_loss = 1.0566801403911086, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 470, train_loss = 1.0551564494817285, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 471, train_loss = 1.053747774407384, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 472, train_loss = 1.0522934322507353, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 473, train_loss = 1.050786305218935, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 474, train_loss = 1.0494634099304676, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 475, train_loss = 1.047913892820361, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 476, train_loss = 1.046637321516755, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 477, train_loss = 1.045120390757802, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 478, train_loss = 1.043735034763813, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 479, train_loss = 1.0422957961709471, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 480, train_loss = 1.0409469654114218, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 481, train_loss = 1.0395675636827946, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 482, train_loss = 1.0380617777555017, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 483, train_loss = 1.0367936765105696, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 484, train_loss = 1.0353242121636868, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 485, train_loss = 1.0340793852956267, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 486, train_loss = 1.0326999624521704, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 487, train_loss = 1.0312310556619195, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 488, train_loss = 1.0299618182034465, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 489, train_loss = 1.028574043259141, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 490, train_loss = 1.0272768822760554, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 491, train_loss = 1.0260199209005805, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 492, train_loss = 1.02464756120753, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 493, train_loss = 1.0233375343232183, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 494, train_loss = 1.0219842841179343, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 495, train_loss = 1.0206682197749615, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 496, train_loss = 1.0194414891302586, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 497, train_loss = 1.0181265932769747, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 498, train_loss = 1.0168376130313845, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "13th- epoch: 499, train_loss = 1.0155629677028628, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████▎                                       | 13/30 [1:28:35<1:56:22, 410.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "14th- epoch: 0, train_loss = 270.3238356113434, train_acc = 0.49557522123893805\n",
      "test Acc 0.5535381750465549:\n",
      "14th- epoch: 1, train_loss = 202.06610763072968, train_acc = 0.5612482533768048\n",
      "test Acc 0.5712290502793296:\n",
      "14th- epoch: 2, train_loss = 156.907790184021, train_acc = 0.5914066138798323\n",
      "test Acc 0.6215083798882681:\n",
      "14th- epoch: 3, train_loss = 133.18214231729507, train_acc = 0.66022356776898\n",
      "test Acc 0.7048417132216015:\n",
      "14th- epoch: 4, train_loss = 115.73512107133865, train_acc = 0.7292734047508151\n",
      "test Acc 0.7518621973929237:\n",
      "14th- epoch: 5, train_loss = 101.05303916335106, train_acc = 0.774219841639497\n",
      "test Acc 0.7914338919925512:\n",
      "14th- epoch: 6, train_loss = 88.60054025053978, train_acc = 0.7964601769911505\n",
      "test Acc 0.8040037243947858:\n",
      "14th- epoch: 7, train_loss = 78.2415264248848, train_acc = 0.8164881229622729\n",
      "test Acc 0.8151769087523277:\n",
      "14th- epoch: 8, train_loss = 69.52413061261177, train_acc = 0.8421052631578947\n",
      "test Acc 0.8566108007448789:\n",
      "14th- epoch: 9, train_loss = 62.08700808882713, train_acc = 0.8742431299487657\n",
      "test Acc 0.8845437616387337:\n",
      "14th- epoch: 10, train_loss = 55.76049368083477, train_acc = 0.8943875174662319\n",
      "test Acc 0.9027001862197392:\n",
      "14th- epoch: 11, train_loss = 50.39758636057377, train_acc = 0.9054494643688868\n",
      "test Acc 0.9129422718808193:\n",
      "14th- epoch: 12, train_loss = 45.82619923353195, train_acc = 0.9189566837447601\n",
      "test Acc 0.9283054003724395:\n",
      "14th- epoch: 13, train_loss = 41.8976476341486, train_acc = 0.9312994876571961\n",
      "test Acc 0.9366852886405959:\n",
      "14th- epoch: 14, train_loss = 38.50597123801708, train_acc = 0.9385188635305077\n",
      "test Acc 0.9404096834264432:\n",
      "14th- epoch: 15, train_loss = 35.57165077328682, train_acc = 0.9416627852817886\n",
      "test Acc 0.9450651769087524:\n",
      "14th- epoch: 16, train_loss = 33.032415606081486, train_acc = 0.9484163949697252\n",
      "test Acc 0.9506517690875232:\n",
      "14th- epoch: 17, train_loss = 30.834760069847107, train_acc = 0.950279459711225\n",
      "test Acc 0.9529795158286778:\n",
      "14th- epoch: 18, train_loss = 28.928374595940113, train_acc = 0.9519096413600373\n",
      "test Acc 0.9543761638733705:\n",
      "14th- epoch: 19, train_loss = 27.26883877068758, train_acc = 0.9540055891942245\n",
      "test Acc 0.9567039106145251:\n",
      "14th- epoch: 20, train_loss = 25.814761355519295, train_acc = 0.9554028877503493\n",
      "test Acc 0.957635009310987:\n",
      "14th- epoch: 21, train_loss = 24.534143671393394, train_acc = 0.9576152771308803\n",
      "test Acc 0.9585661080074488:\n",
      "14th- epoch: 22, train_loss = 23.401362735778093, train_acc = 0.9590125756870052\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 23, train_loss = 22.390855945646763, train_acc = 0.959944108057755\n",
      "test Acc 0.9599627560521415:\n",
      "14th- epoch: 24, train_loss = 21.481774047017097, train_acc = 0.9614578481602236\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 25, train_loss = 20.659677151590586, train_acc = 0.9620400558919422\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 26, train_loss = 19.911498464643955, train_acc = 0.9632044713553796\n",
      "test Acc 0.9618249534450651:\n",
      "14th- epoch: 27, train_loss = 19.22668008878827, train_acc = 0.9642524452724732\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 28, train_loss = 18.59668856486678, train_acc = 0.965649743828598\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 29, train_loss = 18.013580836355686, train_acc = 0.9657661853749417\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 30, train_loss = 17.47175382450223, train_acc = 0.9670470423847228\n",
      "test Acc 0.9632216014897579:\n",
      "14th- epoch: 31, train_loss = 16.966313265264034, train_acc = 0.9677456916627852\n",
      "test Acc 0.9636871508379888:\n",
      "14th- epoch: 32, train_loss = 16.492863230407238, train_acc = 0.9685607824871915\n",
      "test Acc 0.9636871508379888:\n",
      "14th- epoch: 33, train_loss = 16.047572162002325, train_acc = 0.9686772240335352\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 34, train_loss = 15.62672907114029, train_acc = 0.9690265486725663\n",
      "test Acc 0.9650837988826816:\n",
      "14th- epoch: 35, train_loss = 15.22861422225833, train_acc = 0.9701909641360037\n",
      "test Acc 0.9674115456238361:\n",
      "14th- epoch: 36, train_loss = 14.852147500962019, train_acc = 0.9719375873311598\n",
      "test Acc 0.9683426443202979:\n",
      "14th- epoch: 37, train_loss = 14.495469592511654, train_acc = 0.9731020027945971\n",
      "test Acc 0.9697392923649907:\n",
      "14th- epoch: 38, train_loss = 14.156849782913923, train_acc = 0.9746157428970657\n",
      "test Acc 0.9706703910614525:\n",
      "14th- epoch: 39, train_loss = 13.835285112261772, train_acc = 0.9747321844434094\n",
      "test Acc 0.9720670391061452:\n",
      "14th- epoch: 40, train_loss = 13.529347706586123, train_acc = 0.9749650675360969\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 41, train_loss = 13.2384421415627, train_acc = 0.9761294829995343\n",
      "test Acc 0.973463687150838:\n",
      "14th- epoch: 42, train_loss = 12.960865933448076, train_acc = 0.9764788076385654\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 43, train_loss = 12.695606052875519, train_acc = 0.9771774569166278\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 44, train_loss = 12.441941611468792, train_acc = 0.9775267815556591\n",
      "test Acc 0.9739292364990689:\n",
      "14th- epoch: 45, train_loss = 12.198604576289654, train_acc = 0.977992547741034\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 46, train_loss = 11.965019814670086, train_acc = 0.9788076385654402\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 47, train_loss = 11.740671880543232, train_acc = 0.9792734047508151\n",
      "test Acc 0.9743947858472998:\n",
      "14th- epoch: 48, train_loss = 11.525161445140839, train_acc = 0.97973917093619\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 49, train_loss = 11.317720990628004, train_acc = 0.9800884955752213\n",
      "test Acc 0.9748603351955307:\n",
      "14th- epoch: 50, train_loss = 11.117654912173748, train_acc = 0.9800884955752213\n",
      "test Acc 0.9757914338919925:\n",
      "14th- epoch: 51, train_loss = 10.924564354121685, train_acc = 0.9803213786679087\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 52, train_loss = 10.738016001880169, train_acc = 0.9804378202142524\n",
      "test Acc 0.9767225325884544:\n",
      "14th- epoch: 53, train_loss = 10.557443445548415, train_acc = 0.9807871448532837\n",
      "test Acc 0.9771880819366853:\n",
      "14th- epoch: 54, train_loss = 10.382331427186728, train_acc = 0.9810200279459711\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 55, train_loss = 10.21231298148632, train_acc = 0.9811364694923148\n",
      "test Acc 0.9776536312849162:\n",
      "14th- epoch: 56, train_loss = 10.047306351363659, train_acc = 0.9812529110386586\n",
      "test Acc 0.9781191806331471:\n",
      "14th- epoch: 57, train_loss = 9.88733036071062, train_acc = 0.9816022356776898\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 58, train_loss = 9.731958445161581, train_acc = 0.9816022356776898\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 59, train_loss = 9.581061152741313, train_acc = 0.9820680018630648\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 60, train_loss = 9.434065096080303, train_acc = 0.9821844434094085\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 61, train_loss = 9.290817931294441, train_acc = 0.9821844434094085\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 62, train_loss = 9.151137741282582, train_acc = 0.9823008849557522\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 63, train_loss = 9.01468868739903, train_acc = 0.9824173265020959\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 64, train_loss = 8.881704872474074, train_acc = 0.9825337680484397\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 65, train_loss = 8.751826029270887, train_acc = 0.9826502095947834\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 66, train_loss = 8.6249493137002, train_acc = 0.9827666511411272\n",
      "test Acc 0.978584729981378:\n",
      "14th- epoch: 67, train_loss = 8.500889427959919, train_acc = 0.9831159757801584\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 68, train_loss = 8.379354637116194, train_acc = 0.9832324173265021\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 69, train_loss = 8.260425919666886, train_acc = 0.983698183511877\n",
      "test Acc 0.979050279329609:\n",
      "14th- epoch: 70, train_loss = 8.143870238214731, train_acc = 0.9839310666045645\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 71, train_loss = 8.029676547273993, train_acc = 0.9840475081509082\n",
      "test Acc 0.9799813780260708:\n",
      "14th- epoch: 72, train_loss = 7.9178180657327175, train_acc = 0.9845132743362832\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 73, train_loss = 7.808235412463546, train_acc = 0.9846297158826269\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 74, train_loss = 7.700791461393237, train_acc = 0.9849790405216581\n",
      "test Acc 0.9795158286778398:\n",
      "14th- epoch: 75, train_loss = 7.59551583789289, train_acc = 0.9852119236143456\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 76, train_loss = 7.492441274225712, train_acc = 0.985444806707033\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 77, train_loss = 7.391424572095275, train_acc = 0.9856776897997206\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 78, train_loss = 7.29250861145556, train_acc = 0.9857941313460643\n",
      "test Acc 0.9804469273743017:\n",
      "14th- epoch: 79, train_loss = 7.1954181380569935, train_acc = 0.9857941313460643\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 80, train_loss = 7.100267881527543, train_acc = 0.985910572892408\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 81, train_loss = 7.00670332275331, train_acc = 0.9861434559850955\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 82, train_loss = 6.9148925598710775, train_acc = 0.9861434559850955\n",
      "test Acc 0.9809124767225326:\n",
      "14th- epoch: 83, train_loss = 6.824819469824433, train_acc = 0.986376339077783\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 84, train_loss = 6.736443834379315, train_acc = 0.9864927806241267\n",
      "test Acc 0.9813780260707635:\n",
      "14th- epoch: 85, train_loss = 6.649818761274219, train_acc = 0.9866092221704704\n",
      "test Acc 0.9818435754189944:\n",
      "14th- epoch: 86, train_loss = 6.565022425726056, train_acc = 0.9867256637168141\n",
      "test Acc 0.9818435754189944:\n",
      "14th- epoch: 87, train_loss = 6.481659969314933, train_acc = 0.9873078714485328\n",
      "test Acc 0.9818435754189944:\n",
      "14th- epoch: 88, train_loss = 6.399636318907142, train_acc = 0.9875407545412203\n",
      "test Acc 0.9823091247672253:\n",
      "14th- epoch: 89, train_loss = 6.319195097312331, train_acc = 0.9876571960875641\n",
      "test Acc 0.9823091247672253:\n",
      "14th- epoch: 90, train_loss = 6.240121968090534, train_acc = 0.9876571960875641\n",
      "test Acc 0.9827746741154563:\n",
      "14th- epoch: 91, train_loss = 6.162663463503122, train_acc = 0.9877736376339078\n",
      "test Acc 0.9827746741154563:\n",
      "14th- epoch: 92, train_loss = 6.086494853720069, train_acc = 0.9877736376339078\n",
      "test Acc 0.9827746741154563:\n",
      "14th- epoch: 93, train_loss = 6.011852139607072, train_acc = 0.9878900791802515\n",
      "test Acc 0.9827746741154563:\n",
      "14th- epoch: 94, train_loss = 5.938572453334928, train_acc = 0.9880065207265952\n",
      "test Acc 0.9827746741154563:\n",
      "14th- epoch: 95, train_loss = 5.8666331972926855, train_acc = 0.9887051700046576\n",
      "test Acc 0.9827746741154563:\n",
      "14th- epoch: 96, train_loss = 5.796022420749068, train_acc = 0.9887051700046576\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 97, train_loss = 5.726549990475178, train_acc = 0.9887051700046576\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 98, train_loss = 5.658410361036658, train_acc = 0.9888216115510013\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 99, train_loss = 5.591389489360154, train_acc = 0.9889380530973452\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 100, train_loss = 5.525664527900517, train_acc = 0.9890544946436889\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 101, train_loss = 5.461178405210376, train_acc = 0.9891709361900326\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 102, train_loss = 5.397839215584099, train_acc = 0.98940381928272\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 103, train_loss = 5.335594412870705, train_acc = 0.9895202608290639\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 104, train_loss = 5.274434679187834, train_acc = 0.9897531439217513\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 105, train_loss = 5.21449167560786, train_acc = 0.9897531439217513\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 106, train_loss = 5.155674629844725, train_acc = 0.989869585468095\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 107, train_loss = 5.097975096665323, train_acc = 0.9901024685607824\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 108, train_loss = 5.041276634670794, train_acc = 0.9902189101071263\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 109, train_loss = 4.985609541647136, train_acc = 0.9904517931998137\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 110, train_loss = 4.930926258675754, train_acc = 0.9906846762925011\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 111, train_loss = 4.877234946005046, train_acc = 0.9909175593851887\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 112, train_loss = 4.824282567948103, train_acc = 0.9909175593851887\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 113, train_loss = 4.772347166202962, train_acc = 0.9909175593851887\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 114, train_loss = 4.721218335442245, train_acc = 0.9909175593851887\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 115, train_loss = 4.671127900481224, train_acc = 0.9909175593851887\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 116, train_loss = 4.621959467418492, train_acc = 0.9912668840242198\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 117, train_loss = 4.573621173389256, train_acc = 0.9918490917559385\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 118, train_loss = 4.526232183910906, train_acc = 0.9919655333022822\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 119, train_loss = 4.479507590644062, train_acc = 0.992081974848626\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 120, train_loss = 4.433662005700171, train_acc = 0.9921984163949698\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 121, train_loss = 4.388573631644249, train_acc = 0.9925477410340009\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 122, train_loss = 4.34424830134958, train_acc = 0.9925477410340009\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 123, train_loss = 4.300684295594692, train_acc = 0.9925477410340009\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 124, train_loss = 4.257839103229344, train_acc = 0.9926641825803446\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 125, train_loss = 4.215778500773013, train_acc = 0.9927806241266884\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 126, train_loss = 4.174369737505913, train_acc = 0.9928970656730322\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 127, train_loss = 4.133652293123305, train_acc = 0.9930135072193759\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 128, train_loss = 4.093644171021879, train_acc = 0.9931299487657196\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 129, train_loss = 4.054224810563028, train_acc = 0.9931299487657196\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 130, train_loss = 4.015391206368804, train_acc = 0.9931299487657196\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 131, train_loss = 3.9771355725824833, train_acc = 0.9931299487657196\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 132, train_loss = 3.9396377531811595, train_acc = 0.9932463903120633\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 133, train_loss = 3.9025985579937696, train_acc = 0.9932463903120633\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 134, train_loss = 3.8662845185026526, train_acc = 0.9932463903120633\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 135, train_loss = 3.830451974645257, train_acc = 0.9932463903120633\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 136, train_loss = 3.7953200917690992, train_acc = 0.9932463903120633\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 137, train_loss = 3.76054471405223, train_acc = 0.9933628318584071\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 138, train_loss = 3.7263851701281965, train_acc = 0.9933628318584071\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 139, train_loss = 3.6927132420241833, train_acc = 0.9933628318584071\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 140, train_loss = 3.659598769620061, train_acc = 0.9934792734047508\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 141, train_loss = 3.6269593331962824, train_acc = 0.9935957149510946\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 142, train_loss = 3.5949098696000874, train_acc = 0.993828598043782\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 143, train_loss = 3.5632691816426814, train_acc = 0.993828598043782\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 144, train_loss = 3.532130108680576, train_acc = 0.9939450395901258\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 145, train_loss = 3.501408792566508, train_acc = 0.9939450395901258\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 146, train_loss = 3.4711442976258695, train_acc = 0.9940614811364695\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 147, train_loss = 3.441300550941378, train_acc = 0.9940614811364695\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 148, train_loss = 3.4120510914362967, train_acc = 0.9941779226828132\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 149, train_loss = 3.3831032551825047, train_acc = 0.9941779226828132\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 150, train_loss = 3.354588645976037, train_acc = 0.994294364229157\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 151, train_loss = 3.3265306749381125, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 152, train_loss = 3.2989145945757627, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 153, train_loss = 3.2715879660099745, train_acc = 0.9945272473218444\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 154, train_loss = 3.244750283192843, train_acc = 0.9945272473218444\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 155, train_loss = 3.2182210460305214, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 156, train_loss = 3.1921554659493268, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 157, train_loss = 3.1663899603299797, train_acc = 0.9946436888681882\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 158, train_loss = 3.1410044175572693, train_acc = 0.9946436888681882\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 159, train_loss = 3.11589427664876, train_acc = 0.9947601304145319\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 160, train_loss = 3.091204115655273, train_acc = 0.9947601304145319\n",
      "test Acc 0.9846368715083799:\n",
      "14th- epoch: 161, train_loss = 3.066847392823547, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 162, train_loss = 3.042899017687887, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 163, train_loss = 3.019220919813961, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 164, train_loss = 2.9959127265028656, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 165, train_loss = 2.9728522426448762, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 166, train_loss = 2.950137157458812, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 167, train_loss = 2.9276233706623316, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 168, train_loss = 2.905288599897176, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 169, train_loss = 2.883269894402474, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 170, train_loss = 2.861659473273903, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 171, train_loss = 2.8404250727035105, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 172, train_loss = 2.819398278836161, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 173, train_loss = 2.7986385603435338, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 174, train_loss = 2.7782036890275776, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 175, train_loss = 2.7580721378326416, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 176, train_loss = 2.7381371767260134, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 177, train_loss = 2.7184305512346327, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 178, train_loss = 2.6990573261864483, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 179, train_loss = 2.679923818912357, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 180, train_loss = 2.6608973355032504, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 181, train_loss = 2.6423106021247804, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 182, train_loss = 2.6237803641706705, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 183, train_loss = 2.6056744374800473, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 184, train_loss = 2.5875590573996305, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 185, train_loss = 2.569831555709243, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 186, train_loss = 2.552369474200532, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 187, train_loss = 2.5349660869687796, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 188, train_loss = 2.517922669649124, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 189, train_loss = 2.5009975098073483, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 190, train_loss = 2.4842681102454662, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 191, train_loss = 2.4678150080144405, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 192, train_loss = 2.45161295379512, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 193, train_loss = 2.435645705088973, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 194, train_loss = 2.4197756480425596, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 195, train_loss = 2.404240757925436, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 196, train_loss = 2.388925001723692, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 197, train_loss = 2.3735835689585656, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 198, train_loss = 2.3586097590159625, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 199, train_loss = 2.3438166107516736, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 200, train_loss = 2.3292305085342377, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 201, train_loss = 2.314747194526717, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 202, train_loss = 2.300583926960826, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 203, train_loss = 2.2865819211583585, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 204, train_loss = 2.2727082322817296, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 205, train_loss = 2.2590975693892688, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 206, train_loss = 2.245635500177741, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 207, train_loss = 2.2323958713095635, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 208, train_loss = 2.219273818656802, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 209, train_loss = 2.206358875380829, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 210, train_loss = 2.193644904764369, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 211, train_loss = 2.181089337915182, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 212, train_loss = 2.168649189872667, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 213, train_loss = 2.15653368155472, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 214, train_loss = 2.144338474376127, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 215, train_loss = 2.1325241320300847, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 216, train_loss = 2.1207862235605717, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 217, train_loss = 2.1091755367815495, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 218, train_loss = 2.0977372073102742, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 219, train_loss = 2.0864632297307253, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 220, train_loss = 2.07535164244473, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 221, train_loss = 2.0642973966896534, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 222, train_loss = 2.0535026472061872, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 223, train_loss = 2.042723150923848, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 224, train_loss = 2.0321219514589757, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 225, train_loss = 2.021779026836157, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 226, train_loss = 2.0114112303126603, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 227, train_loss = 2.001245992258191, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 228, train_loss = 1.991251475410536, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 229, train_loss = 1.981330793350935, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "14th- epoch: 230, train_loss = 1.9715645543765277, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 231, train_loss = 1.961885328637436, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 232, train_loss = 1.9523557759821415, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 233, train_loss = 1.9429032590705901, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 234, train_loss = 1.9336893546860665, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 235, train_loss = 1.9244723625015467, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 236, train_loss = 1.9153817885089666, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 237, train_loss = 1.9064154643565416, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 238, train_loss = 1.897604427067563, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 239, train_loss = 1.8888373275985941, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 240, train_loss = 1.8802677182247862, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 241, train_loss = 1.871655156253837, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 242, train_loss = 1.8632952322950587, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 243, train_loss = 1.8549400605261326, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 244, train_loss = 1.8467255383729935, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 245, train_loss = 1.838622442097403, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 246, train_loss = 1.8305415933718905, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 247, train_loss = 1.8226801765849814, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 248, train_loss = 1.8147687949240208, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 249, train_loss = 1.8070356411626562, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 250, train_loss = 1.7993655279278755, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 251, train_loss = 1.7917357323458418, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 252, train_loss = 1.784277598024346, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 253, train_loss = 1.776825524866581, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 254, train_loss = 1.7694716081023216, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 255, train_loss = 1.7622257148614153, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 256, train_loss = 1.755080827861093, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 257, train_loss = 1.7478964105248451, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 258, train_loss = 1.740961693227291, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 259, train_loss = 1.7339556129882112, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 260, train_loss = 1.7271152945468202, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 261, train_loss = 1.7203458696603775, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 262, train_loss = 1.7136311680078506, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 263, train_loss = 1.7069861652562395, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 264, train_loss = 1.7004070580005646, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 265, train_loss = 1.6938671879470348, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 266, train_loss = 1.6874898647656664, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "14th- epoch: 267, train_loss = 1.681077832938172, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 268, train_loss = 1.674830416799523, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 269, train_loss = 1.668533249408938, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 270, train_loss = 1.6623557222774252, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 271, train_loss = 1.6562940130243078, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 272, train_loss = 1.6502285400638357, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 273, train_loss = 1.6442384123802185, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 274, train_loss = 1.638374655158259, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 275, train_loss = 1.6324398716678843, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 276, train_loss = 1.626664067269303, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 277, train_loss = 1.6208259327104315, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "14th- epoch: 278, train_loss = 1.6152423123130575, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 279, train_loss = 1.6095328703522682, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 280, train_loss = 1.603985865949653, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 281, train_loss = 1.5984124640235677, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 282, train_loss = 1.5930082984268665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 283, train_loss = 1.5874774853000417, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 284, train_loss = 1.5821353507926688, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 285, train_loss = 1.5768080899724737, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 286, train_loss = 1.5715796127915382, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 287, train_loss = 1.56631839775946, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 288, train_loss = 1.5611775306751952, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 289, train_loss = 1.5560157485306263, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 290, train_loss = 1.5510065840790048, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 291, train_loss = 1.5458789616823196, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 292, train_loss = 1.5409322840860114, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 293, train_loss = 1.5359851768007502, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 294, train_loss = 1.5311698926379904, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th- epoch: 295, train_loss = 1.526187825948, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 296, train_loss = 1.5214830748736858, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 297, train_loss = 1.516621757298708, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 298, train_loss = 1.5119596881559119, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 299, train_loss = 1.5072446105768904, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 300, train_loss = 1.502664746134542, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 301, train_loss = 1.497965358197689, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "14th- epoch: 302, train_loss = 1.4934552013874054, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 303, train_loss = 1.488949429243803, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 304, train_loss = 1.4844148233532906, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 305, train_loss = 1.4800580032169819, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 306, train_loss = 1.4755706675350666, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 307, train_loss = 1.471268324763514, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 308, train_loss = 1.4669126197695732, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 309, train_loss = 1.462612723291386, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "14th- epoch: 310, train_loss = 1.458336969197262, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 311, train_loss = 1.454183366149664, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 312, train_loss = 1.4499593737418763, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 313, train_loss = 1.4458265043795109, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 314, train_loss = 1.4416616621310823, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 315, train_loss = 1.4376051190192811, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 316, train_loss = 1.433545358479023, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 317, train_loss = 1.4295177918975241, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 318, train_loss = 1.425577212125063, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 319, train_loss = 1.4215689152479172, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 320, train_loss = 1.4177223431761377, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 321, train_loss = 1.4137553311884403, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 322, train_loss = 1.4099904869799502, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 323, train_loss = 1.4060132217709906, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 324, train_loss = 1.402406107634306, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 325, train_loss = 1.3985412120819092, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 326, train_loss = 1.3948133550584316, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 327, train_loss = 1.3911293558776379, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 328, train_loss = 1.3874848671257496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 329, train_loss = 1.3838341794908047, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 330, train_loss = 1.3802243073587306, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 331, train_loss = 1.3766261326964013, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 332, train_loss = 1.3730922949616797, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 333, train_loss = 1.3696100724046119, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 334, train_loss = 1.3660044819116592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 335, train_loss = 1.3625822365283966, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 336, train_loss = 1.359140342741739, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 337, train_loss = 1.3557284735143185, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 338, train_loss = 1.3523711934685707, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 339, train_loss = 1.348908108950127, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 340, train_loss = 1.345662375271786, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 341, train_loss = 1.342314696579706, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 342, train_loss = 1.3389991223812103, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 343, train_loss = 1.3357654524152167, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 344, train_loss = 1.332518054812681, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 345, train_loss = 1.3293041661381721, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 346, train_loss = 1.3260941902990453, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 347, train_loss = 1.3228750228881836, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 348, train_loss = 1.319821351498831, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 349, train_loss = 1.3165984737570398, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 350, train_loss = 1.3134984349017031, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 351, train_loss = 1.3104769426281564, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 352, train_loss = 1.3073962715570815, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 353, train_loss = 1.3043925886158831, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 354, train_loss = 1.3013536905054934, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 355, train_loss = 1.2983732633292675, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 356, train_loss = 1.2953476893599145, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 357, train_loss = 1.2924460011417978, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 358, train_loss = 1.2894626446068287, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 359, train_loss = 1.2864579930901527, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 360, train_loss = 1.2836484710569493, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 361, train_loss = 1.280660102784168, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 362, train_loss = 1.277776772796642, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 363, train_loss = 1.274945276498329, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 364, train_loss = 1.272155697166454, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 365, train_loss = 1.2693208158016205, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 366, train_loss = 1.2665800414979458, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 367, train_loss = 1.2638219594955444, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 368, train_loss = 1.2611081252689473, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 369, train_loss = 1.2583686957950704, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 370, train_loss = 1.2556872479617596, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 371, train_loss = 1.2529650789801963, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 372, train_loss = 1.250394752889406, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 373, train_loss = 1.2477031412418, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 374, train_loss = 1.2450388806755655, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 375, train_loss = 1.242477795749437, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 376, train_loss = 1.2398966811597347, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 377, train_loss = 1.2373678510193713, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 378, train_loss = 1.2347670843009837, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 379, train_loss = 1.2323007707600482, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 380, train_loss = 1.2296644796733744, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 381, train_loss = 1.227203405171167, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 382, train_loss = 1.2248050731723197, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 383, train_loss = 1.2222520833020099, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 384, train_loss = 1.2198356215958484, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 385, train_loss = 1.2173649842734449, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 386, train_loss = 1.2149551225011237, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 387, train_loss = 1.2125776435132138, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 388, train_loss = 1.2101513668894768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 389, train_loss = 1.2078395821154118, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 390, train_loss = 1.2053859147126786, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 391, train_loss = 1.2031657348270528, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 392, train_loss = 1.2008093136246316, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 393, train_loss = 1.1984124307637103, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 394, train_loss = 1.196164285123814, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 395, train_loss = 1.1938546858727932, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 396, train_loss = 1.1916492655873299, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 397, train_loss = 1.1893370275793131, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 398, train_loss = 1.1871313229203224, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 399, train_loss = 1.1848888285458088, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 400, train_loss = 1.182727118342882, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 401, train_loss = 1.1804811097681522, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 402, train_loss = 1.1782203453185502, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 403, train_loss = 1.1761309454741422, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 404, train_loss = 1.174025196582079, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 405, train_loss = 1.1718726443650667, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 406, train_loss = 1.1696447966096457, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 407, train_loss = 1.1675849556922913, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 408, train_loss = 1.1655195566418115, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 409, train_loss = 1.1633852161467075, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 410, train_loss = 1.1612698547542095, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 411, train_loss = 1.1591898550686892, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 412, train_loss = 1.1572020227613393, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 413, train_loss = 1.155198622494936, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 414, train_loss = 1.1530926525592804, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 415, train_loss = 1.1510718700883444, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 416, train_loss = 1.14910034215427, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 417, train_loss = 1.1470944968459662, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 418, train_loss = 1.1451205722987652, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 419, train_loss = 1.1431323724391405, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 420, train_loss = 1.141121830791235, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 421, train_loss = 1.139242809265852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 422, train_loss = 1.1372915456595365, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 423, train_loss = 1.1353034625353757, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 424, train_loss = 1.1334122605621815, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 425, train_loss = 1.1315634362399578, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 426, train_loss = 1.1296181356010493, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 427, train_loss = 1.1278094748558942, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 428, train_loss = 1.125836963445181, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 429, train_loss = 1.1240523966553155, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 430, train_loss = 1.122239929944044, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 431, train_loss = 1.1202725234034006, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 432, train_loss = 1.1185114942491055, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 433, train_loss = 1.116725355386734, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 434, train_loss = 1.114827142417198, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 435, train_loss = 1.113166332244873, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 436, train_loss = 1.1112749030289706, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 437, train_loss = 1.109526398271555, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 438, train_loss = 1.1076944656670094, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 439, train_loss = 1.1059780853393022, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 440, train_loss = 1.1042094317672309, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 441, train_loss = 1.1024694492516574, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 442, train_loss = 1.1007231709954794, train_acc = 0.9980204937121565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 443, train_loss = 1.0990420567395631, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 444, train_loss = 1.0972658743557986, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 445, train_loss = 1.0956534395518247, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 446, train_loss = 1.0938854726555292, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 447, train_loss = 1.0922770599427167, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 448, train_loss = 1.0905291264352854, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 449, train_loss = 1.0889556569454726, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 450, train_loss = 1.0872051417827606, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 451, train_loss = 1.0855610072612762, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 452, train_loss = 1.0839824067952577, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 453, train_loss = 1.08228494352079, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 454, train_loss = 1.0807767746446189, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 455, train_loss = 1.0790995843708515, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 456, train_loss = 1.0774958406982478, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 457, train_loss = 1.0758975632488728, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 458, train_loss = 1.074295981467003, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 459, train_loss = 1.0726899740693625, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 460, train_loss = 1.0712563370761927, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 461, train_loss = 1.0695487931370735, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 462, train_loss = 1.0680536540749017, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 463, train_loss = 1.0664837347867433, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 464, train_loss = 1.064930414169794, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 465, train_loss = 1.0634726770222187, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 466, train_loss = 1.0618162850441877, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 467, train_loss = 1.0604291558265686, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 468, train_loss = 1.0588932807149831, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 469, train_loss = 1.0573726134898607, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 470, train_loss = 1.0558576534094755, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 471, train_loss = 1.0544271940889303, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 472, train_loss = 1.0529057756066322, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 473, train_loss = 1.0515223691763822, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 474, train_loss = 1.050023907184368, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 475, train_loss = 1.0485610477626324, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 476, train_loss = 1.0470561484398786, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 477, train_loss = 1.0456186743977014, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 478, train_loss = 1.0442193237540778, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 479, train_loss = 1.04287395751453, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 480, train_loss = 1.041329264640808, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 481, train_loss = 1.0399958888592664, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 482, train_loss = 1.0385314039885998, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 483, train_loss = 1.0371232392790262, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 484, train_loss = 1.0358114205300808, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 485, train_loss = 1.0344097887573298, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 486, train_loss = 1.032970422267681, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 487, train_loss = 1.0316779302957002, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 488, train_loss = 1.030235548823839, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 489, train_loss = 1.028966948390007, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 490, train_loss = 1.027617760002613, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 491, train_loss = 1.0262452363967896, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 492, train_loss = 1.0249289758503437, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 493, train_loss = 1.023599269479746, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 494, train_loss = 1.0222135186195374, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 495, train_loss = 1.0209385218622629, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 496, train_loss = 1.0196181895735208, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 497, train_loss = 1.018322399497265, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 498, train_loss = 1.0170187180337962, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "14th- epoch: 499, train_loss = 1.0157444390060846, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████████████████████████▋                                     | 14/30 [1:35:26<1:49:33, 410.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "15th- epoch: 0, train_loss = 272.1954907178879, train_acc = 0.48509548206800185\n",
      "test Acc 0.5633147113594041:\n",
      "15th- epoch: 1, train_loss = 207.9619860649109, train_acc = 0.564275733581742\n",
      "test Acc 0.5735567970204841:\n",
      "15th- epoch: 2, train_loss = 161.22942781448364, train_acc = 0.583605030274802\n",
      "test Acc 0.6196461824953445:\n",
      "15th- epoch: 3, train_loss = 135.2816698551178, train_acc = 0.6688402421984164\n",
      "test Acc 0.7178770949720671:\n",
      "15th- epoch: 4, train_loss = 116.62349569797516, train_acc = 0.7433628318584071\n",
      "test Acc 0.7728119180633147:\n",
      "15th- epoch: 5, train_loss = 101.37177631258965, train_acc = 0.7862133209129017\n",
      "test Acc 0.792364990689013:\n",
      "15th- epoch: 6, train_loss = 88.77259781956673, train_acc = 0.8003027480204937\n",
      "test Acc 0.8035381750465549:\n",
      "15th- epoch: 7, train_loss = 78.547472178936, train_acc = 0.8099673963670238\n",
      "test Acc 0.8095903165735568:\n",
      "15th- epoch: 8, train_loss = 70.12542676925659, train_acc = 0.8209129017233349\n",
      "test Acc 0.835195530726257:\n",
      "15th- epoch: 9, train_loss = 63.01460140943527, train_acc = 0.8514205868653936\n",
      "test Acc 0.8621973929236499:\n",
      "15th- epoch: 10, train_loss = 56.896534740924835, train_acc = 0.8798323241732651\n",
      "test Acc 0.8915270018621974:\n",
      "15th- epoch: 11, train_loss = 51.563772052526474, train_acc = 0.9081276199347927\n",
      "test Acc 0.9199255121042831:\n",
      "15th- epoch: 12, train_loss = 46.88031527400017, train_acc = 0.9266418258034467\n",
      "test Acc 0.9301675977653632:\n",
      "15th- epoch: 13, train_loss = 42.77017739415169, train_acc = 0.9338612016767582\n",
      "test Acc 0.9348230912476723:\n",
      "15th- epoch: 14, train_loss = 39.17997821420431, train_acc = 0.937936655798789\n",
      "test Acc 0.9413407821229051:\n",
      "15th- epoch: 15, train_loss = 36.063626654446125, train_acc = 0.9417792268281323\n",
      "test Acc 0.9455307262569832:\n",
      "15th- epoch: 16, train_loss = 33.37258645147085, train_acc = 0.9445738239403819\n",
      "test Acc 0.9497206703910615:\n",
      "15th- epoch: 17, train_loss = 31.05857203900814, train_acc = 0.9489986027014439\n",
      "test Acc 0.9529795158286778:\n",
      "15th- epoch: 18, train_loss = 29.067771673202515, train_acc = 0.9527247321844434\n",
      "test Acc 0.9548417132216015:\n",
      "15th- epoch: 19, train_loss = 27.350850649178028, train_acc = 0.9542384722869119\n",
      "test Acc 0.9553072625698324:\n",
      "15th- epoch: 20, train_loss = 25.863059163093567, train_acc = 0.9557522123893806\n",
      "test Acc 0.9562383612662942:\n",
      "15th- epoch: 21, train_loss = 24.564480181783438, train_acc = 0.9577317186772241\n",
      "test Acc 0.957169459962756:\n",
      "15th- epoch: 22, train_loss = 23.42308944836259, train_acc = 0.9593619003260363\n",
      "test Acc 0.9585661080074488:\n",
      "15th- epoch: 23, train_loss = 22.410266902297735, train_acc = 0.9601769911504425\n",
      "test Acc 0.9599627560521415:\n",
      "15th- epoch: 24, train_loss = 21.50344279408455, train_acc = 0.9609920819748486\n",
      "test Acc 0.9604283054003724:\n",
      "15th- epoch: 25, train_loss = 20.684407152235508, train_acc = 0.9620400558919422\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 26, train_loss = 19.94023922085762, train_acc = 0.9628551467163484\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 27, train_loss = 19.259485952556133, train_acc = 0.9636702375407545\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 28, train_loss = 18.63377933949232, train_acc = 0.9646017699115044\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 29, train_loss = 18.055083207786083, train_acc = 0.9653004191895669\n",
      "test Acc 0.9608938547486033:\n",
      "15th- epoch: 30, train_loss = 17.516382563859224, train_acc = 0.9662319515603167\n",
      "test Acc 0.9613594040968343:\n",
      "15th- epoch: 31, train_loss = 17.012025486677885, train_acc = 0.9672799254774104\n",
      "test Acc 0.9622905027932961:\n",
      "15th- epoch: 32, train_loss = 16.538380533456802, train_acc = 0.9671634839310667\n",
      "test Acc 0.962756052141527:\n",
      "15th- epoch: 33, train_loss = 16.092892102897167, train_acc = 0.9682114578481602\n",
      "test Acc 0.9632216014897579:\n",
      "15th- epoch: 34, train_loss = 15.672837983816862, train_acc = 0.9690265486725663\n",
      "test Acc 0.9632216014897579:\n",
      "15th- epoch: 35, train_loss = 15.275825295597315, train_acc = 0.97007452258966\n",
      "test Acc 0.9636871508379888:\n",
      "15th- epoch: 36, train_loss = 14.900212198495865, train_acc = 0.970540288775035\n",
      "test Acc 0.9650837988826816:\n",
      "15th- epoch: 37, train_loss = 14.543690722435713, train_acc = 0.9711224965067536\n",
      "test Acc 0.9669459962756052:\n",
      "15th- epoch: 38, train_loss = 14.205084331333637, train_acc = 0.9720540288775035\n",
      "test Acc 0.9678770949720671:\n",
      "15th- epoch: 39, train_loss = 13.882667444646358, train_acc = 0.9732184443409408\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 40, train_loss = 13.575278472155333, train_acc = 0.9738006520726595\n",
      "test Acc 0.9683426443202979:\n",
      "15th- epoch: 41, train_loss = 13.281630732119083, train_acc = 0.9743828598043782\n",
      "test Acc 0.9697392923649907:\n",
      "15th- epoch: 42, train_loss = 13.001030173152685, train_acc = 0.9751979506287843\n",
      "test Acc 0.9720670391061452:\n",
      "15th- epoch: 43, train_loss = 12.732573978602886, train_acc = 0.9756637168141593\n",
      "test Acc 0.9725325884543762:\n",
      "15th- epoch: 44, train_loss = 12.47560428082943, train_acc = 0.9763623660922217\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 45, train_loss = 12.229083370417356, train_acc = 0.9765952491849091\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 46, train_loss = 11.992236416786909, train_acc = 0.9768281322775967\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 47, train_loss = 11.764416012912989, train_acc = 0.9776432231020028\n",
      "test Acc 0.972998137802607:\n",
      "15th- epoch: 48, train_loss = 11.545025940984488, train_acc = 0.9785747554727526\n",
      "test Acc 0.973463687150838:\n",
      "15th- epoch: 49, train_loss = 11.333550211042166, train_acc = 0.9795062878435026\n",
      "test Acc 0.9739292364990689:\n",
      "15th- epoch: 50, train_loss = 11.129712037742138, train_acc = 0.9798556124825337\n",
      "test Acc 0.9743947858472998:\n",
      "15th- epoch: 51, train_loss = 10.93263316527009, train_acc = 0.9800884955752213\n",
      "test Acc 0.9748603351955307:\n",
      "15th- epoch: 52, train_loss = 10.742101984098554, train_acc = 0.9803213786679087\n",
      "test Acc 0.9753258845437617:\n",
      "15th- epoch: 53, train_loss = 10.557746103033423, train_acc = 0.9804378202142524\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 54, train_loss = 10.37911581993103, train_acc = 0.9807871448532837\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 55, train_loss = 10.206060580909252, train_acc = 0.9811364694923148\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 56, train_loss = 10.038073644042015, train_acc = 0.9817186772240335\n",
      "test Acc 0.9767225325884544:\n",
      "15th- epoch: 57, train_loss = 9.874985320493579, train_acc = 0.9818351187703773\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 58, train_loss = 9.716446096077561, train_acc = 0.9820680018630648\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 59, train_loss = 9.562292076647282, train_acc = 0.9821844434094085\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 60, train_loss = 9.412213334813714, train_acc = 0.9825337680484397\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 61, train_loss = 9.266068153083324, train_acc = 0.9826502095947834\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 62, train_loss = 9.123682925477624, train_acc = 0.9827666511411272\n",
      "test Acc 0.9757914338919925:\n",
      "15th- epoch: 63, train_loss = 8.984863283112645, train_acc = 0.9828830926874709\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 64, train_loss = 8.849607748910785, train_acc = 0.9828830926874709\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 65, train_loss = 8.717532498762012, train_acc = 0.9829995342338146\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 66, train_loss = 8.588593125343323, train_acc = 0.9829995342338146\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 67, train_loss = 8.462564272806048, train_acc = 0.9831159757801584\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 68, train_loss = 8.339334204792976, train_acc = 0.9833488588728458\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 69, train_loss = 8.21906278654933, train_acc = 0.9833488588728458\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 70, train_loss = 8.10148480720818, train_acc = 0.983698183511877\n",
      "test Acc 0.9762569832402235:\n",
      "15th- epoch: 71, train_loss = 7.98650049418211, train_acc = 0.9839310666045645\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 72, train_loss = 7.873986283317208, train_acc = 0.984163949697252\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 73, train_loss = 7.763827098533511, train_acc = 0.9842803912435957\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 74, train_loss = 7.656008027493954, train_acc = 0.9843968327899395\n",
      "test Acc 0.9771880819366853:\n",
      "15th- epoch: 75, train_loss = 7.550387164577842, train_acc = 0.9847461574289706\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 76, train_loss = 7.446806164458394, train_acc = 0.9847461574289706\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 77, train_loss = 7.345401208847761, train_acc = 0.9849790405216581\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 78, train_loss = 7.246162882074714, train_acc = 0.9850954820680019\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 79, train_loss = 7.148959523066878, train_acc = 0.9852119236143456\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 80, train_loss = 7.053660927340388, train_acc = 0.9852119236143456\n",
      "test Acc 0.9776536312849162:\n",
      "15th- epoch: 81, train_loss = 6.960302606225014, train_acc = 0.9855612482533768\n",
      "test Acc 0.9781191806331471:\n",
      "15th- epoch: 82, train_loss = 6.868783516809344, train_acc = 0.985910572892408\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 83, train_loss = 6.778902480378747, train_acc = 0.9862598975314392\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 84, train_loss = 6.6909210700541735, train_acc = 0.9866092221704704\n",
      "test Acc 0.9795158286778398:\n",
      "15th- epoch: 85, train_loss = 6.604520393535495, train_acc = 0.9866092221704704\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 86, train_loss = 6.519820872694254, train_acc = 0.9867256637168141\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 87, train_loss = 6.436667921021581, train_acc = 0.9870749883558454\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 88, train_loss = 6.355215406045318, train_acc = 0.9873078714485328\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 89, train_loss = 6.275170287117362, train_acc = 0.9875407545412203\n",
      "test Acc 0.9799813780260708:\n",
      "15th- epoch: 90, train_loss = 6.196707002818584, train_acc = 0.9878900791802515\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 91, train_loss = 6.119781367480755, train_acc = 0.9883558453656265\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 92, train_loss = 6.044394662603736, train_acc = 0.9883558453656265\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 93, train_loss = 5.970367459580302, train_acc = 0.9884722869119702\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 94, train_loss = 5.897746117785573, train_acc = 0.9885887284583139\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 95, train_loss = 5.8264839965850115, train_acc = 0.9889380530973452\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 96, train_loss = 5.7566146068274975, train_acc = 0.9892873777363763\n",
      "test Acc 0.9804469273743017:\n",
      "15th- epoch: 97, train_loss = 5.6881116684526205, train_acc = 0.9895202608290639\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 98, train_loss = 5.620846824720502, train_acc = 0.9897531439217513\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 99, train_loss = 5.55489182844758, train_acc = 0.989869585468095\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 100, train_loss = 5.49042300414294, train_acc = 0.9902189101071263\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 101, train_loss = 5.4272167617455125, train_acc = 0.9904517931998137\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 102, train_loss = 5.365139142610133, train_acc = 0.9904517931998137\n",
      "test Acc 0.9809124767225326:\n",
      "15th- epoch: 103, train_loss = 5.304164491593838, train_acc = 0.9904517931998137\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 104, train_loss = 5.244361218996346, train_acc = 0.9905682347461574\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 105, train_loss = 5.185559696517885, train_acc = 0.9905682347461574\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 106, train_loss = 5.127840672619641, train_acc = 0.9905682347461574\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 107, train_loss = 5.071201739832759, train_acc = 0.9906846762925011\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 108, train_loss = 5.015585116110742, train_acc = 0.9904517931998137\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 109, train_loss = 4.960852007381618, train_acc = 0.9905682347461574\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 110, train_loss = 4.907152985222638, train_acc = 0.9906846762925011\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 111, train_loss = 4.854385548271239, train_acc = 0.9909175593851887\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 112, train_loss = 4.802490464411676, train_acc = 0.9911504424778761\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 113, train_loss = 4.751452149823308, train_acc = 0.9917326502095948\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 114, train_loss = 4.701293841935694, train_acc = 0.9918490917559385\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 115, train_loss = 4.6519924541935325, train_acc = 0.9918490917559385\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 116, train_loss = 4.603454017080367, train_acc = 0.992081974848626\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 117, train_loss = 4.555756641551852, train_acc = 0.9923148579413135\n",
      "test Acc 0.9813780260707635:\n",
      "15th- epoch: 118, train_loss = 4.508814443834126, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 119, train_loss = 4.462617942132056, train_acc = 0.9924312994876572\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 120, train_loss = 4.417158358730376, train_acc = 0.9924312994876572\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 121, train_loss = 4.372499790973961, train_acc = 0.9924312994876572\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 122, train_loss = 4.328615820035338, train_acc = 0.9924312994876572\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 123, train_loss = 4.285393484868109, train_acc = 0.9924312994876572\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 124, train_loss = 4.242990643717349, train_acc = 0.9925477410340009\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 125, train_loss = 4.201143046841025, train_acc = 0.9925477410340009\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 126, train_loss = 4.1601298758760095, train_acc = 0.9926641825803446\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 127, train_loss = 4.119667840190232, train_acc = 0.9926641825803446\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 128, train_loss = 4.079919089563191, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 129, train_loss = 4.040671016089618, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 130, train_loss = 4.002137894742191, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 131, train_loss = 3.9642766676843166, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 132, train_loss = 3.9268781589344144, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 133, train_loss = 3.889873976819217, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 134, train_loss = 3.853659681044519, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 135, train_loss = 3.817874007858336, train_acc = 0.9931299487657196\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 136, train_loss = 3.782699793577194, train_acc = 0.9932463903120633\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 137, train_loss = 3.7480684532783926, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 138, train_loss = 3.7138865161687136, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 139, train_loss = 3.6803277041763067, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 140, train_loss = 3.647288059350103, train_acc = 0.9934792734047508\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 141, train_loss = 3.614629214629531, train_acc = 0.9937121564974383\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 142, train_loss = 3.582531226798892, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 143, train_loss = 3.550931591540575, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 144, train_loss = 3.5197868864051998, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 145, train_loss = 3.488995874300599, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 146, train_loss = 3.458811833988875, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 147, train_loss = 3.428956525400281, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 148, train_loss = 3.3996465746313334, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 149, train_loss = 3.370704240631312, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 150, train_loss = 3.34222251502797, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 151, train_loss = 3.3142265141941607, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 152, train_loss = 3.2865687287412584, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 153, train_loss = 3.2592798392288387, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 154, train_loss = 3.2324288957752287, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 155, train_loss = 3.2059417772106826, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 156, train_loss = 3.179831399116665, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 157, train_loss = 3.1541589512489736, train_acc = 0.9951094550535631\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 158, train_loss = 3.1287575396709144, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 159, train_loss = 3.10375450970605, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 160, train_loss = 3.0791543405503035, train_acc = 0.9952258965999069\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 161, train_loss = 3.054731063079089, train_acc = 0.9953423381462506\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 162, train_loss = 3.030858220998198, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 163, train_loss = 3.0072107654996216, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 164, train_loss = 2.9838563916273415, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 165, train_loss = 2.9609168698079884, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 166, train_loss = 2.938226224388927, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 167, train_loss = 2.9158564265817404, train_acc = 0.9954587796925943\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 168, train_loss = 2.8937945826910436, train_acc = 0.995575221238938\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 169, train_loss = 2.8720862246118486, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 170, train_loss = 2.8505773334763944, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 171, train_loss = 2.8294088416732848, train_acc = 0.9956916627852818\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 172, train_loss = 2.8085333122871816, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 173, train_loss = 2.7879074569791555, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 174, train_loss = 2.7675890480168164, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 175, train_loss = 2.7475700438953936, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 176, train_loss = 2.7277274350635707, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 177, train_loss = 2.7082336861640215, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 178, train_loss = 2.688962874468416, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 179, train_loss = 2.669945180416107, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 180, train_loss = 2.6511583134997636, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 181, train_loss = 2.6326237216126174, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 182, train_loss = 2.614366538822651, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 183, train_loss = 2.596369542181492, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 184, train_loss = 2.578564463183284, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 185, train_loss = 2.561005511553958, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 186, train_loss = 2.543752431869507, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 187, train_loss = 2.526628538267687, train_acc = 0.9959245458779693\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 188, train_loss = 2.509781563654542, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 189, train_loss = 2.4932305819820613, train_acc = 0.996040987424313\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 190, train_loss = 2.4767772119957954, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 191, train_loss = 2.460668172687292, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 192, train_loss = 2.44467377406545, train_acc = 0.9961574289706567\n",
      "test Acc 0.9818435754189944:\n",
      "15th- epoch: 193, train_loss = 2.428899359656498, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 194, train_loss = 2.4133489094674587, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 195, train_loss = 2.397974844323471, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 196, train_loss = 2.382825617445633, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 197, train_loss = 2.3677926789969206, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 198, train_loss = 2.353079530177638, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 199, train_loss = 2.338563734665513, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 200, train_loss = 2.324119322700426, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 201, train_loss = 2.3099478613585234, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 202, train_loss = 2.2960050005931407, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 203, train_loss = 2.282159101916477, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 204, train_loss = 2.2685565769206733, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 205, train_loss = 2.255103401839733, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 206, train_loss = 2.2418519135098904, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 207, train_loss = 2.228795300005004, train_acc = 0.9962738705170004\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 208, train_loss = 2.215877852169797, train_acc = 0.9963903120633442\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 209, train_loss = 2.2031486816704273, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 210, train_loss = 2.190606714459136, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 211, train_loss = 2.178227963624522, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 212, train_loss = 2.165944542037323, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 213, train_loss = 2.153909896267578, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 214, train_loss = 2.1419577666092664, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 215, train_loss = 2.1301946889143437, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 216, train_loss = 2.118584458483383, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 217, train_loss = 2.107148112729192, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 218, train_loss = 2.095847261371091, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 219, train_loss = 2.084565958706662, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 220, train_loss = 2.0736625615973026, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 221, train_loss = 2.062714258907363, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 222, train_loss = 2.051978303818032, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 223, train_loss = 2.041333392262459, train_acc = 0.996506753609688\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 224, train_loss = 2.030921359779313, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 225, train_loss = 2.0204811219591647, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 226, train_loss = 2.0102893027942628, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 227, train_loss = 2.00021281093359, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 228, train_loss = 1.9901934179943055, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 229, train_loss = 1.9803376111667603, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 230, train_loss = 1.9705498989205807, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 231, train_loss = 1.9609836812596768, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 232, train_loss = 1.9514463233062997, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 233, train_loss = 1.9420471066841856, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 234, train_loss = 1.9327211752533913, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 235, train_loss = 1.923625779687427, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 236, train_loss = 1.9145263880491257, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "15th- epoch: 237, train_loss = 1.9056377410888672, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 238, train_loss = 1.896840619505383, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 239, train_loss = 1.8881220631301403, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 240, train_loss = 1.8795469464967027, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 241, train_loss = 1.8710205120733008, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 242, train_loss = 1.8626255989074707, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 243, train_loss = 1.8543032059678808, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 244, train_loss = 1.846114826737903, train_acc = 0.9967396367023754\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 245, train_loss = 1.837964185862802, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 246, train_loss = 1.8299600556492805, train_acc = 0.9969725197950629\n",
      "test Acc 0.9827746741154563:\n",
      "15th- epoch: 247, train_loss = 1.822019768296741, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 248, train_loss = 1.8141992191085592, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 249, train_loss = 1.806392777711153, train_acc = 0.9972054028877504\n",
      "test Acc 0.9832402234636871:\n",
      "15th- epoch: 250, train_loss = 1.7987555438885465, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 251, train_loss = 1.7911859651794657, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 252, train_loss = 1.7836937233805656, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 253, train_loss = 1.7762598110130057, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 254, train_loss = 1.7689450420439243, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 255, train_loss = 1.7616681518265978, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 256, train_loss = 1.7545441538095474, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 257, train_loss = 1.7474296428263187, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 258, train_loss = 1.7404217073926702, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 259, train_loss = 1.7335249098250642, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 260, train_loss = 1.7266757003962994, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 261, train_loss = 1.7198476903140545, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 262, train_loss = 1.7131713504204527, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 263, train_loss = 1.7065041126916185, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 264, train_loss = 1.6999310230603442, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "15th- epoch: 265, train_loss = 1.6934061410138384, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 266, train_loss = 1.686964675784111, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 267, train_loss = 1.6805673316121101, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 268, train_loss = 1.6742935763904825, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 269, train_loss = 1.668038584291935, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 270, train_loss = 1.6618397533893585, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 271, train_loss = 1.6557280408451334, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 272, train_loss = 1.6496545063564554, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 273, train_loss = 1.6436305654933676, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 274, train_loss = 1.6376810483634472, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 275, train_loss = 1.6318126382539049, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 276, train_loss = 1.6259494051337242, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 277, train_loss = 1.6202202439308167, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 278, train_loss = 1.6145742969820276, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 279, train_loss = 1.6089528674492612, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 280, train_loss = 1.6033497415482998, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 281, train_loss = 1.597807044745423, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 282, train_loss = 1.5923195952782407, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 283, train_loss = 1.5869068130850792, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 284, train_loss = 1.5815282749244943, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 285, train_loss = 1.5761896036565304, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 286, train_loss = 1.5709187475731596, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 287, train_loss = 1.5657059414079413, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 288, train_loss = 1.5605099635431543, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 289, train_loss = 1.5554098648717627, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 290, train_loss = 1.5503039583563805, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 291, train_loss = 1.5452991761267185, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 292, train_loss = 1.5403146581957117, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 293, train_loss = 1.5353198772063479, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 294, train_loss = 1.5304775846889243, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 295, train_loss = 1.525621209293604, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 296, train_loss = 1.520853346795775, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 297, train_loss = 1.5160107227275148, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 298, train_loss = 1.511389497667551, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 299, train_loss = 1.506710208952427, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 300, train_loss = 1.5020866729319096, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 301, train_loss = 1.4974773612921126, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 302, train_loss = 1.4929562956094742, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 303, train_loss = 1.488494171469938, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 304, train_loss = 1.4839769725804217, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 305, train_loss = 1.4795754824881442, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 306, train_loss = 1.4751509726047516, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 307, train_loss = 1.4708020240068436, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 308, train_loss = 1.4665605661575682, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 309, train_loss = 1.462263185530901, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 310, train_loss = 1.4580194999580272, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 311, train_loss = 1.4537563808262348, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 312, train_loss = 1.4496492060716264, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 313, train_loss = 1.4454564315383323, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 314, train_loss = 1.4414233167772181, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 315, train_loss = 1.4373513981699944, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 316, train_loss = 1.4333491859142669, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 317, train_loss = 1.429357876360882, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 318, train_loss = 1.4253642086987384, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 319, train_loss = 1.4214571937918663, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 320, train_loss = 1.417564810544718, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 321, train_loss = 1.4136515048448928, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 322, train_loss = 1.4098397071356885, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 323, train_loss = 1.4061246439814568, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 324, train_loss = 1.4023401724989526, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 325, train_loss = 1.3985715347225778, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 326, train_loss = 1.3948777715559117, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 327, train_loss = 1.3912191179697402, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 328, train_loss = 1.3875825355644338, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 329, train_loss = 1.3839654177427292, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 330, train_loss = 1.3803652226924896, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 331, train_loss = 1.376805278181564, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 332, train_loss = 1.373321283608675, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 333, train_loss = 1.3698101341724396, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 334, train_loss = 1.366323884576559, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 335, train_loss = 1.3628774682874791, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 336, train_loss = 1.3595068069989793, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 337, train_loss = 1.3560525451903231, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 338, train_loss = 1.3526922154123895, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 339, train_loss = 1.3493261237745173, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 340, train_loss = 1.3461006035213359, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 341, train_loss = 1.3427480297978036, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 342, train_loss = 1.3395236060023308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 343, train_loss = 1.3362053471500985, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 344, train_loss = 1.3330337963998318, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 345, train_loss = 1.3298288322985172, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 346, train_loss = 1.326702828228008, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 347, train_loss = 1.323553640395403, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 348, train_loss = 1.3203831638093106, train_acc = 0.9977876106194691\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 349, train_loss = 1.3172875978052616, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 350, train_loss = 1.3142437090282328, train_acc = 0.9977876106194691\n",
      "test Acc 0.984171322160149:\n",
      "15th- epoch: 351, train_loss = 1.3111900488729589, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 352, train_loss = 1.3081811219453812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 353, train_loss = 1.305154487490654, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 354, train_loss = 1.3021625727415085, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 355, train_loss = 1.299224556714762, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 356, train_loss = 1.2962444300646894, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 357, train_loss = 1.293303715705406, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 358, train_loss = 1.2904511640663259, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 359, train_loss = 1.2875951677560806, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 360, train_loss = 1.2847170283203013, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 361, train_loss = 1.2818772693281062, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 362, train_loss = 1.2790461393888108, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 363, train_loss = 1.2762589367921464, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 364, train_loss = 1.273513934283983, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 365, train_loss = 1.2707152788643725, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 366, train_loss = 1.2679842512006871, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 367, train_loss = 1.2652508417959325, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 368, train_loss = 1.2625406607985497, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 369, train_loss = 1.259840828657616, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 370, train_loss = 1.2572437922353856, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 371, train_loss = 1.2545874032075517, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 372, train_loss = 1.251905842393171, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 373, train_loss = 1.2493052768404596, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 374, train_loss = 1.2467400754685514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 375, train_loss = 1.244168572127819, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "15th- epoch: 376, train_loss = 1.2415871632401831, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 377, train_loss = 1.2390564195811749, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 378, train_loss = 1.2365874287788756, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 379, train_loss = 1.2340538439457305, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 380, train_loss = 1.2316003466839902, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 381, train_loss = 1.2290948902373202, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 382, train_loss = 1.2266271598637104, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 383, train_loss = 1.224244773387909, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 384, train_loss = 1.221768872172106, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 385, train_loss = 1.2193883297150023, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 386, train_loss = 1.2169887982308865, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 387, train_loss = 1.214618263154989, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 388, train_loss = 1.2122778221964836, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 389, train_loss = 1.2098967085184995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 390, train_loss = 1.2075759582221508, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 391, train_loss = 1.2052557418646757, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 392, train_loss = 1.2029716608521994, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 393, train_loss = 1.2006930125353392, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 394, train_loss = 1.1984433929028455, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 395, train_loss = 1.196188174188137, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 396, train_loss = 1.1939179661276285, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 397, train_loss = 1.1917139142751694, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 398, train_loss = 1.1894821971654892, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 399, train_loss = 1.1872766079904977, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 400, train_loss = 1.1851115015742835, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 401, train_loss = 1.1829438606800977, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 402, train_loss = 1.1807390227913857, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 403, train_loss = 1.1785989180207253, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 404, train_loss = 1.1764636213483755, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 405, train_loss = 1.174350651592249, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 406, train_loss = 1.172191247344017, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 407, train_loss = 1.1701671530900057, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 408, train_loss = 1.1680315049889032, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 409, train_loss = 1.1659862461092416, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 410, train_loss = 1.1638899209501687, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 411, train_loss = 1.1618725346925203, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 412, train_loss = 1.1598345935344696, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 413, train_loss = 1.1578223047254141, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 414, train_loss = 1.1557933328149375, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 415, train_loss = 1.1538072215917055, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 416, train_loss = 1.1517946310341358, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 417, train_loss = 1.149830279260641, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 418, train_loss = 1.1478707840142306, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 419, train_loss = 1.1459203399717808, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 420, train_loss = 1.143976909428602, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 421, train_loss = 1.142015921563143, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 422, train_loss = 1.1400814577937126, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 423, train_loss = 1.1382299760880414, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 424, train_loss = 1.1363166272640228, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 425, train_loss = 1.13438986116671, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 426, train_loss = 1.1325831736030523, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 427, train_loss = 1.1306703252193984, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 428, train_loss = 1.1287897998990957, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 429, train_loss = 1.1270417372288648, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 430, train_loss = 1.1251015029847622, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 431, train_loss = 1.1233658716082573, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 432, train_loss = 1.1215380132198334, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 433, train_loss = 1.119708962738514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 434, train_loss = 1.1179820212128107, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 435, train_loss = 1.1161704709229525, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 436, train_loss = 1.1143614662287291, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 437, train_loss = 1.1127066761255264, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 438, train_loss = 1.1108323025109712, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 439, train_loss = 1.109183074295288, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 440, train_loss = 1.1073532613518182, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 441, train_loss = 1.1057237461209297, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15th- epoch: 442, train_loss = 1.1040082362887915, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 443, train_loss = 1.1022237564029638, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 444, train_loss = 1.1006243290903512, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 445, train_loss = 1.0988606177270412, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 446, train_loss = 1.0972373423574027, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 447, train_loss = 1.0955522867443506, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 448, train_loss = 1.0939371796848718, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 449, train_loss = 1.0922155380249023, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 450, train_loss = 1.0906674390134867, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 451, train_loss = 1.0890056180360261, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 452, train_loss = 1.0873135340807494, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 453, train_loss = 1.0857593280670699, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 454, train_loss = 1.084127043694025, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 455, train_loss = 1.082614158600336, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 456, train_loss = 1.080948760121828, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 457, train_loss = 1.079409892350668, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 458, train_loss = 1.0778204513189849, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 459, train_loss = 1.0762601358292159, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 460, train_loss = 1.0746655724942684, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 461, train_loss = 1.0731805302202702, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 462, train_loss = 1.0716250824334566, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 463, train_loss = 1.0701020745036658, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 464, train_loss = 1.0685393003222998, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 465, train_loss = 1.06703856959939, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 466, train_loss = 1.0655730006692465, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 467, train_loss = 1.0640349499881268, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 468, train_loss = 1.0625015037658159, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 469, train_loss = 1.0610680542886257, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 470, train_loss = 1.0595741669239942, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 471, train_loss = 1.0581148105266038, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 472, train_loss = 1.056594288587803, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 473, train_loss = 1.0551804825663567, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 474, train_loss = 1.0537522522208747, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 475, train_loss = 1.0522693432867527, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 476, train_loss = 1.0507830865681171, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 477, train_loss = 1.049455783009762, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 478, train_loss = 1.0479985984566156, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 479, train_loss = 1.0466328834590968, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 480, train_loss = 1.0451400888559874, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 481, train_loss = 1.0437978208065033, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 482, train_loss = 1.0423553735017776, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 483, train_loss = 1.0409730821847916, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 484, train_loss = 1.0395613871514797, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 485, train_loss = 1.0382697371242102, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 486, train_loss = 1.0368754205701407, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 487, train_loss = 1.0354925890860613, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 488, train_loss = 1.0341965568659361, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 489, train_loss = 1.0328020552697126, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 490, train_loss = 1.0313994958996773, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 491, train_loss = 1.0301755467953626, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 492, train_loss = 1.0287852672336157, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 493, train_loss = 1.0274475043115672, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 494, train_loss = 1.02620405331254, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 495, train_loss = 1.0248529240489006, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 496, train_loss = 1.0234377247688826, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 497, train_loss = 1.0222606224415358, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 498, train_loss = 1.020979010820156, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "15th- epoch: 499, train_loss = 1.0196572753193323, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|███████████████████████████████████                                   | 15/30 [1:42:19<1:42:52, 411.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "16th- epoch: 0, train_loss = 277.47722828388214, train_acc = 0.4229156963204471\n",
      "test Acc 0.49162011173184356:\n",
      "16th- epoch: 1, train_loss = 213.50494599342346, train_acc = 0.5112948299953424\n",
      "test Acc 0.5651769087523277:\n",
      "16th- epoch: 2, train_loss = 161.24329388141632, train_acc = 0.5839543549138333\n",
      "test Acc 0.6177839851024208:\n",
      "16th- epoch: 3, train_loss = 134.9332236647606, train_acc = 0.6545179319981369\n",
      "test Acc 0.6964618249534451:\n",
      "16th- epoch: 4, train_loss = 116.32472199201584, train_acc = 0.7220540288775035\n",
      "test Acc 0.7490689013035382:\n",
      "16th- epoch: 5, train_loss = 101.36957690119743, train_acc = 0.7617605961807172\n",
      "test Acc 0.7821229050279329:\n",
      "16th- epoch: 6, train_loss = 88.9939743578434, train_acc = 0.79052165812762\n",
      "test Acc 0.8007448789571695:\n",
      "16th- epoch: 7, train_loss = 78.74406731128693, train_acc = 0.8092687470889613\n",
      "test Acc 0.8226256983240223:\n",
      "16th- epoch: 8, train_loss = 70.08745217323303, train_acc = 0.8394271075919888\n",
      "test Acc 0.8524208566108007:\n",
      "16th- epoch: 9, train_loss = 62.65055230259895, train_acc = 0.8688868188169538\n",
      "test Acc 0.87756052141527:\n",
      "16th- epoch: 10, train_loss = 56.25574541091919, train_acc = 0.8897298556124825\n",
      "test Acc 0.8999068901303539:\n",
      "16th- epoch: 11, train_loss = 50.7757263481617, train_acc = 0.9082440614811365\n",
      "test Acc 0.9152700186219739:\n",
      "16th- epoch: 12, train_loss = 46.07731907069683, train_acc = 0.921634839310666\n",
      "test Acc 0.9273743016759777:\n",
      "16th- epoch: 13, train_loss = 42.0247256308794, train_acc = 0.9329296693060084\n",
      "test Acc 0.9380819366852886:\n",
      "16th- epoch: 14, train_loss = 38.52464137971401, train_acc = 0.9389846297158826\n",
      "test Acc 0.9404096834264432:\n",
      "16th- epoch: 15, train_loss = 35.4997922629118, train_acc = 0.9413134606427573\n",
      "test Acc 0.9441340782122905:\n",
      "16th- epoch: 16, train_loss = 32.88538837432861, train_acc = 0.9442244993013508\n",
      "test Acc 0.946927374301676:\n",
      "16th- epoch: 17, train_loss = 30.623710826039314, train_acc = 0.946786213320913\n",
      "test Acc 0.9511173184357542:\n",
      "16th- epoch: 18, train_loss = 28.666019067168236, train_acc = 0.9536562645551933\n",
      "test Acc 0.952513966480447:\n",
      "16th- epoch: 19, train_loss = 26.965275026857853, train_acc = 0.9552864462040056\n",
      "test Acc 0.9543761638733705:\n",
      "16th- epoch: 20, train_loss = 25.480582788586617, train_acc = 0.9569166278528178\n",
      "test Acc 0.9562383612662942:\n",
      "16th- epoch: 21, train_loss = 24.17724969238043, train_acc = 0.9583139264089428\n",
      "test Acc 0.9585661080074488:\n",
      "16th- epoch: 22, train_loss = 23.023804053664207, train_acc = 0.95947834187238\n",
      "test Acc 0.9585661080074488:\n",
      "16th- epoch: 23, train_loss = 21.995720013976097, train_acc = 0.9609920819748486\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 24, train_loss = 21.07566772401333, train_acc = 0.9618071727992548\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 25, train_loss = 20.245314236730337, train_acc = 0.9629715882626921\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 26, train_loss = 19.488691184669733, train_acc = 0.9637866790870983\n",
      "test Acc 0.9594972067039106:\n",
      "16th- epoch: 27, train_loss = 18.79420168325305, train_acc = 0.9646017699115044\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 28, train_loss = 18.15509356930852, train_acc = 0.9653004191895669\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 29, train_loss = 17.56566132605076, train_acc = 0.9663483931066604\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 30, train_loss = 17.01888944581151, train_acc = 0.9683278993945039\n",
      "test Acc 0.9599627560521415:\n",
      "16th- epoch: 31, train_loss = 16.50949265062809, train_acc = 0.9690265486725663\n",
      "test Acc 0.9604283054003724:\n",
      "16th- epoch: 32, train_loss = 16.032505065202713, train_acc = 0.9701909641360037\n",
      "test Acc 0.9608938547486033:\n",
      "16th- epoch: 33, train_loss = 15.585088163614273, train_acc = 0.9712389380530974\n",
      "test Acc 0.9632216014897579:\n",
      "16th- epoch: 34, train_loss = 15.164908297359943, train_acc = 0.9721704704238472\n",
      "test Acc 0.9641527001862198:\n",
      "16th- epoch: 35, train_loss = 14.768931530416012, train_acc = 0.9728691197019096\n",
      "test Acc 0.9655493482309124:\n",
      "16th- epoch: 36, train_loss = 14.395250275731087, train_acc = 0.9735677689799721\n",
      "test Acc 0.9669459962756052:\n",
      "16th- epoch: 37, train_loss = 14.041733581572771, train_acc = 0.974033535165347\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 38, train_loss = 13.706989970058203, train_acc = 0.9750815090824406\n",
      "test Acc 0.9688081936685289:\n",
      "16th- epoch: 39, train_loss = 13.389547359198332, train_acc = 0.9754308337214718\n",
      "test Acc 0.9702048417132216:\n",
      "16th- epoch: 40, train_loss = 13.088255170732737, train_acc = 0.975780158360503\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 41, train_loss = 12.802038379013538, train_acc = 0.9763623660922217\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 42, train_loss = 12.529532041400671, train_acc = 0.9774103400093154\n",
      "test Acc 0.9711359404096834:\n",
      "16th- epoch: 43, train_loss = 12.26925191283226, train_acc = 0.9788076385654402\n",
      "test Acc 0.9720670391061452:\n",
      "16th- epoch: 44, train_loss = 12.020106684416533, train_acc = 0.9791569632044713\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 45, train_loss = 11.781931076198816, train_acc = 0.9793898462971589\n",
      "test Acc 0.972998137802607:\n",
      "16th- epoch: 46, train_loss = 11.553568299859762, train_acc = 0.9796227293898463\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 47, train_loss = 11.33429904654622, train_acc = 0.9799720540288775\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 48, train_loss = 11.123380649834871, train_acc = 0.9800884955752213\n",
      "test Acc 0.973463687150838:\n",
      "16th- epoch: 49, train_loss = 10.920497581362724, train_acc = 0.9803213786679087\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 50, train_loss = 10.724960755556822, train_acc = 0.9805542617605962\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 51, train_loss = 10.536288317292929, train_acc = 0.9807871448532837\n",
      "test Acc 0.9739292364990689:\n",
      "16th- epoch: 52, train_loss = 10.353911330923438, train_acc = 0.9809035863996274\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 53, train_loss = 10.177465802058578, train_acc = 0.9809035863996274\n",
      "test Acc 0.9743947858472998:\n",
      "16th- epoch: 54, train_loss = 10.006652273237705, train_acc = 0.9810200279459711\n",
      "test Acc 0.9748603351955307:\n",
      "16th- epoch: 55, train_loss = 9.841447172686458, train_acc = 0.9814857941313461\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 56, train_loss = 9.681360967457294, train_acc = 0.9817186772240335\n",
      "test Acc 0.9757914338919925:\n",
      "16th- epoch: 57, train_loss = 9.525913324207067, train_acc = 0.9820680018630648\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 58, train_loss = 9.374662209302187, train_acc = 0.9821844434094085\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 59, train_loss = 9.22738398425281, train_acc = 0.9824173265020959\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 60, train_loss = 9.084262438118458, train_acc = 0.9824173265020959\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 61, train_loss = 8.945004036650062, train_acc = 0.9826502095947834\n",
      "test Acc 0.9762569832402235:\n",
      "16th- epoch: 62, train_loss = 8.80961025133729, train_acc = 0.9827666511411272\n",
      "test Acc 0.9767225325884544:\n",
      "16th- epoch: 63, train_loss = 8.67741296812892, train_acc = 0.9827666511411272\n",
      "test Acc 0.9771880819366853:\n",
      "16th- epoch: 64, train_loss = 8.548408037051558, train_acc = 0.9828830926874709\n",
      "test Acc 0.9776536312849162:\n",
      "16th- epoch: 65, train_loss = 8.42234699614346, train_acc = 0.9829995342338146\n",
      "test Acc 0.978584729981378:\n",
      "16th- epoch: 66, train_loss = 8.299245664849877, train_acc = 0.9833488588728458\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 67, train_loss = 8.17920328490436, train_acc = 0.9833488588728458\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 68, train_loss = 8.061891624704003, train_acc = 0.9835817419655333\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 69, train_loss = 7.94727667234838, train_acc = 0.9838146250582208\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 70, train_loss = 7.835015906020999, train_acc = 0.9839310666045645\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 71, train_loss = 7.72512561827898, train_acc = 0.9842803912435957\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 72, train_loss = 7.61753517203033, train_acc = 0.9845132743362832\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 73, train_loss = 7.511991919949651, train_acc = 0.9845132743362832\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 74, train_loss = 7.408715421333909, train_acc = 0.9846297158826269\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 75, train_loss = 7.307548174634576, train_acc = 0.9849790405216581\n",
      "test Acc 0.979050279329609:\n",
      "16th- epoch: 76, train_loss = 7.208418959751725, train_acc = 0.9852119236143456\n",
      "test Acc 0.9795158286778398:\n",
      "16th- epoch: 77, train_loss = 7.111075120046735, train_acc = 0.9853283651606893\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 78, train_loss = 7.0156833082437515, train_acc = 0.9857941313460643\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 79, train_loss = 6.9223878141492605, train_acc = 0.9857941313460643\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 80, train_loss = 6.831005971878767, train_acc = 0.985910572892408\n",
      "test Acc 0.9799813780260708:\n",
      "16th- epoch: 81, train_loss = 6.741357389837503, train_acc = 0.985910572892408\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 82, train_loss = 6.653374169021845, train_acc = 0.986376339077783\n",
      "test Acc 0.9809124767225326:\n",
      "16th- epoch: 83, train_loss = 6.567202204838395, train_acc = 0.9864927806241267\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 84, train_loss = 6.482744412496686, train_acc = 0.9867256637168141\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 85, train_loss = 6.399844301864505, train_acc = 0.9869585468095017\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 86, train_loss = 6.318564482033253, train_acc = 0.9875407545412203\n",
      "test Acc 0.9818435754189944:\n",
      "16th- epoch: 87, train_loss = 6.238764852285385, train_acc = 0.9877736376339078\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 88, train_loss = 6.160358592867851, train_acc = 0.9878900791802515\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 89, train_loss = 6.083294812589884, train_acc = 0.9880065207265952\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 90, train_loss = 6.007898708805442, train_acc = 0.9881229622729389\n",
      "test Acc 0.9813780260707635:\n",
      "16th- epoch: 91, train_loss = 5.933846678584814, train_acc = 0.9883558453656265\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 92, train_loss = 5.861188814043999, train_acc = 0.9884722869119702\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 93, train_loss = 5.789907566271722, train_acc = 0.9885887284583139\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 94, train_loss = 5.7199405720457435, train_acc = 0.9887051700046576\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 95, train_loss = 5.651345546357334, train_acc = 0.9891709361900326\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 96, train_loss = 5.584077753126621, train_acc = 0.9892873777363763\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 97, train_loss = 5.518041747622192, train_acc = 0.9892873777363763\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 98, train_loss = 5.453394435346127, train_acc = 0.98940381928272\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 99, train_loss = 5.389895821921527, train_acc = 0.9896367023754076\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 100, train_loss = 5.327557073906064, train_acc = 0.989869585468095\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 101, train_loss = 5.266384690068662, train_acc = 0.9899860270144387\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 102, train_loss = 5.206264563836157, train_acc = 0.9902189101071263\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 103, train_loss = 5.147348027676344, train_acc = 0.9902189101071263\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 104, train_loss = 5.089498461224139, train_acc = 0.9902189101071263\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 105, train_loss = 5.032703503035009, train_acc = 0.99033535165347\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 106, train_loss = 4.9770402973517776, train_acc = 0.9904517931998137\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 107, train_loss = 4.922334347851574, train_acc = 0.9904517931998137\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 108, train_loss = 4.868623398244381, train_acc = 0.9905682347461574\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 109, train_loss = 4.8159642070531845, train_acc = 0.990801117838845\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 110, train_loss = 4.764112154021859, train_acc = 0.990801117838845\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 111, train_loss = 4.7132561802864075, train_acc = 0.9909175593851887\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 112, train_loss = 4.663274177350104, train_acc = 0.9909175593851887\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 113, train_loss = 4.614064051769674, train_acc = 0.9912668840242198\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 114, train_loss = 4.565578014589846, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 115, train_loss = 4.518032851628959, train_acc = 0.9914997671169073\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 116, train_loss = 4.471374533139169, train_acc = 0.9916162086632511\n",
      "test Acc 0.9823091247672253:\n",
      "16th- epoch: 117, train_loss = 4.42554469127208, train_acc = 0.9917326502095948\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 118, train_loss = 4.380513100884855, train_acc = 0.9918490917559385\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 119, train_loss = 4.336337927728891, train_acc = 0.9918490917559385\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 120, train_loss = 4.2927977200597525, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 121, train_loss = 4.250072987750173, train_acc = 0.9924312994876572\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 122, train_loss = 4.208039627410471, train_acc = 0.9926641825803446\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 123, train_loss = 4.166677107103169, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 124, train_loss = 4.126100606285036, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 125, train_loss = 4.086128270253539, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 126, train_loss = 4.046868781559169, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 127, train_loss = 4.008271056227386, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 128, train_loss = 3.970235286280513, train_acc = 0.9930135072193759\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 129, train_loss = 3.9328298629261553, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 130, train_loss = 3.896005768328905, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 131, train_loss = 3.8598669818602502, train_acc = 0.9935957149510946\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 132, train_loss = 3.8242968041449785, train_acc = 0.9937121564974383\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 133, train_loss = 3.7893271897919476, train_acc = 0.9937121564974383\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 134, train_loss = 3.7549740723334253, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 135, train_loss = 3.7211683527566493, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 136, train_loss = 3.687869121786207, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 137, train_loss = 3.6551038906909525, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 138, train_loss = 3.6228742520324886, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 139, train_loss = 3.591122964862734, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 140, train_loss = 3.559755140915513, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 141, train_loss = 3.5289888423867524, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 142, train_loss = 3.498662186320871, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 143, train_loss = 3.4686895082704723, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 144, train_loss = 3.439246329013258, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 145, train_loss = 3.4102998464368284, train_acc = 0.994294364229157\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 146, train_loss = 3.381696383934468, train_acc = 0.9944108057755007\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 147, train_loss = 3.353669111151248, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 148, train_loss = 3.3260130411945283, train_acc = 0.9945272473218444\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 149, train_loss = 3.2987360265105963, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 150, train_loss = 3.271715742070228, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 151, train_loss = 3.2452626205049455, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 152, train_loss = 3.2190202195197344, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 153, train_loss = 3.1932280608452857, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 154, train_loss = 3.167762016877532, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 155, train_loss = 3.1427453216165304, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 156, train_loss = 3.118042504414916, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 157, train_loss = 3.0936548076570034, train_acc = 0.9952258965999069\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 158, train_loss = 3.0696876384317875, train_acc = 0.9952258965999069\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 159, train_loss = 3.0459438245743513, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 160, train_loss = 3.0225207544863224, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 161, train_loss = 2.9995604790747166, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 162, train_loss = 2.9767964682541788, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 163, train_loss = 2.9544950337149203, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 164, train_loss = 2.9324246696196496, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 165, train_loss = 2.910682922694832, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 166, train_loss = 2.8892697445116937, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 167, train_loss = 2.8680337704718113, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 168, train_loss = 2.8472615689970553, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 169, train_loss = 2.826611998025328, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 170, train_loss = 2.8062981530092657, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 171, train_loss = 2.7863122522830963, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 172, train_loss = 2.7666008074302226, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 173, train_loss = 2.7471161130815744, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 174, train_loss = 2.727851139381528, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 175, train_loss = 2.7089535978157073, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 176, train_loss = 2.6901532236952335, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 177, train_loss = 2.6717994958162308, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 178, train_loss = 2.6534821167588234, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 179, train_loss = 2.6355986297130585, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 180, train_loss = 2.6177909150719643, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 181, train_loss = 2.6002209447324276, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 182, train_loss = 2.583016499876976, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 183, train_loss = 2.565946292132139, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "16th- epoch: 184, train_loss = 2.549096379429102, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 185, train_loss = 2.532463035779074, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 186, train_loss = 2.5159881245344877, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 187, train_loss = 2.4997823406010866, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 188, train_loss = 2.483859193744138, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 189, train_loss = 2.4679368392098695, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 190, train_loss = 2.4524292510468513, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 191, train_loss = 2.43695604801178, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 192, train_loss = 2.4217728674411774, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 193, train_loss = 2.4067331932019442, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 194, train_loss = 2.391926808282733, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 195, train_loss = 2.3772562865633518, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 196, train_loss = 2.362802079645917, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 197, train_loss = 2.3485264361370355, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 198, train_loss = 2.334408038528636, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 199, train_loss = 2.3204793222248554, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 200, train_loss = 2.3068100549280643, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 201, train_loss = 2.2931581623852253, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 202, train_loss = 2.2798200726974756, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "16th- epoch: 203, train_loss = 2.266500315396115, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 204, train_loss = 2.253557462943718, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 205, train_loss = 2.2406037922482938, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 206, train_loss = 2.22782773966901, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 207, train_loss = 2.215254948241636, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 208, train_loss = 2.2027593355160207, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 209, train_loss = 2.1904713418334723, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 210, train_loss = 2.178376776399091, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 211, train_loss = 2.1664690740872175, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 212, train_loss = 2.154676317004487, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 213, train_loss = 2.1429573942441493, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 214, train_loss = 2.131467754021287, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 215, train_loss = 2.120071313576773, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 216, train_loss = 2.1089054986368865, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 217, train_loss = 2.097824779106304, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 218, train_loss = 2.0867709119338542, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 219, train_loss = 2.076027100905776, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 220, train_loss = 2.0653760861605406, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "16th- epoch: 221, train_loss = 2.054902447387576, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 222, train_loss = 2.044429333298467, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 223, train_loss = 2.0342000114033, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 224, train_loss = 2.024035232141614, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 225, train_loss = 2.0140269150724635, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 226, train_loss = 2.0040976461023092, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 227, train_loss = 1.9942952512064949, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 228, train_loss = 1.9847049564123154, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 229, train_loss = 1.975220151245594, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 230, train_loss = 1.9656928250333294, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 231, train_loss = 1.9563794663408771, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 232, train_loss = 1.9472105646273121, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 233, train_loss = 1.9381148995598778, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 234, train_loss = 1.929039534763433, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 235, train_loss = 1.9202810315182433, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 236, train_loss = 1.9115117155015469, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 237, train_loss = 1.9028728207340464, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 238, train_loss = 1.894224833115004, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 239, train_loss = 1.8857918549329042, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 240, train_loss = 1.8774729277938604, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 241, train_loss = 1.8690508858999237, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 242, train_loss = 1.8609855398535728, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 243, train_loss = 1.8528716247528791, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 244, train_loss = 1.8448567563900724, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "16th- epoch: 245, train_loss = 1.8369960486888885, train_acc = 0.9970889613414066\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 246, train_loss = 1.829169649630785, train_acc = 0.9970889613414066\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 247, train_loss = 1.821468840003945, train_acc = 0.9970889613414066\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 248, train_loss = 1.8137565335491672, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 249, train_loss = 1.8062881691148505, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 250, train_loss = 1.7987647745758295, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 251, train_loss = 1.7913749230792746, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 252, train_loss = 1.7840439392020926, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 253, train_loss = 1.776826087385416, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 254, train_loss = 1.7695926992455497, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 255, train_loss = 1.7626214927295223, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 256, train_loss = 1.7555860908469185, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 257, train_loss = 1.7486681459704414, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 258, train_loss = 1.7417863998562098, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 259, train_loss = 1.7349151676753536, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 260, train_loss = 1.7282742081442848, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 261, train_loss = 1.7216580143431202, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 262, train_loss = 1.7150749614229426, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "16th- epoch: 263, train_loss = 1.708561842679046, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 264, train_loss = 1.7020772261312231, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 265, train_loss = 1.6956070885062218, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 266, train_loss = 1.6894002357730642, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 267, train_loss = 1.6831570541253313, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 268, train_loss = 1.6769538087537512, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 269, train_loss = 1.6708263593027368, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 270, train_loss = 1.664779127924703, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 271, train_loss = 1.6586509495973587, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 272, train_loss = 1.6528745194664225, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 273, train_loss = 1.6469746455550194, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 274, train_loss = 1.6411053761839867, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 275, train_loss = 1.6353989714989439, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 276, train_loss = 1.6295541761210188, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 277, train_loss = 1.6239337200531736, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 278, train_loss = 1.6184203153243288, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 279, train_loss = 1.6128361920127645, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 280, train_loss = 1.6073873167624697, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 281, train_loss = 1.6018098468193784, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 282, train_loss = 1.5963982765679248, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 283, train_loss = 1.5911428953404538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 284, train_loss = 1.5858107569511048, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 285, train_loss = 1.580647597729694, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 286, train_loss = 1.5754108652472496, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 287, train_loss = 1.5701899453997612, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 288, train_loss = 1.5652308625285514, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 289, train_loss = 1.5601287769968621, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 290, train_loss = 1.5552035408909433, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 291, train_loss = 1.5501876014168374, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 292, train_loss = 1.5452840365469456, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 293, train_loss = 1.5403838219936006, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 294, train_loss = 1.5355680721695535, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 295, train_loss = 1.5307142026722431, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 296, train_loss = 1.5260744194383733, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 297, train_loss = 1.5213127881288528, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "16th- epoch: 298, train_loss = 1.5165872548823245, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 299, train_loss = 1.5120685895089991, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 300, train_loss = 1.5075460858643055, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 301, train_loss = 1.5029669416253455, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 302, train_loss = 1.4984455208177678, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 303, train_loss = 1.4939159490168095, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 304, train_loss = 1.4896447944338433, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 305, train_loss = 1.4851521427626722, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 306, train_loss = 1.4808956955675967, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 307, train_loss = 1.4765295374090783, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 308, train_loss = 1.4721937750582583, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 309, train_loss = 1.468068689107895, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 310, train_loss = 1.4638724264805205, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 311, train_loss = 1.459730273752939, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 312, train_loss = 1.4555962297017686, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 313, train_loss = 1.451501174538862, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 314, train_loss = 1.4474341037566774, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 315, train_loss = 1.4434231693740003, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 316, train_loss = 1.4394099389319308, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 317, train_loss = 1.435411736369133, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 318, train_loss = 1.4313957976992242, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 319, train_loss = 1.4276745095849037, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 320, train_loss = 1.423692376643885, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 321, train_loss = 1.4199877046048641, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 322, train_loss = 1.4161482130293734, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 323, train_loss = 1.412335593253374, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 324, train_loss = 1.408579594164621, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 325, train_loss = 1.404873086779844, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 326, train_loss = 1.4012129791080952, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 327, train_loss = 1.397539598227013, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 328, train_loss = 1.39390066760825, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 329, train_loss = 1.3903237569029443, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 330, train_loss = 1.3867773935198784, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 331, train_loss = 1.3831901562516578, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 332, train_loss = 1.3797736875712872, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 333, train_loss = 1.3762639786000364, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 334, train_loss = 1.3727621001307853, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 335, train_loss = 1.36941198509885, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 336, train_loss = 1.3659444128279574, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 337, train_loss = 1.3626328433747403, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 338, train_loss = 1.3592027872800827, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 339, train_loss = 1.3559052683413029, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 340, train_loss = 1.3526022136211395, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 341, train_loss = 1.3493551413412206, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 342, train_loss = 1.346097442030441, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 343, train_loss = 1.342885248363018, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 344, train_loss = 1.339581687003374, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 345, train_loss = 1.336485096544493, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 346, train_loss = 1.3332862593233585, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 347, train_loss = 1.330164058774244, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 348, train_loss = 1.327046237885952, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 349, train_loss = 1.3240051766042598, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 350, train_loss = 1.320904043794144, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 351, train_loss = 1.317897703498602, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 352, train_loss = 1.3147987562115304, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "16th- epoch: 353, train_loss = 1.3117816485464573, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "16th- epoch: 354, train_loss = 1.3088929814402945, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "16th- epoch: 355, train_loss = 1.3059267538483255, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "16th- epoch: 356, train_loss = 1.3029483929276466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "16th- epoch: 357, train_loss = 1.3000963131780736, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "16th- epoch: 358, train_loss = 1.2971385580603965, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "16th- epoch: 359, train_loss = 1.2942840320174582, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "16th- epoch: 360, train_loss = 1.2914517534081824, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "16th- epoch: 361, train_loss = 1.2885986057226546, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 362, train_loss = 1.2857168465852737, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 363, train_loss = 1.2830182798206806, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 364, train_loss = 1.2801686165330466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 365, train_loss = 1.277464705199236, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 366, train_loss = 1.274658898502821, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 367, train_loss = 1.272003640740877, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 368, train_loss = 1.2692766040563583, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 369, train_loss = 1.2665395910444204, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 370, train_loss = 1.263895412295824, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 371, train_loss = 1.2612697929143906, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 372, train_loss = 1.2586120913329069, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 373, train_loss = 1.256056228041416, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 374, train_loss = 1.253369688987732, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 375, train_loss = 1.2508558283152524, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 376, train_loss = 1.2482543215155602, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 377, train_loss = 1.2457795081136283, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 378, train_loss = 1.243047152966028, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 379, train_loss = 1.24074013158679, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 380, train_loss = 1.2381694416108076, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 381, train_loss = 1.2356974333524704, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 382, train_loss = 1.2332087978720665, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 383, train_loss = 1.2308127544820309, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 384, train_loss = 1.2283473685383797, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 385, train_loss = 1.2259078758361284, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 386, train_loss = 1.223541222512722, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 387, train_loss = 1.2211451617476996, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 388, train_loss = 1.2187707982957363, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 389, train_loss = 1.21641487130546, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 390, train_loss = 1.2140374705195427, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 391, train_loss = 1.2117871468362864, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 392, train_loss = 1.209434657037491, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 393, train_loss = 1.2071658869681414, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 394, train_loss = 1.2048479629156645, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 395, train_loss = 1.2025994025170803, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 396, train_loss = 1.2003100464644376, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 397, train_loss = 1.1980911406280939, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 398, train_loss = 1.1958577322366182, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 399, train_loss = 1.193584473192459, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 400, train_loss = 1.1914754708705004, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 401, train_loss = 1.1892563799920026, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 402, train_loss = 1.1870684064924717, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 403, train_loss = 1.18494176492095, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 404, train_loss = 1.1828161577286664, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 405, train_loss = 1.1806558656098787, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 406, train_loss = 1.1785643361508846, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 407, train_loss = 1.176404240221018, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 408, train_loss = 1.1743729474546853, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 409, train_loss = 1.1722512058913708, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 410, train_loss = 1.1701527498662472, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 411, train_loss = 1.1681422181427479, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 412, train_loss = 1.1661289321782533, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 413, train_loss = 1.164046622812748, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 414, train_loss = 1.1620856958033983, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 415, train_loss = 1.160072391241556, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 416, train_loss = 1.158022828400135, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 417, train_loss = 1.156099079787964, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 418, train_loss = 1.1540601998567581, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 419, train_loss = 1.1521669489738997, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 420, train_loss = 1.1501437587139662, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 421, train_loss = 1.1481948383152485, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 422, train_loss = 1.1463305726647377, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 423, train_loss = 1.1444244906306267, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 424, train_loss = 1.1425123835506383, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 425, train_loss = 1.1405746415257454, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 426, train_loss = 1.1386941187083721, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 427, train_loss = 1.136883561819559, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 428, train_loss = 1.1350144209864084, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 429, train_loss = 1.1331352877023164, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 430, train_loss = 1.1313458817603532, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 431, train_loss = 1.1294797149894293, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 432, train_loss = 1.1277044551970903, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 433, train_loss = 1.125811298697954, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 434, train_loss = 1.1241090707480907, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 435, train_loss = 1.1223040272889193, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 436, train_loss = 1.1205795034766197, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 437, train_loss = 1.1186728390457574, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 438, train_loss = 1.1169521460833494, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 439, train_loss = 1.115204165369505, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 440, train_loss = 1.1134972324070986, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 441, train_loss = 1.1116687220928725, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 442, train_loss = 1.1100304760038853, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16th- epoch: 443, train_loss = 1.1082951873540878, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 444, train_loss = 1.1066319023666438, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 445, train_loss = 1.1049460607173387, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 446, train_loss = 1.1032433981599752, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 447, train_loss = 1.1015747574565466, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 448, train_loss = 1.0998995167610701, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 449, train_loss = 1.0982712879776955, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 450, train_loss = 1.096598219126463, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 451, train_loss = 1.0949373903276864, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 452, train_loss = 1.0933015035989229, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 453, train_loss = 1.091656797885662, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 454, train_loss = 1.090083653718466, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 455, train_loss = 1.088473810494179, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 456, train_loss = 1.0869750156998634, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 457, train_loss = 1.0852446978387889, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 458, train_loss = 1.083685406803852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 459, train_loss = 1.0821104956266936, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 460, train_loss = 1.0805679174663965, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 461, train_loss = 1.0790220809576567, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 462, train_loss = 1.0774757216277067, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 463, train_loss = 1.075956686079735, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 464, train_loss = 1.0743326967058238, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 465, train_loss = 1.0727643482387066, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 466, train_loss = 1.071320359915262, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 467, train_loss = 1.0698386219737586, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 468, train_loss = 1.0683661624789238, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 469, train_loss = 1.066834270954132, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 470, train_loss = 1.0653383173048496, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 471, train_loss = 1.063850084945443, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 472, train_loss = 1.062400917217019, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 473, train_loss = 1.060924646750209, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 474, train_loss = 1.0594874074013205, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 475, train_loss = 1.058010304972413, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 476, train_loss = 1.0565059867949458, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 477, train_loss = 1.055237766355276, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 478, train_loss = 1.0537259876728058, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 479, train_loss = 1.052299917981145, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 480, train_loss = 1.050858757153037, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 481, train_loss = 1.0494392576365499, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 482, train_loss = 1.0480784066021442, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 483, train_loss = 1.0466451471002074, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 484, train_loss = 1.0453232650907012, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 485, train_loss = 1.0438701758830575, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 486, train_loss = 1.0424746287317248, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 487, train_loss = 1.0411605946719646, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 488, train_loss = 1.0398113491683034, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 489, train_loss = 1.0383900552988052, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 490, train_loss = 1.0369778461754322, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 491, train_loss = 1.0357443280518055, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 492, train_loss = 1.0344221008272143, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 493, train_loss = 1.0330641940236092, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 494, train_loss = 1.031744080290082, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 495, train_loss = 1.0304308769555064, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 496, train_loss = 1.0291085255594226, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 497, train_loss = 1.0278186686336994, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 498, train_loss = 1.026532885924098, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "16th- epoch: 499, train_loss = 1.0252300972788362, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████████████████████████████████████▎                                | 16/30 [1:49:08<1:35:53, 410.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "17th- epoch: 0, train_loss = 274.45615577697754, train_acc = 0.43979972054028876\n",
      "test Acc 0.5330540037243948:\n",
      "17th- epoch: 1, train_loss = 208.34185576438904, train_acc = 0.5525151374010246\n",
      "test Acc 0.5702979515828678:\n",
      "17th- epoch: 2, train_loss = 161.9640538096428, train_acc = 0.581858407079646\n",
      "test Acc 0.6149906890130353:\n",
      "17th- epoch: 3, train_loss = 137.0728903412819, train_acc = 0.6559152305542617\n",
      "test Acc 0.7043761638733705:\n",
      "17th- epoch: 4, train_loss = 119.4905116558075, train_acc = 0.7250815090824406\n",
      "test Acc 0.7490689013035382:\n",
      "17th- epoch: 5, train_loss = 104.67525953054428, train_acc = 0.7564042850489054\n",
      "test Acc 0.7718808193668529:\n",
      "17th- epoch: 6, train_loss = 91.79010763764381, train_acc = 0.7820214252445272\n",
      "test Acc 0.7998137802607076:\n",
      "17th- epoch: 7, train_loss = 80.84921878576279, train_acc = 0.8136935258500233\n",
      "test Acc 0.8226256983240223:\n",
      "17th- epoch: 8, train_loss = 71.57258766889572, train_acc = 0.8405915230554262\n",
      "test Acc 0.8547486033519553:\n",
      "17th- epoch: 9, train_loss = 63.6827877163887, train_acc = 0.8692361434559851\n",
      "test Acc 0.8859404096834265:\n",
      "17th- epoch: 10, train_loss = 56.98758600652218, train_acc = 0.8943875174662319\n",
      "test Acc 0.9054934823091247:\n",
      "17th- epoch: 11, train_loss = 51.31895172595978, train_acc = 0.911504424778761\n",
      "test Acc 0.9236499068901304:\n",
      "17th- epoch: 12, train_loss = 46.50498904287815, train_acc = 0.9241965533302282\n",
      "test Acc 0.9338919925512105:\n",
      "17th- epoch: 13, train_loss = 42.397501811385155, train_acc = 0.933977643223102\n",
      "test Acc 0.9366852886405959:\n",
      "17th- epoch: 14, train_loss = 38.879773676395416, train_acc = 0.9373544480670704\n",
      "test Acc 0.9380819366852886:\n",
      "17th- epoch: 15, train_loss = 35.860590390861034, train_acc = 0.9399161620866325\n",
      "test Acc 0.9399441340782123:\n",
      "17th- epoch: 16, train_loss = 33.26408549398184, train_acc = 0.9424778761061947\n",
      "test Acc 0.9427374301675978:\n",
      "17th- epoch: 17, train_loss = 31.029381185770035, train_acc = 0.9443409408476945\n",
      "test Acc 0.9497206703910615:\n",
      "17th- epoch: 18, train_loss = 29.098886385560036, train_acc = 0.9503959012575687\n",
      "test Acc 0.9529795158286778:\n",
      "17th- epoch: 19, train_loss = 27.421849086880684, train_acc = 0.9526082906380997\n",
      "test Acc 0.9553072625698324:\n",
      "17th- epoch: 20, train_loss = 25.956389047205448, train_acc = 0.9550535631113182\n",
      "test Acc 0.9567039106145251:\n",
      "17th- epoch: 21, train_loss = 24.666890617460012, train_acc = 0.9572659524918491\n",
      "test Acc 0.957169459962756:\n",
      "17th- epoch: 22, train_loss = 23.524788841605186, train_acc = 0.9592454587796926\n",
      "test Acc 0.957169459962756:\n",
      "17th- epoch: 23, train_loss = 22.505805622786283, train_acc = 0.9611085235211924\n",
      "test Acc 0.9590316573556797:\n",
      "17th- epoch: 24, train_loss = 21.589953571558, train_acc = 0.9622729389846297\n",
      "test Acc 0.9594972067039106:\n",
      "17th- epoch: 25, train_loss = 20.760249752551317, train_acc = 0.9629715882626921\n",
      "test Acc 0.9594972067039106:\n",
      "17th- epoch: 26, train_loss = 20.00488593801856, train_acc = 0.9635537959944108\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 27, train_loss = 19.312923274934292, train_acc = 0.9646017699115044\n",
      "test Acc 0.9599627560521415:\n",
      "17th- epoch: 28, train_loss = 18.67577228322625, train_acc = 0.9651839776432231\n",
      "test Acc 0.9608938547486033:\n",
      "17th- epoch: 29, train_loss = 18.085707377642393, train_acc = 0.9663483931066604\n",
      "test Acc 0.9613594040968343:\n",
      "17th- epoch: 30, train_loss = 17.537040390074253, train_acc = 0.9666977177456917\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 31, train_loss = 17.025851763784885, train_acc = 0.9679785747554728\n",
      "test Acc 0.9618249534450651:\n",
      "17th- epoch: 32, train_loss = 16.547939646989107, train_acc = 0.9690265486725663\n",
      "test Acc 0.9641527001862198:\n",
      "17th- epoch: 33, train_loss = 16.099617060273886, train_acc = 0.97007452258966\n",
      "test Acc 0.9660148975791434:\n",
      "17th- epoch: 34, train_loss = 15.6774837449193, train_acc = 0.9708896134140661\n",
      "test Acc 0.9674115456238361:\n",
      "17th- epoch: 35, train_loss = 15.279392343014479, train_acc = 0.9715882626921285\n",
      "test Acc 0.9688081936685289:\n",
      "17th- epoch: 36, train_loss = 14.902708068490028, train_acc = 0.9721704704238472\n",
      "test Acc 0.9706703910614525:\n",
      "17th- epoch: 37, train_loss = 14.545724049210548, train_acc = 0.9736842105263158\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 38, train_loss = 14.20658229291439, train_acc = 0.9739170936190032\n",
      "test Acc 0.9711359404096834:\n",
      "17th- epoch: 39, train_loss = 13.883917648345232, train_acc = 0.9751979506287843\n",
      "test Acc 0.9725325884543762:\n",
      "17th- epoch: 40, train_loss = 13.577128689736128, train_acc = 0.9760130414531905\n",
      "test Acc 0.972998137802607:\n",
      "17th- epoch: 41, train_loss = 13.284963134676218, train_acc = 0.9764788076385654\n",
      "test Acc 0.9739292364990689:\n",
      "17th- epoch: 42, train_loss = 13.005935002118349, train_acc = 0.9768281322775967\n",
      "test Acc 0.9743947858472998:\n",
      "17th- epoch: 43, train_loss = 12.73896374180913, train_acc = 0.9771774569166278\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 44, train_loss = 12.483243845403194, train_acc = 0.9775267815556591\n",
      "test Acc 0.9748603351955307:\n",
      "17th- epoch: 45, train_loss = 12.237714637070894, train_acc = 0.9776432231020028\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 46, train_loss = 12.001644117757678, train_acc = 0.977992547741034\n",
      "test Acc 0.9757914338919925:\n",
      "17th- epoch: 47, train_loss = 11.77457394450903, train_acc = 0.9784583139264089\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 48, train_loss = 11.556503713130951, train_acc = 0.9789240801117839\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 49, train_loss = 11.34638498723507, train_acc = 0.9791569632044713\n",
      "test Acc 0.9767225325884544:\n",
      "17th- epoch: 50, train_loss = 11.143758025020361, train_acc = 0.9796227293898463\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 51, train_loss = 10.948028296232224, train_acc = 0.97973917093619\n",
      "test Acc 0.9771880819366853:\n",
      "17th- epoch: 52, train_loss = 10.758074253797531, train_acc = 0.980204937121565\n",
      "test Acc 0.9781191806331471:\n",
      "17th- epoch: 53, train_loss = 10.573714585974813, train_acc = 0.98067070330694\n",
      "test Acc 0.978584729981378:\n",
      "17th- epoch: 54, train_loss = 10.395115984603763, train_acc = 0.9811364694923148\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 55, train_loss = 10.222055086866021, train_acc = 0.9813693525850024\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 56, train_loss = 10.054587559774518, train_acc = 0.981951560316721\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 57, train_loss = 9.892141949385405, train_acc = 0.9821844434094085\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 58, train_loss = 9.734345156699419, train_acc = 0.9821844434094085\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 59, train_loss = 9.581069657579064, train_acc = 0.9823008849557522\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 60, train_loss = 9.432002672925591, train_acc = 0.9826502095947834\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 61, train_loss = 9.286922728642821, train_acc = 0.9827666511411272\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 62, train_loss = 9.14552552998066, train_acc = 0.9829995342338146\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 63, train_loss = 9.00755863264203, train_acc = 0.9829995342338146\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 64, train_loss = 8.872703524306417, train_acc = 0.9831159757801584\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 65, train_loss = 8.741040049120784, train_acc = 0.9831159757801584\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 66, train_loss = 8.612410156056285, train_acc = 0.9831159757801584\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 67, train_loss = 8.486653370782733, train_acc = 0.9832324173265021\n",
      "test Acc 0.979050279329609:\n",
      "17th- epoch: 68, train_loss = 8.363734494894743, train_acc = 0.9835817419655333\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 69, train_loss = 8.243459023535252, train_acc = 0.9835817419655333\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 70, train_loss = 8.125685844570398, train_acc = 0.9838146250582208\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 71, train_loss = 8.010600287467241, train_acc = 0.984163949697252\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 72, train_loss = 7.897981433197856, train_acc = 0.9842803912435957\n",
      "test Acc 0.9804469273743017:\n",
      "17th- epoch: 73, train_loss = 7.787758300080895, train_acc = 0.9842803912435957\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 74, train_loss = 7.6797922141849995, train_acc = 0.9845132743362832\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 75, train_loss = 7.5740773398429155, train_acc = 0.9845132743362832\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 76, train_loss = 7.470465371385217, train_acc = 0.9847461574289706\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 77, train_loss = 7.368913160637021, train_acc = 0.9847461574289706\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 78, train_loss = 7.269488740712404, train_acc = 0.9850954820680019\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 79, train_loss = 7.171948054805398, train_acc = 0.9853283651606893\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 80, train_loss = 7.076355364173651, train_acc = 0.9853283651606893\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 81, train_loss = 6.982707416638732, train_acc = 0.985444806707033\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 82, train_loss = 6.890678700059652, train_acc = 0.985444806707033\n",
      "test Acc 0.9799813780260708:\n",
      "17th- epoch: 83, train_loss = 6.800556840375066, train_acc = 0.9855612482533768\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 84, train_loss = 6.712122807279229, train_acc = 0.9855612482533768\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 85, train_loss = 6.625293657183647, train_acc = 0.9856776897997206\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 86, train_loss = 6.540186954662204, train_acc = 0.9862598975314392\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 87, train_loss = 6.4566271379590034, train_acc = 0.9866092221704704\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 88, train_loss = 6.374573662877083, train_acc = 0.9867256637168141\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 89, train_loss = 6.294259902089834, train_acc = 0.9869585468095017\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 90, train_loss = 6.215450391173363, train_acc = 0.9871914299021891\n",
      "test Acc 0.9795158286778398:\n",
      "17th- epoch: 91, train_loss = 6.138211568817496, train_acc = 0.9877736376339078\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 92, train_loss = 6.062321566045284, train_acc = 0.9877736376339078\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 93, train_loss = 5.988107323646545, train_acc = 0.9880065207265952\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 94, train_loss = 5.915048219263554, train_acc = 0.9888216115510013\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 95, train_loss = 5.843431005254388, train_acc = 0.9888216115510013\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 96, train_loss = 5.773237805813551, train_acc = 0.9892873777363763\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 97, train_loss = 5.704254621639848, train_acc = 0.9895202608290639\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 98, train_loss = 5.636628583073616, train_acc = 0.9896367023754076\n",
      "test Acc 0.9818435754189944:\n",
      "17th- epoch: 99, train_loss = 5.570189651101828, train_acc = 0.9896367023754076\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 100, train_loss = 5.505010839551687, train_acc = 0.9896367023754076\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 101, train_loss = 5.440972069278359, train_acc = 0.9896367023754076\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 102, train_loss = 5.378217710182071, train_acc = 0.989869585468095\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 103, train_loss = 5.316484460607171, train_acc = 0.99033535165347\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 104, train_loss = 5.25594515632838, train_acc = 0.9905682347461574\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 105, train_loss = 5.196434392593801, train_acc = 0.9906846762925011\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 106, train_loss = 5.1380078522488475, train_acc = 0.990801117838845\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 107, train_loss = 5.080538394860923, train_acc = 0.9906846762925011\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 108, train_loss = 5.024126279167831, train_acc = 0.9906846762925011\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 109, train_loss = 4.968626734800637, train_acc = 0.9906846762925011\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 110, train_loss = 4.914246373809874, train_acc = 0.990801117838845\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 111, train_loss = 4.860723657533526, train_acc = 0.990801117838845\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 112, train_loss = 4.808134063147008, train_acc = 0.9909175593851887\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 113, train_loss = 4.756431019864976, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 114, train_loss = 4.70557043608278, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 115, train_loss = 4.6556751457974315, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 116, train_loss = 4.606596732512116, train_acc = 0.9914997671169073\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 117, train_loss = 4.55824660975486, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 118, train_loss = 4.510808520950377, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 119, train_loss = 4.464032534509897, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 120, train_loss = 4.418128903955221, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 121, train_loss = 4.372866479679942, train_acc = 0.9918490917559385\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 122, train_loss = 4.328317697159946, train_acc = 0.9919655333022822\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 123, train_loss = 4.284464780241251, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 124, train_loss = 4.241415943950415, train_acc = 0.9921984163949698\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 125, train_loss = 4.198976387269795, train_acc = 0.9923148579413135\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 126, train_loss = 4.157255247235298, train_acc = 0.9925477410340009\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 127, train_loss = 4.116128467954695, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 128, train_loss = 4.075716820545495, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 129, train_loss = 4.035910906270146, train_acc = 0.9928970656730322\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 130, train_loss = 3.996759436093271, train_acc = 0.9928970656730322\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 131, train_loss = 3.9581240490078926, train_acc = 0.9930135072193759\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 132, train_loss = 3.920168292708695, train_acc = 0.9931299487657196\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 133, train_loss = 3.882778394035995, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 134, train_loss = 3.8459976026788354, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 135, train_loss = 3.809722227975726, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 136, train_loss = 3.7740785535424948, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 137, train_loss = 3.7389505011960864, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 138, train_loss = 3.704402211122215, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 139, train_loss = 3.670378833077848, train_acc = 0.9937121564974383\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 140, train_loss = 3.6368775414302945, train_acc = 0.9937121564974383\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 141, train_loss = 3.603899206034839, train_acc = 0.9937121564974383\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 142, train_loss = 3.571481172926724, train_acc = 0.9939450395901258\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 143, train_loss = 3.5393770867958665, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 144, train_loss = 3.507790363393724, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 145, train_loss = 3.476784275844693, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 146, train_loss = 3.446210082154721, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 147, train_loss = 3.4159582159481943, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 148, train_loss = 3.3863187464885414, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 149, train_loss = 3.3569224192760885, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 150, train_loss = 3.328023694921285, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 151, train_loss = 3.2995885401032865, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 152, train_loss = 3.27146778954193, train_acc = 0.9944108057755007\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 153, train_loss = 3.2438760828226805, train_acc = 0.9944108057755007\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 154, train_loss = 3.216662593651563, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 155, train_loss = 3.1898191329091787, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 156, train_loss = 3.1632919050753117, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 157, train_loss = 3.137254301458597, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 158, train_loss = 3.1115762735717, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 159, train_loss = 3.0862329839728773, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 160, train_loss = 3.0612441902048886, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 161, train_loss = 3.0366425602696836, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 162, train_loss = 3.0123216011561453, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 163, train_loss = 2.988449786324054, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 164, train_loss = 2.964876142796129, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 165, train_loss = 2.9415609748102725, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 166, train_loss = 2.918747898656875, train_acc = 0.9952258965999069\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 167, train_loss = 2.8962767012417316, train_acc = 0.9952258965999069\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 168, train_loss = 2.8740246635861695, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 169, train_loss = 2.8520754147320986, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 170, train_loss = 2.8304928592406213, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 171, train_loss = 2.8090463117696345, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 172, train_loss = 2.7881792783737183, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 173, train_loss = 2.7674007527530193, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 174, train_loss = 2.746984431054443, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 175, train_loss = 2.7268153284676373, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 176, train_loss = 2.7070508846081793, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 177, train_loss = 2.687365783844143, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 178, train_loss = 2.668187274131924, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 179, train_loss = 2.6491978131234646, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 180, train_loss = 2.6303473892621696, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 181, train_loss = 2.6118813189677894, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 182, train_loss = 2.5936931329779327, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 183, train_loss = 2.575622597243637, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 184, train_loss = 2.557828066404909, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 185, train_loss = 2.540277909487486, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 186, train_loss = 2.522953101899475, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 187, train_loss = 2.505987169686705, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 188, train_loss = 2.489146121311933, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 189, train_loss = 2.472563768271357, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 190, train_loss = 2.456155953463167, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 191, train_loss = 2.440134620293975, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 192, train_loss = 2.4241017382591963, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 193, train_loss = 2.4084106690716, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 194, train_loss = 2.39299473608844, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 195, train_loss = 2.3778215020429343, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 196, train_loss = 2.3627012490760535, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 197, train_loss = 2.3479079373646528, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 198, train_loss = 2.3332694557029754, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 199, train_loss = 2.318890097318217, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "17th- epoch: 200, train_loss = 2.304621930466965, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 201, train_loss = 2.2906424086540937, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 202, train_loss = 2.276725312694907, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 203, train_loss = 2.2631268955301493, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 204, train_loss = 2.2496163125615567, train_acc = 0.9959245458779693\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 205, train_loss = 2.236389556899667, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 206, train_loss = 2.2231473338324577, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 207, train_loss = 2.2102568708360195, train_acc = 0.996040987424313\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 208, train_loss = 2.1975197817664593, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 209, train_loss = 2.1848804920446128, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 210, train_loss = 2.172474394319579, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 211, train_loss = 2.160149535164237, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 212, train_loss = 2.1479892760980874, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 213, train_loss = 2.1360951773822308, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 214, train_loss = 2.124335639178753, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 215, train_loss = 2.1126975268125534, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 216, train_loss = 2.1012336686253548, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 217, train_loss = 2.0898440678138286, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 218, train_loss = 2.078807641984895, train_acc = 0.9966231951560317\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 219, train_loss = 2.067674199817702, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 220, train_loss = 2.056833501905203, train_acc = 0.9967396367023754\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 221, train_loss = 2.04610039293766, train_acc = 0.9968560782487191\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 222, train_loss = 2.0354307268280536, train_acc = 0.9968560782487191\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 223, train_loss = 2.025060001760721, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 224, train_loss = 2.014796193689108, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 225, train_loss = 2.004556094529107, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 226, train_loss = 1.9945459887385368, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 227, train_loss = 1.9845167298335582, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 228, train_loss = 1.974751143483445, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 229, train_loss = 1.9650622035842389, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 230, train_loss = 1.9555141504388303, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 231, train_loss = 1.9460236367303878, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 232, train_loss = 1.9367270097136497, train_acc = 0.9969725197950629\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 233, train_loss = 1.9275386917870492, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 234, train_loss = 1.9183937285561115, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 235, train_loss = 1.9093867565970868, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 236, train_loss = 1.9005023811478168, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 237, train_loss = 1.89171406137757, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 238, train_loss = 1.8830648139119148, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 239, train_loss = 1.8744922045152634, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 240, train_loss = 1.8659070320427418, train_acc = 0.9970889613414066\n",
      "test Acc 0.9823091247672253:\n",
      "17th- epoch: 241, train_loss = 1.8575826473534107, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 242, train_loss = 1.84925468522124, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 243, train_loss = 1.841121396748349, train_acc = 0.9973218444340941\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 244, train_loss = 1.8330442633014172, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 245, train_loss = 1.8250456526875496, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 246, train_loss = 1.8171187590342015, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 247, train_loss = 1.8092761759180576, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 248, train_loss = 1.8015698555391282, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 249, train_loss = 1.793975173146464, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 250, train_loss = 1.786413418711163, train_acc = 0.9974382859804378\n",
      "test Acc 0.9827746741154563:\n",
      "17th- epoch: 251, train_loss = 1.7789603421697393, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 252, train_loss = 1.7715283992001787, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 253, train_loss = 1.7642674123635516, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 254, train_loss = 1.7570107392966747, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 255, train_loss = 1.7498979108640924, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 256, train_loss = 1.742831522016786, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 257, train_loss = 1.735851896344684, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 258, train_loss = 1.7288651379058138, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 259, train_loss = 1.7220580838620663, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 260, train_loss = 1.71526502573397, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 261, train_loss = 1.7085947369923815, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 262, train_loss = 1.702015952556394, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 263, train_loss = 1.6954609317472205, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 264, train_loss = 1.6889526719460264, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 265, train_loss = 1.6824699230492115, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 266, train_loss = 1.6762258969247341, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "17th- epoch: 267, train_loss = 1.6698854366550222, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 268, train_loss = 1.6635984567692503, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 269, train_loss = 1.6575132235884666, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 270, train_loss = 1.6514336144318804, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 271, train_loss = 1.6453848978271708, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 272, train_loss = 1.6394203739473596, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 273, train_loss = 1.6335397673537955, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 274, train_loss = 1.6276842268416658, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 275, train_loss = 1.6219030109932646, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 276, train_loss = 1.6162083050003275, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 277, train_loss = 1.6104658357799053, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 278, train_loss = 1.604883100837469, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 279, train_loss = 1.5993420965969563, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 280, train_loss = 1.5938244884600863, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 281, train_loss = 1.5883859718451276, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "17th- epoch: 282, train_loss = 1.5829476168146357, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 283, train_loss = 1.5775243366369978, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 284, train_loss = 1.5723428502678871, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 285, train_loss = 1.5670823007822037, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 286, train_loss = 1.5618527544429526, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 287, train_loss = 1.5566663878271356, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 288, train_loss = 1.5516049601137638, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 289, train_loss = 1.5464718490839005, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 290, train_loss = 1.541555181145668, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 291, train_loss = 1.5365569131681696, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 292, train_loss = 1.531540042371489, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 293, train_loss = 1.5267470938852057, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 294, train_loss = 1.5219033831963316, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 295, train_loss = 1.5170882766833529, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "17th- epoch: 296, train_loss = 1.5123447539517656, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 297, train_loss = 1.5076726898550987, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 298, train_loss = 1.502917798818089, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 299, train_loss = 1.4982809399953112, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 300, train_loss = 1.4937675906112418, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 301, train_loss = 1.4892185094067827, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 302, train_loss = 1.4846956668188795, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 303, train_loss = 1.4802675768733025, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 304, train_loss = 1.4758581655332819, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 305, train_loss = 1.4714888458838686, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 306, train_loss = 1.4671038798987865, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 307, train_loss = 1.462877418845892, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 308, train_loss = 1.4586125327041373, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 309, train_loss = 1.454389346181415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 310, train_loss = 1.4503010449698195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 311, train_loss = 1.4461314404616132, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 312, train_loss = 1.4419880086788908, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 313, train_loss = 1.437983719049953, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 314, train_loss = 1.433902827440761, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 315, train_loss = 1.4299557618796825, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 316, train_loss = 1.4259926924714819, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 317, train_loss = 1.4220774049172178, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 318, train_loss = 1.418207703740336, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 319, train_loss = 1.4143710732460022, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 320, train_loss = 1.410520141304005, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 321, train_loss = 1.4066729818587191, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 322, train_loss = 1.4029641238157637, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 323, train_loss = 1.3991905066068284, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 324, train_loss = 1.3954650561208837, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 325, train_loss = 1.391826553910505, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 326, train_loss = 1.3881824786658399, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 327, train_loss = 1.3844682264025323, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 328, train_loss = 1.380960262089502, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 329, train_loss = 1.3773107354645617, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 330, train_loss = 1.373830360651482, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 331, train_loss = 1.3702484642271884, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 332, train_loss = 1.366858221590519, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 333, train_loss = 1.363376371562481, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 334, train_loss = 1.3599186676437967, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 335, train_loss = 1.3565245146746747, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 336, train_loss = 1.3531368486583233, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 337, train_loss = 1.3498098254203796, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 338, train_loss = 1.3464898156817071, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 339, train_loss = 1.3432430028915405, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 340, train_loss = 1.339919860183727, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 341, train_loss = 1.336673628538847, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 342, train_loss = 1.3334854704444297, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 343, train_loss = 1.3302666507661343, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 344, train_loss = 1.3271067800815217, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 345, train_loss = 1.323948435485363, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 346, train_loss = 1.3208409249782562, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 347, train_loss = 1.317744744301308, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 348, train_loss = 1.3146775476634502, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 349, train_loss = 1.3116726949810982, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "17th- epoch: 350, train_loss = 1.3086190384929068, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 351, train_loss = 1.3055825767223723, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 352, train_loss = 1.3025647178292274, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 353, train_loss = 1.2995859595830552, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 354, train_loss = 1.2966482192277908, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 355, train_loss = 1.2937406438286416, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 356, train_loss = 1.2907550893723965, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 357, train_loss = 1.2879305059905164, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 358, train_loss = 1.2851198737625964, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 359, train_loss = 1.2821780045633204, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 360, train_loss = 1.279458028555382, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 361, train_loss = 1.276656640053261, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 362, train_loss = 1.2738709685509093, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 363, train_loss = 1.2710736393928528, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 364, train_loss = 1.268311200023163, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 365, train_loss = 1.2656264590914361, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 366, train_loss = 1.2629230953752995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 367, train_loss = 1.2603305068914779, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 368, train_loss = 1.257547352463007, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 369, train_loss = 1.254957792640198, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 370, train_loss = 1.2523588153417222, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 371, train_loss = 1.2497991174459457, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 372, train_loss = 1.2471635974943638, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 373, train_loss = 1.2446108497679234, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 374, train_loss = 1.2420717899804004, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 375, train_loss = 1.239453624933958, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 376, train_loss = 1.237099253863562, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 377, train_loss = 1.23444465798093, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 378, train_loss = 1.2320475007290952, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 379, train_loss = 1.2294869969482534, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 380, train_loss = 1.2271071312134154, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 381, train_loss = 1.2246851958334446, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 382, train_loss = 1.2221811935305595, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 383, train_loss = 1.2198886362020858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 384, train_loss = 1.2173740789294243, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 385, train_loss = 1.2150859708781354, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 386, train_loss = 1.2128075994551182, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 387, train_loss = 1.2103576895897277, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 388, train_loss = 1.208032085269224, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 389, train_loss = 1.2057777580921538, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 390, train_loss = 1.2033663168549538, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 391, train_loss = 1.2011080905795097, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 392, train_loss = 1.1989415176212788, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 393, train_loss = 1.1966394620831124, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 394, train_loss = 1.1944127504830249, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 395, train_loss = 1.1921471903915517, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 396, train_loss = 1.1900364880566485, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 397, train_loss = 1.187798670202028, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 398, train_loss = 1.1856184738571756, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 399, train_loss = 1.1834228076040745, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 400, train_loss = 1.1812802727217786, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 401, train_loss = 1.1792051456868649, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 402, train_loss = 1.1769158517126925, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 403, train_loss = 1.1748902797698975, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 404, train_loss = 1.1727041999693029, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 405, train_loss = 1.1706862610881217, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 406, train_loss = 1.1685972114210017, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 407, train_loss = 1.1665507654543035, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 408, train_loss = 1.1643511950969696, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 409, train_loss = 1.1624798588454723, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 410, train_loss = 1.1604040290112607, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 411, train_loss = 1.1583229092066176, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 412, train_loss = 1.1564712934195995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 413, train_loss = 1.154356423765421, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 414, train_loss = 1.1524201668798923, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 415, train_loss = 1.1503942211566027, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 416, train_loss = 1.148467630147934, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 417, train_loss = 1.1465057022869587, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 418, train_loss = 1.1444752402603626, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 419, train_loss = 1.142765212804079, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 420, train_loss = 1.140693224966526, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 421, train_loss = 1.1388114181754645, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 422, train_loss = 1.137009551137453, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 423, train_loss = 1.1350367429258768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 424, train_loss = 1.1333208171126898, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 425, train_loss = 1.131343041866785, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 426, train_loss = 1.1294602999987546, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 427, train_loss = 1.127686715364689, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 428, train_loss = 1.1258505384030286, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 429, train_loss = 1.1240349051950034, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 430, train_loss = 1.1223355593683664, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 431, train_loss = 1.1204340420663357, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 432, train_loss = 1.1186814953980502, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 433, train_loss = 1.1169799541530665, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 434, train_loss = 1.1150968372821808, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 435, train_loss = 1.1134024560451508, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 436, train_loss = 1.1116595901548862, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 437, train_loss = 1.1098300901649054, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 438, train_loss = 1.1082864254713058, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 439, train_loss = 1.1063827288744505, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 440, train_loss = 1.1047901660203934, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 441, train_loss = 1.1030461490154266, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17th- epoch: 442, train_loss = 1.1013619018194731, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 443, train_loss = 1.0997126015427057, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 444, train_loss = 1.0980237759649754, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 445, train_loss = 1.0963605220022146, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 446, train_loss = 1.0948052530584391, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 447, train_loss = 1.0929510990681592, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 448, train_loss = 1.0914733509125654, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 449, train_loss = 1.0897752208111342, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 450, train_loss = 1.0881108182074968, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 451, train_loss = 1.0865958059730474, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 452, train_loss = 1.0849222180841025, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 453, train_loss = 1.0833267606794834, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 454, train_loss = 1.0819162937405054, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 455, train_loss = 1.0802342357637826, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 456, train_loss = 1.078764100879198, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 457, train_loss = 1.0770694352686405, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 458, train_loss = 1.0756126133201178, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 459, train_loss = 1.074019305408001, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 460, train_loss = 1.0725369142892305, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 461, train_loss = 1.0709797218441963, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 462, train_loss = 1.069410731404787, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 463, train_loss = 1.068025954067707, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 464, train_loss = 1.066460424422985, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 465, train_loss = 1.0649661930801813, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 466, train_loss = 1.0634673958120402, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 467, train_loss = 1.061966030538315, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 468, train_loss = 1.0604844689369202, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 469, train_loss = 1.0589981389639433, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 470, train_loss = 1.05760751789785, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 471, train_loss = 1.0561640734376851, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 472, train_loss = 1.0546781172452029, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 473, train_loss = 1.0532291680574417, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 474, train_loss = 1.0518407399358694, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 475, train_loss = 1.0503607963619288, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 476, train_loss = 1.0489614220859949, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 477, train_loss = 1.047516543418169, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 478, train_loss = 1.0462410996260587, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 479, train_loss = 1.0447358613309916, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 480, train_loss = 1.043358171969885, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 481, train_loss = 1.0420403046009596, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 482, train_loss = 1.0405778661370277, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 483, train_loss = 1.0392529231903609, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 484, train_loss = 1.0379093574883882, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 485, train_loss = 1.036565687507391, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 486, train_loss = 1.0352027341723442, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 487, train_loss = 1.0338685239257757, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 488, train_loss = 1.0324974991381168, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 489, train_loss = 1.0311577071843203, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 490, train_loss = 1.0298580452799797, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 491, train_loss = 1.0286137896182481, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 492, train_loss = 1.0272442387940828, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 493, train_loss = 1.025972987205023, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 494, train_loss = 1.0246427965757903, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 495, train_loss = 1.0233721174299717, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 496, train_loss = 1.0220449157059193, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 497, train_loss = 1.0208368686435279, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 498, train_loss = 1.019471143692499, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "17th- epoch: 499, train_loss = 1.018225446343422, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|███████████████████████████████████████▋                              | 17/30 [1:55:58<1:28:58, 410.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "18th- epoch: 0, train_loss = 274.14282059669495, train_acc = 0.48253376804843967\n",
      "test Acc 0.5605214152700186:\n",
      "18th- epoch: 1, train_loss = 208.60552263259888, train_acc = 0.5612482533768048\n",
      "test Acc 0.5735567970204841:\n",
      "18th- epoch: 2, train_loss = 162.16968524456024, train_acc = 0.5905915230554262\n",
      "test Acc 0.6322160148975792:\n",
      "18th- epoch: 3, train_loss = 135.36707639694214, train_acc = 0.6661620866325105\n",
      "test Acc 0.7067039106145251:\n",
      "18th- epoch: 4, train_loss = 116.21404939889908, train_acc = 0.7333488588728458\n",
      "test Acc 0.7593109869646183:\n",
      "18th- epoch: 5, train_loss = 100.99215695261955, train_acc = 0.7647880763856544\n",
      "test Acc 0.7783985102420856:\n",
      "18th- epoch: 6, train_loss = 88.54445740580559, train_acc = 0.7833022822543083\n",
      "test Acc 0.8002793296089385:\n",
      "18th- epoch: 7, train_loss = 78.39050617814064, train_acc = 0.8148579413134607\n",
      "test Acc 0.8268156424581006:\n",
      "18th- epoch: 8, train_loss = 69.94332531094551, train_acc = 0.8471122496506753\n",
      "test Acc 0.8589385474860335:\n",
      "18th- epoch: 9, train_loss = 62.75204500555992, train_acc = 0.8742431299487657\n",
      "test Acc 0.8859404096834265:\n",
      "18th- epoch: 10, train_loss = 56.56412364542484, train_acc = 0.8936888681881695\n",
      "test Acc 0.9017690875232774:\n",
      "18th- epoch: 11, train_loss = 51.22136129438877, train_acc = 0.9046343735444806\n",
      "test Acc 0.9120111731843575:\n",
      "18th- epoch: 12, train_loss = 46.59764026105404, train_acc = 0.9153469958081043\n",
      "test Acc 0.9189944134078212:\n",
      "18th- epoch: 13, train_loss = 42.591201439499855, train_acc = 0.9281555659059152\n",
      "test Acc 0.9348230912476723:\n",
      "18th- epoch: 14, train_loss = 39.11064828932285, train_acc = 0.9370051234280391\n",
      "test Acc 0.9376163873370578:\n",
      "18th- epoch: 15, train_loss = 36.08968149870634, train_acc = 0.9407312529110387\n",
      "test Acc 0.9422718808193669:\n",
      "18th- epoch: 16, train_loss = 33.4703216701746, train_acc = 0.9427107591988821\n",
      "test Acc 0.9441340782122905:\n",
      "18th- epoch: 17, train_loss = 31.203017584979534, train_acc = 0.9451560316721006\n",
      "test Acc 0.946927374301676:\n",
      "18th- epoch: 18, train_loss = 29.23919080197811, train_acc = 0.9508616674429436\n",
      "test Acc 0.9539106145251397:\n",
      "18th- epoch: 19, train_loss = 27.53110484033823, train_acc = 0.9528411737307871\n",
      "test Acc 0.9557728119180633:\n",
      "18th- epoch: 20, train_loss = 26.036622799932957, train_acc = 0.9551700046576619\n",
      "test Acc 0.9562383612662942:\n",
      "18th- epoch: 21, train_loss = 24.72203502804041, train_acc = 0.9578481602235678\n",
      "test Acc 0.957169459962756:\n",
      "18th- epoch: 22, train_loss = 23.55840327218175, train_acc = 0.9598276665114113\n",
      "test Acc 0.9581005586592178:\n",
      "18th- epoch: 23, train_loss = 22.522997226566076, train_acc = 0.9609920819748486\n",
      "test Acc 0.9585661080074488:\n",
      "18th- epoch: 24, train_loss = 21.595703203231096, train_acc = 0.9614578481602236\n",
      "test Acc 0.9594972067039106:\n",
      "18th- epoch: 25, train_loss = 20.760005716234446, train_acc = 0.9630880298090359\n",
      "test Acc 0.9594972067039106:\n",
      "18th- epoch: 26, train_loss = 20.00119510665536, train_acc = 0.9637866790870983\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 27, train_loss = 19.308745238929987, train_acc = 0.9642524452724732\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 28, train_loss = 18.672334145754576, train_acc = 0.9654168607359106\n",
      "test Acc 0.9608938547486033:\n",
      "18th- epoch: 29, train_loss = 18.083996195346117, train_acc = 0.9659990684676293\n",
      "test Acc 0.9618249534450651:\n",
      "18th- epoch: 30, train_loss = 17.53807795792818, train_acc = 0.9662319515603167\n",
      "test Acc 0.9622905027932961:\n",
      "18th- epoch: 31, train_loss = 17.029744043946266, train_acc = 0.9670470423847228\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 32, train_loss = 16.554161116480827, train_acc = 0.9678621332091291\n",
      "test Acc 0.962756052141527:\n",
      "18th- epoch: 33, train_loss = 16.107953030616045, train_acc = 0.9685607824871915\n",
      "test Acc 0.9636871508379888:\n",
      "18th- epoch: 34, train_loss = 15.687762416899204, train_acc = 0.9699580810433163\n",
      "test Acc 0.9641527001862198:\n",
      "18th- epoch: 35, train_loss = 15.290925092995167, train_acc = 0.9717047042384723\n",
      "test Acc 0.9660148975791434:\n",
      "18th- epoch: 36, train_loss = 14.915598321706057, train_acc = 0.9731020027945971\n",
      "test Acc 0.9683426443202979:\n",
      "18th- epoch: 37, train_loss = 14.560283746570349, train_acc = 0.9742664182580345\n",
      "test Acc 0.9706703910614525:\n",
      "18th- epoch: 38, train_loss = 14.223443038761616, train_acc = 0.9744993013507219\n",
      "test Acc 0.9711359404096834:\n",
      "18th- epoch: 39, train_loss = 13.903249971568584, train_acc = 0.9748486259897532\n",
      "test Acc 0.9720670391061452:\n",
      "18th- epoch: 40, train_loss = 13.59826523810625, train_acc = 0.9751979506287843\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 41, train_loss = 13.307218566536903, train_acc = 0.975780158360503\n",
      "test Acc 0.973463687150838:\n",
      "18th- epoch: 42, train_loss = 13.029449187219143, train_acc = 0.9765952491849091\n",
      "test Acc 0.9739292364990689:\n",
      "18th- epoch: 43, train_loss = 12.763628330081701, train_acc = 0.9769445738239404\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 44, train_loss = 12.508833304047585, train_acc = 0.9772938984629715\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 45, train_loss = 12.264291789382696, train_acc = 0.9775267815556591\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 46, train_loss = 12.029590595513582, train_acc = 0.9783418723800652\n",
      "test Acc 0.9757914338919925:\n",
      "18th- epoch: 47, train_loss = 11.803880173712969, train_acc = 0.9789240801117839\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 48, train_loss = 11.586276657879353, train_acc = 0.9796227293898463\n",
      "test Acc 0.9767225325884544:\n",
      "18th- epoch: 49, train_loss = 11.37648031115532, train_acc = 0.97973917093619\n",
      "test Acc 0.9771880819366853:\n",
      "18th- epoch: 50, train_loss = 11.174109689891338, train_acc = 0.9800884955752213\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 51, train_loss = 10.978888411074877, train_acc = 0.9803213786679087\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 52, train_loss = 10.790253687649965, train_acc = 0.9807871448532837\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 53, train_loss = 10.60773641988635, train_acc = 0.9809035863996274\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 54, train_loss = 10.430963560938835, train_acc = 0.9809035863996274\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 55, train_loss = 10.259546354413033, train_acc = 0.9812529110386586\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 56, train_loss = 10.093344582244754, train_acc = 0.9817186772240335\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 57, train_loss = 9.931913768872619, train_acc = 0.981951560316721\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 58, train_loss = 9.775198858231306, train_acc = 0.9823008849557522\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 59, train_loss = 9.622961258515716, train_acc = 0.9825337680484397\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 60, train_loss = 9.474688220769167, train_acc = 0.9826502095947834\n",
      "test Acc 0.9776536312849162:\n",
      "18th- epoch: 61, train_loss = 9.330171359702945, train_acc = 0.9827666511411272\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 62, train_loss = 9.189059475436807, train_acc = 0.9827666511411272\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 63, train_loss = 9.051373951137066, train_acc = 0.9828830926874709\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 64, train_loss = 8.916998853906989, train_acc = 0.9828830926874709\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 65, train_loss = 8.785995388403535, train_acc = 0.9831159757801584\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 66, train_loss = 8.658226754516363, train_acc = 0.9833488588728458\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 67, train_loss = 8.533380191773176, train_acc = 0.9838146250582208\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 68, train_loss = 8.41126805730164, train_acc = 0.9838146250582208\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 69, train_loss = 8.291935615241528, train_acc = 0.984163949697252\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 70, train_loss = 8.175011647865176, train_acc = 0.9842803912435957\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 71, train_loss = 8.06051062606275, train_acc = 0.9845132743362832\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 72, train_loss = 7.9481884725391865, train_acc = 0.9847461574289706\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 73, train_loss = 7.838106200098991, train_acc = 0.9849790405216581\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 74, train_loss = 7.730306517332792, train_acc = 0.9850954820680019\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 75, train_loss = 7.624417811632156, train_acc = 0.9850954820680019\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 76, train_loss = 7.520677741616964, train_acc = 0.9853283651606893\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 77, train_loss = 7.418969774618745, train_acc = 0.9853283651606893\n",
      "test Acc 0.9781191806331471:\n",
      "18th- epoch: 78, train_loss = 7.3192044496536255, train_acc = 0.985444806707033\n",
      "test Acc 0.978584729981378:\n",
      "18th- epoch: 79, train_loss = 7.221464237198234, train_acc = 0.985910572892408\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 80, train_loss = 7.1255939323455095, train_acc = 0.9860270144387517\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 81, train_loss = 7.031526377424598, train_acc = 0.9860270144387517\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 82, train_loss = 6.939288195222616, train_acc = 0.9862598975314392\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 83, train_loss = 6.8488110434263945, train_acc = 0.9866092221704704\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 84, train_loss = 6.760003417730331, train_acc = 0.9866092221704704\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 85, train_loss = 6.672948408871889, train_acc = 0.9867256637168141\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 86, train_loss = 6.587545279413462, train_acc = 0.9868421052631579\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 87, train_loss = 6.503594774752855, train_acc = 0.9868421052631579\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 88, train_loss = 6.421378938481212, train_acc = 0.9873078714485328\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 89, train_loss = 6.340616833418608, train_acc = 0.9874243129948765\n",
      "test Acc 0.979050279329609:\n",
      "18th- epoch: 90, train_loss = 6.261351123452187, train_acc = 0.9880065207265952\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 91, train_loss = 6.18346787057817, train_acc = 0.9880065207265952\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 92, train_loss = 6.107050450518727, train_acc = 0.9881229622729389\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 93, train_loss = 6.032135114073753, train_acc = 0.9883558453656265\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 94, train_loss = 5.958516465499997, train_acc = 0.9885887284583139\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 95, train_loss = 5.886435266584158, train_acc = 0.9888216115510013\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 96, train_loss = 5.815542809665203, train_acc = 0.9888216115510013\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 97, train_loss = 5.746074499562383, train_acc = 0.9890544946436889\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 98, train_loss = 5.677842004224658, train_acc = 0.9891709361900326\n",
      "test Acc 0.9795158286778398:\n",
      "18th- epoch: 99, train_loss = 5.610873449593782, train_acc = 0.9892873777363763\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 100, train_loss = 5.545218151062727, train_acc = 0.9892873777363763\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 101, train_loss = 5.480683857575059, train_acc = 0.98940381928272\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 102, train_loss = 5.417532531544566, train_acc = 0.9895202608290639\n",
      "test Acc 0.9809124767225326:\n",
      "18th- epoch: 103, train_loss = 5.3553207740187645, train_acc = 0.9895202608290639\n",
      "test Acc 0.9813780260707635:\n",
      "18th- epoch: 104, train_loss = 5.294423842802644, train_acc = 0.9896367023754076\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 105, train_loss = 5.23450515139848, train_acc = 0.9897531439217513\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 106, train_loss = 5.175712503492832, train_acc = 0.989869585468095\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 107, train_loss = 5.117923245765269, train_acc = 0.99033535165347\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 108, train_loss = 5.061230113729835, train_acc = 0.9905682347461574\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 109, train_loss = 5.0054370472207665, train_acc = 0.9906846762925011\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 110, train_loss = 4.950762450695038, train_acc = 0.990801117838845\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 111, train_loss = 4.896939626894891, train_acc = 0.990801117838845\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 112, train_loss = 4.8440633388236165, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 113, train_loss = 4.792240682989359, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 114, train_loss = 4.7412867695093155, train_acc = 0.990801117838845\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 115, train_loss = 4.6912245489656925, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 116, train_loss = 4.642036784440279, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "18th- epoch: 117, train_loss = 4.593773719854653, train_acc = 0.9910340009315324\n",
      "test Acc 0.9823091247672253:\n",
      "18th- epoch: 118, train_loss = 4.546316391788423, train_acc = 0.9910340009315324\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 119, train_loss = 4.499598203226924, train_acc = 0.9913833255705635\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 120, train_loss = 4.453795026987791, train_acc = 0.9914997671169073\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 121, train_loss = 4.408693131990731, train_acc = 0.9916162086632511\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 122, train_loss = 4.364474434405565, train_acc = 0.9917326502095948\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 123, train_loss = 4.3210052493959665, train_acc = 0.9919655333022822\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 124, train_loss = 4.278282697312534, train_acc = 0.9923148579413135\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 125, train_loss = 4.236344828270376, train_acc = 0.9924312994876572\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 126, train_loss = 4.195011310279369, train_acc = 0.9925477410340009\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 127, train_loss = 4.154419663362205, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 128, train_loss = 4.11453499365598, train_acc = 0.9928970656730322\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 129, train_loss = 4.075355863198638, train_acc = 0.9931299487657196\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 130, train_loss = 4.036714611575007, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 131, train_loss = 3.9988670805469155, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 132, train_loss = 3.9615041678771377, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 133, train_loss = 3.9249231461435556, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "18th- epoch: 134, train_loss = 3.888807059265673, train_acc = 0.9933628318584071\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 135, train_loss = 3.8532225834205747, train_acc = 0.9934792734047508\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 136, train_loss = 3.8183531695976853, train_acc = 0.9934792734047508\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 137, train_loss = 3.7839023526757956, train_acc = 0.9934792734047508\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 138, train_loss = 3.7501207822933793, train_acc = 0.9934792734047508\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 139, train_loss = 3.716839887201786, train_acc = 0.9935957149510946\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 140, train_loss = 3.683966778218746, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 141, train_loss = 3.6517336359247565, train_acc = 0.9939450395901258\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 142, train_loss = 3.6200612923130393, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 143, train_loss = 3.5887173851951957, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 144, train_loss = 3.557842139620334, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 145, train_loss = 3.5274980566464365, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 146, train_loss = 3.497641993686557, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18th- epoch: 147, train_loss = 3.4681169632822275, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 148, train_loss = 3.4391862987540662, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 149, train_loss = 3.41049299063161, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 150, train_loss = 3.3824367779307067, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 151, train_loss = 3.354611294809729, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 152, train_loss = 3.327258674427867, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 153, train_loss = 3.300306396558881, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 154, train_loss = 3.2738185194320977, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 155, train_loss = 3.247617097571492, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 156, train_loss = 3.2217752300202847, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 157, train_loss = 3.196410868316889, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 158, train_loss = 3.1712982803583145, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 159, train_loss = 3.146627784240991, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 160, train_loss = 3.122177964542061, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 161, train_loss = 3.0982261523604393, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 162, train_loss = 3.0744929518550634, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 163, train_loss = 3.0511030019260943, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 164, train_loss = 3.028104002121836, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 165, train_loss = 3.005185214802623, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 166, train_loss = 2.9827941763214767, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 167, train_loss = 2.960618364159018, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "18th- epoch: 168, train_loss = 2.9386951830238104, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 169, train_loss = 2.917097119614482, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 170, train_loss = 2.8959488519467413, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 171, train_loss = 2.874843674246222, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 172, train_loss = 2.8541204296052456, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 173, train_loss = 2.833738098386675, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 174, train_loss = 2.8134648837149143, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 175, train_loss = 2.7934611798264086, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 176, train_loss = 2.773855719715357, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 177, train_loss = 2.75438172230497, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 178, train_loss = 2.735200844705105, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 179, train_loss = 2.7163333878852427, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 180, train_loss = 2.6976557462476194, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 181, train_loss = 2.6791247413493693, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 182, train_loss = 2.660911660641432, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 183, train_loss = 2.6429009176790714, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 184, train_loss = 2.6251935861073434, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 185, train_loss = 2.607578095048666, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "18th- epoch: 186, train_loss = 2.590319489594549, train_acc = 0.9956916627852818\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 187, train_loss = 2.5732753998599946, train_acc = 0.9956916627852818\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 188, train_loss = 2.5563372932374477, train_acc = 0.9958081043316255\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 189, train_loss = 2.5396542684175074, train_acc = 0.9958081043316255\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 190, train_loss = 2.523228817153722, train_acc = 0.9958081043316255\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 191, train_loss = 2.5069151029456407, train_acc = 0.9958081043316255\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 192, train_loss = 2.4908284198027104, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 193, train_loss = 2.4749807491898537, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 194, train_loss = 2.4592589922249317, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 195, train_loss = 2.4438691053073853, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 196, train_loss = 2.4285342309158295, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 197, train_loss = 2.413344628410414, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 198, train_loss = 2.398323505418375, train_acc = 0.9959245458779693\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 199, train_loss = 2.3835449919570237, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 200, train_loss = 2.3687962151598185, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 201, train_loss = 2.354280386120081, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 202, train_loss = 2.339968853862956, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 203, train_loss = 2.325800122693181, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 204, train_loss = 2.3117913119494915, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 205, train_loss = 2.2979562282562256, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 206, train_loss = 2.284362345933914, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 207, train_loss = 2.2708761033136398, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 208, train_loss = 2.25754655408673, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 209, train_loss = 2.2444192834664136, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 210, train_loss = 2.2314056486357003, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 211, train_loss = 2.2186217103153467, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 212, train_loss = 2.2059077247977257, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 213, train_loss = 2.193471997976303, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 214, train_loss = 2.181092246202752, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 215, train_loss = 2.168908227235079, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 216, train_loss = 2.1567865039687604, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 217, train_loss = 2.1449148084502667, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 218, train_loss = 2.1331799868494272, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 219, train_loss = 2.1214850719552487, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 220, train_loss = 2.1100496978033334, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 221, train_loss = 2.098720832495019, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 222, train_loss = 2.0875514920335263, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 223, train_loss = 2.0764553181361407, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 224, train_loss = 2.0655650820117444, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 225, train_loss = 2.0548394315410405, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 226, train_loss = 2.0442034006118774, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 227, train_loss = 2.033714796183631, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 228, train_loss = 2.0233432967215776, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 229, train_loss = 2.013067460851744, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 230, train_loss = 2.0029935513157398, train_acc = 0.9966231951560317\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 231, train_loss = 1.9930385400075465, train_acc = 0.9966231951560317\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 232, train_loss = 1.983123616548255, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 233, train_loss = 1.9734152506571263, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 234, train_loss = 1.9637234702240676, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 235, train_loss = 1.9542261741589755, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 236, train_loss = 1.9448666672687978, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 237, train_loss = 1.9355601395945996, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 238, train_loss = 1.9264707725960761, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 239, train_loss = 1.9173484910279512, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 240, train_loss = 1.9083834073971957, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 241, train_loss = 1.8995030068326741, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 242, train_loss = 1.8907827611546963, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 243, train_loss = 1.8821614447515458, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 244, train_loss = 1.8736377202440053, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 245, train_loss = 1.8651515778619796, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 246, train_loss = 1.8567540899384767, train_acc = 0.9970889613414066\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 247, train_loss = 1.8485226302873343, train_acc = 0.9970889613414066\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 248, train_loss = 1.840334617299959, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 249, train_loss = 1.8322128325235099, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 250, train_loss = 1.8243161892751232, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 251, train_loss = 1.816421945928596, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 252, train_loss = 1.8085406062891707, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 253, train_loss = 1.8008400102844462, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 254, train_loss = 1.7932180054485798, train_acc = 0.9973218444340941\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 255, train_loss = 1.7856711422791705, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 256, train_loss = 1.7782394563546404, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 257, train_loss = 1.770765715627931, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 258, train_loss = 1.763557737111114, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 259, train_loss = 1.7562679400434718, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 260, train_loss = 1.749160317122005, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 261, train_loss = 1.7420573817798868, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 262, train_loss = 1.7351645665476099, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 263, train_loss = 1.7281785471132025, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 264, train_loss = 1.7213453985750675, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 265, train_loss = 1.7145574601599947, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 266, train_loss = 1.707864304422401, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 267, train_loss = 1.701085016131401, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 268, train_loss = 1.6944961845874786, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "18th- epoch: 269, train_loss = 1.6878747195005417, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 270, train_loss = 1.681540901423432, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 271, train_loss = 1.67513917631004, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "18th- epoch: 272, train_loss = 1.6689044684171677, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "18th- epoch: 273, train_loss = 1.6626458229729906, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "18th- epoch: 274, train_loss = 1.6565323695540428, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "18th- epoch: 275, train_loss = 1.6504239663481712, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "18th- epoch: 276, train_loss = 1.6443529153475538, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "18th- epoch: 277, train_loss = 1.6384605219354853, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "18th- epoch: 278, train_loss = 1.6325842514634132, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "18th- epoch: 279, train_loss = 1.6266892241546884, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 280, train_loss = 1.6209018677473068, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 281, train_loss = 1.6152395457029343, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 282, train_loss = 1.6095155266812071, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 283, train_loss = 1.6039232028415427, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 284, train_loss = 1.5983522161841393, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 285, train_loss = 1.5928506826749071, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 286, train_loss = 1.5873859549174085, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 287, train_loss = 1.5819826436927542, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 288, train_loss = 1.5766756968805566, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 289, train_loss = 1.5713789401343092, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 290, train_loss = 1.566154383122921, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 291, train_loss = 1.5608852902660146, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 292, train_loss = 1.5558073222637177, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 293, train_loss = 1.5507259418955073, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 294, train_loss = 1.5456748692085966, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 295, train_loss = 1.5406287921359763, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 296, train_loss = 1.53564005845692, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 297, train_loss = 1.5307536708423868, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 298, train_loss = 1.5258583463728428, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 299, train_loss = 1.5211014015367255, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 300, train_loss = 1.5162491239607334, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 301, train_loss = 1.5115355178713799, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 302, train_loss = 1.506854634732008, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 303, train_loss = 1.502185795456171, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 304, train_loss = 1.4976116666803136, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 305, train_loss = 1.493057499290444, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 306, train_loss = 1.4884971143910661, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 307, train_loss = 1.484041833668016, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 308, train_loss = 1.479569306015037, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 309, train_loss = 1.4752547679236159, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 310, train_loss = 1.4708447804441676, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 311, train_loss = 1.4664959026267752, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 312, train_loss = 1.4622448161244392, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 313, train_loss = 1.4579737050225958, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 314, train_loss = 1.453788244514726, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 315, train_loss = 1.4496195018291473, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 316, train_loss = 1.4455287927994505, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 317, train_loss = 1.4413849413394928, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 318, train_loss = 1.4373243724694476, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 319, train_loss = 1.4332701502135023, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 320, train_loss = 1.4292697198688984, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 321, train_loss = 1.4253950864076614, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 322, train_loss = 1.4213540330529213, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 323, train_loss = 1.4174656520481221, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 324, train_loss = 1.4136130685801618, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 325, train_loss = 1.409749735146761, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 326, train_loss = 1.405978320806753, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 327, train_loss = 1.40220022079302, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 328, train_loss = 1.3984658258850686, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 329, train_loss = 1.3947898733313195, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 330, train_loss = 1.391109065443743, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 331, train_loss = 1.3874475422198884, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 332, train_loss = 1.3838929024641402, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 333, train_loss = 1.380200669169426, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 334, train_loss = 1.3766718481783755, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 335, train_loss = 1.3731666940147988, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 336, train_loss = 1.3696504198014736, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 337, train_loss = 1.3661910966038704, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 338, train_loss = 1.3626414823229425, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 339, train_loss = 1.359296600043308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 340, train_loss = 1.3559599183499813, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 341, train_loss = 1.3525033642654307, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 342, train_loss = 1.349208275496494, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 343, train_loss = 1.3458563759922981, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 344, train_loss = 1.3426134933833964, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 345, train_loss = 1.3393931475584395, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 346, train_loss = 1.3361281653051265, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 347, train_loss = 1.3329093232750893, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 348, train_loss = 1.3297207914292812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 349, train_loss = 1.3266013910179026, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 350, train_loss = 1.3234466699068435, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 351, train_loss = 1.3203421458601952, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 352, train_loss = 1.3172644066507928, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 353, train_loss = 1.3141579392249696, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 354, train_loss = 1.3111252300441265, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 355, train_loss = 1.3081641333992593, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 356, train_loss = 1.305168644816149, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 357, train_loss = 1.3021731215412728, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 358, train_loss = 1.2991744466125965, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 359, train_loss = 1.2963304941658862, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 360, train_loss = 1.2934022024273872, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 361, train_loss = 1.290447564155329, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 362, train_loss = 1.2876244050567038, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 363, train_loss = 1.2847502939403057, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 364, train_loss = 1.281943870068062, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 365, train_loss = 1.2791221353108995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 366, train_loss = 1.2763689644634724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 367, train_loss = 1.2736258220975287, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 368, train_loss = 1.2708759282832034, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 369, train_loss = 1.268059778958559, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 370, train_loss = 1.2654040567576885, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 371, train_loss = 1.2626712620258331, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 372, train_loss = 1.2600668755476363, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 373, train_loss = 1.257395199208986, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 374, train_loss = 1.2547100894153118, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 375, train_loss = 1.252164846926462, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 376, train_loss = 1.2495187856256962, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 377, train_loss = 1.2470023296773434, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 378, train_loss = 1.244394128501881, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 379, train_loss = 1.241816335648764, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 380, train_loss = 1.2393601648509502, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 381, train_loss = 1.236858504533302, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 382, train_loss = 1.234289304644335, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 383, train_loss = 1.2318619911675341, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 384, train_loss = 1.2293437731568702, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 385, train_loss = 1.2270210261340253, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 386, train_loss = 1.2245152865652926, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 387, train_loss = 1.2221324357087724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 388, train_loss = 1.2197411942179315, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 389, train_loss = 1.2173534755711444, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 390, train_loss = 1.2150177632574923, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "18th- epoch: 391, train_loss = 1.21265560638858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 392, train_loss = 1.2103382970090024, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 393, train_loss = 1.2080644902889617, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 394, train_loss = 1.2057858295738697, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 395, train_loss = 1.2034134728019126, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 396, train_loss = 1.2011847645044327, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 397, train_loss = 1.1988960008020513, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 398, train_loss = 1.1966914435033686, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 399, train_loss = 1.194445709406864, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 400, train_loss = 1.1923188951914199, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 401, train_loss = 1.1900481879711151, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 402, train_loss = 1.187822339416016, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 403, train_loss = 1.185711921483744, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 404, train_loss = 1.1835365518927574, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 405, train_loss = 1.1813822947442532, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 406, train_loss = 1.1792347890441306, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 407, train_loss = 1.1771342977881432, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 408, train_loss = 1.1750402835314162, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 409, train_loss = 1.1730062464775983, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 410, train_loss = 1.1708915407361928, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 411, train_loss = 1.168804136425024, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 412, train_loss = 1.1667683348059654, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 413, train_loss = 1.1647101988492068, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 414, train_loss = 1.1627150674758013, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 415, train_loss = 1.160686475544935, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 416, train_loss = 1.1586566095647868, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 417, train_loss = 1.156687085836893, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 418, train_loss = 1.154647054761881, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 419, train_loss = 1.1526920398173388, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 420, train_loss = 1.1507868369517382, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 421, train_loss = 1.1488101618888322, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 422, train_loss = 1.1469242523016874, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 423, train_loss = 1.1449675063195173, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 424, train_loss = 1.1430156181158964, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 425, train_loss = 1.1411650367081165, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 426, train_loss = 1.1392772284743842, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 427, train_loss = 1.1373806124029215, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 428, train_loss = 1.1354982741177082, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 429, train_loss = 1.1336454041302204, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 430, train_loss = 1.1317653792502824, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 431, train_loss = 1.1299792143108789, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 432, train_loss = 1.1281317596731242, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 433, train_loss = 1.1263226196169853, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 434, train_loss = 1.124478609621292, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 435, train_loss = 1.1227478919026908, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 436, train_loss = 1.1209277125599328, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 437, train_loss = 1.1191522268054541, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 438, train_loss = 1.1173607967793941, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 439, train_loss = 1.1156482572259847, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 440, train_loss = 1.1138741945324, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 441, train_loss = 1.1121103838086128, train_acc = 0.9979040521658128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 442, train_loss = 1.1103302972915117, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 443, train_loss = 1.10866398861981, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 444, train_loss = 1.1069695688784122, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 445, train_loss = 1.1052932105958462, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 446, train_loss = 1.103558599948883, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 447, train_loss = 1.1019235998392105, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 448, train_loss = 1.1002128596010152, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 449, train_loss = 1.09859842932201, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 450, train_loss = 1.0968530103564262, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 451, train_loss = 1.0952999827859458, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 452, train_loss = 1.0936187133193016, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 453, train_loss = 1.0919815301895142, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 454, train_loss = 1.0904195432958659, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 455, train_loss = 1.0887534531357232, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 456, train_loss = 1.0871692573127802, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 457, train_loss = 1.0855820576252881, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 458, train_loss = 1.0839825309813023, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 459, train_loss = 1.0823495586810168, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 460, train_loss = 1.0808222157356795, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 461, train_loss = 1.0792103049752768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 462, train_loss = 1.0777287570235785, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 463, train_loss = 1.076159480959177, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 464, train_loss = 1.0746578363177832, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 465, train_loss = 1.0730884162185248, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 466, train_loss = 1.071693797915941, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 467, train_loss = 1.0700498968362808, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 468, train_loss = 1.068548634648323, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 469, train_loss = 1.0671342027781066, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 470, train_loss = 1.0655440427362919, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 471, train_loss = 1.0640975547430571, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 472, train_loss = 1.0626438856124878, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 473, train_loss = 1.0610696524381638, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 474, train_loss = 1.0597680856881198, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 475, train_loss = 1.0582083649933338, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 476, train_loss = 1.0567920431494713, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 477, train_loss = 1.0553558530809823, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 478, train_loss = 1.0538953555223998, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 479, train_loss = 1.0524603302183095, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 480, train_loss = 1.0511222568748053, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 481, train_loss = 1.0496522821485996, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 482, train_loss = 1.048276461660862, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 483, train_loss = 1.0467901614902075, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 484, train_loss = 1.0454877180454787, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 485, train_loss = 1.044105021894211, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 486, train_loss = 1.042658768594265, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 487, train_loss = 1.041335945337778, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 488, train_loss = 1.0399243136344012, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 489, train_loss = 1.0385483068821486, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 490, train_loss = 1.0372543608245905, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 491, train_loss = 1.0358083111641463, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 492, train_loss = 1.034568928182125, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 493, train_loss = 1.0331733909843024, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 494, train_loss = 1.0319318448600825, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 495, train_loss = 1.0305074018833693, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 496, train_loss = 1.0292625116708223, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 497, train_loss = 1.0279139056801796, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 498, train_loss = 1.0266536884009838, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "18th- epoch: 499, train_loss = 1.0252462700009346, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████████████████████████████████                            | 18/30 [2:02:48<1:22:03, 410.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "19th- epoch: 0, train_loss = 273.35866820812225, train_acc = 0.4574988355845366\n",
      "test Acc 0.49115456238361266:\n",
      "19th- epoch: 1, train_loss = 209.4586216211319, train_acc = 0.49534233814625056\n",
      "test Acc 0.49767225325884545:\n",
      "19th- epoch: 2, train_loss = 162.78307437896729, train_acc = 0.5700978108989287\n",
      "test Acc 0.6210428305400373:\n",
      "19th- epoch: 3, train_loss = 137.0637003183365, train_acc = 0.6693060083837913\n",
      "test Acc 0.7183426443202979:\n",
      "19th- epoch: 4, train_loss = 118.75594371557236, train_acc = 0.7333488588728458\n",
      "test Acc 0.7523277467411545:\n",
      "19th- epoch: 5, train_loss = 103.8967936038971, train_acc = 0.7578015836050302\n",
      "test Acc 0.7732774674115456:\n",
      "19th- epoch: 6, train_loss = 91.34985229372978, train_acc = 0.774685607824872\n",
      "test Acc 0.7900372439478585:\n",
      "19th- epoch: 7, train_loss = 80.96374174952507, train_acc = 0.8004191895668374\n",
      "test Acc 0.8091247672253259:\n",
      "19th- epoch: 8, train_loss = 72.22172117233276, train_acc = 0.827433628318584\n",
      "test Acc 0.8421787709497207:\n",
      "19th- epoch: 9, train_loss = 64.64267441630363, train_acc = 0.8652771308802981\n",
      "test Acc 0.8817504655493482:\n",
      "19th- epoch: 10, train_loss = 58.0077158510685, train_acc = 0.8942710759198882\n",
      "test Acc 0.9073556797020484:\n",
      "19th- epoch: 11, train_loss = 52.23990447819233, train_acc = 0.9139496972519795\n",
      "test Acc 0.9231843575418994:\n",
      "19th- epoch: 12, train_loss = 47.273186191916466, train_acc = 0.9273404750815091\n",
      "test Acc 0.9324953445065177:\n",
      "19th- epoch: 13, train_loss = 43.01701633632183, train_acc = 0.933977643223102\n",
      "test Acc 0.936219739292365:\n",
      "19th- epoch: 14, train_loss = 39.37773701548576, train_acc = 0.9370051234280391\n",
      "test Acc 0.9390130353817505:\n",
      "19th- epoch: 15, train_loss = 36.26619156450033, train_acc = 0.9399161620866325\n",
      "test Acc 0.9404096834264432:\n",
      "19th- epoch: 16, train_loss = 33.609751388430595, train_acc = 0.9408476944573824\n",
      "test Acc 0.9427374301675978:\n",
      "19th- epoch: 17, train_loss = 31.336779728531837, train_acc = 0.9428272007452259\n",
      "test Acc 0.9464618249534451:\n",
      "19th- epoch: 18, train_loss = 29.38290311396122, train_acc = 0.9470190964136004\n",
      "test Acc 0.9501862197392924:\n",
      "19th- epoch: 19, train_loss = 27.691357977688313, train_acc = 0.9527247321844434\n",
      "test Acc 0.9534450651769087:\n",
      "19th- epoch: 20, train_loss = 26.214831314980984, train_acc = 0.9544713553795995\n",
      "test Acc 0.9534450651769087:\n",
      "19th- epoch: 21, train_loss = 24.915759656578302, train_acc = 0.955519329296693\n",
      "test Acc 0.9557728119180633:\n",
      "19th- epoch: 22, train_loss = 23.76452338322997, train_acc = 0.9570330693991617\n",
      "test Acc 0.957635009310987:\n",
      "19th- epoch: 23, train_loss = 22.73508570715785, train_acc = 0.9577317186772241\n",
      "test Acc 0.9585661080074488:\n",
      "19th- epoch: 24, train_loss = 21.807752318680286, train_acc = 0.9595947834187238\n",
      "test Acc 0.9590316573556797:\n",
      "19th- epoch: 25, train_loss = 20.96777183562517, train_acc = 0.9606427573358174\n",
      "test Acc 0.9594972067039106:\n",
      "19th- epoch: 26, train_loss = 20.200656097382307, train_acc = 0.9622729389846297\n",
      "test Acc 0.9594972067039106:\n",
      "19th- epoch: 27, train_loss = 19.49783167243004, train_acc = 0.9630880298090359\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 28, train_loss = 18.850629296153784, train_acc = 0.9633209129017233\n",
      "test Acc 0.9599627560521415:\n",
      "19th- epoch: 29, train_loss = 18.25180147960782, train_acc = 0.9640195621797858\n",
      "test Acc 0.9608938547486033:\n",
      "19th- epoch: 30, train_loss = 17.694850254803896, train_acc = 0.9647182114578482\n",
      "test Acc 0.9622905027932961:\n",
      "19th- epoch: 31, train_loss = 17.175459656864405, train_acc = 0.9657661853749417\n",
      "test Acc 0.9632216014897579:\n",
      "19th- epoch: 32, train_loss = 16.689325366169214, train_acc = 0.9669306008383791\n",
      "test Acc 0.962756052141527:\n",
      "19th- epoch: 33, train_loss = 16.23385399580002, train_acc = 0.9679785747554728\n",
      "test Acc 0.9632216014897579:\n",
      "19th- epoch: 34, train_loss = 15.805668260902166, train_acc = 0.9697251979506288\n",
      "test Acc 0.9636871508379888:\n",
      "19th- epoch: 35, train_loss = 15.401686143130064, train_acc = 0.9707731718677224\n",
      "test Acc 0.9660148975791434:\n",
      "19th- epoch: 36, train_loss = 15.019562296569347, train_acc = 0.9720540288775035\n",
      "test Acc 0.9669459962756052:\n",
      "19th- epoch: 37, train_loss = 14.658000327646732, train_acc = 0.9732184443409408\n",
      "test Acc 0.9692737430167597:\n",
      "19th- epoch: 38, train_loss = 14.315082006156445, train_acc = 0.974033535165347\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 39, train_loss = 13.989485040307045, train_acc = 0.9746157428970657\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 40, train_loss = 13.679360944777727, train_acc = 0.9755472752678156\n",
      "test Acc 0.9706703910614525:\n",
      "19th- epoch: 41, train_loss = 13.382899302989244, train_acc = 0.9756637168141593\n",
      "test Acc 0.9716014897579144:\n",
      "19th- epoch: 42, train_loss = 13.099418953061104, train_acc = 0.9760130414531905\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 43, train_loss = 12.828114990144968, train_acc = 0.9765952491849091\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 44, train_loss = 12.568138435482979, train_acc = 0.9771774569166278\n",
      "test Acc 0.9720670391061452:\n",
      "19th- epoch: 45, train_loss = 12.318911030888557, train_acc = 0.9774103400093154\n",
      "test Acc 0.9725325884543762:\n",
      "19th- epoch: 46, train_loss = 12.07964288070798, train_acc = 0.9777596646483465\n",
      "test Acc 0.973463687150838:\n",
      "19th- epoch: 47, train_loss = 11.849753316491842, train_acc = 0.9781089892873778\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 48, train_loss = 11.62884433940053, train_acc = 0.9784583139264089\n",
      "test Acc 0.9739292364990689:\n",
      "19th- epoch: 49, train_loss = 11.416210077703, train_acc = 0.9789240801117839\n",
      "test Acc 0.9748603351955307:\n",
      "19th- epoch: 50, train_loss = 11.211265377700329, train_acc = 0.97973917093619\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 51, train_loss = 11.01330429688096, train_acc = 0.980204937121565\n",
      "test Acc 0.9753258845437617:\n",
      "19th- epoch: 52, train_loss = 10.82209992222488, train_acc = 0.9807871448532837\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 53, train_loss = 10.637197585776448, train_acc = 0.98067070330694\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 54, train_loss = 10.45822068862617, train_acc = 0.9809035863996274\n",
      "test Acc 0.9757914338919925:\n",
      "19th- epoch: 55, train_loss = 10.284739505499601, train_acc = 0.9812529110386586\n",
      "test Acc 0.9767225325884544:\n",
      "19th- epoch: 56, train_loss = 10.116253767162561, train_acc = 0.9816022356776898\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 57, train_loss = 9.952526938170195, train_acc = 0.9818351187703773\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 58, train_loss = 9.79344622604549, train_acc = 0.981951560316721\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 59, train_loss = 9.638768488541245, train_acc = 0.981951560316721\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 60, train_loss = 9.488303380087018, train_acc = 0.9825337680484397\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 61, train_loss = 9.341641675680876, train_acc = 0.9826502095947834\n",
      "test Acc 0.9776536312849162:\n",
      "19th- epoch: 62, train_loss = 9.198668736964464, train_acc = 0.9827666511411272\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 63, train_loss = 9.059174247086048, train_acc = 0.9829995342338146\n",
      "test Acc 0.9781191806331471:\n",
      "19th- epoch: 64, train_loss = 8.923303883522749, train_acc = 0.9834653004191896\n",
      "test Acc 0.978584729981378:\n",
      "19th- epoch: 65, train_loss = 8.790710100904107, train_acc = 0.9834653004191896\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 66, train_loss = 8.661258980631828, train_acc = 0.983698183511877\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 67, train_loss = 8.534714993089437, train_acc = 0.9838146250582208\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 68, train_loss = 8.411020245403051, train_acc = 0.9840475081509082\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 69, train_loss = 8.290006896480918, train_acc = 0.984163949697252\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 70, train_loss = 8.17180003784597, train_acc = 0.984163949697252\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 71, train_loss = 8.056080436334014, train_acc = 0.9845132743362832\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 72, train_loss = 7.942809043452144, train_acc = 0.9848625989753144\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 73, train_loss = 7.831856155768037, train_acc = 0.9852119236143456\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 74, train_loss = 7.723051393404603, train_acc = 0.9852119236143456\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 75, train_loss = 7.61644122004509, train_acc = 0.9852119236143456\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 76, train_loss = 7.511878285557032, train_acc = 0.9853283651606893\n",
      "test Acc 0.9795158286778398:\n",
      "19th- epoch: 77, train_loss = 7.409040965139866, train_acc = 0.9853283651606893\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 78, train_loss = 7.308413373306394, train_acc = 0.9853283651606893\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 79, train_loss = 7.20956776291132, train_acc = 0.985444806707033\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 80, train_loss = 7.1128066424280405, train_acc = 0.9856776897997206\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 81, train_loss = 7.017747754231095, train_acc = 0.9856776897997206\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 82, train_loss = 6.924617337062955, train_acc = 0.9860270144387517\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 83, train_loss = 6.833271659910679, train_acc = 0.9861434559850955\n",
      "test Acc 0.9799813780260708:\n",
      "19th- epoch: 84, train_loss = 6.743607133626938, train_acc = 0.9861434559850955\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 85, train_loss = 6.6558884754776955, train_acc = 0.9862598975314392\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 86, train_loss = 6.5696819350123405, train_acc = 0.9864927806241267\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 87, train_loss = 6.485364044085145, train_acc = 0.9867256637168141\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 88, train_loss = 6.402659580111504, train_acc = 0.9868421052631579\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 89, train_loss = 6.321634294465184, train_acc = 0.9868421052631579\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 90, train_loss = 6.242169255390763, train_acc = 0.9869585468095017\n",
      "test Acc 0.9804469273743017:\n",
      "19th- epoch: 91, train_loss = 6.164228290319443, train_acc = 0.9874243129948765\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 92, train_loss = 6.0878093130886555, train_acc = 0.9877736376339078\n",
      "test Acc 0.9809124767225326:\n",
      "19th- epoch: 93, train_loss = 6.0128006264567375, train_acc = 0.9877736376339078\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 94, train_loss = 5.939200637862086, train_acc = 0.9878900791802515\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 95, train_loss = 5.866939898580313, train_acc = 0.9880065207265952\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 96, train_loss = 5.796039143577218, train_acc = 0.9882394038192828\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 97, train_loss = 5.72651282325387, train_acc = 0.9885887284583139\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 98, train_loss = 5.658227290958166, train_acc = 0.9888216115510013\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 99, train_loss = 5.5913102477788925, train_acc = 0.9892873777363763\n",
      "test Acc 0.9813780260707635:\n",
      "19th- epoch: 100, train_loss = 5.525685675442219, train_acc = 0.98940381928272\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 101, train_loss = 5.4612135868519545, train_acc = 0.9896367023754076\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 102, train_loss = 5.398027086630464, train_acc = 0.9896367023754076\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 103, train_loss = 5.335844298824668, train_acc = 0.9897531439217513\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 104, train_loss = 5.274910865351558, train_acc = 0.9897531439217513\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 105, train_loss = 5.214974424801767, train_acc = 0.9899860270144387\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 106, train_loss = 5.156158560886979, train_acc = 0.9899860270144387\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 107, train_loss = 5.098392459563911, train_acc = 0.9899860270144387\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 108, train_loss = 5.0416237860918045, train_acc = 0.9901024685607824\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 109, train_loss = 4.985883018933237, train_acc = 0.9902189101071263\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 110, train_loss = 4.9312570141628385, train_acc = 0.9904517931998137\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 111, train_loss = 4.877462134696543, train_acc = 0.9905682347461574\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 112, train_loss = 4.824634499847889, train_acc = 0.9910340009315324\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 113, train_loss = 4.772877748124301, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 114, train_loss = 4.722030466422439, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 115, train_loss = 4.67205907125026, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 116, train_loss = 4.622997882775962, train_acc = 0.9916162086632511\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 117, train_loss = 4.574811710044742, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 118, train_loss = 4.527427335269749, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 119, train_loss = 4.4809682900086045, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 120, train_loss = 4.435239707119763, train_acc = 0.9916162086632511\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 121, train_loss = 4.390395677648485, train_acc = 0.9918490917559385\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 122, train_loss = 4.346190688200295, train_acc = 0.9919655333022822\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 123, train_loss = 4.30283628590405, train_acc = 0.9919655333022822\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 124, train_loss = 4.260075627826154, train_acc = 0.9919655333022822\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 125, train_loss = 4.217948716133833, train_acc = 0.992081974848626\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 126, train_loss = 4.176552361808717, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 127, train_loss = 4.135940218344331, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 128, train_loss = 4.09597406629473, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 129, train_loss = 4.056760144419968, train_acc = 0.9928970656730322\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 130, train_loss = 4.01814650837332, train_acc = 0.9931299487657196\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 131, train_loss = 3.98012897092849, train_acc = 0.9931299487657196\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 132, train_loss = 3.9427143670618534, train_acc = 0.9932463903120633\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 133, train_loss = 3.9060103483498096, train_acc = 0.9932463903120633\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 134, train_loss = 3.869805228896439, train_acc = 0.9934792734047508\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 135, train_loss = 3.834272005595267, train_acc = 0.9934792734047508\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 136, train_loss = 3.7992171617224813, train_acc = 0.9935957149510946\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 137, train_loss = 3.7648579673841596, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 138, train_loss = 3.7309560468420386, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 139, train_loss = 3.6975882006809115, train_acc = 0.9939450395901258\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 140, train_loss = 3.6647082855924964, train_acc = 0.9939450395901258\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 141, train_loss = 3.6323659559711814, train_acc = 0.9939450395901258\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 142, train_loss = 3.6004971535876393, train_acc = 0.9939450395901258\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 143, train_loss = 3.5691975094377995, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 144, train_loss = 3.538333734497428, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 145, train_loss = 3.5081189032644033, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 146, train_loss = 3.4780837264843285, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 147, train_loss = 3.4487177352420986, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 148, train_loss = 3.4197689234279096, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 149, train_loss = 3.3912059762515128, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 150, train_loss = 3.3630023156292737, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 151, train_loss = 3.3353701545856893, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 152, train_loss = 3.308034013956785, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 153, train_loss = 3.2811456196941435, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 154, train_loss = 3.254657735582441, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 155, train_loss = 3.2285014898516238, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 156, train_loss = 3.2027505324222147, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 157, train_loss = 3.177319900598377, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 158, train_loss = 3.1522839167155325, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 159, train_loss = 3.127619524952024, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 160, train_loss = 3.103321810718626, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 161, train_loss = 3.0793529376387596, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 162, train_loss = 3.055765025317669, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 163, train_loss = 3.0323811671696603, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 164, train_loss = 3.009459288790822, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 165, train_loss = 2.986694472376257, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 166, train_loss = 2.9643729510717094, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 167, train_loss = 2.942395767197013, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 168, train_loss = 2.9204867421649396, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 169, train_loss = 2.898786002304405, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 170, train_loss = 2.8774938411079347, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 171, train_loss = 2.856438873335719, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 172, train_loss = 2.8357515134848654, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 173, train_loss = 2.8152405992150307, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 174, train_loss = 2.7949787243269384, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 175, train_loss = 2.775075350422412, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 176, train_loss = 2.755332603584975, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "19th- epoch: 177, train_loss = 2.7358911666087806, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 178, train_loss = 2.7167784865014255, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 179, train_loss = 2.6977802361361682, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 180, train_loss = 2.679054651875049, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 181, train_loss = 2.6604641708545387, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 182, train_loss = 2.6422387305647135, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 183, train_loss = 2.624062297400087, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 184, train_loss = 2.6062611346133053, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 185, train_loss = 2.5885875462554395, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 186, train_loss = 2.5710699879564345, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 187, train_loss = 2.5538328271359205, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 188, train_loss = 2.5368397259153426, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 189, train_loss = 2.5200273885857314, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 190, train_loss = 2.5033954698592424, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 191, train_loss = 2.486999387620017, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 192, train_loss = 2.4707411986310035, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "19th- epoch: 193, train_loss = 2.454731381731108, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 194, train_loss = 2.4389319408219308, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 195, train_loss = 2.4231707707513124, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 196, train_loss = 2.4077520668506622, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 197, train_loss = 2.392480254173279, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 198, train_loss = 2.377315226243809, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 199, train_loss = 2.362396406708285, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 200, train_loss = 2.3476977106183767, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 201, train_loss = 2.33302260376513, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 202, train_loss = 2.3186962194740772, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 203, train_loss = 2.304492850555107, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 204, train_loss = 2.290408455533907, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 205, train_loss = 2.276565673528239, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 206, train_loss = 2.262735392898321, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 207, train_loss = 2.2491931810509413, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 208, train_loss = 2.2358445413410664, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 209, train_loss = 2.222537362249568, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 210, train_loss = 2.209526975871995, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 211, train_loss = 2.1966098230332136, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 212, train_loss = 2.183782175881788, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 213, train_loss = 2.171204547630623, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 214, train_loss = 2.158730427501723, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 215, train_loss = 2.1465036913286895, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 216, train_loss = 2.1342485297936946, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 217, train_loss = 2.122345815645531, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 218, train_loss = 2.11053529381752, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 219, train_loss = 2.0988506730645895, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 220, train_loss = 2.087306098314002, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 221, train_loss = 2.0759910841006786, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 222, train_loss = 2.0647381755989045, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 223, train_loss = 2.0537147086579353, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 224, train_loss = 2.042770219966769, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 225, train_loss = 2.032002092571929, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 226, train_loss = 2.02134884824045, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 227, train_loss = 2.010843842057511, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 228, train_loss = 2.000457877991721, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 229, train_loss = 1.9902031931560487, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 230, train_loss = 1.9801758129615337, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 231, train_loss = 1.9701551247853786, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 232, train_loss = 1.9603295896667987, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 233, train_loss = 1.9506150458473712, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 234, train_loss = 1.941025062231347, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 235, train_loss = 1.9316037136595696, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 236, train_loss = 1.9222302127163857, train_acc = 0.9966231951560317\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 237, train_loss = 1.9130664232652634, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 238, train_loss = 1.9039531301241368, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 239, train_loss = 1.894955822499469, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 240, train_loss = 1.8860751874744892, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 241, train_loss = 1.8773744516074657, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 242, train_loss = 1.8687320463359356, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 243, train_loss = 1.8601285070180893, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 244, train_loss = 1.8517521606991068, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 245, train_loss = 1.8434071280062199, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 246, train_loss = 1.8352497617015615, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 247, train_loss = 1.8270546533167362, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 248, train_loss = 1.8190602721879259, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 249, train_loss = 1.811123369843699, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "19th- epoch: 250, train_loss = 1.8032474418869242, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 251, train_loss = 1.7955901237437502, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 252, train_loss = 1.7879076823592186, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "19th- epoch: 253, train_loss = 1.7803577954182401, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 254, train_loss = 1.7729085522005334, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 255, train_loss = 1.76552839204669, train_acc = 0.9974382859804378\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 256, train_loss = 1.7581984674325213, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 257, train_loss = 1.7510263869771734, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 258, train_loss = 1.7438464276492596, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 259, train_loss = 1.7368212590226904, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 260, train_loss = 1.7297921366989613, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 261, train_loss = 1.7229387933621183, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 262, train_loss = 1.7161071226000786, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 263, train_loss = 1.7093581991503015, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 264, train_loss = 1.702694067149423, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 265, train_loss = 1.6961144655942917, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 266, train_loss = 1.6895595988025889, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 267, train_loss = 1.6831298967590556, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 268, train_loss = 1.6767265970120206, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 269, train_loss = 1.6704273782670498, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 270, train_loss = 1.6641471484908834, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 271, train_loss = 1.6579318282892928, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 272, train_loss = 1.6517785949399695, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 273, train_loss = 1.6456710770726204, train_acc = 0.9975547275267815\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 274, train_loss = 1.6396613605320454, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "19th- epoch: 275, train_loss = 1.6337002801010385, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 276, train_loss = 1.627796849817969, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 277, train_loss = 1.6220309361815453, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 278, train_loss = 1.616202941746451, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 279, train_loss = 1.6105348294368014, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 280, train_loss = 1.604854137985967, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 281, train_loss = 1.599347174167633, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 282, train_loss = 1.593794139684178, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 283, train_loss = 1.588289904058911, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 284, train_loss = 1.582929597585462, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 285, train_loss = 1.5775808257749304, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 286, train_loss = 1.572280696243979, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 287, train_loss = 1.5669976150384173, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 288, train_loss = 1.5617916658520699, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 289, train_loss = 1.556702577858232, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 290, train_loss = 1.5515652522444725, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 291, train_loss = 1.5465423725545406, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 292, train_loss = 1.5415592081844807, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 293, train_loss = 1.5365796933183447, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 294, train_loss = 1.53164117410779, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 295, train_loss = 1.5267367424676195, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 296, train_loss = 1.5219034403562546, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 297, train_loss = 1.5171020639827475, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 298, train_loss = 1.512335384846665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 299, train_loss = 1.5076928125927225, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 300, train_loss = 1.5030270455172285, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 301, train_loss = 1.4983886802801862, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 302, train_loss = 1.4938331370940432, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 303, train_loss = 1.4892810905585065, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 304, train_loss = 1.484843872487545, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 305, train_loss = 1.4803711213171482, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 306, train_loss = 1.4759054830064997, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 307, train_loss = 1.471557774930261, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 308, train_loss = 1.467184046865441, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 309, train_loss = 1.462892665178515, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 310, train_loss = 1.4586605107178912, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 311, train_loss = 1.454389809339773, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 312, train_loss = 1.4502310305833817, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 313, train_loss = 1.4460149630904198, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 314, train_loss = 1.441941525787115, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 315, train_loss = 1.4378576439921744, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 316, train_loss = 1.4337852137978189, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 317, train_loss = 1.4298151768743992, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 318, train_loss = 1.4257734740967862, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 319, train_loss = 1.4218747094273567, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 320, train_loss = 1.4179471817915328, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 321, train_loss = 1.414144229143858, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 322, train_loss = 1.4102183704380877, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 323, train_loss = 1.4064386251266114, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 324, train_loss = 1.4027457535266876, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 325, train_loss = 1.3988988275523297, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 326, train_loss = 1.3951775133609772, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 327, train_loss = 1.3915522508323193, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 328, train_loss = 1.387867096811533, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 329, train_loss = 1.3842036314308643, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 330, train_loss = 1.3806306545739062, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 331, train_loss = 1.377056036144495, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 332, train_loss = 1.373485165357124, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 333, train_loss = 1.370000449300278, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 334, train_loss = 1.3665554585750215, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 335, train_loss = 1.3630461804568768, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 336, train_loss = 1.359596089750994, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 337, train_loss = 1.356216603249777, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 338, train_loss = 1.352842693508137, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 339, train_loss = 1.3494515630300157, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 340, train_loss = 1.3462168549303897, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 341, train_loss = 1.3428478564019315, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 342, train_loss = 1.3395398643915541, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 343, train_loss = 1.336370060860645, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 344, train_loss = 1.3331109347636811, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 345, train_loss = 1.3298977936501615, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 346, train_loss = 1.3267054110765457, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 347, train_loss = 1.3236183735425584, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "19th- epoch: 348, train_loss = 1.3204245058004744, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 349, train_loss = 1.3173426911234856, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 350, train_loss = 1.3142615680699237, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 351, train_loss = 1.3111150252516381, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 352, train_loss = 1.3081482512061484, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 353, train_loss = 1.3051028437912464, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 354, train_loss = 1.302146676927805, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 355, train_loss = 1.2991647173766978, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 356, train_loss = 1.2961705786292441, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 357, train_loss = 1.29320564243244, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 358, train_loss = 1.2903452875907533, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 359, train_loss = 1.2874445778434165, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 360, train_loss = 1.2845247114892118, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 361, train_loss = 1.2817036298220046, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 362, train_loss = 1.2788740073447116, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 363, train_loss = 1.27602493140148, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 364, train_loss = 1.2732620376045816, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 365, train_loss = 1.2704731027479284, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 366, train_loss = 1.2677112631499767, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 367, train_loss = 1.2650267680292018, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 368, train_loss = 1.2622600495815277, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19th- epoch: 369, train_loss = 1.259552060335409, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 370, train_loss = 1.256872424215544, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 371, train_loss = 1.2542653692071326, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 372, train_loss = 1.2515189337427728, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 373, train_loss = 1.2489798764581792, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 374, train_loss = 1.2462840415537357, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 375, train_loss = 1.2437871371512301, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 376, train_loss = 1.2411626229877584, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 377, train_loss = 1.238596998155117, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 378, train_loss = 1.2361004054546356, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 379, train_loss = 1.233543676615227, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 380, train_loss = 1.231069150089752, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 381, train_loss = 1.2285823225975037, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 382, train_loss = 1.226143145293463, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 383, train_loss = 1.2235946742002852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 384, train_loss = 1.2211891897022724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 385, train_loss = 1.2188144189422019, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 386, train_loss = 1.2163688726723194, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 387, train_loss = 1.2139691871707328, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 388, train_loss = 1.2115520524675958, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 389, train_loss = 1.2092477840487845, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 390, train_loss = 1.2068722422118299, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 391, train_loss = 1.204492801160086, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 392, train_loss = 1.202270646870602, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 393, train_loss = 1.1999263216857798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 394, train_loss = 1.1975819853250869, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 395, train_loss = 1.1954289488494396, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 396, train_loss = 1.1931049190461636, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 397, train_loss = 1.1908255417947657, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 398, train_loss = 1.1886030596797355, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 399, train_loss = 1.1864106108841952, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 400, train_loss = 1.184238145739073, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 401, train_loss = 1.1820181483926717, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 402, train_loss = 1.1798287853598595, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 403, train_loss = 1.1777206622064114, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 404, train_loss = 1.1755216345191002, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 405, train_loss = 1.1734208775160369, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 406, train_loss = 1.1712803890404757, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 407, train_loss = 1.1691261691448744, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 408, train_loss = 1.1671261799929198, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 409, train_loss = 1.164979721099371, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 410, train_loss = 1.1629146026971284, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 411, train_loss = 1.160852557659382, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 412, train_loss = 1.1587498150765896, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 413, train_loss = 1.1566931431589182, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 414, train_loss = 1.1547293340263423, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 415, train_loss = 1.152731616050005, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 416, train_loss = 1.1507946538331453, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 417, train_loss = 1.1487635970115662, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 418, train_loss = 1.1467908447084483, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 419, train_loss = 1.1448604626057204, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 420, train_loss = 1.1429199402628, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 421, train_loss = 1.1408848191204015, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 422, train_loss = 1.1390758814814035, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 423, train_loss = 1.137138375401264, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 424, train_loss = 1.1351896611449774, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 425, train_loss = 1.13333004587912, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 426, train_loss = 1.131448416650528, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 427, train_loss = 1.129547347634798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 428, train_loss = 1.1276708779332694, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 429, train_loss = 1.1258776560425758, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 430, train_loss = 1.1240775063633919, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 431, train_loss = 1.1221966730954591, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 432, train_loss = 1.120419437676901, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 433, train_loss = 1.1185922287404537, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 434, train_loss = 1.1167972298862878, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 435, train_loss = 1.1150007359683514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 436, train_loss = 1.113218987971777, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 437, train_loss = 1.1114852018654346, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 438, train_loss = 1.1097181290388107, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 439, train_loss = 1.1080006497504655, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 440, train_loss = 1.1062010961177293, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 441, train_loss = 1.1045493744313717, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 442, train_loss = 1.1027567734417971, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 443, train_loss = 1.100986892968649, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 444, train_loss = 1.0994056425988674, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 445, train_loss = 1.0976432040333748, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 446, train_loss = 1.0960306835768279, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 447, train_loss = 1.094334858149523, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 448, train_loss = 1.0927086124720518, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 449, train_loss = 1.0910230750741903, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 450, train_loss = 1.0894082536397036, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 451, train_loss = 1.0877547847630922, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 452, train_loss = 1.0861290320754051, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 453, train_loss = 1.0844969513418619, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 454, train_loss = 1.0829120799899101, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 455, train_loss = 1.0812874039111193, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 456, train_loss = 1.0797020407917444, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 457, train_loss = 1.078101513296133, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 458, train_loss = 1.0764986798167229, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 459, train_loss = 1.0749328136444092, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 460, train_loss = 1.0734321797790471, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 461, train_loss = 1.0718735381960869, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 462, train_loss = 1.0703317461011466, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 463, train_loss = 1.06875029951334, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 464, train_loss = 1.0673143764433917, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 465, train_loss = 1.0657157016394194, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 466, train_loss = 1.064184170216322, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 467, train_loss = 1.062749986856943, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 468, train_loss = 1.0612532459199429, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 469, train_loss = 1.0596899700758513, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 470, train_loss = 1.058316479116911, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 471, train_loss = 1.056777191668516, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 472, train_loss = 1.0553934065101203, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 473, train_loss = 1.0538692933914717, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 474, train_loss = 1.0524031383392867, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 475, train_loss = 1.0509493611752987, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 476, train_loss = 1.0495644820330199, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 477, train_loss = 1.048118925333256, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 478, train_loss = 1.0467302836477757, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 479, train_loss = 1.0453100204467773, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 480, train_loss = 1.043915989488596, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 481, train_loss = 1.0425285933015402, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 482, train_loss = 1.0411855280399323, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 483, train_loss = 1.0397288141248282, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 484, train_loss = 1.0383679630758706, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 485, train_loss = 1.037036901951069, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 486, train_loss = 1.0355830043554306, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 487, train_loss = 1.0343249092402402, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 488, train_loss = 1.032913832605118, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 489, train_loss = 1.0315657047030982, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 490, train_loss = 1.030245898902649, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 491, train_loss = 1.0289370380342007, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 492, train_loss = 1.0274786154332105, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 493, train_loss = 1.0262169490160886, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 494, train_loss = 1.0249635639193002, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 495, train_loss = 1.023668381065363, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 496, train_loss = 1.022367494791979, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 497, train_loss = 1.021029739320511, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 498, train_loss = 1.0196928928198759, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "19th- epoch: 499, train_loss = 1.018387384712696, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|████████████████████████████████████████████▎                         | 19/30 [2:09:38<1:15:13, 410.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "20th- epoch: 0, train_loss = 270.27475142478943, train_acc = 0.4892873777363763\n",
      "test Acc 0.5633147113594041:\n",
      "20th- epoch: 1, train_loss = 203.0959175825119, train_acc = 0.5657894736842105\n",
      "test Acc 0.5740223463687151:\n",
      "20th- epoch: 2, train_loss = 159.28140026330948, train_acc = 0.5861667442943642\n",
      "test Acc 0.616852886405959:\n",
      "20th- epoch: 3, train_loss = 135.09762161970139, train_acc = 0.6510246856078249\n",
      "test Acc 0.6955307262569832:\n",
      "20th- epoch: 4, train_loss = 117.26522988080978, train_acc = 0.7265952491849091\n",
      "test Acc 0.7490689013035382:\n",
      "20th- epoch: 5, train_loss = 102.47579577565193, train_acc = 0.7682813227759665\n",
      "test Acc 0.7807262569832403:\n",
      "20th- epoch: 6, train_loss = 90.06419131159782, train_acc = 0.787843502561714\n",
      "test Acc 0.797486033519553:\n",
      "20th- epoch: 7, train_loss = 79.79424777626991, train_acc = 0.8060083837913368\n",
      "test Acc 0.8119180633147114:\n",
      "20th- epoch: 8, train_loss = 71.12469512224197, train_acc = 0.8320912901723335\n",
      "test Acc 0.8375232774674115:\n",
      "20th- epoch: 9, train_loss = 63.64137914776802, train_acc = 0.8593386120167675\n",
      "test Acc 0.8729050279329609:\n",
      "20th- epoch: 10, train_loss = 57.17314901947975, train_acc = 0.8901956217978575\n",
      "test Acc 0.8994413407821229:\n",
      "20th- epoch: 11, train_loss = 51.623870983719826, train_acc = 0.9078947368421053\n",
      "test Acc 0.9134078212290503:\n",
      "20th- epoch: 12, train_loss = 46.87711824476719, train_acc = 0.9239636702375408\n",
      "test Acc 0.9292364990689013:\n",
      "20th- epoch: 13, train_loss = 42.80323587357998, train_acc = 0.9340940847694458\n",
      "test Acc 0.9352886405959032:\n",
      "20th- epoch: 14, train_loss = 39.29450140893459, train_acc = 0.9388681881695389\n",
      "test Acc 0.9380819366852886:\n",
      "20th- epoch: 15, train_loss = 36.26502712816, train_acc = 0.9410805775500699\n",
      "test Acc 0.9399441340782123:\n",
      "20th- epoch: 16, train_loss = 33.6425930634141, train_acc = 0.9425943176525384\n",
      "test Acc 0.9436685288640596:\n",
      "20th- epoch: 17, train_loss = 31.36977357417345, train_acc = 0.9452724732184443\n",
      "test Acc 0.9492551210428305:\n",
      "20th- epoch: 18, train_loss = 29.391194626688957, train_acc = 0.950279459711225\n",
      "test Acc 0.952048417132216:\n",
      "20th- epoch: 19, train_loss = 27.663330294191837, train_acc = 0.952491849091756\n",
      "test Acc 0.9548417132216015:\n",
      "20th- epoch: 20, train_loss = 26.144321493804455, train_acc = 0.9543549138332557\n",
      "test Acc 0.9562383612662942:\n",
      "20th- epoch: 21, train_loss = 24.79720611870289, train_acc = 0.956450861667443\n",
      "test Acc 0.9562383612662942:\n",
      "20th- epoch: 22, train_loss = 23.59875813126564, train_acc = 0.9576152771308803\n",
      "test Acc 0.957169459962756:\n",
      "20th- epoch: 23, train_loss = 22.52724326401949, train_acc = 0.9591290172333489\n",
      "test Acc 0.9581005586592178:\n",
      "20th- epoch: 24, train_loss = 21.56339691951871, train_acc = 0.9607591988821611\n",
      "test Acc 0.9585661080074488:\n",
      "20th- epoch: 25, train_loss = 20.695000678300858, train_acc = 0.9619236143455985\n",
      "test Acc 0.9585661080074488:\n",
      "20th- epoch: 26, train_loss = 19.90869627147913, train_acc = 0.9634373544480671\n",
      "test Acc 0.9594972067039106:\n",
      "20th- epoch: 27, train_loss = 19.1908226236701, train_acc = 0.9643688868188169\n",
      "test Acc 0.9594972067039106:\n",
      "20th- epoch: 28, train_loss = 18.531300902366638, train_acc = 0.9649510945505356\n",
      "test Acc 0.9594972067039106:\n",
      "20th- epoch: 29, train_loss = 17.921673618257046, train_acc = 0.9662319515603167\n",
      "test Acc 0.9590316573556797:\n",
      "20th- epoch: 30, train_loss = 17.35692584887147, train_acc = 0.9669306008383791\n",
      "test Acc 0.9590316573556797:\n",
      "20th- epoch: 31, train_loss = 16.831226214766502, train_acc = 0.9675128085700978\n",
      "test Acc 0.9594972067039106:\n",
      "20th- epoch: 32, train_loss = 16.340408984571695, train_acc = 0.9686772240335352\n",
      "test Acc 0.9613594040968343:\n",
      "20th- epoch: 33, train_loss = 15.880846068263054, train_acc = 0.97007452258966\n",
      "test Acc 0.962756052141527:\n",
      "20th- epoch: 34, train_loss = 15.449783984571695, train_acc = 0.9707731718677224\n",
      "test Acc 0.9636871508379888:\n",
      "20th- epoch: 35, train_loss = 15.044533547013998, train_acc = 0.9714718211457848\n",
      "test Acc 0.9655493482309124:\n",
      "20th- epoch: 36, train_loss = 14.66274868696928, train_acc = 0.9719375873311598\n",
      "test Acc 0.9669459962756052:\n",
      "20th- epoch: 37, train_loss = 14.302220106124878, train_acc = 0.9727526781555659\n",
      "test Acc 0.9674115456238361:\n",
      "20th- epoch: 38, train_loss = 13.960819113999605, train_acc = 0.9733348858872846\n",
      "test Acc 0.9678770949720671:\n",
      "20th- epoch: 39, train_loss = 13.636846359819174, train_acc = 0.974033535165347\n",
      "test Acc 0.9683426443202979:\n",
      "20th- epoch: 40, train_loss = 13.328989326953888, train_acc = 0.9746157428970657\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 41, train_loss = 13.035997942090034, train_acc = 0.9751979506287843\n",
      "test Acc 0.9697392923649907:\n",
      "20th- epoch: 42, train_loss = 12.75681970641017, train_acc = 0.976245924545878\n",
      "test Acc 0.9702048417132216:\n",
      "20th- epoch: 43, train_loss = 12.490095138549805, train_acc = 0.9771774569166278\n",
      "test Acc 0.9706703910614525:\n",
      "20th- epoch: 44, train_loss = 12.235031671822071, train_acc = 0.9778761061946902\n",
      "test Acc 0.9716014897579144:\n",
      "20th- epoch: 45, train_loss = 11.990757077932358, train_acc = 0.9784583139264089\n",
      "test Acc 0.9720670391061452:\n",
      "20th- epoch: 46, train_loss = 11.756266888231039, train_acc = 0.9788076385654402\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 47, train_loss = 11.530996948480606, train_acc = 0.9793898462971589\n",
      "test Acc 0.972998137802607:\n",
      "20th- epoch: 48, train_loss = 11.314242921769619, train_acc = 0.9799720540288775\n",
      "test Acc 0.9725325884543762:\n",
      "20th- epoch: 49, train_loss = 11.105373837053776, train_acc = 0.9800884955752213\n",
      "test Acc 0.9739292364990689:\n",
      "20th- epoch: 50, train_loss = 10.904005147516727, train_acc = 0.9803213786679087\n",
      "test Acc 0.9743947858472998:\n",
      "20th- epoch: 51, train_loss = 10.709428325295448, train_acc = 0.9804378202142524\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 52, train_loss = 10.521380288526416, train_acc = 0.9805542617605962\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 53, train_loss = 10.339495945721865, train_acc = 0.9811364694923148\n",
      "test Acc 0.9748603351955307:\n",
      "20th- epoch: 54, train_loss = 10.163248365744948, train_acc = 0.9811364694923148\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 55, train_loss = 9.99249104782939, train_acc = 0.9814857941313461\n",
      "test Acc 0.9757914338919925:\n",
      "20th- epoch: 56, train_loss = 9.827389374375343, train_acc = 0.9817186772240335\n",
      "test Acc 0.9762569832402235:\n",
      "20th- epoch: 57, train_loss = 9.667230430990458, train_acc = 0.9820680018630648\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 58, train_loss = 9.511688170954585, train_acc = 0.9824173265020959\n",
      "test Acc 0.9767225325884544:\n",
      "20th- epoch: 59, train_loss = 9.360650654882193, train_acc = 0.9826502095947834\n",
      "test Acc 0.9771880819366853:\n",
      "20th- epoch: 60, train_loss = 9.213695585727692, train_acc = 0.9829995342338146\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 61, train_loss = 9.07057641632855, train_acc = 0.9829995342338146\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 62, train_loss = 8.931253107264638, train_acc = 0.9829995342338146\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 63, train_loss = 8.795462898910046, train_acc = 0.9833488588728458\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 64, train_loss = 8.662955597043037, train_acc = 0.9835817419655333\n",
      "test Acc 0.9781191806331471:\n",
      "20th- epoch: 65, train_loss = 8.533753490075469, train_acc = 0.983698183511877\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 66, train_loss = 8.407414387911558, train_acc = 0.9839310666045645\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 67, train_loss = 8.283838219940662, train_acc = 0.9842803912435957\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 68, train_loss = 8.163375459611416, train_acc = 0.9843968327899395\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 69, train_loss = 8.045781560242176, train_acc = 0.9845132743362832\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 70, train_loss = 7.9309097323566675, train_acc = 0.9846297158826269\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 71, train_loss = 7.81859090924263, train_acc = 0.9847461574289706\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 72, train_loss = 7.708726970478892, train_acc = 0.9847461574289706\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 73, train_loss = 7.601252926513553, train_acc = 0.9847461574289706\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 74, train_loss = 7.4959547072649, train_acc = 0.9847461574289706\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 75, train_loss = 7.39240900054574, train_acc = 0.9849790405216581\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 76, train_loss = 7.291535917669535, train_acc = 0.9849790405216581\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 77, train_loss = 7.192964123561978, train_acc = 0.9852119236143456\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 78, train_loss = 7.09675008058548, train_acc = 0.985444806707033\n",
      "test Acc 0.978584729981378:\n",
      "20th- epoch: 79, train_loss = 7.002427808940411, train_acc = 0.9857941313460643\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 80, train_loss = 6.910219624638557, train_acc = 0.985910572892408\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 81, train_loss = 6.819809924811125, train_acc = 0.9861434559850955\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 82, train_loss = 6.731343695893884, train_acc = 0.9862598975314392\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 83, train_loss = 6.644696597009897, train_acc = 0.9866092221704704\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 84, train_loss = 6.559839569032192, train_acc = 0.9867256637168141\n",
      "test Acc 0.979050279329609:\n",
      "20th- epoch: 85, train_loss = 6.476594382897019, train_acc = 0.9869585468095017\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 86, train_loss = 6.395111709833145, train_acc = 0.9873078714485328\n",
      "test Acc 0.9799813780260708:\n",
      "20th- epoch: 87, train_loss = 6.315318949520588, train_acc = 0.9874243129948765\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 88, train_loss = 6.2370208241045475, train_acc = 0.9875407545412203\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 89, train_loss = 6.160293683409691, train_acc = 0.9877736376339078\n",
      "test Acc 0.9804469273743017:\n",
      "20th- epoch: 90, train_loss = 6.084995646029711, train_acc = 0.9882394038192828\n",
      "test Acc 0.9818435754189944:\n",
      "20th- epoch: 91, train_loss = 6.011294344440103, train_acc = 0.9882394038192828\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 92, train_loss = 5.938983773812652, train_acc = 0.9884722869119702\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 93, train_loss = 5.867982983589172, train_acc = 0.9885887284583139\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 94, train_loss = 5.79847064986825, train_acc = 0.9885887284583139\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 95, train_loss = 5.730147434398532, train_acc = 0.9888216115510013\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 96, train_loss = 5.663223254494369, train_acc = 0.9890544946436889\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 97, train_loss = 5.597540679387748, train_acc = 0.9892873777363763\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 98, train_loss = 5.532958670519292, train_acc = 0.98940381928272\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 99, train_loss = 5.469705427996814, train_acc = 0.9895202608290639\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 100, train_loss = 5.407567055895925, train_acc = 0.989869585468095\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 101, train_loss = 5.346545333974063, train_acc = 0.9902189101071263\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 102, train_loss = 5.286559697240591, train_acc = 0.9902189101071263\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 103, train_loss = 5.227755363099277, train_acc = 0.99033535165347\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 104, train_loss = 5.169934160076082, train_acc = 0.99033535165347\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 105, train_loss = 5.112999759614468, train_acc = 0.99033535165347\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 106, train_loss = 5.057170024141669, train_acc = 0.9904517931998137\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 107, train_loss = 5.002347911708057, train_acc = 0.9905682347461574\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 108, train_loss = 4.948384274728596, train_acc = 0.9906846762925011\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 109, train_loss = 4.895324406214058, train_acc = 0.9906846762925011\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 110, train_loss = 4.843174995854497, train_acc = 0.9906846762925011\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 111, train_loss = 4.7918629962950945, train_acc = 0.9911504424778761\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 112, train_loss = 4.741391592659056, train_acc = 0.9911504424778761\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 113, train_loss = 4.691886610351503, train_acc = 0.9912668840242198\n",
      "test Acc 0.9823091247672253:\n",
      "20th- epoch: 114, train_loss = 4.643226587213576, train_acc = 0.9912668840242198\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 115, train_loss = 4.595420992933214, train_acc = 0.9911504424778761\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 116, train_loss = 4.548266259022057, train_acc = 0.9913833255705635\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 117, train_loss = 4.502005933783948, train_acc = 0.9917326502095948\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 118, train_loss = 4.456479481421411, train_acc = 0.9918490917559385\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 119, train_loss = 4.411647266708314, train_acc = 0.9919655333022822\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 120, train_loss = 4.367616142146289, train_acc = 0.992081974848626\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 121, train_loss = 4.324053906835616, train_acc = 0.9923148579413135\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 122, train_loss = 4.281409487128258, train_acc = 0.9924312994876572\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 123, train_loss = 4.2393078450113535, train_acc = 0.9924312994876572\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 124, train_loss = 4.19798828382045, train_acc = 0.9925477410340009\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 125, train_loss = 4.15729409083724, train_acc = 0.9925477410340009\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 126, train_loss = 4.117162965238094, train_acc = 0.9926641825803446\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 127, train_loss = 4.07764267642051, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 128, train_loss = 4.038850853219628, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 129, train_loss = 4.0006534503772855, train_acc = 0.9927806241266884\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 130, train_loss = 3.9628434563055634, train_acc = 0.9928970656730322\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 131, train_loss = 3.9258844209834933, train_acc = 0.9928970656730322\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 132, train_loss = 3.889242828823626, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 133, train_loss = 3.8532722759991884, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 134, train_loss = 3.817817180417478, train_acc = 0.9930135072193759\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 135, train_loss = 3.7829421469941735, train_acc = 0.9931299487657196\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 136, train_loss = 3.7485789135098457, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 137, train_loss = 3.7147464747540653, train_acc = 0.9933628318584071\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 138, train_loss = 3.6813590987585485, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 139, train_loss = 3.648503070231527, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 140, train_loss = 3.6161980419419706, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 141, train_loss = 3.5842875875532627, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 142, train_loss = 3.552918130066246, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 143, train_loss = 3.521967280190438, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 144, train_loss = 3.491484594065696, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 145, train_loss = 3.461394665297121, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 146, train_loss = 3.4317431203089654, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 147, train_loss = 3.402649315074086, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 148, train_loss = 3.373784175608307, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 149, train_loss = 3.345531241968274, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 150, train_loss = 3.3175107445567846, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 151, train_loss = 3.290019253268838, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 152, train_loss = 3.2627408639527857, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 153, train_loss = 3.236065551638603, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 154, train_loss = 3.209586486686021, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 155, train_loss = 3.1835638280026615, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 156, train_loss = 3.157881472725421, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 157, train_loss = 3.1324872318655252, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "20th- epoch: 158, train_loss = 3.107512004673481, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 159, train_loss = 3.0828371909447014, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 160, train_loss = 3.058577365707606, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 161, train_loss = 3.034682819619775, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 162, train_loss = 3.011128348764032, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 163, train_loss = 2.98782481206581, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 164, train_loss = 2.964960724581033, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 165, train_loss = 2.9422988980077207, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 166, train_loss = 2.9200994395650923, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 167, train_loss = 2.898076979443431, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 168, train_loss = 2.8763302084989846, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 169, train_loss = 2.855006888974458, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 170, train_loss = 2.833919908851385, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 171, train_loss = 2.8130541499704123, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 172, train_loss = 2.792562985792756, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 173, train_loss = 2.7722284593619406, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 174, train_loss = 2.752177947666496, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 175, train_loss = 2.732463509310037, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 176, train_loss = 2.712960206437856, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 177, train_loss = 2.693737569730729, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 178, train_loss = 2.6747821955941617, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 179, train_loss = 2.656042801681906, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 180, train_loss = 2.637579672038555, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 181, train_loss = 2.6193798719905317, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 182, train_loss = 2.6014019928406924, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 183, train_loss = 2.583713885396719, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 184, train_loss = 2.5662284679710865, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 185, train_loss = 2.548995417309925, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 186, train_loss = 2.5319614198524505, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 187, train_loss = 2.5151675574015826, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 188, train_loss = 2.4985558316111565, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 189, train_loss = 2.4822381522972137, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 190, train_loss = 2.4661064490210265, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 191, train_loss = 2.4501331739593297, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 192, train_loss = 2.4344044029712677, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 193, train_loss = 2.4189275938551873, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 194, train_loss = 2.403573674382642, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 195, train_loss = 2.3884434525389224, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 196, train_loss = 2.3735435232520103, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 197, train_loss = 2.3588711719494313, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 198, train_loss = 2.344296080293134, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 199, train_loss = 2.329950065119192, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 200, train_loss = 2.3158334388863295, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 201, train_loss = 2.3017939284909517, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 202, train_loss = 2.288100241916254, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 203, train_loss = 2.274507539346814, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 204, train_loss = 2.261056062532589, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 205, train_loss = 2.2478325709234923, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 206, train_loss = 2.2347263519186527, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 207, train_loss = 2.221871789544821, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 208, train_loss = 2.2091240372974426, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 209, train_loss = 2.196542190387845, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 210, train_loss = 2.1841841631103307, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 211, train_loss = 2.1719125125091523, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 212, train_loss = 2.159829198149964, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 213, train_loss = 2.1478790640830994, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 214, train_loss = 2.13604645174928, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 215, train_loss = 2.1244296717923135, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 216, train_loss = 2.112930629402399, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 217, train_loss = 2.1015619572717696, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 218, train_loss = 2.090337209403515, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 219, train_loss = 2.0792050424497575, train_acc = 0.996506753609688\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 220, train_loss = 2.0683379892725497, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 221, train_loss = 2.0576344169676304, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 222, train_loss = 2.0469728994648904, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 223, train_loss = 2.036558219464496, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 224, train_loss = 2.0262224934995174, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 225, train_loss = 2.0159915573894978, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 226, train_loss = 2.0058747914154083, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 227, train_loss = 1.9959115248639137, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 228, train_loss = 1.9860796928405762, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 229, train_loss = 1.9763203784823418, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 230, train_loss = 1.9667926344554871, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 231, train_loss = 1.9572728660423309, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 232, train_loss = 1.947901987703517, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 233, train_loss = 1.938656973419711, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 234, train_loss = 1.929492586525157, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 235, train_loss = 1.9204131017904729, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 236, train_loss = 1.9115281600970775, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 237, train_loss = 1.902742127655074, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 238, train_loss = 1.893951192498207, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 239, train_loss = 1.8853432709584013, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 240, train_loss = 1.876805609674193, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "20th- epoch: 241, train_loss = 1.8684260124573484, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 242, train_loss = 1.8600980950286612, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 243, train_loss = 1.8518783313920721, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 244, train_loss = 1.8437511896481737, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 245, train_loss = 1.8357525939354673, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 246, train_loss = 1.827787198126316, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 247, train_loss = 1.8199214115738869, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 248, train_loss = 1.8121839190134779, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 249, train_loss = 1.804488193243742, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 250, train_loss = 1.7968810833990574, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 251, train_loss = 1.78939987719059, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 252, train_loss = 1.7818886177847162, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 253, train_loss = 1.7746058130869642, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 254, train_loss = 1.7673469620058313, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 255, train_loss = 1.7601574709406123, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 256, train_loss = 1.7530161874601617, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 257, train_loss = 1.7459941083798185, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 258, train_loss = 1.7390385357430205, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 259, train_loss = 1.7321656035492197, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 260, train_loss = 1.7253514528274536, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 261, train_loss = 1.7185471119591966, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 262, train_loss = 1.7119302401551977, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 263, train_loss = 1.705277202068828, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 264, train_loss = 1.6987649450311437, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 265, train_loss = 1.692270454019308, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 266, train_loss = 1.6858804324874654, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 267, train_loss = 1.679562626988627, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 268, train_loss = 1.6732244193553925, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 269, train_loss = 1.6670214595505968, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 270, train_loss = 1.6608834142098203, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 271, train_loss = 1.6547711379826069, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 272, train_loss = 1.6487832739949226, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 273, train_loss = 1.6427763402462006, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 274, train_loss = 1.6368793522706255, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 275, train_loss = 1.6310702102491632, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 276, train_loss = 1.6252389214932919, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 277, train_loss = 1.6194775911280885, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "20th- epoch: 278, train_loss = 1.6138406371464953, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 279, train_loss = 1.608227507560514, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 280, train_loss = 1.6026385301956907, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 281, train_loss = 1.597138237208128, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 282, train_loss = 1.5917077524354681, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 283, train_loss = 1.5862589118769392, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 284, train_loss = 1.5809041373431683, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 285, train_loss = 1.5756186047801748, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 286, train_loss = 1.5703784301877022, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 287, train_loss = 1.5651528189191595, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 288, train_loss = 1.5600069463253021, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 289, train_loss = 1.5549491494894028, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 290, train_loss = 1.5498375644674525, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 291, train_loss = 1.5448344548931345, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 292, train_loss = 1.5398884961614385, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 293, train_loss = 1.5349622605135664, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 294, train_loss = 1.5300971096148714, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 295, train_loss = 1.5252779560396448, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 296, train_loss = 1.5204646798083559, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 297, train_loss = 1.5157506950199604, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 298, train_loss = 1.5110214203596115, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 299, train_loss = 1.5063807852566242, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 300, train_loss = 1.5017778215697035, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 301, train_loss = 1.4971565566956997, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 302, train_loss = 1.4926675545284525, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 303, train_loss = 1.4881709391484037, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 304, train_loss = 1.4837043521692976, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 305, train_loss = 1.4792897378792986, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 306, train_loss = 1.4749091727426276, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 307, train_loss = 1.4705948481569067, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 308, train_loss = 1.4663188023259863, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 309, train_loss = 1.4620726717403159, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 310, train_loss = 1.4578015729784966, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 311, train_loss = 1.4536322616040707, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 312, train_loss = 1.449478141963482, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 313, train_loss = 1.4453416180913337, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 314, train_loss = 1.4412642394308932, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 315, train_loss = 1.4372516932780854, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 316, train_loss = 1.4332389421761036, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 317, train_loss = 1.4292445282335393, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "20th- epoch: 318, train_loss = 1.4252764632110484, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 319, train_loss = 1.4214029498398304, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 320, train_loss = 1.4175140162114985, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 321, train_loss = 1.4136760706896894, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 322, train_loss = 1.4098520402912982, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 323, train_loss = 1.4060951198334806, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 324, train_loss = 1.4023186340928078, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 325, train_loss = 1.3985550490324385, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 326, train_loss = 1.3949175092275254, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 327, train_loss = 1.391241505742073, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 328, train_loss = 1.3875870344345458, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 329, train_loss = 1.3839991055428982, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 330, train_loss = 1.3803997958893888, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 331, train_loss = 1.3768319301307201, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 332, train_loss = 1.3733550670440309, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 333, train_loss = 1.369818092614878, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 334, train_loss = 1.3663976329262368, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 335, train_loss = 1.3628983895177953, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 336, train_loss = 1.359504610300064, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 337, train_loss = 1.3561441488564014, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 338, train_loss = 1.352773915976286, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 339, train_loss = 1.349415245174896, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 340, train_loss = 1.3461412998731248, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 341, train_loss = 1.3428254313766956, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 342, train_loss = 1.3395589962601662, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 343, train_loss = 1.336330123245716, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 344, train_loss = 1.3331081842188723, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 345, train_loss = 1.3299582029576413, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 346, train_loss = 1.3267444881494157, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 347, train_loss = 1.323635543405544, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 348, train_loss = 1.3205186079139821, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 349, train_loss = 1.3174239198560826, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 350, train_loss = 1.3143355858628638, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 351, train_loss = 1.311292051046621, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 352, train_loss = 1.308286922692787, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 353, train_loss = 1.305269644886721, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 354, train_loss = 1.3022888849372976, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 355, train_loss = 1.2993574241991155, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 356, train_loss = 1.2964004737441428, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "20th- epoch: 357, train_loss = 1.2934809885919094, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 358, train_loss = 1.2905684386496432, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 359, train_loss = 1.2876844592392445, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 360, train_loss = 1.2848397195339203, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 361, train_loss = 1.282005765766371, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 362, train_loss = 1.2792009462718852, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 363, train_loss = 1.2763779548113234, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 364, train_loss = 1.2736164082889445, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 365, train_loss = 1.2708658489282243, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 366, train_loss = 1.2681107185781002, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 367, train_loss = 1.2654354919795878, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 368, train_loss = 1.262699370563496, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 369, train_loss = 1.2600349324638955, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 370, train_loss = 1.2574054573778994, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 371, train_loss = 1.2547602206468582, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 372, train_loss = 1.2521342200343497, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 373, train_loss = 1.249500334262848, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 374, train_loss = 1.2469618320465088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 375, train_loss = 1.2443736543064006, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 376, train_loss = 1.241847101598978, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 377, train_loss = 1.2392758813803084, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 378, train_loss = 1.236769288778305, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 379, train_loss = 1.2342742358450778, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 380, train_loss = 1.2317735205288045, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 381, train_loss = 1.2293027962441556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 382, train_loss = 1.2268932300503366, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 383, train_loss = 1.2244191232020967, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 384, train_loss = 1.2220170572400093, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 385, train_loss = 1.2195987937157042, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 386, train_loss = 1.2171929876203649, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 387, train_loss = 1.2148687380249612, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 388, train_loss = 1.2124660921399482, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 389, train_loss = 1.210151568055153, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 390, train_loss = 1.2078031326527707, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 391, train_loss = 1.205467987805605, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 392, train_loss = 1.2031874532694928, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 393, train_loss = 1.2008649197523482, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 394, train_loss = 1.1986123199458234, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 395, train_loss = 1.1963232842390426, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 396, train_loss = 1.194108211726416, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 397, train_loss = 1.191882748156786, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 398, train_loss = 1.189669833809603, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 399, train_loss = 1.1874945499002934, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 400, train_loss = 1.1853011424536817, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 401, train_loss = 1.1831257157027721, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 402, train_loss = 1.1809524396958295, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 403, train_loss = 1.1788576481339987, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 404, train_loss = 1.1766793454589788, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 405, train_loss = 1.1746184515359346, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 406, train_loss = 1.172472527861828, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 407, train_loss = 1.1703944665787276, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 408, train_loss = 1.16833652681089, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 409, train_loss = 1.166249681264162, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 410, train_loss = 1.1641963198781013, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 411, train_loss = 1.162168768554693, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 412, train_loss = 1.160135194659233, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 413, train_loss = 1.1581174445746, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 414, train_loss = 1.1561139760015067, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 415, train_loss = 1.1541422419250011, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 416, train_loss = 1.1521454155445099, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 417, train_loss = 1.150169795990223, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 418, train_loss = 1.1482613869011402, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 419, train_loss = 1.1462800974550191, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 420, train_loss = 1.1443724085984286, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 421, train_loss = 1.142412687331671, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 422, train_loss = 1.140519885957474, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 423, train_loss = 1.1386257944104727, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 424, train_loss = 1.1367262490093708, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 425, train_loss = 1.13486241424107, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 426, train_loss = 1.1329806484282017, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 427, train_loss = 1.1311376405355986, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 428, train_loss = 1.1292935336532537, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 429, train_loss = 1.1274139136075974, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 430, train_loss = 1.125598855316639, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 431, train_loss = 1.1237648626265582, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 432, train_loss = 1.1219426219759043, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 433, train_loss = 1.1202060170471668, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 434, train_loss = 1.118392941862112, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 435, train_loss = 1.1166227012872696, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 436, train_loss = 1.114866023272043, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 437, train_loss = 1.113103640585905, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 438, train_loss = 1.111342016607523, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 439, train_loss = 1.1096169116499368, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 440, train_loss = 1.1078852750360966, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 441, train_loss = 1.1062146673502866, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 442, train_loss = 1.104469640791649, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20th- epoch: 443, train_loss = 1.102786804229254, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 444, train_loss = 1.1010917810199317, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 445, train_loss = 1.0994170010089874, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 446, train_loss = 1.097815285116667, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 447, train_loss = 1.0960903701779898, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 448, train_loss = 1.0944588085112628, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 449, train_loss = 1.0928429576160852, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 450, train_loss = 1.0911601558327675, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 451, train_loss = 1.08956585204578, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 452, train_loss = 1.0879838392138481, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 453, train_loss = 1.0863754177989904, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 454, train_loss = 1.0847892761230469, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 455, train_loss = 1.083162502705818, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 456, train_loss = 1.0815902054309845, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 457, train_loss = 1.080059247702593, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 458, train_loss = 1.0784631955029909, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 459, train_loss = 1.0769051983952522, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 460, train_loss = 1.0753687346877996, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 461, train_loss = 1.0738411831262056, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 462, train_loss = 1.072316459059948, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 463, train_loss = 1.0707545156183187, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 464, train_loss = 1.0692488675413188, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 465, train_loss = 1.067790421337122, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 466, train_loss = 1.0662485994398594, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 467, train_loss = 1.0647898154857103, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 468, train_loss = 1.0633225962519646, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 469, train_loss = 1.0618311613798141, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 470, train_loss = 1.0603294509055559, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 471, train_loss = 1.0589118860661983, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 472, train_loss = 1.0573931063117925, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 473, train_loss = 1.0560120828449726, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 474, train_loss = 1.0545490384101868, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 475, train_loss = 1.0531401882471982, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 476, train_loss = 1.051699262112379, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 477, train_loss = 1.0503030444087926, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 478, train_loss = 1.0489138402044773, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 479, train_loss = 1.0474702144565526, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 480, train_loss = 1.0461018420755863, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 481, train_loss = 1.0446892008185387, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 482, train_loss = 1.0432951326074544, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 483, train_loss = 1.0419416812655982, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 484, train_loss = 1.0405944660305977, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 485, train_loss = 1.0391927709279116, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 486, train_loss = 1.0378249809145927, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 487, train_loss = 1.0364995412528515, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 488, train_loss = 1.0351538136601448, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 489, train_loss = 1.0338483105006162, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 490, train_loss = 1.032490335404873, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 491, train_loss = 1.0311389242706355, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 492, train_loss = 1.0298611968755722, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 493, train_loss = 1.028572147100931, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 494, train_loss = 1.027218472212553, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 495, train_loss = 1.025942680746084, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 496, train_loss = 1.0246415162982885, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 497, train_loss = 1.0233743389544543, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 498, train_loss = 1.0220662169158459, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n",
      "20th- epoch: 499, train_loss = 1.0207883181574289, train_acc = 0.9980204937121565\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████████████████████████████████████████████▋                       | 20/30 [2:16:27<1:08:20, 410.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "21th- epoch: 0, train_loss = 268.40147030353546, train_acc = 0.43060083837913365\n",
      "test Acc 0.5381750465549349:\n",
      "21th- epoch: 1, train_loss = 203.9830733537674, train_acc = 0.5263157894736842\n",
      "test Acc 0.5665735567970205:\n",
      "21th- epoch: 2, train_loss = 161.06809878349304, train_acc = 0.5813926408942711\n",
      "test Acc 0.6187150837988827:\n",
      "21th- epoch: 3, train_loss = 137.13796430826187, train_acc = 0.6563809967396367\n",
      "test Acc 0.7062383612662942:\n",
      "21th- epoch: 4, train_loss = 119.72791588306427, train_acc = 0.7298556124825337\n",
      "test Acc 0.7532588454376163:\n",
      "21th- epoch: 5, train_loss = 104.94414669275284, train_acc = 0.7600139729855613\n",
      "test Acc 0.7723463687150838:\n",
      "21th- epoch: 6, train_loss = 92.01444655656815, train_acc = 0.7707265952491849\n",
      "test Acc 0.7821229050279329:\n",
      "21th- epoch: 7, train_loss = 81.12564301490784, train_acc = 0.7990218910107126\n",
      "test Acc 0.813780260707635:\n",
      "21th- epoch: 8, train_loss = 71.97598108649254, train_acc = 0.8333721471821146\n",
      "test Acc 0.8435754189944135:\n",
      "21th- epoch: 9, train_loss = 64.1000891327858, train_acc = 0.8672566371681416\n",
      "test Acc 0.883147113594041:\n",
      "21th- epoch: 10, train_loss = 57.25276494026184, train_acc = 0.8942710759198882\n",
      "test Acc 0.9031657355679702:\n",
      "21th- epoch: 11, train_loss = 51.36088307201862, train_acc = 0.9110386585933862\n",
      "test Acc 0.9180633147113594:\n",
      "21th- epoch: 12, train_loss = 46.33988805115223, train_acc = 0.9243129948765719\n",
      "test Acc 0.9320297951582868:\n",
      "21th- epoch: 13, train_loss = 42.091740638017654, train_acc = 0.9333954354913834\n",
      "test Acc 0.9352886405959032:\n",
      "21th- epoch: 14, train_loss = 38.50765822827816, train_acc = 0.9377037727061015\n",
      "test Acc 0.9376163873370578:\n",
      "21th- epoch: 15, train_loss = 35.480411276221275, train_acc = 0.9404983698183512\n",
      "test Acc 0.9413407821229051:\n",
      "21th- epoch: 16, train_loss = 32.916287429630756, train_acc = 0.945388914764788\n",
      "test Acc 0.9436685288640596:\n",
      "21th- epoch: 17, train_loss = 30.732582807540894, train_acc = 0.9479506287843502\n",
      "test Acc 0.9483240223463687:\n",
      "21th- epoch: 18, train_loss = 28.860729172825813, train_acc = 0.9501630181648812\n",
      "test Acc 0.9511173184357542:\n",
      "21th- epoch: 19, train_loss = 27.243711702525616, train_acc = 0.9516767582673498\n",
      "test Acc 0.952513966480447:\n",
      "21th- epoch: 20, train_loss = 25.83615829795599, train_acc = 0.9537727061015371\n",
      "test Acc 0.9553072625698324:\n",
      "21th- epoch: 21, train_loss = 24.59964868426323, train_acc = 0.955519329296693\n",
      "test Acc 0.9557728119180633:\n",
      "21th- epoch: 22, train_loss = 23.503220934420824, train_acc = 0.9568001863064741\n",
      "test Acc 0.9562383612662942:\n",
      "21th- epoch: 23, train_loss = 22.521731551736593, train_acc = 0.9585468095016302\n",
      "test Acc 0.9562383612662942:\n",
      "21th- epoch: 24, train_loss = 21.637573163956404, train_acc = 0.9602934326967862\n",
      "test Acc 0.9562383612662942:\n",
      "21th- epoch: 25, train_loss = 20.836318664252758, train_acc = 0.9614578481602236\n",
      "test Acc 0.957169459962756:\n",
      "21th- epoch: 26, train_loss = 20.105441726744175, train_acc = 0.9619236143455985\n",
      "test Acc 0.957635009310987:\n",
      "21th- epoch: 27, train_loss = 19.434079222381115, train_acc = 0.9626222636236609\n",
      "test Acc 0.9604283054003724:\n",
      "21th- epoch: 28, train_loss = 18.81270630657673, train_acc = 0.9633209129017233\n",
      "test Acc 0.9608938547486033:\n",
      "21th- epoch: 29, train_loss = 18.23519330471754, train_acc = 0.9641360037261295\n",
      "test Acc 0.9613594040968343:\n",
      "21th- epoch: 30, train_loss = 17.696947522461414, train_acc = 0.9653004191895669\n",
      "test Acc 0.9618249534450651:\n",
      "21th- epoch: 31, train_loss = 17.193109832704067, train_acc = 0.9657661853749417\n",
      "test Acc 0.9622905027932961:\n",
      "21th- epoch: 32, train_loss = 16.719652272760868, train_acc = 0.9672799254774104\n",
      "test Acc 0.9632216014897579:\n",
      "21th- epoch: 33, train_loss = 16.273893527686596, train_acc = 0.9685607824871915\n",
      "test Acc 0.9636871508379888:\n",
      "21th- epoch: 34, train_loss = 15.85279106721282, train_acc = 0.9689101071262226\n",
      "test Acc 0.9660148975791434:\n",
      "21th- epoch: 35, train_loss = 15.453545838594437, train_acc = 0.9701909641360037\n",
      "test Acc 0.9664804469273743:\n",
      "21th- epoch: 36, train_loss = 15.074531152844429, train_acc = 0.9713553795994411\n",
      "test Acc 0.9688081936685289:\n",
      "21th- epoch: 37, train_loss = 14.713993955403566, train_acc = 0.9726362366092222\n",
      "test Acc 0.9706703910614525:\n",
      "21th- epoch: 38, train_loss = 14.370597820729017, train_acc = 0.9735677689799721\n",
      "test Acc 0.9716014897579144:\n",
      "21th- epoch: 39, train_loss = 14.04347538203001, train_acc = 0.9743828598043782\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 40, train_loss = 13.73098848760128, train_acc = 0.9749650675360969\n",
      "test Acc 0.973463687150838:\n",
      "21th- epoch: 41, train_loss = 13.432137873023748, train_acc = 0.9756637168141593\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 42, train_loss = 13.145592708140612, train_acc = 0.9760130414531905\n",
      "test Acc 0.9743947858472998:\n",
      "21th- epoch: 43, train_loss = 12.871133465319872, train_acc = 0.9768281322775967\n",
      "test Acc 0.9748603351955307:\n",
      "21th- epoch: 44, train_loss = 12.608135655522346, train_acc = 0.9772938984629715\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 45, train_loss = 12.355529896914959, train_acc = 0.9775267815556591\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 46, train_loss = 12.11248917132616, train_acc = 0.977992547741034\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 47, train_loss = 11.878429289907217, train_acc = 0.9783418723800652\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 48, train_loss = 11.653462216258049, train_acc = 0.9790405216581276\n",
      "test Acc 0.9753258845437617:\n",
      "21th- epoch: 49, train_loss = 11.437028788030148, train_acc = 0.9796227293898463\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 50, train_loss = 11.228551935404539, train_acc = 0.980204937121565\n",
      "test Acc 0.9757914338919925:\n",
      "21th- epoch: 51, train_loss = 11.027866823598742, train_acc = 0.9811364694923148\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 52, train_loss = 10.834302987903357, train_acc = 0.9817186772240335\n",
      "test Acc 0.9762569832402235:\n",
      "21th- epoch: 53, train_loss = 10.64729167893529, train_acc = 0.981951560316721\n",
      "test Acc 0.9767225325884544:\n",
      "21th- epoch: 54, train_loss = 10.466417154297233, train_acc = 0.9821844434094085\n",
      "test Acc 0.9771880819366853:\n",
      "21th- epoch: 55, train_loss = 10.291353208944201, train_acc = 0.9824173265020959\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 56, train_loss = 10.121937658637762, train_acc = 0.9824173265020959\n",
      "test Acc 0.9776536312849162:\n",
      "21th- epoch: 57, train_loss = 9.957528134807944, train_acc = 0.9826502095947834\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 58, train_loss = 9.797954551875591, train_acc = 0.9827666511411272\n",
      "test Acc 0.9781191806331471:\n",
      "21th- epoch: 59, train_loss = 9.64313292875886, train_acc = 0.9827666511411272\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 60, train_loss = 9.492831079289317, train_acc = 0.9831159757801584\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 61, train_loss = 9.347077570855618, train_acc = 0.9832324173265021\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 62, train_loss = 9.205424040555954, train_acc = 0.9833488588728458\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 63, train_loss = 9.067645315080881, train_acc = 0.9833488588728458\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 64, train_loss = 8.933561282232404, train_acc = 0.9833488588728458\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 65, train_loss = 8.802973007783294, train_acc = 0.9835817419655333\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 66, train_loss = 8.675680382177234, train_acc = 0.9835817419655333\n",
      "test Acc 0.978584729981378:\n",
      "21th- epoch: 67, train_loss = 8.551542097702622, train_acc = 0.9835817419655333\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 68, train_loss = 8.430398236960173, train_acc = 0.9839310666045645\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 69, train_loss = 8.312267301604152, train_acc = 0.9840475081509082\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 70, train_loss = 8.196773897856474, train_acc = 0.984163949697252\n",
      "test Acc 0.979050279329609:\n",
      "21th- epoch: 71, train_loss = 8.0838628616184, train_acc = 0.984163949697252\n",
      "test Acc 0.9795158286778398:\n",
      "21th- epoch: 72, train_loss = 7.973474089056253, train_acc = 0.9843968327899395\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 73, train_loss = 7.865569565445185, train_acc = 0.9846297158826269\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 74, train_loss = 7.75976824760437, train_acc = 0.9847461574289706\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 75, train_loss = 7.656144138425589, train_acc = 0.9849790405216581\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 76, train_loss = 7.554764838889241, train_acc = 0.9852119236143456\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 77, train_loss = 7.4553034491837025, train_acc = 0.9855612482533768\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 78, train_loss = 7.35776736587286, train_acc = 0.9856776897997206\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 79, train_loss = 7.261981515213847, train_acc = 0.985910572892408\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 80, train_loss = 7.168049272149801, train_acc = 0.9860270144387517\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 81, train_loss = 7.075893200933933, train_acc = 0.986376339077783\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 82, train_loss = 6.985566785559058, train_acc = 0.9864927806241267\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 83, train_loss = 6.896757626906037, train_acc = 0.9867256637168141\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 84, train_loss = 6.809526527300477, train_acc = 0.9868421052631579\n",
      "test Acc 0.9799813780260708:\n",
      "21th- epoch: 85, train_loss = 6.7240403983742, train_acc = 0.9868421052631579\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 86, train_loss = 6.640138551592827, train_acc = 0.9870749883558454\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 87, train_loss = 6.557773876935244, train_acc = 0.9871914299021891\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 88, train_loss = 6.476799830794334, train_acc = 0.9871914299021891\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 89, train_loss = 6.397168541327119, train_acc = 0.9873078714485328\n",
      "test Acc 0.9804469273743017:\n",
      "21th- epoch: 90, train_loss = 6.318859785795212, train_acc = 0.9874243129948765\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 91, train_loss = 6.2419953141361475, train_acc = 0.9875407545412203\n",
      "test Acc 0.9818435754189944:\n",
      "21th- epoch: 92, train_loss = 6.166502231732011, train_acc = 0.9877736376339078\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 93, train_loss = 6.092325046658516, train_acc = 0.9876571960875641\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 94, train_loss = 6.019428012892604, train_acc = 0.9877736376339078\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 95, train_loss = 5.947860702872276, train_acc = 0.9882394038192828\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 96, train_loss = 5.877705160528421, train_acc = 0.9884722869119702\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 97, train_loss = 5.808578019961715, train_acc = 0.9887051700046576\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 98, train_loss = 5.740646636113524, train_acc = 0.9888216115510013\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 99, train_loss = 5.673869216814637, train_acc = 0.9889380530973452\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 100, train_loss = 5.608182279393077, train_acc = 0.9891709361900326\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 101, train_loss = 5.543619181960821, train_acc = 0.98940381928272\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 102, train_loss = 5.480098711326718, train_acc = 0.9896367023754076\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 103, train_loss = 5.417777796275914, train_acc = 0.989869585468095\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 104, train_loss = 5.356481303460896, train_acc = 0.989869585468095\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 105, train_loss = 5.296289858408272, train_acc = 0.989869585468095\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 106, train_loss = 5.237127999775112, train_acc = 0.9899860270144387\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 107, train_loss = 5.178951996378601, train_acc = 0.9899860270144387\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 108, train_loss = 5.121745147742331, train_acc = 0.9901024685607824\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 109, train_loss = 5.065621281974018, train_acc = 0.9902189101071263\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 110, train_loss = 5.010279957205057, train_acc = 0.99033535165347\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 111, train_loss = 4.955947780050337, train_acc = 0.99033535165347\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 112, train_loss = 4.902564827352762, train_acc = 0.99033535165347\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 113, train_loss = 4.85003939922899, train_acc = 0.9904517931998137\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 114, train_loss = 4.798238257877529, train_acc = 0.9909175593851887\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 115, train_loss = 4.747369240038097, train_acc = 0.990801117838845\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 116, train_loss = 4.69737312477082, train_acc = 0.9909175593851887\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 117, train_loss = 4.648184143006802, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 118, train_loss = 4.599803921766579, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 119, train_loss = 4.552194059826434, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 120, train_loss = 4.505380223505199, train_acc = 0.9916162086632511\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 121, train_loss = 4.459221024997532, train_acc = 0.9914997671169073\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 122, train_loss = 4.413958854041994, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 123, train_loss = 4.369398882612586, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 124, train_loss = 4.325581518001854, train_acc = 0.992081974848626\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 125, train_loss = 4.282437948510051, train_acc = 0.9921984163949698\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 126, train_loss = 4.239987633191049, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 127, train_loss = 4.198132903315127, train_acc = 0.9924312994876572\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 128, train_loss = 4.156970298849046, train_acc = 0.9924312994876572\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 129, train_loss = 4.116522783413529, train_acc = 0.9924312994876572\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 130, train_loss = 4.076533997431397, train_acc = 0.9925477410340009\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 131, train_loss = 4.037280037067831, train_acc = 0.9925477410340009\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 132, train_loss = 3.9986629532650113, train_acc = 0.9925477410340009\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 133, train_loss = 3.9605650631710887, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 134, train_loss = 3.9230960765853524, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 135, train_loss = 3.8861609054729342, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 136, train_loss = 3.849747368134558, train_acc = 0.9930135072193759\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 137, train_loss = 3.813973152078688, train_acc = 0.9930135072193759\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 138, train_loss = 3.778681489638984, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 139, train_loss = 3.744008186273277, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 140, train_loss = 3.709801785647869, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 141, train_loss = 3.676219128537923, train_acc = 0.9935957149510946\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 142, train_loss = 3.6430601202882826, train_acc = 0.9937121564974383\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 143, train_loss = 3.610431320499629, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 144, train_loss = 3.5783345266245306, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 145, train_loss = 3.5466467537917197, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 146, train_loss = 3.5154321920126677, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 147, train_loss = 3.484704030677676, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 148, train_loss = 3.4542684871703386, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 149, train_loss = 3.4243899839930236, train_acc = 0.9939450395901258\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 150, train_loss = 3.3949398645199835, train_acc = 0.9940614811364695\n",
      "test Acc 0.9823091247672253:\n",
      "21th- epoch: 151, train_loss = 3.3658101414330304, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 152, train_loss = 3.337107453495264, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 153, train_loss = 3.308808790985495, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 154, train_loss = 3.280946997459978, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 155, train_loss = 3.253535582218319, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 156, train_loss = 3.2264318373054266, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 157, train_loss = 3.1999185918830335, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 158, train_loss = 3.173671475145966, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 159, train_loss = 3.147888259962201, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 160, train_loss = 3.1223125872202218, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 161, train_loss = 3.097265508491546, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 162, train_loss = 3.0724219288676977, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 163, train_loss = 3.048096001148224, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 164, train_loss = 3.023948858026415, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 165, train_loss = 3.000275204423815, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 166, train_loss = 2.9768654671497643, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 167, train_loss = 2.9538138643838465, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 168, train_loss = 2.931135938037187, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 169, train_loss = 2.9087178744375706, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 170, train_loss = 2.88657797453925, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 171, train_loss = 2.8648350001312792, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 172, train_loss = 2.843346429988742, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 173, train_loss = 2.822069235611707, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 174, train_loss = 2.8011938803829253, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 175, train_loss = 2.7804942037910223, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 176, train_loss = 2.760095992591232, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "21th- epoch: 177, train_loss = 2.74007712258026, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 178, train_loss = 2.720200765877962, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 179, train_loss = 2.7006840887479484, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 180, train_loss = 2.6814246303401887, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 181, train_loss = 2.6623945641331375, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 182, train_loss = 2.6435878281481564, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 183, train_loss = 2.6250408813357353, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 184, train_loss = 2.6067337535787374, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 185, train_loss = 2.588660031557083, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 186, train_loss = 2.5708721950650215, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 187, train_loss = 2.5532235130667686, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 188, train_loss = 2.5359144154936075, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 189, train_loss = 2.5187756463419646, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 190, train_loss = 2.501871280372143, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 191, train_loss = 2.4851930122822523, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 192, train_loss = 2.4687906845938414, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 193, train_loss = 2.452509469585493, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 194, train_loss = 2.4365310966968536, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 195, train_loss = 2.4206938117276877, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 196, train_loss = 2.4049956500530243, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 197, train_loss = 2.3895019460469484, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 198, train_loss = 2.3741865314077586, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 199, train_loss = 2.3591341346036643, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 200, train_loss = 2.3442435041069984, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 201, train_loss = 2.3295312989503145, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 202, train_loss = 2.315143220825121, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 203, train_loss = 2.300729190930724, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 204, train_loss = 2.28673403034918, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 205, train_loss = 2.2727411177475005, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 206, train_loss = 2.2590262156445533, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 207, train_loss = 2.2455177034717053, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 208, train_loss = 2.2320690844208, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 209, train_loss = 2.218908225419, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 210, train_loss = 2.2059198815841228, train_acc = 0.9963903120633442\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 211, train_loss = 2.1930095746647567, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 212, train_loss = 2.1804050642531365, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 213, train_loss = 2.1678495600353926, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 214, train_loss = 2.155563184292987, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 215, train_loss = 2.143370070727542, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 216, train_loss = 2.131378473713994, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 217, train_loss = 2.119496313855052, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 218, train_loss = 2.107841790886596, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 219, train_loss = 2.096292482689023, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 220, train_loss = 2.084921446396038, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 221, train_loss = 2.07358894799836, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 222, train_loss = 2.0625525519717485, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 223, train_loss = 2.0515916869044304, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 224, train_loss = 2.0407890614587814, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 225, train_loss = 2.0300672240555286, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 226, train_loss = 2.0196585319936275, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 227, train_loss = 2.0091560166329145, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 228, train_loss = 1.9989515685010701, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 229, train_loss = 1.9888542145490646, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 230, train_loss = 1.9787283644545823, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 231, train_loss = 1.9688944034278393, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "21th- epoch: 232, train_loss = 1.9590878952294588, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 233, train_loss = 1.9495206971187145, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 234, train_loss = 1.9399237085599452, train_acc = 0.9968560782487191\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 235, train_loss = 1.9305494260042906, train_acc = 0.9969725197950629\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 236, train_loss = 1.9212661584606394, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 237, train_loss = 1.912084532319568, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 238, train_loss = 1.9031054017832503, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 239, train_loss = 1.8941197842359543, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 240, train_loss = 1.8853514728834853, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 241, train_loss = 1.8765837164828554, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 242, train_loss = 1.868003105162643, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 243, train_loss = 1.859425370930694, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 244, train_loss = 1.8510304242372513, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 245, train_loss = 1.8426784947514534, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 246, train_loss = 1.834481880068779, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 247, train_loss = 1.8263479185989127, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 248, train_loss = 1.818424983532168, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 249, train_loss = 1.8103703757515177, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 250, train_loss = 1.8025460243225098, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 251, train_loss = 1.7948706509778276, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 252, train_loss = 1.7871882555773482, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 253, train_loss = 1.7796023786067963, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 254, train_loss = 1.7721886025974527, train_acc = 0.9972054028877504\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 255, train_loss = 1.7648042341461405, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 256, train_loss = 1.757412489503622, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 257, train_loss = 1.7502706696977839, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 258, train_loss = 1.7431147433817387, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 259, train_loss = 1.7360539883375168, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 260, train_loss = 1.7290629632771015, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 261, train_loss = 1.7220840702066198, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 262, train_loss = 1.7152915969491005, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 263, train_loss = 1.7085155099630356, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 264, train_loss = 1.7017786303767934, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 265, train_loss = 1.6952421689638868, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 266, train_loss = 1.6886112615466118, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 267, train_loss = 1.6822183491894975, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 268, train_loss = 1.6757746636867523, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 269, train_loss = 1.6694262785604224, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 270, train_loss = 1.663132535875775, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 271, train_loss = 1.6569247109582648, train_acc = 0.9974382859804378\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 272, train_loss = 1.6507519806036726, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 273, train_loss = 1.6447184011340141, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 274, train_loss = 1.6386838890612125, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 275, train_loss = 1.6327130446443334, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 276, train_loss = 1.6268731715390459, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 277, train_loss = 1.6209639459848404, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 278, train_loss = 1.6152409376809373, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 279, train_loss = 1.6095391238341108, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 280, train_loss = 1.6038450287887827, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 281, train_loss = 1.598208056180738, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 282, train_loss = 1.5926555506885052, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 283, train_loss = 1.5872321923961863, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 284, train_loss = 1.5817291276762262, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 285, train_loss = 1.5763146951794624, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 286, train_loss = 1.571006933809258, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 287, train_loss = 1.56571416312363, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 288, train_loss = 1.5604631440946832, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 289, train_loss = 1.5552523484220728, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 290, train_loss = 1.5501551987836137, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 291, train_loss = 1.5450339689850807, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 292, train_loss = 1.5400259917369112, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 293, train_loss = 1.5350167453289032, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 294, train_loss = 1.5300388796022162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21th- epoch: 295, train_loss = 1.525124415755272, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 296, train_loss = 1.5203035349259153, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 297, train_loss = 1.515510323108174, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 298, train_loss = 1.5106605142354965, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 299, train_loss = 1.5059786600177176, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 300, train_loss = 1.501266063482035, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 301, train_loss = 1.4966334104537964, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 302, train_loss = 1.4920649330015294, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 303, train_loss = 1.4874565973877907, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 304, train_loss = 1.4829810075461864, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 305, train_loss = 1.4785049160127528, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 306, train_loss = 1.4740017540752888, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 307, train_loss = 1.469682036607992, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 308, train_loss = 1.4652765157516114, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 309, train_loss = 1.4610289583797567, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 310, train_loss = 1.456681786745321, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 311, train_loss = 1.4524771136348136, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 312, train_loss = 1.4482327190344222, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 313, train_loss = 1.4440545651013963, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 314, train_loss = 1.4398982375860214, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 315, train_loss = 1.4358476040069945, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 316, train_loss = 1.4317017942667007, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 317, train_loss = 1.4277582466602325, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 318, train_loss = 1.4236555148963816, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 319, train_loss = 1.41979457315756, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 320, train_loss = 1.4158459168975241, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 321, train_loss = 1.4118690614704974, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 322, train_loss = 1.4080448895692825, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 323, train_loss = 1.404200294346083, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 324, train_loss = 1.4003725399379618, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 325, train_loss = 1.396628716320265, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 326, train_loss = 1.3928211492602713, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 327, train_loss = 1.38913645100547, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 328, train_loss = 1.3854484421317466, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 329, train_loss = 1.3817791678011417, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 330, train_loss = 1.3781145798857324, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 331, train_loss = 1.3745376777951606, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 332, train_loss = 1.3709186166524887, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 333, train_loss = 1.3674590500886552, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 334, train_loss = 1.3638673350214958, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 335, train_loss = 1.3604148142039776, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 336, train_loss = 1.3569074894185178, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 337, train_loss = 1.3535309545695782, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 338, train_loss = 1.3500868355040438, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 339, train_loss = 1.3466735457186587, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 340, train_loss = 1.3433363598887809, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 341, train_loss = 1.3399266476626508, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "21th- epoch: 342, train_loss = 1.3367066830396652, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 343, train_loss = 1.3333562674815767, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 344, train_loss = 1.3301413145964034, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 345, train_loss = 1.3268617068533786, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 346, train_loss = 1.323663157701958, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 347, train_loss = 1.3205276131629944, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 348, train_loss = 1.317333495884668, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 349, train_loss = 1.3142161307041533, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 350, train_loss = 1.3110542495851405, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 351, train_loss = 1.3079687394201756, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 352, train_loss = 1.3049151189625263, train_acc = 0.9976711690731253\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 353, train_loss = 1.3018661141395569, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 354, train_loss = 1.2988431751728058, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 355, train_loss = 1.2958365082740784, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 356, train_loss = 1.2928145602345467, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 357, train_loss = 1.2899115569889545, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 358, train_loss = 1.28705546510173, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 359, train_loss = 1.2840379141271114, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 360, train_loss = 1.2812583197955973, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 361, train_loss = 1.278296957432758, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 362, train_loss = 1.2754991675610654, train_acc = 0.9977876106194691\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 363, train_loss = 1.2726238630712032, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 364, train_loss = 1.2698461462859996, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 365, train_loss = 1.2670340376789682, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 366, train_loss = 1.2643655824358575, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 367, train_loss = 1.2615348237450235, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 368, train_loss = 1.25882512453245, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 369, train_loss = 1.2560744558577426, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 370, train_loss = 1.2533381668035872, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 371, train_loss = 1.2506980672478676, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 372, train_loss = 1.2479864346678369, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 373, train_loss = 1.2453530617058277, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 374, train_loss = 1.2427279961411841, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 375, train_loss = 1.2402099656756036, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 376, train_loss = 1.237567264586687, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 377, train_loss = 1.2350158455665223, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 378, train_loss = 1.2324453082983382, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 379, train_loss = 1.2299708488280885, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 380, train_loss = 1.227434626489412, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "21th- epoch: 381, train_loss = 1.2248815062339418, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 382, train_loss = 1.2225054813025054, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 383, train_loss = 1.219962908566231, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 384, train_loss = 1.2175633944571018, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 385, train_loss = 1.215119486063486, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 386, train_loss = 1.212691811233526, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 387, train_loss = 1.210333882510895, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 388, train_loss = 1.2078984715044498, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 389, train_loss = 1.2055101791920606, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 390, train_loss = 1.2031975574791431, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 391, train_loss = 1.2008393295109272, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 392, train_loss = 1.1985887649061624, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 393, train_loss = 1.1962920427322388, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 394, train_loss = 1.193953280657297, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 395, train_loss = 1.1916473247110844, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 396, train_loss = 1.18937980136252, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 397, train_loss = 1.1871727046964224, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 398, train_loss = 1.1849086470901966, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 399, train_loss = 1.1827368823287543, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 400, train_loss = 1.180499898880953, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 401, train_loss = 1.178309302777052, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 402, train_loss = 1.1760971335170325, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 403, train_loss = 1.1739893493650015, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 404, train_loss = 1.1718049185874406, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 405, train_loss = 1.1696515679359436, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 406, train_loss = 1.1675294811429922, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 407, train_loss = 1.1654310499725398, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 408, train_loss = 1.1633740738034248, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 409, train_loss = 1.1612307342293207, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 410, train_loss = 1.1591274328529835, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 411, train_loss = 1.1570974700152874, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 412, train_loss = 1.1550722954270896, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 413, train_loss = 1.1530122943222523, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 414, train_loss = 1.1510303454997484, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 415, train_loss = 1.1489931071700994, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 416, train_loss = 1.146999228745699, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 417, train_loss = 1.144994621485239, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 418, train_loss = 1.1430394724011421, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 419, train_loss = 1.141052066028351, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 420, train_loss = 1.1390939615666866, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 421, train_loss = 1.1371969766914845, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 422, train_loss = 1.1352246565220412, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 423, train_loss = 1.1333127009274904, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 424, train_loss = 1.131423187762266, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 425, train_loss = 1.1294946359994356, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 426, train_loss = 1.1276780503394548, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 427, train_loss = 1.1257611848413944, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 428, train_loss = 1.1239154202339705, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 429, train_loss = 1.1220265688898508, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 430, train_loss = 1.1202295733091887, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 431, train_loss = 1.118353253841633, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 432, train_loss = 1.1165562321839388, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 433, train_loss = 1.1147628960607108, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 434, train_loss = 1.112899533152813, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 435, train_loss = 1.1111380544898566, train_acc = 0.9979040521658128\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 436, train_loss = 1.1093515194952488, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 437, train_loss = 1.1075615175068378, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 438, train_loss = 1.1058091396989767, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 439, train_loss = 1.1041074134409428, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 440, train_loss = 1.1023296527564526, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 441, train_loss = 1.1006241751310881, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 442, train_loss = 1.0988324073550757, train_acc = 0.9980204937121565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 443, train_loss = 1.0971838024852332, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 444, train_loss = 1.0954554652271327, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 445, train_loss = 1.0937710516154766, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 446, train_loss = 1.0920681978168432, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 447, train_loss = 1.0904178284108639, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 448, train_loss = 1.0887097107770387, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 449, train_loss = 1.087110746651888, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 450, train_loss = 1.0853937081992626, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 451, train_loss = 1.0837925001978874, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 452, train_loss = 1.0821372705104295, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 453, train_loss = 1.080548378318781, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 454, train_loss = 1.0788956122996751, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 455, train_loss = 1.077326354890829, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 456, train_loss = 1.075707829237217, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 457, train_loss = 1.07413424924016, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 458, train_loss = 1.0725487247109413, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 459, train_loss = 1.070945673942333, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 460, train_loss = 1.069402697175974, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 461, train_loss = 1.0678096674382687, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 462, train_loss = 1.0663250597717706, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 463, train_loss = 1.064747213065857, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 464, train_loss = 1.0632577327487525, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 465, train_loss = 1.061685030668741, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 466, train_loss = 1.0601654946804047, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 467, train_loss = 1.0586796762945596, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 468, train_loss = 1.057172986358637, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 469, train_loss = 1.0556584745645523, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 470, train_loss = 1.0541877088544425, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 471, train_loss = 1.0526994032261427, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 472, train_loss = 1.051195040345192, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 473, train_loss = 1.0497417002916336, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 474, train_loss = 1.0483284704387188, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 475, train_loss = 1.0468717279436532, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 476, train_loss = 1.0453739712538663, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 477, train_loss = 1.0439859864709433, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 478, train_loss = 1.0425161061284598, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 479, train_loss = 1.0411311437783297, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 480, train_loss = 1.0397494522330817, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 481, train_loss = 1.0382795979676303, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 482, train_loss = 1.0369189853372518, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 483, train_loss = 1.0355230992136057, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 484, train_loss = 1.034143445402151, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 485, train_loss = 1.032751053571701, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 486, train_loss = 1.0313771503570024, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 487, train_loss = 1.0300104916095734, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 488, train_loss = 1.0286225328745786, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 489, train_loss = 1.027301767229801, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 490, train_loss = 1.0259596755204257, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 491, train_loss = 1.0245597275643377, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 492, train_loss = 1.0232638369052438, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 493, train_loss = 1.0219133396894904, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 494, train_loss = 1.0205893640668364, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 495, train_loss = 1.0192492964415578, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 496, train_loss = 1.0179315855057212, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 497, train_loss = 1.0165703321545152, train_acc = 0.9980204937121565\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 498, train_loss = 1.0152922670094995, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n",
      "21th- epoch: 499, train_loss = 1.0140522420406342, train_acc = 0.9981369352585002\n",
      "test Acc 0.9846368715083799:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████████████████████████████████████                     | 21/30 [2:23:23<1:01:44, 411.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "22th- epoch: 0, train_loss = 266.2071340084076, train_acc = 0.4786911970190964\n",
      "test Acc 0.5344506517690876:\n",
      "22th- epoch: 1, train_loss = 196.3677613735199, train_acc = 0.5416860735910572\n",
      "test Acc 0.5726256983240223:\n",
      "22th- epoch: 2, train_loss = 154.9409155845642, train_acc = 0.5831392640894271\n",
      "test Acc 0.6229050279329609:\n",
      "22th- epoch: 3, train_loss = 133.2326536178589, train_acc = 0.6803679552864462\n",
      "test Acc 0.7313780260707635:\n",
      "22th- epoch: 4, train_loss = 116.58330363035202, train_acc = 0.7428970656730322\n",
      "test Acc 0.7639664804469274:\n",
      "22th- epoch: 5, train_loss = 101.87781247496605, train_acc = 0.7775966464834653\n",
      "test Acc 0.7891061452513967:\n",
      "22th- epoch: 6, train_loss = 89.01768279075623, train_acc = 0.7976245924545878\n",
      "test Acc 0.8049348230912476:\n",
      "22th- epoch: 7, train_loss = 78.26393422484398, train_acc = 0.8108989287377736\n",
      "test Acc 0.8184357541899442:\n",
      "22th- epoch: 8, train_loss = 69.37415969371796, train_acc = 0.8338379133674895\n",
      "test Acc 0.8533519553072626:\n",
      "22th- epoch: 9, train_loss = 62.0259935259819, train_acc = 0.8672566371681416\n",
      "test Acc 0.8780260707635009:\n",
      "22th- epoch: 10, train_loss = 55.93086166679859, train_acc = 0.8887983232417327\n",
      "test Acc 0.8985102420856611:\n",
      "22th- epoch: 11, train_loss = 50.834271013736725, train_acc = 0.9053330228225431\n",
      "test Acc 0.9185288640595903:\n",
      "22th- epoch: 12, train_loss = 46.51038122177124, train_acc = 0.9201210992081975\n",
      "test Acc 0.9283054003724395:\n",
      "22th- epoch: 13, train_loss = 42.779256254434586, train_acc = 0.9290870982766651\n",
      "test Acc 0.9348230912476723:\n",
      "22th- epoch: 14, train_loss = 39.520338863134384, train_acc = 0.935724266418258\n",
      "test Acc 0.9390130353817505:\n",
      "22th- epoch: 15, train_loss = 36.65770813077688, train_acc = 0.9395668374476013\n",
      "test Acc 0.9413407821229051:\n",
      "22th- epoch: 16, train_loss = 34.134165063500404, train_acc = 0.9422449930135072\n",
      "test Acc 0.9445996275605214:\n",
      "22th- epoch: 17, train_loss = 31.904728315770626, train_acc = 0.9474848625989754\n",
      "test Acc 0.9497206703910615:\n",
      "22th- epoch: 18, train_loss = 29.937143929302692, train_acc = 0.9513274336283186\n",
      "test Acc 0.9534450651769087:\n",
      "22th- epoch: 19, train_loss = 28.200688742101192, train_acc = 0.9528411737307871\n",
      "test Acc 0.9534450651769087:\n",
      "22th- epoch: 20, train_loss = 26.667674720287323, train_acc = 0.9554028877503493\n",
      "test Acc 0.9557728119180633:\n",
      "22th- epoch: 21, train_loss = 25.312583036720753, train_acc = 0.9565673032137867\n",
      "test Acc 0.9567039106145251:\n",
      "22th- epoch: 22, train_loss = 24.11138655990362, train_acc = 0.9573823940381928\n",
      "test Acc 0.957169459962756:\n",
      "22th- epoch: 23, train_loss = 23.041535388678312, train_acc = 0.9588961341406614\n",
      "test Acc 0.9581005586592178:\n",
      "22th- epoch: 24, train_loss = 22.083945494145155, train_acc = 0.9600605496040987\n",
      "test Acc 0.9590316573556797:\n",
      "22th- epoch: 25, train_loss = 21.22198684886098, train_acc = 0.9611085235211924\n",
      "test Acc 0.9590316573556797:\n",
      "22th- epoch: 26, train_loss = 20.440317030996084, train_acc = 0.9618071727992548\n",
      "test Acc 0.9599627560521415:\n",
      "22th- epoch: 27, train_loss = 19.7251486890018, train_acc = 0.9632044713553796\n",
      "test Acc 0.9608938547486033:\n",
      "22th- epoch: 28, train_loss = 19.06647202000022, train_acc = 0.9646017699115044\n",
      "test Acc 0.9613594040968343:\n",
      "22th- epoch: 29, train_loss = 18.457472681999207, train_acc = 0.9651839776432231\n",
      "test Acc 0.9613594040968343:\n",
      "22th- epoch: 30, train_loss = 17.892174154520035, train_acc = 0.9659990684676293\n",
      "test Acc 0.9622905027932961:\n",
      "22th- epoch: 31, train_loss = 17.36550520732999, train_acc = 0.966581276199348\n",
      "test Acc 0.9618249534450651:\n",
      "22th- epoch: 32, train_loss = 16.872842982411385, train_acc = 0.9673963670237541\n",
      "test Acc 0.962756052141527:\n",
      "22th- epoch: 33, train_loss = 16.41062493249774, train_acc = 0.9678621332091291\n",
      "test Acc 0.9636871508379888:\n",
      "22th- epoch: 34, train_loss = 15.975500416010618, train_acc = 0.9687936655798789\n",
      "test Acc 0.9641527001862198:\n",
      "22th- epoch: 35, train_loss = 15.564755737781525, train_acc = 0.9699580810433163\n",
      "test Acc 0.9660148975791434:\n",
      "22th- epoch: 36, train_loss = 15.175795689225197, train_acc = 0.9713553795994411\n",
      "test Acc 0.9678770949720671:\n",
      "22th- epoch: 37, train_loss = 14.807104863226414, train_acc = 0.9720540288775035\n",
      "test Acc 0.9702048417132216:\n",
      "22th- epoch: 38, train_loss = 14.457036506384611, train_acc = 0.9732184443409408\n",
      "test Acc 0.9706703910614525:\n",
      "22th- epoch: 39, train_loss = 14.1243214905262, train_acc = 0.9735677689799721\n",
      "test Acc 0.9711359404096834:\n",
      "22th- epoch: 40, train_loss = 13.808043271303177, train_acc = 0.9746157428970657\n",
      "test Acc 0.9725325884543762:\n",
      "22th- epoch: 41, train_loss = 13.506266620010138, train_acc = 0.9748486259897532\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 42, train_loss = 13.216900754719973, train_acc = 0.975780158360503\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 43, train_loss = 12.93926465511322, train_acc = 0.9761294829995343\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 44, train_loss = 12.673044253140688, train_acc = 0.9764788076385654\n",
      "test Acc 0.972998137802607:\n",
      "22th- epoch: 45, train_loss = 12.417183592915535, train_acc = 0.9771774569166278\n",
      "test Acc 0.973463687150838:\n",
      "22th- epoch: 46, train_loss = 12.170843701809645, train_acc = 0.9778761061946902\n",
      "test Acc 0.9748603351955307:\n",
      "22th- epoch: 47, train_loss = 11.934496968984604, train_acc = 0.9784583139264089\n",
      "test Acc 0.9753258845437617:\n",
      "22th- epoch: 48, train_loss = 11.707436107099056, train_acc = 0.9788076385654402\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 49, train_loss = 11.489325314760208, train_acc = 0.9793898462971589\n",
      "test Acc 0.9757914338919925:\n",
      "22th- epoch: 50, train_loss = 11.279575314372778, train_acc = 0.9798556124825337\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 51, train_loss = 11.077877849340439, train_acc = 0.9803213786679087\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 52, train_loss = 10.883279506117105, train_acc = 0.9805542617605962\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 53, train_loss = 10.695348896086216, train_acc = 0.98067070330694\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 54, train_loss = 10.513774801045656, train_acc = 0.9807871448532837\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 55, train_loss = 10.338156593963504, train_acc = 0.9807871448532837\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 56, train_loss = 10.168263640254736, train_acc = 0.9812529110386586\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 57, train_loss = 10.003713136538863, train_acc = 0.9813693525850024\n",
      "test Acc 0.9762569832402235:\n",
      "22th- epoch: 58, train_loss = 9.844210911542177, train_acc = 0.9818351187703773\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 59, train_loss = 9.68952777609229, train_acc = 0.9820680018630648\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 60, train_loss = 9.539377059787512, train_acc = 0.9823008849557522\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 61, train_loss = 9.393227461725473, train_acc = 0.9827666511411272\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 62, train_loss = 9.251019587740302, train_acc = 0.9831159757801584\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 63, train_loss = 9.11261747032404, train_acc = 0.9832324173265021\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 64, train_loss = 8.97783562541008, train_acc = 0.9832324173265021\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 65, train_loss = 8.846410818397999, train_acc = 0.9833488588728458\n",
      "test Acc 0.9767225325884544:\n",
      "22th- epoch: 66, train_loss = 8.718020047992468, train_acc = 0.9835817419655333\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 67, train_loss = 8.592700514942408, train_acc = 0.9835817419655333\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 68, train_loss = 8.469976296648383, train_acc = 0.9840475081509082\n",
      "test Acc 0.9771880819366853:\n",
      "22th- epoch: 69, train_loss = 8.350055072456598, train_acc = 0.9842803912435957\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 70, train_loss = 8.232960557565093, train_acc = 0.9843968327899395\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 71, train_loss = 8.11833255365491, train_acc = 0.9843968327899395\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 72, train_loss = 8.006050216034055, train_acc = 0.9845132743362832\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 73, train_loss = 7.896179664880037, train_acc = 0.9846297158826269\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 74, train_loss = 7.788706997409463, train_acc = 0.9846297158826269\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 75, train_loss = 7.683501740917563, train_acc = 0.9847461574289706\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 76, train_loss = 7.580290500074625, train_acc = 0.9849790405216581\n",
      "test Acc 0.9776536312849162:\n",
      "22th- epoch: 77, train_loss = 7.479231214150786, train_acc = 0.9850954820680019\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 78, train_loss = 7.380115337669849, train_acc = 0.9853283651606893\n",
      "test Acc 0.9781191806331471:\n",
      "22th- epoch: 79, train_loss = 7.282966172322631, train_acc = 0.985444806707033\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 80, train_loss = 7.1877348981797695, train_acc = 0.9856776897997206\n",
      "test Acc 0.978584729981378:\n",
      "22th- epoch: 81, train_loss = 7.094598107039928, train_acc = 0.9857941313460643\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 82, train_loss = 7.003261756151915, train_acc = 0.9860270144387517\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 83, train_loss = 6.913627028465271, train_acc = 0.986376339077783\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 84, train_loss = 6.8257475681602955, train_acc = 0.986376339077783\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 85, train_loss = 6.739462772384286, train_acc = 0.9864927806241267\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 86, train_loss = 6.654863940551877, train_acc = 0.9864927806241267\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 87, train_loss = 6.5717772003263235, train_acc = 0.9868421052631579\n",
      "test Acc 0.9795158286778398:\n",
      "22th- epoch: 88, train_loss = 6.4903655759990215, train_acc = 0.9870749883558454\n",
      "test Acc 0.9809124767225326:\n",
      "22th- epoch: 89, train_loss = 6.410441894084215, train_acc = 0.9874243129948765\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 90, train_loss = 6.332103457301855, train_acc = 0.9875407545412203\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 91, train_loss = 6.255267499014735, train_acc = 0.9877736376339078\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 92, train_loss = 6.180034393444657, train_acc = 0.9877736376339078\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 93, train_loss = 6.106083691120148, train_acc = 0.9881229622729389\n",
      "test Acc 0.9813780260707635:\n",
      "22th- epoch: 94, train_loss = 6.0337133053690195, train_acc = 0.9881229622729389\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 95, train_loss = 5.962556170299649, train_acc = 0.9882394038192828\n",
      "test Acc 0.9818435754189944:\n",
      "22th- epoch: 96, train_loss = 5.892714619636536, train_acc = 0.9883558453656265\n",
      "test Acc 0.9827746741154563:\n",
      "22th- epoch: 97, train_loss = 5.824111394584179, train_acc = 0.9885887284583139\n",
      "test Acc 0.9832402234636871:\n",
      "22th- epoch: 98, train_loss = 5.756797747686505, train_acc = 0.9888216115510013\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 99, train_loss = 5.69065479002893, train_acc = 0.9890544946436889\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 100, train_loss = 5.625783110037446, train_acc = 0.98940381928272\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 101, train_loss = 5.561961367726326, train_acc = 0.98940381928272\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 102, train_loss = 5.499320644885302, train_acc = 0.98940381928272\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 103, train_loss = 5.4378383699804544, train_acc = 0.98940381928272\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 104, train_loss = 5.377609247341752, train_acc = 0.9895202608290639\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 105, train_loss = 5.318171318620443, train_acc = 0.9896367023754076\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 106, train_loss = 5.2598833329975605, train_acc = 0.989869585468095\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 107, train_loss = 5.202570276334882, train_acc = 0.9899860270144387\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 108, train_loss = 5.1462478982284665, train_acc = 0.99033535165347\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 109, train_loss = 5.091021561063826, train_acc = 0.99033535165347\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 110, train_loss = 5.0366563852876425, train_acc = 0.9905682347461574\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 111, train_loss = 4.983302814885974, train_acc = 0.9909175593851887\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 112, train_loss = 4.93077034316957, train_acc = 0.9911504424778761\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 113, train_loss = 4.879285837523639, train_acc = 0.9912668840242198\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 114, train_loss = 4.828650884330273, train_acc = 0.9913833255705635\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 115, train_loss = 4.778897310607135, train_acc = 0.9913833255705635\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 116, train_loss = 4.729853563942015, train_acc = 0.9913833255705635\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 117, train_loss = 4.681764715351164, train_acc = 0.9913833255705635\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 118, train_loss = 4.634388756006956, train_acc = 0.9914997671169073\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 119, train_loss = 4.587629257701337, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 120, train_loss = 4.541721448302269, train_acc = 0.9918490917559385\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 121, train_loss = 4.496496175415814, train_acc = 0.9919655333022822\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 122, train_loss = 4.452033810317516, train_acc = 0.9919655333022822\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 123, train_loss = 4.408354684710503, train_acc = 0.9921984163949698\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 124, train_loss = 4.365226459689438, train_acc = 0.9923148579413135\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 125, train_loss = 4.322826259769499, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 126, train_loss = 4.2811912866309285, train_acc = 0.9926641825803446\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 127, train_loss = 4.240267880260944, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 128, train_loss = 4.199903879314661, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 129, train_loss = 4.160200132988393, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 130, train_loss = 4.121225546114147, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 131, train_loss = 4.082776696421206, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 132, train_loss = 4.044878198765218, train_acc = 0.9934792734047508\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 133, train_loss = 4.00777873955667, train_acc = 0.9934792734047508\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 134, train_loss = 3.9710414754226804, train_acc = 0.9934792734047508\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 135, train_loss = 3.9349462995305657, train_acc = 0.9934792734047508\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 136, train_loss = 3.8993599703535438, train_acc = 0.9935957149510946\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 137, train_loss = 3.8643810590729117, train_acc = 0.9935957149510946\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 138, train_loss = 3.829954445362091, train_acc = 0.9937121564974383\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 139, train_loss = 3.7959827603772283, train_acc = 0.993828598043782\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 140, train_loss = 3.7625783002004027, train_acc = 0.9939450395901258\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 141, train_loss = 3.7296749744564295, train_acc = 0.9939450395901258\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 142, train_loss = 3.697201988659799, train_acc = 0.9940614811364695\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 143, train_loss = 3.6652123229578137, train_acc = 0.9941779226828132\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 144, train_loss = 3.6336721992120147, train_acc = 0.994294364229157\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 145, train_loss = 3.602703752927482, train_acc = 0.994294364229157\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 146, train_loss = 3.572053854353726, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22th- epoch: 147, train_loss = 3.5418292367830873, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 148, train_loss = 3.5118639222346246, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 149, train_loss = 3.4825157807208598, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 150, train_loss = 3.453616264741868, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 151, train_loss = 3.425105715636164, train_acc = 0.9946436888681882\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 152, train_loss = 3.396953082177788, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 153, train_loss = 3.3691895161755383, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 154, train_loss = 3.341850119177252, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 155, train_loss = 3.314795757178217, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 156, train_loss = 3.288134152069688, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 157, train_loss = 3.2619378571398556, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 158, train_loss = 3.235995128750801, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 159, train_loss = 3.2104342114180326, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 160, train_loss = 3.185160396620631, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 161, train_loss = 3.16019280301407, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 162, train_loss = 3.1356783472001553, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 163, train_loss = 3.1114351078867912, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 164, train_loss = 3.0875574690289795, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 165, train_loss = 3.064041599165648, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 166, train_loss = 3.040793539956212, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 167, train_loss = 3.0179067966528237, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 168, train_loss = 2.9952198094688356, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 169, train_loss = 2.9729073084890842, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 170, train_loss = 2.950833478476852, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 171, train_loss = 2.929120408836752, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 172, train_loss = 2.9077272675931454, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 173, train_loss = 2.886460171546787, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 174, train_loss = 2.865576069802046, train_acc = 0.995575221238938\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 175, train_loss = 2.844856815878302, train_acc = 0.9956916627852818\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 176, train_loss = 2.824372464325279, train_acc = 0.9956916627852818\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 177, train_loss = 2.804255357477814, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 178, train_loss = 2.7843390703201294, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 179, train_loss = 2.7646783771924675, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 180, train_loss = 2.745194537099451, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 181, train_loss = 2.725945893675089, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 182, train_loss = 2.7068769726902246, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 183, train_loss = 2.6882015392184258, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 184, train_loss = 2.669769095722586, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 185, train_loss = 2.6515654865652323, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 186, train_loss = 2.633446732070297, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 187, train_loss = 2.6157357818447053, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 188, train_loss = 2.5980612584389746, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 189, train_loss = 2.5806853803806007, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 190, train_loss = 2.563558792229742, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 191, train_loss = 2.546522745396942, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 192, train_loss = 2.5298370122909546, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 193, train_loss = 2.5132961641065776, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 194, train_loss = 2.4969197679311037, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 195, train_loss = 2.4807804643642157, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 196, train_loss = 2.4648017075378448, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 197, train_loss = 2.448885412188247, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 198, train_loss = 2.4332871821243316, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 199, train_loss = 2.417765973135829, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 200, train_loss = 2.402579452143982, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 201, train_loss = 2.3873716469388455, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 202, train_loss = 2.3725587490480393, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 203, train_loss = 2.357903702184558, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 204, train_loss = 2.3434667319525033, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 205, train_loss = 2.329027696279809, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 206, train_loss = 2.31506849383004, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 207, train_loss = 2.3010614197701216, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 208, train_loss = 2.287246072664857, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "22th- epoch: 209, train_loss = 2.2736231859307736, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 210, train_loss = 2.260229791281745, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 211, train_loss = 2.2468349877744913, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 212, train_loss = 2.2337734054308385, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 213, train_loss = 2.2208278328180313, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 214, train_loss = 2.208006852073595, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 215, train_loss = 2.1953316405415535, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 216, train_loss = 2.182851779507473, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 217, train_loss = 2.170411776052788, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 218, train_loss = 2.158177726669237, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 219, train_loss = 2.146066629095003, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 220, train_loss = 2.1340928587596864, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 221, train_loss = 2.122244047001004, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 222, train_loss = 2.1105133909732103, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 223, train_loss = 2.0990996938198805, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 224, train_loss = 2.0876289394218475, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 225, train_loss = 2.076309395255521, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 226, train_loss = 2.06527188164182, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 227, train_loss = 2.0543038367759436, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 228, train_loss = 2.0434028587769717, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 229, train_loss = 2.0327507636975497, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "22th- epoch: 230, train_loss = 2.022074864478782, train_acc = 0.9966231951560317\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 231, train_loss = 2.011633551446721, train_acc = 0.9966231951560317\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 232, train_loss = 2.0013678576797247, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 233, train_loss = 1.9910645994823426, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 234, train_loss = 1.9810119967442006, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 235, train_loss = 1.9710269446950406, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 236, train_loss = 1.961165728745982, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 237, train_loss = 1.9515334398020059, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 238, train_loss = 1.941854038508609, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 239, train_loss = 1.9324722532182932, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 240, train_loss = 1.9230312674771994, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 241, train_loss = 1.913772938074544, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 242, train_loss = 1.904596743406728, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 243, train_loss = 1.8955178905744106, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 244, train_loss = 1.8866949893999845, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 245, train_loss = 1.87785027991049, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 246, train_loss = 1.8691092871595174, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 247, train_loss = 1.8605383958201855, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 248, train_loss = 1.8520156170707196, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "22th- epoch: 249, train_loss = 1.8435698971152306, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "22th- epoch: 250, train_loss = 1.8352677412331104, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "22th- epoch: 251, train_loss = 1.8271171661326662, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "22th- epoch: 252, train_loss = 1.8189526349306107, train_acc = 0.9969725197950629\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 253, train_loss = 1.8109470742056146, train_acc = 0.9969725197950629\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 254, train_loss = 1.8030368661275133, train_acc = 0.9969725197950629\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 255, train_loss = 1.7951740151038393, train_acc = 0.9972054028877504\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 256, train_loss = 1.787386647076346, train_acc = 0.9972054028877504\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 257, train_loss = 1.77974935376551, train_acc = 0.9972054028877504\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 258, train_loss = 1.772186299203895, train_acc = 0.9972054028877504\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 259, train_loss = 1.76467491814401, train_acc = 0.9972054028877504\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 260, train_loss = 1.7573305517435074, train_acc = 0.9972054028877504\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 261, train_loss = 1.7500086078653112, train_acc = 0.9972054028877504\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 262, train_loss = 1.742700411588885, train_acc = 0.9972054028877504\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 263, train_loss = 1.7355782315135002, train_acc = 0.9973218444340941\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 264, train_loss = 1.7285073399543762, train_acc = 0.9973218444340941\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 265, train_loss = 1.7214601574232802, train_acc = 0.9973218444340941\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 266, train_loss = 1.7145551877329126, train_acc = 0.9973218444340941\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 267, train_loss = 1.7077700197696686, train_acc = 0.9973218444340941\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 268, train_loss = 1.7010097317397594, train_acc = 0.9973218444340941\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 269, train_loss = 1.694295114488341, train_acc = 0.9973218444340941\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 270, train_loss = 1.6877256780862808, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 271, train_loss = 1.6811096282908693, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 272, train_loss = 1.674699243158102, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 273, train_loss = 1.6682937095174566, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 274, train_loss = 1.6619739333400503, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 275, train_loss = 1.655656891525723, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 276, train_loss = 1.6495427340269089, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 277, train_loss = 1.6433751346776262, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 278, train_loss = 1.6372498348355293, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 279, train_loss = 1.6313246811041608, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 280, train_loss = 1.6253170123090968, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 281, train_loss = 1.6194639330497012, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 282, train_loss = 1.6135892743477598, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 283, train_loss = 1.6078598784515634, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 284, train_loss = 1.6021266417810693, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 285, train_loss = 1.5964618101716042, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 286, train_loss = 1.5908789871027693, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 287, train_loss = 1.5852857865393162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 288, train_loss = 1.5798435559263453, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 289, train_loss = 1.574389627785422, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 290, train_loss = 1.5690036626765504, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 291, train_loss = 1.563756786286831, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 292, train_loss = 1.558341145515442, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 293, train_loss = 1.5531492283334956, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 294, train_loss = 1.5479756271233782, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 295, train_loss = 1.5428665913641453, train_acc = 0.9976711690731253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 296, train_loss = 1.5377691289177164, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 297, train_loss = 1.5326786959776655, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 298, train_loss = 1.527742624282837, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 299, train_loss = 1.5228145023575053, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 300, train_loss = 1.517944068997167, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 301, train_loss = 1.5130511583993211, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 302, train_loss = 1.508273514569737, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 303, train_loss = 1.5035100231179968, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 304, train_loss = 1.4988620554795489, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 305, train_loss = 1.494063756079413, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 306, train_loss = 1.4895073622465134, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 307, train_loss = 1.4849339537322521, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 308, train_loss = 1.4803596027195454, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 309, train_loss = 1.475862979888916, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 310, train_loss = 1.4714175002882257, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 311, train_loss = 1.4669252609601244, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 312, train_loss = 1.462548516690731, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 313, train_loss = 1.4582417471101508, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 314, train_loss = 1.4538780538132414, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 315, train_loss = 1.4495928114047274, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 316, train_loss = 1.445302175998222, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 317, train_loss = 1.4410634872619994, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 318, train_loss = 1.436859694600571, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 319, train_loss = 1.4326879170839675, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 320, train_loss = 1.4285618190770037, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 321, train_loss = 1.4243965198402293, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 322, train_loss = 1.4203807165031321, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 323, train_loss = 1.416348795115482, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 324, train_loss = 1.4123489285702817, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 325, train_loss = 1.4083521117572673, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 326, train_loss = 1.4044400726561435, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 327, train_loss = 1.4005437195301056, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 328, train_loss = 1.3966752737760544, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "22th- epoch: 329, train_loss = 1.3928703826968558, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 330, train_loss = 1.3890935244853608, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 331, train_loss = 1.3853038077359088, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 332, train_loss = 1.3816435858607292, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 333, train_loss = 1.3779244248871692, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 334, train_loss = 1.3742398123140447, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 335, train_loss = 1.370680107444059, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 336, train_loss = 1.367085613310337, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 337, train_loss = 1.36349181458354, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 338, train_loss = 1.359973897517193, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 339, train_loss = 1.3565257390146144, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 340, train_loss = 1.353011529892683, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 341, train_loss = 1.3496024807100184, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 342, train_loss = 1.3462034277617931, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 343, train_loss = 1.342787726491224, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 344, train_loss = 1.3394289401476271, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 345, train_loss = 1.3360850363969803, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 346, train_loss = 1.3327518564765342, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 347, train_loss = 1.3295345443184488, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 348, train_loss = 1.3262630167300813, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 349, train_loss = 1.3230112033779733, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 350, train_loss = 1.3197997510433197, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 351, train_loss = 1.316643100231886, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 352, train_loss = 1.3134758099913597, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 353, train_loss = 1.3102899168734439, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 354, train_loss = 1.3072135224938393, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 355, train_loss = 1.3041383003001101, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 356, train_loss = 1.3009988206322305, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 357, train_loss = 1.2980692398850806, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 358, train_loss = 1.2949200992588885, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 359, train_loss = 1.2919782735407352, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 360, train_loss = 1.2890412832493894, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 361, train_loss = 1.2860375779564492, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 362, train_loss = 1.2831327195162885, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 363, train_loss = 1.2802120235865004, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 364, train_loss = 1.2773187756538391, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 365, train_loss = 1.2745226683910005, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 366, train_loss = 1.2716360241174698, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 367, train_loss = 1.2687408576603048, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 368, train_loss = 1.2659003461594693, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 369, train_loss = 1.2632736451923847, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 370, train_loss = 1.2604264467954636, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 371, train_loss = 1.2576464687590487, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 372, train_loss = 1.2550074507598765, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 373, train_loss = 1.2522124834358692, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 374, train_loss = 1.2496320195496082, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 375, train_loss = 1.2469053926761262, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 376, train_loss = 1.2442717105150223, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 377, train_loss = 1.2416742804343812, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 378, train_loss = 1.2389902547001839, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 379, train_loss = 1.2364061176776886, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 380, train_loss = 1.2338995697791688, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 381, train_loss = 1.2312957433168776, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 382, train_loss = 1.2287471878225915, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 383, train_loss = 1.2262404399807565, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 384, train_loss = 1.2237286493182182, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 385, train_loss = 1.2213287738268264, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 386, train_loss = 1.2188105322420597, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 387, train_loss = 1.2163170737330802, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 388, train_loss = 1.2138746393029578, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 389, train_loss = 1.2114880047738552, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 390, train_loss = 1.209058154374361, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 391, train_loss = 1.2066926385159604, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 392, train_loss = 1.2042769963736646, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 393, train_loss = 1.201907643408049, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 394, train_loss = 1.1996223119203933, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 395, train_loss = 1.1973214000463486, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 396, train_loss = 1.19494929414941, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 397, train_loss = 1.1926560650463216, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 398, train_loss = 1.1903541013598442, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 399, train_loss = 1.1881395963137038, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 400, train_loss = 1.1857786178588867, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 401, train_loss = 1.1836356855928898, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 402, train_loss = 1.18132664510631, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 403, train_loss = 1.179136373102665, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 404, train_loss = 1.1769909808936063, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 405, train_loss = 1.1747623967530672, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 406, train_loss = 1.1726279916765634, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 407, train_loss = 1.1703926535847131, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 408, train_loss = 1.1682672823371831, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 409, train_loss = 1.1660668601689395, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 410, train_loss = 1.1639792012574617, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 411, train_loss = 1.1618503692152444, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 412, train_loss = 1.1597274132072926, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 413, train_loss = 1.157699342817068, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 414, train_loss = 1.1555714222195093, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 415, train_loss = 1.1535748379828874, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 416, train_loss = 1.151484680682188, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 417, train_loss = 1.1494864324631635, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 418, train_loss = 1.1474627715942916, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 419, train_loss = 1.1454866329731885, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 420, train_loss = 1.1434748942556325, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 421, train_loss = 1.141512706875801, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 422, train_loss = 1.139502726495266, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 423, train_loss = 1.1376385477778967, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 424, train_loss = 1.1356353908777237, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 425, train_loss = 1.1337599766848143, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 426, train_loss = 1.1317842714488506, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 427, train_loss = 1.1299081196484622, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 428, train_loss = 1.1280214463768061, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 429, train_loss = 1.1261858393845614, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 430, train_loss = 1.1242224437592085, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 431, train_loss = 1.1225031328795012, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 432, train_loss = 1.120546381920576, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 433, train_loss = 1.118734179675812, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 434, train_loss = 1.1169249961676542, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 435, train_loss = 1.1150890700519085, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 436, train_loss = 1.1133202301862184, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 437, train_loss = 1.1114661494793836, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 438, train_loss = 1.109717857092619, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 439, train_loss = 1.1079384076001588, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 440, train_loss = 1.10619985559606, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 441, train_loss = 1.1044009340403136, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 442, train_loss = 1.1026483364403248, train_acc = 0.9980204937121565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 443, train_loss = 1.1009184954164084, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 444, train_loss = 1.0992214232683182, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 445, train_loss = 1.0975011065602303, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 446, train_loss = 1.0957595320942346, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 447, train_loss = 1.0941051157715265, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 448, train_loss = 1.0923689380288124, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 449, train_loss = 1.0907443414034788, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 450, train_loss = 1.089018331229454, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 451, train_loss = 1.0873669361171778, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 452, train_loss = 1.0856980830430984, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 453, train_loss = 1.0841220816073474, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 454, train_loss = 1.0824754871428013, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 455, train_loss = 1.0808014422655106, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 456, train_loss = 1.0791904690267984, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 457, train_loss = 1.0776165040733758, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 458, train_loss = 1.076030571013689, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 459, train_loss = 1.074399237841135, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 460, train_loss = 1.0728265630605165, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 461, train_loss = 1.0712258840503637, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 462, train_loss = 1.0697333924472332, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 463, train_loss = 1.068120980024105, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 464, train_loss = 1.0665775462985039, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 465, train_loss = 1.0650304878654424, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 466, train_loss = 1.0634663502278272, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 467, train_loss = 1.062003397702938, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 468, train_loss = 1.0605046302080154, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 469, train_loss = 1.0589210117759649, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 470, train_loss = 1.0574565418064594, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 471, train_loss = 1.0559501672687475, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 472, train_loss = 1.0544574273226317, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 473, train_loss = 1.0530383015575353, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 474, train_loss = 1.0515208604338113, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 475, train_loss = 1.0500386258063372, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 476, train_loss = 1.0486389560101088, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 477, train_loss = 1.0471871122717857, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 478, train_loss = 1.0456393895146903, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 479, train_loss = 1.0442549623548985, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 480, train_loss = 1.0428016893565655, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 481, train_loss = 1.041374545544386, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 482, train_loss = 1.0400438854994718, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 483, train_loss = 1.0385379505751189, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 484, train_loss = 1.0371646185813006, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 485, train_loss = 1.0358013287186623, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 486, train_loss = 1.034390597284073, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 487, train_loss = 1.0331035194394644, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 488, train_loss = 1.0316233547928277, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 489, train_loss = 1.0303050453367177, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 490, train_loss = 1.0289126299321651, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 491, train_loss = 1.0276080096664373, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 492, train_loss = 1.0262183683516923, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 493, train_loss = 1.0249597653746605, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 494, train_loss = 1.023579727858305, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 495, train_loss = 1.0222746444342192, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 496, train_loss = 1.0209301610884722, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 497, train_loss = 1.0196403836307582, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 498, train_loss = 1.0182921290397644, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "22th- epoch: 499, train_loss = 1.0170256780984346, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|████████████████████████████████████████████████████▊                   | 22/30 [2:30:13<54:50, 411.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "23th- epoch: 0, train_loss = 269.5790022611618, train_acc = 0.43246390312063343\n",
      "test Acc 0.4920856610800745:\n",
      "23th- epoch: 1, train_loss = 203.45971047878265, train_acc = 0.516301816488123\n",
      "test Acc 0.5777467411545624:\n",
      "23th- epoch: 2, train_loss = 155.95737653970718, train_acc = 0.5947834187238007\n",
      "test Acc 0.6364059590316573:\n",
      "23th- epoch: 3, train_loss = 131.26340645551682, train_acc = 0.6613879832324173\n",
      "test Acc 0.6997206703910615:\n",
      "23th- epoch: 4, train_loss = 113.32165682315826, train_acc = 0.7256637168141593\n",
      "test Acc 0.750465549348231:\n",
      "23th- epoch: 5, train_loss = 98.80717241764069, train_acc = 0.7756171401956218\n",
      "test Acc 0.7905027932960894:\n",
      "23th- epoch: 6, train_loss = 86.86070781946182, train_acc = 0.7976245924545878\n",
      "test Acc 0.8044692737430168:\n",
      "23th- epoch: 7, train_loss = 76.94443681836128, train_acc = 0.814741499767117\n",
      "test Acc 0.8240223463687151:\n",
      "23th- epoch: 8, train_loss = 68.57599601149559, train_acc = 0.8361667442943642\n",
      "test Acc 0.8496275605214153:\n",
      "23th- epoch: 9, train_loss = 61.46976621448994, train_acc = 0.8693525850023288\n",
      "test Acc 0.8766294227188082:\n",
      "23th- epoch: 10, train_loss = 55.43714414536953, train_acc = 0.8938053097345132\n",
      "test Acc 0.8999068901303539:\n",
      "23th- epoch: 11, train_loss = 50.27554772794247, train_acc = 0.9096413600372613\n",
      "test Acc 0.9194599627560521:\n",
      "23th- epoch: 12, train_loss = 45.82260704040527, train_acc = 0.9262925011644154\n",
      "test Acc 0.931098696461825:\n",
      "23th- epoch: 13, train_loss = 41.958600640296936, train_acc = 0.9353749417792269\n",
      "test Acc 0.9380819366852886:\n",
      "23th- epoch: 14, train_loss = 38.60064025223255, train_acc = 0.939683278993945\n",
      "test Acc 0.9422718808193669:\n",
      "23th- epoch: 15, train_loss = 35.68295016884804, train_acc = 0.942361434559851\n",
      "test Acc 0.9455307262569832:\n",
      "23th- epoch: 16, train_loss = 33.14660697430372, train_acc = 0.9442244993013508\n",
      "test Acc 0.9497206703910615:\n",
      "23th- epoch: 17, train_loss = 30.940136425197124, train_acc = 0.946786213320913\n",
      "test Acc 0.9511173184357542:\n",
      "23th- epoch: 18, train_loss = 29.023136734962463, train_acc = 0.9522589659990685\n",
      "test Acc 0.9553072625698324:\n",
      "23th- epoch: 19, train_loss = 27.354710772633553, train_acc = 0.9557522123893806\n",
      "test Acc 0.9562383612662942:\n",
      "23th- epoch: 20, train_loss = 25.8953450396657, train_acc = 0.9566837447601304\n",
      "test Acc 0.957635009310987:\n",
      "23th- epoch: 21, train_loss = 24.61200327053666, train_acc = 0.9578481602235678\n",
      "test Acc 0.9590316573556797:\n",
      "23th- epoch: 22, train_loss = 23.47635155543685, train_acc = 0.9592454587796926\n",
      "test Acc 0.9594972067039106:\n",
      "23th- epoch: 23, train_loss = 22.463335119187832, train_acc = 0.9601769911504425\n",
      "test Acc 0.9594972067039106:\n",
      "23th- epoch: 24, train_loss = 21.55476175993681, train_acc = 0.9612249650675361\n",
      "test Acc 0.9599627560521415:\n",
      "23th- epoch: 25, train_loss = 20.733269184827805, train_acc = 0.9615742897065673\n",
      "test Acc 0.9599627560521415:\n",
      "23th- epoch: 26, train_loss = 19.983548145741224, train_acc = 0.9625058220773172\n",
      "test Acc 0.9599627560521415:\n",
      "23th- epoch: 27, train_loss = 19.297437112778425, train_acc = 0.9637866790870983\n",
      "test Acc 0.9608938547486033:\n",
      "23th- epoch: 28, train_loss = 18.666656523942947, train_acc = 0.9647182114578482\n",
      "test Acc 0.9608938547486033:\n",
      "23th- epoch: 29, train_loss = 18.08390836790204, train_acc = 0.965649743828598\n",
      "test Acc 0.9613594040968343:\n",
      "23th- epoch: 30, train_loss = 17.541991483420134, train_acc = 0.966115510013973\n",
      "test Acc 0.9613594040968343:\n",
      "23th- epoch: 31, train_loss = 17.03580029681325, train_acc = 0.966581276199348\n",
      "test Acc 0.962756052141527:\n",
      "23th- epoch: 32, train_loss = 16.562399830669165, train_acc = 0.9670470423847228\n",
      "test Acc 0.9622905027932961:\n",
      "23th- epoch: 33, train_loss = 16.11861888319254, train_acc = 0.9680950163018165\n",
      "test Acc 0.962756052141527:\n",
      "23th- epoch: 34, train_loss = 15.701597969979048, train_acc = 0.9697251979506288\n",
      "test Acc 0.9650837988826816:\n",
      "23th- epoch: 35, train_loss = 15.308929033577442, train_acc = 0.9701909641360037\n",
      "test Acc 0.9674115456238361:\n",
      "23th- epoch: 36, train_loss = 14.93790403008461, train_acc = 0.9717047042384723\n",
      "test Acc 0.9683426443202979:\n",
      "23th- epoch: 37, train_loss = 14.587053906172514, train_acc = 0.9734513274336283\n",
      "test Acc 0.9697392923649907:\n",
      "23th- epoch: 38, train_loss = 14.254596672952175, train_acc = 0.974033535165347\n",
      "test Acc 0.9702048417132216:\n",
      "23th- epoch: 39, train_loss = 13.938866395503283, train_acc = 0.9750815090824406\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 40, train_loss = 13.638174664229155, train_acc = 0.9755472752678156\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 41, train_loss = 13.351137988269329, train_acc = 0.9760130414531905\n",
      "test Acc 0.9711359404096834:\n",
      "23th- epoch: 42, train_loss = 13.07642963156104, train_acc = 0.9763623660922217\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 43, train_loss = 12.813412867486477, train_acc = 0.9768281322775967\n",
      "test Acc 0.9720670391061452:\n",
      "23th- epoch: 44, train_loss = 12.561543699353933, train_acc = 0.9775267815556591\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 45, train_loss = 12.319549407809973, train_acc = 0.9777596646483465\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 46, train_loss = 12.08672470971942, train_acc = 0.9783418723800652\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 47, train_loss = 11.86198716238141, train_acc = 0.9784583139264089\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 48, train_loss = 11.644713830202818, train_acc = 0.9786911970190965\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 49, train_loss = 11.434754982590675, train_acc = 0.9788076385654402\n",
      "test Acc 0.972998137802607:\n",
      "23th- epoch: 50, train_loss = 11.231700528413057, train_acc = 0.9789240801117839\n",
      "test Acc 0.973463687150838:\n",
      "23th- epoch: 51, train_loss = 11.035651925951242, train_acc = 0.9790405216581276\n",
      "test Acc 0.9739292364990689:\n",
      "23th- epoch: 52, train_loss = 10.846102125942707, train_acc = 0.9789240801117839\n",
      "test Acc 0.9748603351955307:\n",
      "23th- epoch: 53, train_loss = 10.66267191246152, train_acc = 0.9795062878435026\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 54, train_loss = 10.485169865190983, train_acc = 0.9803213786679087\n",
      "test Acc 0.9753258845437617:\n",
      "23th- epoch: 55, train_loss = 10.312984578311443, train_acc = 0.9805542617605962\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 56, train_loss = 10.145855452865362, train_acc = 0.9807871448532837\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 57, train_loss = 9.98359869979322, train_acc = 0.9812529110386586\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 58, train_loss = 9.825926944613457, train_acc = 0.9816022356776898\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 59, train_loss = 9.67282359302044, train_acc = 0.9817186772240335\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 60, train_loss = 9.52379323542118, train_acc = 0.981951560316721\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 61, train_loss = 9.37850458174944, train_acc = 0.9821844434094085\n",
      "test Acc 0.9757914338919925:\n",
      "23th- epoch: 62, train_loss = 9.23681415617466, train_acc = 0.9821844434094085\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 63, train_loss = 9.098743224516511, train_acc = 0.9823008849557522\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 64, train_loss = 8.96370591968298, train_acc = 0.9825337680484397\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 65, train_loss = 8.831923769786954, train_acc = 0.9826502095947834\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 66, train_loss = 8.70315288566053, train_acc = 0.9829995342338146\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 67, train_loss = 8.577271757647395, train_acc = 0.9833488588728458\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 68, train_loss = 8.454329816624522, train_acc = 0.9838146250582208\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 69, train_loss = 8.334079410880804, train_acc = 0.9838146250582208\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 70, train_loss = 8.216367654502392, train_acc = 0.9840475081509082\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 71, train_loss = 8.101132610812783, train_acc = 0.9846297158826269\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 72, train_loss = 7.988299580290914, train_acc = 0.9849790405216581\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 73, train_loss = 7.877723377197981, train_acc = 0.9850954820680019\n",
      "test Acc 0.9762569832402235:\n",
      "23th- epoch: 74, train_loss = 7.769205251708627, train_acc = 0.9852119236143456\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 75, train_loss = 7.66269963234663, train_acc = 0.985444806707033\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 76, train_loss = 7.558367384597659, train_acc = 0.9855612482533768\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 77, train_loss = 7.456121560186148, train_acc = 0.985910572892408\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 78, train_loss = 7.355860929936171, train_acc = 0.985910572892408\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 79, train_loss = 7.257662670686841, train_acc = 0.9860270144387517\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 80, train_loss = 7.161317553371191, train_acc = 0.9861434559850955\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 81, train_loss = 7.066906498745084, train_acc = 0.9862598975314392\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 82, train_loss = 6.974080143496394, train_acc = 0.9866092221704704\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 83, train_loss = 6.883080108091235, train_acc = 0.9867256637168141\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 84, train_loss = 6.793698165565729, train_acc = 0.9867256637168141\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 85, train_loss = 6.706084910780191, train_acc = 0.9869585468095017\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 86, train_loss = 6.620063642039895, train_acc = 0.9869585468095017\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 87, train_loss = 6.53573758713901, train_acc = 0.9874243129948765\n",
      "test Acc 0.9767225325884544:\n",
      "23th- epoch: 88, train_loss = 6.4528831504285336, train_acc = 0.9874243129948765\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 89, train_loss = 6.371527506038547, train_acc = 0.9874243129948765\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 90, train_loss = 6.291711911559105, train_acc = 0.9875407545412203\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 91, train_loss = 6.2131483890116215, train_acc = 0.9875407545412203\n",
      "test Acc 0.9771880819366853:\n",
      "23th- epoch: 92, train_loss = 6.136175813153386, train_acc = 0.9876571960875641\n",
      "test Acc 0.978584729981378:\n",
      "23th- epoch: 93, train_loss = 6.0605210326612, train_acc = 0.9878900791802515\n",
      "test Acc 0.978584729981378:\n",
      "23th- epoch: 94, train_loss = 5.98611244186759, train_acc = 0.9878900791802515\n",
      "test Acc 0.978584729981378:\n",
      "23th- epoch: 95, train_loss = 5.913030928000808, train_acc = 0.9881229622729389\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 96, train_loss = 5.841240068897605, train_acc = 0.9883558453656265\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 97, train_loss = 5.7709566336125135, train_acc = 0.9885887284583139\n",
      "test Acc 0.979050279329609:\n",
      "23th- epoch: 98, train_loss = 5.7020857855677605, train_acc = 0.9887051700046576\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 99, train_loss = 5.634254673495889, train_acc = 0.9887051700046576\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 100, train_loss = 5.567762775346637, train_acc = 0.9887051700046576\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 101, train_loss = 5.502397287636995, train_acc = 0.9888216115510013\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 102, train_loss = 5.438137276098132, train_acc = 0.9888216115510013\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 103, train_loss = 5.375058984383941, train_acc = 0.9890544946436889\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 104, train_loss = 5.313073918223381, train_acc = 0.9892873777363763\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 105, train_loss = 5.252248393371701, train_acc = 0.9896367023754076\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 106, train_loss = 5.192561166360974, train_acc = 0.989869585468095\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 107, train_loss = 5.133977627381682, train_acc = 0.9902189101071263\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 108, train_loss = 5.076517252251506, train_acc = 0.9902189101071263\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 109, train_loss = 5.0201169811189175, train_acc = 0.9905682347461574\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 110, train_loss = 4.964838890358806, train_acc = 0.9910340009315324\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 111, train_loss = 4.910554711706936, train_acc = 0.9911504424778761\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 112, train_loss = 4.857271233573556, train_acc = 0.9911504424778761\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 113, train_loss = 4.80502865742892, train_acc = 0.9911504424778761\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 114, train_loss = 4.753610788844526, train_acc = 0.9912668840242198\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 115, train_loss = 4.703108602203429, train_acc = 0.9913833255705635\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 116, train_loss = 4.65356124099344, train_acc = 0.9913833255705635\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 117, train_loss = 4.604874903336167, train_acc = 0.9913833255705635\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 118, train_loss = 4.556897385977209, train_acc = 0.9914997671169073\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 119, train_loss = 4.509969254024327, train_acc = 0.9916162086632511\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 120, train_loss = 4.463653082959354, train_acc = 0.9918490917559385\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 121, train_loss = 4.418358091264963, train_acc = 0.992081974848626\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 122, train_loss = 4.3737636879086494, train_acc = 0.9924312994876572\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 123, train_loss = 4.329917714931071, train_acc = 0.9925477410340009\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 124, train_loss = 4.286743414588273, train_acc = 0.9926641825803446\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 125, train_loss = 4.244388370774686, train_acc = 0.9927806241266884\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 126, train_loss = 4.202636270783842, train_acc = 0.9928970656730322\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 127, train_loss = 4.1616226667538285, train_acc = 0.9931299487657196\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 128, train_loss = 4.121276647783816, train_acc = 0.9932463903120633\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 129, train_loss = 4.081545725464821, train_acc = 0.9932463903120633\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 130, train_loss = 4.042421578429639, train_acc = 0.9932463903120633\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 131, train_loss = 4.003954583778977, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 132, train_loss = 3.966128514148295, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 133, train_loss = 3.928841066546738, train_acc = 0.9933628318584071\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 134, train_loss = 3.8922937037423253, train_acc = 0.9934792734047508\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 135, train_loss = 3.856244317255914, train_acc = 0.9935957149510946\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 136, train_loss = 3.8208027090877295, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 137, train_loss = 3.7859376622363925, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 138, train_loss = 3.7516101812943816, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 139, train_loss = 3.717808548361063, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 140, train_loss = 3.6845564329996705, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 141, train_loss = 3.651853609830141, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 142, train_loss = 3.6196831921115518, train_acc = 0.993828598043782\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 143, train_loss = 3.588005229830742, train_acc = 0.9939450395901258\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 144, train_loss = 3.5567478025332093, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 145, train_loss = 3.5260948734357953, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n",
      "23th- epoch: 146, train_loss = 3.4958769865334034, train_acc = 0.9940614811364695\n",
      "test Acc 0.9795158286778398:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 147, train_loss = 3.4660334172658622, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 148, train_loss = 3.4366472004912794, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 149, train_loss = 3.407701559830457, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 150, train_loss = 3.3793201544322073, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 151, train_loss = 3.3511612745933235, train_acc = 0.9941779226828132\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 152, train_loss = 3.3235908430069685, train_acc = 0.994294364229157\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 153, train_loss = 3.2962664552032948, train_acc = 0.9944108057755007\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 154, train_loss = 3.269421910867095, train_acc = 0.9945272473218444\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 155, train_loss = 3.242956622969359, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 156, train_loss = 3.2169137820601463, train_acc = 0.9947601304145319\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 157, train_loss = 3.191122381016612, train_acc = 0.9948765719608756\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 158, train_loss = 3.16577867558226, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 159, train_loss = 3.140735318418592, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 160, train_loss = 3.116147104650736, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 161, train_loss = 3.091729314532131, train_acc = 0.9949930135072194\n",
      "test Acc 0.9799813780260708:\n",
      "23th- epoch: 162, train_loss = 3.0677116946317255, train_acc = 0.9951094550535631\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 163, train_loss = 3.044020266737789, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 164, train_loss = 3.020665312651545, train_acc = 0.9952258965999069\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 165, train_loss = 2.9975576545111835, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 166, train_loss = 2.974875118583441, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 167, train_loss = 2.95250704837963, train_acc = 0.9953423381462506\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 168, train_loss = 2.9303572825156152, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 169, train_loss = 2.9085760465823114, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 170, train_loss = 2.88710187189281, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 171, train_loss = 2.865831709932536, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 172, train_loss = 2.844990849029273, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 173, train_loss = 2.8243327173404396, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 174, train_loss = 2.8038958851248026, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 175, train_loss = 2.783775540534407, train_acc = 0.9954587796925943\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 176, train_loss = 2.7638973854482174, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 177, train_loss = 2.744409205392003, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 178, train_loss = 2.7250532656908035, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 179, train_loss = 2.7059551868587732, train_acc = 0.9954587796925943\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 180, train_loss = 2.6871694438159466, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 181, train_loss = 2.66854860028252, train_acc = 0.995575221238938\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 182, train_loss = 2.6502096746116877, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 183, train_loss = 2.632088392972946, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 184, train_loss = 2.614277038257569, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 185, train_loss = 2.596603248734027, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 186, train_loss = 2.5792381018400192, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 187, train_loss = 2.5619278005324304, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 188, train_loss = 2.5450861863791943, train_acc = 0.9956916627852818\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 189, train_loss = 2.528248706366867, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 190, train_loss = 2.511739095672965, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 191, train_loss = 2.495393066201359, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 192, train_loss = 2.47933348454535, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 193, train_loss = 2.4632928553037345, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 194, train_loss = 2.4476879369467497, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 195, train_loss = 2.432048475369811, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 196, train_loss = 2.416701107053086, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 197, train_loss = 2.401666671736166, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 198, train_loss = 2.386751975864172, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 199, train_loss = 2.3719582681078464, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 200, train_loss = 2.357424554647878, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 201, train_loss = 2.3430523343849927, train_acc = 0.9958081043316255\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 202, train_loss = 2.328874598024413, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 203, train_loss = 2.3147450536489487, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 204, train_loss = 2.301028447924182, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 205, train_loss = 2.2873748124111444, train_acc = 0.9959245458779693\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 206, train_loss = 2.273847605334595, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 207, train_loss = 2.2605058655608445, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 208, train_loss = 2.247309447033331, train_acc = 0.9959245458779693\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 209, train_loss = 2.2342488274443895, train_acc = 0.996040987424313\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 210, train_loss = 2.2214828797150403, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 211, train_loss = 2.208837265847251, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 212, train_loss = 2.196322103962302, train_acc = 0.9961574289706567\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 213, train_loss = 2.1838166129309684, train_acc = 0.9962738705170004\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 214, train_loss = 2.1717936613131315, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 215, train_loss = 2.15974774886854, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 216, train_loss = 2.1477703265845776, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 217, train_loss = 2.136120165931061, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 218, train_loss = 2.1243706073146313, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 219, train_loss = 2.1130532901734114, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 220, train_loss = 2.101653757272288, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 221, train_loss = 2.0905009277630597, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 222, train_loss = 2.0795240856241435, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 223, train_loss = 2.068485173629597, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 224, train_loss = 2.057875047205016, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 225, train_loss = 2.0472639694344252, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 226, train_loss = 2.0366750236134976, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 227, train_loss = 2.0264145482797176, train_acc = 0.9963903120633442\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 228, train_loss = 2.0159609243273735, train_acc = 0.996506753609688\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 229, train_loss = 2.0060156837571412, train_acc = 0.9966231951560317\n",
      "test Acc 0.9804469273743017:\n",
      "23th- epoch: 230, train_loss = 1.9959853775799274, train_acc = 0.9967396367023754\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 231, train_loss = 1.986101985676214, train_acc = 0.9967396367023754\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 232, train_loss = 1.9763037834782153, train_acc = 0.9967396367023754\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 233, train_loss = 1.9667997125070542, train_acc = 0.9967396367023754\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 234, train_loss = 1.9572179280221462, train_acc = 0.9967396367023754\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 235, train_loss = 1.9478175286203623, train_acc = 0.9967396367023754\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 236, train_loss = 1.938394247321412, train_acc = 0.9967396367023754\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 237, train_loss = 1.929295303998515, train_acc = 0.9967396367023754\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 238, train_loss = 1.920176938874647, train_acc = 0.9967396367023754\n",
      "test Acc 0.9809124767225326:\n",
      "23th- epoch: 239, train_loss = 1.9111091059166938, train_acc = 0.9968560782487191\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 240, train_loss = 1.9023169570136815, train_acc = 0.9968560782487191\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 241, train_loss = 1.8935261040460318, train_acc = 0.9969725197950629\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 242, train_loss = 1.884793683886528, train_acc = 0.9969725197950629\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 243, train_loss = 1.8762138336896896, train_acc = 0.9969725197950629\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 244, train_loss = 1.8676543340552598, train_acc = 0.9970889613414066\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 245, train_loss = 1.8593448009341955, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 246, train_loss = 1.8510082482825965, train_acc = 0.9972054028877504\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 247, train_loss = 1.84271662379615, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 248, train_loss = 1.834682609187439, train_acc = 0.9973218444340941\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 249, train_loss = 1.8267489701975137, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 250, train_loss = 1.8187253635842353, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 251, train_loss = 1.8109428484458476, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 252, train_loss = 1.8032247691880912, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 253, train_loss = 1.7954764601308852, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 254, train_loss = 1.7880555856972933, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 255, train_loss = 1.7805249181110412, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 256, train_loss = 1.7731309898663312, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 257, train_loss = 1.765716265887022, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 258, train_loss = 1.758631782606244, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 259, train_loss = 1.7512825578451157, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 260, train_loss = 1.7442898290464655, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 261, train_loss = 1.7373548311879858, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 262, train_loss = 1.730281392694451, train_acc = 0.9974382859804378\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 263, train_loss = 1.7235156869282946, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 264, train_loss = 1.7166458740830421, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 265, train_loss = 1.7099207950523123, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 266, train_loss = 1.7033625146141276, train_acc = 0.9975547275267815\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 267, train_loss = 1.6967371677746996, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 268, train_loss = 1.6902236776659265, train_acc = 0.9975547275267815\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 269, train_loss = 1.6837084753206, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 270, train_loss = 1.6774149984121323, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 271, train_loss = 1.6711007443955168, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 272, train_loss = 1.6647424759576097, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 273, train_loss = 1.658662911504507, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 274, train_loss = 1.6523871248355135, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 275, train_loss = 1.6464622368803248, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 276, train_loss = 1.6403477787971497, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 277, train_loss = 1.6344245435902849, train_acc = 0.9976711690731253\n",
      "test Acc 0.9813780260707635:\n",
      "23th- epoch: 278, train_loss = 1.6285072279861197, train_acc = 0.9977876106194691\n",
      "test Acc 0.9818435754189944:\n",
      "23th- epoch: 279, train_loss = 1.6227782355854288, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 280, train_loss = 1.6169169110944495, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 281, train_loss = 1.6112699942896143, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 282, train_loss = 1.6055323531618342, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 283, train_loss = 1.6000192947685719, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 284, train_loss = 1.5943907623877749, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 285, train_loss = 1.588983571738936, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 286, train_loss = 1.5834366716444492, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 287, train_loss = 1.578253947198391, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 288, train_loss = 1.572840727865696, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 289, train_loss = 1.5675245287129655, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 290, train_loss = 1.5622810572385788, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 291, train_loss = 1.557219942449592, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 292, train_loss = 1.5519323250046, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 293, train_loss = 1.5469430038938299, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 294, train_loss = 1.5418394170701504, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 295, train_loss = 1.5369896864285693, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 296, train_loss = 1.5319568229606375, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 297, train_loss = 1.5271044796099886, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 298, train_loss = 1.5221951144048944, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 299, train_loss = 1.5174602953484282, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 300, train_loss = 1.5125733552267775, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 301, train_loss = 1.5079355550697073, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 302, train_loss = 1.5031502147903666, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 303, train_loss = 1.4985590180149302, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 304, train_loss = 1.4939766625175253, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 305, train_loss = 1.489434470771812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 306, train_loss = 1.4848774349084124, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 307, train_loss = 1.4804327065357938, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 308, train_loss = 1.4758946970105171, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 309, train_loss = 1.4714844264090061, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 310, train_loss = 1.4673093482851982, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 311, train_loss = 1.4628812918672338, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 312, train_loss = 1.4585680924355984, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 313, train_loss = 1.4543631859123707, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 314, train_loss = 1.4501138478517532, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 315, train_loss = 1.4460499348351732, train_acc = 0.9977876106194691\n",
      "test Acc 0.9823091247672253:\n",
      "23th- epoch: 316, train_loss = 1.4419267611810938, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 317, train_loss = 1.4377295958111063, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 318, train_loss = 1.4336622295668349, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 319, train_loss = 1.4297648729989305, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 320, train_loss = 1.4256339756539091, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 321, train_loss = 1.4216853342950344, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 322, train_loss = 1.4178672097623348, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 323, train_loss = 1.4139434160897508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 324, train_loss = 1.4100239736726508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 325, train_loss = 1.4064047957072034, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 326, train_loss = 1.4023918187012896, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 327, train_loss = 1.3987192598870024, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 328, train_loss = 1.3949244444957003, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 329, train_loss = 1.391349133104086, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 330, train_loss = 1.3875869425246492, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 331, train_loss = 1.3839201232185587, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 332, train_loss = 1.3803036758909002, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 333, train_loss = 1.3768000839045271, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 334, train_loss = 1.373167309910059, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 335, train_loss = 1.3697150064399466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 336, train_loss = 1.366096326499246, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 337, train_loss = 1.3628023751080036, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 338, train_loss = 1.3592291598324664, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 339, train_loss = 1.3557921660249121, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 340, train_loss = 1.3524980917572975, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 341, train_loss = 1.349067386239767, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 342, train_loss = 1.3457454070448875, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 343, train_loss = 1.3424854415352456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 344, train_loss = 1.3391456467215903, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 345, train_loss = 1.3359095218474977, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 346, train_loss = 1.3326414028997533, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 347, train_loss = 1.3295272502000444, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 348, train_loss = 1.326298974454403, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 349, train_loss = 1.3232313878834248, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 350, train_loss = 1.319979780644644, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 351, train_loss = 1.316975362598896, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 352, train_loss = 1.3137572072446346, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 353, train_loss = 1.310831904411316, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 354, train_loss = 1.3077188705210574, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 355, train_loss = 1.3047823049128056, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 356, train_loss = 1.3016667415504344, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 357, train_loss = 1.2986717994208448, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 358, train_loss = 1.2958014805917628, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 359, train_loss = 1.2928433691267855, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 360, train_loss = 1.2899641307885759, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 361, train_loss = 1.2871324283187278, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 362, train_loss = 1.2841687885229476, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 363, train_loss = 1.2813678954844363, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 364, train_loss = 1.2785184010863304, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 365, train_loss = 1.2757925962214358, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 366, train_loss = 1.2730110883712769, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 367, train_loss = 1.2701527823810466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 368, train_loss = 1.2674475821550004, train_acc = 0.9977876106194691\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 369, train_loss = 1.26481370505644, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 370, train_loss = 1.2619948349893093, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 371, train_loss = 1.2595213291351683, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 372, train_loss = 1.2566486584837548, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 373, train_loss = 1.254152084409725, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 374, train_loss = 1.251375148713123, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 375, train_loss = 1.2489220723509789, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 376, train_loss = 1.2463075990672223, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 377, train_loss = 1.2437095455825329, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 378, train_loss = 1.2410611945088021, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 379, train_loss = 1.2386627706582658, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 380, train_loss = 1.2360491554136388, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 381, train_loss = 1.2335849851369858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 382, train_loss = 1.2311752798850648, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 383, train_loss = 1.2286524313385598, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 384, train_loss = 1.2261585083906539, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 385, train_loss = 1.2238349914550781, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 386, train_loss = 1.2213427536189556, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 387, train_loss = 1.2189809058909304, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 388, train_loss = 1.2165106634492986, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 389, train_loss = 1.214250264049042, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 390, train_loss = 1.2118027471005917, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 391, train_loss = 1.2095792864565738, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 392, train_loss = 1.2072377589647658, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 393, train_loss = 1.2049692869186401, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 394, train_loss = 1.2025923530454747, train_acc = 0.9979040521658128\n",
      "test Acc 0.9827746741154563:\n",
      "23th- epoch: 395, train_loss = 1.2003191101248376, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 396, train_loss = 1.1980691042845137, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 397, train_loss = 1.1959611351485364, train_acc = 0.9979040521658128\n",
      "test Acc 0.9832402234636871:\n",
      "23th- epoch: 398, train_loss = 1.193632010370493, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 399, train_loss = 1.1913380660116673, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 400, train_loss = 1.1891965928371064, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 401, train_loss = 1.1869370850617997, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 402, train_loss = 1.1848279697005637, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 403, train_loss = 1.1825706101953983, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 404, train_loss = 1.180522482842207, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 405, train_loss = 1.1783446346526034, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 406, train_loss = 1.1763494238257408, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 407, train_loss = 1.1741236485540867, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 408, train_loss = 1.1720780183677562, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 409, train_loss = 1.1699615741963498, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 410, train_loss = 1.1678112708032131, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 411, train_loss = 1.1658796767587774, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 412, train_loss = 1.1637961069936864, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 413, train_loss = 1.1617294127936475, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 414, train_loss = 1.1597567076678388, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 415, train_loss = 1.1576478120987304, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 416, train_loss = 1.1557245701551437, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 417, train_loss = 1.1537005205755122, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 418, train_loss = 1.151771690696478, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 419, train_loss = 1.1498121333424933, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 420, train_loss = 1.1477105294470675, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 421, train_loss = 1.1459772040252574, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 422, train_loss = 1.1440446637570858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 423, train_loss = 1.141978292434942, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 424, train_loss = 1.1402370023424737, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 425, train_loss = 1.1382722568814643, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 426, train_loss = 1.1364294774830341, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 427, train_loss = 1.134554350108374, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 428, train_loss = 1.132609597116243, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 429, train_loss = 1.130875613540411, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 430, train_loss = 1.12893895059824, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 431, train_loss = 1.127027701586485, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 432, train_loss = 1.1253559949691407, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 433, train_loss = 1.1234011041815393, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 434, train_loss = 1.121737678826321, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 435, train_loss = 1.1199477327172644, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 436, train_loss = 1.1181779839098454, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 437, train_loss = 1.1163605327601545, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 438, train_loss = 1.1146910290117376, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 439, train_loss = 1.1128338699345477, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 440, train_loss = 1.1111077343230136, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 441, train_loss = 1.1094553085567895, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23th- epoch: 442, train_loss = 1.107574600726366, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 443, train_loss = 1.1061287882330362, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 444, train_loss = 1.1042672941985074, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 445, train_loss = 1.102620493620634, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 446, train_loss = 1.100856889039278, train_acc = 0.9979040521658128\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 447, train_loss = 1.099184555321699, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 448, train_loss = 1.0977034444513265, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 449, train_loss = 1.095931425690651, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 450, train_loss = 1.0942883292736951, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 451, train_loss = 1.092645096272463, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 452, train_loss = 1.090993254125351, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 453, train_loss = 1.089327017456526, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 454, train_loss = 1.087765230477089, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 455, train_loss = 1.0862462272343691, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 456, train_loss = 1.0845156895520631, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 457, train_loss = 1.0830293409526348, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 458, train_loss = 1.0814117342233658, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 459, train_loss = 1.0797720402479172, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 460, train_loss = 1.0782259826955851, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 461, train_loss = 1.076640227198368, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 462, train_loss = 1.0750927031040192, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 463, train_loss = 1.0735839580593165, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 464, train_loss = 1.071983123809332, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 465, train_loss = 1.0705792581138667, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 466, train_loss = 1.069013923406601, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 467, train_loss = 1.0674248275754508, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 468, train_loss = 1.0660135062935296, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 469, train_loss = 1.0644258918764535, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 470, train_loss = 1.063001083821291, train_acc = 0.9980204937121565\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 471, train_loss = 1.0614311719837133, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 472, train_loss = 1.0599032950995024, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 473, train_loss = 1.0584360795619432, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 474, train_loss = 1.0569549972715322, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 475, train_loss = 1.0554890930652618, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 476, train_loss = 1.0540948696434498, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 477, train_loss = 1.0526259802281857, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 478, train_loss = 1.0512779168784618, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 479, train_loss = 1.0497624998388346, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 480, train_loss = 1.048401086271042, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 481, train_loss = 1.0469140174391214, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 482, train_loss = 1.0456070341169834, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 483, train_loss = 1.0441268334689084, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 484, train_loss = 1.0429264903068542, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 485, train_loss = 1.0414209167065565, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 486, train_loss = 1.0400517048838083, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 487, train_loss = 1.038651131093502, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 488, train_loss = 1.0374525090155657, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 489, train_loss = 1.0360047606227454, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 490, train_loss = 1.0346688007412013, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 491, train_loss = 1.0333439832029399, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 492, train_loss = 1.03201494118548, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 493, train_loss = 1.0307246260344982, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 494, train_loss = 1.0293074598012026, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 495, train_loss = 1.0281772328016814, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 496, train_loss = 1.0266955085098743, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 497, train_loss = 1.0254148033855017, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 498, train_loss = 1.0241019191744272, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n",
      "23th- epoch: 499, train_loss = 1.0228320819733199, train_acc = 0.9981369352585002\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████████████████████████████████████████████████████▏                | 23/30 [2:37:03<47:56, 410.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "24th- epoch: 0, train_loss = 273.88004529476166, train_acc = 0.39683278993945037\n",
      "test Acc 0.5549348230912476:\n",
      "24th- epoch: 1, train_loss = 211.19254004955292, train_acc = 0.5569399161620866\n",
      "test Acc 0.5702979515828678:\n",
      "24th- epoch: 2, train_loss = 161.92205208539963, train_acc = 0.5881462505822077\n",
      "test Acc 0.6289571694599627:\n",
      "24th- epoch: 3, train_loss = 135.68613547086716, train_acc = 0.6686073591057289\n",
      "test Acc 0.7136871508379888:\n",
      "24th- epoch: 4, train_loss = 117.41164827346802, train_acc = 0.7369585468095017\n",
      "test Acc 0.75512104283054:\n",
      "24th- epoch: 5, train_loss = 102.68581363558769, train_acc = 0.7633907778295296\n",
      "test Acc 0.7760707635009311:\n",
      "24th- epoch: 6, train_loss = 90.61756184697151, train_acc = 0.7815556590591523\n",
      "test Acc 0.7942271880819367:\n",
      "24th- epoch: 7, train_loss = 80.76991009712219, train_acc = 0.8042617605961807\n",
      "test Acc 0.8226256983240223:\n",
      "24th- epoch: 8, train_loss = 72.50384366512299, train_acc = 0.8316255239869585\n",
      "test Acc 0.8375232774674115:\n",
      "24th- epoch: 9, train_loss = 65.35031354427338, train_acc = 0.8510712622263623\n",
      "test Acc 0.8603351955307262:\n",
      "24th- epoch: 10, train_loss = 59.068313643336296, train_acc = 0.8695854680950164\n",
      "test Acc 0.87756052141527:\n",
      "24th- epoch: 11, train_loss = 53.54414799809456, train_acc = 0.8890312063344201\n",
      "test Acc 0.898975791433892:\n",
      "24th- epoch: 12, train_loss = 48.681378930807114, train_acc = 0.9099906846762925\n",
      "test Acc 0.9208566108007449:\n",
      "24th- epoch: 13, train_loss = 44.391858860850334, train_acc = 0.9250116441546343\n",
      "test Acc 0.9329608938547486:\n",
      "24th- epoch: 14, train_loss = 40.622806534171104, train_acc = 0.9329296693060084\n",
      "test Acc 0.9376163873370578:\n",
      "24th- epoch: 15, train_loss = 37.331348307430744, train_acc = 0.9392175128085701\n",
      "test Acc 0.9399441340782123:\n",
      "24th- epoch: 16, train_loss = 34.47371155768633, train_acc = 0.9420121099208197\n",
      "test Acc 0.9436685288640596:\n",
      "24th- epoch: 17, train_loss = 32.00469073653221, train_acc = 0.9444573823940382\n",
      "test Acc 0.9483240223463687:\n",
      "24th- epoch: 18, train_loss = 29.875583194196224, train_acc = 0.9465533302282254\n",
      "test Acc 0.9497206703910615:\n",
      "24th- epoch: 19, train_loss = 28.03706593811512, train_acc = 0.952026082906381\n",
      "test Acc 0.9539106145251397:\n",
      "24th- epoch: 20, train_loss = 26.44403651356697, train_acc = 0.9551700046576619\n",
      "test Acc 0.9553072625698324:\n",
      "24th- epoch: 21, train_loss = 25.056608133018017, train_acc = 0.9568001863064741\n",
      "test Acc 0.9557728119180633:\n",
      "24th- epoch: 22, train_loss = 23.841025792062283, train_acc = 0.9586632510479739\n",
      "test Acc 0.9567039106145251:\n",
      "24th- epoch: 23, train_loss = 22.76562423631549, train_acc = 0.96040987424313\n",
      "test Acc 0.9585661080074488:\n",
      "24th- epoch: 24, train_loss = 21.80865441635251, train_acc = 0.9613414066138798\n",
      "test Acc 0.9599627560521415:\n",
      "24th- epoch: 25, train_loss = 20.951162237673998, train_acc = 0.9619236143455985\n",
      "test Acc 0.9604283054003724:\n",
      "24th- epoch: 26, train_loss = 20.177668683230877, train_acc = 0.9632044713553796\n",
      "test Acc 0.9608938547486033:\n",
      "24th- epoch: 27, train_loss = 19.474852863699198, train_acc = 0.9637866790870983\n",
      "test Acc 0.9613594040968343:\n",
      "24th- epoch: 28, train_loss = 18.831308413296938, train_acc = 0.9646017699115044\n",
      "test Acc 0.9613594040968343:\n",
      "24th- epoch: 29, train_loss = 18.238315477967262, train_acc = 0.9653004191895669\n",
      "test Acc 0.9618249534450651:\n",
      "24th- epoch: 30, train_loss = 17.689530301839113, train_acc = 0.9658826269212856\n",
      "test Acc 0.9618249534450651:\n",
      "24th- epoch: 31, train_loss = 17.179675087332726, train_acc = 0.966581276199348\n",
      "test Acc 0.9618249534450651:\n",
      "24th- epoch: 32, train_loss = 16.70395841822028, train_acc = 0.9672799254774104\n",
      "test Acc 0.962756052141527:\n",
      "24th- epoch: 33, train_loss = 16.258065275847912, train_acc = 0.9686772240335352\n",
      "test Acc 0.9636871508379888:\n",
      "24th- epoch: 34, train_loss = 15.838520385324955, train_acc = 0.97007452258966\n",
      "test Acc 0.9641527001862198:\n",
      "24th- epoch: 35, train_loss = 15.443015914410353, train_acc = 0.9712389380530974\n",
      "test Acc 0.9669459962756052:\n",
      "24th- epoch: 36, train_loss = 15.069345388561487, train_acc = 0.9726362366092222\n",
      "test Acc 0.9678770949720671:\n",
      "24th- epoch: 37, train_loss = 14.715820278972387, train_acc = 0.9733348858872846\n",
      "test Acc 0.9692737430167597:\n",
      "24th- epoch: 38, train_loss = 14.38036384806037, train_acc = 0.9738006520726595\n",
      "test Acc 0.9702048417132216:\n",
      "24th- epoch: 39, train_loss = 14.06177805364132, train_acc = 0.9742664182580345\n",
      "test Acc 0.9711359404096834:\n",
      "24th- epoch: 40, train_loss = 13.758640926331282, train_acc = 0.9754308337214718\n",
      "test Acc 0.9716014897579144:\n",
      "24th- epoch: 41, train_loss = 13.46924313902855, train_acc = 0.975780158360503\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 42, train_loss = 13.192460659891367, train_acc = 0.9760130414531905\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 43, train_loss = 12.927431229501963, train_acc = 0.9767116907312529\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 44, train_loss = 12.673398457467556, train_acc = 0.9770610153702841\n",
      "test Acc 0.9720670391061452:\n",
      "24th- epoch: 45, train_loss = 12.429291270673275, train_acc = 0.9775267815556591\n",
      "test Acc 0.9725325884543762:\n",
      "24th- epoch: 46, train_loss = 12.194188844412565, train_acc = 0.9776432231020028\n",
      "test Acc 0.972998137802607:\n",
      "24th- epoch: 47, train_loss = 11.967687971889973, train_acc = 0.9778761061946902\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 48, train_loss = 11.74893743172288, train_acc = 0.977992547741034\n",
      "test Acc 0.973463687150838:\n",
      "24th- epoch: 49, train_loss = 11.53765569627285, train_acc = 0.9782254308337215\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 50, train_loss = 11.333938516676426, train_acc = 0.9785747554727526\n",
      "test Acc 0.9739292364990689:\n",
      "24th- epoch: 51, train_loss = 11.137403953820467, train_acc = 0.9795062878435026\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 52, train_loss = 10.947516106069088, train_acc = 0.9799720540288775\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 53, train_loss = 10.763887852430344, train_acc = 0.9800884955752213\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 54, train_loss = 10.586070157587528, train_acc = 0.9803213786679087\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 55, train_loss = 10.413924854248762, train_acc = 0.9809035863996274\n",
      "test Acc 0.9743947858472998:\n",
      "24th- epoch: 56, train_loss = 10.247149586677551, train_acc = 0.9813693525850024\n",
      "test Acc 0.9748603351955307:\n",
      "24th- epoch: 57, train_loss = 10.085269059985876, train_acc = 0.9814857941313461\n",
      "test Acc 0.9753258845437617:\n",
      "24th- epoch: 58, train_loss = 9.927948493510485, train_acc = 0.981951560316721\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 59, train_loss = 9.77483175508678, train_acc = 0.9824173265020959\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 60, train_loss = 9.625856794416904, train_acc = 0.9824173265020959\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 61, train_loss = 9.480562655255198, train_acc = 0.9827666511411272\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 62, train_loss = 9.338906951248646, train_acc = 0.9828830926874709\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 63, train_loss = 9.200433807447553, train_acc = 0.9828830926874709\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 64, train_loss = 9.06514510139823, train_acc = 0.9828830926874709\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 65, train_loss = 8.933235447853804, train_acc = 0.9831159757801584\n",
      "test Acc 0.9757914338919925:\n",
      "24th- epoch: 66, train_loss = 8.80431880056858, train_acc = 0.9833488588728458\n",
      "test Acc 0.9762569832402235:\n",
      "24th- epoch: 67, train_loss = 8.6783318631351, train_acc = 0.9835817419655333\n",
      "test Acc 0.9767225325884544:\n",
      "24th- epoch: 68, train_loss = 8.555122336372733, train_acc = 0.9835817419655333\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 69, train_loss = 8.434632323682308, train_acc = 0.983698183511877\n",
      "test Acc 0.9776536312849162:\n",
      "24th- epoch: 70, train_loss = 8.316646197810769, train_acc = 0.983698183511877\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 71, train_loss = 8.200822863727808, train_acc = 0.9839310666045645\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 72, train_loss = 8.087316405028105, train_acc = 0.984163949697252\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 73, train_loss = 7.976052092388272, train_acc = 0.9846297158826269\n",
      "test Acc 0.9781191806331471:\n",
      "24th- epoch: 74, train_loss = 7.8669194560498, train_acc = 0.9847461574289706\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 75, train_loss = 7.759976653382182, train_acc = 0.9849790405216581\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 76, train_loss = 7.655129501596093, train_acc = 0.9850954820680019\n",
      "test Acc 0.978584729981378:\n",
      "24th- epoch: 77, train_loss = 7.552086507901549, train_acc = 0.985444806707033\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 78, train_loss = 7.451197171583772, train_acc = 0.9856776897997206\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 79, train_loss = 7.35207287222147, train_acc = 0.9860270144387517\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 80, train_loss = 7.254829358309507, train_acc = 0.9860270144387517\n",
      "test Acc 0.979050279329609:\n",
      "24th- epoch: 81, train_loss = 7.159272665157914, train_acc = 0.9862598975314392\n",
      "test Acc 0.9795158286778398:\n",
      "24th- epoch: 82, train_loss = 7.065436547622085, train_acc = 0.986376339077783\n",
      "test Acc 0.9795158286778398:\n",
      "24th- epoch: 83, train_loss = 6.973333789035678, train_acc = 0.9866092221704704\n",
      "test Acc 0.9799813780260708:\n",
      "24th- epoch: 84, train_loss = 6.882819794118404, train_acc = 0.9867256637168141\n",
      "test Acc 0.9804469273743017:\n",
      "24th- epoch: 85, train_loss = 6.793962130323052, train_acc = 0.9868421052631579\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 86, train_loss = 6.7069489993155, train_acc = 0.9868421052631579\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 87, train_loss = 6.621489867568016, train_acc = 0.9871914299021891\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 88, train_loss = 6.537491023540497, train_acc = 0.9873078714485328\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 89, train_loss = 6.455209452658892, train_acc = 0.9874243129948765\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 90, train_loss = 6.3745315708220005, train_acc = 0.9876571960875641\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 91, train_loss = 6.295254984870553, train_acc = 0.9876571960875641\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 92, train_loss = 6.217561569064856, train_acc = 0.9878900791802515\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 93, train_loss = 6.141145693138242, train_acc = 0.9878900791802515\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 94, train_loss = 6.066199619323015, train_acc = 0.9880065207265952\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 95, train_loss = 5.992566017434001, train_acc = 0.9881229622729389\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 96, train_loss = 5.920375632122159, train_acc = 0.9885887284583139\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 97, train_loss = 5.8494642823934555, train_acc = 0.9887051700046576\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 98, train_loss = 5.779964674264193, train_acc = 0.9888216115510013\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 99, train_loss = 5.7117795664817095, train_acc = 0.9892873777363763\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 100, train_loss = 5.64487618021667, train_acc = 0.9892873777363763\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 101, train_loss = 5.5793378464877605, train_acc = 0.98940381928272\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 102, train_loss = 5.514870639890432, train_acc = 0.9897531439217513\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 103, train_loss = 5.451505597680807, train_acc = 0.989869585468095\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 104, train_loss = 5.389264525845647, train_acc = 0.9901024685607824\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 105, train_loss = 5.328217048197985, train_acc = 0.9902189101071263\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 106, train_loss = 5.2683373875916, train_acc = 0.9905682347461574\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 107, train_loss = 5.209400903433561, train_acc = 0.9906846762925011\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 108, train_loss = 5.151800299063325, train_acc = 0.9910340009315324\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 109, train_loss = 5.095041929744184, train_acc = 0.9910340009315324\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 110, train_loss = 5.039355133660138, train_acc = 0.9912668840242198\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 111, train_loss = 4.984714492224157, train_acc = 0.9913833255705635\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 112, train_loss = 4.931123252026737, train_acc = 0.9916162086632511\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 113, train_loss = 4.87848546449095, train_acc = 0.9916162086632511\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 114, train_loss = 4.8267792025581, train_acc = 0.9917326502095948\n",
      "test Acc 0.9818435754189944:\n",
      "24th- epoch: 115, train_loss = 4.77602591086179, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 116, train_loss = 4.726171221584082, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 117, train_loss = 4.677209851332009, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 118, train_loss = 4.629098731093109, train_acc = 0.992081974848626\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 119, train_loss = 4.581766406074166, train_acc = 0.9921984163949698\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 120, train_loss = 4.535335862077773, train_acc = 0.9921984163949698\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 121, train_loss = 4.489586030133069, train_acc = 0.9921984163949698\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 122, train_loss = 4.4446042673662305, train_acc = 0.9923148579413135\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 123, train_loss = 4.400310198776424, train_acc = 0.9924312994876572\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 124, train_loss = 4.356744286604226, train_acc = 0.9924312994876572\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 125, train_loss = 4.314039285294712, train_acc = 0.9925477410340009\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 126, train_loss = 4.271907618269324, train_acc = 0.9926641825803446\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 127, train_loss = 4.230579626746476, train_acc = 0.9926641825803446\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 128, train_loss = 4.189881626516581, train_acc = 0.9927806241266884\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 129, train_loss = 4.149906533770263, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 130, train_loss = 4.110421146266162, train_acc = 0.9928970656730322\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 131, train_loss = 4.071650872007012, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 132, train_loss = 4.033503036946058, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 133, train_loss = 3.995900937356055, train_acc = 0.9932463903120633\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 134, train_loss = 3.958977345377207, train_acc = 0.9934792734047508\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 135, train_loss = 3.9226151276379824, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 136, train_loss = 3.8866615956649184, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 137, train_loss = 3.851310999132693, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 138, train_loss = 3.8163316072896123, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 139, train_loss = 3.7819038992747664, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 140, train_loss = 3.7480701887980103, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 141, train_loss = 3.7147155171260238, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 142, train_loss = 3.681790509261191, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 143, train_loss = 3.649387654848397, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 144, train_loss = 3.6174828689545393, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 145, train_loss = 3.585961960721761, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 146, train_loss = 3.554908651858568, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 147, train_loss = 3.5242645498365164, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 148, train_loss = 3.494058198761195, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 149, train_loss = 3.4642082676291466, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 150, train_loss = 3.4349462874233723, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 151, train_loss = 3.4058463969267905, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 152, train_loss = 3.3772767200134695, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 153, train_loss = 3.349174057599157, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 154, train_loss = 3.3213113960810006, train_acc = 0.9947601304145319\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 155, train_loss = 3.2939141504466534, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 156, train_loss = 3.266962795984, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 157, train_loss = 3.240314758848399, train_acc = 0.9948765719608756\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 158, train_loss = 3.214098159223795, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 159, train_loss = 3.18825482390821, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 160, train_loss = 3.1627352288924158, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 161, train_loss = 3.1375673972070217, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 162, train_loss = 3.112785935867578, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 163, train_loss = 3.088331702630967, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 164, train_loss = 3.064171811565757, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 165, train_loss = 3.040389873087406, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 166, train_loss = 3.0168344862759113, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 167, train_loss = 2.9937559328973293, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 168, train_loss = 2.9708034680224955, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 169, train_loss = 2.948299266397953, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 170, train_loss = 2.925992224365473, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 171, train_loss = 2.904053730890155, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 172, train_loss = 2.882312749978155, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 173, train_loss = 2.860928002279252, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 174, train_loss = 2.839691745582968, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 175, train_loss = 2.8187945862300694, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 176, train_loss = 2.7981411959044635, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 177, train_loss = 2.77775895409286, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 178, train_loss = 2.7577068861573935, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 179, train_loss = 2.737841624300927, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 180, train_loss = 2.7182489782571793, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 181, train_loss = 2.6988794808275998, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 182, train_loss = 2.6797052822075784, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 183, train_loss = 2.6608640081249177, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 184, train_loss = 2.642254222650081, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 185, train_loss = 2.623873964417726, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 186, train_loss = 2.6057538241147995, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 187, train_loss = 2.5877689123153687, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 188, train_loss = 2.570209791418165, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 189, train_loss = 2.552738879341632, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 190, train_loss = 2.5355745628476143, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 191, train_loss = 2.518628519028425, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 192, train_loss = 2.501859813928604, train_acc = 0.9956916627852818\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 193, train_loss = 2.485343103064224, train_acc = 0.9958081043316255\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 194, train_loss = 2.469010376604274, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 195, train_loss = 2.4528908133506775, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 196, train_loss = 2.4370654716622084, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 197, train_loss = 2.4213958773761988, train_acc = 0.9958081043316255\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 198, train_loss = 2.406008055433631, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 199, train_loss = 2.3906530167441815, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 200, train_loss = 2.375733368098736, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 201, train_loss = 2.3608260329347104, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 202, train_loss = 2.346104485914111, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 203, train_loss = 2.331591213820502, train_acc = 0.9959245458779693\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 204, train_loss = 2.3173121742438525, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 205, train_loss = 2.3032106801401824, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 206, train_loss = 2.2892419893760234, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 207, train_loss = 2.2754862140864134, train_acc = 0.996040987424313\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 208, train_loss = 2.26190975937061, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 209, train_loss = 2.248538611456752, train_acc = 0.9961574289706567\n",
      "test Acc 0.9823091247672253:\n",
      "24th- epoch: 210, train_loss = 2.2352841820102185, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 211, train_loss = 2.2222682654391974, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 212, train_loss = 2.2094152469653636, train_acc = 0.9961574289706567\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 213, train_loss = 2.1966423883568496, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 214, train_loss = 2.184232070343569, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 215, train_loss = 2.1718633379787207, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 216, train_loss = 2.1595963786821812, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 217, train_loss = 2.147559490054846, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 218, train_loss = 2.135720235062763, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 219, train_loss = 2.123856346355751, train_acc = 0.9962738705170004\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 220, train_loss = 2.1123316835146397, train_acc = 0.9963903120633442\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 221, train_loss = 2.100830365670845, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 222, train_loss = 2.08957379614003, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 223, train_loss = 2.0784428145270795, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 224, train_loss = 2.067425787448883, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 225, train_loss = 2.05656750430353, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 226, train_loss = 2.045836844248697, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 227, train_loss = 2.0351710983086377, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 228, train_loss = 2.024851931259036, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 229, train_loss = 2.014438809128478, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 230, train_loss = 2.0042911923956126, train_acc = 0.996506753609688\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 231, train_loss = 1.9941907562315464, train_acc = 0.9966231951560317\n",
      "test Acc 0.9827746741154563:\n",
      "24th- epoch: 232, train_loss = 1.9842440243810415, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 233, train_loss = 1.9744149383623153, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 234, train_loss = 1.9646768860984594, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 235, train_loss = 1.9550818596035242, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 236, train_loss = 1.9456479493528605, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 237, train_loss = 1.9363520822953433, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 238, train_loss = 1.9270626318175346, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 239, train_loss = 1.9178554471582174, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 240, train_loss = 1.908928770571947, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 241, train_loss = 1.8999601993709803, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 242, train_loss = 1.8911548741161823, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 243, train_loss = 1.8824390333611518, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 244, train_loss = 1.8738346316386014, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 245, train_loss = 1.8653323103208095, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 246, train_loss = 1.8568740009795874, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 247, train_loss = 1.8486743711400777, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 248, train_loss = 1.8404650458833203, train_acc = 0.9968560782487191\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 249, train_loss = 1.8323475992074236, train_acc = 0.9969725197950629\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 250, train_loss = 1.8243667552014813, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 251, train_loss = 1.8163932313909754, train_acc = 0.9970889613414066\n",
      "test Acc 0.9832402234636871:\n",
      "24th- epoch: 252, train_loss = 1.8086193464696407, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 253, train_loss = 1.8008746057748795, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 254, train_loss = 1.7931338796624914, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 255, train_loss = 1.7856180630624294, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 256, train_loss = 1.7780927693238482, train_acc = 0.9970889613414066\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 257, train_loss = 1.770775444805622, train_acc = 0.9970889613414066\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 258, train_loss = 1.7633677957346663, train_acc = 0.9972054028877504\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 259, train_loss = 1.756111342459917, train_acc = 0.9973218444340941\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 260, train_loss = 1.7489202842116356, train_acc = 0.9973218444340941\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 261, train_loss = 1.7419437629869208, train_acc = 0.9974382859804378\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 262, train_loss = 1.7348756542196497, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 263, train_loss = 1.727897254168056, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 264, train_loss = 1.7210802374174818, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 265, train_loss = 1.7143210222711787, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 266, train_loss = 1.707620583474636, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 267, train_loss = 1.700934169231914, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 268, train_loss = 1.6943442138144746, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 269, train_loss = 1.6878409162163734, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 270, train_loss = 1.6814430579543114, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 271, train_loss = 1.6750928474357352, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 272, train_loss = 1.6687805181136355, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 273, train_loss = 1.6624964214861393, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 274, train_loss = 1.6563859457382932, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 275, train_loss = 1.6502329409122467, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 276, train_loss = 1.6441478108754382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 277, train_loss = 1.638214573264122, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 278, train_loss = 1.6322702007601038, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 279, train_loss = 1.6263980070361868, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 280, train_loss = 1.6205295398831367, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 281, train_loss = 1.6147973276674747, train_acc = 0.9975547275267815\n",
      "test Acc 0.9837057728119181:\n",
      "24th- epoch: 282, train_loss = 1.6090918108820915, train_acc = 0.9975547275267815\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 283, train_loss = 1.6033867709338665, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 284, train_loss = 1.5978486463427544, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 285, train_loss = 1.592257903306745, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 286, train_loss = 1.5867593797156587, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 287, train_loss = 1.5813860669732094, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 288, train_loss = 1.5759612247347832, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 289, train_loss = 1.570619985461235, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 290, train_loss = 1.565369481802918, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 291, train_loss = 1.5601457270095125, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 292, train_loss = 1.5549380605807528, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 293, train_loss = 1.5498271050164476, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 294, train_loss = 1.5446808636188507, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24th- epoch: 295, train_loss = 1.539748671115376, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 296, train_loss = 1.5347542675444856, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 297, train_loss = 1.529793450026773, train_acc = 0.9976711690731253\n",
      "test Acc 0.984171322160149:\n",
      "24th- epoch: 298, train_loss = 1.5249038835754618, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 299, train_loss = 1.5199642106890678, train_acc = 0.9976711690731253\n",
      "test Acc 0.9846368715083799:\n",
      "24th- epoch: 300, train_loss = 1.5152319023618475, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 301, train_loss = 1.5104677738854662, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 302, train_loss = 1.50570772215724, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 303, train_loss = 1.5010340673616156, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 304, train_loss = 1.4964772835373878, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 305, train_loss = 1.491827815771103, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 306, train_loss = 1.4872627258300781, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 307, train_loss = 1.4827456498751417, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 308, train_loss = 1.4782508512726054, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 309, train_loss = 1.4738242527237162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 310, train_loss = 1.469397857785225, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 311, train_loss = 1.465060149668716, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 312, train_loss = 1.4607741808285937, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 313, train_loss = 1.4564864076673985, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 314, train_loss = 1.4521848658332601, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 315, train_loss = 1.447957318276167, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 316, train_loss = 1.4438878906075843, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 317, train_loss = 1.4396206624805927, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 318, train_loss = 1.4355674150283448, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 319, train_loss = 1.4315040322835557, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 320, train_loss = 1.427434265613556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 321, train_loss = 1.4234517614240758, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 322, train_loss = 1.4194634693558328, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 323, train_loss = 1.4154901678557508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 324, train_loss = 1.411574310332071, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 325, train_loss = 1.4077404265408404, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 326, train_loss = 1.4038277168874629, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 327, train_loss = 1.4000766910612583, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 328, train_loss = 1.3962156511843204, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 329, train_loss = 1.3924083188176155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 330, train_loss = 1.3887482757563703, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 331, train_loss = 1.3850041143596172, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 332, train_loss = 1.3813628504867665, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 333, train_loss = 1.3776042871177197, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 334, train_loss = 1.3740724734961987, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 335, train_loss = 1.3704621158540249, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 336, train_loss = 1.3669146336615086, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 337, train_loss = 1.363351073116064, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 338, train_loss = 1.359872706234455, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 339, train_loss = 1.3564035544986837, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 340, train_loss = 1.3529133672709577, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 341, train_loss = 1.3495947805349715, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 342, train_loss = 1.3460906979744323, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 343, train_loss = 1.342789951711893, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 344, train_loss = 1.339376608550083, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 345, train_loss = 1.3360618104343303, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 346, train_loss = 1.33275606733514, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 347, train_loss = 1.3294519533519633, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 348, train_loss = 1.3262214275891893, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 349, train_loss = 1.3229863420128822, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 350, train_loss = 1.3197715766727924, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 351, train_loss = 1.3166103661060333, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 352, train_loss = 1.3133715602452867, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 353, train_loss = 1.3103406342561357, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 354, train_loss = 1.3071979247033596, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 355, train_loss = 1.3041202525491826, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 356, train_loss = 1.3009552719886415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 357, train_loss = 1.2979415294830687, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 358, train_loss = 1.2948019380564801, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 359, train_loss = 1.2917302399873734, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 360, train_loss = 1.2888345743413083, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 361, train_loss = 1.2857452903990634, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 362, train_loss = 1.282808440446388, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 363, train_loss = 1.27985954657197, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 364, train_loss = 1.2768878415226936, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 365, train_loss = 1.2738453410565853, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 366, train_loss = 1.2709300418500789, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 367, train_loss = 1.2681450098752975, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 368, train_loss = 1.26527614769293, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 369, train_loss = 1.2625433330540545, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 370, train_loss = 1.2597523641888984, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 371, train_loss = 1.2570282096858136, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 372, train_loss = 1.2542562770540826, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 373, train_loss = 1.251596191257704, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 374, train_loss = 1.2489438876509666, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 375, train_loss = 1.2462036100332625, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 376, train_loss = 1.2435314804315567, train_acc = 0.9977876106194691\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 377, train_loss = 1.2409099389915355, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 378, train_loss = 1.2382450203294866, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 379, train_loss = 1.235634372860659, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 380, train_loss = 1.2330945034627803, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 381, train_loss = 1.2305534605984576, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 382, train_loss = 1.2278781980276108, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 383, train_loss = 1.2254809873993509, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 384, train_loss = 1.2228413869743235, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 385, train_loss = 1.2203625899855979, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 386, train_loss = 1.2179467802052386, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 387, train_loss = 1.2154594448511489, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 388, train_loss = 1.213037105917465, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 389, train_loss = 1.2105525669758208, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 390, train_loss = 1.208258617669344, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 391, train_loss = 1.205778531730175, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 392, train_loss = 1.2034007708425634, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 393, train_loss = 1.2010840264265426, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 394, train_loss = 1.1987230691011064, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 395, train_loss = 1.1963481456041336, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 396, train_loss = 1.1941130024497397, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 397, train_loss = 1.1917998380959034, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 398, train_loss = 1.1894537471234798, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 399, train_loss = 1.1872816656832583, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 400, train_loss = 1.184964305430185, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 401, train_loss = 1.1827303804457188, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 402, train_loss = 1.1804319967632182, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 403, train_loss = 1.17827033624053, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 404, train_loss = 1.1760501811804716, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 405, train_loss = 1.1738813581469003, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 406, train_loss = 1.171716288983589, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 407, train_loss = 1.1695716629328672, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 408, train_loss = 1.1673999900522176, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 409, train_loss = 1.1652347917261068, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 410, train_loss = 1.1631638780236244, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 411, train_loss = 1.1611452884972095, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 412, train_loss = 1.1589498246612493, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 413, train_loss = 1.1568568808434065, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 414, train_loss = 1.1547980221512262, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 415, train_loss = 1.1527803962526377, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 416, train_loss = 1.1507136635482311, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 417, train_loss = 1.1487203277647495, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 418, train_loss = 1.1466403727827128, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 419, train_loss = 1.1446214926836547, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 420, train_loss = 1.142661272227997, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 421, train_loss = 1.1406319414672907, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 422, train_loss = 1.1387161575257778, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 423, train_loss = 1.1367060256598052, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 424, train_loss = 1.1346924317476805, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 425, train_loss = 1.1326468313636724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 426, train_loss = 1.1307657050492708, train_acc = 0.9979040521658128\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 427, train_loss = 1.1288174440560397, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 428, train_loss = 1.1268378856184427, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 429, train_loss = 1.1250261180102825, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 430, train_loss = 1.1230891582963523, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 431, train_loss = 1.121214280516142, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 432, train_loss = 1.1194077307882253, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 433, train_loss = 1.1175813836453017, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 434, train_loss = 1.115628787636524, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 435, train_loss = 1.1138620227575302, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 436, train_loss = 1.1120986925961915, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 437, train_loss = 1.1102142495510634, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 438, train_loss = 1.1084434588847216, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 439, train_loss = 1.1065806175174657, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 440, train_loss = 1.104858780890936, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 441, train_loss = 1.1031228353676852, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 442, train_loss = 1.1013588309288025, train_acc = 0.9980204937121565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 443, train_loss = 1.0995847508311272, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 444, train_loss = 1.097835548222065, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 445, train_loss = 1.0961335934698582, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 446, train_loss = 1.094397203385597, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 447, train_loss = 1.0927118696272373, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 448, train_loss = 1.0910082968475763, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 449, train_loss = 1.0893174149096012, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 450, train_loss = 1.0875677205622196, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 451, train_loss = 1.085970072686905, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 452, train_loss = 1.0842178141174372, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 453, train_loss = 1.0826326248643454, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 454, train_loss = 1.0809582558867987, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 455, train_loss = 1.0793298246862832, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 456, train_loss = 1.0776555562915746, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 457, train_loss = 1.0761030241847038, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 458, train_loss = 1.0744121596217155, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 459, train_loss = 1.0729097475705203, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 460, train_loss = 1.0712701492011547, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 461, train_loss = 1.0696890652179718, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 462, train_loss = 1.0680620968341827, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 463, train_loss = 1.066500951856142, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 464, train_loss = 1.064968249440426, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 465, train_loss = 1.0633166581392288, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 466, train_loss = 1.0617364247736987, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 467, train_loss = 1.060236786812311, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 468, train_loss = 1.0586595448257867, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 469, train_loss = 1.0571798880991992, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 470, train_loss = 1.0556119816901628, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 471, train_loss = 1.0541862485406455, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 472, train_loss = 1.052597988396883, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 473, train_loss = 1.0511456703243311, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 474, train_loss = 1.0496379186806735, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 475, train_loss = 1.0482331030070782, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 476, train_loss = 1.046700311213499, train_acc = 0.9980204937121565\n",
      "test Acc 0.9851024208566108:\n",
      "24th- epoch: 477, train_loss = 1.0452704851923045, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 478, train_loss = 1.04379709935165, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 479, train_loss = 1.04224836701178, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 480, train_loss = 1.0409327931702137, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 481, train_loss = 1.0394369711575564, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 482, train_loss = 1.0380527252855245, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 483, train_loss = 1.036640428006649, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 484, train_loss = 1.0352065736951772, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 485, train_loss = 1.0338190756738186, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 486, train_loss = 1.0323597329261247, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 487, train_loss = 1.0309790981409606, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 488, train_loss = 1.0295548029243946, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 489, train_loss = 1.0282149501144886, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 490, train_loss = 1.0267937878670637, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 491, train_loss = 1.025444002210861, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 492, train_loss = 1.0240771882236004, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 493, train_loss = 1.0227422242460307, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 494, train_loss = 1.0213656909763813, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 495, train_loss = 1.0201231290993746, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 496, train_loss = 1.018668389559025, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 497, train_loss = 1.0173674933612347, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 498, train_loss = 1.0160741209983826, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "24th- epoch: 499, train_loss = 1.014698682964081, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████████████████████████████████████████▌              | 24/30 [2:43:55<41:06, 411.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "25th- epoch: 0, train_loss = 268.2239191532135, train_acc = 0.5030274802049371\n",
      "test Acc 0.5605214152700186:\n",
      "25th- epoch: 1, train_loss = 201.07598423957825, train_acc = 0.5556590591523055\n",
      "test Acc 0.5716945996275605:\n",
      "25th- epoch: 2, train_loss = 157.8474069237709, train_acc = 0.5759198882161155\n",
      "test Acc 0.6019553072625698:\n",
      "25th- epoch: 3, train_loss = 134.14732360839844, train_acc = 0.6599906846762925\n",
      "test Acc 0.7122905027932961:\n",
      "25th- epoch: 4, train_loss = 116.21204960346222, train_acc = 0.7502328830926874\n",
      "test Acc 0.7788640595903166:\n",
      "25th- epoch: 5, train_loss = 100.7720213830471, train_acc = 0.7902887750349324\n",
      "test Acc 0.797951582867784:\n",
      "25th- epoch: 6, train_loss = 87.62444323301315, train_acc = 0.8061248253376805\n",
      "test Acc 0.8058659217877095:\n",
      "25th- epoch: 7, train_loss = 76.96813678741455, train_acc = 0.8139264089427107\n",
      "test Acc 0.8161080074487895:\n",
      "25th- epoch: 8, train_loss = 68.35432022809982, train_acc = 0.8353516534699581\n",
      "test Acc 0.8412476722532588:\n",
      "25th- epoch: 9, train_loss = 61.250331714749336, train_acc = 0.8619003260363297\n",
      "test Acc 0.8784916201117319:\n",
      "25th- epoch: 10, train_loss = 55.24678982794285, train_acc = 0.891709361900326\n",
      "test Acc 0.9054934823091247:\n",
      "25th- epoch: 11, train_loss = 50.05462674796581, train_acc = 0.9110386585933862\n",
      "test Acc 0.9217877094972067:\n",
      "25th- epoch: 12, train_loss = 45.52035787701607, train_acc = 0.9257102934326968\n",
      "test Acc 0.9366852886405959:\n",
      "25th- epoch: 13, train_loss = 41.56877528131008, train_acc = 0.9377037727061015\n",
      "test Acc 0.9422718808193669:\n",
      "25th- epoch: 14, train_loss = 38.13964817672968, train_acc = 0.9417792268281323\n",
      "test Acc 0.9464618249534451:\n",
      "25th- epoch: 15, train_loss = 35.17895886301994, train_acc = 0.9445738239403819\n",
      "test Acc 0.9506517690875232:\n",
      "25th- epoch: 16, train_loss = 32.62979908287525, train_acc = 0.9474848625989754\n",
      "test Acc 0.9539106145251397:\n",
      "25th- epoch: 17, train_loss = 30.438968800008297, train_acc = 0.9501630181648812\n",
      "test Acc 0.9553072625698324:\n",
      "25th- epoch: 18, train_loss = 28.55252741277218, train_acc = 0.9523754075454122\n",
      "test Acc 0.9562383612662942:\n",
      "25th- epoch: 19, train_loss = 26.919923193752766, train_acc = 0.9543549138332557\n",
      "test Acc 0.957635009310987:\n",
      "25th- epoch: 20, train_loss = 25.497706905007362, train_acc = 0.9563344201210993\n",
      "test Acc 0.9585661080074488:\n",
      "25th- epoch: 21, train_loss = 24.25004256144166, train_acc = 0.9573823940381928\n",
      "test Acc 0.9599627560521415:\n",
      "25th- epoch: 22, train_loss = 23.146019838750362, train_acc = 0.9584303679552865\n",
      "test Acc 0.9604283054003724:\n",
      "25th- epoch: 23, train_loss = 22.161863140761852, train_acc = 0.9597112249650676\n",
      "test Acc 0.9613594040968343:\n",
      "25th- epoch: 24, train_loss = 21.27729593589902, train_acc = 0.9611085235211924\n",
      "test Acc 0.9622905027932961:\n",
      "25th- epoch: 25, train_loss = 20.476523775607347, train_acc = 0.9618071727992548\n",
      "test Acc 0.962756052141527:\n",
      "25th- epoch: 26, train_loss = 19.74661674723029, train_acc = 0.9626222636236609\n",
      "test Acc 0.962756052141527:\n",
      "25th- epoch: 27, train_loss = 19.077153623104095, train_acc = 0.9634373544480671\n",
      "test Acc 0.9632216014897579:\n",
      "25th- epoch: 28, train_loss = 18.45891786366701, train_acc = 0.9636702375407545\n",
      "test Acc 0.962756052141527:\n",
      "25th- epoch: 29, train_loss = 17.88470284640789, train_acc = 0.9644853283651607\n",
      "test Acc 0.9622905027932961:\n",
      "25th- epoch: 30, train_loss = 17.347480159252882, train_acc = 0.9654168607359106\n",
      "test Acc 0.962756052141527:\n",
      "25th- epoch: 31, train_loss = 16.84337716922164, train_acc = 0.965649743828598\n",
      "test Acc 0.962756052141527:\n",
      "25th- epoch: 32, train_loss = 16.3701440282166, train_acc = 0.966115510013973\n",
      "test Acc 0.9636871508379888:\n",
      "25th- epoch: 33, train_loss = 15.924538776278496, train_acc = 0.9673963670237541\n",
      "test Acc 0.9632216014897579:\n",
      "25th- epoch: 34, train_loss = 15.503213249146938, train_acc = 0.9691429902189101\n",
      "test Acc 0.9646182495344506:\n",
      "25th- epoch: 35, train_loss = 15.104110848158598, train_acc = 0.9703074056823474\n",
      "test Acc 0.9664804469273743:\n",
      "25th- epoch: 36, train_loss = 14.7256177701056, train_acc = 0.9712389380530974\n",
      "test Acc 0.9669459962756052:\n",
      "25th- epoch: 37, train_loss = 14.365953292697668, train_acc = 0.9724033535165347\n",
      "test Acc 0.9683426443202979:\n",
      "25th- epoch: 38, train_loss = 14.023196712136269, train_acc = 0.9729855612482534\n",
      "test Acc 0.9692737430167597:\n",
      "25th- epoch: 39, train_loss = 13.696019165217876, train_acc = 0.974033535165347\n",
      "test Acc 0.9706703910614525:\n",
      "25th- epoch: 40, train_loss = 13.383639845997095, train_acc = 0.9743828598043782\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 41, train_loss = 13.085180662572384, train_acc = 0.9749650675360969\n",
      "test Acc 0.9720670391061452:\n",
      "25th- epoch: 42, train_loss = 12.799668490886688, train_acc = 0.975780158360503\n",
      "test Acc 0.9725325884543762:\n",
      "25th- epoch: 43, train_loss = 12.52645781263709, train_acc = 0.9763623660922217\n",
      "test Acc 0.9743947858472998:\n",
      "25th- epoch: 44, train_loss = 12.264943897724152, train_acc = 0.9764788076385654\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 45, train_loss = 12.014306258410215, train_acc = 0.9770610153702841\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 46, train_loss = 11.773952879011631, train_acc = 0.9776432231020028\n",
      "test Acc 0.9753258845437617:\n",
      "25th- epoch: 47, train_loss = 11.543213304132223, train_acc = 0.9785747554727526\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 48, train_loss = 11.32140676677227, train_acc = 0.9791569632044713\n",
      "test Acc 0.9757914338919925:\n",
      "25th- epoch: 49, train_loss = 11.107754692435265, train_acc = 0.9795062878435026\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 50, train_loss = 10.901833195239305, train_acc = 0.9798556124825337\n",
      "test Acc 0.9767225325884544:\n",
      "25th- epoch: 51, train_loss = 10.703150779008865, train_acc = 0.9803213786679087\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 52, train_loss = 10.51125418394804, train_acc = 0.9810200279459711\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 53, train_loss = 10.325740899890661, train_acc = 0.9811364694923148\n",
      "test Acc 0.9776536312849162:\n",
      "25th- epoch: 54, train_loss = 10.146387830376625, train_acc = 0.9813693525850024\n",
      "test Acc 0.9781191806331471:\n",
      "25th- epoch: 55, train_loss = 9.972607111558318, train_acc = 0.9814857941313461\n",
      "test Acc 0.978584729981378:\n",
      "25th- epoch: 56, train_loss = 9.804185276851058, train_acc = 0.9823008849557522\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 57, train_loss = 9.640735883265734, train_acc = 0.9825337680484397\n",
      "test Acc 0.979050279329609:\n",
      "25th- epoch: 58, train_loss = 9.482091950252652, train_acc = 0.9827666511411272\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 59, train_loss = 9.327893549576402, train_acc = 0.9832324173265021\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 60, train_loss = 9.177994687110186, train_acc = 0.9833488588728458\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 61, train_loss = 9.032132484018803, train_acc = 0.9835817419655333\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 62, train_loss = 8.890054857358336, train_acc = 0.9835817419655333\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 63, train_loss = 8.751639172434807, train_acc = 0.9838146250582208\n",
      "test Acc 0.9795158286778398:\n",
      "25th- epoch: 64, train_loss = 8.616679729893804, train_acc = 0.9838146250582208\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 65, train_loss = 8.485047103837132, train_acc = 0.9838146250582208\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 66, train_loss = 8.356545416638255, train_acc = 0.9838146250582208\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 67, train_loss = 8.231317043304443, train_acc = 0.9840475081509082\n",
      "test Acc 0.9799813780260708:\n",
      "25th- epoch: 68, train_loss = 8.109019700437784, train_acc = 0.9840475081509082\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 69, train_loss = 7.98959194123745, train_acc = 0.984163949697252\n",
      "test Acc 0.9804469273743017:\n",
      "25th- epoch: 70, train_loss = 7.872726215049624, train_acc = 0.9842803912435957\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 71, train_loss = 7.758656052872539, train_acc = 0.9843968327899395\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 72, train_loss = 7.647189756855369, train_acc = 0.9849790405216581\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 73, train_loss = 7.538079788908362, train_acc = 0.9849790405216581\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 74, train_loss = 7.4314798060804605, train_acc = 0.9855612482533768\n",
      "test Acc 0.9809124767225326:\n",
      "25th- epoch: 75, train_loss = 7.3269628174602985, train_acc = 0.9857941313460643\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 76, train_loss = 7.224595746025443, train_acc = 0.985910572892408\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 77, train_loss = 7.124380080029368, train_acc = 0.9862598975314392\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 78, train_loss = 7.026190692558885, train_acc = 0.9866092221704704\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 79, train_loss = 6.930075401440263, train_acc = 0.9869585468095017\n",
      "test Acc 0.9813780260707635:\n",
      "25th- epoch: 80, train_loss = 6.8359423372894526, train_acc = 0.9870749883558454\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 81, train_loss = 6.743770986795425, train_acc = 0.9870749883558454\n",
      "test Acc 0.9818435754189944:\n",
      "25th- epoch: 82, train_loss = 6.653473164886236, train_acc = 0.9871914299021891\n",
      "test Acc 0.9823091247672253:\n",
      "25th- epoch: 83, train_loss = 6.564918918535113, train_acc = 0.9873078714485328\n",
      "test Acc 0.9823091247672253:\n",
      "25th- epoch: 84, train_loss = 6.478312851861119, train_acc = 0.9877736376339078\n",
      "test Acc 0.9823091247672253:\n",
      "25th- epoch: 85, train_loss = 6.393402421846986, train_acc = 0.9880065207265952\n",
      "test Acc 0.9823091247672253:\n",
      "25th- epoch: 86, train_loss = 6.310196174308658, train_acc = 0.9882394038192828\n",
      "test Acc 0.9823091247672253:\n",
      "25th- epoch: 87, train_loss = 6.228734185919166, train_acc = 0.9883558453656265\n",
      "test Acc 0.9823091247672253:\n",
      "25th- epoch: 88, train_loss = 6.148791642859578, train_acc = 0.9883558453656265\n",
      "test Acc 0.9823091247672253:\n",
      "25th- epoch: 89, train_loss = 6.0705018527805805, train_acc = 0.9884722869119702\n",
      "test Acc 0.9823091247672253:\n",
      "25th- epoch: 90, train_loss = 5.99370676651597, train_acc = 0.9885887284583139\n",
      "test Acc 0.9823091247672253:\n",
      "25th- epoch: 91, train_loss = 5.918332684785128, train_acc = 0.9888216115510013\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 92, train_loss = 5.844497645273805, train_acc = 0.9888216115510013\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 93, train_loss = 5.771969169378281, train_acc = 0.9888216115510013\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 94, train_loss = 5.700780730694532, train_acc = 0.9888216115510013\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 95, train_loss = 5.631016353145242, train_acc = 0.9890544946436889\n",
      "test Acc 0.9827746741154563:\n",
      "25th- epoch: 96, train_loss = 5.562651768326759, train_acc = 0.9891709361900326\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 97, train_loss = 5.495513655245304, train_acc = 0.9896367023754076\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 98, train_loss = 5.429620028473437, train_acc = 0.9897531439217513\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 99, train_loss = 5.364958769641817, train_acc = 0.9899860270144387\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 100, train_loss = 5.301438691094518, train_acc = 0.9902189101071263\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 101, train_loss = 5.238978394307196, train_acc = 0.9904517931998137\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 102, train_loss = 5.1777670392766595, train_acc = 0.9905682347461574\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 103, train_loss = 5.117619612254202, train_acc = 0.9906846762925011\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 104, train_loss = 5.058583124540746, train_acc = 0.9906846762925011\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 105, train_loss = 5.000794027931988, train_acc = 0.990801117838845\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 106, train_loss = 4.944322247058153, train_acc = 0.9909175593851887\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 107, train_loss = 4.888747403398156, train_acc = 0.9910340009315324\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 108, train_loss = 4.834114388562739, train_acc = 0.9910340009315324\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 109, train_loss = 4.78053011931479, train_acc = 0.9909175593851887\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 110, train_loss = 4.727882830426097, train_acc = 0.9910340009315324\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 111, train_loss = 4.676113452762365, train_acc = 0.9911504424778761\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 112, train_loss = 4.6253302013501525, train_acc = 0.9913833255705635\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 113, train_loss = 4.57550358120352, train_acc = 0.9914997671169073\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 114, train_loss = 4.526442175731063, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 115, train_loss = 4.478229632601142, train_acc = 0.9917326502095948\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 116, train_loss = 4.430914214812219, train_acc = 0.9918490917559385\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 117, train_loss = 4.384232020936906, train_acc = 0.9919655333022822\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 118, train_loss = 4.33854110725224, train_acc = 0.992081974848626\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 119, train_loss = 4.293388462625444, train_acc = 0.992081974848626\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 120, train_loss = 4.249240756034851, train_acc = 0.9924312994876572\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 121, train_loss = 4.205629040487111, train_acc = 0.9926641825803446\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 122, train_loss = 4.162879895418882, train_acc = 0.9926641825803446\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 123, train_loss = 4.120672669261694, train_acc = 0.9926641825803446\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 124, train_loss = 4.079309722408652, train_acc = 0.9927806241266884\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 125, train_loss = 4.038493857719004, train_acc = 0.9930135072193759\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 126, train_loss = 3.9984309105202556, train_acc = 0.9930135072193759\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 127, train_loss = 3.959054564125836, train_acc = 0.9930135072193759\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 128, train_loss = 3.9203133257105947, train_acc = 0.9930135072193759\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 129, train_loss = 3.8821879029273987, train_acc = 0.9931299487657196\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 130, train_loss = 3.844726965762675, train_acc = 0.9931299487657196\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 131, train_loss = 3.807888167910278, train_acc = 0.9931299487657196\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 132, train_loss = 3.771683916449547, train_acc = 0.9931299487657196\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 133, train_loss = 3.7360158562660217, train_acc = 0.9931299487657196\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 134, train_loss = 3.7010130141861737, train_acc = 0.9933628318584071\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 135, train_loss = 3.666485473513603, train_acc = 0.9935957149510946\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 136, train_loss = 3.6326449178159237, train_acc = 0.9937121564974383\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 137, train_loss = 3.5991667080670595, train_acc = 0.9939450395901258\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 138, train_loss = 3.5664360858500004, train_acc = 0.9939450395901258\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 139, train_loss = 3.534000102430582, train_acc = 0.9940614811364695\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 140, train_loss = 3.502267641481012, train_acc = 0.9941779226828132\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 141, train_loss = 3.4709064210765064, train_acc = 0.9941779226828132\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 142, train_loss = 3.4401247301138937, train_acc = 0.9941779226828132\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 143, train_loss = 3.409705548081547, train_acc = 0.9941779226828132\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 144, train_loss = 3.3797838990576565, train_acc = 0.9941779226828132\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 145, train_loss = 3.3503340054303408, train_acc = 0.994294364229157\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 146, train_loss = 3.321356326341629, train_acc = 0.994294364229157\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 147, train_loss = 3.292827669531107, train_acc = 0.994294364229157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 148, train_loss = 3.264633856713772, train_acc = 0.9944108057755007\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 149, train_loss = 3.2370304386131465, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 150, train_loss = 3.209799733478576, train_acc = 0.9947601304145319\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 151, train_loss = 3.1829316411167383, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 152, train_loss = 3.156430309638381, train_acc = 0.9948765719608756\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 153, train_loss = 3.1304574687965214, train_acc = 0.9949930135072194\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 154, train_loss = 3.1047391183674335, train_acc = 0.9949930135072194\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 155, train_loss = 3.0794593268074095, train_acc = 0.9949930135072194\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 156, train_loss = 3.0545179354958236, train_acc = 0.9951094550535631\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 157, train_loss = 3.0299268793314695, train_acc = 0.9951094550535631\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 158, train_loss = 3.0057358890771866, train_acc = 0.9951094550535631\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 159, train_loss = 2.9818266215734184, train_acc = 0.9951094550535631\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 160, train_loss = 2.9582910579629242, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 161, train_loss = 2.935083746444434, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 162, train_loss = 2.9122130260802805, train_acc = 0.9951094550535631\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 163, train_loss = 2.889588300604373, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 164, train_loss = 2.8672428629361093, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 165, train_loss = 2.8453308478929102, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 166, train_loss = 2.8236748524941504, train_acc = 0.9953423381462506\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 167, train_loss = 2.8023495548404753, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 168, train_loss = 2.781258369330317, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 169, train_loss = 2.7604808225296438, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 170, train_loss = 2.7400425411760807, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 171, train_loss = 2.719788277056068, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 172, train_loss = 2.699870505835861, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 173, train_loss = 2.680205963551998, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 174, train_loss = 2.6608548182994127, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 175, train_loss = 2.6417765580117702, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 176, train_loss = 2.622987650334835, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 177, train_loss = 2.604428827064112, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 178, train_loss = 2.586188015760854, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "25th- epoch: 179, train_loss = 2.5681154802441597, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 180, train_loss = 2.550280191702768, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 181, train_loss = 2.532808468444273, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 182, train_loss = 2.515497974352911, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 183, train_loss = 2.4984319128561765, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 184, train_loss = 2.48160567949526, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 185, train_loss = 2.4649963297415525, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 186, train_loss = 2.4486041094642133, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 187, train_loss = 2.4324728928040713, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 188, train_loss = 2.4165457740891725, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 189, train_loss = 2.4008789632935077, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 190, train_loss = 2.385309388162568, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 191, train_loss = 2.3700096991378814, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 192, train_loss = 2.354993127984926, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 193, train_loss = 2.3401031487155706, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 194, train_loss = 2.3254644628614187, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 195, train_loss = 2.3109606578946114, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 196, train_loss = 2.2966932400595397, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 197, train_loss = 2.2826970785390586, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 198, train_loss = 2.268790291622281, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 199, train_loss = 2.2550785082858056, train_acc = 0.996040987424313\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 200, train_loss = 2.2416015018243343, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 201, train_loss = 2.2283830035012215, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "25th- epoch: 202, train_loss = 2.2152458615601063, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 203, train_loss = 2.202334542525932, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 204, train_loss = 2.189520012587309, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 205, train_loss = 2.1769348543602973, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 206, train_loss = 2.1644989971537143, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 207, train_loss = 2.1522354676853865, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 208, train_loss = 2.1401114233303815, train_acc = 0.9961574289706567\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 209, train_loss = 2.1281865693163127, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 210, train_loss = 2.1163985386956483, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 211, train_loss = 2.1048391859512776, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 212, train_loss = 2.0932694741059095, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 213, train_loss = 2.081977828172967, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 214, train_loss = 2.070843379246071, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 215, train_loss = 2.0598195244092494, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "25th- epoch: 216, train_loss = 2.0489774991292506, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 217, train_loss = 2.0381952598690987, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 218, train_loss = 2.027559593319893, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 219, train_loss = 2.017093747854233, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 220, train_loss = 2.006794440327212, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 221, train_loss = 1.996556181460619, train_acc = 0.9966231951560317\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 222, train_loss = 1.986478105187416, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 223, train_loss = 1.9765366662759334, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 224, train_loss = 1.9666965119540691, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 225, train_loss = 1.9570446200668812, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 226, train_loss = 1.947411437286064, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 227, train_loss = 1.9378814399242401, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 228, train_loss = 1.9285506010055542, train_acc = 0.9969725197950629\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 229, train_loss = 1.919324674992822, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 230, train_loss = 1.9101992597570643, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 231, train_loss = 1.9011186497518793, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 232, train_loss = 1.892224264680408, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "25th- epoch: 233, train_loss = 1.8834040003130212, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 234, train_loss = 1.8747212091693655, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 235, train_loss = 1.8661029817303643, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 236, train_loss = 1.8576826862990856, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 237, train_loss = 1.8492679577320814, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 238, train_loss = 1.8409732294967398, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 239, train_loss = 1.8327817426761612, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 240, train_loss = 1.8247346939751878, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 241, train_loss = 1.8167282423237339, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 242, train_loss = 1.8088252817979082, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 243, train_loss = 1.8010283509502187, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 244, train_loss = 1.7933270348003134, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 245, train_loss = 1.785683541209437, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 246, train_loss = 1.7780987545847893, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 247, train_loss = 1.7707241190364584, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 248, train_loss = 1.7633231729269028, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 249, train_loss = 1.7560002530226484, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 250, train_loss = 1.7488492442062125, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 251, train_loss = 1.741632847697474, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 252, train_loss = 1.734601929783821, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 253, train_loss = 1.7276216050377116, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 254, train_loss = 1.7207236774265766, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 255, train_loss = 1.7138617374002934, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 256, train_loss = 1.707140900194645, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 257, train_loss = 1.700427113682963, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 258, train_loss = 1.6938068544259295, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 259, train_loss = 1.6872256100177765, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 260, train_loss = 1.6808626552810892, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 261, train_loss = 1.6742651214590296, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 262, train_loss = 1.6678078497061506, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 263, train_loss = 1.661379911005497, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 264, train_loss = 1.655237448750995, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 265, train_loss = 1.6490532954921946, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 266, train_loss = 1.642935780226253, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 267, train_loss = 1.6369571350514889, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 268, train_loss = 1.63102660945151, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 269, train_loss = 1.6251231580972672, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 270, train_loss = 1.619227963150479, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "25th- epoch: 271, train_loss = 1.6135070038726553, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 272, train_loss = 1.607753517688252, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 273, train_loss = 1.6021308153867722, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 274, train_loss = 1.5965312123298645, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 275, train_loss = 1.5909974500536919, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 276, train_loss = 1.5854485655436292, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 277, train_loss = 1.580042845220305, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 278, train_loss = 1.57465733459685, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 279, train_loss = 1.569340705871582, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 280, train_loss = 1.5640346184372902, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 281, train_loss = 1.558784601627849, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 282, train_loss = 1.5535610914230347, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 283, train_loss = 1.548520341515541, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 284, train_loss = 1.543416228145361, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 285, train_loss = 1.5384035309543833, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 286, train_loss = 1.5333907008171082, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 287, train_loss = 1.5284423740813509, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 288, train_loss = 1.5234157541999593, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 289, train_loss = 1.5186454951763153, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 290, train_loss = 1.513789607794024, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 291, train_loss = 1.5089701525866985, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 292, train_loss = 1.5041986157302745, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 293, train_loss = 1.4995058576459996, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 294, train_loss = 1.494786002964247, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 295, train_loss = 1.490261955827009, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 296, train_loss = 1.4856839887797832, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 297, train_loss = 1.4811978216166608, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 298, train_loss = 1.4767013999517076, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 299, train_loss = 1.4722387927467935, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 300, train_loss = 1.4678748659789562, train_acc = 0.9975547275267815\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 301, train_loss = 1.4635266897385009, train_acc = 0.9975547275267815\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 302, train_loss = 1.4591521968250163, train_acc = 0.9975547275267815\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 303, train_loss = 1.454940028488636, train_acc = 0.9975547275267815\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 304, train_loss = 1.450598721683491, train_acc = 0.9975547275267815\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 305, train_loss = 1.4464547199313529, train_acc = 0.9975547275267815\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 306, train_loss = 1.4423173032701015, train_acc = 0.9975547275267815\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 307, train_loss = 1.4381537375156768, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 308, train_loss = 1.4339459501206875, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 309, train_loss = 1.4299331841175444, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 310, train_loss = 1.425888605415821, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 311, train_loss = 1.4219211898744106, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 312, train_loss = 1.4179660106892698, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 313, train_loss = 1.4139336993102916, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 314, train_loss = 1.4100325356121175, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 315, train_loss = 1.4062982958857901, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 316, train_loss = 1.4023929300601594, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 317, train_loss = 1.3986191488802433, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 318, train_loss = 1.3947046014363877, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 319, train_loss = 1.3910823849146254, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 320, train_loss = 1.3873142351512797, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 321, train_loss = 1.383665557950735, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 322, train_loss = 1.3800359082524665, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 323, train_loss = 1.376301746815443, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 324, train_loss = 1.3727730860118754, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 325, train_loss = 1.369271143048536, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 326, train_loss = 1.3656894353334792, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 327, train_loss = 1.3621759973466396, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 328, train_loss = 1.3587444077129476, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 329, train_loss = 1.3552848137915134, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 330, train_loss = 1.3518224221770652, train_acc = 0.9977876106194691\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 331, train_loss = 1.3484462213818915, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 332, train_loss = 1.3450644451077096, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 333, train_loss = 1.341800943017006, train_acc = 0.9976711690731253\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 334, train_loss = 1.3385089586372487, train_acc = 0.9977876106194691\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 335, train_loss = 1.3351687813992612, train_acc = 0.9977876106194691\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 336, train_loss = 1.3319410222466104, train_acc = 0.9977876106194691\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 337, train_loss = 1.3286198861896992, train_acc = 0.9977876106194691\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 338, train_loss = 1.325463714718353, train_acc = 0.9977876106194691\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 339, train_loss = 1.3222505077719688, train_acc = 0.9977876106194691\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 340, train_loss = 1.3191058176453225, train_acc = 0.9977876106194691\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 341, train_loss = 1.3159171044826508, train_acc = 0.9977876106194691\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 342, train_loss = 1.3128924816846848, train_acc = 0.9977876106194691\n",
      "test Acc 0.9874301675977654:\n",
      "25th- epoch: 343, train_loss = 1.3097126546199434, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 344, train_loss = 1.3066192530095577, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 345, train_loss = 1.3035379660432227, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 346, train_loss = 1.300454104959499, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 347, train_loss = 1.29746439185692, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 348, train_loss = 1.2944634457235225, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "25th- epoch: 349, train_loss = 1.2914251387119293, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 350, train_loss = 1.2885073237121105, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 351, train_loss = 1.2855286871199496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 352, train_loss = 1.2826227955520153, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 353, train_loss = 1.2797527089715004, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 354, train_loss = 1.2768077391083352, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 355, train_loss = 1.27391703549074, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 356, train_loss = 1.2710548117756844, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 357, train_loss = 1.268317838490475, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 358, train_loss = 1.265473150939215, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 359, train_loss = 1.2627077859942801, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 360, train_loss = 1.2599701608414762, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 361, train_loss = 1.257250374823343, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 362, train_loss = 1.2545228476519696, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 363, train_loss = 1.251856656104792, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 364, train_loss = 1.2492080492083915, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 365, train_loss = 1.2465536358649842, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 366, train_loss = 1.243954237550497, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 367, train_loss = 1.2413218219880946, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 368, train_loss = 1.2387000173330307, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 369, train_loss = 1.2361514295334928, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 370, train_loss = 1.2336121599073522, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 371, train_loss = 1.2310089468955994, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 372, train_loss = 1.2285324148833752, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 373, train_loss = 1.2260328668053262, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 374, train_loss = 1.223519392311573, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 375, train_loss = 1.2210666996834334, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 376, train_loss = 1.2186372727155685, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 377, train_loss = 1.2161381555197295, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 378, train_loss = 1.213781173020834, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 379, train_loss = 1.2113251363334712, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 380, train_loss = 1.2088887815771159, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 381, train_loss = 1.206587833672529, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 382, train_loss = 1.2041990123689175, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 383, train_loss = 1.201859893888468, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 384, train_loss = 1.1994925116596278, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 385, train_loss = 1.1972409027221147, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 386, train_loss = 1.194967004150385, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 387, train_loss = 1.1926316829922143, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 388, train_loss = 1.1903630135057028, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 389, train_loss = 1.18806167319417, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 390, train_loss = 1.1859167988004629, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 391, train_loss = 1.1836604861018714, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 392, train_loss = 1.1814343904552516, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 393, train_loss = 1.1792374700307846, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 394, train_loss = 1.1770455750229303, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 395, train_loss = 1.174869615584612, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 396, train_loss = 1.1727528348565102, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 397, train_loss = 1.1705764023063239, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 398, train_loss = 1.1684094928205013, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 399, train_loss = 1.1663286189141218, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 400, train_loss = 1.1642082035541534, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 401, train_loss = 1.1621425400080625, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 402, train_loss = 1.1600412974657957, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 403, train_loss = 1.1579603900609072, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 404, train_loss = 1.1560094356536865, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 405, train_loss = 1.153882979095215, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 406, train_loss = 1.1518454948964063, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 407, train_loss = 1.1498843667504843, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 408, train_loss = 1.1478327549993992, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 409, train_loss = 1.1458460427820683, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 410, train_loss = 1.1439349688589573, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 411, train_loss = 1.1417997951211873, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 412, train_loss = 1.1399720894696657, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 413, train_loss = 1.1380563067796174, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 414, train_loss = 1.1359935353102628, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 415, train_loss = 1.134072121232748, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 416, train_loss = 1.132077131420374, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 417, train_loss = 1.1302577517926693, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 418, train_loss = 1.1283453168871347, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 419, train_loss = 1.1263388134539127, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 420, train_loss = 1.124557572096819, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 421, train_loss = 1.1226650327444077, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 422, train_loss = 1.1208997977373656, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 423, train_loss = 1.1190250366926193, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 424, train_loss = 1.1171771945955697, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 425, train_loss = 1.1153750345110893, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 426, train_loss = 1.1135593578219414, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 427, train_loss = 1.1118373771605548, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 428, train_loss = 1.1099449805915356, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 429, train_loss = 1.108190342783928, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 430, train_loss = 1.106510187179083, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 431, train_loss = 1.1047272334399167, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 432, train_loss = 1.1029809179308359, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 433, train_loss = 1.1011540591716766, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 434, train_loss = 1.0995654376747552, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 435, train_loss = 1.097783104836708, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 436, train_loss = 1.0961005178687628, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 437, train_loss = 1.0943170972168446, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 438, train_loss = 1.0927600699069444, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 439, train_loss = 1.091063375264639, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 440, train_loss = 1.089372939110035, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 441, train_loss = 1.0877058444020804, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 442, train_loss = 1.0860231307742652, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25th- epoch: 443, train_loss = 1.0844388504920062, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 444, train_loss = 1.0828492417931557, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 445, train_loss = 1.0811015889048576, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 446, train_loss = 1.0796067342162132, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 447, train_loss = 1.0779211223125458, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "25th- epoch: 448, train_loss = 1.0763777966203634, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 449, train_loss = 1.07472450658679, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 450, train_loss = 1.0732013049128, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 451, train_loss = 1.071634128689766, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 452, train_loss = 1.0701130293309689, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 453, train_loss = 1.068448989331955, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 454, train_loss = 1.0669702254235744, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 455, train_loss = 1.0654538733360823, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 456, train_loss = 1.0638880940678064, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 457, train_loss = 1.0623859527113382, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 458, train_loss = 1.0608120498654898, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 459, train_loss = 1.0594024496676866, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 460, train_loss = 1.0578842448594514, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 461, train_loss = 1.056293067842489, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 462, train_loss = 1.0549098625779152, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 463, train_loss = 1.053398826479679, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 464, train_loss = 1.0519505751726683, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 465, train_loss = 1.0504020974040031, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 466, train_loss = 1.0489998435077723, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 467, train_loss = 1.0475828386843204, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 468, train_loss = 1.046103553235298, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 469, train_loss = 1.0446368480625097, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 470, train_loss = 1.0432441135344561, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 471, train_loss = 1.0418836039898451, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 472, train_loss = 1.0404050635697786, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 473, train_loss = 1.0390116572380066, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 474, train_loss = 1.0376010996697005, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 475, train_loss = 1.0362576184270438, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 476, train_loss = 1.0348447933793068, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 477, train_loss = 1.033467322587967, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 478, train_loss = 1.0320867585542146, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 479, train_loss = 1.0308139646949712, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 480, train_loss = 1.0294295673666056, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 481, train_loss = 1.0279527232050896, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 482, train_loss = 1.0267341062426567, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 483, train_loss = 1.0253615081310272, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 484, train_loss = 1.0240966429410037, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 485, train_loss = 1.0226352140307426, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 486, train_loss = 1.0214908632187871, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 487, train_loss = 1.0200447825045558, train_acc = 0.9981369352585002\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 488, train_loss = 1.018811779722455, train_acc = 0.9981369352585002\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 489, train_loss = 1.0174329082219629, train_acc = 0.9981369352585002\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 490, train_loss = 1.0162495126278372, train_acc = 0.9981369352585002\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 491, train_loss = 1.0148701655416517, train_acc = 0.9981369352585002\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 492, train_loss = 1.013663814708707, train_acc = 0.9981369352585002\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 493, train_loss = 1.0123002690525027, train_acc = 0.9981369352585002\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 494, train_loss = 1.0111580230295658, train_acc = 0.9981369352585002\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 495, train_loss = 1.0098502710461617, train_acc = 0.9981369352585002\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 496, train_loss = 1.0086425257177325, train_acc = 0.9981369352585002\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 497, train_loss = 1.0072970390319824, train_acc = 0.9981369352585002\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 498, train_loss = 1.006162581339595, train_acc = 0.9981369352585002\n",
      "test Acc 0.9860335195530726:\n",
      "25th- epoch: 499, train_loss = 1.004842306181672, train_acc = 0.9981369352585002\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████████████████████████████████████████████████████████            | 25/30 [2:50:46<34:15, 411.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "26th- epoch: 0, train_loss = 266.6124004125595, train_acc = 0.46960875640428507\n",
      "test Acc 0.48463687150837986:\n",
      "26th- epoch: 1, train_loss = 201.89216649532318, train_acc = 0.49091755938518866\n",
      "test Acc 0.5:\n",
      "26th- epoch: 2, train_loss = 160.77011960744858, train_acc = 0.5803446669771775\n",
      "test Acc 0.6373370577281192:\n",
      "26th- epoch: 3, train_loss = 134.62328219413757, train_acc = 0.6762925011644154\n",
      "test Acc 0.7202048417132216:\n",
      "26th- epoch: 4, train_loss = 115.05591773986816, train_acc = 0.7434792734047508\n",
      "test Acc 0.7676908752327747:\n",
      "26th- epoch: 5, train_loss = 99.78141731023788, train_acc = 0.7688635305076852\n",
      "test Acc 0.7811918063314711:\n",
      "26th- epoch: 6, train_loss = 87.62352585792542, train_acc = 0.7852817885421518\n",
      "test Acc 0.7956238361266295:\n",
      "26th- epoch: 7, train_loss = 77.77276226878166, train_acc = 0.8108989287377736\n",
      "test Acc 0.8310055865921788:\n",
      "26th- epoch: 8, train_loss = 69.45030534267426, train_acc = 0.8405915230554262\n",
      "test Acc 0.8500931098696461:\n",
      "26th- epoch: 9, train_loss = 62.20202651619911, train_acc = 0.8685374941779227\n",
      "test Acc 0.8789571694599627:\n",
      "26th- epoch: 10, train_loss = 55.86662486195564, train_acc = 0.8929902189101071\n",
      "test Acc 0.9031657355679702:\n",
      "26th- epoch: 11, train_loss = 50.35413561761379, train_acc = 0.9151141127154169\n",
      "test Acc 0.9273743016759777:\n",
      "26th- epoch: 12, train_loss = 45.58561736345291, train_acc = 0.9295528644620401\n",
      "test Acc 0.9338919925512105:\n",
      "26th- epoch: 13, train_loss = 41.48848243057728, train_acc = 0.9363064741499767\n",
      "test Acc 0.9357541899441341:\n",
      "26th- epoch: 14, train_loss = 37.99067094177008, train_acc = 0.9389846297158826\n",
      "test Acc 0.9394785847299814:\n",
      "26th- epoch: 15, train_loss = 35.01463197916746, train_acc = 0.9436422915696321\n",
      "test Acc 0.9464618249534451:\n",
      "26th- epoch: 16, train_loss = 32.480132184922695, train_acc = 0.9486492780624126\n",
      "test Acc 0.9478584729981379:\n",
      "26th- epoch: 17, train_loss = 30.314533196389675, train_acc = 0.9506287843502562\n",
      "test Acc 0.9515828677839852:\n",
      "26th- epoch: 18, train_loss = 28.45378352701664, train_acc = 0.9523754075454122\n",
      "test Acc 0.9529795158286778:\n",
      "26th- epoch: 19, train_loss = 26.84366174042225, train_acc = 0.9537727061015371\n",
      "test Acc 0.9562383612662942:\n",
      "26th- epoch: 20, train_loss = 25.439762383699417, train_acc = 0.9549371215649743\n",
      "test Acc 0.957635009310987:\n",
      "26th- epoch: 21, train_loss = 24.206352092325687, train_acc = 0.956450861667443\n",
      "test Acc 0.9581005586592178:\n",
      "26th- epoch: 22, train_loss = 23.113264448940754, train_acc = 0.9580810433162552\n",
      "test Acc 0.9594972067039106:\n",
      "26th- epoch: 23, train_loss = 22.138000514358282, train_acc = 0.9598276665114113\n",
      "test Acc 0.9599627560521415:\n",
      "26th- epoch: 24, train_loss = 21.260728117078543, train_acc = 0.9612249650675361\n",
      "test Acc 0.9618249534450651:\n",
      "26th- epoch: 25, train_loss = 20.465755570679903, train_acc = 0.961690731252911\n",
      "test Acc 0.9622905027932961:\n",
      "26th- epoch: 26, train_loss = 19.74085809290409, train_acc = 0.9623893805309734\n",
      "test Acc 0.9622905027932961:\n",
      "26th- epoch: 27, train_loss = 19.076064202934504, train_acc = 0.9629715882626921\n",
      "test Acc 0.962756052141527:\n",
      "26th- epoch: 28, train_loss = 18.463478922843933, train_acc = 0.9637866790870983\n",
      "test Acc 0.962756052141527:\n",
      "26th- epoch: 29, train_loss = 17.895743940025568, train_acc = 0.9651839776432231\n",
      "test Acc 0.9632216014897579:\n",
      "26th- epoch: 30, train_loss = 17.367140527814627, train_acc = 0.9658826269212856\n",
      "test Acc 0.9632216014897579:\n",
      "26th- epoch: 31, train_loss = 16.873608961701393, train_acc = 0.9670470423847228\n",
      "test Acc 0.9636871508379888:\n",
      "26th- epoch: 32, train_loss = 16.411763980984688, train_acc = 0.9678621332091291\n",
      "test Acc 0.9650837988826816:\n",
      "26th- epoch: 33, train_loss = 15.977331683039665, train_acc = 0.9687936655798789\n",
      "test Acc 0.9660148975791434:\n",
      "26th- epoch: 34, train_loss = 15.567158926278353, train_acc = 0.9694923148579413\n",
      "test Acc 0.9664804469273743:\n",
      "26th- epoch: 35, train_loss = 15.179496843367815, train_acc = 0.9707731718677224\n",
      "test Acc 0.9669459962756052:\n",
      "26th- epoch: 36, train_loss = 14.813066992908716, train_acc = 0.9711224965067536\n",
      "test Acc 0.9697392923649907:\n",
      "26th- epoch: 37, train_loss = 14.465579435229301, train_acc = 0.9721704704238472\n",
      "test Acc 0.9702048417132216:\n",
      "26th- epoch: 38, train_loss = 14.13546109572053, train_acc = 0.9726362366092222\n",
      "test Acc 0.9706703910614525:\n",
      "26th- epoch: 39, train_loss = 13.820899408310652, train_acc = 0.9729855612482534\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 40, train_loss = 13.520449589937925, train_acc = 0.9739170936190032\n",
      "test Acc 0.9711359404096834:\n",
      "26th- epoch: 41, train_loss = 13.232971105724573, train_acc = 0.9744993013507219\n",
      "test Acc 0.9716014897579144:\n",
      "26th- epoch: 42, train_loss = 12.957473512738943, train_acc = 0.9754308337214718\n",
      "test Acc 0.9720670391061452:\n",
      "26th- epoch: 43, train_loss = 12.693752400577068, train_acc = 0.9763623660922217\n",
      "test Acc 0.972998137802607:\n",
      "26th- epoch: 44, train_loss = 12.440672419965267, train_acc = 0.9767116907312529\n",
      "test Acc 0.973463687150838:\n",
      "26th- epoch: 45, train_loss = 12.197733648121357, train_acc = 0.9776432231020028\n",
      "test Acc 0.9739292364990689:\n",
      "26th- epoch: 46, train_loss = 11.964308507740498, train_acc = 0.9784583139264089\n",
      "test Acc 0.9739292364990689:\n",
      "26th- epoch: 47, train_loss = 11.739626560360193, train_acc = 0.9789240801117839\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 48, train_loss = 11.523064069449902, train_acc = 0.9789240801117839\n",
      "test Acc 0.9748603351955307:\n",
      "26th- epoch: 49, train_loss = 11.314216420054436, train_acc = 0.9795062878435026\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 50, train_loss = 11.112717673182487, train_acc = 0.9796227293898463\n",
      "test Acc 0.9753258845437617:\n",
      "26th- epoch: 51, train_loss = 10.91795950755477, train_acc = 0.9803213786679087\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 52, train_loss = 10.729471258819103, train_acc = 0.9804378202142524\n",
      "test Acc 0.9762569832402235:\n",
      "26th- epoch: 53, train_loss = 10.546800378710032, train_acc = 0.9805542617605962\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 54, train_loss = 10.369898840785027, train_acc = 0.9807871448532837\n",
      "test Acc 0.9767225325884544:\n",
      "26th- epoch: 55, train_loss = 10.198521222919226, train_acc = 0.9812529110386586\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 56, train_loss = 10.03197392821312, train_acc = 0.9812529110386586\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 57, train_loss = 9.869871988892555, train_acc = 0.9816022356776898\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 58, train_loss = 9.712504420429468, train_acc = 0.9816022356776898\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 59, train_loss = 9.559480246156454, train_acc = 0.9818351187703773\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 60, train_loss = 9.410448648035526, train_acc = 0.9825337680484397\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 61, train_loss = 9.265587700530887, train_acc = 0.9826502095947834\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 62, train_loss = 9.124400768429041, train_acc = 0.9828830926874709\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 63, train_loss = 8.986855367198586, train_acc = 0.9829995342338146\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 64, train_loss = 8.85286503098905, train_acc = 0.9831159757801584\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 65, train_loss = 8.722018003463745, train_acc = 0.9832324173265021\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 66, train_loss = 8.594206847250462, train_acc = 0.9833488588728458\n",
      "test Acc 0.9771880819366853:\n",
      "26th- epoch: 67, train_loss = 8.469146944582462, train_acc = 0.9833488588728458\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 68, train_loss = 8.34693773649633, train_acc = 0.9833488588728458\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 69, train_loss = 8.22743178345263, train_acc = 0.9835817419655333\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 70, train_loss = 8.110683469101787, train_acc = 0.9838146250582208\n",
      "test Acc 0.9776536312849162:\n",
      "26th- epoch: 71, train_loss = 7.996497951447964, train_acc = 0.9838146250582208\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 72, train_loss = 7.884731389582157, train_acc = 0.9840475081509082\n",
      "test Acc 0.9781191806331471:\n",
      "26th- epoch: 73, train_loss = 7.775420332327485, train_acc = 0.9843968327899395\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 74, train_loss = 7.6682102382183075, train_acc = 0.9847461574289706\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 75, train_loss = 7.563228372484446, train_acc = 0.9852119236143456\n",
      "test Acc 0.978584729981378:\n",
      "26th- epoch: 76, train_loss = 7.46015171520412, train_acc = 0.9855612482533768\n",
      "test Acc 0.979050279329609:\n",
      "26th- epoch: 77, train_loss = 7.3594401981681585, train_acc = 0.9856776897997206\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 78, train_loss = 7.2607540637254715, train_acc = 0.9857941313460643\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 79, train_loss = 7.163932645693421, train_acc = 0.985910572892408\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 80, train_loss = 7.06915589235723, train_acc = 0.985910572892408\n",
      "test Acc 0.9804469273743017:\n",
      "26th- epoch: 81, train_loss = 6.9762317799031734, train_acc = 0.985910572892408\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 82, train_loss = 6.885147958993912, train_acc = 0.9860270144387517\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 83, train_loss = 6.795974409207702, train_acc = 0.9862598975314392\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 84, train_loss = 6.708448637276888, train_acc = 0.9862598975314392\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 85, train_loss = 6.622643897309899, train_acc = 0.9864927806241267\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 86, train_loss = 6.53847018070519, train_acc = 0.9866092221704704\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 87, train_loss = 6.455809222534299, train_acc = 0.9867256637168141\n",
      "test Acc 0.9809124767225326:\n",
      "26th- epoch: 88, train_loss = 6.374813821166754, train_acc = 0.9869585468095017\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 89, train_loss = 6.295183636248112, train_acc = 0.9873078714485328\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 90, train_loss = 6.217090420424938, train_acc = 0.9874243129948765\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 91, train_loss = 6.140408735722303, train_acc = 0.9878900791802515\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 92, train_loss = 6.06496998667717, train_acc = 0.9880065207265952\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 93, train_loss = 5.99090164154768, train_acc = 0.9881229622729389\n",
      "test Acc 0.9823091247672253:\n",
      "26th- epoch: 94, train_loss = 5.918176002800465, train_acc = 0.9884722869119702\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 95, train_loss = 5.84682229347527, train_acc = 0.9888216115510013\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 96, train_loss = 5.776824774220586, train_acc = 0.9889380530973452\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 97, train_loss = 5.708086846396327, train_acc = 0.9891709361900326\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 98, train_loss = 5.640513984486461, train_acc = 0.98940381928272\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 99, train_loss = 5.574412826448679, train_acc = 0.9895202608290639\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 100, train_loss = 5.509334536269307, train_acc = 0.9896367023754076\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 101, train_loss = 5.445642359554768, train_acc = 0.9895202608290639\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 102, train_loss = 5.383009383454919, train_acc = 0.98940381928272\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 103, train_loss = 5.321668296121061, train_acc = 0.98940381928272\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 104, train_loss = 5.261312021873891, train_acc = 0.9897531439217513\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 105, train_loss = 5.202216780744493, train_acc = 0.989869585468095\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 106, train_loss = 5.144112958572805, train_acc = 0.9901024685607824\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 107, train_loss = 5.087084081955254, train_acc = 0.9902189101071263\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 108, train_loss = 5.03098754119128, train_acc = 0.9904517931998137\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 109, train_loss = 4.975933902896941, train_acc = 0.9905682347461574\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 110, train_loss = 4.921760222874582, train_acc = 0.9909175593851887\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 111, train_loss = 4.868489678017795, train_acc = 0.9909175593851887\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 112, train_loss = 4.816162257455289, train_acc = 0.9909175593851887\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 113, train_loss = 4.76480798330158, train_acc = 0.9910340009315324\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 114, train_loss = 4.714266690425575, train_acc = 0.9910340009315324\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 115, train_loss = 4.664546511135995, train_acc = 0.9911504424778761\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 116, train_loss = 4.615761131979525, train_acc = 0.9912668840242198\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 117, train_loss = 4.5677889017388225, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 118, train_loss = 4.520745820365846, train_acc = 0.9916162086632511\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 119, train_loss = 4.4743683794513345, train_acc = 0.9918490917559385\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 120, train_loss = 4.428943943232298, train_acc = 0.9919655333022822\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 121, train_loss = 4.384123168885708, train_acc = 0.9919655333022822\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 122, train_loss = 4.340065150521696, train_acc = 0.992081974848626\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 123, train_loss = 4.296774115413427, train_acc = 0.992081974848626\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 124, train_loss = 4.254176486283541, train_acc = 0.9923148579413135\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 125, train_loss = 4.212201309390366, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 126, train_loss = 4.170906795188785, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 127, train_loss = 4.13030950166285, train_acc = 0.9932463903120633\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 128, train_loss = 4.090393838472664, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 129, train_loss = 4.051147517748177, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 130, train_loss = 4.012585454620421, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 131, train_loss = 3.97465836443007, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 132, train_loss = 3.937305453233421, train_acc = 0.993828598043782\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 133, train_loss = 3.9005727590993047, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 134, train_loss = 3.8643000284209847, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 135, train_loss = 3.8286602525040507, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 136, train_loss = 3.7936189733445644, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 137, train_loss = 3.7590296203270555, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 138, train_loss = 3.7250129310414195, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 139, train_loss = 3.691533643286675, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 140, train_loss = 3.6584863867610693, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 141, train_loss = 3.625857236329466, train_acc = 0.9940614811364695\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 142, train_loss = 3.5937694534659386, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 143, train_loss = 3.562226763460785, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 144, train_loss = 3.5312648210674524, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 145, train_loss = 3.5006565083749592, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 146, train_loss = 3.4705499610863626, train_acc = 0.9944108057755007\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 147, train_loss = 3.4409917783923447, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 148, train_loss = 3.4117501680739224, train_acc = 0.9945272473218444\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 149, train_loss = 3.38301563821733, train_acc = 0.9946436888681882\n",
      "test Acc 0.9827746741154563:\n",
      "26th- epoch: 150, train_loss = 3.35466711781919, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 151, train_loss = 3.3268291410058737, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 152, train_loss = 3.299211608245969, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 153, train_loss = 3.2722287997603416, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 154, train_loss = 3.2454699594527483, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 155, train_loss = 3.219089324120432, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 156, train_loss = 3.193213297519833, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 157, train_loss = 3.167530902195722, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 158, train_loss = 3.1423717755824327, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 159, train_loss = 3.117394247557968, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 160, train_loss = 3.0928522939793766, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 161, train_loss = 3.0686149862594903, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 162, train_loss = 3.0447224867530167, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 163, train_loss = 3.0211552027612925, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 164, train_loss = 2.9978853687644005, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 165, train_loss = 2.9749366394244134, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 166, train_loss = 2.952294600661844, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 167, train_loss = 2.930042549967766, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 168, train_loss = 2.907969897147268, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 169, train_loss = 2.886271069291979, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 170, train_loss = 2.8647753573022783, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 171, train_loss = 2.8436293485574424, train_acc = 0.9952258965999069\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 172, train_loss = 2.822801839094609, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 173, train_loss = 2.802186803892255, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 174, train_loss = 2.7819070550613105, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 175, train_loss = 2.761913401540369, train_acc = 0.9954587796925943\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 176, train_loss = 2.7420543525367975, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 177, train_loss = 2.7226947229355574, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 178, train_loss = 2.7034106589853764, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 179, train_loss = 2.6844026166945696, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 180, train_loss = 2.665626437868923, train_acc = 0.995575221238938\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 181, train_loss = 2.647172483149916, train_acc = 0.9956916627852818\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 182, train_loss = 2.6288479398936033, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 183, train_loss = 2.610802263021469, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 184, train_loss = 2.5929828316438943, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 185, train_loss = 2.575512293726206, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 186, train_loss = 2.5581506092566997, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 187, train_loss = 2.5409691978711635, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 188, train_loss = 2.5241257045418024, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 189, train_loss = 2.507553559495136, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 190, train_loss = 2.4910434279590845, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 191, train_loss = 2.4748832390177995, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 192, train_loss = 2.458841413957998, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 193, train_loss = 2.443063950864598, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 194, train_loss = 2.427409188821912, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 195, train_loss = 2.412109487922862, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 196, train_loss = 2.3968606032431126, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 197, train_loss = 2.381887600524351, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 198, train_loss = 2.3670493867248297, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 199, train_loss = 2.3525409132707864, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 200, train_loss = 2.3380029138643295, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 201, train_loss = 2.3237901348620653, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 202, train_loss = 2.3096513263881207, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 203, train_loss = 2.2957095317542553, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 204, train_loss = 2.2819990410935134, train_acc = 0.9959245458779693\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 205, train_loss = 2.268487361492589, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 206, train_loss = 2.2551697604358196, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 207, train_loss = 2.2418724701274186, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 208, train_loss = 2.228888314915821, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 209, train_loss = 2.216069385409355, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "26th- epoch: 210, train_loss = 2.2033373105805367, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 211, train_loss = 2.1908397383522242, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 212, train_loss = 2.178470191312954, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 213, train_loss = 2.1662320618052036, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 214, train_loss = 2.154205684782937, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 215, train_loss = 2.142305512679741, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 216, train_loss = 2.1305817142128944, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 217, train_loss = 2.11890432680957, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 218, train_loss = 2.1075169791001827, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 219, train_loss = 2.0962170579005033, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 220, train_loss = 2.085034320829436, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 221, train_loss = 2.073997899889946, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 222, train_loss = 2.063174766721204, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 223, train_loss = 2.052393549354747, train_acc = 0.9962738705170004\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 224, train_loss = 2.0418634489178658, train_acc = 0.9963903120633442\n",
      "test Acc 0.9837057728119181:\n",
      "26th- epoch: 225, train_loss = 2.0313450917601585, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 226, train_loss = 2.0210093818604946, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 227, train_loss = 2.0107800711411983, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 228, train_loss = 2.0007067311089486, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 229, train_loss = 1.990788484690711, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 230, train_loss = 1.980893525062129, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 231, train_loss = 1.9711599436122924, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 232, train_loss = 1.961616662563756, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 233, train_loss = 1.9520981248933822, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 234, train_loss = 1.9427998252213001, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "26th- epoch: 235, train_loss = 1.9335261720698327, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 236, train_loss = 1.9244470472913235, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 237, train_loss = 1.915420112432912, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 238, train_loss = 1.9065653358120471, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 239, train_loss = 1.89775826910045, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 240, train_loss = 1.8890953660011292, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 241, train_loss = 1.8803951516747475, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 242, train_loss = 1.8719339184463024, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 243, train_loss = 1.863562822341919, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 244, train_loss = 1.8552008954575285, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 245, train_loss = 1.847036843537353, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 246, train_loss = 1.8389373483369127, train_acc = 0.9968560782487191\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 247, train_loss = 1.8309269758174196, train_acc = 0.9970889613414066\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 248, train_loss = 1.8229880990693346, train_acc = 0.9970889613414066\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 249, train_loss = 1.8152473730733618, train_acc = 0.9970889613414066\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 250, train_loss = 1.8074714528629556, train_acc = 0.9970889613414066\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 251, train_loss = 1.799829045892693, train_acc = 0.9970889613414066\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 252, train_loss = 1.7923113442957401, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "26th- epoch: 253, train_loss = 1.784838823019527, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 254, train_loss = 1.7774309379747137, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 255, train_loss = 1.7702037543058395, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "26th- epoch: 256, train_loss = 1.762908880948089, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 257, train_loss = 1.7557806322583929, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 258, train_loss = 1.748707735328935, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 259, train_loss = 1.7417668936541304, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 260, train_loss = 1.7348460666835308, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 261, train_loss = 1.7280542738735676, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 262, train_loss = 1.7212605426320806, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 263, train_loss = 1.714552061050199, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 264, train_loss = 1.707954759360291, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 265, train_loss = 1.7014123847475275, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 266, train_loss = 1.6949131228029728, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 267, train_loss = 1.688559445203282, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 268, train_loss = 1.6821533379843459, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 269, train_loss = 1.6759394345572218, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 270, train_loss = 1.6697041305014864, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 271, train_loss = 1.663500310271047, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 272, train_loss = 1.6575650783488527, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 273, train_loss = 1.6514296879759058, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 274, train_loss = 1.6455409241607413, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "26th- epoch: 275, train_loss = 1.6395499123027548, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 276, train_loss = 1.633732353686355, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 277, train_loss = 1.6279708991060033, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 278, train_loss = 1.6222355155041441, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 279, train_loss = 1.6165926394751295, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 280, train_loss = 1.6109496528515592, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 281, train_loss = 1.6054488817462698, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 282, train_loss = 1.5998641116311774, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 283, train_loss = 1.5944854927947745, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 284, train_loss = 1.589040707796812, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 285, train_loss = 1.5837207237491384, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 286, train_loss = 1.578385872184299, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 287, train_loss = 1.573245664476417, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 288, train_loss = 1.568005365668796, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 289, train_loss = 1.5628745319554582, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 290, train_loss = 1.5577790141105652, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 291, train_loss = 1.5527851121732965, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 292, train_loss = 1.5476949587464333, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 293, train_loss = 1.5428743436932564, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 294, train_loss = 1.5378955379128456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 295, train_loss = 1.5330789051949978, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 296, train_loss = 1.5282758884131908, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 297, train_loss = 1.5234890965512022, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 298, train_loss = 1.5187291590264067, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 299, train_loss = 1.5140821846434847, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 300, train_loss = 1.5093634439399466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 301, train_loss = 1.5048392588505521, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 302, train_loss = 1.5002662973711267, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 303, train_loss = 1.4957171119749546, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 304, train_loss = 1.4913161856820807, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 305, train_loss = 1.486766462563537, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 306, train_loss = 1.4824447879800573, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 307, train_loss = 1.4780485766823404, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 308, train_loss = 1.4737791257794015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 309, train_loss = 1.4694713167846203, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 310, train_loss = 1.4652421164209954, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 311, train_loss = 1.460985116660595, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 312, train_loss = 1.4568694246117957, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 313, train_loss = 1.4526569384033792, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 314, train_loss = 1.4485670899157412, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "26th- epoch: 315, train_loss = 1.4445505129988305, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 316, train_loss = 1.4404790066182613, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 317, train_loss = 1.4364277484710328, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 318, train_loss = 1.4325517776305787, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 319, train_loss = 1.42850287881447, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 320, train_loss = 1.4246594707365148, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 321, train_loss = 1.4208065693383105, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 322, train_loss = 1.4168773293495178, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 323, train_loss = 1.4131674517993815, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 324, train_loss = 1.4093060058658011, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 325, train_loss = 1.4055494579370134, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 326, train_loss = 1.4017467647790909, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 327, train_loss = 1.3981309669907205, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 328, train_loss = 1.3943696568603627, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 329, train_loss = 1.390817402570974, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 330, train_loss = 1.387274295091629, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 331, train_loss = 1.3835990552906878, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 332, train_loss = 1.380079336464405, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 333, train_loss = 1.376587440550793, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 334, train_loss = 1.3731075040996075, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 335, train_loss = 1.369649877131451, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 336, train_loss = 1.3661478633875959, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 337, train_loss = 1.362794244021643, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 338, train_loss = 1.3594281834666617, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 339, train_loss = 1.3559828475117683, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 340, train_loss = 1.3527683094143867, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 341, train_loss = 1.3494475148618221, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 342, train_loss = 1.3460963889956474, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 343, train_loss = 1.3428507335484028, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 344, train_loss = 1.3396753656561486, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 345, train_loss = 1.3363915979862213, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 346, train_loss = 1.3332692843978293, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 347, train_loss = 1.3300829741056077, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 348, train_loss = 1.3269627330009826, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 349, train_loss = 1.3238791450858116, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 350, train_loss = 1.3207223527133465, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 351, train_loss = 1.3176820439402945, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 352, train_loss = 1.3146120223100297, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 353, train_loss = 1.3115122529561631, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 354, train_loss = 1.3085483312606812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 355, train_loss = 1.3054247684776783, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 356, train_loss = 1.3025650096242316, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 357, train_loss = 1.2995087330345996, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 358, train_loss = 1.2966658721561544, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 359, train_loss = 1.2937074725632556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 360, train_loss = 1.2909052570466883, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 361, train_loss = 1.288092963397503, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 362, train_loss = 1.2851379265193827, train_acc = 0.9977876106194691\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 363, train_loss = 1.2824344511027448, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 364, train_loss = 1.2796290392871015, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 365, train_loss = 1.2768860645592213, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 366, train_loss = 1.2740958618815057, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 367, train_loss = 1.2714326865971088, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 368, train_loss = 1.268620991439093, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 369, train_loss = 1.265954916656483, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 370, train_loss = 1.2633128575980663, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 371, train_loss = 1.2606567554175854, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 372, train_loss = 1.2580265713040717, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 373, train_loss = 1.2553327518398874, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 374, train_loss = 1.2528135155444033, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 375, train_loss = 1.2501501540536992, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 376, train_loss = 1.2476339948480017, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 377, train_loss = 1.2450519539415836, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 378, train_loss = 1.2426001231069677, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 379, train_loss = 1.2399409599602222, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 380, train_loss = 1.2373870238661766, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 381, train_loss = 1.2350958536262624, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 382, train_loss = 1.2325313513283618, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 383, train_loss = 1.2300567291676998, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 384, train_loss = 1.227647704363335, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 385, train_loss = 1.225201852619648, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 386, train_loss = 1.222779769450426, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 387, train_loss = 1.2203941742773168, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 388, train_loss = 1.2180504277348518, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 389, train_loss = 1.2156441596453078, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 390, train_loss = 1.2133461572229862, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 391, train_loss = 1.211070338904392, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 392, train_loss = 1.2087056177551858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 393, train_loss = 1.206402099400293, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 394, train_loss = 1.204094907909166, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 395, train_loss = 1.2018545145983808, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 396, train_loss = 1.1995359870197717, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 397, train_loss = 1.1974120736122131, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 398, train_loss = 1.1951363893749658, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 399, train_loss = 1.192937040090328, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 400, train_loss = 1.190685234963894, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 401, train_loss = 1.1885998571815435, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 402, train_loss = 1.1863630612788256, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 403, train_loss = 1.1841456194815692, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 404, train_loss = 1.1819767455162946, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 405, train_loss = 1.1798813181521837, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 406, train_loss = 1.1777417808771133, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 407, train_loss = 1.175618965178728, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 408, train_loss = 1.173487896710867, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 409, train_loss = 1.1715445232985076, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 410, train_loss = 1.169393002986908, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 411, train_loss = 1.1673189091088716, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 412, train_loss = 1.1652533188462257, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 413, train_loss = 1.1632751102151815, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 414, train_loss = 1.1611493627133314, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 415, train_loss = 1.1592813680472318, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 416, train_loss = 1.157237426697975, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 417, train_loss = 1.1551901996135712, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 418, train_loss = 1.153290065616602, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 419, train_loss = 1.1513810319302138, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 420, train_loss = 1.1492755065264646, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 421, train_loss = 1.1474831303057726, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 422, train_loss = 1.1454443894326687, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 423, train_loss = 1.1435604393482208, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 424, train_loss = 1.1416308147308882, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 425, train_loss = 1.1397609772684518, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 426, train_loss = 1.1378455311059952, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 427, train_loss = 1.1360387379827444, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 428, train_loss = 1.1340650332567748, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 429, train_loss = 1.132343983888859, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 430, train_loss = 1.1304136638937052, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 431, train_loss = 1.1286311646399554, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 432, train_loss = 1.1266946556570474, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 433, train_loss = 1.1250253866019193, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 434, train_loss = 1.1231486139295157, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 435, train_loss = 1.1213956661522388, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 436, train_loss = 1.1195378278789576, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 437, train_loss = 1.1178505991993006, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 438, train_loss = 1.1161146784725133, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 439, train_loss = 1.114293890685076, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 440, train_loss = 1.1125047306122724, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 441, train_loss = 1.1106179592607077, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26th- epoch: 442, train_loss = 1.1091838628053665, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 443, train_loss = 1.1074069713649806, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 444, train_loss = 1.1056173332035542, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 445, train_loss = 1.1037538883683737, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 446, train_loss = 1.1023063895700034, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 447, train_loss = 1.1006757678987924, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 448, train_loss = 1.0987259782850742, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 449, train_loss = 1.0972819725575391, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 450, train_loss = 1.095626456051832, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 451, train_loss = 1.0937630881962832, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 452, train_loss = 1.0923145661654416, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 453, train_loss = 1.0908136715588626, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 454, train_loss = 1.0890241178276483, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 455, train_loss = 1.0874448542890605, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 456, train_loss = 1.0857795352640096, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 457, train_loss = 1.084318400680786, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 458, train_loss = 1.0826142132282257, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 459, train_loss = 1.0809144154191017, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 460, train_loss = 1.0794348964991514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 461, train_loss = 1.0777648712100927, train_acc = 0.9979040521658128\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 462, train_loss = 1.07622959712171, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 463, train_loss = 1.074785961449379, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 464, train_loss = 1.0730921501817647, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 465, train_loss = 1.0716394198534545, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 466, train_loss = 1.0701863368449267, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 467, train_loss = 1.0684333393874113, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 468, train_loss = 1.0671710198221263, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 469, train_loss = 1.0656646291317884, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 470, train_loss = 1.0639669386146124, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 471, train_loss = 1.0627142265439034, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 472, train_loss = 1.0610991629364435, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 473, train_loss = 1.0598364286124706, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 474, train_loss = 1.0580802063050214, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 475, train_loss = 1.056795177370077, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 476, train_loss = 1.0553460543451365, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 477, train_loss = 1.0539612099528313, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 478, train_loss = 1.052441322564846, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 479, train_loss = 1.0510587878525257, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 480, train_loss = 1.049532982200617, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 481, train_loss = 1.0482889798877295, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 482, train_loss = 1.0467770410177764, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 483, train_loss = 1.045402381569147, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 484, train_loss = 1.0438563637435436, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 485, train_loss = 1.0424960615637247, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 486, train_loss = 1.0411715780792292, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 487, train_loss = 1.0400775857269764, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 488, train_loss = 1.0383280056121293, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 489, train_loss = 1.0371688840386923, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 490, train_loss = 1.035516211151844, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 491, train_loss = 1.0345394598843995, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 492, train_loss = 1.033033608138794, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 493, train_loss = 1.0317346006631851, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 494, train_loss = 1.0303644413652364, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 495, train_loss = 1.0291548135282937, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 496, train_loss = 1.027717299759388, train_acc = 0.9980204937121565\n",
      "test Acc 0.9869646182495344:\n",
      "26th- epoch: 497, train_loss = 1.0265495963394642, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "26th- epoch: 498, train_loss = 1.0248478477296885, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n",
      "26th- epoch: 499, train_loss = 1.02403717362904, train_acc = 0.9980204937121565\n",
      "test Acc 0.9864990689013036:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|██████████████████████████████████████████████████████████████▍         | 26/30 [2:57:37<27:24, 411.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "27th- epoch: 0, train_loss = 270.071494102478, train_acc = 0.4763623660922217\n",
      "test Acc 0.5702979515828678:\n",
      "27th- epoch: 1, train_loss = 208.28842914104462, train_acc = 0.5561248253376805\n",
      "test Acc 0.5665735567970205:\n",
      "27th- epoch: 2, train_loss = 164.44804072380066, train_acc = 0.5859338612016768\n",
      "test Acc 0.6247672253258846:\n",
      "27th- epoch: 3, train_loss = 137.75022900104523, train_acc = 0.6794364229156963\n",
      "test Acc 0.7164804469273743:\n",
      "27th- epoch: 4, train_loss = 117.98581022024155, train_acc = 0.7346297158826269\n",
      "test Acc 0.7569832402234636:\n",
      "27th- epoch: 5, train_loss = 102.48236858844757, train_acc = 0.7612948299953424\n",
      "test Acc 0.7728119180633147:\n",
      "27th- epoch: 6, train_loss = 90.08819234371185, train_acc = 0.7780624126688402\n",
      "test Acc 0.7918994413407822:\n",
      "27th- epoch: 7, train_loss = 79.95633745193481, train_acc = 0.8096180717279925\n",
      "test Acc 0.8198324022346368:\n",
      "27th- epoch: 8, train_loss = 71.34109815955162, train_acc = 0.8423381462505822\n",
      "test Acc 0.8538175046554934:\n",
      "27th- epoch: 9, train_loss = 63.839722245931625, train_acc = 0.8685374941779227\n",
      "test Acc 0.8845437616387337:\n",
      "27th- epoch: 10, train_loss = 57.31349064409733, train_acc = 0.8933395435491384\n",
      "test Acc 0.9068901303538175:\n",
      "27th- epoch: 11, train_loss = 51.69326975941658, train_acc = 0.9078947368421053\n",
      "test Acc 0.9222532588454376:\n",
      "27th- epoch: 12, train_loss = 46.89243532717228, train_acc = 0.9224499301350721\n",
      "test Acc 0.9315642458100558:\n",
      "27th- epoch: 13, train_loss = 42.79106426239014, train_acc = 0.9307172799254774\n",
      "test Acc 0.9371508379888268:\n",
      "27th- epoch: 14, train_loss = 39.26988863945007, train_acc = 0.9370051234280391\n",
      "test Acc 0.9390130353817505:\n",
      "27th- epoch: 15, train_loss = 36.24047702550888, train_acc = 0.9392175128085701\n",
      "test Acc 0.9408752327746741:\n",
      "27th- epoch: 16, train_loss = 33.633025363087654, train_acc = 0.9410805775500699\n",
      "test Acc 0.9464618249534451:\n",
      "27th- epoch: 17, train_loss = 31.37960523366928, train_acc = 0.9442244993013508\n",
      "test Acc 0.9473929236499069:\n",
      "27th- epoch: 18, train_loss = 29.424479082226753, train_acc = 0.9486492780624126\n",
      "test Acc 0.9539106145251397:\n",
      "27th- epoch: 19, train_loss = 27.723043829202652, train_acc = 0.9533069399161621\n",
      "test Acc 0.9553072625698324:\n",
      "27th- epoch: 20, train_loss = 26.23628882318735, train_acc = 0.9550535631113182\n",
      "test Acc 0.9557728119180633:\n",
      "27th- epoch: 21, train_loss = 24.929337367415428, train_acc = 0.9569166278528178\n",
      "test Acc 0.957169459962756:\n",
      "27th- epoch: 22, train_loss = 23.77478038519621, train_acc = 0.9581974848625989\n",
      "test Acc 0.9581005586592178:\n",
      "27th- epoch: 23, train_loss = 22.74755273759365, train_acc = 0.9598276665114113\n",
      "test Acc 0.9604283054003724:\n",
      "27th- epoch: 24, train_loss = 21.827030055224895, train_acc = 0.961690731252911\n",
      "test Acc 0.9608938547486033:\n",
      "27th- epoch: 25, train_loss = 20.99654084444046, train_acc = 0.9630880298090359\n",
      "test Acc 0.9613594040968343:\n",
      "27th- epoch: 26, train_loss = 20.242158990353346, train_acc = 0.963903120633442\n",
      "test Acc 0.9608938547486033:\n",
      "27th- epoch: 27, train_loss = 19.55195354297757, train_acc = 0.963903120633442\n",
      "test Acc 0.9608938547486033:\n",
      "27th- epoch: 28, train_loss = 18.917190488427877, train_acc = 0.9647182114578482\n",
      "test Acc 0.9613594040968343:\n",
      "27th- epoch: 29, train_loss = 18.329446963965893, train_acc = 0.9653004191895669\n",
      "test Acc 0.9622905027932961:\n",
      "27th- epoch: 30, train_loss = 17.783211331814528, train_acc = 0.966581276199348\n",
      "test Acc 0.9622905027932961:\n",
      "27th- epoch: 31, train_loss = 17.273779958486557, train_acc = 0.9673963670237541\n",
      "test Acc 0.9622905027932961:\n",
      "27th- epoch: 32, train_loss = 16.797136019915342, train_acc = 0.9679785747554728\n",
      "test Acc 0.9632216014897579:\n",
      "27th- epoch: 33, train_loss = 16.349655997008085, train_acc = 0.9686772240335352\n",
      "test Acc 0.9646182495344506:\n",
      "27th- epoch: 34, train_loss = 15.928276602178812, train_acc = 0.9692594317652539\n",
      "test Acc 0.9664804469273743:\n",
      "27th- epoch: 35, train_loss = 15.530295133590698, train_acc = 0.9697251979506288\n",
      "test Acc 0.9664804469273743:\n",
      "27th- epoch: 36, train_loss = 15.15114264562726, train_acc = 0.9706567303213787\n",
      "test Acc 0.9674115456238361:\n",
      "27th- epoch: 37, train_loss = 14.79059648141265, train_acc = 0.971821145784816\n",
      "test Acc 0.9692737430167597:\n",
      "27th- epoch: 38, train_loss = 14.44879038259387, train_acc = 0.9728691197019096\n",
      "test Acc 0.9716014897579144:\n",
      "27th- epoch: 39, train_loss = 14.124625913798809, train_acc = 0.9735677689799721\n",
      "test Acc 0.973463687150838:\n",
      "27th- epoch: 40, train_loss = 13.816038731485605, train_acc = 0.9744993013507219\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 41, train_loss = 13.521806702017784, train_acc = 0.9749650675360969\n",
      "test Acc 0.9748603351955307:\n",
      "27th- epoch: 42, train_loss = 13.240418754518032, train_acc = 0.975780158360503\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 43, train_loss = 12.971390917897224, train_acc = 0.9761294829995343\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 44, train_loss = 12.71331675350666, train_acc = 0.976245924545878\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 45, train_loss = 12.465642243623734, train_acc = 0.9763623660922217\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 46, train_loss = 12.227981846779585, train_acc = 0.9767116907312529\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 47, train_loss = 11.999359704554081, train_acc = 0.9768281322775967\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 48, train_loss = 11.77936601638794, train_acc = 0.9775267815556591\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 49, train_loss = 11.567369639873505, train_acc = 0.9781089892873778\n",
      "test Acc 0.9753258845437617:\n",
      "27th- epoch: 50, train_loss = 11.363047733902931, train_acc = 0.9792734047508151\n",
      "test Acc 0.9757914338919925:\n",
      "27th- epoch: 51, train_loss = 11.165765669196844, train_acc = 0.9793898462971589\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 52, train_loss = 10.97508255764842, train_acc = 0.97973917093619\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 53, train_loss = 10.790851071476936, train_acc = 0.9799720540288775\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 54, train_loss = 10.612537994980812, train_acc = 0.9805542617605962\n",
      "test Acc 0.9762569832402235:\n",
      "27th- epoch: 55, train_loss = 10.439769083634019, train_acc = 0.98067070330694\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 56, train_loss = 10.272094212472439, train_acc = 0.9814857941313461\n",
      "test Acc 0.9767225325884544:\n",
      "27th- epoch: 57, train_loss = 10.109239606186748, train_acc = 0.9817186772240335\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 58, train_loss = 9.951025933027267, train_acc = 0.9820680018630648\n",
      "test Acc 0.9771880819366853:\n",
      "27th- epoch: 59, train_loss = 9.797364547848701, train_acc = 0.9825337680484397\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 60, train_loss = 9.647668689489365, train_acc = 0.9826502095947834\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 61, train_loss = 9.501740200445056, train_acc = 0.9828830926874709\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 62, train_loss = 9.359513908624649, train_acc = 0.9829995342338146\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 63, train_loss = 9.221053814515471, train_acc = 0.9832324173265021\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 64, train_loss = 9.08587477914989, train_acc = 0.9832324173265021\n",
      "test Acc 0.9776536312849162:\n",
      "27th- epoch: 65, train_loss = 8.953987857326865, train_acc = 0.9834653004191896\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 66, train_loss = 8.825116707012057, train_acc = 0.983698183511877\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 67, train_loss = 8.699237789958715, train_acc = 0.9839310666045645\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 68, train_loss = 8.576321594417095, train_acc = 0.9840475081509082\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 69, train_loss = 8.456039080396295, train_acc = 0.984163949697252\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 70, train_loss = 8.3384745772928, train_acc = 0.984163949697252\n",
      "test Acc 0.9781191806331471:\n",
      "27th- epoch: 71, train_loss = 8.223412677645683, train_acc = 0.9845132743362832\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 72, train_loss = 8.110789109021425, train_acc = 0.9846297158826269\n",
      "test Acc 0.978584729981378:\n",
      "27th- epoch: 73, train_loss = 8.00046973861754, train_acc = 0.9848625989753144\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 74, train_loss = 7.89241324737668, train_acc = 0.9848625989753144\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 75, train_loss = 7.786563239991665, train_acc = 0.9849790405216581\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 76, train_loss = 7.6828206069767475, train_acc = 0.9849790405216581\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 77, train_loss = 7.581081910058856, train_acc = 0.9852119236143456\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 78, train_loss = 7.481425633653998, train_acc = 0.9853283651606893\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 79, train_loss = 7.383620008826256, train_acc = 0.9853283651606893\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 80, train_loss = 7.287610732018948, train_acc = 0.9855612482533768\n",
      "test Acc 0.979050279329609:\n",
      "27th- epoch: 81, train_loss = 7.193340411409736, train_acc = 0.9856776897997206\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 82, train_loss = 7.100760705769062, train_acc = 0.9857941313460643\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 83, train_loss = 7.010014133527875, train_acc = 0.9857941313460643\n",
      "test Acc 0.9795158286778398:\n",
      "27th- epoch: 84, train_loss = 6.9209941085428, train_acc = 0.9860270144387517\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 85, train_loss = 6.833500636741519, train_acc = 0.9861434559850955\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 86, train_loss = 6.747630052268505, train_acc = 0.9862598975314392\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 87, train_loss = 6.663485061377287, train_acc = 0.986376339077783\n",
      "test Acc 0.9799813780260708:\n",
      "27th- epoch: 88, train_loss = 6.580923702567816, train_acc = 0.9868421052631579\n",
      "test Acc 0.9804469273743017:\n",
      "27th- epoch: 89, train_loss = 6.499982390552759, train_acc = 0.9868421052631579\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 90, train_loss = 6.420529197901487, train_acc = 0.9869585468095017\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 91, train_loss = 6.342642107978463, train_acc = 0.9869585468095017\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 92, train_loss = 6.266094475984573, train_acc = 0.9871914299021891\n",
      "test Acc 0.9809124767225326:\n",
      "27th- epoch: 93, train_loss = 6.190908540040255, train_acc = 0.9873078714485328\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 94, train_loss = 6.117096757516265, train_acc = 0.9876571960875641\n",
      "test Acc 0.9813780260707635:\n",
      "27th- epoch: 95, train_loss = 6.044653948396444, train_acc = 0.9881229622729389\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 96, train_loss = 5.97373415902257, train_acc = 0.9887051700046576\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 97, train_loss = 5.90386675298214, train_acc = 0.9887051700046576\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 98, train_loss = 5.835386456921697, train_acc = 0.9888216115510013\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 99, train_loss = 5.768098520115018, train_acc = 0.9888216115510013\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 100, train_loss = 5.702041074633598, train_acc = 0.9889380530973452\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 101, train_loss = 5.637058061547577, train_acc = 0.9891709361900326\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 102, train_loss = 5.573257674463093, train_acc = 0.9892873777363763\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 103, train_loss = 5.510482748970389, train_acc = 0.9892873777363763\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 104, train_loss = 5.448799223639071, train_acc = 0.98940381928272\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 105, train_loss = 5.388204145245254, train_acc = 0.98940381928272\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 106, train_loss = 5.3287109201774, train_acc = 0.9896367023754076\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 107, train_loss = 5.270269961096346, train_acc = 0.989869585468095\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 108, train_loss = 5.212739760056138, train_acc = 0.989869585468095\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 109, train_loss = 5.156213516369462, train_acc = 0.9902189101071263\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 110, train_loss = 5.100526148453355, train_acc = 0.9904517931998137\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 111, train_loss = 5.045955842360854, train_acc = 0.9905682347461574\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 112, train_loss = 4.992136713117361, train_acc = 0.9905682347461574\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 113, train_loss = 4.9391736928373575, train_acc = 0.9910340009315324\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 114, train_loss = 4.887135670520365, train_acc = 0.9910340009315324\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 115, train_loss = 4.83592393156141, train_acc = 0.9911504424778761\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 116, train_loss = 4.785569467581809, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 117, train_loss = 4.735937846824527, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 118, train_loss = 4.687162569724023, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 119, train_loss = 4.639017610810697, train_acc = 0.9916162086632511\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 120, train_loss = 4.591643397696316, train_acc = 0.9916162086632511\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 121, train_loss = 4.544950870797038, train_acc = 0.9918490917559385\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 122, train_loss = 4.4989913227036595, train_acc = 0.992081974848626\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 123, train_loss = 4.4536897130310535, train_acc = 0.9923148579413135\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 124, train_loss = 4.4090370973572135, train_acc = 0.9924312994876572\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 125, train_loss = 4.365126406773925, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 126, train_loss = 4.32187585812062, train_acc = 0.9925477410340009\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 127, train_loss = 4.279260697774589, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 128, train_loss = 4.237351377494633, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 129, train_loss = 4.196101342327893, train_acc = 0.9926641825803446\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 130, train_loss = 4.1555494396016, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 131, train_loss = 4.115630337037146, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 132, train_loss = 4.076303793117404, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 133, train_loss = 4.037557007744908, train_acc = 0.9928970656730322\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 134, train_loss = 3.999376155436039, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 135, train_loss = 3.96187671367079, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 136, train_loss = 3.924850733485073, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 137, train_loss = 3.8883236688561738, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 138, train_loss = 3.8524655643850565, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 139, train_loss = 3.8170945621095598, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 140, train_loss = 3.7822392960079014, train_acc = 0.9934792734047508\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 141, train_loss = 3.7479558382183313, train_acc = 0.9935957149510946\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 142, train_loss = 3.714138137176633, train_acc = 0.9935957149510946\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 143, train_loss = 3.6808597333729267, train_acc = 0.9935957149510946\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 144, train_loss = 3.6480573173612356, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 145, train_loss = 3.615807823371142, train_acc = 0.9935957149510946\n",
      "test Acc 0.9827746741154563:\n",
      "27th- epoch: 146, train_loss = 3.583898342680186, train_acc = 0.9937121564974383\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 147, train_loss = 3.5526631958782673, train_acc = 0.9937121564974383\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 148, train_loss = 3.5216823522932827, train_acc = 0.993828598043782\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 149, train_loss = 3.491290141362697, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 150, train_loss = 3.4612093432806432, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 151, train_loss = 3.431675700470805, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 152, train_loss = 3.4025133862160146, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 153, train_loss = 3.3738681375980377, train_acc = 0.9941779226828132\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 154, train_loss = 3.345581043045968, train_acc = 0.994294364229157\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 155, train_loss = 3.3177516483701766, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 156, train_loss = 3.290230926591903, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 157, train_loss = 3.263313950970769, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 158, train_loss = 3.2364636748097837, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 159, train_loss = 3.2103500440716743, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 160, train_loss = 3.1843182086013258, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 161, train_loss = 3.158865665551275, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 162, train_loss = 3.133629759773612, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 163, train_loss = 3.1088278307579458, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 164, train_loss = 3.0844272919930518, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 165, train_loss = 3.0603268132545054, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 166, train_loss = 3.036473523825407, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 167, train_loss = 3.0131134404800832, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 168, train_loss = 2.989948460366577, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 169, train_loss = 2.967167006339878, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 170, train_loss = 2.944646082818508, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 171, train_loss = 2.922555536031723, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 172, train_loss = 2.90054953051731, train_acc = 0.9948765719608756\n",
      "test Acc 0.9832402234636871:\n",
      "27th- epoch: 173, train_loss = 2.879081137944013, train_acc = 0.9948765719608756\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 174, train_loss = 2.8577300310134888, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 175, train_loss = 2.8367382218129933, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 176, train_loss = 2.8159282938577235, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 177, train_loss = 2.7956290256697685, train_acc = 0.9951094550535631\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 178, train_loss = 2.7753960117697716, train_acc = 0.9952258965999069\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 179, train_loss = 2.7554992723744363, train_acc = 0.9953423381462506\n",
      "test Acc 0.9837057728119181:\n",
      "27th- epoch: 180, train_loss = 2.735828474164009, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 181, train_loss = 2.7164179168175906, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 182, train_loss = 2.6973965403158218, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 183, train_loss = 2.67844595015049, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 184, train_loss = 2.659878507955, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 185, train_loss = 2.6413649804890156, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 186, train_loss = 2.6232568062841892, train_acc = 0.9954587796925943\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 187, train_loss = 2.605387518880889, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 188, train_loss = 2.587634914787486, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 189, train_loss = 2.5702077616006136, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 190, train_loss = 2.5529909897595644, train_acc = 0.995575221238938\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 191, train_loss = 2.535901815863326, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 192, train_loss = 2.5191156696528196, train_acc = 0.9956916627852818\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 193, train_loss = 2.502457940252498, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 194, train_loss = 2.4860923048108816, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 195, train_loss = 2.4699210624676198, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 196, train_loss = 2.453938353806734, train_acc = 0.9958081043316255\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 197, train_loss = 2.438225307269022, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 198, train_loss = 2.4226980183739215, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 199, train_loss = 2.4073517702054232, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 200, train_loss = 2.3921724401880056, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 201, train_loss = 2.377305605215952, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 202, train_loss = 2.362521655159071, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 203, train_loss = 2.3479768093675375, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 204, train_loss = 2.333679412258789, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 205, train_loss = 2.3194550697226077, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 206, train_loss = 2.3055376696866006, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 207, train_loss = 2.2918126955628395, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 208, train_loss = 2.278095572022721, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 209, train_loss = 2.2647053252439946, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 210, train_loss = 2.251450991258025, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 211, train_loss = 2.23833875101991, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 212, train_loss = 2.2254868254531175, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 213, train_loss = 2.2127341621089727, train_acc = 0.9962738705170004\n",
      "test Acc 0.984171322160149:\n",
      "27th- epoch: 214, train_loss = 2.200152911245823, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 215, train_loss = 2.187790182651952, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 216, train_loss = 2.1755262191873044, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 217, train_loss = 2.1634217251557857, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 218, train_loss = 2.151453521102667, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 219, train_loss = 2.1397145744413137, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 220, train_loss = 2.128115215105936, train_acc = 0.9962738705170004\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 221, train_loss = 2.1165637739468366, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 222, train_loss = 2.105246441438794, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 223, train_loss = 2.094047363149002, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 224, train_loss = 2.0830163166392595, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 225, train_loss = 2.072129870997742, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 226, train_loss = 2.061254791216925, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 227, train_loss = 2.0507336880546063, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 228, train_loss = 2.040140538709238, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 229, train_loss = 2.0298485551029444, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 230, train_loss = 2.0195757610490546, train_acc = 0.9963903120633442\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 231, train_loss = 2.0094407157739624, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 232, train_loss = 1.999466042383574, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 233, train_loss = 1.9896056385478005, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 234, train_loss = 1.9797648651292548, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 235, train_loss = 1.970213538617827, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 236, train_loss = 1.960645304992795, train_acc = 0.996506753609688\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 237, train_loss = 1.951197492540814, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 238, train_loss = 1.9418782839784399, train_acc = 0.9967396367023754\n",
      "test Acc 0.9846368715083799:\n",
      "27th- epoch: 239, train_loss = 1.9327117943903431, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 240, train_loss = 1.9236010989407077, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 241, train_loss = 1.9146230388432741, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 242, train_loss = 1.905723592848517, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 243, train_loss = 1.8969595251837745, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 244, train_loss = 1.8883039405336604, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 245, train_loss = 1.879679904668592, train_acc = 0.9967396367023754\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 246, train_loss = 1.871264398097992, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 247, train_loss = 1.862869419157505, train_acc = 0.9967396367023754\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 248, train_loss = 1.8546361960470676, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 249, train_loss = 1.8463907800614834, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 250, train_loss = 1.8382394276559353, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 251, train_loss = 1.8303077444434166, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 252, train_loss = 1.8223964609205723, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 253, train_loss = 1.8145856050541624, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 254, train_loss = 1.8068117648363113, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 255, train_loss = 1.79918796941638, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 256, train_loss = 1.7916989736258984, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 257, train_loss = 1.7841313928365707, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "27th- epoch: 258, train_loss = 1.7767055556178093, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 259, train_loss = 1.7694622998824343, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 260, train_loss = 1.7621351467678323, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 261, train_loss = 1.7550573361804709, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 262, train_loss = 1.7479731614002958, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 263, train_loss = 1.740965979755856, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 264, train_loss = 1.7339808469405398, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 265, train_loss = 1.7272318564355373, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 266, train_loss = 1.7203692557523027, train_acc = 0.9972054028877504\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 267, train_loss = 1.7136188670992851, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 268, train_loss = 1.7069411625852808, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 269, train_loss = 1.7003762548556551, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 270, train_loss = 1.6938479878008366, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 271, train_loss = 1.6873225830495358, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "27th- epoch: 272, train_loss = 1.6810145688941702, train_acc = 0.9973218444340941\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 273, train_loss = 1.6747030144324526, train_acc = 0.9974382859804378\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 274, train_loss = 1.6684030592441559, train_acc = 0.9974382859804378\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 275, train_loss = 1.6621764922747388, train_acc = 0.9974382859804378\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 276, train_loss = 1.6559032934019342, train_acc = 0.9974382859804378\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 277, train_loss = 1.6497263560304418, train_acc = 0.9974382859804378\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 278, train_loss = 1.6437275037169456, train_acc = 0.9974382859804378\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 279, train_loss = 1.6378318406641483, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 280, train_loss = 1.6318259736290202, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 281, train_loss = 1.6261229974916205, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 282, train_loss = 1.6202177467057481, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 283, train_loss = 1.6146348156034946, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 284, train_loss = 1.6088312516221777, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 285, train_loss = 1.603342262445949, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 286, train_loss = 1.5977600937476382, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 287, train_loss = 1.5922792492201552, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 288, train_loss = 1.5868541760137305, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 289, train_loss = 1.5814346646657214, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 290, train_loss = 1.5761110795428976, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 291, train_loss = 1.5708693005144596, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 292, train_loss = 1.5655708300182596, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 293, train_loss = 1.5604173330357298, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 294, train_loss = 1.5552654104540125, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27th- epoch: 295, train_loss = 1.550166952132713, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 296, train_loss = 1.545153499871958, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 297, train_loss = 1.5401518965954892, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 298, train_loss = 1.535153626173269, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 299, train_loss = 1.5302627186174504, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 300, train_loss = 1.5253654730622657, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 301, train_loss = 1.52059892937541, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 302, train_loss = 1.5157177138025872, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 303, train_loss = 1.5110032558441162, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 304, train_loss = 1.5062951371073723, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 305, train_loss = 1.501655398576986, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 306, train_loss = 1.4970534828607924, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 307, train_loss = 1.4924293011426926, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 308, train_loss = 1.4879567747120745, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 309, train_loss = 1.4834392828051932, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 310, train_loss = 1.478977280377876, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 311, train_loss = 1.4745815296773799, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 312, train_loss = 1.4701929564471357, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 313, train_loss = 1.4658948443830013, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 314, train_loss = 1.4615247659385204, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 315, train_loss = 1.457261759787798, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 316, train_loss = 1.4529557302594185, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 317, train_loss = 1.4487069782917388, train_acc = 0.9975547275267815\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 318, train_loss = 1.4445346780121326, train_acc = 0.9975547275267815\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 319, train_loss = 1.440393174707424, train_acc = 0.9975547275267815\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 320, train_loss = 1.4362077477271669, train_acc = 0.9975547275267815\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 321, train_loss = 1.4322135684196837, train_acc = 0.9975547275267815\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 322, train_loss = 1.4279904452268966, train_acc = 0.9975547275267815\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 323, train_loss = 1.4240641022915952, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 324, train_loss = 1.4200854760711081, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 325, train_loss = 1.4161354092066176, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 326, train_loss = 1.4122304779593833, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 327, train_loss = 1.4083865086431615, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 328, train_loss = 1.4045699809794314, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 329, train_loss = 1.400783333927393, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 330, train_loss = 1.3970114029943943, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 331, train_loss = 1.3932414117152803, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 332, train_loss = 1.38959338265704, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 333, train_loss = 1.3858775794506073, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 334, train_loss = 1.3823055711691268, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 335, train_loss = 1.378637995570898, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 336, train_loss = 1.3750000198488124, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 337, train_loss = 1.3715092415804975, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 338, train_loss = 1.3679476169054396, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 339, train_loss = 1.3643931995029561, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 340, train_loss = 1.3609934424166568, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 341, train_loss = 1.3574500891263597, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 342, train_loss = 1.354004469991196, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 343, train_loss = 1.350674166053068, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 344, train_loss = 1.3472424298524857, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 345, train_loss = 1.3438166330452077, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 346, train_loss = 1.340569029271137, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 347, train_loss = 1.3372538748080842, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 348, train_loss = 1.3339146810467355, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 349, train_loss = 1.3307713866233826, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 350, train_loss = 1.3275159138138406, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 351, train_loss = 1.3243149034678936, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 352, train_loss = 1.3211844774778, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 353, train_loss = 1.3180298891966231, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 354, train_loss = 1.3148827962577343, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 355, train_loss = 1.3118594934348948, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 356, train_loss = 1.3087421096861362, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 357, train_loss = 1.3057110061054118, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 358, train_loss = 1.3026945106685162, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 359, train_loss = 1.2996590596740134, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 360, train_loss = 1.2966566793620586, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 361, train_loss = 1.293685109645594, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 362, train_loss = 1.2907831532065757, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 363, train_loss = 1.2878626237506978, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 364, train_loss = 1.284990067302715, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 365, train_loss = 1.2820816934108734, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 366, train_loss = 1.2792005389928818, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 367, train_loss = 1.2764529163832776, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 368, train_loss = 1.27356344088912, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 369, train_loss = 1.2707415607874282, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 370, train_loss = 1.2680240732734092, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 371, train_loss = 1.2652638008003123, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 372, train_loss = 1.2625200425391085, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 373, train_loss = 1.2597600879962556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 374, train_loss = 1.2570985431666486, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 375, train_loss = 1.2544341919128783, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 376, train_loss = 1.251711109012831, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 377, train_loss = 1.249069121957291, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 378, train_loss = 1.2464210279285908, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 379, train_loss = 1.243892655998934, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 380, train_loss = 1.2412775096890982, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 381, train_loss = 1.2386595122516155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 382, train_loss = 1.2361406274139881, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 383, train_loss = 1.2335691725311335, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 384, train_loss = 1.2310482151806355, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 385, train_loss = 1.2285990839300212, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 386, train_loss = 1.2260792975721415, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 387, train_loss = 1.2235951808688696, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 388, train_loss = 1.2211612326500472, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 389, train_loss = 1.2187186206283513, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 390, train_loss = 1.2162670604884624, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 391, train_loss = 1.2138717100024223, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 392, train_loss = 1.2115109264850616, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 393, train_loss = 1.2091141479613725, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 394, train_loss = 1.206737995147705, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 395, train_loss = 1.2043908536434174, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 396, train_loss = 1.2021302245557308, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 397, train_loss = 1.199803655355936, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 398, train_loss = 1.197397588432068, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 399, train_loss = 1.1952124970557634, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 400, train_loss = 1.192933122307295, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 401, train_loss = 1.1906308183970395, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 402, train_loss = 1.1883787984552328, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 403, train_loss = 1.186218277871376, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 404, train_loss = 1.1839135450718459, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 405, train_loss = 1.1817054587008897, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "27th- epoch: 406, train_loss = 1.1795497996208724, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 407, train_loss = 1.177395155042177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 408, train_loss = 1.1751606091856956, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 409, train_loss = 1.1730441612598952, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 410, train_loss = 1.1709651177225169, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 411, train_loss = 1.1688106718065683, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 412, train_loss = 1.1667404137551785, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 413, train_loss = 1.1645854699017946, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 414, train_loss = 1.1625256600382272, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 415, train_loss = 1.160409864038229, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 416, train_loss = 1.1584211761655752, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 417, train_loss = 1.156333763152361, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 418, train_loss = 1.1542795412242413, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 419, train_loss = 1.1523094525036868, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 420, train_loss = 1.1502968097629491, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 421, train_loss = 1.1482838951051235, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 422, train_loss = 1.1462946025130805, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 423, train_loss = 1.144337392091984, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 424, train_loss = 1.1423072206380311, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 425, train_loss = 1.140432824700838, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 426, train_loss = 1.1384807440044824, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 427, train_loss = 1.136487072944874, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 428, train_loss = 1.1346308762731496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 429, train_loss = 1.132688980549574, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 430, train_loss = 1.1308351382613182, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 431, train_loss = 1.1289507038891315, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 432, train_loss = 1.1270381646754686, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 433, train_loss = 1.1252407965657767, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 434, train_loss = 1.123306903988123, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 435, train_loss = 1.1215090677142143, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 436, train_loss = 1.1197182623145636, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 437, train_loss = 1.1178723697958048, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 438, train_loss = 1.116051202028757, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 439, train_loss = 1.1142272464931011, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 440, train_loss = 1.112469149142271, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 441, train_loss = 1.1106583985092584, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 442, train_loss = 1.108897153288126, train_acc = 0.9977876106194691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 443, train_loss = 1.107113167643547, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 444, train_loss = 1.1054467273352202, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 445, train_loss = 1.1035968773066998, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 446, train_loss = 1.1019245497882366, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 447, train_loss = 1.1001478508114815, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 448, train_loss = 1.0984838269650936, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 449, train_loss = 1.0967271836998407, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 450, train_loss = 1.0950639434158802, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 451, train_loss = 1.0933327128586825, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 452, train_loss = 1.0917536268534604, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 453, train_loss = 1.0900209471583366, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 454, train_loss = 1.088344231247902, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 455, train_loss = 1.086735618620878, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 456, train_loss = 1.08507845675922, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 457, train_loss = 1.083454074949259, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 458, train_loss = 1.0818244156835135, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 459, train_loss = 1.0802380653622095, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 460, train_loss = 1.0786466784775257, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 461, train_loss = 1.0770124557020608, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 462, train_loss = 1.0754124546947423, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 463, train_loss = 1.073842709272867, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 464, train_loss = 1.0722544404270593, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 465, train_loss = 1.0706473799946252, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 466, train_loss = 1.0690929405391216, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 467, train_loss = 1.0675450153648853, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 468, train_loss = 1.0659784910676535, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 469, train_loss = 1.0644115979375783, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 470, train_loss = 1.0629626164736692, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 471, train_loss = 1.0613599990902003, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 472, train_loss = 1.0598821776511613, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 473, train_loss = 1.0583254707453307, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 474, train_loss = 1.056848799198633, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 475, train_loss = 1.0553555861115456, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 476, train_loss = 1.0539048587379511, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 477, train_loss = 1.0524141887726728, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 478, train_loss = 1.0510005590913352, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 479, train_loss = 1.0495255229470786, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 480, train_loss = 1.0480997562408447, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 481, train_loss = 1.0466474989952985, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 482, train_loss = 1.0451482993958052, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 483, train_loss = 1.0437296653690282, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 484, train_loss = 1.0423055067658424, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 485, train_loss = 1.0408791899681091, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 486, train_loss = 1.0394697027804796, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 487, train_loss = 1.0380728244781494, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 488, train_loss = 1.0366745305655058, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 489, train_loss = 1.0352419863047544, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 490, train_loss = 1.0338435123267118, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 491, train_loss = 1.032529927790165, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 492, train_loss = 1.0310884825885296, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 493, train_loss = 1.0297456979751587, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 494, train_loss = 1.028378389775753, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 495, train_loss = 1.0270257455704268, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 496, train_loss = 1.0256874226033688, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 497, train_loss = 1.0243218677787809, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 498, train_loss = 1.0230070066900225, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "27th- epoch: 499, train_loss = 1.0216778417379828, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████▊       | 27/30 [3:04:27<20:32, 410.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "28th- epoch: 0, train_loss = 272.40190720558167, train_acc = 0.43153237074988354\n",
      "test Acc 0.4888268156424581:\n",
      "28th- epoch: 1, train_loss = 204.4525716304779, train_acc = 0.49254774103400095\n",
      "test Acc 0.49068901303538176:\n",
      "28th- epoch: 2, train_loss = 162.19801515340805, train_acc = 0.5602002794597112\n",
      "test Acc 0.6219739292364991:\n",
      "28th- epoch: 3, train_loss = 137.28849029541016, train_acc = 0.6775733581741965\n",
      "test Acc 0.7253258845437617:\n",
      "28th- epoch: 4, train_loss = 117.3971797823906, train_acc = 0.7401024685607824\n",
      "test Acc 0.7583798882681564:\n",
      "28th- epoch: 5, train_loss = 101.63588088750839, train_acc = 0.764555193292967\n",
      "test Acc 0.7821229050279329:\n",
      "28th- epoch: 6, train_loss = 88.95109590888023, train_acc = 0.7936655798789007\n",
      "test Acc 0.8072625698324022:\n",
      "28th- epoch: 7, train_loss = 78.66376560926437, train_acc = 0.8153237074988355\n",
      "test Acc 0.8161080074487895:\n",
      "28th- epoch: 8, train_loss = 70.07412758469582, train_acc = 0.8374476013041453\n",
      "test Acc 0.839851024208566:\n",
      "28th- epoch: 9, train_loss = 62.77629980444908, train_acc = 0.863996273870517\n",
      "test Acc 0.8798882681564246:\n",
      "28th- epoch: 10, train_loss = 56.548184514045715, train_acc = 0.8892640894271076\n",
      "test Acc 0.9013035381750466:\n",
      "28th- epoch: 11, train_loss = 51.20857806503773, train_acc = 0.9054494643688868\n",
      "test Acc 0.9129422718808193:\n",
      "28th- epoch: 12, train_loss = 46.601761028170586, train_acc = 0.9175593851886353\n",
      "test Acc 0.931098696461825:\n",
      "28th- epoch: 13, train_loss = 42.61252984404564, train_acc = 0.9316488122962273\n",
      "test Acc 0.9366852886405959:\n",
      "28th- epoch: 14, train_loss = 39.1507847905159, train_acc = 0.9368886818816954\n",
      "test Acc 0.9399441340782123:\n",
      "28th- epoch: 15, train_loss = 36.14309939742088, train_acc = 0.9382859804378202\n",
      "test Acc 0.9427374301675978:\n",
      "28th- epoch: 16, train_loss = 33.53715110570192, train_acc = 0.9402654867256637\n",
      "test Acc 0.9455307262569832:\n",
      "28th- epoch: 17, train_loss = 31.279974229633808, train_acc = 0.9427107591988821\n",
      "test Acc 0.9478584729981379:\n",
      "28th- epoch: 18, train_loss = 29.322031393647194, train_acc = 0.9499301350721937\n",
      "test Acc 0.952048417132216:\n",
      "28th- epoch: 19, train_loss = 27.61617109924555, train_acc = 0.9517931998136935\n",
      "test Acc 0.9543761638733705:\n",
      "28th- epoch: 20, train_loss = 26.123163305222988, train_acc = 0.9543549138332557\n",
      "test Acc 0.9553072625698324:\n",
      "28th- epoch: 21, train_loss = 24.809189423918724, train_acc = 0.955519329296693\n",
      "test Acc 0.9567039106145251:\n",
      "28th- epoch: 22, train_loss = 23.6478456184268, train_acc = 0.9579646017699115\n",
      "test Acc 0.9585661080074488:\n",
      "28th- epoch: 23, train_loss = 22.615011744201183, train_acc = 0.95947834187238\n",
      "test Acc 0.9594972067039106:\n",
      "28th- epoch: 24, train_loss = 21.690106760710478, train_acc = 0.9607591988821611\n",
      "test Acc 0.9608938547486033:\n",
      "28th- epoch: 25, train_loss = 20.85528190433979, train_acc = 0.9615742897065673\n",
      "test Acc 0.9613594040968343:\n",
      "28th- epoch: 26, train_loss = 20.09767385944724, train_acc = 0.9627387051700047\n",
      "test Acc 0.9618249534450651:\n",
      "28th- epoch: 27, train_loss = 19.404974579811096, train_acc = 0.963903120633442\n",
      "test Acc 0.9613594040968343:\n",
      "28th- epoch: 28, train_loss = 18.76813428848982, train_acc = 0.9655333022822543\n",
      "test Acc 0.9613594040968343:\n",
      "28th- epoch: 29, train_loss = 18.17899614572525, train_acc = 0.966581276199348\n",
      "test Acc 0.9613594040968343:\n",
      "28th- epoch: 30, train_loss = 17.63139244541526, train_acc = 0.9669306008383791\n",
      "test Acc 0.9618249534450651:\n",
      "28th- epoch: 31, train_loss = 17.1211222037673, train_acc = 0.9678621332091291\n",
      "test Acc 0.9618249534450651:\n",
      "28th- epoch: 32, train_loss = 16.643895015120506, train_acc = 0.9686772240335352\n",
      "test Acc 0.9636871508379888:\n",
      "28th- epoch: 33, train_loss = 16.1960514113307, train_acc = 0.9691429902189101\n",
      "test Acc 0.9636871508379888:\n",
      "28th- epoch: 34, train_loss = 15.774214908480644, train_acc = 0.9693758733115976\n",
      "test Acc 0.9636871508379888:\n",
      "28th- epoch: 35, train_loss = 15.37640981003642, train_acc = 0.9699580810433163\n",
      "test Acc 0.9650837988826816:\n",
      "28th- epoch: 36, train_loss = 15.00056629255414, train_acc = 0.970540288775035\n",
      "test Acc 0.9674115456238361:\n",
      "28th- epoch: 37, train_loss = 14.6442267075181, train_acc = 0.9717047042384723\n",
      "test Acc 0.9678770949720671:\n",
      "28th- epoch: 38, train_loss = 14.305516351014376, train_acc = 0.9724033535165347\n",
      "test Acc 0.9702048417132216:\n",
      "28th- epoch: 39, train_loss = 13.982858907431364, train_acc = 0.9734513274336283\n",
      "test Acc 0.9702048417132216:\n",
      "28th- epoch: 40, train_loss = 13.675265777856112, train_acc = 0.9744993013507219\n",
      "test Acc 0.9711359404096834:\n",
      "28th- epoch: 41, train_loss = 13.381290450692177, train_acc = 0.975314392175128\n",
      "test Acc 0.9716014897579144:\n",
      "28th- epoch: 42, train_loss = 13.099591590464115, train_acc = 0.9758965999068467\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 43, train_loss = 12.82953380793333, train_acc = 0.9760130414531905\n",
      "test Acc 0.972998137802607:\n",
      "28th- epoch: 44, train_loss = 12.570555567741394, train_acc = 0.9763623660922217\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 45, train_loss = 12.321698941290379, train_acc = 0.9770610153702841\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 46, train_loss = 12.08231632038951, train_acc = 0.9782254308337215\n",
      "test Acc 0.973463687150838:\n",
      "28th- epoch: 47, train_loss = 11.851567704230547, train_acc = 0.9785747554727526\n",
      "test Acc 0.9748603351955307:\n",
      "28th- epoch: 48, train_loss = 11.629302576184273, train_acc = 0.9788076385654402\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 49, train_loss = 11.414607837796211, train_acc = 0.9788076385654402\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 50, train_loss = 11.207230281084776, train_acc = 0.9790405216581276\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 51, train_loss = 11.006906230002642, train_acc = 0.9790405216581276\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 52, train_loss = 10.813279371708632, train_acc = 0.9798556124825337\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 53, train_loss = 10.625826861709356, train_acc = 0.9804378202142524\n",
      "test Acc 0.9753258845437617:\n",
      "28th- epoch: 54, train_loss = 10.444577094167471, train_acc = 0.98067070330694\n",
      "test Acc 0.9757914338919925:\n",
      "28th- epoch: 55, train_loss = 10.269062779843807, train_acc = 0.98067070330694\n",
      "test Acc 0.9762569832402235:\n",
      "28th- epoch: 56, train_loss = 10.09898829832673, train_acc = 0.98067070330694\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 57, train_loss = 9.933994423598051, train_acc = 0.9814857941313461\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 58, train_loss = 9.773850839585066, train_acc = 0.9817186772240335\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 59, train_loss = 9.618111992254853, train_acc = 0.9818351187703773\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 60, train_loss = 9.466698985546827, train_acc = 0.981951560316721\n",
      "test Acc 0.9776536312849162:\n",
      "28th- epoch: 61, train_loss = 9.319520754739642, train_acc = 0.9820680018630648\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 62, train_loss = 9.17627764865756, train_acc = 0.9823008849557522\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 63, train_loss = 9.036649463698268, train_acc = 0.9824173265020959\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 64, train_loss = 8.900399290025234, train_acc = 0.9827666511411272\n",
      "test Acc 0.9767225325884544:\n",
      "28th- epoch: 65, train_loss = 8.767485648393631, train_acc = 0.9828830926874709\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 66, train_loss = 8.637876618653536, train_acc = 0.9831159757801584\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 67, train_loss = 8.511409744620323, train_acc = 0.9832324173265021\n",
      "test Acc 0.9771880819366853:\n",
      "28th- epoch: 68, train_loss = 8.387626398354769, train_acc = 0.9833488588728458\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 69, train_loss = 8.266606660559773, train_acc = 0.9835817419655333\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 70, train_loss = 8.1483559217304, train_acc = 0.9838146250582208\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 71, train_loss = 8.032654985785484, train_acc = 0.9839310666045645\n",
      "test Acc 0.978584729981378:\n",
      "28th- epoch: 72, train_loss = 7.919658292084932, train_acc = 0.9845132743362832\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 73, train_loss = 7.8089861534535885, train_acc = 0.9846297158826269\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 74, train_loss = 7.700723459944129, train_acc = 0.9848625989753144\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 75, train_loss = 7.5947046130895615, train_acc = 0.9852119236143456\n",
      "test Acc 0.9795158286778398:\n",
      "28th- epoch: 76, train_loss = 7.490822695195675, train_acc = 0.9853283651606893\n",
      "test Acc 0.9799813780260708:\n",
      "28th- epoch: 77, train_loss = 7.389003759250045, train_acc = 0.9855612482533768\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 78, train_loss = 7.289172578603029, train_acc = 0.9855612482533768\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 79, train_loss = 7.19130545668304, train_acc = 0.9855612482533768\n",
      "test Acc 0.9804469273743017:\n",
      "28th- epoch: 80, train_loss = 7.095518374815583, train_acc = 0.9855612482533768\n",
      "test Acc 0.9799813780260708:\n",
      "28th- epoch: 81, train_loss = 7.001600347459316, train_acc = 0.985910572892408\n",
      "test Acc 0.9799813780260708:\n",
      "28th- epoch: 82, train_loss = 6.909594958648086, train_acc = 0.9866092221704704\n",
      "test Acc 0.9799813780260708:\n",
      "28th- epoch: 83, train_loss = 6.819264179095626, train_acc = 0.9868421052631579\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 84, train_loss = 6.7308517917990685, train_acc = 0.9871914299021891\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 85, train_loss = 6.644022824242711, train_acc = 0.9871914299021891\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 86, train_loss = 6.558908179402351, train_acc = 0.9871914299021891\n",
      "test Acc 0.9813780260707635:\n",
      "28th- epoch: 87, train_loss = 6.47550299949944, train_acc = 0.9870749883558454\n",
      "test Acc 0.9818435754189944:\n",
      "28th- epoch: 88, train_loss = 6.393738977611065, train_acc = 0.9871914299021891\n",
      "test Acc 0.9818435754189944:\n",
      "28th- epoch: 89, train_loss = 6.313552329316735, train_acc = 0.9875407545412203\n",
      "test Acc 0.9818435754189944:\n",
      "28th- epoch: 90, train_loss = 6.234809286892414, train_acc = 0.9878900791802515\n",
      "test Acc 0.9818435754189944:\n",
      "28th- epoch: 91, train_loss = 6.157595179975033, train_acc = 0.9878900791802515\n",
      "test Acc 0.9818435754189944:\n",
      "28th- epoch: 92, train_loss = 6.081811081618071, train_acc = 0.9883558453656265\n",
      "test Acc 0.9818435754189944:\n",
      "28th- epoch: 93, train_loss = 6.00728097371757, train_acc = 0.9884722869119702\n",
      "test Acc 0.9827746741154563:\n",
      "28th- epoch: 94, train_loss = 5.934336390346289, train_acc = 0.9884722869119702\n",
      "test Acc 0.9827746741154563:\n",
      "28th- epoch: 95, train_loss = 5.862870544195175, train_acc = 0.9885887284583139\n",
      "test Acc 0.9827746741154563:\n",
      "28th- epoch: 96, train_loss = 5.792821926996112, train_acc = 0.9887051700046576\n",
      "test Acc 0.9827746741154563:\n",
      "28th- epoch: 97, train_loss = 5.723892094567418, train_acc = 0.9888216115510013\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 98, train_loss = 5.656481213867664, train_acc = 0.9888216115510013\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 99, train_loss = 5.590205788612366, train_acc = 0.9890544946436889\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 100, train_loss = 5.525053959339857, train_acc = 0.9891709361900326\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 101, train_loss = 5.461117852479219, train_acc = 0.9892873777363763\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 102, train_loss = 5.398252634331584, train_acc = 0.98940381928272\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 103, train_loss = 5.3362906612455845, train_acc = 0.98940381928272\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 104, train_loss = 5.275320701301098, train_acc = 0.9896367023754076\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 105, train_loss = 5.215387364849448, train_acc = 0.9899860270144387\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 106, train_loss = 5.156492903828621, train_acc = 0.9899860270144387\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 107, train_loss = 5.098663529381156, train_acc = 0.9904517931998137\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 108, train_loss = 5.041889745742083, train_acc = 0.9905682347461574\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 109, train_loss = 4.9861047845333815, train_acc = 0.9906846762925011\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 110, train_loss = 4.931311195716262, train_acc = 0.9909175593851887\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 111, train_loss = 4.877630192786455, train_acc = 0.9911504424778761\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 112, train_loss = 4.824692215770483, train_acc = 0.9912668840242198\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 113, train_loss = 4.772721822373569, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 114, train_loss = 4.72145941387862, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 115, train_loss = 4.6711521446704865, train_acc = 0.9914997671169073\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 116, train_loss = 4.621755187399685, train_acc = 0.9914997671169073\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 117, train_loss = 4.573107151314616, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 118, train_loss = 4.525417570956051, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 119, train_loss = 4.478363324888051, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 120, train_loss = 4.4320507273077965, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 121, train_loss = 4.386545977555215, train_acc = 0.9916162086632511\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 122, train_loss = 4.341757354326546, train_acc = 0.9919655333022822\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 123, train_loss = 4.29771941434592, train_acc = 0.9919655333022822\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 124, train_loss = 4.254451563581824, train_acc = 0.992081974848626\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 125, train_loss = 4.211816464550793, train_acc = 0.9921984163949698\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 126, train_loss = 4.1698700319975615, train_acc = 0.9924312994876572\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 127, train_loss = 4.128438647836447, train_acc = 0.9925477410340009\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 128, train_loss = 4.08790282625705, train_acc = 0.9927806241266884\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 129, train_loss = 4.047926118597388, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 130, train_loss = 4.008581520058215, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 131, train_loss = 3.969934049062431, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 132, train_loss = 3.93179904576391, train_acc = 0.9930135072193759\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 133, train_loss = 3.894349900074303, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 134, train_loss = 3.8574531860649586, train_acc = 0.9931299487657196\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 135, train_loss = 3.821106950752437, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 136, train_loss = 3.7854769956320524, train_acc = 0.9933628318584071\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 137, train_loss = 3.750350975431502, train_acc = 0.9934792734047508\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 138, train_loss = 3.7157624289393425, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 139, train_loss = 3.681837405078113, train_acc = 0.993828598043782\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 140, train_loss = 3.6483475072309375, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 141, train_loss = 3.6154451640322804, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 142, train_loss = 3.582874611020088, train_acc = 0.9939450395901258\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 143, train_loss = 3.5509137474000454, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 144, train_loss = 3.5194379398599267, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 145, train_loss = 3.488312571309507, train_acc = 0.9940614811364695\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 146, train_loss = 3.4578492660075426, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 147, train_loss = 3.427752156741917, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 148, train_loss = 3.3980783210135996, train_acc = 0.9941779226828132\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 149, train_loss = 3.368955521378666, train_acc = 0.9944108057755007\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 150, train_loss = 3.3402140769176185, train_acc = 0.9944108057755007\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 151, train_loss = 3.3118435093201697, train_acc = 0.9944108057755007\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 152, train_loss = 3.2839941061101854, train_acc = 0.9945272473218444\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 153, train_loss = 3.2564350836910307, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 154, train_loss = 3.2293655672110617, train_acc = 0.9946436888681882\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 155, train_loss = 3.2027046768926084, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 156, train_loss = 3.17634324869141, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 157, train_loss = 3.150527272839099, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 158, train_loss = 3.124899588059634, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 159, train_loss = 3.0998161248862743, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 160, train_loss = 3.0749649442732334, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 161, train_loss = 3.0505702276714146, train_acc = 0.9947601304145319\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 162, train_loss = 3.026564251165837, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 163, train_loss = 3.002838933840394, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 164, train_loss = 2.979478010442108, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 165, train_loss = 2.956417590379715, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 166, train_loss = 2.9336710548959672, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 167, train_loss = 2.9113491675816476, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 168, train_loss = 2.889272712636739, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 169, train_loss = 2.867618326563388, train_acc = 0.9949930135072194\n",
      "test Acc 0.9837057728119181:\n",
      "28th- epoch: 170, train_loss = 2.8461852720938623, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 171, train_loss = 2.825148723553866, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "28th- epoch: 172, train_loss = 2.804308148100972, train_acc = 0.9949930135072194\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 173, train_loss = 2.7839512708596885, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 174, train_loss = 2.7637826767750084, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 175, train_loss = 2.743921706918627, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 176, train_loss = 2.7243489790707827, train_acc = 0.9952258965999069\n",
      "test Acc 0.984171322160149:\n",
      "28th- epoch: 177, train_loss = 2.705041167791933, train_acc = 0.9952258965999069\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 178, train_loss = 2.6861136513762176, train_acc = 0.9953423381462506\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 179, train_loss = 2.6673531495034695, train_acc = 0.9953423381462506\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 180, train_loss = 2.648893182631582, train_acc = 0.9953423381462506\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 181, train_loss = 2.6307351794093847, train_acc = 0.9954587796925943\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 182, train_loss = 2.612802139017731, train_acc = 0.995575221238938\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 183, train_loss = 2.595144545659423, train_acc = 0.995575221238938\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 184, train_loss = 2.5777579192072153, train_acc = 0.995575221238938\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 185, train_loss = 2.560627929866314, train_acc = 0.9956916627852818\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 186, train_loss = 2.5437114094384015, train_acc = 0.9958081043316255\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 187, train_loss = 2.5271059894002974, train_acc = 0.9958081043316255\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 188, train_loss = 2.5106453238986433, train_acc = 0.9958081043316255\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 189, train_loss = 2.4944541454315186, train_acc = 0.9958081043316255\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 190, train_loss = 2.4784998134709895, train_acc = 0.9958081043316255\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 191, train_loss = 2.462769529549405, train_acc = 0.9958081043316255\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 192, train_loss = 2.447340175509453, train_acc = 0.9958081043316255\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 193, train_loss = 2.431997651234269, train_acc = 0.9958081043316255\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 194, train_loss = 2.4169408306479454, train_acc = 0.9958081043316255\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 195, train_loss = 2.4021024715621024, train_acc = 0.9958081043316255\n",
      "test Acc 0.9846368715083799:\n",
      "28th- epoch: 196, train_loss = 2.3874195280950516, train_acc = 0.9959245458779693\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 197, train_loss = 2.3728313844185323, train_acc = 0.9959245458779693\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 198, train_loss = 2.3585762344300747, train_acc = 0.9959245458779693\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 199, train_loss = 2.3443958088755608, train_acc = 0.9959245458779693\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 200, train_loss = 2.330436300486326, train_acc = 0.9959245458779693\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 201, train_loss = 2.3167657759040594, train_acc = 0.9959245458779693\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 202, train_loss = 2.303238593041897, train_acc = 0.9959245458779693\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 203, train_loss = 2.2897726248484105, train_acc = 0.9959245458779693\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 204, train_loss = 2.2766767006833106, train_acc = 0.9959245458779693\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 205, train_loss = 2.2636187181342393, train_acc = 0.9959245458779693\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 206, train_loss = 2.250703851925209, train_acc = 0.996040987424313\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 207, train_loss = 2.2380810796748847, train_acc = 0.996040987424313\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 208, train_loss = 2.225553623633459, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 209, train_loss = 2.213160178856924, train_acc = 0.9961574289706567\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 210, train_loss = 2.2009753703605384, train_acc = 0.9962738705170004\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 211, train_loss = 2.188775984570384, train_acc = 0.9962738705170004\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 212, train_loss = 2.1769497618079185, train_acc = 0.9963903120633442\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 213, train_loss = 2.1653298623859882, train_acc = 0.9963903120633442\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 214, train_loss = 2.1537696172017604, train_acc = 0.9963903120633442\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 215, train_loss = 2.1423726689536124, train_acc = 0.9963903120633442\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 216, train_loss = 2.131150418194011, train_acc = 0.9963903120633442\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 217, train_loss = 2.1200201909523457, train_acc = 0.9963903120633442\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 218, train_loss = 2.1089794400613755, train_acc = 0.9963903120633442\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 219, train_loss = 2.098239916143939, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 220, train_loss = 2.087490179343149, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 221, train_loss = 2.0769890907686204, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 222, train_loss = 2.066527559189126, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 223, train_loss = 2.0561081140767783, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 224, train_loss = 2.046015917090699, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 225, train_loss = 2.0358771085739136, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 226, train_loss = 2.026006232248619, train_acc = 0.996506753609688\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 227, train_loss = 2.016260412754491, train_acc = 0.9966231951560317\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 228, train_loss = 2.0065447941888124, train_acc = 0.9966231951560317\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 229, train_loss = 1.996868374524638, train_acc = 0.9966231951560317\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 230, train_loss = 1.9875488940160722, train_acc = 0.9968560782487191\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 231, train_loss = 1.9780919190961868, train_acc = 0.9969725197950629\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 232, train_loss = 1.9688963268417865, train_acc = 0.9970889613414066\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 233, train_loss = 1.9598075188696384, train_acc = 0.9970889613414066\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 234, train_loss = 1.950725206406787, train_acc = 0.9970889613414066\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 235, train_loss = 1.9418572101276368, train_acc = 0.9970889613414066\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 236, train_loss = 1.9330360286403447, train_acc = 0.9970889613414066\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 237, train_loss = 1.9242557336110622, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 238, train_loss = 1.915678293677047, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 239, train_loss = 1.9071405932772905, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 240, train_loss = 1.8987247049808502, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 241, train_loss = 1.8903997261077166, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 242, train_loss = 1.8821612906176597, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 243, train_loss = 1.8740343439858407, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 244, train_loss = 1.86597557249479, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 245, train_loss = 1.857968564494513, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 246, train_loss = 1.850080298841931, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 247, train_loss = 1.8422458650311455, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 248, train_loss = 1.8345362562686205, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 249, train_loss = 1.826963615254499, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 250, train_loss = 1.8193439580500126, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 251, train_loss = 1.8118182737380266, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 252, train_loss = 1.8044927628943697, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 253, train_loss = 1.7971186513314024, train_acc = 0.9974382859804378\n",
      "test Acc 0.9851024208566108:\n",
      "28th- epoch: 254, train_loss = 1.7899410339305177, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 255, train_loss = 1.7827074093511328, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 256, train_loss = 1.775556075037457, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 257, train_loss = 1.768587440252304, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 258, train_loss = 1.7615996090462431, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 259, train_loss = 1.7546662153908983, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 260, train_loss = 1.7478813914349303, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 261, train_loss = 1.7410822473466396, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 262, train_loss = 1.7344698259839788, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 263, train_loss = 1.7277661910047755, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 264, train_loss = 1.7212272795150056, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 265, train_loss = 1.714771161437966, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 266, train_loss = 1.7082809495041147, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 267, train_loss = 1.7019692236790434, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 268, train_loss = 1.6956183599540964, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 269, train_loss = 1.6893846318125725, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 270, train_loss = 1.6832494909176603, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 271, train_loss = 1.676926415413618, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 272, train_loss = 1.6709348944714293, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 273, train_loss = 1.664934137254022, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 274, train_loss = 1.6588877564063296, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 275, train_loss = 1.653002587496303, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 276, train_loss = 1.6471667563309893, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 277, train_loss = 1.6413517892360687, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 278, train_loss = 1.6356285276124254, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 279, train_loss = 1.629926659166813, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 280, train_loss = 1.6243505453458056, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 281, train_loss = 1.6186553835868835, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 282, train_loss = 1.6131434006383643, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 283, train_loss = 1.607655988424085, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 284, train_loss = 1.6022548215696588, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 285, train_loss = 1.5968394950032234, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 286, train_loss = 1.5915214767446741, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 287, train_loss = 1.5862331489333883, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 288, train_loss = 1.5809461822500452, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 289, train_loss = 1.5756683088839054, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 290, train_loss = 1.5705636739730835, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 291, train_loss = 1.5654317028820515, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 292, train_loss = 1.560371338040568, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 293, train_loss = 1.555340763181448, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 294, train_loss = 1.5503633953630924, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 295, train_loss = 1.5454323155572638, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 296, train_loss = 1.5405439747264609, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 297, train_loss = 1.535713117569685, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 298, train_loss = 1.5309770727762952, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 299, train_loss = 1.526137242675759, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "28th- epoch: 300, train_loss = 1.5214019851991907, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 301, train_loss = 1.5166737312683836, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 302, train_loss = 1.5120834596455097, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 303, train_loss = 1.5075235503027216, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 304, train_loss = 1.5028841011226177, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 305, train_loss = 1.4983804250368848, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 306, train_loss = 1.4938354654004797, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 307, train_loss = 1.4893391331424937, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 308, train_loss = 1.4848766326904297, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 309, train_loss = 1.4805325804045424, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 310, train_loss = 1.4760272912681103, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 311, train_loss = 1.4717396348714828, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 312, train_loss = 1.4673403054475784, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 313, train_loss = 1.4630935725872405, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 314, train_loss = 1.45885370176984, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 315, train_loss = 1.454595286399126, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 316, train_loss = 1.4504400404985063, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 317, train_loss = 1.4462966844439507, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 318, train_loss = 1.442086053371895, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 319, train_loss = 1.4380720580811612, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 320, train_loss = 1.4340244941413403, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 321, train_loss = 1.4300465074484237, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 322, train_loss = 1.426053587347269, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 323, train_loss = 1.4221216713194735, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 324, train_loss = 1.4181753571028821, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 325, train_loss = 1.4142655432224274, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 326, train_loss = 1.410523448139429, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 327, train_loss = 1.4067557975649834, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 328, train_loss = 1.4029418962891214, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 329, train_loss = 1.399265265732538, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 330, train_loss = 1.3955291484599002, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 331, train_loss = 1.3917799753253348, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 332, train_loss = 1.3881727631087415, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 333, train_loss = 1.3844743060762994, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 334, train_loss = 1.3809181079268456, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 335, train_loss = 1.3773353112046607, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 336, train_loss = 1.3737757354974747, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 337, train_loss = 1.3702628600294702, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 338, train_loss = 1.3667231338913552, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 339, train_loss = 1.3633360850508325, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 340, train_loss = 1.3598988528246991, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 341, train_loss = 1.356503417075146, train_acc = 0.9976711690731253\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 342, train_loss = 1.3530439150636084, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 343, train_loss = 1.349681784689892, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 344, train_loss = 1.3463822764460929, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 345, train_loss = 1.343111552298069, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 346, train_loss = 1.3398418215219863, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 347, train_loss = 1.33655671402812, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 348, train_loss = 1.3332363304798491, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 349, train_loss = 1.3301546548609622, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 350, train_loss = 1.3269144755904563, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 351, train_loss = 1.3238195578451268, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 352, train_loss = 1.320606704801321, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 353, train_loss = 1.3174843129818328, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 354, train_loss = 1.314385452598799, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 355, train_loss = 1.3113277405500412, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 356, train_loss = 1.3082991081173532, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 357, train_loss = 1.3052752588992007, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 358, train_loss = 1.3021776676177979, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 359, train_loss = 1.299255056947004, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 360, train_loss = 1.2962701395154, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 361, train_loss = 1.2932660542428493, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 362, train_loss = 1.2904318918590434, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 363, train_loss = 1.2874739617109299, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 364, train_loss = 1.284612737596035, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 365, train_loss = 1.2817381459171884, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 366, train_loss = 1.2788527098600753, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 367, train_loss = 1.2760644343798049, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 368, train_loss = 1.2732683457434177, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28th- epoch: 369, train_loss = 1.270377080887556, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 370, train_loss = 1.2676778957247734, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 371, train_loss = 1.2649159816210158, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 372, train_loss = 1.2621454919571988, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 373, train_loss = 1.2594328385894187, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 374, train_loss = 1.256723244965542, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 375, train_loss = 1.254066324501764, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 376, train_loss = 1.2514693115954287, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 377, train_loss = 1.2487176495487802, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 378, train_loss = 1.2461179345846176, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 379, train_loss = 1.2435417734086514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 380, train_loss = 1.2408424404566176, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 381, train_loss = 1.2383271220023744, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 382, train_loss = 1.2358108994667418, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 383, train_loss = 1.233154285699129, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 384, train_loss = 1.230717945843935, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 385, train_loss = 1.228199766308535, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 386, train_loss = 1.2255756594240665, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 387, train_loss = 1.2232370364363305, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 388, train_loss = 1.2207300712470897, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 389, train_loss = 1.2183004369144328, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 390, train_loss = 1.2157921977341175, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 391, train_loss = 1.2134569957852364, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 392, train_loss = 1.2110367913846858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 393, train_loss = 1.2086116448044777, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 394, train_loss = 1.2063210482592694, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 395, train_loss = 1.2038696532254107, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 396, train_loss = 1.2015882370178588, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 397, train_loss = 1.1992062330245972, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 398, train_loss = 1.1969847505097277, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 399, train_loss = 1.1946807342465036, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 400, train_loss = 1.192303514748346, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 401, train_loss = 1.1901788040995598, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 402, train_loss = 1.1878297850489616, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 403, train_loss = 1.185608302563196, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 404, train_loss = 1.1833525213005487, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 405, train_loss = 1.1810924423334654, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 406, train_loss = 1.1789808707835618, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 407, train_loss = 1.1767190086247865, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 408, train_loss = 1.1745870237646159, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 409, train_loss = 1.172401306539541, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 410, train_loss = 1.1702920322713908, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 411, train_loss = 1.1680738888680935, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 412, train_loss = 1.1659860610961914, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 413, train_loss = 1.1638921312987804, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 414, train_loss = 1.1618224543926772, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 415, train_loss = 1.1597290312347468, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 416, train_loss = 1.1575962863862514, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 417, train_loss = 1.1555324507353362, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 418, train_loss = 1.1535395545361098, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 419, train_loss = 1.1515098623931408, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 420, train_loss = 1.1494469481112901, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 421, train_loss = 1.1474008026125375, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 422, train_loss = 1.1455419423582498, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 423, train_loss = 1.1433768769202288, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 424, train_loss = 1.1415419727563858, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 425, train_loss = 1.139503118902212, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 426, train_loss = 1.137538773327833, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 427, train_loss = 1.1356198328139726, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 428, train_loss = 1.1336572505533695, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 429, train_loss = 1.1318101795914117, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 430, train_loss = 1.1298365108668804, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 431, train_loss = 1.1279443763196468, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 432, train_loss = 1.1260820887982845, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 433, train_loss = 1.1241042601468507, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 434, train_loss = 1.1223912785353605, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 435, train_loss = 1.1204239440558013, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 436, train_loss = 1.1186779364943504, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 437, train_loss = 1.1167845241725445, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 438, train_loss = 1.1149725504219532, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 439, train_loss = 1.1131864128110465, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 440, train_loss = 1.1113756597042084, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 441, train_loss = 1.109450171381468, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 442, train_loss = 1.107765762746567, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 443, train_loss = 1.1059784317913, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 444, train_loss = 1.1042337132093962, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 445, train_loss = 1.1024423092603683, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 446, train_loss = 1.1007594056427479, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 447, train_loss = 1.0989561254682485, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 448, train_loss = 1.0972309981880244, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 449, train_loss = 1.0954995689389762, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 450, train_loss = 1.0938324058952276, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 451, train_loss = 1.0921897465887014, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 452, train_loss = 1.090453109383816, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 453, train_loss = 1.0887682735919952, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 454, train_loss = 1.0870785489678383, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 455, train_loss = 1.0853216437099036, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 456, train_loss = 1.0837781876325607, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 457, train_loss = 1.0820210315287113, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 458, train_loss = 1.0805142298340797, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 459, train_loss = 1.0788019808533136, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 460, train_loss = 1.0773201696574688, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 461, train_loss = 1.0755866169929504, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 462, train_loss = 1.0740500055253506, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 463, train_loss = 1.0724563350377139, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 464, train_loss = 1.070756929606432, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 465, train_loss = 1.0692460983991623, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 466, train_loss = 1.067719912767643, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 467, train_loss = 1.0661875332298223, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 468, train_loss = 1.0645559144613799, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 469, train_loss = 1.063078261911869, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "28th- epoch: 470, train_loss = 1.0615030502376612, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 471, train_loss = 1.0599602485599462, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 472, train_loss = 1.0584643160400447, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 473, train_loss = 1.0569846096041147, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 474, train_loss = 1.0554090899822768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 475, train_loss = 1.053965825587511, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 476, train_loss = 1.0524720177054405, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 477, train_loss = 1.0509328804910183, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 478, train_loss = 1.0493971854448318, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 479, train_loss = 1.048086999595398, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 480, train_loss = 1.0465713292360306, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 481, train_loss = 1.0450851395726204, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 482, train_loss = 1.0436727218329906, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 483, train_loss = 1.0422279549238738, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 484, train_loss = 1.040903564542532, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 485, train_loss = 1.039375784486765, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 486, train_loss = 1.0379944878222886, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 487, train_loss = 1.0365353102388326, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 488, train_loss = 1.0351655197737273, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 489, train_loss = 1.033700986445183, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 490, train_loss = 1.0323680142464582, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 491, train_loss = 1.0309398236277048, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 492, train_loss = 1.0296040028333664, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 493, train_loss = 1.0282370212080423, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 494, train_loss = 1.026854964584345, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 495, train_loss = 1.0255429334938526, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 496, train_loss = 1.0241106674075127, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 497, train_loss = 1.022777651756769, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 498, train_loss = 1.0214995952846948, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "28th- epoch: 499, train_loss = 1.0200772719981615, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|███████████████████████████████████████████████████████████████████▏    | 28/30 [3:11:19<13:42, 411.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "29th- epoch: 0, train_loss = 274.99546468257904, train_acc = 0.42524452724732187\n",
      "test Acc 0.5470204841713222:\n",
      "29th- epoch: 1, train_loss = 207.57960975170135, train_acc = 0.544014904517932\n",
      "test Acc 0.5684357541899442:\n",
      "29th- epoch: 2, train_loss = 159.48678505420685, train_acc = 0.5982766651141127\n",
      "test Acc 0.6461824953445066:\n",
      "29th- epoch: 3, train_loss = 134.3399796485901, train_acc = 0.6774569166278528\n",
      "test Acc 0.7169459962756052:\n",
      "29th- epoch: 4, train_loss = 115.884670317173, train_acc = 0.7377736376339078\n",
      "test Acc 0.7630353817504656:\n",
      "29th- epoch: 5, train_loss = 101.1388313472271, train_acc = 0.7703772706101537\n",
      "test Acc 0.7867783985102421:\n",
      "29th- epoch: 6, train_loss = 89.10945987701416, train_acc = 0.7921518397764322\n",
      "test Acc 0.8002793296089385:\n",
      "29th- epoch: 7, train_loss = 79.25675386190414, train_acc = 0.807638565440149\n",
      "test Acc 0.8249534450651769:\n",
      "29th- epoch: 8, train_loss = 70.96002933382988, train_acc = 0.8319748486259898\n",
      "test Acc 0.8449720670391061:\n",
      "29th- epoch: 9, train_loss = 63.795878887176514, train_acc = 0.8556124825337681\n",
      "test Acc 0.8719739292364991:\n",
      "29th- epoch: 10, train_loss = 57.56893905997276, train_acc = 0.8819282720074523\n",
      "test Acc 0.8961824953445066:\n",
      "29th- epoch: 11, train_loss = 52.16353753209114, train_acc = 0.9025384257102934\n",
      "test Acc 0.9110800744878957:\n",
      "29th- epoch: 12, train_loss = 47.465826228260994, train_acc = 0.9202375407545412\n",
      "test Acc 0.9264432029795159:\n",
      "29th- epoch: 13, train_loss = 43.37102957069874, train_acc = 0.9340940847694458\n",
      "test Acc 0.936219739292365:\n",
      "29th- epoch: 14, train_loss = 39.79985912144184, train_acc = 0.9394503959012576\n",
      "test Acc 0.9394785847299814:\n",
      "29th- epoch: 15, train_loss = 36.687126606702805, train_acc = 0.9403819282720075\n",
      "test Acc 0.9418063314711359:\n",
      "29th- epoch: 16, train_loss = 33.98251688480377, train_acc = 0.9431765253842571\n",
      "test Acc 0.9473929236499069:\n",
      "29th- epoch: 17, train_loss = 31.63639795780182, train_acc = 0.9492314857941313\n",
      "test Acc 0.9515828677839852:\n",
      "29th- epoch: 18, train_loss = 29.60120791196823, train_acc = 0.9513274336283186\n",
      "test Acc 0.9534450651769087:\n",
      "29th- epoch: 19, train_loss = 27.829045988619328, train_acc = 0.9536562645551933\n",
      "test Acc 0.9548417132216015:\n",
      "29th- epoch: 20, train_loss = 26.28116402029991, train_acc = 0.9557522123893806\n",
      "test Acc 0.9567039106145251:\n",
      "29th- epoch: 21, train_loss = 24.920900899916887, train_acc = 0.9570330693991617\n",
      "test Acc 0.9581005586592178:\n",
      "29th- epoch: 22, train_loss = 23.71739000454545, train_acc = 0.9581974848625989\n",
      "test Acc 0.957635009310987:\n",
      "29th- epoch: 23, train_loss = 22.646897334605455, train_acc = 0.9593619003260363\n",
      "test Acc 0.9581005586592178:\n",
      "29th- epoch: 24, train_loss = 21.686723198741674, train_acc = 0.9613414066138798\n",
      "test Acc 0.9594972067039106:\n",
      "29th- epoch: 25, train_loss = 20.821287117898464, train_acc = 0.9620400558919422\n",
      "test Acc 0.9599627560521415:\n",
      "29th- epoch: 26, train_loss = 20.03611385077238, train_acc = 0.9630880298090359\n",
      "test Acc 0.9608938547486033:\n",
      "29th- epoch: 27, train_loss = 19.319374833256006, train_acc = 0.9642524452724732\n",
      "test Acc 0.9608938547486033:\n",
      "29th- epoch: 28, train_loss = 18.661690670996904, train_acc = 0.9657661853749417\n",
      "test Acc 0.9608938547486033:\n",
      "29th- epoch: 29, train_loss = 18.05548409000039, train_acc = 0.9663483931066604\n",
      "test Acc 0.962756052141527:\n",
      "29th- epoch: 30, train_loss = 17.49373423308134, train_acc = 0.9668141592920354\n",
      "test Acc 0.9632216014897579:\n",
      "29th- epoch: 31, train_loss = 16.970965143293142, train_acc = 0.9680950163018165\n",
      "test Acc 0.9636871508379888:\n",
      "29th- epoch: 32, train_loss = 16.48391744494438, train_acc = 0.9685607824871915\n",
      "test Acc 0.9646182495344506:\n",
      "29th- epoch: 33, train_loss = 16.028594940900803, train_acc = 0.9691429902189101\n",
      "test Acc 0.9650837988826816:\n",
      "29th- epoch: 34, train_loss = 15.601242825388908, train_acc = 0.9697251979506288\n",
      "test Acc 0.9641527001862198:\n",
      "29th- epoch: 35, train_loss = 15.198353979736567, train_acc = 0.9707731718677224\n",
      "test Acc 0.9655493482309124:\n",
      "29th- epoch: 36, train_loss = 14.817345466464758, train_acc = 0.9720540288775035\n",
      "test Acc 0.9683426443202979:\n",
      "29th- epoch: 37, train_loss = 14.456216264516115, train_acc = 0.9733348858872846\n",
      "test Acc 0.9692737430167597:\n",
      "29th- epoch: 38, train_loss = 14.11329047754407, train_acc = 0.9744993013507219\n",
      "test Acc 0.9706703910614525:\n",
      "29th- epoch: 39, train_loss = 13.787669315934181, train_acc = 0.9750815090824406\n",
      "test Acc 0.9725325884543762:\n",
      "29th- epoch: 40, train_loss = 13.47758026048541, train_acc = 0.9758965999068467\n",
      "test Acc 0.972998137802607:\n",
      "29th- epoch: 41, train_loss = 13.182330716401339, train_acc = 0.9763623660922217\n",
      "test Acc 0.9725325884543762:\n",
      "29th- epoch: 42, train_loss = 12.90062415227294, train_acc = 0.9767116907312529\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 43, train_loss = 12.631400909274817, train_acc = 0.9771774569166278\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 44, train_loss = 12.373723693192005, train_acc = 0.9776432231020028\n",
      "test Acc 0.9739292364990689:\n",
      "29th- epoch: 45, train_loss = 12.126736100763083, train_acc = 0.9777596646483465\n",
      "test Acc 0.9743947858472998:\n",
      "29th- epoch: 46, train_loss = 11.889916073530912, train_acc = 0.9778761061946902\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 47, train_loss = 11.662443116307259, train_acc = 0.9784583139264089\n",
      "test Acc 0.9748603351955307:\n",
      "29th- epoch: 48, train_loss = 11.443599380552769, train_acc = 0.9788076385654402\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 49, train_loss = 11.233066875487566, train_acc = 0.9796227293898463\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 50, train_loss = 11.03011642023921, train_acc = 0.980204937121565\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 51, train_loss = 10.834261789917946, train_acc = 0.9805542617605962\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 52, train_loss = 10.645209074020386, train_acc = 0.9811364694923148\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 53, train_loss = 10.462709169834852, train_acc = 0.9812529110386586\n",
      "test Acc 0.9757914338919925:\n",
      "29th- epoch: 54, train_loss = 10.286102868616581, train_acc = 0.9816022356776898\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 55, train_loss = 10.115095300599933, train_acc = 0.9818351187703773\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 56, train_loss = 9.949147030711174, train_acc = 0.9823008849557522\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 57, train_loss = 9.788288930431008, train_acc = 0.9825337680484397\n",
      "test Acc 0.9762569832402235:\n",
      "29th- epoch: 58, train_loss = 9.632143691182137, train_acc = 0.9826502095947834\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 59, train_loss = 9.48053627833724, train_acc = 0.9828830926874709\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 60, train_loss = 9.33311177417636, train_acc = 0.9829995342338146\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 61, train_loss = 9.189878314733505, train_acc = 0.9834653004191896\n",
      "test Acc 0.9767225325884544:\n",
      "29th- epoch: 62, train_loss = 9.05050678178668, train_acc = 0.9835817419655333\n",
      "test Acc 0.9771880819366853:\n",
      "29th- epoch: 63, train_loss = 8.914609856903553, train_acc = 0.9839310666045645\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 64, train_loss = 8.782281506806612, train_acc = 0.9839310666045645\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 65, train_loss = 8.653079131618142, train_acc = 0.9839310666045645\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 66, train_loss = 8.527084784582257, train_acc = 0.9840475081509082\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 67, train_loss = 8.403974181041121, train_acc = 0.9840475081509082\n",
      "test Acc 0.978584729981378:\n",
      "29th- epoch: 68, train_loss = 8.283781882375479, train_acc = 0.984163949697252\n",
      "test Acc 0.979050279329609:\n",
      "29th- epoch: 69, train_loss = 8.166253700852394, train_acc = 0.9843968327899395\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 70, train_loss = 8.051364915445447, train_acc = 0.9846297158826269\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 71, train_loss = 7.938962189480662, train_acc = 0.9848625989753144\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 72, train_loss = 7.828966783359647, train_acc = 0.9850954820680019\n",
      "test Acc 0.9795158286778398:\n",
      "29th- epoch: 73, train_loss = 7.721284372732043, train_acc = 0.9853283651606893\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 74, train_loss = 7.615737844258547, train_acc = 0.9853283651606893\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 75, train_loss = 7.51239007897675, train_acc = 0.9853283651606893\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 76, train_loss = 7.411250047385693, train_acc = 0.9855612482533768\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 77, train_loss = 7.312006512656808, train_acc = 0.985910572892408\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 78, train_loss = 7.214772570878267, train_acc = 0.985910572892408\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 79, train_loss = 7.119303695857525, train_acc = 0.9861434559850955\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 80, train_loss = 7.025789692997932, train_acc = 0.9864927806241267\n",
      "test Acc 0.9804469273743017:\n",
      "29th- epoch: 81, train_loss = 6.934002727270126, train_acc = 0.9867256637168141\n",
      "test Acc 0.9809124767225326:\n",
      "29th- epoch: 82, train_loss = 6.843929251655936, train_acc = 0.9868421052631579\n",
      "test Acc 0.9809124767225326:\n",
      "29th- epoch: 83, train_loss = 6.755367137491703, train_acc = 0.9869585468095017\n",
      "test Acc 0.9809124767225326:\n",
      "29th- epoch: 84, train_loss = 6.668551256880164, train_acc = 0.9871914299021891\n",
      "test Acc 0.9809124767225326:\n",
      "29th- epoch: 85, train_loss = 6.583228735253215, train_acc = 0.9873078714485328\n",
      "test Acc 0.9813780260707635:\n",
      "29th- epoch: 86, train_loss = 6.499408297240734, train_acc = 0.9873078714485328\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 87, train_loss = 6.417133012786508, train_acc = 0.9876571960875641\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 88, train_loss = 6.3361695278435946, train_acc = 0.9876571960875641\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 89, train_loss = 6.25672047957778, train_acc = 0.9881229622729389\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 90, train_loss = 6.178629780188203, train_acc = 0.9882394038192828\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 91, train_loss = 6.101999640464783, train_acc = 0.9884722869119702\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 92, train_loss = 6.026838134974241, train_acc = 0.9888216115510013\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 93, train_loss = 5.95305247977376, train_acc = 0.9889380530973452\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 94, train_loss = 5.880742019042373, train_acc = 0.9890544946436889\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 95, train_loss = 5.809615088626742, train_acc = 0.9890544946436889\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 96, train_loss = 5.739949196577072, train_acc = 0.9891709361900326\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 97, train_loss = 5.671435000374913, train_acc = 0.9897531439217513\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 98, train_loss = 5.604121692478657, train_acc = 0.989869585468095\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 99, train_loss = 5.538206968456507, train_acc = 0.9901024685607824\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 100, train_loss = 5.473492356017232, train_acc = 0.9902189101071263\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 101, train_loss = 5.4099343828856945, train_acc = 0.99033535165347\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 102, train_loss = 5.3476344626396894, train_acc = 0.9904517931998137\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 103, train_loss = 5.2863460928201675, train_acc = 0.9905682347461574\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 104, train_loss = 5.226305326446891, train_acc = 0.9906846762925011\n",
      "test Acc 0.9837057728119181:\n",
      "29th- epoch: 105, train_loss = 5.167357726022601, train_acc = 0.990801117838845\n",
      "test Acc 0.9837057728119181:\n",
      "29th- epoch: 106, train_loss = 5.109456949867308, train_acc = 0.9909175593851887\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 107, train_loss = 5.052695878781378, train_acc = 0.9910340009315324\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 108, train_loss = 4.996792754158378, train_acc = 0.9911504424778761\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 109, train_loss = 4.942089303396642, train_acc = 0.9911504424778761\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 110, train_loss = 4.888301373459399, train_acc = 0.9913833255705635\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 111, train_loss = 4.835480674169958, train_acc = 0.9912668840242198\n",
      "test Acc 0.9837057728119181:\n",
      "29th- epoch: 112, train_loss = 4.783657825551927, train_acc = 0.9912668840242198\n",
      "test Acc 0.9837057728119181:\n",
      "29th- epoch: 113, train_loss = 4.732714990153909, train_acc = 0.9912668840242198\n",
      "test Acc 0.9837057728119181:\n",
      "29th- epoch: 114, train_loss = 4.682660362683237, train_acc = 0.9912668840242198\n",
      "test Acc 0.9837057728119181:\n",
      "29th- epoch: 115, train_loss = 4.633416500873864, train_acc = 0.9917326502095948\n",
      "test Acc 0.9837057728119181:\n",
      "29th- epoch: 116, train_loss = 4.585085567086935, train_acc = 0.9917326502095948\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 117, train_loss = 4.537456993944943, train_acc = 0.9918490917559385\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 118, train_loss = 4.490880548022687, train_acc = 0.9918490917559385\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 119, train_loss = 4.4448906341567636, train_acc = 0.9919655333022822\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 120, train_loss = 4.399808398447931, train_acc = 0.9919655333022822\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 121, train_loss = 4.3554172506555915, train_acc = 0.9923148579413135\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 122, train_loss = 4.311869892291725, train_acc = 0.9923148579413135\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 123, train_loss = 4.268917811103165, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 124, train_loss = 4.226769567467272, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 125, train_loss = 4.185296227224171, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 126, train_loss = 4.144510758109391, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 127, train_loss = 4.104458850808442, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 128, train_loss = 4.064926567487419, train_acc = 0.9924312994876572\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 129, train_loss = 4.0260069305077195, train_acc = 0.9926641825803446\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 130, train_loss = 3.98779015801847, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 131, train_loss = 3.950035477988422, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 132, train_loss = 3.913031975738704, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 133, train_loss = 3.876585074700415, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 134, train_loss = 3.8407594626769423, train_acc = 0.9930135072193759\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 135, train_loss = 3.805462686344981, train_acc = 0.9930135072193759\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 136, train_loss = 3.7706429082900286, train_acc = 0.9931299487657196\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 137, train_loss = 3.73645060043782, train_acc = 0.9932463903120633\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 138, train_loss = 3.7027301052585244, train_acc = 0.9933628318584071\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 139, train_loss = 3.6695899283513427, train_acc = 0.9937121564974383\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 140, train_loss = 3.636954457499087, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 141, train_loss = 3.604832020588219, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "29th- epoch: 142, train_loss = 3.573256709612906, train_acc = 0.9939450395901258\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 143, train_loss = 3.5420645037665963, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 144, train_loss = 3.511512925848365, train_acc = 0.9940614811364695\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 145, train_loss = 3.4813399710692465, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 146, train_loss = 3.4516103621572256, train_acc = 0.9941779226828132\n",
      "test Acc 0.9827746741154563:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 147, train_loss = 3.422218116465956, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 148, train_loss = 3.393376846332103, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 149, train_loss = 3.3647092897444963, train_acc = 0.994294364229157\n",
      "test Acc 0.9827746741154563:\n",
      "29th- epoch: 150, train_loss = 3.3366992133669555, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 151, train_loss = 3.3089039586484432, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 152, train_loss = 3.281616320833564, train_acc = 0.9944108057755007\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 153, train_loss = 3.254738972056657, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 154, train_loss = 3.228234500158578, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 155, train_loss = 3.202048863749951, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 156, train_loss = 3.176269709598273, train_acc = 0.9945272473218444\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 157, train_loss = 3.1508884211070836, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 158, train_loss = 3.1257325098849833, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 159, train_loss = 3.1010590721853077, train_acc = 0.9946436888681882\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 160, train_loss = 3.0767208449542522, train_acc = 0.9947601304145319\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 161, train_loss = 3.0526786665432155, train_acc = 0.9949930135072194\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 162, train_loss = 3.029066748917103, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 163, train_loss = 3.005725890863687, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 164, train_loss = 2.9827589043416083, train_acc = 0.9951094550535631\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 165, train_loss = 2.96012151427567, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 166, train_loss = 2.937740662600845, train_acc = 0.9952258965999069\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 167, train_loss = 2.915682654827833, train_acc = 0.9953423381462506\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 168, train_loss = 2.8938864525407553, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 169, train_loss = 2.8724282435141504, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 170, train_loss = 2.85118953185156, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 171, train_loss = 2.8303794250823557, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 172, train_loss = 2.8097377493977547, train_acc = 0.9954587796925943\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 173, train_loss = 2.789439780637622, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 174, train_loss = 2.7692851019091904, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 175, train_loss = 2.7496070861816406, train_acc = 0.995575221238938\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 176, train_loss = 2.7299845037050545, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 177, train_loss = 2.710771238896996, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 178, train_loss = 2.6917796451598406, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 179, train_loss = 2.672899615485221, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 180, train_loss = 2.6544539486058056, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 181, train_loss = 2.636176175903529, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 182, train_loss = 2.618104036897421, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 183, train_loss = 2.6002671546302736, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 184, train_loss = 2.5826513641513884, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 185, train_loss = 2.5652653188444674, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 186, train_loss = 2.5480665899813175, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 187, train_loss = 2.5312261700164527, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 188, train_loss = 2.514469313202426, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 189, train_loss = 2.498005439294502, train_acc = 0.9958081043316255\n",
      "test Acc 0.9832402234636871:\n",
      "29th- epoch: 190, train_loss = 2.481652231188491, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "29th- epoch: 191, train_loss = 2.4655558753293008, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "29th- epoch: 192, train_loss = 2.4497804201673716, train_acc = 0.9959245458779693\n",
      "test Acc 0.9837057728119181:\n",
      "29th- epoch: 193, train_loss = 2.4340815630275756, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 194, train_loss = 2.418622898636386, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 195, train_loss = 2.4033981908578426, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 196, train_loss = 2.3882955897133797, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 197, train_loss = 2.373423448530957, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 198, train_loss = 2.358728799968958, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 199, train_loss = 2.3441965288948268, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 200, train_loss = 2.329817619873211, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 201, train_loss = 2.315710188122466, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 202, train_loss = 2.301630784990266, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 203, train_loss = 2.287771226838231, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 204, train_loss = 2.274061259580776, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 205, train_loss = 2.260599148226902, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 206, train_loss = 2.2472751557361335, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 207, train_loss = 2.234042078955099, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 208, train_loss = 2.221117625012994, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 209, train_loss = 2.2082085472065955, train_acc = 0.9959245458779693\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 210, train_loss = 2.195645198225975, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 211, train_loss = 2.183072378858924, train_acc = 0.996040987424313\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 212, train_loss = 2.170792667893693, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 213, train_loss = 2.1585357647854835, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 214, train_loss = 2.1465629029553384, train_acc = 0.9961574289706567\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 215, train_loss = 2.134672411950305, train_acc = 0.9963903120633442\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 216, train_loss = 2.122829098254442, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 217, train_loss = 2.1113248963374645, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 218, train_loss = 2.0998959827702492, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 219, train_loss = 2.088572145672515, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 220, train_loss = 2.0774246715009212, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 221, train_loss = 2.0664193455595523, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 222, train_loss = 2.055605348199606, train_acc = 0.996506753609688\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 223, train_loss = 2.0448806148488075, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 224, train_loss = 2.034258894622326, train_acc = 0.9966231951560317\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 225, train_loss = 2.0238805438857526, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 226, train_loss = 2.013509365497157, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 227, train_loss = 2.0033306144177914, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 228, train_loss = 1.9933153092861176, train_acc = 0.9967396367023754\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 229, train_loss = 1.9832925151567906, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 230, train_loss = 1.9735848121345043, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 231, train_loss = 1.963816624134779, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 232, train_loss = 1.9542911276221275, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 233, train_loss = 1.9447810400743037, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 234, train_loss = 1.9353972859680653, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 235, train_loss = 1.9261423125863075, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 236, train_loss = 1.917026205570437, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 237, train_loss = 1.9080503843724728, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 238, train_loss = 1.8990169564494863, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 239, train_loss = 1.8902451047906652, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 240, train_loss = 1.8815600015223026, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 241, train_loss = 1.8729577250778675, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 242, train_loss = 1.8644337318837643, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 243, train_loss = 1.856051211594604, train_acc = 0.9968560782487191\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 244, train_loss = 1.847739682882093, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 245, train_loss = 1.8396263854810968, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 246, train_loss = 1.8314853832125664, train_acc = 0.9969725197950629\n",
      "test Acc 0.984171322160149:\n",
      "29th- epoch: 247, train_loss = 1.8234800907084718, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 248, train_loss = 1.8156110061099753, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 249, train_loss = 1.807776919216849, train_acc = 0.9969725197950629\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 250, train_loss = 1.800021064816974, train_acc = 0.9970889613414066\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 251, train_loss = 1.7924256399273872, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 252, train_loss = 1.7849052374949679, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 253, train_loss = 1.7773499874165282, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 254, train_loss = 1.769961038022302, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 255, train_loss = 1.7625962980091572, train_acc = 0.9972054028877504\n",
      "test Acc 0.9846368715083799:\n",
      "29th- epoch: 256, train_loss = 1.755369090824388, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 257, train_loss = 1.7483047097921371, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 258, train_loss = 1.7411863742163405, train_acc = 0.9973218444340941\n",
      "test Acc 0.9851024208566108:\n",
      "29th- epoch: 259, train_loss = 1.7342718889703974, train_acc = 0.9973218444340941\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 260, train_loss = 1.72736670949962, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 261, train_loss = 1.720577577711083, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 262, train_loss = 1.7138395583024248, train_acc = 0.9974382859804378\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 263, train_loss = 1.7071644911775365, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 264, train_loss = 1.700600754469633, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 265, train_loss = 1.6941097676753998, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 266, train_loss = 1.687603134661913, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 267, train_loss = 1.6812776699662209, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 268, train_loss = 1.674895583302714, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 269, train_loss = 1.6687076290836558, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 270, train_loss = 1.6625069802394137, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 271, train_loss = 1.6563851410755888, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 272, train_loss = 1.6503446461865678, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 273, train_loss = 1.644311840296723, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 274, train_loss = 1.6384093327214941, train_acc = 0.9975547275267815\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 275, train_loss = 1.6325334943830967, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 276, train_loss = 1.6266600837698206, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 277, train_loss = 1.6209524323930964, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 278, train_loss = 1.6151639433810487, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 279, train_loss = 1.6095885498216376, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 280, train_loss = 1.603941903798841, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 281, train_loss = 1.5983789724996313, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 282, train_loss = 1.592986311763525, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 283, train_loss = 1.5874438831815496, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 284, train_loss = 1.5821096301078796, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 285, train_loss = 1.5767549561569467, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 286, train_loss = 1.5715009371051565, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 287, train_loss = 1.5662767527392134, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 288, train_loss = 1.5610621744999662, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 289, train_loss = 1.5559336990118027, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 290, train_loss = 1.5507952310144901, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 291, train_loss = 1.5458119722316042, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 292, train_loss = 1.5407780905952677, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 293, train_loss = 1.535822174162604, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 294, train_loss = 1.5309794520726427, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 295, train_loss = 1.526056562899612, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 296, train_loss = 1.521310287178494, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 297, train_loss = 1.516446201771032, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 298, train_loss = 1.5118100233376026, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 299, train_loss = 1.507105911790859, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 300, train_loss = 1.5024335819180124, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 301, train_loss = 1.4978297638590448, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 302, train_loss = 1.493240023672115, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 303, train_loss = 1.4887695014476776, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 304, train_loss = 1.4842356257140636, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 305, train_loss = 1.47980697453022, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 306, train_loss = 1.4753474009339698, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 307, train_loss = 1.4709471464157104, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 308, train_loss = 1.4666173768346198, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 309, train_loss = 1.462310319126118, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 310, train_loss = 1.4580750067834742, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 311, train_loss = 1.4538517135079019, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 312, train_loss = 1.4495727208559401, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 313, train_loss = 1.4454750269651413, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 314, train_loss = 1.4412847583298571, train_acc = 0.9976711690731253\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 315, train_loss = 1.4373145650024526, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 316, train_loss = 1.4331637099385262, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 317, train_loss = 1.4291511587798595, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 318, train_loss = 1.4252363021369092, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 319, train_loss = 1.4211572855710983, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 320, train_loss = 1.4173265409772284, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 321, train_loss = 1.4134500262443908, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 322, train_loss = 1.4095190254156478, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 323, train_loss = 1.4057629369199276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 324, train_loss = 1.4018104821443558, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 325, train_loss = 1.3981413903529756, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 326, train_loss = 1.3943092947010882, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 327, train_loss = 1.390610986680258, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 328, train_loss = 1.3869680290226825, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 329, train_loss = 1.3833466482465155, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 330, train_loss = 1.3796849772334099, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 331, train_loss = 1.3762004773016088, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 332, train_loss = 1.3725325539708138, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 333, train_loss = 1.3691248607938178, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 334, train_loss = 1.3655025561456569, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 335, train_loss = 1.3621865610475652, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 336, train_loss = 1.3586503490805626, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 337, train_loss = 1.355239658325445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 338, train_loss = 1.3518553624744527, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 339, train_loss = 1.3485531695187092, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 340, train_loss = 1.345261175185442, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 341, train_loss = 1.3419341668486595, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 342, train_loss = 1.3386837244033813, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 343, train_loss = 1.335406806319952, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 344, train_loss = 1.3321941370959394, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 345, train_loss = 1.3290055033867247, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 346, train_loss = 1.3258748936350457, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 347, train_loss = 1.3226764698629268, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 348, train_loss = 1.319475281983614, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 349, train_loss = 1.3164279970224015, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 350, train_loss = 1.3134306755964644, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 351, train_loss = 1.3103473174269311, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 352, train_loss = 1.3071879781782627, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 353, train_loss = 1.3041799652273767, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 354, train_loss = 1.301139007031452, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 355, train_loss = 1.2982282526791096, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 356, train_loss = 1.295217274397146, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 357, train_loss = 1.2923177182674408, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 358, train_loss = 1.2894965832238086, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 359, train_loss = 1.2864226450328715, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 360, train_loss = 1.2836438715457916, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 361, train_loss = 1.2808158087427728, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 362, train_loss = 1.2779408432543278, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 363, train_loss = 1.2751820348203182, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 364, train_loss = 1.2723420870606788, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 365, train_loss = 1.269607885449659, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 366, train_loss = 1.2668315023183823, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 367, train_loss = 1.2641265280544758, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 368, train_loss = 1.2614104449748993, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 369, train_loss = 1.2586684499983676, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 370, train_loss = 1.2560929208993912, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 371, train_loss = 1.2533924505114555, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 372, train_loss = 1.2507607613806613, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 373, train_loss = 1.24809941399144, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 374, train_loss = 1.2455716344411485, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 375, train_loss = 1.2430083528161049, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 376, train_loss = 1.2403936286573298, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 377, train_loss = 1.2378782480955124, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 378, train_loss = 1.2353666611015797, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 379, train_loss = 1.2328327521681786, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 380, train_loss = 1.2302447172405664, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 381, train_loss = 1.227827432245249, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 382, train_loss = 1.225331143796211, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 383, train_loss = 1.2229823097586632, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 384, train_loss = 1.2205106342735235, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 385, train_loss = 1.2180650271475315, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 386, train_loss = 1.2156948844494764, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 387, train_loss = 1.213237023592228, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 388, train_loss = 1.2108696103096008, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 389, train_loss = 1.2085321384074632, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 390, train_loss = 1.2061916564998683, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 391, train_loss = 1.203867457807064, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 392, train_loss = 1.201563154667383, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 393, train_loss = 1.1992824226617813, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 394, train_loss = 1.1968800326285418, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 395, train_loss = 1.1947483830153942, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 396, train_loss = 1.1924710335733835, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 397, train_loss = 1.1901860050857067, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 398, train_loss = 1.1880176973936614, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 399, train_loss = 1.1858342873456422, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 400, train_loss = 1.1835756761429366, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 401, train_loss = 1.1814162408409175, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 402, train_loss = 1.1791645027697086, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 403, train_loss = 1.1771210829319898, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 404, train_loss = 1.1749374481441919, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 405, train_loss = 1.1728073060512543, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 406, train_loss = 1.1706675154564437, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 407, train_loss = 1.1686624748108443, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 408, train_loss = 1.1664254243078176, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 409, train_loss = 1.1644453443586826, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 410, train_loss = 1.1622844388184603, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 411, train_loss = 1.1603611359896604, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 412, train_loss = 1.1582785857317504, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 413, train_loss = 1.156203892081976, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 414, train_loss = 1.1541542708873749, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 415, train_loss = 1.15212894231081, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 416, train_loss = 1.150253580271965, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 417, train_loss = 1.1482344952819403, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 418, train_loss = 1.1462063441576902, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 419, train_loss = 1.144351559370989, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 420, train_loss = 1.1423365051450673, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 421, train_loss = 1.1403740929963533, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 422, train_loss = 1.1384900274279062, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 423, train_loss = 1.1365718841552734, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 424, train_loss = 1.134679026901722, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 425, train_loss = 1.1327930018305779, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 426, train_loss = 1.1308339039387647, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 427, train_loss = 1.129047260939842, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 428, train_loss = 1.1271930783987045, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 429, train_loss = 1.1252599246799946, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 430, train_loss = 1.1235125971434172, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 431, train_loss = 1.1216339257953223, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 432, train_loss = 1.11987373730517, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 433, train_loss = 1.1179582998156548, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 434, train_loss = 1.1162405672075693, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 435, train_loss = 1.1144105134007987, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 436, train_loss = 1.1126126646995544, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 437, train_loss = 1.1108646380307619, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 438, train_loss = 1.1091617929341737, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 439, train_loss = 1.1072959428129252, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 440, train_loss = 1.1057309359312057, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 441, train_loss = 1.1038662046194077, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29th- epoch: 442, train_loss = 1.10212572911405, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 443, train_loss = 1.10053651034832, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 444, train_loss = 1.0987713560461998, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 445, train_loss = 1.0970779359340668, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 446, train_loss = 1.0954118333756924, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 447, train_loss = 1.0937413933279458, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 448, train_loss = 1.0920260126295034, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 449, train_loss = 1.0904131059942301, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 450, train_loss = 1.0887011053564493, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 451, train_loss = 1.0871472706494387, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 452, train_loss = 1.0854503052833024, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 453, train_loss = 1.0838418466446456, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 454, train_loss = 1.0822393583657686, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 455, train_loss = 1.0806447813811246, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 456, train_loss = 1.078997886419529, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 457, train_loss = 1.0774308840336744, train_acc = 0.9979040521658128\n",
      "test Acc 0.9855679702048417:\n",
      "29th- epoch: 458, train_loss = 1.0758850959537085, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 459, train_loss = 1.0742244621214923, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 460, train_loss = 1.0726649835705757, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 461, train_loss = 1.0710793708858546, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 462, train_loss = 1.069662731140852, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 463, train_loss = 1.0680658432247583, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 464, train_loss = 1.0665039978921413, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 465, train_loss = 1.0650597835483495, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 466, train_loss = 1.0634594721195754, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 467, train_loss = 1.0619411170482635, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 468, train_loss = 1.0604397753777448, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 469, train_loss = 1.0590341128408909, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 470, train_loss = 1.057381426304346, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 471, train_loss = 1.0559855438768864, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 472, train_loss = 1.0544766001403332, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 473, train_loss = 1.0530033260583878, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 474, train_loss = 1.0515857338905334, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 475, train_loss = 1.0501446314156055, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 476, train_loss = 1.0485803919436876, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 477, train_loss = 1.0472887779178564, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 478, train_loss = 1.0458819940686226, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 479, train_loss = 1.0443399722280446, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 480, train_loss = 1.0429852344095707, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 481, train_loss = 1.0415328343806323, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 482, train_loss = 1.0401474932732526, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 483, train_loss = 1.038784639298683, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 484, train_loss = 1.0374299263057765, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 485, train_loss = 1.0359506184759084, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 486, train_loss = 1.0346561608312186, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 487, train_loss = 1.0332370599207934, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 488, train_loss = 1.0318907536566257, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 489, train_loss = 1.0305305471119937, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 490, train_loss = 1.0292475683090743, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 491, train_loss = 1.0278268493711948, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 492, train_loss = 1.0265470805316, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 493, train_loss = 1.0252548890857724, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 494, train_loss = 1.0238917892129393, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 495, train_loss = 1.0225101324467687, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 496, train_loss = 1.0212944174854783, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 497, train_loss = 1.019911448165658, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 498, train_loss = 1.018668203309062, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "29th- epoch: 499, train_loss = 1.0173737506120233, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████▌  | 29/30 [3:18:09<06:50, 410.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm1(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=256, out_features=9, bias=True)\n",
      "  )\n",
      ")\n",
      "30th- epoch: 0, train_loss = 274.46309661865234, train_acc = 0.441895668374476\n",
      "test Acc 0.5581936685288641:\n",
      "30th- epoch: 1, train_loss = 209.75742936134338, train_acc = 0.5635770843036796\n",
      "test Acc 0.5721601489757915:\n",
      "30th- epoch: 2, train_loss = 162.2271118760109, train_acc = 0.5789473684210527\n",
      "test Acc 0.6075418994413407:\n",
      "30th- epoch: 3, train_loss = 136.10176706314087, train_acc = 0.6655798789007918\n",
      "test Acc 0.7183426443202979:\n",
      "30th- epoch: 4, train_loss = 116.9993224143982, train_acc = 0.7413833255705635\n",
      "test Acc 0.7732774674115456:\n",
      "30th- epoch: 5, train_loss = 101.09262543916702, train_acc = 0.7876106194690266\n",
      "test Acc 0.7932960893854749:\n",
      "30th- epoch: 6, train_loss = 87.94222795963287, train_acc = 0.8040288775034933\n",
      "test Acc 0.803072625698324:\n",
      "30th- epoch: 7, train_loss = 77.31594187021255, train_acc = 0.8203306939916162\n",
      "test Acc 0.8221601489757915:\n",
      "30th- epoch: 8, train_loss = 68.61557731032372, train_acc = 0.841988821611551\n",
      "test Acc 0.8514897579143389:\n",
      "30th- epoch: 9, train_loss = 61.40203332901001, train_acc = 0.8706334420121099\n",
      "test Acc 0.8864059590316573:\n",
      "30th- epoch: 10, train_loss = 55.36288993060589, train_acc = 0.8932231020027946\n",
      "test Acc 0.9003724394785847:\n",
      "30th- epoch: 11, train_loss = 50.24080486595631, train_acc = 0.9071960875640428\n",
      "test Acc 0.9152700186219739:\n",
      "30th- epoch: 12, train_loss = 45.84367357194424, train_acc = 0.9196553330228225\n",
      "test Acc 0.9283054003724395:\n",
      "30th- epoch: 13, train_loss = 42.02605618536472, train_acc = 0.9295528644620401\n",
      "test Acc 0.9385474860335196:\n",
      "30th- epoch: 14, train_loss = 38.69715827703476, train_acc = 0.9363064741499767\n",
      "test Acc 0.9408752327746741:\n",
      "30th- epoch: 15, train_loss = 35.792452692985535, train_acc = 0.939683278993945\n",
      "test Acc 0.9436685288640596:\n",
      "30th- epoch: 16, train_loss = 33.26111336052418, train_acc = 0.9450395901257569\n",
      "test Acc 0.9483240223463687:\n",
      "30th- epoch: 17, train_loss = 31.054892234504223, train_acc = 0.9495808104331626\n",
      "test Acc 0.9497206703910615:\n",
      "30th- epoch: 18, train_loss = 29.12680221349001, train_acc = 0.9514438751746623\n",
      "test Acc 0.9539106145251397:\n",
      "30th- epoch: 19, train_loss = 27.439313925802708, train_acc = 0.9538891476478808\n",
      "test Acc 0.9562383612662942:\n",
      "30th- epoch: 20, train_loss = 25.958461344242096, train_acc = 0.9556357708430367\n",
      "test Acc 0.957169459962756:\n",
      "30th- epoch: 21, train_loss = 24.653988793492317, train_acc = 0.9572659524918491\n",
      "test Acc 0.9581005586592178:\n",
      "30th- epoch: 22, train_loss = 23.496264770627022, train_acc = 0.9590125756870052\n",
      "test Acc 0.9585661080074488:\n",
      "30th- epoch: 23, train_loss = 22.46332248672843, train_acc = 0.9606427573358174\n",
      "test Acc 0.9590316573556797:\n",
      "30th- epoch: 24, train_loss = 21.535627845674753, train_acc = 0.961690731252911\n",
      "test Acc 0.9594972067039106:\n",
      "30th- epoch: 25, train_loss = 20.69719960913062, train_acc = 0.9620400558919422\n",
      "test Acc 0.9594972067039106:\n",
      "30th- epoch: 26, train_loss = 19.933762699365616, train_acc = 0.9628551467163484\n",
      "test Acc 0.9608938547486033:\n",
      "30th- epoch: 27, train_loss = 19.23569307848811, train_acc = 0.9642524452724732\n",
      "test Acc 0.9608938547486033:\n",
      "30th- epoch: 28, train_loss = 18.594569601118565, train_acc = 0.9653004191895669\n",
      "test Acc 0.9618249534450651:\n",
      "30th- epoch: 29, train_loss = 18.002746790647507, train_acc = 0.9664648346530041\n",
      "test Acc 0.962756052141527:\n",
      "30th- epoch: 30, train_loss = 17.453498262912035, train_acc = 0.9673963670237541\n",
      "test Acc 0.9632216014897579:\n",
      "30th- epoch: 31, train_loss = 16.94137915223837, train_acc = 0.9679785747554728\n",
      "test Acc 0.9636871508379888:\n",
      "30th- epoch: 32, train_loss = 16.462221067398787, train_acc = 0.9686772240335352\n",
      "test Acc 0.9641527001862198:\n",
      "30th- epoch: 33, train_loss = 16.012800853699446, train_acc = 0.9694923148579413\n",
      "test Acc 0.9646182495344506:\n",
      "30th- epoch: 34, train_loss = 15.590626124292612, train_acc = 0.9707731718677224\n",
      "test Acc 0.9664804469273743:\n",
      "30th- epoch: 35, train_loss = 15.193559344857931, train_acc = 0.9721704704238472\n",
      "test Acc 0.9683426443202979:\n",
      "30th- epoch: 36, train_loss = 14.818701792508364, train_acc = 0.9732184443409408\n",
      "test Acc 0.9692737430167597:\n",
      "30th- epoch: 37, train_loss = 14.46346889436245, train_acc = 0.9739170936190032\n",
      "test Acc 0.9697392923649907:\n",
      "30th- epoch: 38, train_loss = 14.12644724175334, train_acc = 0.9744993013507219\n",
      "test Acc 0.9702048417132216:\n",
      "30th- epoch: 39, train_loss = 13.805961400270462, train_acc = 0.9748486259897532\n",
      "test Acc 0.9716014897579144:\n",
      "30th- epoch: 40, train_loss = 13.500902466475964, train_acc = 0.9751979506287843\n",
      "test Acc 0.9720670391061452:\n",
      "30th- epoch: 41, train_loss = 13.210164301097393, train_acc = 0.9756637168141593\n",
      "test Acc 0.9725325884543762:\n",
      "30th- epoch: 42, train_loss = 12.93239101395011, train_acc = 0.9763623660922217\n",
      "test Acc 0.9725325884543762:\n",
      "30th- epoch: 43, train_loss = 12.666676741093397, train_acc = 0.9767116907312529\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 44, train_loss = 12.412265505641699, train_acc = 0.9772938984629715\n",
      "test Acc 0.972998137802607:\n",
      "30th- epoch: 45, train_loss = 12.16831562295556, train_acc = 0.9785747554727526\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 46, train_loss = 11.93421621248126, train_acc = 0.9795062878435026\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 47, train_loss = 11.70963592454791, train_acc = 0.9798556124825337\n",
      "test Acc 0.973463687150838:\n",
      "30th- epoch: 48, train_loss = 11.493266519159079, train_acc = 0.9799720540288775\n",
      "test Acc 0.9743947858472998:\n",
      "30th- epoch: 49, train_loss = 11.284718446433544, train_acc = 0.9800884955752213\n",
      "test Acc 0.9748603351955307:\n",
      "30th- epoch: 50, train_loss = 11.08348086848855, train_acc = 0.98067070330694\n",
      "test Acc 0.9753258845437617:\n",
      "30th- epoch: 51, train_loss = 10.88914056494832, train_acc = 0.9807871448532837\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 52, train_loss = 10.701282285153866, train_acc = 0.9810200279459711\n",
      "test Acc 0.9757914338919925:\n",
      "30th- epoch: 53, train_loss = 10.519561529159546, train_acc = 0.9814857941313461\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 54, train_loss = 10.343575729057193, train_acc = 0.9817186772240335\n",
      "test Acc 0.9762569832402235:\n",
      "30th- epoch: 55, train_loss = 10.173077626153827, train_acc = 0.9820680018630648\n",
      "test Acc 0.9776536312849162:\n",
      "30th- epoch: 56, train_loss = 10.007645593956113, train_acc = 0.9821844434094085\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 57, train_loss = 9.847078511491418, train_acc = 0.9821844434094085\n",
      "test Acc 0.9781191806331471:\n",
      "30th- epoch: 58, train_loss = 9.691116264089942, train_acc = 0.9823008849557522\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 59, train_loss = 9.539718072861433, train_acc = 0.9824173265020959\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 60, train_loss = 9.392233433201909, train_acc = 0.9825337680484397\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 61, train_loss = 9.248668467625976, train_acc = 0.9825337680484397\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 62, train_loss = 9.10883753374219, train_acc = 0.9826502095947834\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 63, train_loss = 8.972479298710823, train_acc = 0.9829995342338146\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 64, train_loss = 8.839421264827251, train_acc = 0.9831159757801584\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 65, train_loss = 8.709434602409601, train_acc = 0.9832324173265021\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 66, train_loss = 8.582620864734054, train_acc = 0.9833488588728458\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 67, train_loss = 8.458652645349503, train_acc = 0.983698183511877\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 68, train_loss = 8.337380411103368, train_acc = 0.9839310666045645\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 69, train_loss = 8.218911672011018, train_acc = 0.9840475081509082\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 70, train_loss = 8.103172272443771, train_acc = 0.9840475081509082\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 71, train_loss = 7.9900278858840466, train_acc = 0.9840475081509082\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 72, train_loss = 7.879375644028187, train_acc = 0.9842803912435957\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 73, train_loss = 7.771053142845631, train_acc = 0.9843968327899395\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 74, train_loss = 7.66524245403707, train_acc = 0.9845132743362832\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 75, train_loss = 7.561562044546008, train_acc = 0.9848625989753144\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 76, train_loss = 7.460087897256017, train_acc = 0.9848625989753144\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 77, train_loss = 7.36085749976337, train_acc = 0.9850954820680019\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 78, train_loss = 7.263642001897097, train_acc = 0.9852119236143456\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 79, train_loss = 7.168200679123402, train_acc = 0.9852119236143456\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 80, train_loss = 7.07471526414156, train_acc = 0.9853283651606893\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 81, train_loss = 6.983112433925271, train_acc = 0.9853283651606893\n",
      "test Acc 0.978584729981378:\n",
      "30th- epoch: 82, train_loss = 6.893396073952317, train_acc = 0.9855612482533768\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 83, train_loss = 6.805542428046465, train_acc = 0.9856776897997206\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 84, train_loss = 6.719479529187083, train_acc = 0.985910572892408\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 85, train_loss = 6.635122634470463, train_acc = 0.985910572892408\n",
      "test Acc 0.979050279329609:\n",
      "30th- epoch: 86, train_loss = 6.552523411810398, train_acc = 0.9860270144387517\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 87, train_loss = 6.471503445878625, train_acc = 0.986376339077783\n",
      "test Acc 0.9804469273743017:\n",
      "30th- epoch: 88, train_loss = 6.39203293249011, train_acc = 0.9868421052631579\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 89, train_loss = 6.314037756994367, train_acc = 0.9868421052631579\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 90, train_loss = 6.237553706392646, train_acc = 0.9870749883558454\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 91, train_loss = 6.162395752966404, train_acc = 0.9873078714485328\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 92, train_loss = 6.088757984340191, train_acc = 0.9873078714485328\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 93, train_loss = 6.0164138693362474, train_acc = 0.9874243129948765\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 94, train_loss = 5.945478362962604, train_acc = 0.9878900791802515\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 95, train_loss = 5.875710196793079, train_acc = 0.9881229622729389\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 96, train_loss = 5.8073878940194845, train_acc = 0.9883558453656265\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 97, train_loss = 5.74009938724339, train_acc = 0.9884722869119702\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 98, train_loss = 5.674107560887933, train_acc = 0.9888216115510013\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 99, train_loss = 5.609252421185374, train_acc = 0.9889380530973452\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 100, train_loss = 5.545531453564763, train_acc = 0.9891709361900326\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 101, train_loss = 5.483003158122301, train_acc = 0.9895202608290639\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 102, train_loss = 5.421463366597891, train_acc = 0.9895202608290639\n",
      "test Acc 0.9813780260707635:\n",
      "30th- epoch: 103, train_loss = 5.361143117770553, train_acc = 0.989869585468095\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 104, train_loss = 5.3017533197999, train_acc = 0.9902189101071263\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 105, train_loss = 5.2433927822858095, train_acc = 0.9902189101071263\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 106, train_loss = 5.185996955260634, train_acc = 0.990801117838845\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 107, train_loss = 5.12945946585387, train_acc = 0.990801117838845\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 108, train_loss = 5.073824065737426, train_acc = 0.9909175593851887\n",
      "test Acc 0.9809124767225326:\n",
      "30th- epoch: 109, train_loss = 5.019039493985474, train_acc = 0.9909175593851887\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 110, train_loss = 4.965218626894057, train_acc = 0.9911504424778761\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 111, train_loss = 4.912229220382869, train_acc = 0.9912668840242198\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 112, train_loss = 4.860142444260418, train_acc = 0.9914997671169073\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 113, train_loss = 4.808757306076586, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 114, train_loss = 4.757991694845259, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 115, train_loss = 4.708345807157457, train_acc = 0.9917326502095948\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 116, train_loss = 4.659418533556163, train_acc = 0.9917326502095948\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 117, train_loss = 4.6114893751218915, train_acc = 0.9916162086632511\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 118, train_loss = 4.564026067964733, train_acc = 0.9917326502095948\n",
      "test Acc 0.9818435754189944:\n",
      "30th- epoch: 119, train_loss = 4.517412515357137, train_acc = 0.9917326502095948\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 120, train_loss = 4.471610758453608, train_acc = 0.9918490917559385\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 121, train_loss = 4.426098134368658, train_acc = 0.9919655333022822\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 122, train_loss = 4.381596361286938, train_acc = 0.9921984163949698\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 123, train_loss = 4.337348135188222, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 124, train_loss = 4.2942475555464625, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 125, train_loss = 4.251362595707178, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 126, train_loss = 4.2095139948651195, train_acc = 0.9923148579413135\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 127, train_loss = 4.168001263402402, train_acc = 0.9925477410340009\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 128, train_loss = 4.127434686757624, train_acc = 0.9925477410340009\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 129, train_loss = 4.087222741916776, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 130, train_loss = 4.047896748408675, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 131, train_loss = 4.008912546560168, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 132, train_loss = 3.970766772516072, train_acc = 0.9927806241266884\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 133, train_loss = 3.9330044696107507, train_acc = 0.9928970656730322\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 134, train_loss = 3.8956362614408135, train_acc = 0.9931299487657196\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 135, train_loss = 3.859197306446731, train_acc = 0.9931299487657196\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 136, train_loss = 3.822765245102346, train_acc = 0.9932463903120633\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 137, train_loss = 3.787263954989612, train_acc = 0.9935957149510946\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 138, train_loss = 3.7523875376209617, train_acc = 0.9937121564974383\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 139, train_loss = 3.717457174323499, train_acc = 0.993828598043782\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 140, train_loss = 3.683877200819552, train_acc = 0.9939450395901258\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 141, train_loss = 3.650113402865827, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 142, train_loss = 3.617390776053071, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 143, train_loss = 3.5847820537164807, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 144, train_loss = 3.5530212353914976, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 145, train_loss = 3.5214288607239723, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 146, train_loss = 3.490654327441007, train_acc = 0.9941779226828132\n",
      "test Acc 0.9823091247672253:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 147, train_loss = 3.4598238528706133, train_acc = 0.994294364229157\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 148, train_loss = 3.4300296497531235, train_acc = 0.9944108057755007\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 149, train_loss = 3.4002596978098154, train_acc = 0.9946436888681882\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 150, train_loss = 3.371155075263232, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 151, train_loss = 3.3422959577292204, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 152, train_loss = 3.314156390260905, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 153, train_loss = 3.2858683331869543, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 154, train_loss = 3.2585742720402777, train_acc = 0.9947601304145319\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 155, train_loss = 3.231568167451769, train_acc = 0.9948765719608756\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 156, train_loss = 3.2044372246600688, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 157, train_loss = 3.1784780849702656, train_acc = 0.9949930135072194\n",
      "test Acc 0.9823091247672253:\n",
      "30th- epoch: 158, train_loss = 3.152250492479652, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 159, train_loss = 3.1264889142476022, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 160, train_loss = 3.101561015471816, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 161, train_loss = 3.07635062886402, train_acc = 0.9949930135072194\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 162, train_loss = 3.0517363846302032, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 163, train_loss = 3.0277631408534944, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 164, train_loss = 3.0036374959163368, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 165, train_loss = 2.9800358931533992, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 166, train_loss = 2.9569488898850977, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 167, train_loss = 2.9339500055648386, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 168, train_loss = 2.9112670817412436, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 169, train_loss = 2.8891588519327343, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 170, train_loss = 2.8669554009102285, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 171, train_loss = 2.8454991541802883, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 172, train_loss = 2.823981823399663, train_acc = 0.9951094550535631\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 173, train_loss = 2.8027299605309963, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 174, train_loss = 2.7821653285063803, train_acc = 0.9952258965999069\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 175, train_loss = 2.761507995892316, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 176, train_loss = 2.7411667085252702, train_acc = 0.9953423381462506\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 177, train_loss = 2.7214336288161576, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 178, train_loss = 2.701534513849765, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 179, train_loss = 2.6821152050979435, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 180, train_loss = 2.6629325258545578, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 181, train_loss = 2.6439394033513963, train_acc = 0.9954587796925943\n",
      "test Acc 0.9827746741154563:\n",
      "30th- epoch: 182, train_loss = 2.625457091256976, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 183, train_loss = 2.6068530324846506, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 184, train_loss = 2.58853522548452, train_acc = 0.9956916627852818\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 185, train_loss = 2.5709336404688656, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 186, train_loss = 2.5530390688218176, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 187, train_loss = 2.535552252084017, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 188, train_loss = 2.5184971280395985, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 189, train_loss = 2.5013536226470023, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 190, train_loss = 2.4847442999016494, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 191, train_loss = 2.4680584974121302, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 192, train_loss = 2.4516931604593992, train_acc = 0.9958081043316255\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 193, train_loss = 2.4356969986110926, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 194, train_loss = 2.4196136842947453, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 195, train_loss = 2.4041570492554456, train_acc = 0.996040987424313\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 196, train_loss = 2.3884750965517014, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 197, train_loss = 2.3730912015307695, train_acc = 0.996040987424313\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 198, train_loss = 2.3583284795749933, train_acc = 0.9961574289706567\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 199, train_loss = 2.343243579613045, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 200, train_loss = 2.328533124178648, train_acc = 0.9961574289706567\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 201, train_loss = 2.314158017979935, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 202, train_loss = 2.299863011809066, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 203, train_loss = 2.285664926050231, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 204, train_loss = 2.271764022530988, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 205, train_loss = 2.2581880886573344, train_acc = 0.9962738705170004\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 206, train_loss = 2.244520241394639, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 207, train_loss = 2.231165111064911, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 208, train_loss = 2.2182247161399573, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 209, train_loss = 2.204975188942626, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 210, train_loss = 2.192133791744709, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 211, train_loss = 2.179448613198474, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 212, train_loss = 2.1672305937390774, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 213, train_loss = 2.1545733213424683, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 214, train_loss = 2.142814616439864, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 215, train_loss = 2.1305266295094043, train_acc = 0.996506753609688\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 216, train_loss = 2.1186372365336865, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 217, train_loss = 2.1071904748678207, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 218, train_loss = 2.0952778793871403, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 219, train_loss = 2.0841156356036663, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 220, train_loss = 2.073053402127698, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 221, train_loss = 2.0615445238072425, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 222, train_loss = 2.05063006025739, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 223, train_loss = 2.0400669302325696, train_acc = 0.9966231951560317\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 224, train_loss = 2.0290069356560707, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 225, train_loss = 2.018763804109767, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 226, train_loss = 2.0083802081644535, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 227, train_loss = 1.9981570926029235, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 228, train_loss = 1.9879536691587418, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 229, train_loss = 1.978017107816413, train_acc = 0.9967396367023754\n",
      "test Acc 0.9832402234636871:\n",
      "30th- epoch: 230, train_loss = 1.967790899099782, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 231, train_loss = 1.9579202570021152, train_acc = 0.9967396367023754\n",
      "test Acc 0.9837057728119181:\n",
      "30th- epoch: 232, train_loss = 1.9482108044903725, train_acc = 0.9968560782487191\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 233, train_loss = 1.9389194461982697, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 234, train_loss = 1.9292148638051003, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 235, train_loss = 1.9202148504555225, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 236, train_loss = 1.910981134744361, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 237, train_loss = 1.9018893614411354, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 238, train_loss = 1.892901214538142, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 239, train_loss = 1.8841648027300835, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 240, train_loss = 1.8750560556072742, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 241, train_loss = 1.8662497289478779, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 242, train_loss = 1.8582040916662663, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 243, train_loss = 1.8493855185806751, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 244, train_loss = 1.8408612348139286, train_acc = 0.9970889613414066\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 245, train_loss = 1.833073670626618, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 246, train_loss = 1.824809793382883, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 247, train_loss = 1.8164196088910103, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 248, train_loss = 1.8087430149316788, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 249, train_loss = 1.8008604273200035, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 250, train_loss = 1.793185101239942, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 251, train_loss = 1.7850045809755102, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 252, train_loss = 1.777928094030358, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 253, train_loss = 1.769958889693953, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 254, train_loss = 1.7628211391856894, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 255, train_loss = 1.7551023438572884, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 256, train_loss = 1.7481812698533759, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 257, train_loss = 1.7411241084337234, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 258, train_loss = 1.7336251847445965, train_acc = 0.9972054028877504\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 259, train_loss = 1.7269170867512003, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 260, train_loss = 1.7195268335053697, train_acc = 0.9975547275267815\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 261, train_loss = 1.7130668523022905, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 262, train_loss = 1.7063594510545954, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 263, train_loss = 1.6992137270281091, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 264, train_loss = 1.6928533477475867, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 265, train_loss = 1.6859787130961195, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 266, train_loss = 1.6796979270875454, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 267, train_loss = 1.67288790398743, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 268, train_loss = 1.66700631135609, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 269, train_loss = 1.6605982892215252, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 270, train_loss = 1.6538881150772795, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 271, train_loss = 1.6482858074596152, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 272, train_loss = 1.642044031410478, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 273, train_loss = 1.6359791904687881, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 274, train_loss = 1.6296720281243324, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 275, train_loss = 1.624039592803456, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 276, train_loss = 1.6181639581918716, train_acc = 0.9976711690731253\n",
      "test Acc 0.9851024208566108:\n",
      "30th- epoch: 277, train_loss = 1.612371681840159, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "30th- epoch: 278, train_loss = 1.6067940244683996, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "30th- epoch: 279, train_loss = 1.6007216336438432, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "30th- epoch: 280, train_loss = 1.5950909791281447, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "30th- epoch: 281, train_loss = 1.5894387686857954, train_acc = 0.9976711690731253\n",
      "test Acc 0.9855679702048417:\n",
      "30th- epoch: 282, train_loss = 1.5842695161700249, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "30th- epoch: 283, train_loss = 1.5783404608955607, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "30th- epoch: 284, train_loss = 1.5734698375454172, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "30th- epoch: 285, train_loss = 1.5680300580570474, train_acc = 0.9977876106194691\n",
      "test Acc 0.9855679702048417:\n",
      "30th- epoch: 286, train_loss = 1.562727084965445, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 287, train_loss = 1.5571115985512733, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 288, train_loss = 1.5522475751349702, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 289, train_loss = 1.5471446961164474, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 290, train_loss = 1.5420092070708051, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 291, train_loss = 1.5371598018100485, train_acc = 0.9977876106194691\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 292, train_loss = 1.531773446709849, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 293, train_loss = 1.5268149599432945, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 294, train_loss = 1.5222029151627794, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 295, train_loss = 1.517101110308431, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 296, train_loss = 1.5122799860546365, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 297, train_loss = 1.507816269993782, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 298, train_loss = 1.5026412270963192, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 299, train_loss = 1.4985367817571387, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 300, train_loss = 1.493764415383339, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 301, train_loss = 1.4892137931892648, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 302, train_loss = 1.4842734014382586, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 303, train_loss = 1.480153621523641, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 304, train_loss = 1.4756204324075952, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 305, train_loss = 1.4714362658560276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 306, train_loss = 1.4666281217942014, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 307, train_loss = 1.462279366911389, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 308, train_loss = 1.4582799760391936, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 309, train_loss = 1.4535186365246773, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 310, train_loss = 1.4498940097400919, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 311, train_loss = 1.4455491925473325, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 312, train_loss = 1.4414151174132712, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 313, train_loss = 1.4372956044971943, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 314, train_loss = 1.4328293353319168, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 315, train_loss = 1.4291149501805194, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 316, train_loss = 1.4252365256543271, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 317, train_loss = 1.4206832994823344, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 318, train_loss = 1.417315358936321, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 319, train_loss = 1.4130122947390191, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 320, train_loss = 1.4090310260653496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 321, train_loss = 1.4055130407214165, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 322, train_loss = 1.4013990201056004, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 323, train_loss = 1.3979354712064378, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 324, train_loss = 1.3936929616029374, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 325, train_loss = 1.390568058937788, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 326, train_loss = 1.3867087289690971, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 327, train_loss = 1.383033259480726, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 328, train_loss = 1.3794553466141224, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 329, train_loss = 1.3754531008307822, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 330, train_loss = 1.372203204780817, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 331, train_loss = 1.3686921410262585, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 332, train_loss = 1.3653284795582294, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 333, train_loss = 1.361428366333712, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 334, train_loss = 1.3579373334650882, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 335, train_loss = 1.354787750809919, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 336, train_loss = 1.3510785587131977, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 337, train_loss = 1.3480451579089276, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 338, train_loss = 1.3443197284941562, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 339, train_loss = 1.3413389883935452, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 340, train_loss = 1.3377214160864241, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 341, train_loss = 1.3347400886123069, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 342, train_loss = 1.3310402545030229, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 343, train_loss = 1.3283851283486001, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 344, train_loss = 1.3250872045755386, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 345, train_loss = 1.3218672188813798, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 346, train_loss = 1.3183759326930158, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 347, train_loss = 1.3155768886208534, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 348, train_loss = 1.3124555622343905, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 349, train_loss = 1.3095602604444139, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 350, train_loss = 1.306055390567053, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 351, train_loss = 1.3033326392178424, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 352, train_loss = 1.3000332526862621, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 353, train_loss = 1.2973068058490753, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 354, train_loss = 1.294111531227827, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 355, train_loss = 1.290962215512991, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 356, train_loss = 1.2886289830203168, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 357, train_loss = 1.2856031482224353, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 358, train_loss = 1.2827244524960406, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 359, train_loss = 1.2794397175312042, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 360, train_loss = 1.2769962127204053, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 361, train_loss = 1.274179135740269, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 362, train_loss = 1.2715277944807895, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 363, train_loss = 1.2683262812788598, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 364, train_loss = 1.2658559207920916, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 365, train_loss = 1.2628344471449964, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 366, train_loss = 1.2601121949846856, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 367, train_loss = 1.2572744588251226, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 368, train_loss = 1.2551392155583017, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 369, train_loss = 1.2523554128711112, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 370, train_loss = 1.2496874717180617, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 371, train_loss = 1.246746025979519, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 372, train_loss = 1.244412425905466, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 373, train_loss = 1.2418615681235678, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 374, train_loss = 1.239431248337496, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 375, train_loss = 1.2364076624508016, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 376, train_loss = 1.2342411813442595, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 377, train_loss = 1.2313821178977378, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 378, train_loss = 1.2287474523182027, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 379, train_loss = 1.2268330603837967, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 380, train_loss = 1.2242299628560431, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 381, train_loss = 1.2214389592409134, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 382, train_loss = 1.2193153277039528, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 383, train_loss = 1.216423325240612, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 384, train_loss = 1.2145877207512967, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 385, train_loss = 1.2121507326955907, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 386, train_loss = 1.2093531687860377, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 387, train_loss = 1.2074143390054815, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 388, train_loss = 1.2046048641204834, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 389, train_loss = 1.2028507962822914, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 390, train_loss = 1.2004317206447013, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 391, train_loss = 1.1977773259277456, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 392, train_loss = 1.1958361466531642, train_acc = 0.9977876106194691\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 393, train_loss = 1.1930759226088412, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 394, train_loss = 1.1914441734552383, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 395, train_loss = 1.189082060009241, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 396, train_loss = 1.1864656955003738, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 397, train_loss = 1.1846821941435337, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 398, train_loss = 1.1819965653121471, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 399, train_loss = 1.1803327935631387, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 400, train_loss = 1.1781240838463418, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 401, train_loss = 1.1754755514557473, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 402, train_loss = 1.1739165298640728, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 403, train_loss = 1.1717074724729173, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 404, train_loss = 1.1692176014184952, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 405, train_loss = 1.1674729449150618, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 406, train_loss = 1.164905484765768, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 407, train_loss = 1.1634322789905127, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 408, train_loss = 1.1612535156309605, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 409, train_loss = 1.1587333604693413, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 410, train_loss = 1.157262002438074, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 411, train_loss = 1.1551635464129504, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 412, train_loss = 1.152757922798628, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 413, train_loss = 1.1511490581033286, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 414, train_loss = 1.148666251450777, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 415, train_loss = 1.1472308995726053, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 416, train_loss = 1.1451799869537354, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 417, train_loss = 1.1427932108344976, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 418, train_loss = 1.1413789875805378, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 419, train_loss = 1.1393459600803908, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 420, train_loss = 1.1369730954465922, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 421, train_loss = 1.1356170251965523, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 422, train_loss = 1.1336333689687308, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 423, train_loss = 1.1313600478169974, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 424, train_loss = 1.1298717819154263, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 425, train_loss = 1.1275478278694209, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 426, train_loss = 1.1262227706611156, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 427, train_loss = 1.123864004999632, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 428, train_loss = 1.1225345457496587, train_acc = 0.9979040521658128\n",
      "test Acc 0.9864990689013036:\n",
      "30th- epoch: 429, train_loss = 1.120652542769676, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 430, train_loss = 1.1184020278451499, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 431, train_loss = 1.1170537173748016, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 432, train_loss = 1.1147349625825882, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 433, train_loss = 1.1135661130247172, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 434, train_loss = 1.1116510766150896, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 435, train_loss = 1.1094831302762032, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 436, train_loss = 1.1082307311298791, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 437, train_loss = 1.1064117476344109, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 438, train_loss = 1.1042144099774305, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 439, train_loss = 1.1030220687389374, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 440, train_loss = 1.100770726799965, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 441, train_loss = 1.0995651694538537, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30th- epoch: 442, train_loss = 1.0978123222885188, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 443, train_loss = 1.0956230523588601, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 444, train_loss = 1.094519704580307, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 445, train_loss = 1.0927419923245907, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 446, train_loss = 1.0906214912829455, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 447, train_loss = 1.089521593094105, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 448, train_loss = 1.0878000110387802, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 449, train_loss = 1.0857076905667782, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 450, train_loss = 1.084620177745819, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 451, train_loss = 1.0825495161116123, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 452, train_loss = 1.081297845899826, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 453, train_loss = 1.079262476414442, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 454, train_loss = 1.0781953570840415, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 455, train_loss = 1.0760668379662093, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 456, train_loss = 1.0750306211411953, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 457, train_loss = 1.0733944984676782, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 458, train_loss = 1.0713771134614944, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 459, train_loss = 1.0703679658472538, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 460, train_loss = 1.0687194553611334, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 461, train_loss = 1.0667228884994984, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 462, train_loss = 1.0657185738382395, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 463, train_loss = 1.0637875137326773, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 464, train_loss = 1.062535105884308, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 465, train_loss = 1.0606863076391164, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 466, train_loss = 1.059538621455431, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 467, train_loss = 1.0582168164255563, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 468, train_loss = 1.0562576726078987, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 469, train_loss = 1.0551443099975586, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 470, train_loss = 1.0531856628658716, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 471, train_loss = 1.0522060295043048, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 472, train_loss = 1.0508105593326036, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 473, train_loss = 1.0489594216051046, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 474, train_loss = 1.0478467295470182, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 475, train_loss = 1.0460265216825064, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 476, train_loss = 1.0449416314659175, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 477, train_loss = 1.043723368406063, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 478, train_loss = 1.0418041907250881, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 479, train_loss = 1.040798799454933, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 480, train_loss = 1.0389454116520938, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 481, train_loss = 1.037943178176647, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 482, train_loss = 1.0367064041492995, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 483, train_loss = 1.034926075488329, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 484, train_loss = 1.0334188540873583, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 485, train_loss = 1.0325841965677682, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 486, train_loss = 1.031174447387457, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 487, train_loss = 1.0293603725731373, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 488, train_loss = 1.0284313013253268, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 489, train_loss = 1.0271938902733382, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 490, train_loss = 1.025465631246334, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 491, train_loss = 1.0244303569197655, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 492, train_loss = 1.022731559962267, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 493, train_loss = 1.0217902176082134, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 494, train_loss = 1.0205273615720216, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 495, train_loss = 1.0193045089545194, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 496, train_loss = 1.017633260547882, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 497, train_loss = 1.0162890242936555, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 498, train_loss = 1.0153773861529771, train_acc = 0.9979040521658128\n",
      "test Acc 0.9860335195530726:\n",
      "30th- epoch: 499, train_loss = 1.0136723543109838, train_acc = 0.9980204937121565\n",
      "test Acc 0.9860335195530726:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 30/30 [3:24:23<00:00, 399.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3h 24min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if __name__ == '__main__':\n",
    "    img_path = 'D:virus/image/3gram_512_pca/image_arr.npy'\n",
    "    label_path = 'D:virus/image/3gram_512_pca/label_arr.npy'\n",
    "    \n",
    "    data_a, label_a = np.load(img_path), np.load(label_path)\n",
    "    \n",
    "    idx = np.argsort(label_a)\n",
    "    \n",
    "    sorted_data = data_a[idx]\n",
    "    sorted_label = sorted(label_a)\n",
    "        \n",
    "    BATCH_SIZE = 64\n",
    "    TOTAL = 30\n",
    "    EPOCH = 500\n",
    "    NUM_CLASS = 9\n",
    "    LR = 0.005\n",
    "    SEED = [s for s in range(TOTAL)]\n",
    "    INPUT_NODES = 512                   \n",
    "    \n",
    "    CUDA_N = 'cuda:1'\n",
    "    \n",
    "    # creating data indices for spliting\n",
    "    full_dataset = CustomDataset(sorted_data, sorted_label)\n",
    "    train_size = int(0.8 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # spliting\n",
    "    torch.manual_seed(10)\n",
    "    train_dataset, test_dataset = data.random_split(full_dataset, [train_size, test_size])\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle = False)\n",
    "    test_loader = data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    loss_total = []\n",
    "    acc_total = []\n",
    "    pred_total = []\n",
    "    true_total = []\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(TOTAL)):\n",
    "        \n",
    "        device = torch.device(CUDA_N if torch.cuda.is_available() else 'cpu')\n",
    "        torch.manual_seed(SEED[i])\n",
    "        net = Algorithm1(INPUT_NODES, NUM_CLASS)           \n",
    "        net.to(device)\n",
    "        print(net)\n",
    "        \n",
    "        softmax = nn.Softmax()\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(net.parameters(), lr=LR, momentum = 0.1)\n",
    "        \n",
    "        loss_list = []\n",
    "        train_acc_list = []\n",
    "        test_acc_list = []\n",
    "        \n",
    "        pred_temp = []\n",
    "        true_temp = []\n",
    "        \n",
    "        for epoch in range(EPOCH):\n",
    "            net.train()\n",
    "            running_loss = 0\n",
    "            total = train_size\n",
    "            correct = 0 \n",
    "            \n",
    "            for step, image_and_label in enumerate(train_loader):\n",
    "                inputs, labels = image_and_label            \n",
    "                inputs, labels = inputs.type(torch.FloatTensor).to(device), labels.type(torch.LongTensor).to(device)\n",
    "                \n",
    "                outputs = net(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, pred = torch.max(outputs, dim=1)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            train_acc = correct/total\n",
    "            loss_list.append(running_loss)\n",
    "            train_acc_list.append(train_acc)\n",
    "            print('{}th- epoch: {}, train_loss = {}, train_acc = {}'.format(i+1, epoch, running_loss, train_acc))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                net.eval()\n",
    "                correct = 0\n",
    "                total = test_size\n",
    "                pt, tt = [], []\n",
    "                \n",
    "                for step_t, image_and_label_t in enumerate(test_loader):\n",
    "                    inputs_t, labels_t = image_and_label_t            \n",
    "                    inputs_t, labels_t = inputs_t.type(torch.FloatTensor).to(device), labels_t.type(torch.LongTensor).to(device)\n",
    "                    \n",
    "                    outputs_t = net(inputs_t)\n",
    "                    outputs_t = softmax(outputs_t)\n",
    "                    \n",
    "                    # test accuracy\n",
    "                    _, pred_t = torch.max(outputs_t, dim = 1)\n",
    "                    \n",
    "                    pt.append(pred_t)\n",
    "                    tt.append(labels_t)\n",
    "                    \n",
    "                    correct += (pred_t == labels_t).sum().item()\n",
    "                    \n",
    "                pred_temp.append(torch.cat(pt))\n",
    "                true_temp.append(torch.cat(tt))\n",
    "                \n",
    "                test_acc = correct/total\n",
    "                test_acc_list.append(test_acc)\n",
    "                \n",
    "                print('test Acc {}:'.format(test_acc))\n",
    "                \n",
    "        best_result_index = np.argmax(np.array(test_acc_list))\n",
    "        loss_total.append(loss_list[best_result_index])\n",
    "        acc_total.append(test_acc_list[best_result_index])\n",
    "        pred_total.append(pred_temp[best_result_index].tolist())\n",
    "        true_total.append(true_temp[best_result_index].tolist())\n",
    "        \n",
    "    file_name = 'res/Algorithm1_3gram'\n",
    "    torch.save(net.state_dict(), file_name +'.pth')\n",
    "    \n",
    "    loss_DF = pd.DataFrame(loss_total)\n",
    "    loss_DF.to_csv(file_name+\" loss.csv\")\n",
    "    \n",
    "    acc_DF = pd.DataFrame(acc_total)\n",
    "    acc_DF.to_csv(file_name +\" acc.csv\")\n",
    "    \n",
    "    pred_DF = pd.DataFrame(pred_total)\n",
    "    pred_DF.to_csv(file_name +\" pred.csv\")\n",
    "    \n",
    "    true_DF = pd.DataFrame(true_total)\n",
    "    true_DF.to_csv(file_name +\" true.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
